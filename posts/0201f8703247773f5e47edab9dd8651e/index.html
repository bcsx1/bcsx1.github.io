<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【目标检测算法】YOLO-V5训练结果的分析与评价 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【目标检测算法】YOLO-V5训练结果的分析与评价" />
<meta property="og:description" content="文章目录 零、目标检测性能指标一、 confusion_matrix二、P&amp;R&amp;PR&amp;F1_curve1. P_curve2. R_curve3. PR_curve4. F1_curve 三、labels&amp;labels_correlogram四、result.png&amp;result.txt1. loss functions2. result.csv 五、train_batchx六、val_batchx_labels&amp;val_batchx_pred voc2007数据集下的结果评价： 权重文件为：yolov5m。我只训练了10轮 零、目标检测性能指标 检测精度检测速度Precision，Recall，F1 score前传耗时IoU（Intersection over Union）每秒帧数 FPS（Frames Per Sencond）P-R curve浮点运算量（FLOPS）AP、mAP 检测速度
前传耗时(ms)：从输入一张图像到输出最终结果所消耗的时间，包括前处理耗时(如图像归一化)、网络前传耗时、后处理耗时(如非极大值抑制)每秒帧数FPS (Frames Per Second)： 每秒钟能处理的图像数量浮点运算量(FLOPS)：处理一-张图像所需要的浮点运算数量,跟具体软硬件没有关系，可以公平地比较不同算法之间的检测速度 检测精度 下面会逐步介绍
一、 confusion_matrix 在机器学习领域和统计分类问题中，混淆矩阵（英语：confusion matrix）是可视化工具，特别用于监督学习，在无监督学习一般叫做匹配矩阵。矩阵的每一列代表一个类的实例预测，而每一行表示一个实际的类的实例。之所以如此命名，是因为通过这个矩阵可以方便地看出机器是否将两个不同的类混淆了（比如说把一个类错当成了另一个）。
混淆矩阵的每一列代表了预测类别，每一行是预测类别。每一列是真实类别。矩阵中Aij的含义是：第j个类别被预测为第i个类别的概率。 二、P&amp;R&amp;PR&amp;F1_curve 涉及到准确率（查准率）和召回率（查全率）。这一块内容其他博主介绍也十分详细。
1. P_curve precision（单一类准确率） : 预测为positive的准确率。
准确率和置信度的关系图。
意思就是，当我设置置信度为某一数值的时候，各个类别识别的准确率。可以看到，当置信度越大的时候，类别检测的越准确。这也很好理解，只有confidence很大，才被判断是某一类别。但也很好想到，这样的话，会漏检一些置信度低的类别。
2. R_curve recall（真实为positive的准确率），即正样本有多少被找出来了（召回了多少）。
召回率（查全率）和置信度的关系图。
意思就是，当我设置置信度为某一数值的时候，各个类别查全的概率。可以看到，当置信度越小的时候，类别检测的越全面。
3. PR_curve mAP 是 Mean Average Precision 的缩写，即 均值平均精度。可以看到：精度越高，召回率越低。
但我们希望我们的网络，在准确率很高的前提下，尽可能的检测到全部的类别。所以希望我们的曲线接近（1，1）点，即希望mAP曲线的面积尽可能接近1。
4. F1_curve F1分数（F1-score）是分类问题的一个衡量指标。一些多分类问题的机器学习竞赛，常常将F1-score作为最终测评的方法。它是精确率和召回率的调和平均数，最大为1，最小为0。
对于某个分类，综合了Precision和Recall的一个判断指标，F1-Score的值是从0到1的，1是最好，0是最差。
三、labels&amp;labels_correlogram 第一个图是训练集得数据量，每个类别有多少个第二个是框的尺寸和数量第三个是center点的位置。可以看到口罩数据集中口罩的位置大多分布在图像的中心。第四个是labeld的高宽。口罩一般相比于整个图片比较小，所以看到样本大多分布在（0-0.2，0-0.2）。 ？？？这个框体的输出结果是做什么用的，我也没搜到…
四、result.png&amp;result.txt 1. loss functions 损失函数是用来衡量模型预测值和真实值不一样的程度，极大程度上决定了模型的性能。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/0201f8703247773f5e47edab9dd8651e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-27T14:36:27+08:00" />
<meta property="article:modified_time" content="2022-09-27T14:36:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【目标检测算法】YOLO-V5训练结果的分析与评价</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_4" rel="nofollow">零、目标检测性能指标</a></li><li><a href="#_confusion_matrix_25" rel="nofollow">一、 confusion_matrix</a></li><li><a href="#PRPRF1_curve_35" rel="nofollow">二、P&amp;R&amp;PR&amp;F1_curve</a></li><li><ul><li><a href="#1_P_curve_37" rel="nofollow">1. P_curve</a></li><li><a href="#2_R_curve_43" rel="nofollow">2. R_curve</a></li><li><a href="#3_PR_curve_47" rel="nofollow">3. PR_curve</a></li><li><a href="#4_F1_curve_52" rel="nofollow">4. F1_curve</a></li></ul> 
  </li><li><a href="#labelslabels_correlogram_58" rel="nofollow">三、labels&amp;labels_correlogram</a></li><li><a href="#resultpngresulttxt_70" rel="nofollow">四、result.png&amp;result.txt</a></li><li><ul><li><a href="#1_loss_functions_71" rel="nofollow">1. loss functions</a></li><li><a href="#2_resultcsv_98" rel="nofollow">2. result.csv</a></li></ul> 
  </li><li><a href="#train_batchx_108" rel="nofollow">五、train_batchx</a></li><li><a href="#val_batchx_labelsval_batchx_pred_113" rel="nofollow">六、val_batchx_labels&amp;val_batchx_pred</a></li></ul> 
</div> 
<br> 
<strong>voc2007数据集下的结果评价：</strong> 权重文件为：yolov5m。我只训练了10轮 
<p></p> 
<h2><a id="_4"></a>零、目标检测性能指标</h2> 
<table><thead><tr><th><strong>检测精度</strong></th><th><strong>检测速度</strong></th></tr></thead><tbody><tr><td>Precision，Recall，F1 score</td><td>前传耗时</td></tr><tr><td>IoU（Intersection over Union）</td><td>每秒帧数 FPS（Frames Per Sencond）</td></tr><tr><td>P-R curve</td><td>浮点运算量（FLOPS）</td></tr><tr><td>AP、mAP</td><td></td></tr></tbody></table> 
<p><strong>检测速度</strong></p> 
<ul><li>前传耗时(ms)：从<strong>输入一张图像到输出最终结果所消耗的时间</strong>，包括前处理耗时(如图像归一化)、网络前传耗时、后处理耗时(如非极大值抑制)</li><li>每秒帧数FPS (Frames Per Second)： 每秒钟能处理的图像数量</li><li>浮点运算量(FLOPS)：处理一-张图像所需要的浮点运算数量,跟具体软硬件没有关系，可以公平地比较不同算法之间的检测速度</li></ul> 
<blockquote> 
 <p><strong>检测精度</strong> 下面会逐步介绍</p> 
</blockquote> 
<h2><a id="_confusion_matrix_25"></a>一、 confusion_matrix</h2> 
<p><img src="https://images2.imgbox.com/27/65/evFJLJpq_o.png" alt="请添加图片描述"></p> 
<blockquote> 
 <p>在机器学习领域和统计分类问题中，混淆矩阵（英语：confusion matrix）是可视化工具，<strong>特别用于监督学习</strong>，在无监督学习一般叫做匹配矩阵。矩阵的每一列代表一个类的实例预测，而每一行表示一个实际的类的实例。之所以如此命名，是因为通过这个矩阵可以方便地看出机器是否将两个不同的类混淆了（比如说把一个类错当成了另一个）。</p> 
</blockquote> 
<ul><li>混淆矩阵的每一列代表了预测类别，每一行是预测类别。每一列是真实类别。</li><li>矩阵中<strong>Aij</strong>的含义是：<strong>第j个类别被预测为第i个类别的概率</strong>。</li></ul> 
<h2><a id="PRPRF1_curve_35"></a>二、P&amp;R&amp;PR&amp;F1_curve</h2> 
<p>涉及到<strong>准确率（查准率）和召回率（查全率）</strong>。这一块内容其他博主介绍也十分详细。</p> 
<h3><a id="1_P_curve_37"></a>1. P_curve</h3> 
<p><strong>precision（单一类准确率） : 预测为positive的准确率。</strong><br> <img src="https://images2.imgbox.com/16/8f/2aTAUGXB_o.png" alt="请添加图片描述"><br> 准确率和置信度的关系图。<br> 意思就是，当我设置置信度为某一数值的时候，各个类别识别的准确率。可以看到，当置信度越大的时候，类别检测的越准确。这也很好理解，只有confidence很大，才被判断是某一类别。但也很好想到，这样的话，会漏检一些置信度低的类别。</p> 
<h3><a id="2_R_curve_43"></a>2. R_curve</h3> 
<p><strong>recall（真实为positive的准确率），即正样本有多少被找出来了（召回了多少）。</strong><img src="https://images2.imgbox.com/66/bd/wfobDrrJ_o.png" alt="请添加图片描述"><br> 召回率（查全率）和置信度的关系图。<br> 意思就是，当我设置置信度为某一数值的时候，各个类别查全的概率。可以看到，当置信度越小的时候，类别检测的越全面。</p> 
<h3><a id="3_PR_curve_47"></a>3. PR_curve</h3> 
<p>mAP 是 <strong>Mean Average Precision</strong> 的缩写，即 均值平均精度。可以看到：精度越高，召回率越低。<br> 但我们希望我们的网络，在准确率很高的前提下，尽可能的检测到全部的类别。所以希望我们的曲线接近（1，1）点，即希望mAP曲线的面积尽可能接近1。<br> <img src="https://images2.imgbox.com/84/1c/uBQzQpSE_o.png" alt="请添加图片描述"></p> 
<h3><a id="4_F1_curve_52"></a>4. F1_curve</h3> 
<p>F1分数（F1-score）是分类问题的一个衡量指标。一些多分类问题的机器学习竞赛，常常将F1-score作为最终测评的方法。<strong>它是精确率和召回率的调和平均数</strong>，最大为1，最小为0。</p> 
<p>对于某个分类，综合了Precision和Recall的一个判断指标，<strong>F1-Score的值是从0到1的，1是最好，0是最差。</strong><br> <img src="https://images2.imgbox.com/ea/7b/CBHikgWt_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/6a/dc/WP2TFQL8_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="labelslabels_correlogram_58"></a>三、labels&amp;labels_correlogram</h2> 
<p><img src="https://images2.imgbox.com/6c/c2/CCXHM5qX_o.jpg" alt="请添加图片描述"></p> 
<ul><li>第一个图是训练集得数据量，每个类别有多少个</li><li>第二个是框的尺寸和数量</li><li>第三个是center点的位置。<strong>可以看到口罩数据集中口罩的位置大多分布在图像的中心。</strong></li><li>第四个是labeld的高宽。<strong>口罩一般相比于整个图片比较小，所以看到样本大多分布在（0-0.2，0-0.2）。</strong></li></ul> 
<p><img src="https://images2.imgbox.com/45/bb/vyyvaaIG_o.jpg" alt="请添加图片描述"></p> 
<blockquote> 
 <p>？？？这个框体的输出结果是做什么用的，我也没搜到…</p> 
</blockquote> 
<h2><a id="resultpngresulttxt_70"></a>四、result.png&amp;result.txt</h2> 
<h3><a id="1_loss_functions_71"></a>1. loss functions</h3> 
<p>损失函数是用来衡量模型预测值和真实值不一样的程度，极大程度上决定了模型的性能。</p> 
<ul><li>定位损失box_loss：预测框与标定框之间的误差（GIoU）</li><li>置信度损失obj_loss：计算网络的置信度</li><li>分类损失cls_loss：计算锚框与对应的标定分类是否正确</li></ul> 
<p><img src="https://images2.imgbox.com/dc/7f/xx9W0lyz_o.png" alt="请添加图片描述"><br> Box：YOLOV5使用 GIOU loss作为bounding box的损失，Box推测为GIoU损失函数均值越小，方框越准<br> Objectness：推测为目标检测loss均值，越小目标检测越准<br> Classification：推测为分类loss均值，越小分类越准</p> 
<p>val BOX: 验证集bounding box损失<br> val Objectness：验证集目标检测loss均值<br> val classification：验证集分类loss均值</p> 
<p>Precision：精度（找对的正类/所有找到的正类）<br> Recall：真实为positive的准确率，即正样本有多少被找出来了（召回了多少）</p> 
<p>mAP@0.5:0.95（mAP@[0.5:0.95]）<br> 表示在不同IoU阈值（从0.5到0.95，步长0.05）（0.5、0.55、0.6、0.65、0.7、0.75、0.8、0.85、0.9、0.95）上的平均mAP。</p> 
<p>mAP@0.5：表示阈值大于0.5的平均mAP</p> 
<p><a href="https://blog.csdn.net/weixin_43869938/article/details/120732783?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E7%94%B1pr%E6%9B%B2%E7%BA%BF%E8%AE%A1%E7%AE%97map&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-120732783.142%5Ev46%5Epc_rank_34_default_2&amp;spm=1018.2226.3001.4187">目标检测中PR曲线和mAP<br> </a></p> 
<h3><a id="2_resultcsv_98"></a>2. result.csv</h3> 
<p>results.txt中最后三列是验证集结果，前面的是训练集结果，<strong>全部列分别是：<br> 训练次数，GPU消耗，边界框损失，目标检测损失，分类损失，total，targets，图片大小，P，R，mAP@.5, mAP@.5:.95, 验证集val Box, 验证集val obj, 验证集val cls</strong></p> 
<p><img src="https://images2.imgbox.com/15/c8/ecseTKOp_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="train_batchx_108"></a>五、train_batchx</h2> 
<p>这里我设置的一个batchsize是8，所以一次读了8张照片<br> <img src="https://images2.imgbox.com/61/c7/XAvbvi7o_o.jpg" alt="请添加图片描述"></p> 
<h2><a id="val_batchx_labelsval_batchx_pred_113"></a>六、val_batchx_labels&amp;val_batchx_pred</h2> 
<p>val_batchx_labels：验证集第x轮的<strong>实际标签</strong><br> <img src="https://images2.imgbox.com/03/10/Qnf5oapP_o.jpg" alt="请添加图片描述"><br> val_batchx_pred：验证集第x轮的<strong>预测标签</strong><br> <img src="https://images2.imgbox.com/b3/b3/xIIjiKyS_o.jpg" alt="请添加图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/df9c32ae30f67114af26091a112ca645/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【uni-app】点击左上角返回按钮，弹出弹窗或者是携带参数返回上一页</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/cea75e62490676bcfcc9fc5b616a2df4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">failed to parse field [name] of type [text] in document with id ‘1‘</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>