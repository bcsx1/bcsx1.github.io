<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Android OpenGL ES - 纹理 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Android OpenGL ES - 纹理" />
<meta property="og:description" content="纹理基本概念 纹理是一个2D图片（甚至也有1D和3D的纹理）
纹理坐标 为了能够把纹理映射(Map)到三角形上，我们需要指定三角形的每个顶点各自对应纹理的哪个部分.
这样每个顶点就会关联着一个纹理坐标(Texture Coordinate)，用来标明该从纹理图像的哪个部分采样（译注：采集片段颜色）。之后在图形的其它片段上进行片段插值(Fragment Interpolation)。
纹理坐标在x和y轴上，范围为0到1之间（注意我们使用的是2D纹理图像）。使用纹理坐标获取纹理颜色叫做采样(Sampling)。
纹理坐标起始于(0, 0)，也就是纹理图片的左下角，终始于(1, 1)，即纹理图片的右上角。
下面的图片展示了我们是如何把纹理坐标映射到三角形上的。
我们为三角形指定了3个纹理坐标点。如上图所示，我们希望三角形的左下角对应纹理的左下角，因此我们把三角形左下角顶点的纹理坐标设置为(0, 0)；三角形的上顶点对应于图片的上中位置所以我们把它的纹理坐标设置为(0.5, 1.0)；同理右下方的顶点设置为(1, 0)。
我们只要给顶点着色器传递这三个纹理坐标就行了，接下来它们会被传片段着色器中，它会为每个片段进行纹理坐标的插值。
纹理坐标看起来就像这样：
//纹理坐标
const GLfloat m_texture_coors[6] = { 0.0f, 0.0f, // 左下角 1.0f, 0.0f, // 右下角 0.5f, 1.0f//上 }; 2D纹理的坐标系是从左下角为原点向上为t轴,向右为s轴的坐标系。这个坐标系的y方向和GL坐标系相反，所以默认按顶点坐标系方向输入的图像是倒置的。
如果想要让纹理正向显示，我们需要做的一步工作便是将输入的纹理坐标或者顶点坐标进行y轴方向的倒置。
这些我们会在下面的示例中看到
加载图片 我们上面了解了纹理的坐标系之后，那么要做的第一件事自然是把它们加载到我们的应用中。
纹理图像可能被储存为各种各样的格式，每种都有自己的数据结构和排列，所以我们如何才能把这些图像加载到应用中呢？
我们这里采用Android上的API，
BitmapFactory.decodeResource(getResources(), R.mipmap.wall) 然后把得到的Bitmap对象传入Native进行处理
AndroidBitmapInfo info; // create a AndroidBitmapInfo int result; // 获取图片信息 result = AndroidBitmap_getInfo(env, bitmap, &amp;info); // 获取像素信息 unsigned char *data; result = AndroidBitmap_lockPixels(env, bitmap, reinterpret_cast&lt;void **&gt;(&amp;data)); size_t count = info." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/33f4861bbabe55044bbd97bf53f0bdbd/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-06T22:52:26+08:00" />
<meta property="article:modified_time" content="2022-04-06T22:52:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Android OpenGL ES - 纹理</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3 id="item-1-1">纹理基本概念</h3> 
<p><code>纹理是一个2D图片（甚至也有1D和3D的纹理）</code></p> 
<h3 id="item-1-2">纹理坐标</h3> 
<p>为了能够把纹理映射(Map)到三角形上，我们需要指定三角形的每个顶点各自对应纹理的哪个部分.<br> 这样每个顶点就会关联着一个纹理坐标(Texture Coordinate)，用来标明该从纹理图像的哪个部分采样（译注：采集片段颜色）。之后在图形的其它片段上进行片段插值(Fragment Interpolation)。<br> 纹理坐标在x和y轴上，范围为0到1之间（注意我们使用的是2D纹理图像）。使用纹理坐标获取纹理颜色叫做采样(Sampling)。<br> 纹理坐标起始于(0, 0)，也就是纹理图片的左下角，终始于(1, 1)，即纹理图片的右上角。<br> 下面的图片展示了我们是如何把纹理坐标映射到三角形上的。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/98/a4/AYyioUx3_o.png"></p> 
<p>我们为三角形指定了3个纹理坐标点。如上图所示，我们希望三角形的左下角对应纹理的左下角，因此我们把三角形左下角顶点的纹理坐标设置为(0, 0)；三角形的上顶点对应于图片的上中位置所以我们把它的纹理坐标设置为(0.5, 1.0)；同理右下方的顶点设置为(1, 0)。<br> 我们只要给顶点着色器传递这三个纹理坐标就行了，接下来它们会被传片段着色器中，它会为每个片段进行纹理坐标的插值。</p> 
<p>纹理坐标看起来就像这样：<br> //纹理坐标</p> 
<pre><code class="language-cpp">const GLfloat m_texture_coors[6] = {
     0.0f, 0.0f, // 左下角
     1.0f, 0.0f, // 右下角
     0.5f, 1.0f//上
};</code></pre> 
<p>2D纹理的坐标系是从<strong>左下角为原点向上为t轴,向右为s轴的坐标系</strong>。<code>这个坐标系的y方向和GL坐标系相反，所以默认按顶点坐标系方向输入的图像是倒置的</code>。</p> 
<p>如果想要让纹理正向显示，我们需要做的一步工作便是将输入的纹理坐标或者顶点坐标进行y轴方向的倒置。<br> 这些我们会在下面的示例中看到</p> 
<h3 id="item-1-3">加载图片</h3> 
<p>我们上面了解了纹理的坐标系之后，那么要做的第一件事自然是把它们加载到我们的应用中。<br> 纹理图像可能被储存为各种各样的格式，每种都有自己的数据结构和排列，所以我们如何才能把这些图像加载到应用中呢？</p> 
<p>我们这里采用Android上的API，</p> 
<pre>BitmapFactory.decodeResource(getResources(), R.mipmap.wall)</pre> 
<p>然后把得到的Bitmap对象传入Native进行处理</p> 
<pre><code class="language-cpp">AndroidBitmapInfo info; // create a AndroidBitmapInfo
int result;
// 获取图片信息
result = AndroidBitmap_getInfo(env, bitmap, &amp;info);
// 获取像素信息
unsigned char *data;
result = AndroidBitmap_lockPixels(env, bitmap, reinterpret_cast&lt;void **&gt;(&amp;data));
size_t count = info.stride * info.height;
unsigned char *resultData = (unsigned char *) malloc(count * sizeof(unsigned char));;
memcpy(resultData, data, count);
// 像素信息不再使用后需要解除锁定
result = AndroidBitmap_unlockPixels(env, bitmap);</code></pre> 
<p>最后得到unsigned char *resultData指向图片的内存地址</p> 
<h3 id="item-1-4">创建纹理</h3> 
<p>和之前生成的OpenGL对象一样，纹理也是使用ID引用的。让我们来创建一个：</p> 
<pre><code class="language-cpp">GLuint m_texture_id = 0;
glGenTextures(1, &amp;m_texture_id); </code></pre> 
<p><strong>产生纹理，激活纹理，绑定纹理 ，glTexImage2D生成纹理</strong></p> 
<p>glGenTextures函数首先需要输入生成纹理的数量，然后把它们储存在第二个参数的<code>GLuint</code>数组中（我们的例子中只是单独的一个<code>GLuint</code>）</p> 
<p>生成纹理之后还需要<code>激活纹理</code>,<code>绑定纹理</code>，让之后任何的纹理指令都可以配置当前绑定的纹理：</p> 
<pre>//激活指定纹理单元
//glActiveTexture(GL_TEXTURE0);
//绑定纹理ID到纹理单元
glBindTexture(GL_TEXTURE_2D, texture);</pre> 
<p>现在纹理已经绑定了，我们可以使用前面载入的图片数据生成一个纹理了。纹理可以通过glTexImage2D来生成：</p> 
<pre>glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data);
</pre> 
<p>当调用glTexImage2D时，当前绑定的纹理对象就会被附加上纹理图像。</p> 
<h3 id="item-1-5">使用纹理</h3> 
<p>上面我们已经加载了纹理，那么我们来看看怎么使用</p> 
<p>首先一些初始化坐标</p> 
<pre><code class="language-cpp">//顶点坐标
const GLfloat m_vertex_coors[9] = {
        -0.5f, -0.5f, 0.0f,//左下
        0.5f, -0.5f, 0.0f,//右下
        0.0f, 0.5f, 0.0f//左上
};
//纹理坐标
const GLfloat m_texture_coors[6] = {
        0.0f, 0.0f, // 左下角
        1.0f, 0.0f, // 右下角
        0.5f, 1.0f//上
};</code></pre> 
<p>接着是Vertex Shader</p> 
<pre><code class="language-cpp">const char *BitmapDrawer::GetVertexShader() {
    return   "attribute vec4 aPosition; \n"//顶点坐标
             "attribute vec2 aCoordinate; \n"//纹理坐标
             "varying vec2 vCoordinate; \n"//输出纹理坐标
             "void main() \n"
             "{ \n"
             "   gl_Position = aPosition; \n"
             "   vCoordinate = aCoordinate; \n"
             "} \n";
}</code></pre> 
<p>对比前文的绘制三角形的Vertex Shader，我们这里多了<code>纹理坐标</code></p> 
<p>然后Fragment Shader</p> 
<pre><code class="language-cpp">const char *BitmapDrawer::GetFragmentShader() {
    return "precision mediump float; \n"//配置精度
             "uniform sampler2D uTexture; \n"
             "varying vec2 vCoordinate; \n"
             "void main() \n"
             "{ \n"
             "   gl_FragColor = texture2D ( uTexture, vCoordinate); \n"
             "} \n";
}</code></pre> 
<p>最后是我们前文讲过的OpenGL的GLSL使用流程了，</p> 
<pre><code class="language-cpp">void BitmapDrawer::InitVarHandler() {
    //获取变量句柄
    m_vertex_pos_handler = glGetAttribLocation(m_program_id, "aPosition");
     m_texture_pos_handler = glGetAttribLocation(m_program_id, "aCoordinate");
     m_texture_handler = glGetUniformLocation(m_program_id, "uTexture");
     //生成纹理
     glGenTextures(1, &amp;m_texture_id);

     ActivateTexture();
     //绑定纹理数据
     if (cst_data != NULL) {
            glTexImage2D(GL_TEXTURE_2D, 0, // level一般为0
                         GL_RGBA, //纹理内部格式
                         m_origin_width, m_origin_height, // 画面宽高
                         0, // 必须为0
                         GL_RGBA, // 数据格式，必须和上面的纹理格式保持一直
                         GL_UNSIGNED_BYTE, // RGBA每位数据的字节数，这里是BYTE​: 1 byte
                         cst_data);// 画面数据
         //释放资源
         free(cst_data);
         cst_data = NULL;
     }
}

void BitmapDrawer::ActivateTexture() {
    GLenum type = GL_TEXTURE_2D;
     //激活指定纹理单元
    //    glActiveTexture(GL_TEXTURE0 + index);
     //绑定纹理ID到纹理单元
     glBindTexture(type, m_texture_id);
     //将活动的纹理单元传递到着色器里面
    //    glUniform1i(texture_handler, index);
     //配置边缘过渡参数
     glTexParameterf(type, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
     glTexParameterf(type, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
     glTexParameteri(type, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
     glTexParameteri(type, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
}
//绘制

void BitmapDrawer::DoDraw() {
 //启用顶点的句柄
 glEnableVertexAttribArray(m_vertex_pos_handler);
 glEnableVertexAttribArray(m_texture_pos_handler);
 //设置着色器参数
//    glUniformMatrix4fv(m_vertex_matrix_handler, 1, false, m_matrix, 0);
 glVertexAttribPointer(m_vertex_pos_handler, 3, GL_FLOAT, GL_FALSE, 0, m_vertex_coors);
 glVertexAttribPointer(m_texture_pos_handler, 2, GL_FLOAT, GL_FALSE, 0, m_texture_coors);
 //开始绘制
 glDrawArrays(GL_TRIANGLE_STRIP, 0, 3);
}</code></pre> 
<p>最终结果如下图</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/e1/3c/z9yOrzRJ_o.png"></p> 
<p>上面的代码中有几处我们之前没有接触过的地方，还有存有疑惑的地方，下面我们一一解释</p> 
<pre>    //配置边缘过渡参数
     glTexParameterf(type, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
     glTexParameterf(type, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
     glTexParameteri(type, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
     glTexParameteri(type, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);</pre> 
<h3 id="item-1-6">纹理过滤与环绕</h3> 
<h4>纹理过滤</h4> 
<p>上面说了纹理坐标相关的内容,但是纹理坐标不依赖于分辨率(Resolution),它可以是任意浮点值,<br> 所以OpenGL需要知道怎样将纹理像素映射到纹理坐标。<br> 当你有一个很大的物体但是纹理的分辨率很低的时候这就变得很重要了。<br> 你可能已经猜到了，OpenGL也有对于纹理过滤(Texture Filtering)的选项。<br> 纹理过滤有很多个选项，但是现在我们只讨论最重要的两种：<strong>GL_NEAREST和GL_LINEAR。</strong></p> 
<blockquote>
  PS 
 <br> Texture Pixel也叫Texel，你可以想象你打开一张 
 <code>.jpg</code>格式图片，不断放大你会发现它是由无数像素点组成的，这个点就是纹理像素； 
 <br> 注意不要和纹理坐标搞混，纹理坐标是你给模型顶点设置的那个数组，OpenGL以这个顶点的纹理坐标数据去查找纹理图像上的像素，然后进行采样提取纹理像素的颜色。 
</blockquote> 
<p>GL_NEAREST（也叫邻近过滤，Nearest Neighbor Filtering）是OpenGL默认的纹理过滤方式。<br> 当设置为GL_NEAREST的时候，OpenGL会选择中心点最接近纹理坐标的那个像素。<br> 下图中你可以看到四个像素，加号代表纹理坐标。左上角那个纹理像素的中心距离纹理坐标最近，所以它会被选择为样本颜色：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/71/37/fVSxu1C3_o.png"></p> 
<p>GL_LINEAR（也叫线性过滤，(Bi)linear Filtering）它会基于纹理坐标附近的纹理像素，计算出一个插值，近似出这些纹理像素之间的颜色。一个纹理像素的中心距离纹理坐标越近，那么这个纹理像素的颜色对最终的样本颜色的贡献越大。下图中你可以看到返回的颜色是邻近像素的混合色：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/73/1e/gTj1fC9P_o.png"></p> 
<p>那么这两种纹理过滤方式有怎样的视觉效果呢？让我们看看在一个很大的物体上应用一张低分辨率的纹理会发生什么吧（纹理被放大了，每个纹理像素都能看到）：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/f3/0a/v0o6xvuQ_o.png"></p> 
<p>GL_NEAREST产生了颗粒状的图案，我们能够清晰看到组成纹理的像素，而GL_LINEAR能够产生更平滑的图案，很难看出单个的纹理像素。GL_LINEAR可以产生更真实的输出，但有些开发者更喜欢8-bit风格，所以他们会用GL_NEAREST选项。</p> 
<p>当进行放大(Magnify)和缩小(Minify)操作的时候可以设置纹理过滤的选项，比如你可以在纹理被缩小的时候使用邻近过滤，被放大时使用线性过滤。我们需要使用glTexParameter*函数为放大和缩小指定过滤方式。</p> 
<pre>glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);</pre> 
<h4>纹理环绕</h4> 
<p>纹理坐标的范围通常是从[0, 0]到[1, 1]，超过[0.0, 1.0]的范围是允许的，而对与超出范围的内容要如何显示，这就取决于纹理的环绕方式(Wrapping mode)。在OpenGL默认的行为是重复这个纹理图像(GL_REPEAT)。</p> 
<p>下图从左到右依次是这三种效果：</p> 
<table><thead><tr><th>环绕方式(Wrapping)</th><th>描述</th></tr></thead><tbody><tr><td>GL_REPEAT</td><td>对纹理的默认行为。重复纹理图像</td></tr><tr><td>GL_MIRRORED_REPEAT</td><td>但每次重复图片是镜像放置的</td></tr><tr><td>GL_CLAMP_TO_EDGE</td><td>纹理坐标会被约束在0到1之间，超出的部分会重复纹理坐标的边缘，产生一种边缘被拉伸的效果。</td></tr></tbody></table> 
<p>我们通过glTexParameteri指定Texture的环绕模式,可以看见它是可以在S,T两个方向上独立设置的.</p> 
<pre>// 设置Texutre的环绕模式
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);</pre> 
<p>GL_CLAMP_TO_EDGE</p> 
<p class="img-center"><img alt="" height="395" src="https://images2.imgbox.com/ba/f5/b0iJdveO_o.png" width="226"></p> 
<p>GL_REPEAT</p> 
<p class="img-center"><img alt="" height="379" src="https://images2.imgbox.com/6d/ae/YN9MWGVO_o.png" width="208"></p> 
<p>GL_MIRRORED_REPEAT</p> 
<p class="img-center"><img alt="" height="478" src="https://images2.imgbox.com/e7/b3/PzG1oWC9_o.png" width="265"></p> 
<h3 id="item-1-7">纹理单元</h3> 
<p>下面我们来看这段代码</p> 
<pre><code class="language-cpp">//激活指定纹理单元
//    glActiveTexture(GL_TEXTURE0 + index);
//绑定纹理ID到纹理单元
glBindTexture(type, m_texture_id);
//将活动的纹理单元传递到着色器里面
//    glUniform1i(texture_handler, index);</code></pre> 
<p>你可能会奇怪为什么<code>// glUniform1i(texture_handler, index);</code>这句代码被注释了，而且在我们的 Fragment Shader中明显有个<code>sampler2D</code>变量是个uniform，我们却不用glUniform给它赋值。<br> 使用glUniform1i，我们可以给纹理采样器分配一个位置值，这样的话我们能够在一个片段着色器中设置多个纹理。<br> 一个纹理的位置值通常称为一个纹理单元(Texture Unit)。<strong>一个纹理的默认纹理单元是0，它是默认的激活纹理单元，所以教程前面部分我们没有分配一个位置值。</strong><br> 纹理单元的主要目的是让我们在着色器中可以使用多于一个的纹理.通过把纹理单元赋值给采样器,我们可以一次绑定多个纹理，只要我们首先激活对应的纹理单元。就像glBindTexture一样，我们可以使用glActiveTexture激活纹理单元，传入我们需要使用的纹理单元：</p> 
<pre><code class="language-cpp">glActiveTexture(GL_TEXTURE0); // 在绑定纹理之前先激活纹理单元
glBindTexture(GL_TEXTURE_2D, texture); </code></pre> 
<p>激活纹理单元之后，接下来的glBindTexture函数调用会绑定这个纹理到当前激活的纹理单元，纹理单元GL_TEXTURE0默认总是被激活，所以我们在前面的例子里当我们使用<code>glBindTexture</code>的时候，无需激活任何纹理单元。</p> 
<blockquote>
  PS 
 <br> OpenGL至少保证有16个纹理单元供你使用，也就是说你可以激活从GL_TEXTURE0到GL_TEXTRUE15。它们都是按顺序定义的，所以我们也可以通过GL_TEXTURE0 + 8的方式获得GL_TEXTURE8，这在当我们需要循环一些纹理单元的时候会很有用。 
</blockquote> 
<h3 id="item-1-8">多级渐远纹理</h3> 
<p>上面我们对一个三角形或者矩形物体使用了纹理，但是想象一下当我们拥有很多个这样的物体，<br> 每个物体上都有纹理。有些物体会很远，但其纹理会拥有与近处物体同样高的分辨率。由于远处的物体可能只产生很少的片段，OpenGL从高分辨率纹理中为这些片段获取正确的颜色值就很困难，因为它需要对一个跨过纹理很大部分的片段只拾取一个纹理颜色。在小物体上这会产生不真实的感觉，更不用说对它们使用高分辨率纹理浪费内存的问题了。</p> 
<p>OpenGL使用一种叫做多级渐远纹理(Mipmap)的概念来解决这个问题，它简单来说就是一系列的纹理图像，后一个纹理图像是前一个的二分之一。多级渐远纹理背后的理念很简单：距观察者的距离超过一定的阈值，OpenGL会使用不同的多级渐远纹理，即最适合物体的距离的那个。由于距离远，解析度不高也不会被用户注意到。同时，多级渐远纹理另一加分之处是它的性能非常好。让我们看一下多级渐远纹理是什么样子的：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/d0/c7/6bT43zTu_o.png"></p> 
<p>手工为每个纹理图像创建一系列多级渐远纹理很麻烦，幸好OpenGL有一个glGenerateMipmaps函数，在创建完一个纹理后调用它OpenGL就会承担接下来的所有工作了。后面的教程中你会看到该如何使用它。</p> 
<p>在渲染中切换多级渐远纹理级别(Level)时，OpenGL在两个不同级别的多级渐远纹理层之间会产生不真实的生硬边界。就像普通的纹理过滤一样，切换多级渐远纹理级别时你也可以在两个不同多级渐远纹理级别之间使用NEAREST和LINEAR过滤。为了指定不同多级渐远纹理级别之间的过滤方式，你可以使用下面四个选项中的一个代替原有的过滤方式：</p> 
<table><thead><tr><th>过滤方式</th><th>描述</th></tr></thead><tbody><tr><td>GL_NEAREST_MIPMAP_NEAREST</td><td>使用最邻近的多级渐远纹理来匹配像素大小，并使用邻近插值进行纹理采样</td></tr><tr><td>GL_LINEAR_MIPMAP_NEAREST</td><td>使用最邻近的多级渐远纹理级别，并使用线性插值进行采样</td></tr><tr><td>GL_NEAREST_MIPMAP_LINEAR</td><td>在两个最匹配像素大小的多级渐远纹理之间进行线性插值，使用邻近插值进行采样</td></tr><tr><td>GL_LINEAR_MIPMAP_LINEAR</td><td>在两个邻近的多级渐远纹理之间使用线性插值，并使用线性插值进行采样</td></tr></tbody></table> 
<p>就像纹理过滤一样，我们可以使用glTexParameteri将过滤方式设置为前面四种提到的方法之一：</p> 
<pre>glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); </pre> 
<blockquote>
  PS 
 <br> 一个常见的错误是，将放大过滤的选项设置为多级渐远纹理过滤选项之一。这样没有任何效果，因为多级渐远纹理主要是使用在纹理被缩小的情况下的：纹理放大不会使用多级渐远纹理，为放大过滤设置多级渐远纹理的选项会产生一个GL_INVALID_ENUM错误代码。 
</blockquote> 
<h3 id="item-1-9">片段(Frament Shader)纹理取样</h3> 
<p>我们再回顾一下上面的代码，</p> 
<pre><code class="language-cpp">//顶点坐标
const GLfloat m_vertex_coors[9] = {
        -0.5f, -0.5f, 0.0f,//左下
        0.5f, -0.5f, 0.0f,//右下
        0.0f, 0.5f, 0.0f//左上
};
//纹理坐标
const GLfloat m_texture_coors[6] = {
        0.0f, 0.0f, // 左下角
        1.0f, 0.0f, // 右下角
        0.5f, 1.0f//上
};</code></pre> 
<p>在使用glTexImage2D把图片数据绑定纹理数据之后，我们到了Fragment Shader代码中用GLSL的内置函<strong>数texture2D对顶点生成的光栅化几何图形进行逐片段涂色操作</strong>，</p> 
<pre> gl_FragColor = texture2D ( uTexture, vCoordinate);</pre> 
<p>至于<code>texture2D</code>函数我开始也理解了很久，但是我们可以先用PS打开我们提供的超越的美图，然后放大到最大，我们就看到了下面的图片(太大了放不下，这是局部图)，我们看到超越的美图是由一个个带有颜色的方格组成的，这些方格(不带有颜色的)就对应着我们前面强调的<strong>光栅化</strong>，</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/e2/40/uerli0Bt_o.png"></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/8a/4d/mFQemixX_o.png"></p> 
<p>我们可以想象一下，纹理是一张绘有图片的纸，无缝折叠贴合到你的几何图形上，这样你的几何图形看起来就像有图片外表了。因为我们可以在一张图片上插入非常多的细节，这样就可以让物体非常精细而不用指定额外的顶点。</p> 
<p>我们只需要指定<strong>每个顶点坐标对应的纹理坐标</strong>，对纹理进行取样操作，我们就能以很少的顶点用纹理来添加物体的细节，这也是我们之后进行图片处理的基础。</p> 
<p><a href="https://www.jianshu.com/p/8d2d93c4229b" rel="nofollow" title="高斯模糊与图像卷积滤波一些知识点 - 简书">高斯模糊与图像卷积滤波一些知识点 - 简书</a><br><a href="https://blog.csdn.net/a360940265a/article/details/107861956" title="OpenGL.Shader：志哥教你写一个滤镜直播客户端（11）高斯滤波优化の卷积降维运算_Mr_Zzr的博客-CSDN博客">OpenGL.Shader：志哥教你写一个滤镜直播客户端（11）高斯滤波优化の卷积降维运算_Mr_Zzr的博客-CSDN博客</a></p> 
<p><a href="https://blog.csdn.net/a360940265a/article/details/106615865" title="OpenGL.Shader：志哥教你写一个滤镜直播客户端（8）视觉滤镜：什么是卷积？图像锐化_Mr_Zzr的博客-CSDN博客_opengl 锐化">OpenGL.Shader：志哥教你写一个滤镜直播客户端（8）视觉滤镜：什么是卷积？图像锐化_Mr_Zzr的博客-CSDN博客_opengl 锐化</a><a href="https://blog.csdn.net/a360940265a/article/details/107247120" title="OpenGL.Shader：志哥教你写一个滤镜直播客户端（9）视觉滤镜：均值模糊/均值滤波 原理实现_Mr_Zzr的博客-CSDN博客_opengl噪声">OpenGL.Shader：志哥教你写一个滤镜直播客户端（9）视觉滤镜：均值模糊/均值滤波 原理实现_Mr_Zzr的博客-CSDN博客_opengl噪声</a></p> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b58aedb72f661608daf4d231034b09fc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">线程安全的观察者模式</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c9dd5afd9e0a6d9bc89e1b2382385086/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">五点差分法求解偏微分方程（PDE）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>