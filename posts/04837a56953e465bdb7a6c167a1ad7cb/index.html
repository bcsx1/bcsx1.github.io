<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>逻辑回归模型：信用卡欺诈分析 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="逻辑回归模型：信用卡欺诈分析" />
<meta property="og:description" content="逻辑回归案例分析——信用卡欺诈 本次案例为信用卡欺诈数据，一共包含31个自变量，其中因变量Class表示用户在交易中是否发生欺诈行为（1表示欺诈交易，0表示正常交易）。由于数据涉及敏感信息，其中V1~V28自变量做了标准化处理。本次案例涉及到分类问题中类别比例严重失调的情况下应该如何应对，当然主要任务是对0-1样本即正常与异常样本的区分。
类别比例失调如何处理正负样本的划分 首先是库的导入操作：
import numpy as np import matplotlib.pyplot as plt import pandas as pd %matplotlib inline data = pd.read_csv(&#34;creditcard.csv&#34;) data.head(5) TimeV1V2V3V4V5V6V7V8V9...V21V22V23V24V25V26V27V28AmountClass00.0-1.359807-0.0727812.5363471.378155-0.3383210.4623880.2395990.0986980.363787...-0.0183070.277838-0.1104740.0669280.128539-0.1891150.133558-0.021053149.62010.01.1918570.2661510.1664800.4481540.060018-0.082361-0.0788030.085102-0.255425...-0.225775-0.6386720.101288-0.3398460.1671700.125895-0.0089830.0147242.69021.0-1.358354-1.3401631.7732090.379780-0.5031981.8004990.7914610.247676-1.514654...0.2479980.7716790.909412-0.689281-0.327642-0.139097-0.055353-0.059752378.66031.0-0.966272-0.1852261.792993-0.863291-0.0103091.2472030.2376090.377436-1.387024...-0.1083000.005274-0.190321-1.1755750.647376-0.2219290.0627230.061458123.50042.0-1.1582330.8777371.5487180.403034-0.4071930.0959210.592941-0.2705330.817739...-0.0094310.798278-0.1374580.141267-0.2060100.5022920.2194220.21515369.990 5 rows × 31 columns
数据集检测 在本案例中是的数据集是是否有信用卡欺诈的数据集，结合实际情况，应该是正常类占绝大多数，出现信用卡欺诈的类别占少数的，首先我们需要对我们的数据进行检验，看是否满足这样的特征
pd.value_counts()对DataFrame的某一列中具有多少重复的值进行统计，并对不同的值进行计数。使用的时候需要对特定的列进行指定，比如下面的使用中指定了Class列，并且进行排序。
#使用注释掉的代码可以直接输出列的情况： # print(data[&#34;Class&#34;].value_counts()) count_classes = pd.value_counts(data[&#34;Class&#34;], sort = True).sort_index() count_classes.plot(kind = &#34;bar&#34;) plt.title(&#34;Fruad class histogram&#34;) plt.xlabel(&#34;Class&#34;) plt.ylabel(&#34;Frequancy&#34;) Text(0, 0.5, &#39;Frequancy&#39;) 样本数量均衡化处理 可以看出正常样本的数量时明显多于异常样本的，即样本的数据是极度不均衡的，需要进行处理。
面对数据不均衡时我们往往采取两种解决方法：
过采样：对少数样本进行数据生成，使少数的样本变得与多数样本数量相当下采样：在多数的样本中取出和少数样本规模相同的子样本作为分类的数据对象，这样使得两个样本同样的少 后面会针对两种不同的方法分别进行分析
样本特征的归一化处理 此外，在上面的数据中我们也可以发现Amount列的数据的大小浮动是比较大的，有的是几百，有的数据是个位数，amount和前面的V1-V28这些特征在未说明的情况下对结果产生的影响是相当的，如果不进行处理，机器学习算法的结果可能对较大的数予以较大的权重赋值，进入误区。所以在机器学习中我们要保证特征之间的分布差异处于一个相当的范围内。
比如我们可以看到前面的V1-V28这些特征，他们大概分布在-1-1这样的区间内，所以我们最好也要对amount的数值进行归一化处理。
from sklearn.preprocessing import StandardScaler #生成新的特征 data[&#39;normAmount&#39;] = StandardScaler().fit_transform(data[&#39;Amount&#39;].values.reshape(-1, 1)) #去除不需要的特征 data = data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/04837a56953e465bdb7a6c167a1ad7cb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-01-30T23:28:14+08:00" />
<meta property="article:modified_time" content="2021-01-30T23:28:14+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">逻辑回归模型：信用卡欺诈分析</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="center_0"></a> 
 <center>
   逻辑回归案例分析——信用卡欺诈 
 </center></h2> 
<p>本次案例为信用卡欺诈数据，一共包含31个自变量，其中因变量Class表示用户在交易中是否发生欺诈行为（1表示欺诈交易，0表示正常交易）。由于数据涉及敏感信息，其中V1~V28自变量做了标准化处理。本次案例涉及到分类问题中类别比例严重失调的情况下应该如何应对，当然主要任务是对0-1样本即正常与异常样本的区分。</p> 
<ul><li>类别比例失调如何处理</li><li>正负样本的划分</li></ul> 
<p>首先是库的导入操作：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token operator">%</span>matplotlib inline
</code></pre> 
<pre><code class="prism language-python">data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"creditcard.csv"</span><span class="token punctuation">)</span>
data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre> 
<div> 
 <table border="1" class="dataframe"><thead><tr><th></th><th>Time</th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>...</th><th>V21</th><th>V22</th><th>V23</th><th>V24</th><th>V25</th><th>V26</th><th>V27</th><th>V28</th><th>Amount</th><th>Class</th></tr></thead><tbody><tr><th>0</th><td>0.0</td><td>-1.359807</td><td>-0.072781</td><td>2.536347</td><td>1.378155</td><td>-0.338321</td><td>0.462388</td><td>0.239599</td><td>0.098698</td><td>0.363787</td><td>...</td><td>-0.018307</td><td>0.277838</td><td>-0.110474</td><td>0.066928</td><td>0.128539</td><td>-0.189115</td><td>0.133558</td><td>-0.021053</td><td>149.62</td><td>0</td></tr><tr><th>1</th><td>0.0</td><td>1.191857</td><td>0.266151</td><td>0.166480</td><td>0.448154</td><td>0.060018</td><td>-0.082361</td><td>-0.078803</td><td>0.085102</td><td>-0.255425</td><td>...</td><td>-0.225775</td><td>-0.638672</td><td>0.101288</td><td>-0.339846</td><td>0.167170</td><td>0.125895</td><td>-0.008983</td><td>0.014724</td><td>2.69</td><td>0</td></tr><tr><th>2</th><td>1.0</td><td>-1.358354</td><td>-1.340163</td><td>1.773209</td><td>0.379780</td><td>-0.503198</td><td>1.800499</td><td>0.791461</td><td>0.247676</td><td>-1.514654</td><td>...</td><td>0.247998</td><td>0.771679</td><td>0.909412</td><td>-0.689281</td><td>-0.327642</td><td>-0.139097</td><td>-0.055353</td><td>-0.059752</td><td>378.66</td><td>0</td></tr><tr><th>3</th><td>1.0</td><td>-0.966272</td><td>-0.185226</td><td>1.792993</td><td>-0.863291</td><td>-0.010309</td><td>1.247203</td><td>0.237609</td><td>0.377436</td><td>-1.387024</td><td>...</td><td>-0.108300</td><td>0.005274</td><td>-0.190321</td><td>-1.175575</td><td>0.647376</td><td>-0.221929</td><td>0.062723</td><td>0.061458</td><td>123.50</td><td>0</td></tr><tr><th>4</th><td>2.0</td><td>-1.158233</td><td>0.877737</td><td>1.548718</td><td>0.403034</td><td>-0.407193</td><td>0.095921</td><td>0.592941</td><td>-0.270533</td><td>0.817739</td><td>...</td><td>-0.009431</td><td>0.798278</td><td>-0.137458</td><td>0.141267</td><td>-0.206010</td><td>0.502292</td><td>0.219422</td><td>0.215153</td><td>69.99</td><td>0</td></tr></tbody></table> 
 <p>5 rows × 31 columns</p> 
</div> 
<h3><a id="_188"></a>数据集检测</h3> 
<p>在本案例中是的数据集是是否有信用卡欺诈的数据集，结合实际情况，应该是正常类占绝大多数，出现信用卡欺诈的类别占少数的，首先我们需要对我们的数据进行检验，看是否满足这样的特征</p> 
<p>pd.value_counts()对DataFrame的某一列中具有多少重复的值进行统计，并对不同的值进行计数。使用的时候需要对特定的列进行指定，比如下面的使用中指定了Class列，并且进行排序。</p> 
<pre><code class="prism language-python"><span class="token comment">#使用注释掉的代码可以直接输出列的情况：</span>
<span class="token comment"># print(data["Class"].value_counts())</span>

count_classes <span class="token operator">=</span> pd<span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">"Class"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sort <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sort_index<span class="token punctuation">(</span><span class="token punctuation">)</span>
count_classes<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>kind <span class="token operator">=</span> <span class="token string">"bar"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Fruad class histogram"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Class"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Frequancy"</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>Text(0, 0.5, 'Frequancy')
</code></pre> 
<p><img src="https://images2.imgbox.com/fc/87/dquRQJ9S_o.png" alt="6_1"></p> 
<h3><a id="_216"></a>样本数量均衡化处理</h3> 
<p>可以看出正常样本的数量时明显多于异常样本的，即样本的数据是极度不均衡的，需要进行处理。</p> 
<p>面对数据不均衡时我们往往采取两种解决方法：</p> 
<ul><li>过采样：对少数样本进行数据生成，使少数的样本变得与多数样本数量相当</li><li>下采样：在多数的样本中取出和少数样本规模相同的子样本作为分类的数据对象，这样使得两个样本同样的少</li></ul> 
<p>后面会针对两种不同的方法分别进行分析</p> 
<h3><a id="_225"></a>样本特征的归一化处理</h3> 
<p>此外，在上面的数据中我们也可以发现Amount列的数据的大小浮动是比较大的，有的是几百，有的数据是个位数，amount和前面的V1-V28这些特征在未说明的情况下对结果产生的影响是相当的，如果不进行处理，机器学习算法的结果可能对较大的数予以较大的权重赋值，进入误区。所以在机器学习中我们要保证特征之间的分布差异处于一个相当的范围内。</p> 
<p>比如我们可以看到前面的V1-V28这些特征，他们大概分布在-1-1这样的区间内，所以我们最好也要对amount的数值进行归一化处理。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler

<span class="token comment">#生成新的特征</span>
data<span class="token punctuation">[</span><span class="token string">'normAmount'</span><span class="token punctuation">]</span> <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'Amount'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#去除不需要的特征</span>
data <span class="token operator">=</span> data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"Time"</span><span class="token punctuation">,</span> <span class="token string">"Amount"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<div> 
</div> 
<table border="1" class="dataframe"><thead><tr><th></th><th>V1</th><th>V2</th><th>V3</th><th>V4</th><th>V5</th><th>V6</th><th>V7</th><th>V8</th><th>V9</th><th>V10</th><th>...</th><th>V21</th><th>V22</th><th>V23</th><th>V24</th><th>V25</th><th>V26</th><th>V27</th><th>V28</th><th>Class</th><th>normAmount</th></tr></thead><tbody><tr><th>0</th><td>-1.359807</td><td>-0.072781</td><td>2.536347</td><td>1.378155</td><td>-0.338321</td><td>0.462388</td><td>0.239599</td><td>0.098698</td><td>0.363787</td><td>0.090794</td><td>...</td><td>-0.018307</td><td>0.277838</td><td>-0.110474</td><td>0.066928</td><td>0.128539</td><td>-0.189115</td><td>0.133558</td><td>-0.021053</td><td>0</td><td>0.244964</td></tr><tr><th>1</th><td>1.191857</td><td>0.266151</td><td>0.166480</td><td>0.448154</td><td>0.060018</td><td>-0.082361</td><td>-0.078803</td><td>0.085102</td><td>-0.255425</td><td>-0.166974</td><td>...</td><td>-0.225775</td><td>-0.638672</td><td>0.101288</td><td>-0.339846</td><td>0.167170</td><td>0.125895</td><td>-0.008983</td><td>0.014724</td><td>0</td><td>-0.342475</td></tr><tr><th>2</th><td>-1.358354</td><td>-1.340163</td><td>1.773209</td><td>0.379780</td><td>-0.503198</td><td>1.800499</td><td>0.791461</td><td>0.247676</td><td>-1.514654</td><td>0.207643</td><td>...</td><td>0.247998</td><td>0.771679</td><td>0.909412</td><td>-0.689281</td><td>-0.327642</td><td>-0.139097</td><td>-0.055353</td><td>-0.059752</td><td>0</td><td>1.160686</td></tr><tr><th>3</th><td>-0.966272</td><td>-0.185226</td><td>1.792993</td><td>-0.863291</td><td>-0.010309</td><td>1.247203</td><td>0.237609</td><td>0.377436</td><td>-1.387024</td><td>-0.054952</td><td>...</td><td>-0.108300</td><td>0.005274</td><td>-0.190321</td><td>-1.175575</td><td>0.647376</td><td>-0.221929</td><td>0.062723</td><td>0.061458</td><td>0</td><td>0.140534</td></tr><tr><th>4</th><td>-1.158233</td><td>0.877737</td><td>1.548718</td><td>0.403034</td><td>-0.407193</td><td>0.095921</td><td>0.592941</td><td>-0.270533</td><td>0.817739</td><td>0.753074</td><td>...</td><td>-0.009431</td><td>0.798278</td><td>-0.137458</td><td>0.141267</td><td>-0.206010</td><td>0.502292</td><td>0.219422</td><td>0.215153</td><td>0</td><td>-0.073403</td></tr></tbody></table> 
<p>5 rows × 30 columns</p> 
<h4><a id="_413"></a>下采样处理</h4> 
<p>减少多数的样本以和少数的样本的数量一样多</p> 
<pre><code class="prism language-python"><span class="token comment">#取出特征列</span>
X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span>columns <span class="token operator">!=</span> <span class="token string">"Class"</span><span class="token punctuation">]</span>
<span class="token comment">#取出标签列</span>
y <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span>columns <span class="token operator">==</span> <span class="token string">"Class"</span><span class="token punctuation">]</span>

<span class="token comment">#Number of data points in the minority class</span>
<span class="token comment"># 得到不正常样本的索引值和数量</span>
number_records_fraud <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span>data<span class="token punctuation">.</span>Class <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
fraud_indices <span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">[</span>data<span class="token punctuation">.</span>Class <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>index<span class="token punctuation">)</span>

<span class="token comment">#在正常样本中进行随机选择</span>
normal_indices <span class="token operator">=</span> data<span class="token punctuation">[</span>data<span class="token punctuation">.</span>Class <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>index

<span class="token comment">#基于我们上一步找出来的那些样本的下标，在这些下标中随机选择出number_records_fraud数量的下标，并转换成ndarray对象</span>
random_normal_indices <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>normal_indices<span class="token punctuation">,</span> number_records_fraud<span class="token punctuation">,</span> replace <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment"># replace = False 形成的数据不能有重复的</span>
random_normal_indices <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>random_normal_indices<span class="token punctuation">)</span>


<span class="token comment">#将两部分的下标粘合在一起，形成整体的新的样本的下标</span>
under_sample_indices <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>fraud_indices<span class="token punctuation">,</span>random_normal_indices<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 根据索引，得到下采样的数据集(根据下标取行)</span>
under_sample_data <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>under_sample_indices<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token comment">#选取最终的特征列和标签列</span>
X_undersample <span class="token operator">=</span> under_sample_data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>under_sample_data<span class="token punctuation">.</span>columns <span class="token operator">!=</span> <span class="token string">"Class"</span><span class="token punctuation">]</span>
y_undersample <span class="token operator">=</span> under_sample_data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>under_sample_data<span class="token punctuation">.</span>columns <span class="token operator">==</span> <span class="token string">"Class"</span><span class="token punctuation">]</span>

<span class="token comment"># 展示下采样样本比例</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正常样本占下采样样本的比例："</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>under_sample_data<span class="token punctuation">[</span>under_sample_data<span class="token punctuation">.</span>Class <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>under_sample_data<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"异常样本占下采样样本的比例："</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>under_sample_data<span class="token punctuation">[</span>under_sample_data<span class="token punctuation">.</span>Class <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>under_sample_data<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"下采样样本总数："</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>under_sample_data<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>正常样本占下采样样本的比例： 0.5
异常样本占下采样样本的比例： 0.5
下采样样本总数： 984
</code></pre> 
<h3><a id="_458"></a>训练集和测试集的划分以及交叉验证</h3> 
<h4><a id="_460"></a>训练集和测试集划分</h4> 
<p>经过上面的操作我们已经得到了需要处理的一系列的数据，下面我们要做的就是数据集和测试集的划分的过程了。</p> 
<p>所谓的划分就是要把样本分为数据集和测试集两个部分</p> 
<ul><li>数据集：用来建立我们的回归模型</li><li>测试集：用来验证建立模型的准确性</li></ul> 
<p>注意的是数据集和测试集的选择要随机且采用同一选择的算法。</p> 
<h4><a id="_469"></a>交叉验证</h4> 
<p>交叉验证是指我们要将数据集进行进一步的划分，这样进一步的划分内进行互相组合，记录结果以更好地选择模型中的参数。<br> 具体的操作见下面的过程：</p> 
<p>原始测试集进行测试</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token comment">#导入原始数据集进行一个切分的操作，这种切分是经过洗牌的切分的</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"原始训练集包含样本数量："</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"原始测试集包含样本数量："</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"原始样本总数："</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token operator">+</span><span class="token builtin">len</span><span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#导入下采样数据集进行切分操作</span>
X_train_undersample<span class="token punctuation">,</span> X_test_undersample<span class="token punctuation">,</span> y_train_undersample<span class="token punctuation">,</span> y_test_undersample <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X_undersample<span class="token punctuation">,</span> y_undersample<span class="token punctuation">,</span> 
                                                                                                    test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"下采样训练集包含样本数量："</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_train_undersample<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"下采样测试集包含样本数量："</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_test_undersample<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"下采样样本总数："</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>X_train_undersample<span class="token punctuation">)</span><span class="token operator">+</span><span class="token builtin">len</span><span class="token punctuation">(</span>X_test_undersample<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>原始训练集包含样本数量： 199364
原始测试集包含样本数量： 85443
原始样本总数： 284807

下采样训练集包含样本数量： 688
下采样测试集包含样本数量： 296
下采样样本总数： 984
</code></pre> 
<h3><a id="_505"></a>模型的评估</h3> 
<h4><a id="recall_506"></a>召回率：recall</h4> 
<p>如何评价我们建立模型的好坏，直接的想法是使用精度来判断。下面我们举一个例子说明精度判断的局限性，</p> 
<p>有上面的例子可以知道精度评估具有一定的欺骗性，所以这里我们引入“召回率”:recall的概念，来对我们模型的好坏进行评估<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          R 
         
        
          e 
         
        
          c 
         
        
          a 
         
        
          l 
         
        
          l 
         
        
          = 
         
         
          
          
            T 
           
          
            P 
           
          
          
          
            ( 
           
          
            T 
           
          
            P 
           
          
            + 
           
          
            F 
           
          
            N 
           
          
            ) 
           
          
         
        
       
         Recall =\frac{ TP}{ (TP + FN)} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.01968em;">l</span><span class="mord mathdefault" style="margin-right: 0.01968em;">l</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.29633em; vertical-align: -0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.36033em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.13889em;">T</span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mclose">)</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">T</span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.936em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p> 
<h4><a id="_514"></a>正则化惩罚</h4> 
<p>假如我们得到了模型A(<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          θ 
         
        
          1 
         
        
       
         , 
        
        
        
          θ 
         
        
          2 
         
        
       
         , 
        
        
        
          θ 
         
        
          3 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          θ 
         
        
          10 
         
        
       
      
        \theta_1,\theta_2,\theta_3,...,\theta_{10} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>)和模型B(<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          θ 
         
        
          1 
         
        
       
         , 
        
        
        
          θ 
         
        
          2 
         
        
       
         , 
        
        
        
          θ 
         
        
          3 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          θ 
         
        
          10 
         
        
       
      
        \theta_1,\theta_2,\theta_3,...,\theta_{10} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>)两个模型，两个模型经过召回率的评估结果是一样的，那么我们在选择的时候是不是在A和B两个模型中随意选择一个就可以了呢？</p> 
<p>这里我们还要考虑A和B得到的参数(<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          θ 
         
        
          1 
         
        
       
         , 
        
        
        
          θ 
         
        
          2 
         
        
       
         , 
        
        
        
          θ 
         
        
          3 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          θ 
         
        
          10 
         
        
       
      
        \theta_1,\theta_2,\theta_3,...,\theta_{10} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>)的正则化问题，要考虑这组参数的波动程度。一般情况下我们认为波动程度更小的参数组合的模型更好，因为这样的模型泛化程度更高，能过减小过拟合的现象。</p> 
<p>所谓的过拟合是指我们的模型在训练集上的发挥是很好的，但是在测试集上的效果不是很好，过拟合现象在机器学习的算法中经常出现，需要避免。</p> 
<p>对于正则化惩罚的方法这里介绍一种<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
        
          2 
         
        
       
      
        L_2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>惩罚法。在未引入这个概念之前我们我们对于模型的建立的过程是要经过梯度下降的过程，使损失函数loss达到最小值，而现在我们引入了正交惩罚这个概念，在损失函数loss的基础上添加了<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          1 
         
        
          2 
         
        
        
        
          ω 
         
        
          2 
         
        
       
      
        \frac{1}{2}\omega^2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.19011em; vertical-align: -0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.845108em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">ω</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>，即添加了正则系数。我们现在的目标不是仅仅使损失函数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
         o 
        
       
         s 
        
       
         s 
        
       
      
        loss 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span></span>达到最小值了，我们的目标是要经过梯度下降使<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
         o 
        
       
         s 
        
       
         s 
        
       
         + 
        
        
        
          1 
         
        
          2 
         
        
        
        
          ω 
         
        
          2 
         
        
       
      
        loss+\frac{1}{2}\omega^2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.77777em; vertical-align: -0.08333em;"></span><span class="mord mathdefault" style="margin-right: 0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.19011em; vertical-align: -0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.845108em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">ω</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>达到最小值，这就是正则化惩罚的过程。<br> 此外还有一种<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
        
          1 
         
        
       
      
        L_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>正则化惩罚的方式，是加上<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ∣ 
        
       
         ω 
        
       
         ∣ 
        
       
      
        |\omega| 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right: 0.03588em;">ω</span><span class="mord">∣</span></span></span></span></span></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> KFold<span class="token punctuation">,</span> cross_val_score
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrix<span class="token punctuation">,</span> recall_score<span class="token punctuation">,</span> classification_report
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">printing_Kfold_scores</span><span class="token punctuation">(</span>x_train_data<span class="token punctuation">,</span> y_train_data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#表示进行k折的交叉验证</span>
    fold <span class="token operator">=</span> KFold<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> shuffle <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
    
    <span class="token comment">#惩罚项的不同的权重</span>
    c_param_range <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span>
    
    <span class="token comment">#展示结果所用的表格，5行2列，来存储不同的参数进行交叉验证的召回率</span>
    result_table <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>index <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>c_param_range<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"C_parameter"</span><span class="token punctuation">,</span><span class="token string">"Mean recall score"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    result_table<span class="token punctuation">[</span><span class="token string">"C_parameter"</span><span class="token punctuation">]</span> <span class="token operator">=</span> c_param_range
    
    
    j <span class="token operator">=</span> <span class="token number">0</span>
    
    <span class="token comment"># 外层循环：寻找最佳的惩罚项的权重：</span>
    <span class="token keyword">for</span> c_param <span class="token keyword">in</span> c_param_range<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-------------------------------------------"</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"C parameter:"</span><span class="token punctuation">,</span> c_param<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-------------------------------------------"</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span>
        
        recall_accs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment">#内层循环：进行交叉验证</span>
        <span class="token keyword">for</span> iteration<span class="token punctuation">,</span> indices <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>fold<span class="token punctuation">.</span>split<span class="token punctuation">(</span>x_train_data<span class="token punctuation">)</span><span class="token punctuation">,</span>start<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment">#iteration:i值，第i次交叉验证；indices:两个索引集合，训练集 = indices[0],验证集 = indices[1]</span>
            <span class="token comment">#enumerate():用于将一个可比案例的数据对象组合为一个索引序列,将fold和下标组合成一个索引序列</span>
            
            
            <span class="token comment">#【建立逻辑回归模型】，传入惩罚项权重和惩罚方式，这里选择L1惩罚</span>
            lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C <span class="token operator">=</span> c_param<span class="token punctuation">,</span> penalty <span class="token operator">=</span> <span class="token string">"l1"</span><span class="token punctuation">,</span> solver<span class="token operator">=</span><span class="token string">"liblinear"</span><span class="token punctuation">)</span>
            
            <span class="token comment">#使用训练集（索引是0）【训练模型】</span>
            lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train_data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>indices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y_train_data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>indices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token comment">#建立好模型后用测试集去预测模型结果</span>
            y_pred_undersample <span class="token operator">=</span> lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_train_data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>indices<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span>
            
            <span class="token comment">#评估分类结果，计算召回率</span>
            recall_acc <span class="token operator">=</span> recall_score<span class="token punctuation">(</span>y_train_data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>indices<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span> y_pred_undersample<span class="token punctuation">)</span><span class="token comment">#计算一次召回率</span>
            recall_accs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>recall_acc<span class="token punctuation">)</span><span class="token comment">#把五次的召回率的结果和在一起，以便后续求平均值</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Iteration "</span><span class="token punctuation">,</span> iteration<span class="token punctuation">,</span><span class="token string">":召回率="</span><span class="token punctuation">,</span> recall_acc<span class="token punctuation">)</span>
            
        <span class="token comment">#当执行完所有的交叉验证后，计算每个参数c对应的平均召回率并打印</span>
        result_table<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>j<span class="token punctuation">,</span><span class="token string">"Mean recall score"</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>recall_accs<span class="token punctuation">)</span>
        j <span class="token operator">+=</span><span class="token number">1</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"平均召回率："</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>recall_accs<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>
        
    best_c <span class="token operator">=</span> result_table<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>result_table<span class="token punctuation">[</span><span class="token string">"Mean recall score"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span>idxmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"C_parameter"</span><span class="token punctuation">]</span>
    
    <span class="token comment">#打印出最好的结果:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"*********************************************************************************"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"效果最好的模型所选的惩罚参数C是："</span><span class="token punctuation">,</span> best_c<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"*********************************************************************************"</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> best_c
</code></pre> 
<pre><code class="prism language-python">best_c <span class="token operator">=</span> printing_Kfold_scores<span class="token punctuation">(</span>X_train_undersample<span class="token punctuation">,</span> y_train_undersample<span class="token punctuation">)</span>
</code></pre> 
<pre><code>-------------------------------------------
C parameter: 0.01
-------------------------------------------
 
Iteration  1 :召回率= 0.9315068493150684
Iteration  2 :召回率= 0.9178082191780822
Iteration  3 :召回率= 1.0
Iteration  4 :召回率= 0.9594594594594594
Iteration  5 :召回率= 0.9545454545454546

平均召回率： 0.9526639964996129

-------------------------------------------
C parameter: 0.1
-------------------------------------------
 
Iteration  1 :召回率= 0.8493150684931506
Iteration  2 :召回率= 0.863013698630137
Iteration  3 :召回率= 0.9491525423728814
Iteration  4 :召回率= 0.9324324324324325
Iteration  5 :召回率= 0.8939393939393939

平均召回率： 0.897570627173599

-------------------------------------------
C parameter: 1
-------------------------------------------
 
Iteration  1 :召回率= 0.863013698630137
Iteration  2 :召回率= 0.9041095890410958
Iteration  3 :召回率= 0.9491525423728814
Iteration  4 :召回率= 0.9459459459459459
Iteration  5 :召回率= 0.9090909090909091

平均召回率： 0.9142625370161939

-------------------------------------------
C parameter: 10
-------------------------------------------
 
Iteration  1 :召回率= 0.863013698630137
Iteration  2 :召回率= 0.9041095890410958
Iteration  3 :召回率= 0.9661016949152542
Iteration  4 :召回率= 0.9459459459459459
Iteration  5 :召回率= 0.9090909090909091

平均召回率： 0.9176523675246685

-------------------------------------------
C parameter: 100
-------------------------------------------
 
Iteration  1 :召回率= 0.863013698630137
Iteration  2 :召回率= 0.9041095890410958
Iteration  3 :召回率= 0.9661016949152542
Iteration  4 :召回率= 0.9459459459459459
Iteration  5 :召回率= 0.9090909090909091

平均召回率： 0.9176523675246685

*********************************************************************************
效果最好的模型所选的惩罚参数C是： 0.01
*********************************************************************************
</code></pre> 
<h4><a id="_662"></a>模型的测试</h4> 
<h5><a id="_663"></a>绘制混淆矩阵</h5> 
<pre><code class="prism language-python"><span class="token comment">#绘制混淆矩阵函数（cm:计算出的混淆矩阵的值，classes:标签分类, title：标题,cmp:绘图样式）</span>
<span class="token keyword">def</span> <span class="token function">plot_confusion_matrix</span><span class="token punctuation">(</span>cm<span class="token punctuation">,</span> classes<span class="token punctuation">,</span>
                          title<span class="token operator">=</span><span class="token string">'Confusion matrix'</span><span class="token punctuation">,</span>
                          cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>Blues<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>cm<span class="token punctuation">,</span>cmap<span class="token operator">=</span>cmap<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>title<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span><span class="token punctuation">)</span>
    tick_marks <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>classes<span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span>tick_marks<span class="token punctuation">,</span> classes<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span>tick_marks<span class="token punctuation">,</span> classes<span class="token punctuation">)</span>

    thresh <span class="token operator">=</span> cm<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">.</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> itertools<span class="token punctuation">.</span>product<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>cm<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">range</span><span class="token punctuation">(</span>cm<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span>j<span class="token punctuation">,</span> i<span class="token punctuation">,</span> cm<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">,</span>
                 horizontalalignment<span class="token operator">=</span><span class="token string">"center"</span><span class="token punctuation">,</span>
                 color<span class="token operator">=</span><span class="token string">"white"</span> <span class="token keyword">if</span> cm<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">&gt;</span> thresh <span class="token keyword">else</span> <span class="token string">"black"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'True label'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Predicted label'</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="_689"></a>使用下采样数据集测试下采样方案</h5> 
<p>上述的探索已经得出了最佳的惩罚权重值，best_c，这里直接使用best_c作为惩罚项的权重系数，进行回归预测，并用混淆矩阵进行结果展示</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> itertools
lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C <span class="token operator">=</span> best_c<span class="token punctuation">,</span> penalty <span class="token operator">=</span> <span class="token string">'l1'</span><span class="token punctuation">,</span> solver <span class="token operator">=</span> <span class="token string">"liblinear"</span><span class="token punctuation">)</span>
lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_undersample<span class="token punctuation">,</span>y_train_undersample<span class="token punctuation">.</span>values<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y_pred_undersample <span class="token operator">=</span> lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test_undersample<span class="token punctuation">.</span>values<span class="token punctuation">)</span>

cnf_matrix <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>y_test_undersample<span class="token punctuation">,</span> y_pred_undersample<span class="token punctuation">)</span><span class="token comment">#计算混淆矩阵所需值</span>
np<span class="token punctuation">.</span>set_printoptions<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment">#设置精度为小数点后两位</span>

<span class="token comment">#使用公式进行召回率的计算</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试集中的召回率为："</span><span class="token punctuation">,</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token punctuation">(</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#绘图</span>
class_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#画图前先设置好画布</span>
plot_confusion_matrix<span class="token punctuation">(</span>cnf_matrix
                      <span class="token punctuation">,</span> classes<span class="token operator">=</span>class_names
                      <span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'Confusion matrix'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>测试集中的召回率为： 0.9387755102040817
</code></pre> 
<p><img src="https://images2.imgbox.com/f2/6c/WYfH9GHf_o.png" alt="output_20_1"></p> 
<p>上面的情况是对下采样样本的测试集进行测试的结果，是理想情况下的判断结果。而实际我们应该是用整个样本的测试集对模型进行测试，下面我们进行用整个模型的测试集测试，检验一下下采样模型的可靠性：</p> 
<h5><a id="_724"></a>用原始测试集测试下采样</h5> 
<pre><code class="prism language-python">lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C <span class="token operator">=</span> best_c<span class="token punctuation">,</span> penalty <span class="token operator">=</span> <span class="token string">'l1'</span><span class="token punctuation">,</span>solver <span class="token operator">=</span> <span class="token string">"liblinear"</span><span class="token punctuation">)</span>
lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_undersample<span class="token punctuation">,</span>y_train_undersample<span class="token punctuation">.</span>values<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y_pred <span class="token operator">=</span> lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>values<span class="token punctuation">)</span>

<span class="token comment"># Compute confusion matrix</span>
cnf_matrix <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_pred<span class="token punctuation">)</span>
np<span class="token punctuation">.</span>set_printoptions<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Recall metric in the testing dataset: "</span><span class="token punctuation">,</span> cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token punctuation">(</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Plot non-normalized confusion matrix</span>
class_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
plot_confusion_matrix<span class="token punctuation">(</span>cnf_matrix
                      <span class="token punctuation">,</span> classes<span class="token operator">=</span>class_names
                      <span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'Confusion matrix'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>Recall metric in the testing dataset:  0.9115646258503401
</code></pre> 
<p><img src="https://images2.imgbox.com/04/f8/cH9K32Cz_o.png" alt="output_22_1"></p> 
<p>根据上述的结果，可以看出在下采样的处理方法下，在测试集数据量增大的情况下，召回率的结果并没有太大的变化，但是可以看到正常数据被误判成异常数据的比例较高，即假阳性太多，需要做出改进。</p> 
<h3><a id="_758"></a>下采样方法的改进</h3> 
<h4><a id="_759"></a>①不进行采样，直接使用原数据集进行模型的建立与预测</h4> 
<pre><code class="prism language-python">best_c <span class="token operator">=</span> printing_Kfold_scores<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
</code></pre> 
<pre><code>-------------------------------------------
C parameter: 0.01
-------------------------------------------
 
Iteration  1 :召回率= 0.4925373134328358
Iteration  2 :召回率= 0.6027397260273972
Iteration  3 :召回率= 0.6833333333333333
Iteration  4 :召回率= 0.5692307692307692
Iteration  5 :召回率= 0.45

平均召回率： 0.5595682284048672

-------------------------------------------
C parameter: 0.1
-------------------------------------------
 
Iteration  1 :召回率= 0.5671641791044776
Iteration  2 :召回率= 0.6164383561643836
Iteration  3 :召回率= 0.6833333333333333
Iteration  4 :召回率= 0.5846153846153846
Iteration  5 :召回率= 0.525

平均召回率： 0.5953102506435158

-------------------------------------------
C parameter: 1
-------------------------------------------
 
Iteration  1 :召回率= 0.5522388059701493
Iteration  2 :召回率= 0.6164383561643836
Iteration  3 :召回率= 0.7166666666666667
Iteration  4 :召回率= 0.6153846153846154
Iteration  5 :召回率= 0.5625

平均召回率： 0.612645688837163

-------------------------------------------
C parameter: 10
-------------------------------------------
 
Iteration  1 :召回率= 0.5522388059701493
Iteration  2 :召回率= 0.6164383561643836
Iteration  3 :召回率= 0.7333333333333333
Iteration  4 :召回率= 0.6153846153846154
Iteration  5 :召回率= 0.575

平均召回率： 0.6184790221704963

-------------------------------------------
C parameter: 100
-------------------------------------------
 
Iteration  1 :召回率= 0.5522388059701493
Iteration  2 :召回率= 0.6164383561643836
Iteration  3 :召回率= 0.7333333333333333
Iteration  4 :召回率= 0.6153846153846154
Iteration  5 :召回率= 0.575

平均召回率： 0.6184790221704963

*********************************************************************************
效果最好的模型所选的惩罚参数C是： 10.0
*********************************************************************************
</code></pre> 
<p>可以看出由于原始数据严重的不平衡，所以召回率较低，由此，对于数据进行下采样处理，进行平衡化是很有必要的。</p> 
<p>下面我们通过混淆矩阵来观察直接用原数据集处理的效果。</p> 
<pre><code class="prism language-python">lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C <span class="token operator">=</span> best_c<span class="token punctuation">,</span> penalty <span class="token operator">=</span> <span class="token string">'l1'</span><span class="token punctuation">,</span>solver <span class="token operator">=</span> <span class="token string">"liblinear"</span><span class="token punctuation">)</span>
lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">.</span>values<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y_pred <span class="token operator">=</span> lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>values<span class="token punctuation">)</span>

<span class="token comment"># Compute confusion matrix</span>
cnf_matrix <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_pred<span class="token punctuation">)</span>
np<span class="token punctuation">.</span>set_printoptions<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Recall metric in the testing dataset: "</span><span class="token punctuation">,</span> cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token punctuation">(</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Plot non-normalized confusion matrix</span>
class_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
plot_confusion_matrix<span class="token punctuation">(</span>cnf_matrix
                      <span class="token punctuation">,</span> classes<span class="token operator">=</span>class_names
                      <span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'Confusion matrix'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>Recall metric in the testing dataset:  0.6190476190476191
</code></pre> 
<p><img src="https://images2.imgbox.com/83/d1/e58tabdj_o.png" alt="output_27_1"></p> 
<p>由上述结果可以看出，直接使用原数据集进行模型的训练，测试结果中的假阳性变少，但是对应的召回率较低，其实很多的异常数据没有找到，模型仍需改进。<br> 下面使用过采样的方式对模型进行训练分析。</p> 
<h4><a id="_867"></a>法②改变判断的阈值的方式</h4> 
<p>在模型的默认参数中，我们认为概率大于0.5为A类，概率小于0.5为B类。这个0.5被称为阈值，但是他是可以手动进行调整的，所以下面我们对模型的阈值thresh进行人为地设定，再分别进行模型的召回率计算和检验</p> 
<pre><code class="prism language-python"><span class="token comment">#建模</span>
lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">,</span> penalty <span class="token operator">=</span> <span class="token string">'l1'</span><span class="token punctuation">,</span> solver <span class="token operator">=</span> <span class="token string">"liblinear"</span><span class="token punctuation">)</span>
lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_undersample<span class="token punctuation">,</span>y_train_undersample<span class="token punctuation">.</span>values<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#仍采用下采样的数据进行模型训练</span>
y_pred_undersample_proba <span class="token operator">=</span> lr<span class="token punctuation">.</span>predict_proba<span class="token punctuation">(</span>X_test_undersample<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token comment">#利用predict_prob得到预测结果的概率值</span>
<span class="token comment">#之前的predict（）函数是会直接得到0-1的类别的，现在我们得到的是一个概率值,用这个得到的概率与thresholds作比较</span>


<span class="token comment">#设置不同的阈值</span>
thresholds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.3</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.6</span><span class="token punctuation">,</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.8</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment">#设置画布大小</span>

j<span class="token operator">=</span><span class="token number">1</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> thresholds<span class="token punctuation">:</span>
    y_test_predictions_high_recall <span class="token operator">=</span> y_pred_undersample_proba<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> i<span class="token comment">#将概率值转化，判断（以0.5为例），大于0.5是异常，小于0.5是正常</span>
    
    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>j<span class="token punctuation">)</span>   <span class="token comment">#3*3的子图， j表示第几个图，每张图对应一个阈值</span>
    j <span class="token operator">+=</span><span class="token number">1</span> 
    
    <span class="token comment">#计算混淆矩阵所需值</span>
    cnf_matrix <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>y_test_undersample<span class="token punctuation">,</span>y_test_predictions_high_recall<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>set_printoptions<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试集的召回率："</span><span class="token punctuation">,</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token punctuation">(</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          
    <span class="token comment">#绘图</span>
    class_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
    plot_confusion_matrix<span class="token punctuation">(</span>cnf_matrix
                          <span class="token punctuation">,</span> classes<span class="token operator">=</span>class_names
                          <span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'Thresholds &gt;= %s'</span><span class="token operator">%</span>i<span class="token punctuation">)</span>
</code></pre> 
<pre><code>测试集的召回率： 1.0
测试集的召回率： 1.0
测试集的召回率： 1.0
测试集的召回率： 0.9727891156462585
测试集的召回率： 0.9387755102040817
测试集的召回率： 0.8775510204081632
测试集的召回率： 0.8163265306122449
测试集的召回率： 0.7755102040816326
测试集的召回率： 0.5918367346938775
</code></pre> 
<p><img src="https://images2.imgbox.com/f8/a4/AULBh02q_o.png" alt="output_29_1"></p> 
<p>从上面的结果可以看出，随着阈值的增大，因为判断异常的标准升高，召回率降低。当阈值为0.1-0.3时，召回率为1，但是将所有的样本都当成了异常样本，这样的模型失去了意义。而当阈值为0.4时，召回率高但是假阳性太高，不适合。当阈值为0.6时，对比0.5时，检漏变多，但是假阳性变少，具体使用哪个阈值要看需求。当模型的阈值大于等于0.7时，召回率过低，模型不适合。</p> 
<p>下采样模型具有假阳性高的缺点，下面使用过采样方案。</p> 
<h3><a id="_925"></a>过采样方案</h3> 
<p>过采样方案主要是要生成更多的异常样本，使异常样本变得和正常样本一样多，即将异常样本规模扩大n倍。</p> 
<p>异常样本的生成主要是使用SMOTE算法：</p> 
<p>首先我们要选择出少数类样本，选择出其中的一个样本，对其他的样本点进行欧式距离计算，并且从小到大排列，只取出最小的1/n*样本数个，然后使用一定的随机数进行填充，其他的样本也进行，直至完成扩大n倍数。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd 
<span class="token comment">#引入SOMTE算法模块</span>
<span class="token keyword">from</span> imblearn<span class="token punctuation">.</span>over_sampling <span class="token keyword">import</span> SMOTE
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrix
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
</code></pre> 
<p>读取数据，划分特征值和标签</p> 
<pre><code class="prism language-python">credit_cards<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"creditcard.csv"</span><span class="token punctuation">)</span>

columns<span class="token operator">=</span>credit_cards<span class="token punctuation">.</span>columns
features_columns<span class="token operator">=</span>columns<span class="token punctuation">.</span>delete<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>columns<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#删除最后一列：Class列</span>

features<span class="token operator">=</span>credit_cards<span class="token punctuation">[</span>features_columns<span class="token punctuation">]</span>
labels<span class="token operator">=</span>credit_cards<span class="token punctuation">[</span><span class="token string">'Class'</span><span class="token punctuation">]</span>
</code></pre> 
<p>数据集切分，将数据集切分为训练集和测试集</p> 
<pre><code class="prism language-python">features_train<span class="token punctuation">,</span> features_test<span class="token punctuation">,</span> labels_train<span class="token punctuation">,</span> labels_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>features<span class="token punctuation">,</span> 
                                                                            labels<span class="token punctuation">,</span> 
                                                                            test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> 
                                                                            random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre> 
<p>基于SMOTE算法进行样本的生成，创造新的数据集，这样正负样本的数量就一致了。</p> 
<pre><code class="prism language-python">oversampler<span class="token operator">=</span>SMOTE<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment">#获得一个对象</span>
os_features<span class="token punctuation">,</span>os_labels<span class="token operator">=</span>oversampler<span class="token punctuation">.</span>fit_sample<span class="token punctuation">(</span>features_train<span class="token punctuation">,</span>labels_train<span class="token punctuation">)</span>
<span class="token comment">#只对train集进行数据的生成,测试集一定是不动的，会使两个label的自动平衡</span>
</code></pre> 
<p>此时我们查看训练集的样本数据，可以发现是1:1的了</p> 
<pre><code class="prism language-python">count_classes <span class="token operator">=</span> pd<span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span>os_labels<span class="token punctuation">,</span> sort <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sort_index<span class="token punctuation">(</span><span class="token punctuation">)</span>
count_classes<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>kind <span class="token operator">=</span> <span class="token string">"bar"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Fruad class histogram"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Class"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Frequancy"</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>Text(0, 0.5, 'Frequancy')
</code></pre> 
<p><img src="https://images2.imgbox.com/05/de/S4EppCfj_o.png" alt="output_39_1"></p> 
<pre><code class="prism language-python"><span class="token comment">#进行惩罚参数权重的选择</span>
os_features <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>os_features<span class="token punctuation">)</span>
os_labels <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>os_labels<span class="token punctuation">)</span>
best_c <span class="token operator">=</span> printing_Kfold_scores<span class="token punctuation">(</span>os_features<span class="token punctuation">,</span>os_labels<span class="token punctuation">)</span>
</code></pre> 
<pre><code>-------------------------------------------
C parameter: 0.01
-------------------------------------------
 
Iteration  1 :召回率= 0.8903225806451613
Iteration  2 :召回率= 0.8947368421052632
Iteration  3 :召回率= 0.968861347792409
Iteration  4 :召回率= 0.9578593332673855
Iteration  5 :召回率= 0.958408898561238

平均召回率： 0.9340378004742915

-------------------------------------------
C parameter: 0.1
-------------------------------------------
 
Iteration  1 :召回率= 0.8903225806451613
Iteration  2 :召回率= 0.8947368421052632
Iteration  3 :召回率= 0.9704769281841319
Iteration  4 :召回率= 0.9599256987722712
Iteration  5 :召回率= 0.9603323770897221

平均召回率： 0.93515888535931

-------------------------------------------
C parameter: 1
-------------------------------------------
 
Iteration  1 :召回率= 0.8903225806451613
Iteration  2 :召回率= 0.8947368421052632
Iteration  3 :召回率= 0.9705433218988603
Iteration  4 :召回率= 0.960321385783845
Iteration  5 :召回率= 0.954517976280762

平均召回率： 0.9340884213427783

-------------------------------------------
C parameter: 10
-------------------------------------------
 
Iteration  1 :召回率= 0.8903225806451613
Iteration  2 :召回率= 0.8947368421052632
Iteration  3 :召回率= 0.9705211906606175
Iteration  4 :召回率= 0.957529594091074
Iteration  5 :召回率= 0.9605082379837548

平均召回率： 0.9347236890971743

-------------------------------------------
C parameter: 100
-------------------------------------------
 
Iteration  1 :召回率= 0.8903225806451613
Iteration  2 :召回率= 0.8947368421052632
Iteration  3 :召回率= 0.9700121721810335
Iteration  4 :召回率= 0.9603433683955991
Iteration  5 :召回率= 0.960761038018927

平均召回率： 0.9352352002691969

*********************************************************************************
效果最好的模型所选的惩罚参数C是： 100.0
*********************************************************************************
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#s使用最佳的惩罚系数进行模型的训练和验证</span>
lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C <span class="token operator">=</span> best_c<span class="token punctuation">,</span> penalty <span class="token operator">=</span> <span class="token string">'l1'</span><span class="token punctuation">,</span>solver<span class="token operator">=</span><span class="token string">'liblinear'</span><span class="token punctuation">)</span>
lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>os_features<span class="token punctuation">,</span>os_labels<span class="token punctuation">.</span>values<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y_pred <span class="token operator">=</span> lr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>features_test<span class="token punctuation">.</span>values<span class="token punctuation">)</span>

cnf_matrix <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>labels_test<span class="token punctuation">,</span>y_pred<span class="token punctuation">)</span>
np<span class="token punctuation">.</span>set_printoptions<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试集中的召回率: "</span><span class="token punctuation">,</span> cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token punctuation">(</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span>cnf_matrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

class_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
plot_confusion_matrix<span class="token punctuation">(</span>cnf_matrix
                      <span class="token punctuation">,</span> classes<span class="token operator">=</span>class_names
                      <span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'Confusion matrix'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>测试集中的召回率:  0.9108910891089109
</code></pre> 
<p><img src="https://images2.imgbox.com/fe/c8/Qw7p4K7r_o.png" alt="41_1"></p> 
<p>观察混淆矩阵可知，在召回率较高的情况下，此时我们的误判数由原来的8000+降低到了500+，误判的数量大大降低了，即假阳性降低，故采用过采样的方案效果更好。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/15c96eacf338efa74864e7b4159432b0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">那些年踩过的坑: endl耗时比‘\n‘多</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e81d9297873d0ca384547698ed7e12fb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">剑指 Offer 20. 表示数值的字符串 C&#43;&#43;</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>