<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>opencv图像处理 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="opencv图像处理" />
<meta property="og:description" content="1 保存带透明通道的图片 透明通道的无论怎么操作显示的多是带白色背景的, 只有通过设置imread(“”,imread_unchanged), 保存下来的才是透明通道的
unchanged: 4通道, 有个透明通道
IMREAD_UNCHANGED 加载代透明的图片IMREAD_COLOR: 加载bgr图片IMREAD_GRAYSCALE: 加载灰色图片IMREAD_ANYCOLOR: 加载各种颜色 2. mat对象 mat对象: 用来存储图像的数据(二维数据)的内存对象
存储枚举结果的
头部: 宽高, 数据类型,通道(单通道一般是灰色图像, 三通道一般是rgb图像. 四通道一般是透明通道)
数据部分: 像素值
创建Mat对象: Mat(size(x,y),cv_8uc3)
mat对象赋值: 只是地址的指向, 复制的变量, 他的内存地址是被复制的内存地址
mat对象拷贝或者克隆: 会创建一个新的mat对象, 而不是直接执行被拷贝的内存地址
mat.depth(): 返回的是个int类型, 图像的深度
mat. type(): 返回的是个int类型, 图像的类型
[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-JL3V6aZE-1656318416402)(D:\opencvSourse\openImg\imgType&amp;&amp;depth对应表.png)]
type数值:
type = depth &#43; (channle -1)* 8
Mat src = Mat::zeros(Size(100, 100), CV_8UC3); cout &lt;&lt; &#34;图片类型8: &#34; &lt;&lt; src.type() &lt;&lt; &#34;\t&#34; &lt;&lt; &#34;图像深度0: &#34; &lt;&lt; src.depth() &lt;&lt; endl; //图片类型8: 16 图像深度0: 0 Mat src1 = Mat::zeros(Size(100, 100), CV_8SC3); cout &lt;&lt; &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/675c66f84ec1a8a242382a06eaba9d76/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-27T16:31:31+08:00" />
<meta property="article:modified_time" content="2022-06-27T16:31:31+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">opencv图像处理</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h6><a id="1__0"></a>1 保存带透明通道的图片</h6> 
<p>透明通道的无论怎么操作显示的多是带白色背景的, 只有通过设置imread(“”,imread_unchanged), 保存下来的才是透明通道的</p> 
<p>unchanged: 4通道, 有个透明通道</p> 
<ul><li><code>IMREAD_UNCHANGED</code> 加载代透明的图片</li><li><code>IMREAD_COLOR</code>: 加载bgr图片</li><li><code>IMREAD_GRAYSCALE</code>: 加载灰色图片</li><li><code>IMREAD_ANYCOLOR</code>: 加载各种颜色</li></ul> 
<h6><a id="2_mat_11"></a>2. mat对象</h6> 
<p>mat对象: 用来存储图像的数据(二维数据)的内存对象</p> 
<p>存储枚举结果的</p> 
<ul><li> <p>头部: 宽高, 数据类型,通道(单通道一般是灰色图像, 三通道一般是rgb图像. 四通道一般是透明通道)</p> </li><li> <p>数据部分: 像素值</p> </li><li> <p>创建Mat对象: Mat(size(x,y),cv_8uc3)</p> </li></ul> 
<p>mat对象赋值: 只是地址的指向, 复制的变量, 他的内存地址是被复制的内存地址</p> 
<p>mat对象拷贝或者克隆: 会创建一个新的mat对象, 而不是直接执行被拷贝的内存地址</p> 
<p><code>mat.depth()</code>: 返回的是个int类型, 图像的深度</p> 
<p><code>mat. type()</code>: 返回的是个int类型, 图像的类型</p> 
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-JL3V6aZE-1656318416402)(D:\opencvSourse\openImg\imgType&amp;&amp;depth对应表.png)]</p> 
<p>type数值:</p> 
<ul><li> <p>type = depth + (channle -1)* 8</p> </li><li> <pre><code>Mat src = Mat::zeros(Size(100, 100), CV_8UC3);
cout &lt;&lt; "图片类型8: " &lt;&lt; src.type() &lt;&lt; "\t" &lt;&lt; "图像深度0: " &lt;&lt; src.depth() &lt;&lt; endl;
//图片类型8: 16   图像深度0: 0

Mat src1 = Mat::zeros(Size(100, 100), CV_8SC3);
cout &lt;&lt; "图片类型9: " &lt;&lt; src1.type() &lt;&lt; "\t" &lt;&lt; "图像深度1: " &lt;&lt; src1.depth() &lt;&lt; endl;
//图片类型9: 17   图像深度1: 1

Mat src2 = Mat::zeros(Size(100, 100), CV_16UC1);
cout &lt;&lt; "图片类型9: " &lt;&lt; src2.type() &lt;&lt; "\t" &lt;&lt; "图像深度2: " &lt;&lt; src2.depth() &lt;&lt; endl;
//图片类型8+2: 10 图像深度2: 2
</code></pre> </li></ul> 
<h6><a id="2_Mat__52"></a>2 Mat 对象创建</h6> 
<p><code>Mat(x,x,type())</code> : 这样创建, 他默认不会全为0, 会自带一些颜色</p> 
<p><code>Mat::zeros(Size(x,x), type())</code>: 创建一个全是0的对象</p> 
<p><code>Mat::zeros</code> mat::once : 创建一个全是1的对象</p> 
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-8JS5rn6r-1656318416403)()]</p> 
<ul><li>mat.clone(): clone是把所有的都复制过来，不论你是否设置了ROI、COI等影响，clone都会原封不动的克隆过来</li><li>copyTo是实现图像roi操作的正确方法</li></ul> 
<h6><a id="3_mat_69"></a>3 mat对象遍历</h6> 
<pre><code>imshow("原图", img);
	Mat dst = Mat::zeros(img.size(), img.type());
	/*for (int row = 0; row &lt; img.rows; row++)
	{
		for (int col = 0; col &lt; img.cols; col++)
		{
			if (img.channels() == 3)
			{
				dst.at&lt;Vec3b&gt;(row, col)[0] = img.at&lt;Vec3b&gt;(row, col)[0];
				dst.at&lt;Vec3b&gt;(row, col)[1] = img.at&lt;Vec3b&gt;(row, col)[1];
				dst.at&lt;Vec3b&gt;(row, col)[2] = img.at&lt;Vec3b&gt;(row, col)[2];
			}
		}
	}*/
	/*imshow("遍历", dst);*/
	for (int row = 0; row &lt; img.rows; row++)
	{
		uchar* y = img.ptr&lt;uchar&gt;(row);
		uchar* newI = dst.ptr&lt;uchar&gt;(row);
		for (int col = 0; col &lt; img.cols; col++)
		{
			*newI++ = *y++;
			*newI++ = *y++;
			*newI++ = *y++;
		}
	}
	imshow("遍历", dst);
</code></pre> 
<h6><a id="4__103"></a>4 图像算术操作</h6> 
<ol><li> <p>注意点: <strong>2张图片必须大小一致, 类型一致</strong></p> <p>越界: opencv会自动去处理, 如果得大于255 ,会等于255, 如果小于0会等于0</p> <p>add, subtract,multiple, divide</p> </li><li> <p>API</p> <p>addWeighted: 用来调节亮度和对比度(伪装透明度)</p> 
  <ul><li>参数2, 4 是权重(*权重)</li><li>参数5: 合并的dst + 参数5</li></ul> </li></ol> 
<pre><code>void Person::erithmetic(Mat&amp; img)
{
	imshow("原图", img);
	Mat src = Mat::zeros(img.size(), img.type());
	src = Scalar(128, 128, 128);
	Mat dst;
	//伪装透明度
	addWeighted(img, 0.5, src, 0.5,0,dst);
	//addWeighted(img, 1.5, img, -0.2, 0, dst);
	imshow("位置透明度", dst);
}
</code></pre> 
<h6><a id="5__134"></a>5 与或非</h6> 
<p>mask满足条件:</p> 
<ol><li><strong>大小必须跟原图一致, 类型为:CV_8UC1</strong></li></ol> 
<p><strong><code>bitwise_not (img,dst,mask)</code> :如果mask区域为0的地方, 不进行取反, 为黑色0, mask为255的地方则进行取反</strong></p> 
<p>bitwise_and, bitweise_or, bitweise_xor</p> 
<pre><code>imshow("原图", img);
	Mat mask = Mat::zeros(img.size(), CV_8UC1);
	for (int row = img.rows / 4; row &lt; img.rows / 4 * 3; row++)
	{
		uchar* p = mask.ptr&lt;uchar&gt;(row);
		for (int col = 0 ; col &lt; img.cols / 4 * 2; col++)
		{
			*(p + (col + img.cols / 4)) = 255;
		}
	}
	imshow("mask", mask);
	Mat dst;
	bitwise_not(img, dst, mask);
	imshow("取反", dst);
</code></pre> 
<h6><a id="6__163"></a>6 像素信息统计</h6> 
<h6><a id="1_api__165"></a>1. api, 可以通过方差或者均值过滤掉一些颜色</h6> 
<ul><li>mean 返回的是scalar对象, 求取每个通道的均值</li><li>meanStdDev: 返回的是一个mat对象</li><li>minMaxLoc: 最大值最小值, 最大值的像素点位置, 值小值的point&amp; 
  <ul><li>参数1: 是一个double类型的引用(最小值)</li><li>参数2: 是一个double类型的引用(最大值)</li><li>参数3: 是一个点类型的地址 Loc.x</li><li>参数3: 是一个点类型的地址 Loc.y</li></ul> </li></ul> 
<pre><code>void Person::distribution(Mat&amp; img)
{
	imshow("原图", img);
	double min; double max;
	Point minLoc; Point maxLoc;
	vector&lt;Mat&gt; vMat(img.channels());
	split(img, vMat);
	//均值
	Scalar mea = mean(img);
	Scalar mea1;
	vector&lt;Mat&gt; stddev(img.channels());
	for (int i = 1; i &lt; vMat.size(); i++)
	{
		//最小最大值
		minMaxLoc(vMat[i-1], &amp;min, &amp;max, &amp;minLoc, &amp;maxLoc, Mat());
		cout &lt;&lt; "通道:" &lt;&lt; i &lt;&lt; "最小值: " &lt;&lt; min &lt;&lt; "\t" &lt;&lt; "最大值: " &lt;&lt; max &lt;&lt; "\t" &lt;&lt; "最小值像素点: " &lt;&lt; minLoc &lt;&lt; "最大值像素点" &lt;&lt; maxLoc &lt;&lt; endl;
		cout &lt;&lt; "通道:" &lt;&lt; i &lt;&lt; "均值: " &lt;&lt; mea[i - 1] &lt;&lt; endl;

		meanStdDev(vMat[i - 1], mea1, stddev[i-1], Mat());
		cout &lt;&lt; "通道:" &lt;&lt; i &lt;&lt; "方差: " &lt;&lt; stddev[i - 1] &lt;&lt; endl;
	}
}
</code></pre> 
<h6><a id="1__202"></a>六.1. 图形绘制与填充</h6> 
<ol><li>直线绘制</li></ol> 
<ul><li> <p>api: line(canvas, Point(x,y), Point(x1,y1), scalar(B,G,R), thickness, lineType,)</p> <p>lineType: LINE_AA(反锯齿)</p> </li><li> <p>rectangle(canvas, Rect(10, 200, 300, 300), Scalar(0, 0, 200), -1, 8);</p> </li><li> <p>circle(canvas, Point(250, 250), 100, Scalar(200, 10, 10), -1, 8);</p> </li><li> <p>ellipse(canvas, RotatedRect(Point(300, 100), Size(200, 100), 45.5),Scalar(0, 200, 10), -1, LINE_AA);</p> </li></ul> 
<ol start="2"><li> <p>在img中写文字</p> <p>putText(canvas, “value”,Point(x,y), Font_, 1.0 , scalar(b,g,r), thickness, line_type)</p> </li></ol> 
<h6><a id="7___222"></a>7. 像素通道的分离和合并 (实现通道提取)</h6> 
<p>putText(): 向图片中写文字</p> 
<p>scalar: 可以()里面可以只有一个值</p> 
<p>split: 通道分离</p> 
<ul><li>输入是img, 输出是<code>vector &lt;mat&gt;</code>容器</li></ul> 
<p>merge: 合并(输入,输出),</p> 
<p>roi:</p> 
<pre><code>rect roi
mat sub = img(roi)// sub是roi在img中的地方, 是赋值
mat sub = img(roi).clone// 是引用
</code></pre> 
<h6><a id="8__244"></a>8 图像直方图</h6> 
<p>pic: 最高峰</p> 
<p>range: 像素分类</p> 
<p>bin: 每个分类好了的像素区域</p> 
<p>逻辑: 分离 --&gt; 计算直方图(calcHist)–&gt;输出图片归一化(对应高度)–&gt;把归一化绘制到输出img上</p> 
<p>API:</p> 
<ul><li>calcHist 
  <ul><li>图片指针</li><li>多少张图片</li><li>哪一个channels</li><li>mask</li><li>直方图输出</li><li>直方图的维度</li><li>直方图有多少个bins: 是一个指针</li><li>rangs, 是一个指针</li><li>每个bins自动分配取值范围</li><li>累加器</li></ul> </li></ul> 
<pre><code>void Person::calcHistogram(Mat&amp; img)
{
	imshow("原图", img);
	vector&lt;Mat&gt; vImg;
	split(img, vImg);
	Mat bImg; Mat gImg; Mat rImg;
	int bins = 256;
	float rang[] = { 0,255 };
	const float* rangs = { rang };
	calcHist(&amp;vImg[0], 1, 0, Mat(), bImg, 1, &amp;bins, &amp;rangs, true, false);
	calcHist(&amp;vImg[1], 1, 0, Mat(), gImg, 1, &amp;bins, &amp;rangs, true, false);
	calcHist(&amp;vImg[2], 1, 0, Mat(), rImg, 1, &amp;bins, &amp;rangs, true, false);

	imshow("b", bImg);
	imshow("g", bImg);
	imshow("r", bImg);

	Mat dst = Mat::zeros(Size(500, 300), img.type());
	int margin = 50;
	int height = dst.rows - 2 * margin;
	cout &lt;&lt; "高度" &lt;&lt; height &lt;&lt; endl;
	normalize(bImg, bImg, 0, height, NORM_MINMAX);
	normalize(gImg, gImg, 0, height, NORM_MINMAX);
	normalize(rImg, rImg, 0, height, NORM_MINMAX);
	double step = (dst.cols - 2 * 50) / double(bins);
	cout &lt;&lt; "步长" &lt;&lt; step &lt;&lt; endl;
	for (int i = 0; i &lt; bins-1; i++)
	{
		//cout &lt;&lt; bImg.at&lt;double&gt;(i, 0) &lt;&lt; endl;
		line(dst, Point(i * step + margin, height + margin - bImg.at&lt;float&gt;(i, 0)), Point((i + 1) * step + margin, height + margin - bImg.at&lt;float&gt;(i + 1, 0)), Scalar(255, 0, 0), 2);
		//cout &lt;&lt; "电一" &lt;&lt; i * step + margin &lt;&lt; endl;
		line(dst, Point(i * step + margin, height + margin - gImg.at&lt;float&gt;(i, 0)), Point((i + 1) * step + margin, height + margin - gImg.at&lt;float&gt;(i + 1, 0)), Scalar(0, 255, 0), 2);
		line(dst, Point(i * step + margin, height + margin - rImg.at&lt;float&gt;(i, 0)), Point((i + 1) * step + margin, height + margin - rImg.at&lt;float&gt;(i + 1, 0)), Scalar(0, 0, 255), 2);
	}
	imshow("输出", dst);
}
</code></pre> 
<h6><a id="9__311"></a>9 图像图均衡化</h6> 
<h6><a id="1__bins___bins_pik__pik__rangs______bins________313"></a>1. 思路: 划分bins --&gt; 求出bins pik --&gt; pik / rangs = 占比 --&gt; 然后依次每个占比累加 / bins --&gt; 求占比 --&gt; 重新划分 --&gt; 映射</h6> 
<p>用来增加许多图像的全局对比度, <strong>当图像的有用数据的对比度相当接近的时候，通过这种方法，亮度可以更好地在直方图上分布</strong>, <strong>比较相似度</strong></p> 
<h6><a id="2_API_317"></a>2. API</h6> 
<p>equalizeHist: 直方图均衡化 equalizeHist: <strong>只接受灰色图像</strong></p> 
<p>compareHist: 直方图比较</p> 
<ul><li>HISTCMP_BHATTACHARYYA: 巴斯距离比较 <strong>相似性越大, 值越大小</strong></li><li>HISTCMP_CORREL: 相关性比较 <strong>相似性越大,值越大</strong></li></ul> 
<h6><a id="3__326"></a>3. 重点</h6> 
<p>下面代码最好把图片转换为hsv(色彩分明), 在进行比较</p> 
<pre><code>Mat myCalcHistogram(Mat&amp; img)
{
	int bin1 = 256; int bin2 = 256; int bin3 = 256;
	int bins[] = { bin1,bin2,bin3 };
	float rang1[] = { 0,255 }; float rang2[] = { 0,255 }; float rang3[] = { 0,255 };
	const float* rangs[] = { rang1,rang2,rang3 };
	int channels[] = { 0,1,2 };
	Mat dst;
	calcHist(&amp;img, 1, channels, Mat(), dst, 3, bins, rangs, true, false);

	return dst;
}
void Person::compare(Mat&amp; img1, Mat&amp; img2)
{
	cout &lt;&lt; "aa" &lt;&lt; endl;
	imshow("原图1", img1); imshow("原图2", img2);
	Mat histImg = myCalcHistogram(img1);
	Mat histImg2 = myCalcHistogram(img2);
	
	normalize(histImg, histImg, 0, 1, NORM_MINMAX);
	normalize(histImg2, histImg2, 0, 1, NORM_MINMAX);

	double minBha = compareHist(histImg, histImg2, HISTCMP_BHATTACHARYYA);
	double maxBha = compareHist(histImg, histImg, HISTCMP_BHATTACHARYYA);
	cout &lt;&lt; "巴斯距离越大差异越大" &lt;&lt; minBha &lt;&lt; "相同图" &lt;&lt; maxBha &lt;&lt; endl;

	double minCor = compareHist(histImg, histImg2, HISTCMP_CORREL);
	double manCor = compareHist(histImg, histImg, HISTCMP_CORREL);
	cout &lt;&lt; "相似性越大差异越小: 小" &lt;&lt; minCor &lt;&lt; "相同图: 大" &lt;&lt; manCor &lt;&lt; endl;

}
</code></pre> 
<h6><a id="10__366"></a>10 颜色查找表</h6> 
<h6><a id="1_api_368"></a>1. api</h6> 
<ul><li>applyColorMap(img,dst,color[])</li><li>color:是颜色表, 在百度中可以查的到, 速度快</li></ul> 
<h6><a id="2___373"></a>2. 注意点: 只支持彩色图像和灰度图像</h6> 
<pre><code>void Person::colorMap(Mat&amp; img)
{
	int colormap[] =
	{
		COLORMAP_AUTUMN ,
		COLORMAP_BONE,
		COLORMAP_CIVIDIS,
		COLORMAP_DEEPGREEN,
		COLORMAP_HOT,
		COLORMAP_HSV,
		COLORMAP_INFERNO,
		COLORMAP_JET,
		COLORMAP_MAGMA,
		COLORMAP_OCEAN,
		COLORMAP_PINK,
		COLORMAP_PARULA,
		COLORMAP_RAINBOW,
		COLORMAP_SPRING,
		COLORMAP_TWILIGHT,
		COLORMAP_TURBO,
		COLORMAP_TWILIGHT,
		COLORMAP_VIRIDIS,
		COLORMAP_TWILIGHT_SHIFTED,
		COLORMAP_WINTER
	};
	imshow("原图", img);
	Mat dst;
	int index = 0;
	while (true)
	{
		applyColorMap(img, dst, colormap[index % 19]);
		index++;
		imshow("颜色表", dst);
		int key = waitKey(100);
		if (key == 27)
		{
			break;
		}
	}
}
</code></pre> 
<h6><a id="11__420"></a>11. 图像卷积(滤波)</h6> 
<h6><a id="1__422"></a>1. 概率</h6> 
<p>卷积核窗口系数: 卷积核里面的数据</p> 
<p>原理: (卷积系数/权重 * 处于卷积核位置的img的像素相加) / 卷积核面积 = result,取整(<strong>四舍五入</strong>), 把原图中处于卷积核的中心位置像素替换为 result. 卷积核一次前进移动, 反复执行.</p> 
<h6><a id="2__430"></a>2. 卷积的作用</h6> 
<ol><li>实现图像的模糊</li><li>计算图像的梯度</li><li>发现边缘</li><li>进行噪声抑制</li><li>图像的锐化或者增强</li></ol> 
<h6><a id="2__438"></a>2. 处理边缘</h6> 
<ul><li>边缘填0</li><li>border_default</li><li>border_replicate</li><li>border_warp</li><li>border_reflect_101</li><li>border_constant</li></ul> 
<h6><a id="3_API_447"></a>3. API</h6> 
<p>blur: 一般用于处理图像的随机噪声</p> 
<p>boxFilter 是 blur的快速版本, 最好使用boxFilter</p> 
<ul><li>锚定位置 
  <ul><li>Point(-1,-1)——卷积核与原图左边重合；卷积核与原图上边重合；锚定点位于卷积核中心<br> 注意：卷积核大小不同，如3x3，5x5，则卷积核中心不同（偶数无核）</li><li>Point(0,0)——卷积核与原图左边重合；卷积核与原图上边重合；锚定点位于Point(0,0)</li><li>Point(1,1)——卷积核与原图左边-1重合；卷积核与原图上边-1重合；锚定点位于Point(1,1)</li><li>Point(2,2)——卷积核与原图左边-2重合；卷积核与原图上边-2重合；锚定点位于Point(2,2)</li></ul> </li></ul> 
<h6><a id="4__460"></a>4. 注意点:</h6> 
<p>当卷积核大小为偶数: 其实这个时候中心也为(ksize/2)， 对<strong>2x2</strong>的卷积核，中心位置为Point**(1,1)<strong>，<strong>4x4</strong>的卷积核中心位置为Point</strong>(2,2)**。</p> 
<pre><code>imshow("原图", img);
	Mat dst = Mat::zeros(img.size(),img.type());
	Mat dst2;
	for (int row = 1; row &lt; img.rows -1; row++)
	{
		for (int col = 0; col &lt; img.cols; col++)
		{
			int b = round((img.at&lt;Vec3b&gt;(row - 1, col - 1)[0] + img.at&lt;Vec3b&gt;(row - 1, col)[0] + img.at&lt;Vec3b&gt;(row - 1, col + 1)[0] +
				img.at&lt;Vec3b&gt;(row, col - 1)[0] + img.at&lt;Vec3b&gt;(row, col)[0] + img.at&lt;Vec3b&gt;(row, col + 1)[0] +
				img.at&lt;Vec3b&gt;(row + 1, col - 1)[0] + img.at&lt;Vec3b&gt;(row + 1, col)[0] + img.at&lt;Vec3b&gt;(row + 1, col + 1)[0]) / 9);

			int g = round((img.at&lt;Vec3b&gt;(row - 1, col - 1)[1] + img.at&lt;Vec3b&gt;(row - 1, col)[1] + img.at&lt;Vec3b&gt;(row - 1, col + 1)[1] +
				img.at&lt;Vec3b&gt;(row, col - 1)[1] + img.at&lt;Vec3b&gt;(row, col)[1] + img.at&lt;Vec3b&gt;(row, col + 1)[1] +
				img.at&lt;Vec3b&gt;(row + 1, col - 1)[1] + img.at&lt;Vec3b&gt;(row + 1, col)[1] + img.at&lt;Vec3b&gt;(row + 1, col + 1)[1]) / 9);

			int r = round((img.at&lt;Vec3b&gt;(row - 1, col - 1)[2] + img.at&lt;Vec3b&gt;(row - 1, col)[2] + img.at&lt;Vec3b&gt;(row - 1, col + 1)[2] +
				img.at&lt;Vec3b&gt;(row, col - 1)[2] + img.at&lt;Vec3b&gt;(row, col)[2] + img.at&lt;Vec3b&gt;(row, col + 1)[2] +
				img.at&lt;Vec3b&gt;(row + 1, col - 1)[2] + img.at&lt;Vec3b&gt;(row + 1, col)[2] + img.at&lt;Vec3b&gt;(row + 1, col + 1)[2]) / 9);
			dst.at&lt;Vec3b&gt;(row, col)[0] = b; dst.at&lt;Vec3b&gt;(row, col)[1] = g; dst.at&lt;Vec3b&gt;(row, col)[2] = r;
		}
	}
	imshow("手动blue", dst);
	blur(img, dst2, Size(3, 3), Point(-1, -1),BORDER_DEFAULT);
	imshow("blur", dst2);
</code></pre> 
<h6><a id="5__491"></a>5. 处理边缘像素</h6> 
<p>进行卷积之前就应该填充好</p> 
<table><thead><tr><th>填充类型</th><th>方法</th></tr></thead><tbody><tr><td>BORDERT_CONSTANT(常量填充),填充的是0</td><td>iiii|abc|iii (i:常量,abc:像素值)</td></tr><tr><td>border_replicate(填充的是2头的值)</td><td>aaa|abc|hhh</td></tr><tr><td>border_warp(尾填到头,头填到尾)</td><td>cba|abc|abc</td></tr><tr><td>border_reflect_101(看上去最合理)</td><td>fcb|abcf|cba</td></tr><tr><td>border_default(看上去最合理)</td><td>fcb|abcf|cba</td></tr></tbody></table> 
<h6><a id="1__503"></a>1. 边缘填充:</h6> 
<ul><li>copyMakeBorder // 可以用来做边框, 也可以用来卷积 
  <ul><li><code>copyMakeBorder(src,dst,margin, margin1, margin2,margin, 填充方式, 填充的颜色)</code></li></ul> </li></ul> 
<pre><code>void Person::fill(Mat&amp; img)
{
	imshow("原图", img);
	int top = 2; int bottom = 2; int left = 3; int right = 3;
	int margin[] = { top,bottom,left,right };
	Mat dst; Mat dst1;
	copyMakeBorder(img, dst, margin[0], margin[1], margin[2], margin[3], BORDER_CONSTANT, Scalar(0, 0, 250));
	imshow("dst", dst);
	blur(dst, dst1, Size(3, 3), Point(-1, -1), BORDER_DEFAULT);
	imshow("blur", dst1);
	cout &lt;&lt; img.rows &lt;&lt; "\t" &lt;&lt; dst.rows &lt;&lt; "\t" &lt;&lt; dst1.rows &lt;&lt; endl;
}
</code></pre> 
<h6><a id="12__525"></a>12 图像模糊</h6> 
<ol><li> <p>高斯模糊</p> 
  <ol><li> <p><strong>优点: 会更好的保留中心点像素, 对轮廓保存好</strong></p> </li><li> <p>卷积核系数不一样, 非均值, 越是中心位置权重系数越高, 中心化对称(高斯数学公式),</p> </li><li> <p>API: GuassianBlur</p> </li></ol> 
  <ul><li>设置了第三个参数, 第四个参数会自动换算, 只要当size = 0的时候才需要设置第四个参数</li><li>高斯模糊默认是中心位置所有不需要设定锚定点</li></ul> </li><li> <p>盒子模糊(均值模糊)</p> 
  <ol><li><strong>优点: 可以对图像任意一个方向模糊 (调节卷积核大小)</strong></li><li>API: boxfilter 
    <ul><li>参数3: img深度(如果-1就是与原图一致)</li><li>参数5: 锚定点,</li><li>参数6: 对卷积核归一化, 加和 = 1</li></ul> </li></ol> </li></ol> 
<pre><code>void Person::fill(Mat&amp; img)
{
	imshow("原图", img);
	int top = 2; int bottom = 2; int left = 3; int right = 3;
	int margin[] = { top,bottom,left,right };
	Mat dst; Mat dst1; Mat dst2;
	copyMakeBorder(img, dst, margin[0], margin[1], margin[2], margin[3], BORDER_CONSTANT, Scalar(0, 0, 250));
	imshow("dst", dst);
	blur(img, dst1, Size(3, 3), Point(-1, -1), BORDER_DEFAULT);
	imshow("blur", dst1);
	
	boxFilter(img, dst2, -1, Size(3, 3), Point(-1, -1), true, BORDER_DEFAULT);
	imshow("dst2", dst2);
	cout &lt;&lt; img.rows &lt;&lt; "\t" &lt;&lt; dst.rows &lt;&lt; "\t" &lt;&lt; dst1.rows &lt;&lt;"\t" &lt;&lt; dst2.rows&lt;&lt;endl;
}
</code></pre> 
<h6><a id="13__565"></a>13 自定义卷积核(自定义滤波器)</h6> 
<h6><a id="1_API_filter2D_567"></a>1. API: filter2D</h6> 
<ul><li>参数5: 用来提升亮度</li></ul> 
<h6><a id="2API_convertScaleAbsMatMat__571"></a>2.API: convertScaleAbs(Mat,Mat) :</h6> 
<p>装换为8U的, 并且所有的值为正数</p> 
<h6><a id="3__575"></a>3. 注意点:</h6> 
<ol><li> <p>均值滤波<strong>如果原图是16或者16以下的depth,kernel depth * 2</strong></p> </li><li> <p><strong>非均值滤波: 非均值卷积核depth应该设置大些, (不然数据会溢出, 有负数), 然后使用abs转换全为正数, 不然输出的全是空白图像</strong></p> </li></ol> 
<pre><code>void Person::myFilt(Mat&amp; img)
{
	imshow("input", img);
	Mat dst; Mat dst1;
	int width = 12;

	Mat kernel = Mat::ones(width, width, CV_16F) / float(width * width);
	filter2D(img, dst, -1, kernel, Point(-1, -1), 0, BORDER_DEFAULT);
	imshow("均值滤波", dst);
	cout &lt;&lt; img.rows &lt;&lt; "\t" &lt;&lt; dst.rows &lt;&lt; endl;

	Mat kernel1 = (Mat_&lt;int&gt;(2, 2) &lt;&lt; 1, 0, 0, -1);
	filter2D(img, dst1, CV_32F, kernel1, Point(-1, -1), 128, 4);
	convertScaleAbs(dst1, dst1);
	imshow("非均值滤波", dst1);
}
</code></pre> 
<h6><a id="14__602"></a>14 图像梯度(一阶导数)</h6> 
<p>robot算子: 非均值卷积, 求出x的梯度和y梯度相加</p> 
<h6><a id="1sobel__606"></a>1.sobel 算子</h6> 
<ul><li>参数4,5: 哪个方向的梯度(x,y),0为假, 1为真</li><li>参数7: 扩张的倍数</li><li>参数8: 用来提升亮度</li></ul> 
<h6><a id="2_scharr_612"></a>2. scharr算子</h6> 
<p>sobel的增强版, scharr算子的卷子核系数大</p> 
<p>三种梯度算子呈现强度: robot &lt; sobel &lt; scharr</p> 
<pre><code>imshow("原图", img);
	Mat gradX; Mat gradY;
	Mat robotX = (Mat_&lt;int&gt;(2, 2) &lt;&lt; 1, 0, 0, -1);
	Mat robotY = (Mat_&lt;int&gt;(2, 2) &lt;&lt; 0, 1, -1, 0) ;
	filter2D(img, gradX, CV_32F, robotX, Point(-1, -1), 0, 4);
	filter2D(img, gradY, CV_32F, robotY);
	convertScaleAbs(gradX, gradX);
	convertScaleAbs(gradY, gradY);
	Mat dst;
	add(gradX, gradY, dst);
	imshow("robot梯度", dst);

	/*Mat sobelx = (Mat_&lt;int&gt;(3,3)&lt;&lt;-1,0,1,
									-2,0,2,
									-1,0,1);
	
	Mat sobelY = (Mat_&lt;int&gt;(3, 3)  -1, -2, -1,
								   0, 0, 0,
								   1, 2, 1);

	Mat gradSobelX; Mat gradSobelY;
	filter2D(img, gradSobelX, CV_32F, sobelx, Point(-1, -1));
	filter2D(img, gradSobelY, CV_32F, sobelY, Point(-1, -1));
	convertScaleAbs(gradSobelX, gradSobelX);
	convertScaleAbs(gradSobelY, gradSobelY);
	Mat dst1; Mat result;
	add(gradSobelX, gradSobelY, dst1);*/

	Mat dst1;
	Sobel(img, gradX, CV_32F, 1, 0, 3, 1, 0, BORDER_DEFAULT);
	Sobel(img, gradY, CV_32F, 1, 0, 3, 1, 0, BORDER_DEFAULT);
	convertScaleAbs(gradX, gradX);
	convertScaleAbs(gradY, gradY);
	//因为sobel卷积核其中有些系数为2, 通过abs转化会放大梯度
	addWeighted(gradX, 0.5, gradY, 0.5, 0, dst1); //不然图片会偏白, 
	imshow("sobel", dst1);

	Mat dst2;
	Scharr(img, gradX, CV_32F, 1, 0, 1, 0);
	Scharr(img, gradY, CV_32F, 0, 1, 1, 0, 4);
	convertScaleAbs(gradX, gradX);
	convertScaleAbs(gradY, gradY);
	addWeighted(gradX, 0.5, gradY, 0.5, 0, dst2); 

	imshow("scharr", dst2);
</code></pre> 
<h6><a id="15__670"></a>15 图像边缘发现(二阶导数)</h6> 
<p>四邻域, 八邻域, 拉普拉斯变种</p> 
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-UKNPniCL-1656318416405)(D:\opencvSourse\openImg\拉普拉斯分类.png)]</p> 
<p>推导公式:</p> 
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-PWX2C5wE-1656318416406)(D:\opencvSourse\openImg\图像锐化原理.png)]</p> 
<p><strong>图像锐化: 原图 + 拉普拉斯得出来的结果(图像的边缘跟梯度比较尖锐的值加到原图上), 可以很好的反映图像的边缘, 也可以反模糊</strong></p> 
<p><strong>拉普拉斯的卷积核必须是奇数</strong></p> 
<p><strong>缺点: 很容易受噪声干扰(对小的细节造成干扰)</strong></p> 
<p>拉普拉斯api得出来的是边缘</p> 
<pre><code>void Person::laplasi(Mat&amp; img)
{
	cout &lt;&lt; img.channels() &lt;&lt; endl;
	imshow("原图", img);
	Mat Box = (Mat_&lt;int&gt;(3, 3) &lt;&lt; 0, -1, 0,
							    -1, 5, -1,
							    0, -1, 0);
	Mat dst;
	filter2D(img, dst, CV_32F, Box,Point(-1,-1),0,4);
	convertScaleAbs(dst, dst);
	imshow("拉普拉斯", dst);

	Mat dst1; Mat dst2;
	Laplacian(img, dst1, -1);
	add(img, dst1, dst2);
	imshow("锐化", dst1);
}
</code></pre> 
<h6><a id="16_usm_710"></a>16 usm锐化</h6> 
<p>原理: blur/高斯 - 拉普拉斯算子</p> 
<p><strong>相对于拉普拉斯, 他会处理掉极小值(对小的细节不造成干扰), 不容易受噪声干扰</strong>, <strong>对大的细节进行锐化</strong></p> 
<pre><code>imshow("原图", img);
	Mat gua; Mat lap;
	GaussianBlur(img, gua, Size(3,3),0);
	Laplacian(img, lap, -1, 3, 1, 0);
	Mat result;
	addWeighted(gua, 1, lap, -0.7, 0, result);
	imshow("usm", result);
</code></pre> 
<h6><a id="17__728"></a>17 图像的噪声和去噪</h6> 
<ol><li> <p>API:</p> 
  <ul><li>randn 产生噪声 
    <ul><li>参数1: 输入图像</li><li>均值</li><li>方差</li></ul> </li></ul> </li><li> <p>去噪:</p> 
  <ol><li> <p>中值滤波: 能反映信号理想的样子, 去除极致点,</p> 
    <ol><li> <p>原理: 对图像某一块区域进行排序, 取出sort中间的值替换这块局域的中心点</p> <p>还有最小值滤波(sort[0]替换中心点), 最大值滤波(sort[lenght-1]替换中心点)</p> </li><li> <p>作用: 最适用于椒盐噪声非0就255</p> </li><li> <p><strong>重要: 卷积核必须是奇数而且是大于1</strong></p> </li></ol> </li><li> <p>均值滤波: 没有反映信号本来的样子, 会扰动</p> </li><li> <p>API:</p> 
    <ul><li> <p>medianBlur: 均值滤波</p> <p>没有考虑中心像素的权重, 可能会导致图片破坏</p> </li><li> <p>GaussianBlur 高斯滤波 没有考虑中心像素点与周围像素点差值很大</p> </li></ul> </li></ol> </li></ol> 
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-DqhqGCcS-1656318416407)(D:\opencvSourse\openImg\均值滤波和中值滤波.png)]</p> 
<h6><a id="18_EPF_763"></a>18 边缘保留滤波(EPF)</h6> 
<p>考虑图像的梯度(边缘):高斯双边, 均值前移, 非局部均值去噪, 局部均值方差</p> 
<h6><a id="1_EPF_767"></a>1. EPF概念</h6> 
<ol><li> <p>高斯双边模糊</p> 
  <ol><li>原理: 当差异比较大的时候(边缘),权重会趋向于0(有边缘的时候不进行模糊)</li><li>API: bilaterFilter 
    <ul><li>参数3: 过滤过程中每个像素领域的直径范围, 如果这个值是非正数, 则函数会从第五个参数sigmaSpace计算该值</li><li>参数4: 颜色过滤器, 这个参数越大, 表明该像素领域内有越宽广的颜色会混合到一起, 产生较大的半相等颜色区域(<strong>理解为中心像素权重, 越大中心像素权重越高, 细微的部分会丢失</strong>),</li><li>参数5: 空间滤波器, 如果该值较大, 则意味着越远的像素将相互影响, 从而使更大的区域中足够相似的颜色获取相同颜色(<strong>理解为,sigmaS越大,去噪越明显, 一般为Half_size为4，可以选用2sigma原则，设置为2</strong>,)</li></ul> </li></ol> </li><li> <p>非局部均值滤波</p> 
  <ol><li> <p>简单理解原理: 相似像素块, 权重比较大, 不相似的权重比较小</p> </li><li> <p>API</p> 
    <ul><li>fastNIMeansDenoising 速度慢 
      <ol><li>参数三: h 决定过滤器强度。h 值高可以很好的去除噪声,但也会把图像的细节抹去。(取 10 的效果不错）</li><li>参数五: 在划分区域的卷积核</li><li>参数六: 搜索窗口(划分区域)</li></ol> </li><li>fastNIMeansDenoisingColord 彩色版本</li></ul> </li></ol> </li></ol> 
<pre><code>void Person::noise(Mat&amp; img)
{
	Mat result1; Mat result2;
	Mat dst = img.clone();
	imshow("原图", img);
	//salt and pepper
	RNG r(12345);
	int ipt = 1000;
	for (int i = 0; i &lt; ipt; i++)
	{
		int xNum = r.uniform(0, img.cols);
		int yNum = r.uniform(0, img.rows);
		if (i % 2 == 1)
		{
			
			img.at&lt;Vec3b&gt;(xNum, yNum) = Vec3b(255, 255, 255);
		}
		else
		{
			img.at&lt;Vec3b&gt;(xNum, yNum) = Vec3b(0, 0, 0);
		}
	}
	imshow("椒盐噪声", img);
	medianBlur(img, result1, 3);
	imshow("椒盐去噪", result1);
	GaussianBlur(img, result2, Size(3, 3), 0);
	imshow("高斯去噪", result2);


	//高斯噪声
	Mat res1; Mat res2;
	Mat src = Mat::zeros(img.size(), img.type());
	randn(src, Scalar(25,15,45), Scalar(60,40,30));
	add(dst, src, dst);
	imshow("高斯", dst);
	bilateralFilter(dst, res1, 0, 100, 10);
	imshow("双边模糊", res1);
	fastNlMeansDenoisingColored(dst, res2, 3, 3, 7, 21);
	imshow("非局部去噪",res2);

}
</code></pre> 
<h6><a id="18_833"></a>18边缘提取</h6> 
<h6><a id="1__835"></a>1. 基本概念</h6> 
<ul><li>边缘法线: 与边缘垂直的线, 在图像像素强度变化最大</li><li>边缘强度</li></ul> 
<h6><a id="2__840"></a>2. 边缘类型</h6> 
<p>​ 实际图像可能不平整有噪声</p> 
<ol><li>跃迁类型: 只有陡坡或者下坡</li><li>屋脊类型: 有上坡和下坡</li></ol> 
<h6><a id="3__847"></a>3. 基于梯度的边缘提取</h6> 
<p>步骤:</p> 
<ol><li>去噪(卷积核不能太大, 不然会破坏掉边缘, 一般使用3或者5),</li><li>基于梯度提取边缘: robot, sobel, prewit Operator</li></ol> 
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-WSFkBplS-1656318416407)(D:\opencvSourse\openImg\梯度提取边缘算子.png)]</p> 
<ol start="3"><li> <p>基于阈值T,得到边缘(梯度&gt;T保留, &lt;丢弃)</p> <p><strong>问题: 基于T的会不够连贯</strong></p> </li></ol> 
<h6><a id="API_canny___860"></a>API: canny 输出是一个二值图像</h6> 
<p>非最大抑制: 求出角度, 如果中心像素大于2侧梯度值则保留, 否则丢弃, 然后进行阈值连接</p> 
<p>阈值连接: T1 / T2 = 2 ≈ 2~3, 大于T1全部保留, 小于T2全部丢弃, t1至T2之间的如果可以连接则保留, 否则丢弃</p> 
<p>参数:</p> 
<ol><li>参数5: suobel算子大小</li><li>参数6: 为计算图像梯度幅度（gradient magnitude）的标识。其默认值为 False。如果为 True，则使用更精确的 L2 范数进行计算（即两个方向的导数的平方和再开方），否则使用 L1 范数（直接将两个方向导数的绝对值相加）。</li><li>参数3,4: 高低阈值的比值应该是2~3</li></ol> 
<pre><code>void myCanny(int min, void* img)
{
	Mat newImg = *(Mat*)img;
	Mat dst; Mat dst1;
	Canny(newImg, dst, min, 200, 3, false);
	bitwise_and(newImg, newImg, dst1, dst);
	imshow("边缘提取", dst1);
}
void Person::canny(Mat&amp; img)
{
	string barName = "提取范围";
	string winName = "边缘提取";
	namedWindow(winName, WINDOW_AUTOSIZE);
	imshow("原图", img);
	int min = 50;
	int max = 120;
	createTrackbar(barName, winName, &amp;min, max, myCanny,(void*)&amp;img);
	myCanny(0, (void*)&amp;img);
}
</code></pre> 
<h6><a id="19____sicBolb_896"></a>19 二值图像概念 sic(Bolb分析)</h6> 
<p><strong>必须是灰色图像</strong></p> 
<p>对机器视觉或者工业领域</p> 
<p>灰度图像 : 单通道, 取值范围0~255</p> 
<p>二值图像: 单通道, 要么是0要么是255, 以黑色作为背景</p> 
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-IfSlKbwl-1656318416408)(D:\opencvSourse\openImg\二值分割5钟方法.png)]</p> 
<p>二值化</p> 
<ul><li>THRESH_BINARY</li><li>THRESH_BINARY_INV</li></ul> 
<p>阈值化</p> 
<ul><li>THRESH_TRUNC: 截断, 对应第三种方式</li><li>THRESH_TOZEREO:</li><li>thresh_TOZERO_INV</li></ul> 
<p>API:</p> 
<p>threshold: 只接受灰色图像</p> 
<pre><code>void Person::myThreshold(Mat&amp; img)
{
	Mat dst;
	cvtColor(img, img, COLOR_BGR2GRAY);
	imshow("原图灰色图像", img);
	//二值化
	threshold(img, dst, 127, 255, THRESH_BINARY);
	imshow("二值化", dst);
	//反二值化
	threshold(img, dst, 127, 255, THRESH_BINARY_INV);
	imshow("反二值化", dst);
	//阈值化切割, 小于阈值化保持原数据, 否则为T
	threshold(img, dst, 127, 255, THRESH_TRUNC);
	imshow("阈值化切割", dst);
	//阈值化,大于T的保持原数据, 其他的为0
	threshold(img, dst, 127, 255, THRESH_TOZERO);
	imshow("阈值化", dst);
	//反阈值化, 
	threshold(img, dst, 127, 255, THRESH_TOZERO_INV);
	imshow("反阈值化", dst);
}
//返回二值化分割
Mat Person::myThresh(const Mat&amp; img)
{
	Mat newImg = img.clone();
	GaussianBlur(newImg, newImg, Size(3, 3), 0);
	cvtColor(newImg, newImg, COLOR_BGR2GRAY);
	Mat dst;
	threshold(newImg, dst, 0, 255, THRESH_BINARY | THRESH_OTSU);
	return dst;
}
</code></pre> 
<h6><a id="191__961"></a>19.1 全局阈值</h6> 
<p>​ 概述: <strong>全局阈值, 自适应阈值, 缺点: 不适用与光线不均匀的情况</strong></p> 
<ol><li> <p>通过mean, 取0号下标得均值,这个均值设为T</p> 
  <ol><li>缺点: 不能反应图像像素分布情况</li></ol> </li><li> <p>OTSU</p> 
  <ol><li>api: THRESH_OTSU, 返回值是一个double类型</li><li>计算类内方差: 比重 * 方差 + 比重1*方差1, 取切割后,类内方差最小的阈值T</li></ol> <p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-kr1Qrs0g-1656318416409)(D:\opencvSourse\openImg\OTSU解释.png)]</p> </li><li> <p>三角法</p> 
  <ol><li>api: thresh_triangle</li><li><strong>缺点: 只对单峰比较友好,适合医学领域:x光片, 生物图像.</strong></li></ol> <pre><code>void Person::tThreshold(Mat&amp; img)
{
	Mat dst;
	cvtColor(img, img, COLOR_BGR2GRAY);
	imshow("原图", img);
	Scalar m = mean(img);
	threshold(img, dst, m[0], 255, THRESH_BINARY);
	imshow("均值", dst);
	//otsu
	double otsu = threshold(img, dst, 0, 255, THRESH_BINARY | THRESH_OTSU);
	imshow("otsu", dst);
	//三角法
	double angle = threshold(img, dst, 0, 255, THRESH_BINARY | THRESH_TRIANGLE);
	imshow("三角法", dst);
	cout &lt;&lt; "otsu切割阈值T: " &lt;&lt; otsu &lt;&lt; "\t" &lt;&lt; "三角法: " &lt;&lt; angle &lt;&lt; endl
		&lt;&lt;"\t" &lt;&lt; "均值:"&lt;&lt;m[0];
}
</code></pre> </li><li> <p>自适应阈值</p> </li></ol> 
<p>​ 概述: 全局阈值的局限性: <strong>对光线照度不均匀的图像容易错误的二值化分割,</strong> <strong>自适应阈值对图像模糊求差然后二值化</strong>,叫做自适应的高斯分割或者是自适应均值分割, <strong>相比于自适应阈值, 会更好的保留细节</strong></p> 
<p>相对于全局自适应, 会提取更多的梯度</p> 
<p>原图-模糊后的图+偏执常量 &gt; 0 = 255, 否则=0</p> 
<ol><li>API: adaptiveThreshold, 卷积核必须为奇数(倒数第二个) 
  <ul><li>ADAPTIVE_THRESH_MEAN_C 盒子模糊</li><li>ADAPTIVE_THRESH_GAUSSIAN_C 高斯模糊</li></ul> </li></ol> 
<pre><code>//自适应阈值分割
void Person::myAdaptive(Mat &amp;img)
{
	Mat dst;
	cvtColor(img, img, COLOR_BGR2GRAY);
	imshow("原图", img);
	threshold(img, dst, 0, 255, THRESH_BINARY | THRESH_OTSU);
	imshow("otsu", dst);
	//自适应
	adaptiveThreshold(img, dst, 255, ADAPTIVE_THRESH_GAUSSIAN_C, THRESH_BINARY, 21, 5);
	imshow("自适应", dst);
}
</code></pre> 
<h6><a id="20_ccl8_1032"></a>20 ccl连通组件扫描(默认值是8领域)</h6> 
<p>如果是白色对象 将过滤点不会进行处理, 只有为黑色的时候才会考虑连通性</p> 
<p>opencv是基于块扫描结合决策表(DT) ==&gt; BBDT</p> 
<ol><li> <p>概念: 联通组件标记: CCL</p> </li><li> <p>算法:</p> 
  <ul><li> <p>基于像素的扫描的方法</p> <p>缺点: 有大量重复的扫描, 而且不规则扫描</p> </li><li> <p>基于块扫描的方法</p> </li><li> <p>两步法扫描</p> <p>概率: 对前景像素点产生一个临时标记, 通过连通性进行等价队列合并, 然后获取lable</p> <p>决策表:DT</p> </li><li> <p>现在opencv联通组件采用的是BBDT: 块扫描+决策表</p> </li></ul> </li><li> <p>api: connectedComponents, <strong>背景必须为黑色, 只能知道有多少个联通组件</strong></p> 
  <ol><li><strong>输出图片类型为cv_32s</strong>. 数量包括背景, 真实数量=result - 1, 组件第一个是背景</li><li>参数: 
    <ul><li>参数3: 选择几领域(8领域或者4领域)</li><li>参数4: 输出类型, 默认是cv_32s</li></ul> </li><li>返回值是组件个数+ 1个背景</li></ol> <p>api:connectedComponentsWithStats</p> 
  <ol><li>携带附加信息(像素值,外接矩形大小,中心位置)</li><li>第三个mat对象:外接矩形,矩形面积 
    <ol><li>stats: <strong>前四个值是连通组件外接矩形的信息(前2个是初始点, 后2个是宽高), 最后一个值是统计出来的这个前景对象的面积(像素面积)</strong></li></ol> </li><li>第四个mat对象:组件的中心坐标</li></ol> <p>一般先进行高斯模糊降噪</p> <pre><code>void Person::connectComp(Mat&amp; img)
{
	RNG rn(12345);
	imshow("原图", img);
	Mat denoi;
	GaussianBlur(img, denoi, Size(11, 11), 0);
	imshow("去噪", denoi);
	Mat grey;
	cvtColor(denoi, grey, COLOR_BGR2GRAY);
	Mat cutting;
	threshold(grey, cutting, 0, 255, THRESH_BINARY | THRESH_OTSU);
	imshow("二值化", cutting);
	Mat labels = Mat::zeros(img.size(), CV_32S);
	int num = connectedComponents(cutting, labels, 8, CV_32S, CCL_DEFAULT);
	cout &lt;&lt; "数量" &lt;&lt; num &lt;&lt; endl;
	//染色
	vector&lt;Vec3b&gt;color(num);
	color[0] = Vec3b(0, 0, 0);
	for (int index = 1; index &lt; num; index++)
	{
		color[index] = Vec3b(rn.uniform(0, 256), rn.uniform(0, 256), rn.uniform(0, 256));
	}
	Mat result = Mat::zeros(img.size(), CV_8UC3);
	for (int x = 0; x &lt; result.rows; x++)
	{
		for (int y = 0; y &lt; result.cols; y++)
		{
			result.at&lt;Vec3b&gt;(x, y) = color[labels.at&lt;int&gt;(x, y)];
		}
	}
	//显示详细信息
	Mat stats; Mat centroids;
	int num1 = connectedComponentsWithStats(cutting, labels, stats, centroids, 8, CV_32S, CCL_DEFAULT);
	string numn = to_string(num1);
	for (int i = 1; i &lt; num1; i++)
	{
		//center
		double centerX = centroids.at&lt;double&gt;(i, 0);
		double centerY = centroids.at&lt;double&gt;(i, 1);
		//ractangle
		int racLeft = stats.at&lt;int&gt;(i, CC_STAT_LEFT);
		int racTop = stats.at&lt;int&gt;(i, CC_STAT_TOP);
		int racWidth = stats.at&lt;int&gt;(i, CC_STAT_WIDTH);
		int racHeight = stats.at&lt;int&gt;(i, CC_STAT_HEIGHT);
		int area = stats.at&lt;int&gt;(i, CC_STAT_AREA);
		cout &lt;&lt; "面积" &lt;&lt; i &lt;&lt; area &lt;&lt; endl;
		string s =  to_string(area);
		circle(result, Point(centerX, centerY), 3, Scalar(255, 20, 20), 2, 8);
		Rect rect = Rect(racLeft, racTop, racWidth, racHeight);
		rectangle(result, rect, Scalar(0, 0, 200), 2, LINE_8);
		putText(result, s, Point(centerX, centerY), FONT_HERSHEY_PLAIN, 1.0, Scalar(0, 255, 0), 2, 8);
		putText(result, numn, Point(50,50), FONT_HERSHEY_PLAIN, 3, Scalar(0, 255, 0), 2, 8);
	}
	imshow("切割染色", result);
}
</code></pre> </li></ol> 
<h6><a id="201__1135"></a>20.1 图像轮廓发现</h6> 
<h6><a id="1__1137"></a>1. 轮廓发现(二值化的前景边缘)</h6> 
<ol><li> <p>基本概率: 理解为图像边界, 主要针对二值图像, 轮廓是一系列点的集合</p> <p>基于联通组件, 反映图像拓扑结构</p> </li><li> <p>算法:</p> <p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-FeJh7Je9-1656318416410)(D:\opencvSourse\openImg\轮廓发现.png)]</p> </li><li> <p>API:</p> 
  <ul><li> <p>findContours</p> <p>轮廓: 是点的集合<code>vector&lt;vector&lt;point&gt;&gt;P</code> 多个组件, 组件里面是像素</p> <p>层次: vec4i</p> <p>拓扑结构: list或者tree或者最外层最大的轮廓(external) retr</p> <p>编码方式:</p> 
    <ul><li> <p>chain_approx_simple</p> <p>hirearchy里面只存储: 4个顶点位置</p> </li><li> <p>chain_approx_none</p> <p>hirearchy里面存储所有轮廓的点位</p> </li></ul> </li><li> <p>drawContours</p> <p>contourldx: 绘制的是哪一个轮廓,如果是-1就是绘制全部</p> </li></ul> <pre><code>void Person::myContour(Mat&amp; img)
{
	//binaryimg是一个处理过的二值化图像
	Mat binaryImg = this-&gt;myThresh(img).clone();
	Mat dst = Mat::zeros(img.size(),CV_8UC3);
	Mat dst1 = dst.clone();
	Mat dst2 = dst.clone();
	imshow("二值化", binaryImg);
	vector&lt;vector&lt;Point&gt;&gt;contours;
	vector&lt;Vec4i&gt;hierarchy;
	findContours(binaryImg, contours, hierarchy, RETR_TREE, CHAIN_APPROX_SIMPLE, Point());
	for (int i = 0; i &lt; contours.size(); i++)
	{
		drawContours(dst, contours, i, Scalar(0, 255, 0), 2, LINE_8);
	}
	imshow("轮廓", dst);
	findContours(binaryImg, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
	drawContours(dst1, contours, -1, Scalar(255, 0, 0), 2, 8);
	imshow("最大轮廓", dst1);
}
</code></pre> </li></ol> 
<h6><a id="202__1196"></a>20.2 轮廓计算</h6> 
<ol><li>计算公式:</li></ol> 
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-yC6XUZCC-1656318416411)(D:\opencvSourse\openImg\轮廓面积和周长计算.png)]</p> 
<ol start="2"><li> <p>contourArea: 轮廓面积 contourArea[contour1]</p> <p>arcLength: 轮廓周长(contour1, 是否闭合)</p> <p>boundingRect: 最大外接矩形</p> <p>nimAreaRect: 最小矩形 , 数据类型是RotatedRect</p> <pre><code class="prism language-c++">//轮廓细节
void Person::contourDetails(Mat&amp; img)
{
	Mat result = Mat::zeros(img.size(), CV_8UC3);
	imshow("原图", img);
	GaussianBlur(img, img, Size(3, 3), 0);
	cvtColor(img, img, COLOR_BGR2GRAY);
	Mat dst;
	threshold(img, dst, 0, 255, THRESH_BINARY_INV | THRESH_OTSU);
	imshow("二值化分割", dst);
	vector&lt;vector&lt;Point&gt;&gt;contours;
	vector&lt;Vec4i&gt;hierarchy;
	//Mat result = Mat::zeros(img.size(), CV_8UC3);
	findContours(dst, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
	/*double minLength;
	cout &lt;&lt; "输入最小周长" &lt;&lt; endl;
	cin &gt;&gt; minLength;
	double minArea;
	cout &lt;&lt; "输入最小面积" &lt;&lt; endl;
	cin &gt;&gt; minArea;*/
	for (int i = 0; i &lt; contours.size(); i++)
	{
		if (arcLength(contours[i],true) &lt; 100 || contourArea(contours[i]) &lt; 10) continue;
		//最大外接矩形
		Rect maxRect = boundingRect(contours[i]);
		rectangle(result, maxRect, Scalar(200, 20, 20), 2, 8);
		//最小外接矩形
		RotatedRect minRect = minAreaRect(contours[i]);
		ellipse(result, minRect, Scalar(20, 200, 20), 2, 8);
		Point2f pts[4];
		//通过点连接成线绘制最小外接矩形
		minRect.points(pts);
		for (int i = 0; i &lt; 4; i++)
		{
			line(result, pts[i], pts[(i + 1)%4], Scalar(20, 20, 200), 2, 8);
		}
		drawContours(result, contours, -1, Scalar(100, 100, 100), 2, 8);
		cout &lt;&lt; "轮廓" &lt;&lt; i &lt;&lt; "面积: " &lt;&lt; contourArea(contours[i]) &lt;&lt; "\t" &lt;&lt; "轮廓" &lt;&lt; i &lt;&lt; "周长: " &lt;&lt; arcLength(contours[i], true) &lt;&lt; endl;
	}
	imshow("输出", result);
}
</code></pre> </li></ol> 
<h6><a id="203__1256"></a>20.3 轮廓匹配</h6> 
<p>作用: 可以匹配大小不一致, 旋转不一致的图像</p> 
<p>API</p> 
<ul><li> <p>Moments : 几何矩 Moments(contours[i])</p> <p>作用: 计算弧矩, 计算中心位置</p> <p>根据原理推中心矩: mm.m10 / mm.00 = x || mm.m01 / mm.00 = y</p> </li><li> <p>HuMoments: 弧矩(Moments, mat对象) : 选择不变性, 缩放不变性</p> </li><li> <p>matchShapes: 比较弧矩 参数3:contours_match_l1/l2/l3, 第一种比较效果比较好</p> </li></ul> 
<pre><code>void contoursFn( Mat &amp;dst, const vector&lt;vector&lt;Point&gt;&gt; &amp;imgContours, const vector&lt;vector&lt;Point&gt;&gt;&amp; srcContours)
{
	Moments srcMm = moments(srcContours[0]);
	Mat srcHu;
	HuMoments(srcMm, srcHu);
	for (int i = 0; i &lt; imgContours.size(); i++)
	{
		Mat imgHu;
		Moments imgMm = moments(imgContours[i]);
		double pX = imgMm.m10 / imgMm.m00;
		double pY = imgMm.m01 / imgMm.m00;
		circle(dst, Point(pX, pY), 3, Scalar(200, 200, 20), 2, LINE_8);
		HuMoments(imgMm, imgHu);
		double ss = matchShapes(imgHu, srcHu, CONTOURS_MATCH_I1,0);
		//cout &lt;&lt; ss &lt;&lt; endl;
		if (ss &lt; 2.0)
		{
			cout &lt;&lt; ss &lt;&lt; endl;
			drawContours(dst, imgContours, i, Scalar(20, 20, 200), 2, 8);
		}
		else
		{
			cout &lt;&lt; "匹配不成功" &lt;&lt; endl;
		}
	}
	imshow("axx", dst);
	/*for (int i = 0; i &lt; srcContours.size(); i++)
	{
		moImg.push_back(moments(srcContours[i]));
	}*/
	
}
void Person::contourComp(Mat&amp; img, Mat&amp; src)
{
	namedWindow("匹配轮廓图", WINDOW_FREERATIO);
	imshow("匹配轮廓图", src);
	Mat binaryImg = this-&gt;myThresh(img);
	Mat binarysrc = this-&gt;myThresh(src);
	vector&lt;vector&lt;Point&gt;&gt; imgContours;
	vector&lt;vector&lt;Point&gt;&gt; srcContours;
	vector&lt;Vec4i&gt; hierarchy;
	vector&lt;Vec4i&gt; hierarchy1;
	findContours(binaryImg, imgContours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
	findContours(binarysrc, srcContours, hierarchy1, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
	contoursFn(img, imgContours, srcContours);
}
</code></pre> 
<h6><a id="204__1323"></a>20.4 轮廓逼近与拟合</h6> 
<ol><li> <p>轮廓拟合和逼近(进行轮廓发现之后通过api越来越接近真实的情况)</p> 
  <ol><li> <p>概念:</p> 
    <ul><li> <p>轮廓逼近, 本质是减少编码点, 轮廓逼近的越厉害, 编码点增多</p> </li><li> <p>拟合圆, 生成最相似的圆或者椭圆</p> </li></ul> </li><li> <p>API:</p> 
    <ol><li> <p>approxPolyDP: 轮廓逼近, 一般用来区分图形</p> <p>参数:</p> 
      <ul><li> <p>参数1: contours[i]</p> </li><li> <p>参数2: mat对象 里面有存放每个点,</p> </li><li> <p>参数3: 精度,值越低精度越高(编码点越多)(一般为4)</p> </li><li> <p>参数4:是否为闭合区</p> </li></ul> </li></ol> </li><li> <p>fitEllipse</p> 
    <ol><li>图像拟合, 返回值是一个rotateRact,</li><li>通过rotateRact.size.width/height获取拟合之后的长宽</li><li>通过rotateRact.center, 获取拟合之后的中心点</li></ol> </li></ol> </li></ol> 
<pre><code>void Person::contourProx(Mat&amp; img)
{
	imshow("原图", img);
	Mat binaryImg = this-&gt;myThresh(img);
	vector&lt;vector&lt;Point&gt;&gt; contours;
	vector&lt;Vec4i&gt; hierarchy;
	findContours(binaryImg, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
	for (int i = 0; i &lt; contours.size(); i++)
	{
		Mat poly;
		approxPolyDP(contours[i], poly, 4, true);
		cout &lt;&lt; "图形:" &lt;&lt; i &lt;&lt; "行数 " &lt;&lt; poly.rows &lt;&lt; "列数: " &lt;&lt; poly.cols &lt;&lt; endl;
		double len = arcLength(contours[i], true);
		double Area = contourArea(contours[i]);
		Moments mm = moments(contours[i]);
		double pX = mm.m10 / mm.m00;
		double pY = mm.m01 / mm.m00;
		//if (poly.rows = 4)
		//{
		//	putText(img, "矩形", Point(pX, pY - 10), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);
		//	string Sarea = "面积: " + to_string(Area);
		//	string Slen = "周长: " + to_string(len);
		//	/*putText(img, Sarea, Point(pX, pY - 10), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);
		//	putText(img, Slen, Point(pX, pY - 20), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);*/
		//	circle(img, Point(pX, pY), 4, Scalar(20, 20, 200), 2, LINE_8);
		//}
		//if (poly.rows = 3)
		//{
		//	putText(img, "三角形", Point(pX, pY - 10), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);
		//	string Sarea = "面积: " + to_string(Area);
		//	string Slen = "周长: " + to_string(len);
		//	/*putText(img, Sarea, Point(pX, pY - 10), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);
		//	putText(img, Slen, Point(pX, pY - 20), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);*/
		//	circle(img, Point(pX, pY), 4, Scalar(20, 20, 200), 2, LINE_8);
		//}
		//if (poly.rows = 6)
		//{
		//	putText(img, "6边形", Point(pX, pY - 10), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);
		//	string Sarea = "面积: " + to_string(Area);
		//	string Slen = "周长: " + to_string(len);
		///*	putText(img, Sarea, Point(pX, pY - 10), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);
		//	putText(img, Slen, Point(pX, pY - 20), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);*/
		//	circle(img, Point(pX, pY), 4, Scalar(20, 20, 200), 2, LINE_8);
		//}
		//if (poly.rows &gt; 12)
		//{
		//	putText(img, "圆", Point(pX, pY - 10), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);
		//	string Sarea = "面积: " + to_string(Area);
		//	string Slen = "周长: " + to_string(len);
		///*	putText(img, Sarea, Point(pX, pY - 10), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);
		//	putText(img, Slen, Point(pX, pY - 20), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);*/
		//	circle(img, Point(pX, pY), 4, Scalar(20, 20, 200), 2, LINE_8);
		//}
		putText(img, "我", Point(pX, pY - 20), FONT_HERSHEY_PLAIN, 1, Scalar(20, 200, 20), 2, 8);
	}
	imshow("判断轮廓图像", img);
}
</code></pre> 
<p>图像拟合</p> 
<pre><code>//返回二值化轮廓
vector&lt;vector&lt;Point&gt;&gt; Person::contourOne(Mat&amp; img)
{
	Mat binary = this-&gt;myBinary(img);
	vector&lt;vector&lt;Point&gt;&gt; contours;
	vector&lt;Vec4i&gt; hierarchy;
	findContours(binary, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point());
	return contours;
}

//拟合
void Person::myFitEllipse(Mat&amp; img)
{
	imshow("原图", img);
	vector&lt;vector&lt;Point&gt;&gt; contours = this-&gt;contourOne(img);
	for (int i = 0; i &lt; contours.size(); i++)
	{
		 RotatedRect rotRect = fitEllipse(contours[i]);
		 Point center = rotRect.center;
		 string height = to_string(rotRect.size.height);
		 string width = to_string(rotRect.size.width);
		 string are = to_string(rotRect.size.area());
		 ellipse(img, rotRect, Scalar(255, 0, 10), 2, 8);
		 circle(img, center, 3, Scalar(0, 255, 0), 2, LINE_8);
	}
	imshow("处理图", img);
	
}
</code></pre> 
<h6><a id="21__1448"></a>21 霍夫直线检测</h6> 
<p>对噪声很敏感, 需要降噪</p> 
<p>r = x<sub>0</sub>*cosθ + y<sub>0</sub> * sinθ ==&gt;如果点坐标在同一条直线: r和θ是相同的</p> 
<ol><li> <p>API:</p> 
  <ol><li> <p>HoughLines : 得出来的是极坐标空间参数 vector(p,θ) 直线</p> <p>霍夫直线检测出的来的结果是vec3F, 距离,角度,累加</p> <p>参数:</p> 
    <ol><li> <p>参数2: 输出 <code>vector&lt;vec3f&gt;</code>, 这个vec3f</p> <p>下标0: 代表R(距离)</p> <p>下标1: 代表θ</p> <p>下标2: 代表累加值</p> </li><li> <p>参数3: 步长</p> </li><li> <p>参数4: 角度: cv_pi / xx</p> </li><li> <p>参数5: 阈值, 有多少个点集中在一起 算直线</p> </li></ol> 
    <hr> <pre><code>//InputArray image：输入图像，必须是8位单通道图像。 
　　//OutputArray lines：检测到的线条参数集合。 
　　//double rho：	累加器的距离
　　//double theta：累加器的角度。 
　　//int threshold：累加计数值的阈值参数，当参数空间某个交点的累加计数的值超过该阈值，则认为该交点对应了图像空间的一条直线。 
　　//double srn：默认值为0，用于在多尺度霍夫变换中作为参数rho的除数，rho=rho/srn。 
　　//double stn：默认值为0，用于在多尺度霍夫变换中作为参数theta的除数，theta=theta/stn。
　　//如果srn和stn同时为0，就表示HoughLines函数执行标准霍夫变换，否则就是执行多尺度霍夫变换
</code></pre> <p>代码:</p> <pre><code>void Person::Houline(Mat&amp; img)
{
	imshow("原图", img);
	Mat binary = this-&gt;myBinary(img);
	vector&lt;Vec3f&gt;lines;
	HoughLines(binary, lines, 1, CV_PI / 180, 160, 0, 0);
	Point p1; Point p2;
	for (int i = 0; i &lt; lines.size(); i++)
	{
		double step = lines[i][0];
		double angle = lines[i][1];
		double add = lines[i][2];
		cout &lt;&lt; "直线" &lt;&lt; i &lt;&lt; "\t" &lt;&lt; "距离: " &lt;&lt; step &lt;&lt; "角度: " &lt;&lt; angle &lt;&lt; i &lt;&lt; "累加点: " &lt;&lt; add &lt;&lt; endl;
		double x = cos(angle);
		double y = sin(angle);
		double x0 = step * x;
		double y0 = step * y;
		p1.x = cvRound(x0 + 1000 * -y);
		p1.y = cvRound(y0 + 1000 * x);
		p2.x = cvRound(x0 - 1000 * -y);
		p2.y = cvRound(y0 - 1000 * x);
		line(img, p1, p2, Scalar(0, 0, 255), 2, 8);
	}
	imshow("霍夫直线", img);
}
</code></pre> </li><li> <p>HoughLinesP() 线段</p> <p>参数2: 为2个点的坐标的容器: <code>vector&lt;Vec4i&gt;</code></p> <p>参数3, 4 步长, 角度</p> <p>参数5: 阈值, 有这么多点以上连接的线段</p> <p>参数6: 检测出的最小长度(minLineLength)</p> <p>参数7: 线段之间的间隔, 如果超出则为新的线段</p> </li></ol> <pre><code>void Person::houlineP(Mat&amp; img)
{
	Mat result = Mat::zeros(img.size(), img.type());
	imshow("原图", img);
	Mat binary = this-&gt;myBinary(img); //之前有封装一个返回二值化的函数的对象
	vector&lt;Vec4i&gt; lines;
	imshow("binary",binary);
	HoughLinesP(binary, lines, 1, CV_PI / 180, 80,30,10);
	//Point p1; Point p2;
	for (int i = 0; i &lt; lines.size(); i++)
	{
		/*p1.x = lines[i][0];
		p1.y = lines[i][1];
		p2.x = lines[i][2];
		p2.y = lines[i][3];*/
		//line(result, p1, p2, Scalar(0, 0, 255), 1, 8);
		line(result, Point(lines[i][0], lines[i][1]), Point(lines[i][2], lines[i][3]), Scalar(255, 0, 0), 1, 8);
	}
	imshow("霍夫直线", result);
}
</code></pre> </li></ol> 
<p>​</p> 
<h6><a id="211__1558"></a>21.1 霍夫圆检测</h6> 
<p>x = x<sub>0</sub> + rcos(θ); y = y<sub>0</sub>+rsin(θ) 一直圆心(x<sub>0</sub>,y<sub>0</sub>)和r</p> 
<p>基于梯度去寻找, 不然计算量太大了</p> 
<p><strong>接收的必须是灰色图像, 而且对噪声很敏感, 需要进行降噪</strong></p> 
<ol><li> <p>圆的参数方程:</p> <p>​ 圆的参数(X<sub>0</sub>, Y<sub>0</sub>, r), 圆任意三个点, 以这些点位圆心 r为半径, 相交的一个点</p> <p>​ 基于梯度或者边缘,轮廓进行查找</p> 
  <ol><li>X = X<sub>0</sub> + r * cos(θ)</li><li>Y = Y<sub>0</sub> + r * sin(θ)</li></ol> </li><li> <p>api: HoughCircles</p> 
  <ol><li>参数2: 输出的圆 <code>vector&lt;ve3f&gt;</code></li><li>参数3: 方法(可以为霍夫梯度,HOUGH_GRADIENT)</li><li>参数4: 参数方程空间的整个数据的大小(dp, 在其他参数不变的情况下,参数越高, 越容易检测出圆)</li><li>参数5: 两个圆直径的最小距离 (防止得到同心圆)</li><li>参数6: canny边缘提取的高阈值</li><li>参数7: 累计值(阈值)</li><li>参数8,9: 最小半径, 最大半径</li></ol> </li></ol> 
<pre><code>void Person::houghCir(Mat &amp;img)
{
	imshow("原图", img);
	Mat result = Mat::zeros(img.size(), CV_8UC3);
	Mat gray;
	cvtColor(img, gray, COLOR_BGR2GRAY);
	GaussianBlur(gray, gray, Size(15,15), 2, 2);
	vector&lt;Vec3f&gt; cir;
	int dp = 2;
	double cirSpace = 5;
	int add = 100;
	int maxThreshold = 100;
	double cirMin = 15; double cirMax = 100;
	HoughCircles(gray, cir, HOUGH_GRADIENT, dp, cirSpace, add, maxThreshold, cirMin, cirMax);
	for (int i = 0; i &lt; cir.size(); i++)
	{
		int cenX = round(cir[i][0]);
		int cenY = round(cir[i][1]);
		int radius = round(cir[i][2]);
		circle(result, Point(cenX, cenY), radius, Scalar(0, 0, 200), 2, 8);
	}
	imshow("霍夫找园", result);
}
</code></pre> 
<h6><a id="212__1613"></a>21.2 图像形态学</h6> 
<p>图像形态学操作</p> 
<p>概念: 可以对灰度图像和二值化图像处理</p> 
<h6><a id="1___1619"></a>1. 腐蚀与膨胀 支持彩色图像</h6> 
<p>原理:对处于卷积核像素的进行排序 腐蚀, 用最小像素来替换中心像素, 膨胀是用最大像素来替换中心像素</p> 
<p>作用: 断开或者连接前景对象</p> 
<p>getStructuringElement: 获取类型() 形态学</p> 
<ul><li>类型: morph_rect</li><li>大小: size(x,y)</li><li>中心点: Point()</li></ul> 
<ol><li> <p>API:</p> <p>腐蚀: erode</p> <p>膨胀: dilate</p> <p>参数: 第3个参数是结构元素(形态学)</p> </li></ol> 
<pre><code>void Person::erodeDilate(Mat&amp; img)
{
	imshow("原图", img);
	Mat result; 
	Mat result1;
	Mat binary = this-&gt;myBinary(img);
	Mat rect = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1));
	erode(img, result1, rect);
	imshow("腐蚀", result1);
	dilate(img, result, rect);
	imshow("膨胀", result);
}
</code></pre> 
<h6><a id="2__1656"></a>2. 开闭操作</h6> 
<p>只对起作用的区域产生变化, 对其他没作用到的不会产生变化</p> 
<ol><li> <p>开操作 = 腐蚀+膨胀, <strong>删除小的干扰块</strong></p> </li><li> <p>闭操作 = 膨胀+腐蚀, 填充闭合区域</p> </li></ol> 
<pre><code>void Person::erodeDilate(Mat&amp; img)
{
	imshow("原图", img);
	Mat result; 
	Mat result1;
	Mat binary = this-&gt;myBinary(img);
	Mat rect = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1));
	erode(img, result1, rect);
	imshow("腐蚀", result1);
	dilate(img, result, rect);
	imshow("膨胀", result);
}
</code></pre> 
<ol><li> <p>API: morphologyEx</p> 
  <ol><li> <p>参数3:morph_open</p> </li><li> <p>参数6: 连续操作(iterations):</p> <p>作用: 速度会高于直接提升kernel大小</p> </li></ol> </li></ol> 
<h6><a id="3_morph_1689"></a>3. 结构元素形状(morph形态学)</h6> 
<ul><li>线形 - 水平与垂直</li><li>矩形 - w*h</li><li>十字交叉形状</li></ul> 
<pre><code>void Person::openCloss(Mat&amp; img)
{
	Mat dst;
	imshow("原图", img);
	Mat binary = this-&gt;myBinary(img);
	imshow("二值化", binary);
	Mat kernel =  getStructuringElement(MORPH_RECT, Size(15, 1), Point(-1, -1));
	morphologyEx(binary, dst, MORPH_OPEN, kernel, Point(-1, -1), 1);
	imshow("腐蚀", dst);
}
</code></pre> 
<h6><a id="4___1710"></a>4. 形态学梯度(轮廓,线) 支持彩色</h6> 
<ul><li>基本梯度: 膨胀减去腐蚀之后的结果</li><li>内梯度: 原图减去腐蚀之后的结果</li><li>外梯度: 膨胀减去原图的结果</li></ul> 
<h6><a id="6__1718"></a>6. 更多形态学操作</h6> 
<ol><li> <p>黑帽和顶帽</p> 
  <ul><li>顶帽: 是原图减去开操作之后的结果(morph_TOPHAT)</li><li>黑帽: 是闭操作之后的结果减去原图(morph_BLACKHAT)</li><li>顶帽与黑帽的作用是用来提取图像中微小有用信息块</li></ul> </li><li> <p>击中击不中变换(morph_hitmiss)</p> <p>通过特点的元素去匹配 如果匹配成功则击中</p> <p>MORPH_CROSS: 十字交叉元素</p> </li></ol> 
<h6><a id="213__1732"></a>21.3 形态学梯度</h6> 
<ul><li>基本梯度: 膨胀减去腐蚀之后的结果</li><li>内梯度: 原图减去腐蚀之后的结果</li><li>外梯度: 膨胀减去原图的结果</li></ul> 
<pre><code>void Person::gradi(Mat&amp; img)
{
	
	if (img.empty())
	{
		cout &lt;&lt; "图片路径错误" &lt;&lt; endl;
		return;
	}
	imshow("原图", img);
	Mat gray; Mat binary;
	cvtColor(img, gray, COLOR_BGR2GRAY);
	Mat Ksize = getStructuringElement(MORPH_RECT, Size(3, 3), Point(-1, -1));
	Mat grad; Mat inside; Mat extral; Mat src; Mat src1;
	erode(gray, src, Ksize, Point(-1, -1));
	dilate(gray, src1, Ksize, Point(-1, -1));
	subtract(src1, src, grad);
	subtract(gray, src, inside);
	subtract(src1, gray, extral);
	imshow("形态学", grad);
	threshold(grad, grad, 0, 255, THRESH_BINARY_INV | THRESH_OTSU);
	imshow("基本形态学梯度", grad);
}
</code></pre> 
<h6><a id="214_1765"></a>21.4更多形态学操作</h6> 
<h6><a id="1__1767"></a>1. 黑帽和顶帽(提取瑕疵)</h6> 
<p>API:morph_TOPHAT, morph_BLACKHAT</p> 
<ul><li>顶帽: 是原图减去开操作之后的结果(morph_TOPHAT) 提取微小(被腐蚀)的像素块</li><li>黑帽: 是闭操作之后的结果减去原图(morph_BLACKHAT) 找出被膨胀的像素块</li><li>顶帽与黑帽的作用是用来提取图像中微小有用信息块</li></ul> 
<pre><code>void Person::morph1(Mat&amp; img)
{
	imshow("原图", img);
	Mat binary = this-&gt;myBinary(img);
	Mat dst;
	Mat rect = getStructuringElement(MORPH_ELLIPSE, Size(14, 14), Point(-1, -1));
	imshow("二值化", binary);
	//MORPH_TOPHAT
	morphologyEx(binary, dst, MORPH_BLACKHAT, rect);
	imshow("顶帽", dst);
}
</code></pre> 
<h6><a id="2_morph_hitmiss_1791"></a>2. 击中击不中变换(morph_hitmiss)</h6> 
<p>API:morph_hitmiss</p> 
<p>通过特点的元素去匹配 如果匹配成功则击中/通过结构元素去寻找, 如果形状一致则被击中</p> 
<p>MORPH_CROSS: 十字交叉元素</p> 
<pre><code>void Person::morph2(Mat&amp; img)
{
	imshow("原图", img);
	Mat dst;
	Mat binary = this-&gt;myBinary(img);
	Mat rect = getStructuringElement(MORPH_CROSS, Size(12, 12), Point(-1, -1));
	morphologyEx(binary, dst, MORPH_HITMISS, rect);
	imshow("匹配模板", dst);
}
</code></pre> 
<h6><a id="22__1813"></a>22: 视频读和写</h6> 
<h6><a id="1_api_1815"></a>1. api</h6> 
<ol><li> <p>VideoCapture xx(0): 打开当前摄像头, 也可以打开usb摄像头</p> 
  <ol><li>如果是(“xxx”): 代表读取视频流文件路径</li><li>如果是网址, 就直接从网址上去读取</li></ol> </li><li> <p>capture.isOpened: 确认是否打开摄像头, 为1=打开</p> </li><li> <p>namedWindow默认打开的摄像头是640*480</p> </li><li> <p>capture.read(mat) || capture &gt;&gt; mat: 读取摄像头</p> </li><li> <p>capture内置属性</p> 
  <ol><li>capture.get(CAP_PROP_FPS): 帧率</li><li>CAP_PROP_FRAME_WIDTH: 宽度</li><li>CAP_PROP_FRAME_HEIGHT: 高度</li><li>CAP_PROP_FRAME_COUNT: 总共多少帧</li><li>CAP_PROP_FRAME_FOURCC: 视频类型</li></ol> </li><li> <p>VideoWirter: 保存视频/写入</p> 
  <ol><li>保存路径</li><li>参数2: 视频类型</li><li>参数3: 帧率</li><li>参数4: 宽高</li><li>参数5: 是否是彩色的</li></ol> <p>一个文件保存视频流最大是2g</p> </li></ol> 
<p><strong>注意点: 如果不是c++语言要记得销毁: 读取.release(), 写入.release(), 如果没有可能会造成视频保存打不开</strong>, <strong>保存摄像头一般设置为25.否则打不开</strong></p> 
<pre><code>void Person::cvtVideos(string src)
{
	VideoCapture capture(src);
	if (!capture.isOpened())
	{
		cout &lt;&lt; "视频路径错误" &lt;&lt; endl;
		return;
	}
	Mat img;
	while (true)
	{
		Mat hsv; Mat mask; Mat result;
		bool b = capture.read(img);
		if (!b) break;
		imshow("加载视频", img);
		cvtColor(img, hsv, COLOR_BGR2HSV);
		inRange(hsv, Scalar(35, 43, 46), Scalar(77, 255, 255), hsv);
		imshow("hsv", hsv);
		bitwise_not(hsv, mask);
		imshow("mask", mask);

		bitwise_and(img, img, result,mask);
		imshow("roi", result);
		int key = waitKey(25);
		if (key == 27)
		{
			break;
		}
	}
	capture.release();
}
</code></pre> 
<h6><a id="23__1884"></a>23: 图像色彩空间转换</h6> 
<ol><li> <p>色彩空间分布</p> <p>绝大数的普遍的</p> 
  <ol><li>RGB色彩空间</li></ol> <p>特点设备的</p> 
  <ul><li> <p>HSV色彩空间</p> <p>对各种颜色分辨很清楚</p> </li><li> <p>Lab色彩空间</p> <p>主要的颜色在L和B上面 只有2个通道</p> </li><li> <p>YC<sub>b</sub>C<sub>r</sub>色彩空间</p> <p>对皮肤能更好的显示</p> </li></ul> <p>inrang: rgb转换lab设置的参数,</p> <p>h:0~180, s:0~255</p> <pre><code>void Person::cvtVideos(string src)
{
	VideoCapture capture(src);
	if (!capture.isOpened())
	{
		cout &lt;&lt; "视频路径错误" &lt;&lt; endl;
		return;
	}
	Mat img;
	while (true)
	{
		Mat hsv; Mat mask; Mat result;
		bool b = capture.read(img);
		if (!b) break;
		imshow("加载视频", img);
		cvtColor(img, hsv, COLOR_BGR2HSV);
		inRange(hsv, Scalar(35, 43, 46), Scalar(77, 255, 255), hsv);
		imshow("hsv", hsv);
		bitwise_not(hsv, mask);
		imshow("mask", mask);

		bitwise_and(img, img, result,mask);
		imshow("roi", result);
		int key = waitKey(25);
		if (key == 27)
		{
			break;
		}
	}
	capture.release();
}
</code></pre> </li></ol> 
<h6><a id="24__1948"></a>24: 直方图反向投影</h6> 
<ol><li> <p>注意点: 模型和样品的bins必须完全一直</p> </li><li> <p>API: calcBackProject : 反向投影</p> <p><strong>会受到2个因素影响, 直方图的bins会影响到, bins越大, 匹配越细微, bins一般设置为48左右</strong></p> <pre><code>void Person::calcBack(Mat sample, Mat target)
{
	if (sample.empty() || target.empty())
	{
		cout &lt;&lt; "img路径错误" &lt;&lt; endl;
		return;
	}
	imshow("样本", sample); imshow("模板", target);
	Mat hsvSample; Mat hsvTarget;
	cvtColor(sample, hsvSample, COLOR_BGR2HSV);
	cvtColor(target, hsvTarget, COLOR_BGR2HSV);
	int channles[] = { 0,1 };
	Mat hist;
	int hBins = 48; int sBins = 48;
	int bins[] = { hBins,sBins };
	float hRangs[] = { 0,180 };
	float sRangs[] = { 0,255 };
	const float* rangs[] = { hRangs,sRangs };
	calcHist(&amp;hsvSample, 1, channles, Mat(), hist, 2, bins, rangs, true, false);
	Mat norm;
	normalize(hist, norm, 0, 255,NORM_MINMAX,-1,Mat());
	Mat dst;
	calcBackProject(&amp;hsvTarget, 1, channles, norm, dst, rangs, 1.0, true);
	imshow("直方图反向投影", dst);
}
</code></pre> </li><li> <p>色彩空间分布</p> <p>绝大数的普遍的</p> 
  <ol><li>RGB色彩空间</li></ol> <p>特点设备的</p> 
  <ul><li> <p>HSV色彩空间</p> <p>对各种颜色分辨很清楚</p> </li><li> <p>Lab色彩空间</p> <p>主要的颜色在L和B上面 只有2个通道</p> </li><li> <p>YC<sub>b</sub>C<sub>r</sub>色彩空间</p> <p>对皮肤能更好的显示</p> </li></ul> <p>inrang: rgb转换lab设置的参数,</p> <p>h:0~180, s:0~255</p> <pre><code>void Person::cvtVideos(string src)
{
	VideoCapture capture(src);
	if (!capture.isOpened())
	{
		cout &lt;&lt; "视频路径错误" &lt;&lt; endl;
		return;
	}
	Mat img;
	while (true)
	{
		Mat hsv; Mat mask; Mat result;
		bool b = capture.read(img);
		if (!b) break;
		imshow("加载视频", img);
		cvtColor(img, hsv, COLOR_BGR2HSV);
		inRange(hsv, Scalar(35, 43, 46), Scalar(77, 255, 255), hsv);
		imshow("hsv", hsv);
		bitwise_not(hsv, mask);
		imshow("mask", mask);

		bitwise_and(img, img, result,mask);
		imshow("roi", result);
		int key = waitKey(25);
		if (key == 27)
		{
			break;
		}
	}
	capture.release();
}
</code></pre> </li></ol> 
<h6><a id="24__2046"></a>24: 直方图反向投影</h6> 
<ol><li> <p>注意点: 模型和样品的bins必须完全一直</p> </li><li> <p>API: calcBackProject : 反向投影</p> <p><strong>会受到2个因素影响, 直方图的bins会影响到, bins越大, 匹配越细微, bins一般设置为48左右</strong></p> <pre><code>void Person::calcBack(Mat sample, Mat target)
{
	if (sample.empty() || target.empty())
	{
		cout &lt;&lt; "img路径错误" &lt;&lt; endl;
		return;
	}
	imshow("样本", sample); imshow("模板", target);
	Mat hsvSample; Mat hsvTarget;
	cvtColor(sample, hsvSample, COLOR_BGR2HSV);
	cvtColor(target, hsvTarget, COLOR_BGR2HSV);
	int channles[] = { 0,1 };
	Mat hist;
	int hBins = 48; int sBins = 48;
	int bins[] = { hBins,sBins };
	float hRangs[] = { 0,180 };
	float sRangs[] = { 0,255 };
	const float* rangs[] = { hRangs,sRangs };
	calcHist(&amp;hsvSample, 1, channles, Mat(), hist, 2, bins, rangs, true, false);
	Mat norm;
	normalize(hist, norm, 0, 255,NORM_MINMAX,-1,Mat());
	Mat dst;
	calcBackProject(&amp;hsvTarget, 1, channles, norm, dst, rangs, 1.0, true);
	imshow("直方图反向投影", dst);
}
</code></pre> </li></ol>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/127d979c3508477f064985194716ef89/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C语言全局变量（c文件和h文件中的全局变量、静态全局变量）使用注意事项</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/13bad68b7426fc25652eb3681f3d1a49/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">CSDN的打码的年龄是咋算的？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>