<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>轻量化CNN模型整理—MobileNet，ShuffleNet，GhostNet - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="轻量化CNN模型整理—MobileNet，ShuffleNet，GhostNet" />
<meta property="og:description" content="卷积神经网络（Convolutional Neural Networks, CNNs）由于其强大的表征学习能力，在计算机视觉领域取得了瞩目的成就，并得到了广泛的应用。为了进一步提高网络的精度，目前CNN的整体发展趋势是向着更深、更复杂的网络发展，但也因此导致了更高的计算代价。而在实际应用中，网络可能需要部署在计算资源有限的平台上，因此简化网络参数、减少网络计算量、提高网络效率也成为卷积网络研究的一个方向。目前轻量化网络研究主要包括以下几个思路：（1）压缩预训练的网络，如通过剪枝(pruning)、乘积量化(product quantization)、矢量量化(vector quantization)、哈希编码、霍夫曼编码等方式实现网络计算量压缩；（2）设计具有更少参数及计算量的高效网络模型，如SquezeNet、Deep fried convnets 、MobileNet、ShuffleNet、GhostNet等；（3）模型蒸馏（distillation），基于预训练的大规模网络引导训练更小规模的网络。
本文主要整理了轻量化网络结构设计研究中的几个经典网络模型：MobileNet[1]、ShuffleNet[2]和GhostNet[3]。
1. 常规卷积网络 在介绍轻量化网络模型前，先对常规卷积网络的操作做一回顾。常规卷积网络中，一个卷积层包含若干个滤波器（filters），每个滤波器包含若干个滤波矩阵，即卷积核（kernels）。一个滤波器对输入的操作如图1所示（忽略偏置计算），对于3通道的输入，一个滤波器将包含3个卷积核，每个卷积核对输入的一个通道进行卷积，各卷积核计算结果相加，得到一个输出特征图。当采用多个滤波器时，即可得到多通道的输出特征图。
图1 常规卷积运算 常规卷积层的计算量（乘加操作数）为 。其中H，W，C分别为输入的高、宽及通道数，N为输出通道数（即滤波器数），k为卷积核尺寸。
2. MobileNet MobileNet由Google团队提出，旨在提供一种适用于计算资源有限的移动设备的卷积网络。其核心是卷积层采用深度可分离卷积（Depthwise separable convolution）。
由第1节回顾可以发现常规卷积层操作其实可以分成两步。第一步是对输入各通道进行卷积滤波，第二步是对第一步结果线性组合。由于常规卷积层中这两步操作并不解耦，因此每个滤波器的卷积核参数并不相同，卷积时需要独立计算，当各层输出特征图通道数增加（即增大）时计算量显著增大。
深度可分离卷积的基本思路是将常规卷积层的两步操作解耦，即逐通道卷积（Depthwise convolution）和逐点卷积（Pointwise convolution），如图2所示。具体操作如下：
（1）逐通道卷积实现深度方向的空间卷积。这一步中输入的每个通道对应一个卷积核，通过卷积操作得到和输入通道数C相同通道的输出。这一步可以看做只采用1个包含C个卷积核的滤波器对输入各通道分别卷积滤波但不求和。也可以看做C个滤波器，每个滤波器仅包含对应单通道的1个卷积核，相当于极端的分成C组的分组卷积（Group convolution）。该步的计算量为。
（2）接着逐点卷积将逐通道卷积结果各通道进行组合的卷积。这一步可以看做对逐通道卷积输出结果进行常规的卷积操作，但卷积核尺寸固定为1*1，从而实现逐点的线性组合。这一步中滤波器数量可以自己设定，从而可以输出通道数为的特征图。该步的计算量为，这里假设逐通道卷积输出与输入尺寸相同。
图2 深度可分离卷积运算 综上一个深度可分离卷积层的计算量为，相比具有相同输出特征图的常规卷积层其计算量减少为原来的倍。
图3给出了MobileNet中采用的深度可分离卷积层结构和MobileNet整体结构。可以注意到MobileNet采用的深度可分离卷积在逐通道卷积和逐点卷积后均跟随Batch Normalization和ReLU激活函数。也有其他一些采用深度可分离卷积的方法尽在逐点卷积后进行Batch Normalization和ReLU激活。此外后续研究中MobileNet也有了更新的版本，如MobileNet V2，MobileNet V3，感兴趣的读者可以自行研究。
图3 MobileNet结构[1] 3. ShuffleNet ShuffleNet是旷视科技提出的应用于移动设备的高效CNN模型。其作者注意到此前的运用深度可分离卷积的方法中1*1的逐点级卷积（Pointwise convolution）占用大量的计算资源。一个直接的解决思路是利用通道稀疏连接的方法，如分组卷积（Group convolution），来降低其计算复杂度。
分组卷积实际上早在AlexNet中就有使用，其基本思路是将输入特征图分为g组，每组内分别进行常规卷积，如图4（a）。由于每组输入和输出的通道数均变为原本的1/g，总计算量变为常规卷积的1/g。但是分组卷积存在的一个问题是一组输出只与本组内的输入有关，不同组间缺乏信息交互，可能会降低模型表征能力。
图4 两层的分组卷积及通道混洗分组卷积[2] (a) 分组卷积；(b), (c) 通道混洗分组卷积 为了解决分组卷积组间信息无法交互的问题，ShuffleNet提出一种采用通道间混洗（Channel shuffle）的分组卷积。在一层分组卷积得到输出后，对各组输出均匀打乱，使得下一层分组卷积中各分组的特征图来自上一层不同组的输出，从而实现不同分组间信息交互，如图4（b）及（c）。具体实现中，如图5所示，通过简单的维度变换（Reshape）和转置（Transpose）即可实现通道混洗：首先将上一层输出的通道数g×n维度变化为（g, n），接着转置为（n, g），最后重新维度变化为g×n。综上通过通道混洗的分组卷积一方面降低了计算量，一方面实现了通道间的信息交互。
图5 具体的通道混洗操作 在此基础上原文参考残差网络的bottleneck设计给出包含和不包含下采样的两个ShuffleNet Unit，如图6。
图6 ShuffleNet Unit[2] (a) 具有Depthwise Conv的bottleneck; (b) ShuffleNet Unit, stride=1; (c)ShuffleNet Unit, stride=2 进一步的，给出不同分组数的ShuffleNet如图7。此外后续研究中ShuffleNet也有了更新的版本，如ShuffleNet V2，感兴趣的读者可以自行研究。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/747cae1af05f3f8e443ddc35631898c3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-22T15:03:03+08:00" />
<meta property="article:modified_time" content="2023-06-22T15:03:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">轻量化CNN模型整理—MobileNet，ShuffleNet，GhostNet</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p>        卷积神经网络（Convolutional Neural Networks, CNNs）由于其强大的表征学习能力，在计算机视觉领域取得了瞩目的成就，并得到了广泛的应用。为了进一步提高网络的精度，目前CNN的整体发展趋势是向着更深、更复杂的网络发展，但也因此导致了更高的计算代价。而在实际应用中，网络可能需要部署在计算资源有限的平台上，因此简化网络参数、减少网络计算量、提高网络效率也成为卷积网络研究的一个方向。目前轻量化网络研究主要包括以下几个思路：（1）压缩预训练的网络，如通过剪枝(pruning)、乘积量化(product quantization)、矢量量化(vector quantization)、哈希编码、霍夫曼编码等方式实现网络计算量压缩；（2）设计具有更少参数及计算量的高效网络模型，如SquezeNet、Deep fried convnets 、MobileNet、ShuffleNet、GhostNet等；（3）模型蒸馏（distillation），基于预训练的大规模网络引导训练更小规模的网络。</p> 
 <p>        本文主要整理了轻量化网络结构设计研究中的几个经典网络模型：<a class="link-info" href="https://arxiv.org/abs/1704.04861" rel="nofollow" title="MobileNet[1]">MobileNet[1]</a>、<a class="link-info" href="https://ieeexplore.ieee.org/document/8578814/" rel="nofollow" title="ShuffleNet[2]">ShuffleNet[2]</a>和<a class="link-info" href="https://ieeexplore.ieee.org/document/9157333/" rel="nofollow" title="GhostNet[3]">GhostNet[3]</a>。</p> 
</blockquote> 
<h4>1. 常规卷积网络</h4> 
<p>        在介绍轻量化网络模型前，先对常规卷积网络的操作做一回顾。常规卷积网络中，一个卷积层包含若干个滤波器（filters），每个滤波器包含若干个滤波矩阵，即卷积核（kernels）。一个滤波器对输入的操作如图1所示（忽略偏置计算），对于3通道的输入，一个滤波器将包含3个卷积核，每个卷积核对输入的一个通道进行卷积，各卷积核计算结果相加，得到一个输出特征图。当采用多个滤波器时，即可得到多通道的输出特征图。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/ef/dd/l6nkDnvr_o.jpg"> 
  <figcaption>
    图1 常规卷积运算 
  </figcaption> 
 </figure> 
</div> 
<p>         常规卷积层的计算量（乘加操作数）为 <img alt="H\times W\times C\times N\times k \times k" class="mathcode" src="https://images2.imgbox.com/e6/62/FswUkIUf_o.png">。其中<em>H</em>，<em>W</em>，<em>C</em>分别为输入的高、宽及通道数，<em>N</em>为输出通道数（即滤波器数），<em>k</em>为卷积核尺寸。</p> 
<h4>2. MobileNet</h4> 
<p>        MobileNet由Google团队提出，旨在提供一种适用于计算资源有限的移动设备的卷积网络。其核心是卷积层采用<strong>深度可分离卷积（Depthwise separable convolution）</strong>。</p> 
<p>        由第1节回顾可以发现常规卷积层操作其实可以分成两步。第一步是对输入各通道进行卷积滤波，第二步是对第一步结果线性组合。由于常规卷积层中这两步操作并不解耦，因此每个滤波器的卷积核参数并不相同，卷积时需要独立计算，当各层输出特征图通道数增加（即<img alt="C\times N" class="mathcode" src="https://images2.imgbox.com/4e/6e/Jil91pg2_o.png">增大）时计算量显著增大。</p> 
<p>        深度可分离卷积的基本思路是将常规卷积层的两步操作解耦，即逐通道卷积（Depthwise convolution）和逐点卷积（Pointwise convolution），如图2所示。具体操作如下：</p> 
<p>        （1）逐通道卷积实现深度方向的空间卷积。这一步中输入的每个通道对应一个卷积核，通过卷积操作得到和输入通道数<em>C</em>相同通道的输出。这一步可以看做只采用1个包含<em>C</em>个卷积核的滤波器对输入各通道分别卷积滤波但不求和。也可以看做<em>C</em>个滤波器，每个滤波器仅包含对应单通道的1个卷积核，相当于极端的分成<em>C</em>组的分组卷积（Group convolution）。该步的计算量为<img alt="H \times W \times C \times k \times k" class="mathcode" src="https://images2.imgbox.com/11/2a/m4ik4d2h_o.png">。</p> 
<p>        （2）接着逐点卷积将逐通道卷积结果各通道进行组合的卷积。这一步可以看做对逐通道卷积输出结果进行常规的卷积操作，但卷积核尺寸固定为1*1，从而实现逐点的线性组合。这一步中滤波器数量可以自己设定，从而可以输出通道数为的特征图。该步的计算量为<img alt="H \times W \times C \times N" class="mathcode" src="https://images2.imgbox.com/bd/06/tpYu7XSs_o.png">，这里假设逐通道卷积输出与输入尺寸相同。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/be/75/L4JFK5OR_o.jpg"> 
  <figcaption>
    图2 深度可分离卷积运算 
  </figcaption> 
 </figure> 
</div> 
<p>        综上一个深度可分离卷积层的计算量为<img alt="H \times W \times C \times k \times k + H \times W \times C \times N" class="mathcode" src="https://images2.imgbox.com/ae/66/HW9nudBP_o.png">，相比具有相同输出特征图的常规卷积层其计算量减少为原来的<img alt="1/N + 1/k^2" class="mathcode" src="https://images2.imgbox.com/b3/9f/RgBecO0Q_o.png">倍。</p> 
<p>        图3给出了MobileNet中采用的深度可分离卷积层结构和MobileNet整体结构。可以注意到MobileNet采用的深度可分离卷积在逐通道卷积和逐点卷积后均跟随Batch Normalization和ReLU激活函数。也有其他一些采用深度可分离卷积的方法尽在逐点卷积后进行Batch Normalization和ReLU激活。此外后续研究中MobileNet也有了更新的版本，如MobileNet V2，MobileNet V3，感兴趣的读者可以自行研究。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" height="467" src="https://images2.imgbox.com/c3/8b/oSgGy1Yl_o.jpg" width="600"> 
  <figcaption>
    图3 MobileNet结构[1] 
  </figcaption> 
 </figure> 
</div> 
<p></p> 
<h4>3. ShuffleNet</h4> 
<p>        ShuffleNet是旷视科技提出的应用于移动设备的高效CNN模型。其作者注意到此前的运用深度可分离卷积的方法中1*1的逐点级卷积（Pointwise convolution）占用大量的计算资源。一个直接的解决思路是利用通道稀疏连接的方法，如分组卷积（Group convolution），来降低其计算复杂度。</p> 
<p>        分组卷积实际上早在AlexNet中就有使用，其基本思路是将输入特征图分为g组，每组内分别进行常规卷积，如图4（a）。由于每组输入和输出的通道数均变为原本的1/g，总计算量变为常规卷积的1/g。但是分组卷积存在的一个问题是一组输出只与本组内的输入有关，不同组间缺乏信息交互，可能会降低模型表征能力。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/cf/98/jFDpWqA4_o.jpg"> 
  <figcaption>
    图4 两层的分组卷积及通道混洗分组卷积[2] (a) 分组卷积；(b), (c) 通道混洗分组卷积 
  </figcaption> 
 </figure> 
</div> 
<p>        为了解决分组卷积组间信息无法交互的问题，ShuffleNet提出一种<strong>采用通道间混洗（Channel shuffle）的分组卷积</strong>。在一层分组卷积得到输出后，对各组输出均匀打乱，使得下一层分组卷积中各分组的特征图来自上一层不同组的输出，从而实现不同分组间信息交互，如图4（b）及（c）。具体实现中，如图5所示，通过简单的维度变换（Reshape）和转置（Transpose）即可实现通道混洗：首先将上一层输出的通道数<em>g</em>×<em>n</em>维度变化为（<em>g</em>, <em>n</em>），接着转置为（<em>n</em>, <em>g</em>），最后重新维度变化为<em>g</em>×<em>n</em>。综上通过通道混洗的分组卷积一方面降低了计算量，一方面实现了通道间的信息交互。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" height="205" src="https://images2.imgbox.com/3a/fc/lwMedmus_o.jpg" width="550"> 
  <figcaption>
    图5 具体的通道混洗操作 
  </figcaption> 
 </figure> 
</div> 
<p>         在此基础上原文参考残差网络的bottleneck设计给出包含和不包含下采样的两个ShuffleNet Unit，如图6。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/a4/fa/zAoy9vZy_o.jpg"> 
  <figcaption>
    图6 ShuffleNet Unit[2] (a) 具有Depthwise Conv的bottleneck; (b) ShuffleNet Unit, stride=1; (c)ShuffleNet Unit, stride=2 
  </figcaption> 
 </figure> 
</div> 
<p>         进一步的，给出不同分组数的ShuffleNet如图7。此外后续研究中ShuffleNet也有了更新的版本，如ShuffleNet V2，感兴趣的读者可以自行研究。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" height="320" src="https://images2.imgbox.com/f3/b1/upuVNDZO_o.jpg" width="700"> 
  <figcaption>
    图7 ShuffleNet结构[3] 注意在Stage2，由于输出通道数较少，因此不应用分组卷积。 
  </figcaption> 
 </figure> 
</div> 
<p></p> 
<h4>4. GhostNet</h4> 
<p>        GhostNet由华为诺亚方舟实验室提出，作者注意到常规卷积操作得到的特征图间存在很多冗余，例如图8中用相同颜色标出的特征图间相关性很高。因此可以减少常规卷积生成的特征图数量，而基于这些特征图采用一些廉价操作（Cheap operations），如简单线性变换等，生成更多特征图。原文中将常规卷积生成的特征图称为本质特征图（Intrinsic feature maps），由廉价操作生成的特征图称为幻影特征图（Ghost feature maps），因此该操作也可以称为<strong>幻影卷积（Ghost convolution）</strong>。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/fc/25/PGbyjJIT_o.jpg"> 
  <figcaption>
    图8 ResNet-50特征图可视化[3] 
  </figcaption> 
 </figure> 
</div> 
<p></p> 
<p>        幻影卷积的具体操作如图9所示。假设希望生成通道数为<em>N</em>的特征图输出，幻影卷积也可以分为两步：</p> 
<p>（1）首先通过常规卷积生成通道数为<em>M</em>=<em>N</em>/<em>s</em>的本质特征图。这一步操作与常规卷积无异，但通过减少输出通道数降低了计算量，该步的计算量为<img alt="H\times W\times C\times \frac{N}{s}\times k \times k" class="mathcode" src="https://images2.imgbox.com/36/42/BISGsoVj_o.png">。</p> 
<p>（2）接着对于本质特征图中的每一个特征图分别通过<em>s</em>个变换<img alt="\phi_{1}, \cdots, \phi_{k}, \cdots, \phi_{s}" class="mathcode" src="https://images2.imgbox.com/13/bc/SIxebB0B_o.png">生成最终输出的特征图。<img alt="\phi_{k}" class="mathcode" src="https://images2.imgbox.com/46/c2/T4HrgMBk_o.png">可以采用线性变换、仿射变换及小波变换等，且可以同时采用多个不同类型或超参数的变换。但考虑到硬件计算效率及实用性，原文中采用固定尺寸的卷积操作实现线性变换（该卷积操作对每个通道独立进行，相当于对本质特征图进行了s-1次depthwise卷积）。同时变换的最后一项<img alt="\phi_{s}" class="mathcode" src="https://images2.imgbox.com/70/b7/bMUt9aT5_o.png">取恒等映射，即在最终输出中保留本质特征图。假设采用卷积核尺寸为<em>d</em>的卷积实现线性变换，则该步的计算量为<img alt="(s-1)\times \frac{N}{s}\times H\times W\times d \times d" class="mathcode" src="https://images2.imgbox.com/5b/29/RA66Sicy_o.png">。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/58/1f/tG5mEWcw_o.jpg"> 
  <figcaption>
    图9 幻影卷积运算 
  </figcaption> 
 </figure> 
</div> 
<p>         综上一个幻影卷积的计算量为</p> 
<p style="text-align:center;"><img alt="H\times W\times C\times \frac{N}{s}\times k \times k+(s-1)\times \frac{N}{s}\times H\times W\times d \times d" class="mathcode" src="https://images2.imgbox.com/b3/8a/0yXSdAC3_o.png"></p> 
<p>相比具有相同输出特征图的常规卷积层其计算量比为(后两项近似是通过假设<em>k</em>与<em>d</em>近似相等，<em>s</em>远小于<em>C</em>得到的)</p> 
<p style="text-align:center;"><img alt="\frac{}{}" class="mathcode" src="https://images2.imgbox.com/97/17/GipXkeA4_o.png"><img alt="\frac{H\times W\times C\times \frac{N}{s}\times k \times k+(s-1)\times \frac{N}{s}\times H\times W\times d \times d}{H \times W \times C \times N \times k \times k} \\= \frac{\frac{1}{s} \times C \times k \times k + \frac{s-1}{s} \times d \times d}{C \times k \times k}\approx \frac{s + C -1}{s \times C}\approx \frac{1}{s}" class="mathcode" src="https://images2.imgbox.com/92/13/n5UReLa5_o.png"></p> 
<p>即计算量近似为常规卷积的1/<em>s</em>倍。</p> 
<p>        在此基础上原文参考残差网络的bottleneck设计给出包含和不包含下采样的两个幻影卷积bottleneck（G-bneck），如图10。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/c5/96/MiV3R9MW_o.jpg" width="450"> 
  <figcaption>
    图10 幻影卷积Bottleneck（G-bneck）[3] 
  </figcaption> 
 </figure> 
</div> 
<p>        进一步的给出GhostNet结构设计如图11。其中SE代表是否采用SE模块。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/f0/24/Gtg3isfK_o.jpg" width="450"> 
  <figcaption>
    图11 GhostNet结构[3] 
  </figcaption> 
 </figure> 
</div> 
<p></p> 
<p></p> 
<h4>5. 参考文献</h4> 
<p><a class="link-info" href="https://arxiv.org/abs/1704.04861" rel="nofollow" title="[1] MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, 2017.">[1] MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, 2017.</a></p> 
<p><a class="link-info" href="https://ieeexplore.ieee.org/document/8578814/" rel="nofollow" title="[2] ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices, 2018.">[2] ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices, 2018.</a></p> 
<p><a class="link-info" href="https://ieeexplore.ieee.org/document/9157333/" rel="nofollow" title="[3] GhostNet: More Features from Cheap Operations, 2020.">[3] GhostNet: More Features from Cheap Operations, 2020.</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/62c5a4d0a5cd1a2350591a1c772b1d26/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">docker安装mosquitto</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/386292d6d2a8b113dc2d4092838fb893/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">（2020，StyleGAN2）分析和提高 StyleGAN 的图像质量</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>