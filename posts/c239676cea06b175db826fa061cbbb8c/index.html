<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>18. 深度学习 - 从零理解神经网络 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="18. 深度学习 - 从零理解神经网络" />
<meta property="og:description" content="文章目录 本文目标预测趋势与关系波士顿房价预测 Hi, 你好。我是茶桁。
我们终于又开启新的篇章了，从今天这节课开始，我们会花几节课来理解一下深度学习的相关知识，了解神经网络，多层神经网络相关知识。并且，我们会尝试着来打造一个自己的深度学习框架。
以前很多时候都会被人问到很多问题，其中比较多的就包括现在各种各样的框架应该用到哪一个，在学习人工智能的时候，对于深度学习框架有比较多的问题。那在这里我就希望能帮助各位小伙伴彻底的去理解一下什么是学习框架。
对于我们来说，就像小孩子去学一个东西，最好的就是从头到尾能把它拆了，然后再重建起来。
从今天开始往后的几节课里，我们都会去好好了解「如何从零构建一个深度学习框架」。
本文目标 我们基本的核心目的就是来讲明白，什么是神经网络，以及神经网络的原理是什么。
我们要知道，人工智能有很多方法，但是神经网络是现代人工智能里面一个非常核心的内容。
咱们现在就是要先去了解神经网络的原理是怎么回事，然后在这个过程中我们来讲解清楚神经网络的框架到底是什么样的。
如我们之前学习过的几节机器学习课程，会发现它有很多的概念。
比方说非监督学习、监督学习、强化学习，监督学习里面又分了回归和分类等等。
很多人看到这些，在初次接触、初次学习的时候就觉得人工智能很复杂，很难学会。除此之外，我们在学到人工智能目前比较核心的一个内容是关于深度学习神经网络。好多人不知道深度学习神经网络到底是什么原理。
在整个学习过程会发现有很多很多的问题，概念很多，变体也很多，学习很困难。
那这里要跟大家强调一点，就是千万别成为「马保国」，为什么这里会提到这个人呢？在我看来，这其实是一类人，他是一类人的代表。就是整很多的概念，假装子集很厉害。
就是我们脑子里不要总是去提很多概念，或者说很多很花哨的东西，最重要的还是基本功修炼好。我一直都强调一个观念，就是基础学科，基本功才是所有学科的基石。过多的概念其实并没有什么卵用。
早些时候，我上班的地方有一个叫「李雨晨」（匿名🙄）的产品经理，各种概念信手拈来，都是一些高大上的东西。也是将面试官唬的一愣一愣的。当时大家也是没多想，心想人家既然是个牛逼人物，那就多配合人家呗，结果是没过3个月就原形毕露，当然是下面干事的人最先觉察出来的。
没办法，为了继续装下去只能是利用自己的职权和谎言去盗用别人的成果，比如设计稿啊，文档啊啥的，拿着当自己的东西向上汇报。
再然后，基本人人都开始防着他了，就开始恼羞成怒，一直打压那个最开始说他不行并防着他的产品。不过不行就是不行，其实最开始就能看出端倪，因为基本没有一家公司干活超过6个月，那肯定是有问题的。就这资质也能忽悠成高级产品经理，也能看出来那会儿产品这个行业的水份多大，门槛多低。不过终归潮水退了之后，裸泳的王八都要现行是吧。
好，说这么多吐槽的话其实也是想说一个道理，不要去搞花里胡哨的玩意，踏踏实实的把基本功练扎实，否则一时唬的了人，但是终归是走不远。
那这也是咱们这节课的目的，让大家去除掉背后这些繁杂的表象，那么它背后到底是什么，这就是咱们这三天的目的。
这些年，人工智能已经应用到我们各个地方了。先不说现在大火的AIGC，人工智能还应用到其他各个地方。
比方说在商场购物的时候，它的楼宇灯光，自动停车都是在做这些事情。买票的时候，机场，火车站都有人脸识别。每天给你推荐的各种商品，以及我们做物流配送等等这些东西，背后都有人工智能。
而这些人工智能背后有一个很重要的东西，就是用到了神经网络框架。
比方说众所周知的TensorFlow, 我们每次调用的时候，框架背后调用了很多东西。
# Store layers weight &amp; bias # A random value generator to initialize weights. random_normal = tf.initializers.RandomNormal() weights = { &#39;h1&#39;: tf.Variable(random_normal([num_features, n_hidden_1])), &#39;h2&#39;: tf.Variable(random_normal([n_hidden_1, n_hidden_2])), &#39;out&#39;: tf.Variable(random_normal([n_hidden_2, num_classes])) } biases = { &#39;b1&#39;: tf.Variable(tf.zeros([n_hidden_1])), &#39;b2&#39;: tf.Variable(tf.zeros([n_hidden_2])), &#39;out&#39;: tf.Variable(tf.zeros([num_classes])) } ... # Create model." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/c239676cea06b175db826fa061cbbb8c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-09T16:20:09+08:00" />
<meta property="article:modified_time" content="2023-11-09T16:20:09+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">18. 深度学习 - 从零理解神经网络</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#_14" rel="nofollow">本文目标</a></li><li><a href="#_96" rel="nofollow">预测趋势与关系</a></li><li><a href="#_142" rel="nofollow">波士顿房价预测</a></li></ul> 
 </li></ul> 
</div> 
<br> 
<img src="https://images2.imgbox.com/e2/f8/i88qMyif_o.png" alt="在这里插入图片描述"> 
<p></p> 
<p>Hi, 你好。我是茶桁。</p> 
<p>我们终于又开启新的篇章了，从今天这节课开始，我们会花几节课来理解一下深度学习的相关知识，了解神经网络，多层神经网络相关知识。并且，我们会尝试着来打造一个自己的深度学习框架。</p> 
<p>以前很多时候都会被人问到很多问题，其中比较多的就包括现在各种各样的框架应该用到哪一个，在学习人工智能的时候，对于深度学习框架有比较多的问题。那在这里我就希望能帮助各位小伙伴彻底的去理解一下什么是学习框架。</p> 
<p>对于我们来说，就像小孩子去学一个东西，最好的就是从头到尾能把它拆了，然后再重建起来。</p> 
<p>从今天开始往后的几节课里，我们都会去好好了解「如何从零构建一个深度学习框架」。</p> 
<h3><a id="_14"></a>本文目标</h3> 
<p>我们基本的核心目的就是来讲明白，什么是神经网络，以及神经网络的原理是什么。</p> 
<p>我们要知道，人工智能有很多方法，但是神经网络是现代人工智能里面一个非常核心的内容。</p> 
<p>咱们现在就是要先去了解神经网络的原理是怎么回事，然后在这个过程中我们来讲解清楚神经网络的框架到底是什么样的。</p> 
<p>如我们之前学习过的几节机器学习课程，会发现它有很多的概念。</p> 
<p><img src="https://images2.imgbox.com/a0/aa/WTxD8v2U_o.png" alt="Alt text"></p> 
<p>比方说非监督学习、监督学习、强化学习，监督学习里面又分了回归和分类等等。</p> 
<p>很多人看到这些，在初次接触、初次学习的时候就觉得人工智能很复杂，很难学会。除此之外，我们在学到人工智能目前比较核心的一个内容是关于深度学习神经网络。好多人不知道深度学习神经网络到底是什么原理。</p> 
<p>在整个学习过程会发现有很多很多的问题，概念很多，变体也很多，学习很困难。</p> 
<p>那这里要跟大家强调一点，就是千万别成为「马保国」，为什么这里会提到这个人呢？在我看来，这其实是一类人，他是一类人的代表。就是整很多的概念，假装子集很厉害。</p> 
<p>就是我们脑子里不要总是去提很多概念，或者说很多很花哨的东西，最重要的还是基本功修炼好。我一直都强调一个观念，就是基础学科，基本功才是所有学科的基石。过多的概念其实并没有什么卵用。</p> 
<p>早些时候，我上班的地方有一个叫「李雨晨」（匿名🙄）的产品经理，各种概念信手拈来，都是一些高大上的东西。也是将面试官唬的一愣一愣的。当时大家也是没多想，心想人家既然是个牛逼人物，那就多配合人家呗，结果是没过3个月就原形毕露，当然是下面干事的人最先觉察出来的。</p> 
<p>没办法，为了继续装下去只能是利用自己的职权和谎言去盗用别人的成果，比如设计稿啊，文档啊啥的，拿着当自己的东西向上汇报。</p> 
<p>再然后，基本人人都开始防着他了，就开始恼羞成怒，一直打压那个最开始说他不行并防着他的产品。不过不行就是不行，其实最开始就能看出端倪，因为基本没有一家公司干活超过6个月，那肯定是有问题的。就这资质也能忽悠成高级产品经理，也能看出来那会儿产品这个行业的水份多大，门槛多低。不过终归潮水退了之后，裸泳的王八都要现行是吧。</p> 
<p>好，说这么多吐槽的话其实也是想说一个道理，不要去搞花里胡哨的玩意，踏踏实实的把基本功练扎实，否则一时唬的了人，但是终归是走不远。</p> 
<p>那这也是咱们这节课的目的，让大家去除掉背后这些繁杂的表象，那么它背后到底是什么，这就是咱们这三天的目的。</p> 
<p>这些年，人工智能已经应用到我们各个地方了。先不说现在大火的AIGC，人工智能还应用到其他各个地方。</p> 
<p>比方说在商场购物的时候，它的楼宇灯光，自动停车都是在做这些事情。买票的时候，机场，火车站都有人脸识别。每天给你推荐的各种商品，以及我们做物流配送等等这些东西，背后都有人工智能。</p> 
<p>而这些人工智能背后有一个很重要的东西，就是用到了神经网络框架。</p> 
<p>比方说众所周知的TensorFlow, 我们每次调用的时候，框架背后调用了很多东西。</p> 
<pre><code class="prism language-python"><span class="token comment"># Store layers weight &amp; bias</span>
<span class="token comment"># A random value generator to initialize weights.</span>
random_normal <span class="token operator">=</span> tf<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>RandomNormal<span class="token punctuation">(</span><span class="token punctuation">)</span>

weights <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'h1'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span>num_features<span class="token punctuation">,</span> n_hidden_1<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'h2'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span>n_hidden_1<span class="token punctuation">,</span> n_hidden_2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'out'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span>n_hidden_2<span class="token punctuation">,</span> num_classes<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>

biases <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'b1'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>n_hidden_1<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'b2'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>n_hidden_2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">'out'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>num_classes<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

<span class="token comment"># Create model.</span>
<span class="token keyword">def</span> <span class="token function">neural_net</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Hidden fully connected layer with 128 neurons.</span>
    layer_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> weights<span class="token punctuation">[</span><span class="token string">'h1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> biases<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># Apply sigmoid to layer_1 output for non_linerity.</span>
    layer_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>layer_1<span class="token punctuation">)</span>

    <span class="token comment"># Hidden fully connected layer with 256 neurons.</span>
    layer_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>layer_1<span class="token punctuation">,</span> weights<span class="token punctuation">[</span><span class="token string">'h2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> biases<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># Apply sigmoid to layer_1 output for non_linerity.</span>
    layer_2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>layer_2<span class="token punctuation">)</span>

    <span class="token comment"># Output fully connected layer with a neuron for each class.</span>
    out_layer <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>layer_2<span class="token punctuation">,</span> weights<span class="token punctuation">[</span><span class="token string">'out'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> biases<span class="token punctuation">[</span><span class="token string">'out'</span><span class="token punctuation">]</span>
    <span class="token comment"># Apply softmax to normalize the logits to a probability distribution</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>out_layer<span class="token punctuation">)</span>
</code></pre> 
<p>我们现在想把这些框架搞清楚，就需要知道它背后这些东西到底是什么原理、什么原因。</p> 
<p>那这几节课之后，就希望我们能从0到1学会创建一个深度学习框架，从底层来理解这个神经网络的原理，理解现代人工智能的核心。</p> 
<p>一开始的课程，内容也会稍微比较简单一些，越往后咱们就越难一点。最后，彻底理解深度学习神经网络原理。</p> 
<h3><a id="_96"></a>预测趋势与关系</h3> 
<p>我们以一个趋势预测的问题为引入。</p> 
<p>如果对于自然哲学或者说科学研究这些，就是对科学研究方法论感兴趣的话，你会知道我们整个科学研究其实分为三个层面。</p> 
<p>不管是牛顿、爱因斯坦，还是伽利略、图灵等等，所有的科学研究，所有的research，不管是关于数据还是别的，它都是三个层面。</p> 
<p>第一个层面叫做描述性的，第二个叫做因果推理，第三个叫做未来的预测。</p> 
<p>就说我们所有的科学活动，所有的研究活动都可以归为这三类。</p> 
<p>描述性的东西，比方说你又长胖了多少，然后又增加了多少重量。今天的体重，明天的体重等等。</p> 
<p>除此之外第二个层面是我们要看出来它们之间的相关性。比方吃的多和你长胖，它们之间是呈正相关的。还有其他的一些关系，比方说是呈负相关的等等。</p> 
<p>那我们最重要也是最难的一个科学活动是要对它进行未来的预测，对于未来的预测。这个未来它不仅是predict。</p> 
<p>比方说现在你知道的是几组数据，知道每个对应的结果。然后你看到了一组没有见过的数据，你去预测它。</p> 
<p>就好比一个孩子做题，他见过的题都能做，没见过的题他也要会做。这个其实就是属于对未来的一种预测能力。</p> 
<p>关于预测，我们最关心的预测是关于我们的身体健康，能活多久；还有就是关于挣钱的问题。</p> 
<p><img src="https://images2.imgbox.com/cf/3c/WULO3mw0_o.png" alt="Alt text"></p> 
<p>我们看一下这个例子，你的性别和你的吸烟的频率，跟一种疾病（可能是肺癌），它会有一个相对应的概率。</p> 
<p>性别不同，年龄不同，抽烟频率不同。我们会发现，得病概率随着年龄的增大并不会有多少增加，此时男性得病概率反而比女性还小。</p> 
<p>但是随着抽烟频率越多，得病概率上升的非常快。其中呢，同样的年龄和抽烟频率下，男性得病的概率则会更高。</p> 
<p>假设存在一个人p，男性，年龄是72岁，他每天抽三根：P{age:72, sex: male, rate: 3/day}。那他得这种病的概率大约是多少？那我们就先在图上随意画一个，假如说就如图的位置一样的概率：</p> 
<p><img src="https://images2.imgbox.com/b9/87/yxLeWtOZ_o.png" alt="Alt text"></p> 
<p>那么这个概率到底是多少？我们就需要用到数据去做预测，此时我们就得去做个拟合。</p> 
<p>除此之外，我们再来看BMI，也就是身体指数。身体指数就是体重除以身高的平方：BMI = kg/h^2，越大就表示你越胖。</p> 
<p><img src="https://images2.imgbox.com/b7/64/HmQnrExb_o.png" alt="Alt text"></p> 
<p>当你到某一个值的时候，可以看到得病的概率。</p> 
<p>我们假设有一个人180斤，身高一米73，我们来预测他得肾病的概率是多少。这个时候我们还是需要去做预测。</p> 
<h3><a id="_142"></a>波士顿房价预测</h3> 
<p>现在就来看一个非常经典的预测案例：波士顿房价案例。这个波士顿房价的数据，我们曾经在机器学习的线性回归里有用到，不知道小伙伴们有没有去看过。</p> 
<p>波士顿地区是在美国东北部，房地产的价钱也比较稳定，那这个数据也是比较老的数据了，通过这些数据来考察，希望机器能够根据输入的内容来预测它的房价。</p> 
<p>现在就以波士顿房价问题为例，来讲讲计算机怎么去预测。然后在预测的过程中我们来讲解实现深度学习的原理。最终把它封装成我们所需要的一个深度学习框架。</p> 
<p>第一步自然是加载和分析数据。</p> 
<p>之前的课程我提到过，这个数据由于一些原因，sklearn的datasets中已经删除了，那我们要想加载数据，就需要用到其中的fetch_openml：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_openml

dataset <span class="token operator">=</span> fetch_openml<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'boston'</span><span class="token punctuation">,</span> version<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> as_frame<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_X_y<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> parser<span class="token operator">=</span><span class="token string">'pandas'</span><span class="token punctuation">)</span>
</code></pre> 
<p>在我们第一次获取到这个数据不知道怎么处理的时候，我们可以使用dir来看看这个数据里面的内容：</p> 
<pre><code class="prism language-python"><span class="token builtin">dir</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token punctuation">[</span><span class="token string">'DESCR'</span><span class="token punctuation">,</span> <span class="token string">'categories'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'details'</span><span class="token punctuation">,</span> <span class="token string">'feature_names'</span><span class="token punctuation">,</span> <span class="token string">'frame'</span><span class="token punctuation">,</span> <span class="token string">'target'</span><span class="token punctuation">,</span> <span class="token string">'target_names'</span><span class="token punctuation">,</span> <span class="token string">'url'</span><span class="token punctuation">]</span>
</code></pre> 
<p>我们看到这个dataset里有一个<code>feature_names</code>，直觉上这个应该是一些特征名称，我们来查看一下这个的内容：</p> 
<pre><code class="prism language-python">dataset<span class="token punctuation">[</span><span class="token string">'feature_names'</span><span class="token punctuation">]</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token punctuation">[</span><span class="token string">'CRIM'</span><span class="token punctuation">,</span> <span class="token string">'ZN'</span><span class="token punctuation">,</span> <span class="token string">'INDUS'</span><span class="token punctuation">,</span> <span class="token string">'CHAS'</span><span class="token punctuation">,</span> <span class="token string">'NOX'</span><span class="token punctuation">,</span> <span class="token string">'RM'</span><span class="token punctuation">,</span> <span class="token string">'AGE'</span><span class="token punctuation">,</span> <span class="token string">'DIS'</span><span class="token punctuation">,</span> <span class="token string">'RAD'</span><span class="token punctuation">,</span> <span class="token string">'TAX'</span><span class="token punctuation">,</span> <span class="token string">'PTRATIO'</span><span class="token punctuation">,</span> <span class="token string">'B'</span><span class="token punctuation">,</span> <span class="token string">'LSTAT'</span><span class="token punctuation">]</span>
</code></pre> 
<p>这里要说明一下，因为我是用的Jupyter，所以我可以这样直接打印出变量的具体内容，如果小伙伴们不是在Jupyter里，而是在Python文件中去编写代码，不要忘了使用<code>print</code>函数。</p> 
<p>在拿到数据之后，我们先来定义一下问题。 就是假设你现在要买一个房子，那么你就要根据他的这个房子的相关数据，来判断这个房子到底应该能卖到多少钱。所以我们的任务就是给定一组房屋的数据，然后要能够预测售价是多少。</p> 
<p>定义完问题之后，我们来分析一下数据。</p> 
<p>首先，要做数据,我们会先把它装载到一个表格里边。这里，我们使用Pandas。</p> 
<p>Pandas在Python基础课里我有详细的讲过，它是做数据科学非常常用的一个东西。不要把它认为是熊猫啊，它是panel data set的缩写，就是「面板数据集」，可以理解为一个Excel。可是它比Excel更方便编程。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span>
dataframe <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataframe<span class="token punctuation">)</span><span class="token punctuation">)</span>
dataframe<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>为了节省篇幅，打印结果我就不贴出来了。</p> 
</blockquote> 
<p>有的小伙伴在处理这里<code>data</code>的时候，会发现头部没有特征名，会呈现1， 2， 3， 4这样的数字。我们就需要将名称给它加上，之前我们说过，feature_name是特征名，于是：</p> 
<pre><code class="prism language-python">dataframe<span class="token punctuation">.</span>columns <span class="token operator">=</span> dataset<span class="token punctuation">[</span>'feature_names<span class="token punctuation">]</span>
</code></pre> 
<p>这个时候我们就能看出来每一个特征到底是什么。不过这组数据里因为只是特征数据，并没有相关的价格。价格原本是目标数据，也就是最初始数据里的<code>target</code>，所以我们这里给这组特征数据里加上一列。</p> 
<pre><code class="prism language-python">dataframe<span class="token punctuation">[</span><span class="token string">'price'</span><span class="token punctuation">]</span> <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">'target'</span><span class="token punctuation">]</span>
</code></pre> 
<p>然后我们要想看看到底什么因素对房价的影响是最大的。「What’s the most significant（salient） feature of the house price」。</p> 
<p>对于决定一个东西最重要的特征我们就叫做significant，或者silence，显著特征。</p> 
<p>在pandas里边有一个很简单的东西，<code>correlation</code>。correlation就是两组变量的相关性。</p> 
<p>关于特征相关性，我们在机器学习里面有详细的讲过，这里我们就粗略带过就行了，在使用<code>corr()</code>找到特征之间的相关性数据之后，可以使用seaborn来将热图可视化出来：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns

sns<span class="token punctuation">.</span>heatmap<span class="token punctuation">(</span>dataframe<span class="token punctuation">.</span>corr<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/66/e4/dqK9Vdy4_o.png" alt="Alt text"></p> 
<p>这里我们着重来看和价格相关的特征，除了它本身之外，正相关性最大的就是RM，负相关性最大的是LSTAT。</p> 
<p>我们来看一下这两个特征的说明：</p> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">'DESCR'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
RM       average number of rooms per dwelling
LSTAT    <span class="token operator">%</span> lower status of the population
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> 
<p>RM是一套住宅的房间数量，一个是低收入人群的人口比例。也就是说，房间越多的房子越贵，小区内低收入人群的比例越低，小区内的房子越贵。那小区内低收入人群的比例居然比犯罪率的影响还要大一些，似乎有点让人难以接受，但是这个确实是事实。</p> 
<p>基于以上分析，我们需要把房屋里边卧室的个数和房屋价格最成正相关。</p> 
<p>把问题简单化：如何依据房屋里边卧室的数量来估计房子的面积?</p> 
<p>在一九七几年的时候啊, 当时有过这样一种想法，首先，我们将所有的RM数据存下来, 还有目标数据，也就是price也存下来：</p> 
<pre><code class="prism language-python">X_rm <span class="token operator">=</span> dataframe<span class="token punctuation">[</span><span class="token string">'RM'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values
y <span class="token operator">=</span> dataframe<span class="token punctuation">[</span><span class="token string">'price'</span><span class="token punctuation">]</span>
</code></pre> 
<p>存下来之后我们把做一个字典映射：</p> 
<pre><code class="prism language-python">rm_to_price <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>r<span class="token punctuation">:</span> y <span class="token keyword">for</span> r<span class="token punctuation">,</span> y <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>X_rm<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">}</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token punctuation">{<!-- --></span><span class="token number">6.575</span><span class="token punctuation">:</span> <span class="token number">24.0</span><span class="token punctuation">,</span>
 <span class="token number">6.421</span><span class="token punctuation">:</span> <span class="token number">21.6</span><span class="token punctuation">,</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token number">6.976</span><span class="token punctuation">:</span> <span class="token number">23.9</span><span class="token punctuation">}</span>
</code></pre> 
<p>这样之后，问题也就相应的做了一个简化。假如有人在销售那里要求买房子，那销售就可以拿出一个字典，里面都是这样的对应关系，然后我们就可以去查一下就知道了。</p> 
<p>这个时候假如有人告诉你有一个小区，他平均里边房屋平均是6.421。那一查就发现这个6.421的基本上卖21万。那如果小区里房屋数量是5.57的时候我卖多少钱？卖13万。这都是一一对应的关系。</p> 
<pre><code class="prism language-python">rm_to_price<span class="token punctuation">[</span><span class="token number">6.421</span><span class="token punctuation">]</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token number">21.6</span>
</code></pre> 
<p>不过这个时候有一个人说我们那个小区里面平均是7个房间，那是多少呢？我们发现，我们的字典里没有超过7的数字，也就是没有这么一个对应关系。</p> 
<p>那么找不到的时候怎么办呢？我们大部分时候解决问题都会找一个近似值，也就是最接近的数据来做参考。也可以根据以前的数据来做计算， 其实也就是一句话的事：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">find_price_by_simila</span><span class="token punctuation">(</span>history_price<span class="token punctuation">,</span> query_x<span class="token punctuation">,</span> topn<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">[</span>p <span class="token keyword">for</span> x<span class="token punctuation">,</span> p <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>history_price<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x_y<span class="token punctuation">:</span> <span class="token punctuation">(</span>x_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> query_x<span class="token punctuation">)</span> <span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span>topn<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

</code></pre> 
<p>要根据以前的数据来做计算的话，我们定义了一个方法，传入了参数历史价格以及查询特征。然后我们返回的内容稍微有点复杂，首先给这个房屋进行排序，排序依据是按照x和query之间的距离来给他排序。排序的时候我们取最接近的这几个数字，这样就能够得到最接近的x和y。然后在x和y里面我们取它的price，这就是最接近的price。</p> 
<p>然后我们来看看它给咱们算的如果房间数是7的情况是什么价格：</p> 
<pre><code class="prism language-python">find_price_by_simila<span class="token punctuation">(</span>rm_to_price<span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token number">29.233333333333334</span>
</code></pre> 
<p>关于排序那里看不懂的小伙伴，我们这里额外花点篇幅开个小灶。这样，假如说我们有下面一组数据：</p> 
<pre><code class="prism language-python">person_and_age <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'A张学友'</span><span class="token punctuation">:</span> <span class="token number">62</span><span class="token punctuation">,</span>
    <span class="token string">'C周杰伦'</span><span class="token punctuation">:</span> <span class="token number">44</span><span class="token punctuation">,</span>
    <span class="token string">'B毛不易'</span><span class="token punctuation">:</span> <span class="token number">29</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>然后我们将这组数据改成列表并进行排序：</p> 
<pre><code class="prism language-python">l <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>person_and_age<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token builtin">sorted</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'A张学友'</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'B毛不易'</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'C周杰伦'</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<p>我们可以看到它是按照数据的首字母进行排序的，可是这个时候我们不想以首字母来排序，而是想根据年龄大小进行排序该怎么办？这个时候我们就可以给排序方法的key里面定规则，这个规则就是按照元素的第二个下标进行排序。</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">get_first_items</span><span class="token punctuation">(</span>element<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> element<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token builtin">sorted</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span> key<span class="token operator">=</span>get_first_items<span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'B毛不易'</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'C周杰伦'</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'A张学友'</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<p>我们这里定义了一个函数<code>get_first_items</code>, 其实做了一件很简单的事情，就是获得了<code>element</code>的第二个下标。</p> 
<p>那么这里我们其实可以不用这样定义函数，而是直接用匿名函数。关于匿名函数，我在Python基础课里也有详细的讲到，大家可以回头去翻看一下。</p> 
<pre><code class="prism language-python"><span class="token builtin">sorted</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> element<span class="token punctuation">:</span> element<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>那其实，element是一个输入参数，是一个变量，所以我们完全可以就简写一下就行：</p> 
<pre><code class="prism language-python"><span class="token builtin">sorted</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> e<span class="token punctuation">:</span> e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>然后我们再在后面多加一个切片操作：</p> 
<pre><code class="prism language-python"><span class="token builtin">sorted</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> e<span class="token punctuation">:</span> e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'A张学友'</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'C周杰伦'</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<p>不用在意那个<code>reverse=True</code>, 只是打开了反向排序，因为个人情感上不想去掉<code>张学友</code>。</p> 
<p>好，那这个时候呢我们在前面加一个<code>for</code>，就可以拿到名字和age，而我们只需要age:</p> 
<pre><code class="prism language-python"><span class="token punctuation">[</span>age <span class="token keyword">for</span> name<span class="token punctuation">,</span> age <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> e<span class="token punctuation">:</span> e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token punctuation">[</span><span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">]</span>
</code></pre> 
<p>这样我们就可以只取两个排序最靠前的年龄值，当然最后，就是<code>mean</code>，取平均值。</p> 
<pre><code class="prism language-python">np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">[</span>age <span class="token keyword">for</span> name<span class="token punctuation">,</span> age <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> e<span class="token punctuation">:</span> e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token number">53.0</span>
</code></pre> 
<p>那我们之前所写的函数内容就是这样一段话，拆解之后是不是就能明白了？</p> 
<p>那么刚才讲到的这种方法，你会发现它是在找相似的东西，其实我们定义的这种方法，后来给它起个名字叫做：发现K个最相近的邻居，<code>K-Neighbor-Nearest</code>, 简称<code>KNN</code>。</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">knn</span><span class="token punctuation">(</span>history_price<span class="token punctuation">,</span> query_x<span class="token punctuation">,</span> topn<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">[</span>p <span class="token keyword">for</span> x<span class="token punctuation">,</span> p <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>history_price<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x_y<span class="token punctuation">:</span> <span class="token punctuation">(</span>x_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> query_x<span class="token punctuation">)</span> <span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span>topn<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>这种算法之前机器学习的章节里咱们也详细讲过，这是一个非常经典的机器学习算法。关于KNN的有优点和缺点，我们之前也讲的很详细。那大家可以回过头取看我关于机器学习KNN的部分来学习，这里就不再继续赘述KNN的内容了，在这里，我们就了解之前我们所做的这么多内容，其实就是KNN，就可以了。</p> 
<p>好，那这节课的内容就到这里，下一节课，咱们会继续写这一篇未完成的代码，来找到X_rm和y之间的函数关系。那么代码文件就依然还是<code>18.ipynb</code>。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8d0aca3fefc2ae111c3df352cbe8ac2b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43;之List容器</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/84811d6ccdadd6a1f6df32218ec6fc3b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">桌面远程连接</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>