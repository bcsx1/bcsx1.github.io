<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】数据挖掘实战-信用卡欺诈建模全流程！ - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【机器学习】数据挖掘实战-信用卡欺诈建模全流程！" />
<meta property="og:description" content="公众号：尤而小屋
作者：Peter
编辑：Peter
今天给大家分享一篇关于机器学习建模实战的文章：基于机器学习树模型的信用卡欺诈检测。
导入库 首先导入建模所需要的各种库，包含：可视化、数据预处理、特征工作、模型评估等
In [2]:
import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline plt.rcParams[&#34;font.sans-serif&#34;]=[&#34;SimHei&#34;] #设置字体 plt.rcParams[&#34;axes.unicode_minus&#34;]=False #正常显示负号 import plotly.graph_objs as go import plotly.figure_factory as ff from plotly import tools from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot init_notebook_mode(connected=True) import gc from datetime import datetime from sklearn.model_selection import train_test_split from sklearn.model_selection import KFold from sklearn.metrics import roc_auc_score from sklearn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/0519bf93a8b629248636825669d27c75/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-29T11:23:01+08:00" />
<meta property="article:modified_time" content="2023-06-29T11:23:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】数据挖掘实战-信用卡欺诈建模全流程！</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <blockquote> 
  <p>公众号：尤而小屋<br>作者：Peter<br>编辑：Peter</p> 
 </blockquote> 
 <p>今天给大家分享一篇关于机器学习建模实战的文章：<strong>基于机器学习树模型的信用卡欺诈检测。</strong></p> 
 <h3>导入库</h3> 
 <p>首先导入建模所需要的各种库，包含：可视化、数据预处理、特征工作、模型评估等</p> 
 <p>In [2]:</p> 
 <pre class="has"><code class="language-go">import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline 

plt.rcParams["font.sans-serif"]=["SimHei"] #设置字体
plt.rcParams["axes.unicode_minus"]=False #正常显示负号

import plotly.graph_objs as go
import plotly.figure_factory as ff
from plotly import tools
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
init_notebook_mode(connected=True)

import gc
from datetime import datetime 
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from catboost import CatBoostClassifier
from sklearn import svm
import lightgbm as lgb
from lightgbm import LGBMClassifier
import xgboost as xgb

import warnings
warnings.filterwarnings("ignore")</code></pre> 
 <h3>导入数据</h3> 
 <h4>数据基本信息</h4> 
 <p>In [3]:</p> 
 <pre class="has"><code class="language-go">df = pd.read_csv("creditcard.csv")
df.head()</code></pre> 
 <p>Out[3]:</p> 
 <p>1、整体的数据量：</p> 
 <p>In [4]:</p> 
 <pre class="has"><code class="language-go">df.shape</code></pre> 
 <p>Out[4]:</p> 
 <pre class="has"><code class="language-go">(284807, 31)</code></pre> 
 <p>2、数据的字段类型：</p> 
 <p>In [5]:</p> 
 <pre class="has"><code class="language-go">df.dtypes</code></pre> 
 <p>Out[5]:</p> 
 <pre class="has"><code class="language-go">Time      float64
V1        float64
V2        float64
V3        float64
V4        float64
V5        float64
V6        float64
V7        float64
V8        float64
V9        float64
V10       float64
V11       float64
V12       float64
V13       float64
V14       float64
V15       float64
V16       float64
V17       float64
V18       float64
V19       float64
V20       float64
V21       float64
V22       float64
V23       float64
V24       float64
V25       float64
V26       float64
V27       float64
V28       float64
Amount    float64
Class       int64
dtype: object</code></pre> 
 <p>3、数据的描述统计信息：</p> 
 <p>In [6]:</p> 
 <pre class="has"><code class="language-go">df.describe()</code></pre> 
 <p>4、直接查看数据信息：包含字段名、非缺失值数量、字段类型、数据占用内存等信息</p> 
 <p>In [7]:</p> 
 <pre class="has"><code class="language-go">df.info()
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 284807 entries, 0 to 284806
Data columns (total 31 columns):
 #   Column  Non-Null Count   Dtype  
---  ------  --------------   -----  
 0   Time    284807 non-null  float64
 1   V1      284807 non-null  float64
 2   V2      284807 non-null  float64
 3   V3      284807 non-null  float64
 4   V4      284807 non-null  float64
 5   V5      284807 non-null  float64
 6   V6      284807 non-null  float64
 7   V7      284807 non-null  float64
 8   V8      284807 non-null  float64
 9   V9      284807 non-null  float64
 10  V10     284807 non-null  float64
 11  V11     284807 non-null  float64
 12  V12     284807 non-null  float64
 13  V13     284807 non-null  float64
 14  V14     284807 non-null  float64
 15  V15     284807 non-null  float64
 16  V16     284807 non-null  float64
 17  V17     284807 non-null  float64
 18  V18     284807 non-null  float64
 19  V19     284807 non-null  float64
 20  V20     284807 non-null  float64
 21  V21     284807 non-null  float64
 22  V22     284807 non-null  float64
 23  V23     284807 non-null  float64
 24  V24     284807 non-null  float64
 25  V25     284807 non-null  float64
 26  V26     284807 non-null  float64
 27  V27     284807 non-null  float64
 28  V28     284807 non-null  float64
 29  Amount  284807 non-null  float64
 30  Class   284807 non-null  int64  
dtypes: float64(30), int64(1)
memory usage: 67.4 MB</code></pre> 
 <h4>缺失值情况</h4> 
 <p>In [8]:</p> 
 <pre class="has"><code class="language-go">df.isnull().sum()</code></pre> 
 <p>Out[8]:</p> 
 <pre class="has"><code class="language-go">Time      0
V1        0
V2        0
V3        0
V4        0
V5        0
V6        0
V7        0
V8        0
V9        0
V10       0
V11       0
V12       0
V13       0
V14       0
V15       0
V16       0
V17       0
V18       0
V19       0
V20       0
V21       0
V22       0
V23       0
V24       0
V25       0
V26       0
V27       0
V28       0
Amount    0
Class     0
dtype: int64</code></pre> 
 <p>In [9]:</p> 
 <pre class="has"><code class="language-go">total = df.isnull().sum().sort_values(ascending = False)

percent = (df.isnull().sum()/df.isnull().count() * 100).sort_values(ascending = False)

pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])</code></pre> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/8e/f1/qYeO93fa_o.png" alt="bc91ccc869d9074aa13dce047cadf0ee.png"></p> 
 <p>结果表明：本次数据中没有缺失值的。</p> 
 <h4>数据不均衡性</h4> 
 <p>本次数据有一个突出的特点：就是极其不均衡。我们查看目标变量Class中不同取值的情况：</p> 
 <p>In [10]:</p> 
 <pre class="has"><code class="language-go">sns.countplot(df["Class"])

plt.show()</code></pre> 
 <img src="https://images2.imgbox.com/7d/b9/PGVmgGFQ_o.png" alt="86232e14915792e87c2af1d9cfad6cbd.png"> 
 <p>基于plotly库的写法：</p> 
 <p>In [11]:</p> 
 <pre class="has"><code class="language-go">df["Class"].value_counts().to_frame()</code></pre> 
 <p>Out[11]:</p> 
 <table><thead><tr><th><br></th><th>Class</th></tr></thead><tbody><tr><td>0</td><td>284315</td></tr><tr><td>1</td><td>492</td></tr></tbody></table> 
 <p>In [12]:</p> 
 <pre class="has"><code class="language-go">df_class = df["Class"].value_counts().to_frame()</code></pre> 
 <p>In [13]:</p> 
 <pre class="has"><code class="language-go">trace = go.Bar(
    x = df_class.index.tolist(),
    y = df_class.Class.tolist(),
    name = "数据不均衡性对比 (Not fraud = 0, Fraud = 1)",
    marker = dict(color="Red"),
    text = df_class["Class"].tolist()
)

data = [trace]


layout = dict(title = "数据不均衡性对比 (Not fraud = 0, Fraud = 1)",
              xaxis = dict(title="Class", showticklabels=True),
              yaxis = dict(title="Number", showticklabels=True),
              hovermode = "closest",
              width=600
             )


fig = dict(data=data, layout=layout)

iplot(fig, filename='class')</code></pre> 
 <img src="https://images2.imgbox.com/1c/ee/oJLSDMCG_o.png" alt="ed8cfa4b379d0f52baeadab51479d94b.png"> 
 <h3>数据EDA</h3> 
 <h4>Time</h4> 
 <p>单独取出Class为0或者1的数据：</p> 
 <p>In [14]:</p> 
 <pre class="has"><code class="language-go">class_0 = df[df["Class"] == 0]["Time"]  # not fraud
class_1 = df[df["Class"] == 1]["Time"]  # fraud</code></pre> 
 <p>In [15]:</p> 
 <pre class="has"><code class="language-go">hist_data = [class_0, class_1]
group_labels = ['Not Fraud', 'Fraud']</code></pre> 
 <p>In [16]:</p> 
 <pre class="has"><code class="language-go">fig = ff.create_distplot(hist_data, 
                         group_labels, 
                         show_hist=False, 
                         show_rug=False)


fig['layout'].update(title='Credit Card Transactions Time Density Plot', 
                     xaxis=dict(title='Time [s]'))

iplot(fig)</code></pre> 
 <img src="https://images2.imgbox.com/c5/46/flYEEcrF_o.png" alt="cb0c71e33f14ea4320a39812422790c7.png"> 
 <p>基于不同时间频率下的交易金额统计：</p> 
 <p>In [17]:</p> 
 <pre class="has"><code class="language-go">df["Hour"] = df["Time"].apply(lambda x: np.floor(x / 3600))  # 时间转成小时</code></pre> 
 <p>基于小时Hour和Class的聚合统计：</p> 
 <p>In [18]:</p> 
 <pre class="has"><code class="language-go">tmp = df.groupby(['Hour', 'Class'])['Amount'].aggregate(['min', 'max', 'count', 'sum', 'mean', 'median', 'var']).reset_index()
tmp.head()</code></pre> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/58/02/ZGGTEpeZ_o.png" alt="88246ead3803cb8c5d7c701259c16fdd.png"></p> 
 <p>对字段的重命名操作：</p> 
 <p>In [19]:</p> 
 <pre class="has"><code class="language-go"># 重命名
tmp.columns = ["Hour", "Class", "Min", "Max", "Transactions", "Sum", "Mean", "Median", "Var"]</code></pre> 
 <h5>总和sum对比</h5> 
 <p>1、欺诈或非欺诈的总和对比：</p> 
 <p>In [20]:</p> 
 <pre class="has"><code class="language-go">fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))

s = sns.lineplot(ax=ax1, x="Hour", y="Sum", data=tmp.loc[tmp.Class==0])
s = sns.lineplot(ax=ax2, x="Hour", y="Sum", data=tmp.loc[tmp.Class==1],color="red")

plt.suptitle("Total Amount/Hour")
plt.show()</code></pre> 
 <h5><img src="https://images2.imgbox.com/7c/59/fFzOzCEA_o.png" alt="a02adf9f7ede4d4b773b055e00c00d9c.png"></h5> 
 <h5>次数count对比</h5> 
 <p>In [21]:</p> 
 <pre class="has"><code class="language-go">fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))

s = sns.lineplot(ax=ax1, x="Hour", y="Transactions", data=tmp.loc[tmp.Class==0])
s = sns.lineplot(ax=ax2, x="Hour", y="Transactions", data=tmp.loc[tmp.Class==1],color="blue")

plt.suptitle("Transactions/Hour")
plt.show()</code></pre> 
 <h5><img src="https://images2.imgbox.com/a4/f7/IHq89nA1_o.png" alt="4e3f2e7d303ef475b622434a71320d79.png"></h5> 
 <h5>均值mean对比</h5> 
 <p>In [22]:</p> 
 <pre class="has"><code class="language-go">fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))

s = sns.lineplot(ax=ax1, x="Hour", y="Mean", data=tmp.loc[tmp.Class==0])
s = sns.lineplot(ax=ax2, x="Hour", y="Mean", data=tmp.loc[tmp.Class==1],color="blue")

plt.suptitle("Mean/Hour")
plt.show()</code></pre> 
 <h5><img src="https://images2.imgbox.com/a4/4a/pOJd3UkR_o.png" alt="fe57cfe2bd8b99d256c434036efcf9a0.png"></h5> 
 <h5>最大值max对比</h5> 
 <p>In [23]:</p> 
 <pre class="has"><code class="language-go">fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))

s = sns.lineplot(ax=ax1, x="Hour", y="Max", data=tmp.loc[tmp.Class==0])
s = sns.lineplot(ax=ax2, x="Hour", y="Max", data=tmp.loc[tmp.Class==1],color="red")

plt.suptitle("Max/Hour")
plt.show()</code></pre> 
 <h5><img src="https://images2.imgbox.com/a2/f7/mVXVUsy6_o.png" alt="bb7621abb07d94e25f248bd172545f19.png"></h5> 
 <h5>最小值Min对比</h5> 
 <p>In [24]:</p> 
 <pre class="has"><code class="language-go">fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))

s = sns.lineplot(ax=ax1, x="Hour", y="Min", data=tmp.loc[tmp.Class==0])
s = sns.lineplot(ax=ax2, x="Hour", y="Min", data=tmp.loc[tmp.Class==1],color="red")

plt.suptitle("Min/Hour")
plt.show()</code></pre> 
 <h5><img src="https://images2.imgbox.com/40/2d/MQYjUXgb_o.png" alt="c0ee7fa7e49eb472821d54e92e43bf0a.png"></h5> 
 <h5>中位数median对比</h5> 
 <p>In [25]:</p> 
 <pre class="has"><code class="language-go">fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))

s = sns.lineplot(ax=ax1, x="Hour", y="Median", data=tmp.loc[tmp.Class==0])
s = sns.lineplot(ax=ax2, x="Hour", y="Median", data=tmp.loc[tmp.Class==1],color="red")

plt.suptitle("Median/Hour")
plt.show()</code></pre> 
 <h3><img src="https://images2.imgbox.com/5f/fc/WjDDntrK_o.png" alt="6f49cdf8ca763b050eae884d7b369e46.png"></h3> 
 <h3>Amount对比</h3> 
 <p>In [26]:</p> 
 <pre class="has"><code class="language-go">fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))

s = sns.boxplot(ax = ax1, x="Class", y="Amount", hue="Class", data=df, palette="PRGn",showfliers=True)
s = sns.boxplot(ax = ax2, x="Class", y="Amount", hue="Class", data=df, palette="PRGn",showfliers=False)

plt.show()</code></pre> 
 <p><img src="https://images2.imgbox.com/2d/ee/oUMzii4y_o.png" alt="2e5d4d79bf1e4b833a1963b350d4e32c.png"></p> 
 <p>欺诈或者非欺诈情况下Amount的描述统计信息对比：</p> 
 <p>In [27]:</p> 
 <pre class="has"><code class="language-go">df_copy = df[["Amount","Class"]].copy()
             
df_0 = df_copy[df_copy["Class"]==0]["Amount"]
df_1 = df_copy[df_copy["Class"]==1]["Amount"]</code></pre> 
 <p>In [28]:</p> 
 <pre class="has"><code class="language-go">df_0.describe()</code></pre> 
 <p>Out[28]:</p> 
 <pre class="has"><code class="language-go">count    284315.000000
mean         88.291022
std         250.105092
min           0.000000
25%           5.650000
50%          22.000000
75%          77.050000
max       25691.160000
Name: Amount, dtype: float64</code></pre> 
 <p>In [29]:</p> 
 <pre class="has"><code class="language-go">df_1.describe()</code></pre> 
 <p>Out[29]:</p> 
 <pre class="has"><code class="language-go">count     492.000000
mean      122.211321
std       256.683288
min         0.000000
25%         1.000000
50%         9.250000
75%       105.890000
max      2125.870000
Name: Amount, dtype: float64</code></pre> 
 <p>欺诈情况下的数据分布：</p> 
 <p>In [30]:</p> 
 <pre class="has"><code class="language-go">fraud = df[df["Class"]==1]  # 欺诈</code></pre> 
 <p>In [31]:</p> 
 <pre class="has"><code class="language-go">fig = go.Figure(data=go.Scatter(x = fraud['Time'],
                                y = fraud['Amount'],
                                name = "Amount",
                                marker=dict(
                                    color='rgb(238,23,11)',
                                    line=dict(color='red',width=1),opacity=0.5,),
                               text= fraud['Amount'],
                               mode = "markers"
                               ))

fig.update_layout(dict(title = 'Amount of Fraud',
                       xaxis = dict(title = 'Time [s]', 
                                    showticklabels=True), 
                       yaxis = dict(title = 'Amount'),
                       hovermode='closest'))


fig.show()</code></pre> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/62/a2/J5VHLdw5_o.png" alt="2d041959e6eec2610fd6df029e3ed064.png"></p> 
 <h3>特征相关性分析</h3> 
 <h4>相关性热力图</h4> 
 <p>In [32]:</p> 
 <pre class="has"><code class="language-go">corr = df.corr()</code></pre> 
 <p>In [33]:</p> 
 <pre class="has"><code class="language-go">plt.figure(figsize = (12,8))
sns.heatmap(corr,  # corr = df.corr()  
            xticklabels=corr.columns,
            yticklabels=corr.columns,
            linewidths=.02,
            cmap="YlGnBu")

plt.title('Credit Card Transactions features correlation plot (Pearson)')
plt.show()</code></pre> 
 <h4><img src="https://images2.imgbox.com/17/eb/82kfFrql_o.png" alt="43956c3e6ac7a6c0ab3bfb8a29c638ad.png"></h4> 
 <h4>特征两两关系</h4> 
 <p>可以看到特征之间没有明显的相关性。但是一些特征和时间Time（和V3负相关）或者总额Amount（V7和V20直接相关）具有一定的关系。</p> 
 <p>探索V7和V20与Amount的关系：</p> 
 <p>In [34]:</p> 
 <pre class="has"><code class="language-go">s = sns.lmplot(x='V20', 
               y='Amount',
               data=df,
               hue='Class', 
               fit_reg=True,
               scatter_kws={'s':2})

s = sns.lmplot(x='V7', 
               y='Amount',
               data=df,
               hue='Class', 
               fit_reg=True,
               scatter_kws={'s':2})
plt.show()</code></pre> 
 <p><img src="https://images2.imgbox.com/d9/bb/x6FKQmHr_o.png" alt="b1d372980a3b326363265e0705ea553e.png"></p> 
 <p>从结果中观察到：Class=0具有一定的回归斜率；而Class=1的斜率不是很明显。</p> 
 <p>下面绘制的是具有反相关的特征和Amount的关系图：</p> 
 <p>In [35]:</p> 
 <pre class="has"><code class="language-go">s = sns.lmplot(x='V2', 
               y='Amount',
               data=df,
               hue='Class', 
               fit_reg=True,
               scatter_kws={'s': 2})

s = sns.lmplot(x='V5', 
               y='Amount',
               data=df,
               hue='Class', 
               fit_reg=True,
               scatter_kws={'s': 2})

plt.show()</code></pre> 
 <p><img src="https://images2.imgbox.com/86/d4/no1oBHq4_o.png" alt="764af0a4cf88ecae093a87fdd016f203.png"></p> 
 <p>同样的结论：在Class=0的时候负相关性明显。</p> 
 <h4>特征分布密度图</h4> 
 <p>In [36]:</p> 
 <pre class="has"><code class="language-go">columns = df.columns.values
columns</code></pre> 
 <p>Out[36]:</p> 
 <pre class="has"><code class="language-go">array(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9',
       'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',
       'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27',
       'V28', 'Amount', 'Class', 'Hour'], dtype=object)</code></pre> 
 <p>In [37]:</p> 
 <pre class="has"><code class="language-go">i = 0

t0 = df[df["Class"] == 0]
t1 = df[df["Class"] == 1]

sns.set_style("whitegrid")
plt.figure()

fig, ax = plt.subplots(8,4,figsize=(12,20))

for column in columns:
    i += 1
    plt.subplot(8,4,i)
    sns.kdeplot(t0[column], bw=0.5, label="Class = 0")
    sns.kdeplot(t1[column], bw=0.5, label="Class = 1")
    
    plt.xlabel(column, fontsize=12)
    locs, labels = plt.xticks()
    plt.tick_params(axis='both', which='major', labelsize=12)

plt.show()</code></pre> 
 <p><img src="https://images2.imgbox.com/aa/fc/JMCnMXPl_o.png" alt="cc53fa34e5b4cd86c42df6f666eb1df6.png"></p> 
 <p>可以看到，部分特征有下面的特点：</p> 
 <ol><li><p>V4和V11在Class=0或者1的情况下，分离性很好</p></li><li><p>V12、V14、V18 有部分分离</p></li><li><p>V25、V26、V28具有接近相同的数据分布</p></li></ol> 
 <h3>建模</h3> 
 <h4>目标和变量</h4> 
 <p>定义预测目标变量和特征：</p> 
 <p>In [38]:</p> 
 <pre class="has"><code class="language-go"># 目标
target = 'Class'   
# 特征
features = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7',
            'V8', 'V9', 'V10','V11', 'V12', 'V13', 'V14','V15', 
            'V16', 'V17', 'V18', 'V19','V20', 'V21', 'V22', 
            'V23', 'V24', 'V25', 'V26', 'V27', 'V28','Amount']</code></pre> 
 <h4>切分数据</h4> 
 <p>先切分训练集和测试集：</p> 
 <p>In [39]:</p> 
 <pre class="has"><code class="language-go">TEST_SIZE = 0.20  # 测试集比例
RANDOM_STATE = 2023 # 随机种子

train_df, test_df = train_test_split(df, 
                                     test_size=TEST_SIZE, 
                                     random_state=RANDOM_STATE, 
                                     shuffle=True )</code></pre> 
 <p>再切分验证集：</p> 
 <p>In [40]:</p> 
 <pre class="has"><code class="language-go">VALID_SIZE = 0.20  # 验证集比例

train_df, valid_df = train_test_split(train_df, 
                                      test_size=VALID_SIZE, 
                                      random_state=RANDOM_STATE, 
                                      shuffle=True )</code></pre> 
 <h4>RandomForestClassifier</h4> 
 <h5>模型训练与预测</h5> 
 <p>基于随机森林建模；树模型不需要数据的归一化操作：</p> 
 <p>In [41]:</p> 
 <pre class="has"><code class="language-go"># rf
RFC_METRIC = 'gini'  
NUM_ESTIMATORS = 100 
NO_JOBS = 4</code></pre> 
 <p>In [42]:</p> 
 <pre class="has"><code class="language-go">clf = RandomForestClassifier(n_jobs=NO_JOBS,  # 4
                             random_state=RANDOM_STATE, # 2023
                             criterion=RFC_METRIC, # 评估指标
                             n_estimators=NUM_ESTIMATORS,  # 评估器个数
                             verbose=False)</code></pre> 
 <p>实施模型训练：</p> 
 <p>In [43]:</p> 
 <pre class="has"><code class="language-go">clf.fit(train_df[features], train_df[target].values)</code></pre> 
 <p>Out[43]:</p> 
 <pre class="has"><code class="language-go">RandomForestClassifier(n_jobs=4, random_state=2023, verbose=False)</code></pre> 
 <p>基于clf模型对验证集valid_df的预测：</p> 
 <p>In [44]:</p> 
 <pre class="has"><code class="language-go">valid_pred = clf.predict(valid_df[features])
valid_pred</code></pre> 
 <p>Out[44]:</p> 
 <pre class="has"><code class="language-go">array([0, 0, 0, ..., 0, 0, 0], dtype=int64)</code></pre> 
 <h5>特征重要性</h5> 
 <p>随机森立模型的feature_importances属性可以返回特征的重要性：</p> 
 <p>In [45]:</p> 
 <pre class="has"><code class="language-go">clf.feature_importances_</code></pre> 
 <p>Out[45]:</p> 
 <pre class="has"><code class="language-go">array([0.0137962 , 0.01290299, 0.01301561, 0.0156942 , 0.03348877,
       0.01203327, 0.01123946, 0.02267493, 0.01520727, 0.03879355,
       0.08446134, 0.06249404, 0.13079459, 0.01028684, 0.13948669,
       0.0114192 , 0.05495422, 0.17256602, 0.02514331, 0.01279881,
       0.01048097, 0.01514546, 0.00886384, 0.00656329, 0.00914622,
       0.00887252, 0.01777976, 0.01047754, 0.00909545, 0.01032364])</code></pre> 
 <p>In [46]:</p> 
 <pre class="has"><code class="language-go">fi = pd.DataFrame({"Features":features,"Importance":clf.feature_importances_})
fi.head()</code></pre> 
 <p>Out[46]:</p> 
 <table><thead><tr><th><br></th><th>Features</th><th>Importance</th></tr></thead><tbody><tr><td>0</td><td>Time</td><td>0.013796</td></tr><tr><td>1</td><td>V1</td><td>0.012903</td></tr><tr><td>2</td><td>V2</td><td>0.013016</td></tr><tr><td>3</td><td>V3</td><td>0.015694</td></tr><tr><td>4</td><td>V4</td><td>0.033489</td></tr></tbody></table> 
 <p>按照重要性降序排列：</p> 
 <p>In [47]:</p> 
 <pre class="has"><code class="language-go">fi.sort_values("Importance",ascending=False,inplace=True, ignore_index=True)

fi.head(10)</code></pre> 
 <p>Out[47]:</p> 
 <table><thead><tr><th><br></th><th>Features</th><th>Importance</th></tr></thead><tbody><tr><td>0</td><td>V17</td><td>0.172566</td></tr><tr><td>1</td><td>V14</td><td>0.139487</td></tr><tr><td>2</td><td>V12</td><td>0.130795</td></tr><tr><td>3</td><td>V10</td><td>0.084461</td></tr><tr><td>4</td><td>V11</td><td>0.062494</td></tr><tr><td>5</td><td>V16</td><td>0.054954</td></tr><tr><td>6</td><td>V9</td><td>0.038794</td></tr><tr><td>7</td><td>V4</td><td>0.033489</td></tr><tr><td>8</td><td>V18</td><td>0.025143</td></tr><tr><td>9</td><td>V7</td><td>0.022675</td></tr></tbody></table> 
 <p>In [48]:</p> 
 <pre class="has"><code class="language-go">plt.figure(figsize = (7,4))

plt.title('Features Importance Based On RandomForestClassifier',fontsize=14)

s = sns.barplot(x='Features',y='Importance',data=fi)

s.set_xticklabels(s.get_xticklabels(), rotation=90)

plt.show()</code></pre> 
 <p><img src="https://images2.imgbox.com/5d/bb/yK8DsyTR_o.png" alt="164df6fbb836e3d9ec7a973e7c4fea90.png"></p> 
 <p>可以看到前5个重要的特征是：V17、V14、V12、V10、V11</p> 
 <h5>混淆矩阵</h5> 
 <p>In [49]:</p> 
 <pre class="has"><code class="language-go">cm = pd.crosstab(valid_df[target].values, valid_pred, rownames=['Actual Value'], colnames=['Predicted Value'])

fig, (ax1) = plt.subplots(ncols=1, figsize=(8,6))

sns.heatmap(cm, 
            xticklabels=['Not Fraud', 'Fraud'],
            yticklabels=['Not Fraud', 'Fraud'],
            annot=True,
            ax=ax1,
            linewidths=.2,
            linecolor="Darkblue", 
            cmap="YlGnBu_r"
           )

plt.title('Confusion Matrix Based On RandomForestClassifier', fontsize=20)
plt.show()</code></pre> 
 <p><img src="https://images2.imgbox.com/46/9e/eZXsxHQI_o.png" alt="dd72f4ac17c49ff3f3e09fa5402d6baf.png"></p> 
 <p>在分类问题中，当数据极度不均衡的时候，混淆矩阵一般不能够很好地反应结果。可以考虑一类错误或者二类错误。</p> 
 <p>我们可以考虑使用其他分类问题中的评估指标，比如：ROC-AUC</p> 
 <p>In [50]:</p> 
 <pre class="has"><code class="language-go">roc_auc_score(valid_df[target].values, valid_pred)</code></pre> 
 <p>Out[50]:</p> 
 <pre class="has"><code class="language-go">0.8909926674704323</code></pre> 
 <h4>AdaBoostClassifier</h4> 
 <p>Adaptive Boosting Classifier 表示自适应提升分类器，一种分类算法的组装方法，即将弱分类器组装成强分类器的方法。</p> 
 <h5>模型训练与预测</h5> 
 <p>In [51]:</p> 
 <pre class="has"><code class="language-go">ada = AdaBoostClassifier(random_state=RANDOM_STATE,  # 2023
                         algorithm='SAMME.R',
                         learning_rate=0.8,
                         n_estimators=NUM_ESTIMATORS  #  NUM_ESTIMATORS = 100
                        )</code></pre> 
 <p>ada模型的训练：</p> 
 <p>In [52]:</p> 
 <pre class="has"><code class="language-go">ada.fit(train_df[features], train_df[target].values)</code></pre> 
 <p>Out[52]:</p> 
 <pre class="has"><code class="language-go">AdaBoostClassifier(learning_rate=0.8, n_estimators=100, random_state=2023)</code></pre> 
 <p>In [53]:</p> 
 <pre class="has"><code class="language-go">valid_pred = ada.predict(valid_df[features])
valid_pred</code></pre> 
 <p>Out[53]:</p> 
 <pre class="has"><code class="language-go">array([0, 0, 0, ..., 0, 0, 0], dtype=int64)</code></pre> 
 <h5>特征重要性</h5> 
 <p>In [54]:</p> 
 <pre class="has"><code class="language-go">fi = pd.DataFrame({"Features":features,"Importance":ada.feature_importances_})

# 排序
fi.sort_values("Importance",ascending=False,inplace=True, ignore_index=True)</code></pre> 
 <p>In [55]:</p> 
 <pre class="has"><code class="language-go">plt.figure(figsize = (7,4))

plt.title('Features Importance Based On AdaBoostClassifier',fontsize=14)

s = sns.barplot(x='Features',y='Importance',data=fi)

s.set_xticklabels(s.get_xticklabels(), rotation=90)

plt.show()</code></pre> 
 <h5><img src="https://images2.imgbox.com/00/ad/eGCTHt81_o.png" alt="0d49b180d92c72aeca8c0288ddbca389.png"></h5> 
 <h5>混淆矩阵</h5> 
 <p>In [56]:</p> 
 <pre class="has"><code class="language-go">cm = pd.crosstab(valid_df[target].values, valid_pred, rownames=['Actual Value'], colnames=['Predicted Value'])

fig, (ax1) = plt.subplots(ncols=1, figsize=(8,6))

sns.heatmap(cm, 
            xticklabels=['Not Fraud', 'Fraud'],
            yticklabels=['Not Fraud', 'Fraud'],
            annot=True,
            ax=ax1,
            linewidths=.2,
            linecolor="Darkblue", 
            cmap="YlGnBu_r"
           )

plt.title('Confusion Matrix Based On AdaBoostClassifier', fontsize=20)

plt.show()</code></pre> 
 <p><img src="https://images2.imgbox.com/d1/c8/UmLlsGur_o.png" alt="abc15da7b81f1d15f61e35d91636ced3.png"></p> 
 <p>ROC-AUC的值：</p> 
 <p>In [57]:</p> 
 <pre class="has"><code class="language-go">roc_auc_score(valid_df[target].values, valid_pred)</code></pre> 
 <p>Out[57]:</p> 
 <pre class="has"><code class="language-go">0.9101135248505058</code></pre> 
 <h4>CatBoostClassifier</h4> 
 <p>CatBoostClassifier分类提升分类器也是一种梯度提升树，它支持处理分类型数据。</p> 
 <h5>模型训练与预测</h5> 
 <p>In [58]:</p> 
 <pre class="has"><code class="language-go">VERBOSE_EVAL = 50 

cbc = CatBoostClassifier(
        iterations=500,
        learning_rate=0.02,
        depth=12,
        eval_metric='AUC',
        random_seed = RANDOM_STATE, # 2023
        bagging_temperature = 0.2,
        od_type='Iter',
        metric_period = VERBOSE_EVAL,
        od_wait=100
)</code></pre> 
 <p>模型的训练：</p> 
 <p>In [59]:</p> 
 <pre class="has"><code class="language-go">cbc.fit(train_df[features], train_df[target].values,verbose=True)  
0: total: 510ms remaining: 4m 14s
50: total: 16.9s remaining: 2m 28s
100: total: 32.6s remaining: 2m 8s
150: total: 47.9s remaining: 1m 50s
200: total: 1m 2s remaining: 1m 33s
250: total: 1m 17s remaining: 1m 17s
300: total: 1m 33s remaining: 1m 1s
350: total: 1m 48s remaining: 45.9s
400: total: 2m 3s remaining: 30.4s
450: total: 2m 18s remaining: 15s
499: total: 2m 33s remaining: 0us</code></pre> 
 <p>Out[59]:</p> 
 <pre class="has"><code class="language-go">&lt;catboost.core.CatBoostClassifier at 0x1edb47a9190&gt;</code></pre> 
 <p>基于cbc模型对验证集进行预测：</p> 
 <p>In [60]:</p> 
 <pre class="has"><code class="language-go">valid_pred = cbc.predict(valid_df[features])
valid_pred</code></pre> 
 <p>Out[60]:</p> 
 <pre class="has"><code class="language-go">array([0, 0, 0, ..., 0, 0, 0], dtype=int64)</code></pre> 
 <h5>特征重要性</h5> 
 <p>In [61]:</p> 
 <pre class="has"><code class="language-go">fi = pd.DataFrame({"Features":features, "Importance": ada.feature_importances_})

# 排序
fi.sort_values("Importance", ascending=False, inplace=True, ignore_index=True)</code></pre> 
 <p>In [62]:</p> 
 <pre class="has"><code class="language-go">plt.figure(figsize = (7,4))

plt.title('Features Importance Based On CatBoostClassifier',fontsize=14)

s = sns.barplot(x='Features',y='Importance',data=fi)

s.set_xticklabels(s.get_xticklabels(), rotation=90)

plt.show()</code></pre> 
 <h5><img src="https://images2.imgbox.com/29/1d/2mRY60jm_o.png" alt="e5a47aee63feac4b1bcddf7377baaffe.png"></h5> 
 <h5>混淆矩阵</h5> 
 <p>In [63]:</p> 
 <pre class="has"><code class="language-go">cm = pd.crosstab(valid_df[target].values, valid_pred, rownames=['Actual Value'], colnames=['Predicted Value'])

fig, (ax1) = plt.subplots(ncols=1, figsize=(8,6))

sns.heatmap(cm, 
            xticklabels=['Not Fraud', 'Fraud'],
            yticklabels=['Not Fraud', 'Fraud'],
            annot=True,
            ax=ax1,
            linewidths=.2,
            linecolor="Darkblue", 
            cmap="YlGnBu_r"
           )

plt.title('Confusion Matrix Based On CatBoostClassifier', fontsize=20)

plt.show()</code></pre> 
 <p><img src="https://images2.imgbox.com/a8/61/LNJn2IHV_o.png" alt="3293b1c114a94d06d1f5b303aba0ae7c.png"></p> 
 <p>ROC-AUC的值：</p> 
 <p>In [64]:</p> 
 <pre class="has"><code class="language-go">roc_auc_score(valid_df[target].values, valid_pred)</code></pre> 
 <p>Out[64]:</p> 
 <pre class="has"><code class="language-go">0.9038131802909452</code></pre> 
 <h4>XGBoost</h4> 
 <p>XGBoost也是一种梯度提升树算法</p> 
 <h5>数据准备</h5> 
 <p>现将3个数据转成XGBoost模型所需要的数据格式：</p> 
 <p>In [65]:</p> 
 <pre class="has"><code class="language-go">dtrain = xgb.DMatrix(train_df[features], train_df[target].values)
dvalid = xgb.DMatrix(valid_df[features], valid_df[target].values)
dtest = xgb.DMatrix(test_df[features], test_df[target].values)</code></pre> 
 <p>In [66]:</p> 
 <pre class="has"><code class="language-go">watchlist = [(dtrain, 'train'), (dvalid, 'valid')]</code></pre> 
 <h5>设置模型参数</h5> 
 <p>In [67]:</p> 
 <pre class="has"><code class="language-go">params = {}
params['objective'] = 'binary:logistic' 
params['eta'] = 0.039
params['silent'] = True
params['max_depth'] = 2
params['subsample'] = 0.8
params['colsample_bytree'] = 0.9
params['eval_metric'] = 'auc'
params['random_state'] = RANDOM_STATE</code></pre> 
 <h5>训练模型</h5> 
 <p>In [68]:</p> 
 <pre class="has"><code class="language-go"># 部分模型的参数设置

MAX_ROUNDS = 1000 
EARLY_STOP = 50 
OPT_ROUNDS = 1000  
VERBOSE_EVAL = 50 

IS_LOCAL = False

model = xgb.train(params,  # 参数
                dtrain,  # 数据
                MAX_ROUNDS, 
                watchlist, 
                early_stopping_rounds=EARLY_STOP, 
                maximize=True, 
                verbose_eval=VERBOSE_EVAL)
[17:52:22] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\xgboost\xgboost-ci-windows\src\learner.cc:767: 
Parameters: { "silent" } are not used.

[0] train-auc:0.86720 valid-auc:0.87807
[50] train-auc:0.92560 valid-auc:0.94196
[100] train-auc:0.95528 valid-auc:0.96492
[150] train-auc:0.97618 valid-auc:0.96857
[200] train-auc:0.98831 valid-auc:0.98431
[250] train-auc:0.99199 valid-auc:0.98761
[300] train-auc:0.99412 valid-auc:0.98951
[350] train-auc:0.99587 valid-auc:0.99085
[400] train-auc:0.99689 valid-auc:0.99157
[450] train-auc:0.99772 valid-auc:0.99227
[496] train-auc:0.99828 valid-auc:0.99207</code></pre> 
 <p>可以看到最好的ROC-AUC值是99.227%。</p> 
 <h5>特征重要性</h5> 
 <p>直接使用plot_importance方法绘制</p> 
 <p>In [69]:</p> 
 <pre class="has"><code class="language-go">fig, (ax) = plt.subplots(ncols=1, figsize=(8,5))

xgb.plot_importance(model, 
                    height=0.8, 
                    title="Features importance (XGBoost)", 
                    ax=ax, 
                    color="blue") 
plt.show()</code></pre> 
 <h5><img src="https://images2.imgbox.com/3b/d2/WkSQlGaO_o.png" alt="4238e6fd7ae1967d46a8a27a1e2e93c0.png"></h5> 
 <h5>模型预测</h5> 
 <p>基于模型的预测：</p> 
 <p>In [70]:</p> 
 <pre class="has"><code class="language-go">test_pred = model.predict(dtest)
test_pred</code></pre> 
 <p>Out[70]:</p> 
 <pre class="has"><code class="language-go">array([5.2011404e-05, 2.5495124e-04, 1.5237682e-03, ..., 1.2446250e-04,
       2.0297051e-03, 9.4309878e-05], dtype=float32)</code></pre> 
 <p>基于模型对测试集计算ROC-AUC值：</p> 
 <p>In [71]:</p> 
 <pre class="has"><code class="language-go">roc_auc_score(test_df[target].values, test_pred)</code></pre> 
 <p>Out[71]:</p> 
 <pre class="has"><code class="language-go">0.98309175770932</code></pre> 
 <h4>LightGBM</h4> 
 <h5>定义模型参数</h5> 
 <p>In [72]:</p> 
 <pre class="has"><code class="language-go">params = {
          'boosting_type': 'gbdt',
          'objective': 'binary',
          'metric':'auc',
          'learning_rate': 0.05,
          'num_leaves': 7,  # 小于的 2^(max_depth)次方
          'max_depth': 4,   
          'min_child_samples': 100,  # 最小子树个数
          'max_bin': 100,  
          'subsample': 0.9,  
          'subsample_freq': 1,  
          'colsample_bytree': 0.7,  
          'min_child_weight': 0,  
          'min_split_gain': 0, 
          'nthread': 8,
          'verbose': 0, 
          'scale_pos_weight':150, 
         }</code></pre> 
 <h5>数据准备</h5> 
 <p>In [73]:</p> 
 <pre class="has"><code class="language-go">train_df.head()</code></pre> 
 <p>转成lgb模型所需的格式：</p> 
 <p>In [74]:</p> 
 <pre class="has"><code class="language-go">dtrain = lgb.Dataset(train_df[features].values, # 特征
                     label=train_df[target].values, # 目标变量
                     feature_name=features)  # 特征名称

dvalid = lgb.Dataset(valid_df[features].values,
                     label=valid_df[target].values,
                     feature_name=features)</code></pre> 
 <h5>模型训练</h5> 
 <p>In [75]:</p> 
 <pre class="has"><code class="language-go">evals_results = {}

model = lgb.train(params, # 参数
                  dtrain,  # 数据
                  valid_sets = [dtrain, dvalid], # 交叉验证数据集
                  valid_names = ['train','valid'],  # 名字
                  evals_result = evals_results, 
                  num_boost_round = MAX_ROUNDS,
                  early_stopping_rounds= 2 * EARLY_STOP,
                  verbose_eval = VERBOSE_EVAL, 
                  feval = None
                 )
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011147 seconds.
You can set `force_col_wise=true` to remove the overhead.
Training until validation scores don't improve for 100 rounds
[50] train's auc: 0.986784 valid's auc: 0.92025
[100] train's auc: 0.982458 valid's auc: 0.906221
Early stopping, best iteration is:
[2] train's auc: 0.97387 valid's auc: 0.97051</code></pre> 
 <h5>特征重要性</h5> 
 <p>In [76]:</p> 
 <pre class="has"><code class="language-go">fig, (ax) = plt.subplots(ncols=1, figsize=(8,5))

lgb.plot_importance(model,  # 使用 plot_importance方法
                    height=0.4, 
                    title="Features importance (LightGBM)", 
                    ax=ax,
                    max_num_features=30,
                    color="red"
                   ) 

plt.show()</code></pre> 
 <h5><img src="https://images2.imgbox.com/e6/4d/aPQwKNJH_o.png" alt="2bb79a673a5a3082b9c42c3e0f1778fc.png"></h5> 
 <h5>模型预测</h5> 
 <p>In [77]:</p> 
 <pre class="has"><code class="language-go">test_pred = model.predict(test_df[features])
test_pred</code></pre> 
 <p>Out[77]:</p> 
 <pre class="has"><code class="language-go">array([0.00295975, 0.00288036, 0.9999795 , ..., 0.00497163, 0.00295975,
       0.00295975])</code></pre> 
 <p>计算ROC-AUC值：</p> 
 <p>In [78]:</p> 
 <pre class="has"><code class="language-go">roc_auc_score(test_df[target].values, test_pred)</code></pre> 
 <p>Out[78]:</p> 
 <pre class="has"><code class="language-go">0.951076589143652</code></pre> 
 <h3>交叉验证 cross-validation</h3> 
 <p>实施基于5折的交叉验证：</p> 
 <h4>定义Kfold实例</h4> 
 <p>In [79]:</p> 
 <pre class="has"><code class="language-go">NUMBER_KFOLDS = 5  # 折数

kf = KFold(n_splits = NUMBER_KFOLDS, 
           random_state = RANDOM_STATE, 
           shuffle = True)</code></pre> 
 <h4>定义初始矩阵</h4> 
 <p>定义全0矩阵，用来存储最终结果。</p> 
 <p>In [80]:</p> 
 <pre class="has"><code class="language-go">oof_preds = np.zeros(train_df.shape[0]) 
test_preds = np.zeros(test_df.shape[0])

feature_importance_df = pd.DataFrame()
n_fold = 0</code></pre> 
 <h4>实施交叉验证</h4> 
 <p>In [81]:</p> 
 <pre class="has"><code class="language-go">for train_idx, valid_idx in kf.split(train_df):
    train_x, train_y = train_df[features].iloc[train_idx], train_df[target].iloc[train_idx]
    valid_x, valid_y = train_df[features].iloc[valid_idx], train_df[target].iloc[valid_idx]
    
    evals_result = {}
    # 模型定义
    model = LGBMClassifier(
                            nthread=-1,
                            n_estimators=2000,
                            learning_rate=0.01,
                            num_leaves=80,
                            colsample_bytree=0.98,
                            subsample=0.78,
                            reg_alpha=0.04,
                            reg_lambda=0.073,
                            subsample_for_bin=50,
                            boosting_type='gbdt',
                            is_unbalance=False,
                            min_split_gain=0.025,
                            min_child_weight=40,
                            min_child_samples=510,
                            objective='binary',
                            metric='auc',
                            silent=-1,
                            verbose=-1,
                            feval=None
                            )
    # 模型训练
    model.fit(train_x, 
              train_y, 
              eval_set=[(train_x, train_y), (valid_x, valid_y)], 
              eval_metric= 'auc', 
              verbose= VERBOSE_EVAL, 
              early_stopping_rounds= EARLY_STOP
             )
    
    # 模型预测概率
    oof_preds[valid_idx] = model.predict_proba(valid_x, num_iteration=model.best_iteration_)[:, 1]
    test_preds += model.predict_proba(test_df[features], num_iteration=model.best_iteration_)[:, 1] / kf.n_splits
    
    # 特征重要性
    fold_importance_df = pd.DataFrame()
    fold_importance_df["feature"] = features
    fold_importance_df["importance"] = model.feature_importances_  # 原文是 clf.feature_importances_
    fold_importance_df["fold"] = n_fold + 1
    # 生成dataframe：feature + importance + fold
    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)
    
    # roc-auc值
    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))
    
    # 回收机制
    del model, train_x, train_y, valid_x, valid_y
    gc.collect()
    
    n_fold = n_fold + 1
[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1
[50] training's auc: 0.975109 valid_1's auc: 0.964242
Fold  1 AUC : 0.966735
[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1
[50] training's auc: 0.973376 valid_1's auc: 0.97159
[100] training's auc: 0.974581 valid_1's auc: 0.975146
Fold  2 AUC : 0.976924
[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1
[50] training's auc: 0.971525 valid_1's auc: 0.981105
[100] training's auc: 0.973605 valid_1's auc: 0.979233
Fold  3 AUC : 0.981177
[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1
[50] training's auc: 0.970153 valid_1's auc: 0.981887
Fold  4 AUC : 0.983433
[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1
[50] training's auc: 0.980285 valid_1's auc: 0.962565
Fold  5 AUC : 0.965422</code></pre> 
 <p>In [82]:</p> 
 <pre class="has"><code class="language-go">train_auc_score = roc_auc_score(train_df[target], oof_preds)

print('Full AUC score %.6f' % train_auc_score)  
Full AUC score 0.949809</code></pre> 
 <pre></pre> 
 <p><img src="https://images2.imgbox.com/8b/5c/fNjbXY6Y_o.png" alt="40d93276e09895e42c1189c1aef5259a.jpeg"></p> 
 <pre></pre> 
 <pre></pre> 
 <pre></pre> 
 <pre></pre> 
 <pre class="has"><code class="language-go">往期精彩回顾




适合初学者入门人工智能的路线及资料下载(图文+视频)机器学习入门系列下载机器学习及深度学习笔记等资料打印《统计学习方法》的代码复现专辑机器学习交流qq群955171419，加入微信群请扫码</code></pre> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a38c89373479102edcf3e4dc0a0f19e1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">终极解决：Error: error:0308010C:digital envelope routines::unsupported</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d05ce799463a49e78ed5e170e092f4b3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【ArcGIS】使用ArcMap进行北京1954-120E坐标转WGS84坐标系</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>