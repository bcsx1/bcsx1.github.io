<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>独家 | 从基础到实现：集成学习综合教程（附Python代码） - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="独家 | 从基础到实现：集成学习综合教程（附Python代码）" />
<meta property="og:description" content="作者：AISHWARYA SINGH
翻译：和中华
校对：丁楠雅
本文约8000字，建议阅读10&#43;分钟。
本文从基础集成技术讲起，随后介绍了高级的集成技术，最后特别介绍了一些流行的基于Bagging和Boosting的算法，帮助读者对集成学习建立一个整体印象。
介绍 当你想购买一辆新车时，你会走到第一家汽车商店就根据经销商的建议购买一辆车吗？这是不太可能的。
你可能会浏览一些人们发布评论并比较不同车型的门户网站，检查其功能和价格。你也可能会问你的朋友和同事们的意见。总之，你不会直接得出结论，还会参考其他人的意见做出决定。
机器学习中的集成模型也是类似的思路。它们结合了多个模型的决策来提高整体性能。这可以通过各种方式实现，本文将会带你一起探索。
本文的目的是介绍集成学习的概念并理解使用这种技术的算法。为了巩固你对这个多元化主题的理解，我们将用真实问题的动手案例，配合Python来解释其中的高级算法。
注意：本文假定你对机器学习算法有基本的了解。我建议阅读这篇文章以熟悉这些概念。
文章链接：
https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
目录 集成学习介绍
基础集成技术
最大投票（Max Voting）法
平均（Averaging）法
加权平均（Weighted Average）法
高级集成技术
堆叠（Stacking）
混合（Blending）
Bagging
提升（Boosting）
基于Bagging和Boosting的算法
Bagging meta-estimator
随机森林
AdaBoost
GBM
XGB
Light GBM
CatBoost
一、集成学习介绍 我们通过一个例子来理解集成学习的概念。假设你是一名电影导演，你依据一个非常重要且有趣的话题创作了一部短片。现在，你想在公开发布前获得影片的初步反馈（评级）。有哪些可行的方法呢？
A：可以请一位朋友为电影打分。
于是完全有可能出现这种结果：你所选择的人由于非常爱你，并且不希望给你这部糟糕的影片打1星评级来伤害你脆弱的小心脏。
B：另一种方法是让你的5位同事评价这部电影。
这个办法应该更好，可能会为电影提供更客观诚实的评分。但问题依然存在。这5个人可能不是电影主题方面的“专家”。当然，他们可能懂电影摄制，镜头或音效，但他们可能并不是黑色幽默的最佳评判者。
C：让50个人评价这部电影呢？
其中一些可以是你的朋友，可以是你的同事，甚至是完完全全的陌生人。
在这种情况下，回应将更加普遍化和多样化，因为他们拥有不同的技能。事实证明，与我们之前看到的情况相比，这是获得诚实评级的更好方法。
通过这些例子，你可以推断，与个人相比，不同群体的人可能会做出更好的决策。与单一模型相比，各种不同模型也是这个道理。机器学习中的多样化是通过称为集成学习（Ensemble learning）的技术实现的。
现在你已经掌握了集成学习的要旨，接下来让我们看看集成学习中的各种技术及其实现。
二、简单集成技术 这一节中，我们会看一些简单但是强大的技术，比如：
最大投票法
平均法
加权平均法
2.1 最大投票法 最大投票方法通常用于分类问题。这种技术中使用多个模型来预测每个数据点。每个模型的预测都被视为一次“投票”。大多数模型得到的预测被用作最终预测结果。
例如，当你让5位同事评价你的电影时（最高5分）; 我们假设其中三位将它评为4，而另外两位给它一个5。由于多数人评分为4，所以最终评分为4。你可以将此视为采用了所有预测的众数（mode）。
最大投票的结果有点像这样：
示例代码：
这里x_train由训练数据中的自变量组成，y_train是训练数据的目标变量。验证集是x_test（自变量）和y_test（目标变量）。
model1 = tree.DecisionTreeClassifier()
model2 = KNeighborsClassifier()
model3= LogisticRegression()" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/a1d105dbbcd98a156f34c77e1d20bf54/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-07-23T19:00:00+08:00" />
<meta property="article:modified_time" content="2018-07-23T19:00:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">独家 | 从基础到实现：集成学习综合教程（附Python代码）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div class="rich_media_content" lang="en" id="js_content"> 
 <p style="min-height:1em;color:rgb(51,51,51);"><img src="https://images2.imgbox.com/f3/e8/DVJKXM33_o.png" alt="640?wx_fmt=png"></p> 
 <p style="line-height:1.5em;"><span style="letter-spacing:1px;font-size:14px;">作者：AISHWARYA SINGH</span></p> 
 <p style="line-height:1.5em;"><span style="letter-spacing:1px;font-size:14px;">翻译：和中华</span></p> 
 <p style="line-height:1.5em;"><span style="letter-spacing:1px;font-size:14px;">校对：丁楠雅</span></p> 
 <p style="min-height:1em;line-height:normal;">本文约<strong><span style="color:rgb(166,91,203);">8000</span></strong><span style="color:rgb(166,91,203);"><strong>字，</strong></span>建议阅读<strong><span style="color:rgb(166,91,203);">10</span></strong><strong><span style="color:rgb(166,91,203);">+</span></strong><strong><span style="color:rgb(166,91,203);">分钟。</span></strong></p> 
 <p><span style="letter-spacing:1px;font-size:14px;">本文从基础集成技术讲起，随后介绍了高级的集成技术，最后特别介绍了一些流行的基于Bagging和Boosting的算法，帮助读者对集成学习建立一个整体印象。</span></p> 
 <p style="line-height:1.5em;"><br></p> 
 <h3 style="line-height:1.5em;text-align:center;"><span style="color:rgb(166,91,203);"><strong><span style="font-size:15px;letter-spacing:1px;">介绍</span></strong></span></h3> 
 <p><span style="color:rgb(166,91,203);"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">当你想购买一辆新车时，你会走到第一家汽车商店就根据经销商的建议购买一辆车吗？这是不太可能的。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">你可能会浏览一些人们发布评论并比较不同车型的门户网站，检查其功能和价格。你也可能会问你的朋友和同事们的意见。总之，你不会直接得出结论，还会参考其他人的意见做出决定。</span></p> 
 <p><img src="https://images2.imgbox.com/3e/12/1oqRac3V_o.png" alt="640?wx_fmt=png"></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">机器学习中的集成模型也是类似的思路。它们结合了多个模型的决策来提高整体性能。这可以通过各种方式实现，本文将会带你一起探索。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">本文的目的是介绍集成学习的概念并理解使用这种技术的算法。为了巩固你对这个多元化主题的理解，我们将用真实问题的动手案例，配合Python来解释其中的高级算法。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">注意：本文假定你对机器学习算法有基本的了解。我建议阅读这篇文章以熟悉这些概念。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <blockquote> 
  <p style="line-height:normal;"><strong><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">文章链接：</span></strong></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <h3 style="line-height:1.5em;text-align:center;"><span style="color:rgb(166,91,203);"><strong><span style="color:rgb(166,91,203);font-size:15px;letter-spacing:1px;">目录</span></strong></span></h3> 
 <p><span style="color:rgb(166,91,203);"><strong><span style="color:rgb(166,91,203);font-size:15px;letter-spacing:1px;"><br></span></strong></span></p> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">集成学习介绍</span></strong></p></li><li><p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">基础集成技术</span></strong></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">最大投票（Max Voting）法</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">平均（Averaging）法</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">加权平均（Weighted Average）法</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">高级集成技术</span></strong></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">堆叠（Stacking）</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">混合（Blending）</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Bagging</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> 提升（Boosting）</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">基于Bagging和Boosting的算法</span></strong></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Bagging meta-estimator</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">随机森林</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">AdaBoost</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">GBM</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">XGB</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Light GBM</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">CatBoost</span></p></li></ul></li></ul> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <h3 style="line-height:1.5em;text-align:center;"><span style="color:rgb(166,91,203);"><strong><span style="color:rgb(166,91,203);font-size:15px;letter-spacing:1px;">一、集成学习介绍</span></strong></span></h3> 
 <p><span style="color:rgb(166,91,203);"><strong><span style="color:rgb(166,91,203);font-size:15px;letter-spacing:1px;"><br></span></strong></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">我们通过一个例子来理解集成学习的概念。假设你是一名电影导演，你依据一个非常重要且有趣的话题创作了一部短片。现在，你想在公开发布前获得影片的初步反馈（评级）。有哪些可行的方法呢？</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">A：可以请一位朋友为电影打分。</span></strong></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">于是完全有可能出现这种结果：你所选择的人由于非常爱你，并且不希望给你这部糟糕的影片打1星评级来伤害你脆弱的小心脏。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">B：另一种方法是让你的5位同事评价这部电影。</span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">这个办法应该更好，可能会为电影提供更客观诚实的评分。但问题依然存在。这5个人可能不是电影主题方面的“专家”。当然，他们可能懂电影摄制，镜头或音效，但他们可能并不是黑色幽默的最佳评判者。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">C：让50个人评价</span></strong><strong><span style="font-size:15px;letter-spacing:1px;">这部电影呢？</span></strong></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">其中一些可以是你的朋友，可以是你的同事，甚至是完完全全的陌生人。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">在这种情况下，回应将更加普遍化和多样化，因为他们拥有不同的技能。事实证明，与我们之前看到的情况相比，这是获得诚实评级的更好方法。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">通过这些例子，你可以推断，与个人相比，不同群体的人可能会做出更好的决策。与单一模型相比，各种不同模型也是这个道理。机器学习中的多样化是通过称为集成学习（Ensemble learning）的技术实现的。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">现在你已经掌握了集成学习的要旨，接下来让我们看看集成学习中的各种技术及其实现。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <h3 style="line-height:1.5em;text-align:center;"><span style="color:rgb(166,91,203);"><strong><span style="color:rgb(166,91,203);font-size:15px;letter-spacing:1px;">二、简单集成技术</span></strong></span></h3> 
 <p><span style="color:rgb(166,91,203);"><strong><span style="color:rgb(166,91,203);font-size:15px;letter-spacing:1px;"><br></span></strong></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">这一节中，我们会看一些简单但是强大的技术，比如：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">最大投票法</span></strong></p></li><li><p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">平均法</span></strong></p></li><li><p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">加权平均法</span></strong></p></li></ul> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">2.1 最大投票法</span></strong></h4> 
 <p><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">最大投票方法通常用于分类问题。这种技术中使用多个模型来预测每个数据点。每个模型的预测都被视为一次“投票”。大多数模型得到的预测被用作最终预测结果。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">例如，当你让5位同事评价你的电影时（最高5分）; 我们假设其中三位将它评为4，而另外两位给它一个5。由于多数人评分为4，所以最终评分为4。你可以将此视为采用了所有预测的众数（mode）。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">最大投票的结果有点像这样：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p><img style="width:553px;" src="https://images2.imgbox.com/c7/e9/SOiIFBg0_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p><br></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">这里x_train由训练数据中的自变量组成，y_train是训练数据的目标变量。验证集是x_test（自变量）和y_test（目标变量）。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <blockquote> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model1 = tree.DecisionTreeClassifier()</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model2 = KNeighborsClassifier()</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model3= LogisticRegression()</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model1.fit(x_train,y_train)</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model2.fit(x_train,y_train)</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model3.fit(x_train,y_train)</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">pred1=model1.predict(x_test)</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">pred2=model2.predict(x_test)</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">pred3=model3.predict(x_test)</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">final_pred = np.array([])</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">for i in range(0,len(x_test)):</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">    final_pred =np.append(final_pred, mode([pred1[i], pred2[i], pred3[i]]))</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;text-align:left;"><span style="font-size:15px;letter-spacing:1px;">或者，你也可以在<span style="font-size:15px;letter-spacing:normal;">sklearn</span>中使用<span style="font-size:15px;letter-spacing:normal;">“VotingClassifier”</span>模块，如下所示：</span></p> 
 <p style="line-height:normal;text-align:left;"><span style="font-size:14px;letter-spacing:normal;"> </span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">from sklearn.ensemble import VotingClassifier</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model1 = LogisticRegression(random_state=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model2 = tree.DecisionTreeClassifier(random_state=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model.fit(x_train,y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
 </blockquote> 
 <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">2.2 平均法</span></strong></h4> 
 <p><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">类似于最大投票技术，这里对每个数据点的多次预测进行平均。在这种方法中，我们从所有模型中取平均值作为最终预测。平均法可用于在回归问题中进行预测或在计算分类问题的概率时使用。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">例如，在下面的情况中，平均法将取所有值的平均值。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">即（5 + 4 + 5 + 4 + 4）/ 5 = 4.4</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p><img style="width:552px;" src="https://images2.imgbox.com/e3/60/Bdr2UHgR_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">model1 = tree.DecisionTreeClassifier()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">model2 = KNeighborsClassifier()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">model3= LogisticRegression()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">model1.fit(x_train,y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">model2.fit(x_train,y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">model3.fit(x_train,y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">pred1=model1.predict_proba(x_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">pred2=model2.predict_proba(x_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">pred3=model3.predict_proba(x_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">finalpred=(pred1+pred2+pred3)/3</span></p> 
 </blockquote> 
 <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;"> </span></p> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">2.3 加权平均法</span></strong></h4> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">这是平均法的扩展。为所有模型分配不同的权重，定义每个模型的预测重要性。例如，如果你的两个同事是评论员，而其他人在这方面没有任何经验，那么与其他人相比，这两个朋友的答案就更加重要。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">计算结果为[（5 * 0.23）+（4 * 0.23）+（5 * 0.18）+（4 * 0.18）+（4 * 0.18）] = 4.41。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p><img src="https://images2.imgbox.com/3a/cf/oL3uZCh8_o.png" alt="640?wx_fmt=png"></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong><br></p> 
 <p><br></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">model1 = tree.DecisionTreeClassifier()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">model2 = KNeighborsClassifier()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">model3= LogisticRegression()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">model1.fit(x_train,y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">model2.fit(x_train,y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">model3.fit(x_train,y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">pred1=model1.predict_proba(x_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">pred2=model2.predict_proba(x_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">pred3=model3.predict_proba(x_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">finalpred=(pred1*0.3+pred2*0.3+pred3*0.4)</span></p> 
 </blockquote> 
 <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;"> </span></p> 
 <h3 style="line-height:1.5em;text-align:center;"><span style="color:rgb(166,91,203);"><strong><span style="color:rgb(166,91,203);font-size:15px;letter-spacing:1px;">三、高级集成技术</span></strong></span></h3> 
 <p><span style="color:rgb(166,91,203);"><strong><span style="color:rgb(166,91,203);font-size:15px;letter-spacing:1px;"><br></span></strong></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">我们已经介绍了基础的集成技术，让我们继续了解高级的技术。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">3.1 堆叠（Stacking）</span></strong></h4> 
 <p><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">堆叠是一种集成学习技术，它使用多个模型（例如决策树，knn或svm）的预测来构建新模型。该新模型用于对测试集进行预测。以下是简单堆叠集成法的逐步解释：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第一步：</span></strong><span style="font-size:15px;letter-spacing:1px;">把训练集分成10份</span></p> 
 <p style="line-height:1.5em;"><br></p> 
 <p style="text-align:center;"><img style="width:133px;" src="https://images2.imgbox.com/14/19/EeFxac5j_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="line-height:1.5em;text-align:center;"><strong><span style="font-size:15px;letter-spacing:1px;"> </span></strong></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第二步：</span></strong><span style="font-size:15px;letter-spacing:1px;">基础模型（假设是决策树）在其中9份上拟合，并对第10份进行预测。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><strong>第三步：</strong>对训练集上的每一份如此做一遍。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="text-align:center;"><img style="width:166px;" src="https://images2.imgbox.com/5a/ad/w7LhSxA3_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="text-align:center;"><br></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第四步：</span></strong><span style="font-size:15px;letter-spacing:1px;">然后将基础模型（此处是决策树）拟合到整个训练集上。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第五步：</span></strong><span style="font-size:15px;letter-spacing:1px;">使用此模型，在测试集上进行预测。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="text-align:center;"><img style="width:159px;" src="https://images2.imgbox.com/e5/3c/knUM31yj_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="text-align:center;"><br></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第六步：</span></strong><span style="font-size:15px;letter-spacing:1px;">对另一个基本模型（比如knn）重复步骤2到4，产生对训练集和测试集的另一组预测。</span></p> 
 <p><br></p> 
 <p style="text-align:center;"><img style="width:263px;" src="https://images2.imgbox.com/dc/c2/vW31pnB6_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p><br></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第七步：</span></strong><span style="font-size:15px;letter-spacing:1px;">训练集预测被用作构建新模型的特征。</span></p> 
 <p><br></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第八步：</span></strong><span style="font-size:15px;letter-spacing:1px;">该新模型用于对测试预测集（test prediction set，上图的右下角）进行最终预测。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="text-align:center;"><img style="width:132px;" src="https://images2.imgbox.com/e0/92/Dblwkc0c_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span><br></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">我们首先定义一个函数来对n折的训练集和测试集进行预测。此函数返回每个模型对训练集和测试集的预测。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">def Stacking(model,train,y,test,n_fold):</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">   folds=StratifiedKFold(n_splits=n_fold,random_state=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">   test_pred=np.empty((test.shape[0],1),float)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">   train_pred=np.empty((0,1),float)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">   for train_indices,val_indices in folds.split(train,y.values):</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">      x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">      y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">      model.fit(X=x_train,y=y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">      train_pred=np.append(train_pred,model.predict(x_val))</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">      test_pred=np.append(test_pred,model.predict(test))</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">    return test_pred.reshape(-1,1),train_pred</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">现在我们将创建两个基本模型：决策树和knn。</span></p> 
 <p><br></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model1 = tree.DecisionTreeClassifier(random_state=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">test_pred1 ,train_pred1=Stacking(model=model1,n_fold=10, train=x_train,test=x_test,y=y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">train_pred1=pd.DataFrame(train_pred1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">test_pred1=pd.DataFrame(test_pred1)</span></p> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model2 = KNeighborsClassifier()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">test_pred2 ,train_pred2=Stacking(model=model2,n_fold=10,train=x_train,test=x_test,y=y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">train_pred2=pd.DataFrame(train_pred2)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">test_pred2=pd.DataFrame(test_pred2)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">创建第三个模型，逻辑回归，在决策树和knn模型的预测之上。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">df = pd.concat([train_pred1, train_pred2], axis=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">df_test = pd.concat([test_pred1, test_pred2], axis=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model = LogisticRegression(random_state=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.fit(df,y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.score(df_test, y_test)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">为了简化上面的解释，我们创建的堆叠模型只有两层。决策树和knn模型建立在零级，而逻辑回归模型建立在第一级。其实可以随意的在堆叠模型中创建多个层次。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">3.2 混合（Stacking）</span></strong></h4> 
 <p><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">混合遵循与堆叠相同的方法，但仅使用来自训练集的一个留出(holdout)/验证集来进行预测。换句话说，与堆叠不同，预测仅在留出集上进行。留出集和预测用于构建在测试集上运行的模型。以下是混合过程的详细说明：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第一步：</span></strong><span style="font-size:15px;letter-spacing:1px;">原始训练数据被分为训练集合验证集。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="text-align:center;"><img style="width:197px;" src="https://images2.imgbox.com/0f/9a/rG8fIOyp_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="text-align:center;"><br></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第二步：</span></strong><span style="font-size:15px;letter-spacing:1px;">在训练集上拟合模型。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第三步：</span></strong><span style="font-size:15px;letter-spacing:1px;">在验证集和测试集上进行预测。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="text-align:center;"><img style="width:308px;" src="https://images2.imgbox.com/02/4d/fNRcgKQa_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="text-align:center;"><br></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第四步：</span></strong><span style="font-size:15px;letter-spacing:1px;">验证集及其预测用作构建新模型的特征。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第五步：</span></strong><span style="font-size:15px;letter-spacing:1px;">该新模型用于对测试集和元特征(meta-features)进行最终预测。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"> </span></strong></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">我们将在训练集上建立两个模型，决策树和knn，以便对验证集进行预测。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model1 = tree.DecisionTreeClassifier()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model1.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">val_pred1=model1.predict(x_val)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">test_pred1=model1.predict(x_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">val_pred1=pd.DataFrame(val_pred1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">test_pred1=pd.DataFrame(test_pred1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model2 = KNeighborsClassifier()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model2.fit(x_train,y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">val_pred2=model2.predict(x_val)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">test_pred2=model2.predict(x_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">val_pred2=pd.DataFrame(val_pred2)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">test_pred2=pd.DataFrame(test_pred2)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">结合元特征和验证集，构建逻辑回归模型以对测试集进行预测。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">df_val=pd.concat([x_val, val_pred1,val_pred2],axis=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">df_test=pd.concat([x_test, test_pred1,test_pred2],axis=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model = LogisticRegression()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model.fit(df_val,y_val)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model.score(df_test,y_test)</span></p> 
 </blockquote> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></h4> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">3.3 Bagging</span></strong></h4> 
 <p><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Bagging背后的想法是结合多个模型的结果（例如，所有决策树）来获得泛化的结果。这有一个问题：如果在同样一组数据上创建所有模型并将其组合起来，它会有用吗？这些模型极大可能会得到相同的结果，因为它们获得的输入相同。那我们该如何解决这个问题呢？其中一种技术是自举(bootstrapping)。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Bootstrapping是一种采样技术，我们有放回的从原始数据集上创建观察子集，子集的大小与原始集的大小相同。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Bagging（或Bootstrap Aggregating）技术使用这些子集（包）来获得分布的完整概念（完备集）。为bagging创建的子集的大小也可能小于原始集。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p><img style="width:553px;" src="https://images2.imgbox.com/99/1c/HrP6InET_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第一步：</span></strong><span style="font-size:15px;letter-spacing:1px;">从原始数据集有放回的选择观测值来创建多个子集。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第二步：</span></strong><span style="font-size:15px;letter-spacing:1px;">在每一个子集上创建一个基础模型（弱模型）。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第三步：</span></strong><span style="font-size:15px;letter-spacing:1px;">这些模型同时运行，彼此独立。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第四步：</span></strong><span style="font-size:15px;letter-spacing:1px;">通过组合所有模型的预测来确定最终预测。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p><img src="https://images2.imgbox.com/6a/30/smi4zQ9O_o.png" alt="640?wx_fmt=png"></p> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></h4> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">3.4 Boosting</span></strong><br></h4> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">在我们进一步讨论之前，这里有另一个问题：如果第一个模型错误地预测了某一个数据点，然后接下来的模型（可能是所有模型），将预测组合起来会提供更好的结果吗？Boosting就是来处理这种情况的。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Boosting是一个顺序过程，每个后续模型都会尝试纠正先前模型的错误。后续的模型依赖于之前的模型。接下来一起看看boosting的工作方式：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第一步：</span></strong><span style="font-size:15px;letter-spacing:1px;">从原始数据集创建一个子集。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第二步：</span></strong><span style="font-size:15px;letter-spacing:1px;">最初，所有数据点都具有相同的权重。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第三步：</span></strong><span style="font-size:15px;letter-spacing:1px;">在此子集上创建基础模型。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第四步：</span></strong><span style="font-size:15px;letter-spacing:1px;">该模型用于对整个数据集进行预测。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="text-align:center;"><img style="width:171px;" src="https://images2.imgbox.com/80/cd/DLBxWQHD_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="text-align:center;"><br></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第五步：</span></strong><span style="font-size:15px;letter-spacing:1px;">使用实际值和预测值计算误差。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第六步：</span></strong><span style="font-size:15px;letter-spacing:1px;">预测错误的点获得更高的权重。（这里，三个错误分类的蓝色加号点将被赋予更高的权重）</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><strong style="font-size:15px;letter-spacing:1px;">第七步：</strong>创建另一个模型并对数据集进行预测（此模型尝试更正先前模型中的错误）。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/d3/d3/bb2LyezH_o.png" alt="640?wx_fmt=png"></p> 
 <p><br></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第八步：</span></strong><span style="font-size:15px;letter-spacing:1px;">类似地，创建多个模型，每个模型校正先前模型的错误。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第九步：</span></strong><span style="font-size:15px;letter-spacing:1px;">最终模型（强学习器）是所有模型（弱学习器）的加权平均值。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"></span></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/0e/6b/ccgQZ0QU_o.png" alt="640?wx_fmt=png"></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">因此，boosting算法结合了许多弱学习器来形成一个强学习器。单个模型在整个数据集上表现不佳，但它们在数据集的某些部分上表现很好。因此，每个模型实际上提升了集成的整体性能。</span><br></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;text-align:center;"><span style="font-size:15px;letter-spacing:1px;"> <img style="text-align:center;width:180px;" src="https://images2.imgbox.com/f0/36/HR2UW8MW_o.png" alt="640?wx_fmt=jpeg"></span></p> 
 <p style="line-height:1.5em;text-align:center;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <h3 style="line-height:1.5em;text-align:center;"><span style="color:rgb(166,91,203);"><strong><span style="color:rgb(166,91,203);font-size:15px;letter-spacing:1px;">四、基于Bagging和Boosting的算法</span></strong></span></h3> 
 <p><span style="color:rgb(166,91,203);"><strong><span style="color:rgb(166,91,203);font-size:15px;letter-spacing:1px;"><br></span></strong></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Bagging和Boosting是机器学习中最常用的两种技术。在本节中，我们将详细介绍它们。以下是我们将关注的算法：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">Bagging 算法:</span><br></strong></p> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Bagging meta-estimator</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">随机森林</span></p></li></ul> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">Boosting算法：</span></strong></p> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">AdaBoost</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">GBM</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">XGBM</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Light GBM</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">CatBoost</span></p></li></ul> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">对于本节中讨论的所有算法，我们将遵循以下顺序：</span></strong></p> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">算法介绍</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">示例代码</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">参数</span></p></li></ul> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">本文中，我使用了贷款预测问题。你可以从此处下载数据集。请注意，对于每种算法，某些代码（读取数据，划分训练测试集等）将是相同的。为了避免重复，我在下面编写了相同的代码，并且只对算法相关的代码进行进一步讨论。</span></p> 
 <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">#importing important packages</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">import pandas as pd</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">import numpy as np</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">#reading the dataset</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">df=pd.read_csv("/home/user/Desktop/train.csv")</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">#filling missing values</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">df['Gender'].fillna('Male', inplace=True)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">同理，对所有列进行值填充。本文只考虑所讨论的主题，已跳过EDA，缺失值和异常值处理等步骤。要了解这些主题，可以阅读此文：Ultimate guide for Data Explorationin Python using NumPy, Matplotlib and Pandas.</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">#split dataset into train and test</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">from sklearn.model_selection import train_test_split</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">train, test = train_test_split(df, test_size=0.3, random_state=0)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">x_train=train.drop('Loan_Status',axis=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">y_train=train['Loan_Status']</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">x_test=test.drop('Loan_Status',axis=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">y_test=test['Loan_Status']</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">#create dummies</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">x_train=pd.get_dummies(x_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">x_test=pd.get_dummies(x_test)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">让我们来探索bagging和boosting算法。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">4.1 Bagging meta-estimator</span></strong></h4> 
 <p><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;text-align:left;"><span style="font-size:15px;letter-spacing:normal;">Bagging meta-estimator</span><span style="font-size:15px;letter-spacing:1px;">是一种集成算法，可用于分类</span><span style="font-size:15px;letter-spacing:normal;">(BaggingClassifier)</span><span style="font-size:15px;letter-spacing:1px;">和回归</span><span style="font-size:15px;letter-spacing:normal;">(BaggingRegressor)</span><span style="font-size:15px;letter-spacing:1px;">问题。它采用典型的bagging技术进行预测。以下是</span><span style="font-size:15px;letter-spacing:normal;">Bagging meta-estimator</span><span style="font-size:15px;letter-spacing:1px;">算法的步骤：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第一步：</span></strong><span style="font-size:15px;letter-spacing:1px;">从原始数据集（Bootstrapping）创建随机子集。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第二步：</span></strong><span style="font-size:15px;letter-spacing:1px;">数据集的子集包括所有特征。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第三步</span></strong><span style="font-size:15px;letter-spacing:1px;">用户指定的基础估计器在这些较小的集合上拟合。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第四步：</span></strong><span style="font-size:15px;letter-spacing:1px;">将每个模型的预测结合起来得到最终结果。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong></p> 
 <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"><strong><span style="font-size:14px;color:rgb(136,136,136);"><br></span></strong></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">from sklearn.ensemble import BaggingClassifier</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">from sklearn import tree</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">0.75135135135135134</span></p> 
 </blockquote> 
 <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">回归问题示例代码：</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">from sklearn.ensemble import BaggingRegressor</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model = BaggingRegressor(tree.DecisionTreeRegressor(random_state=1))</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">算法中用到的参数：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">base_estimator</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义了在随机子集上拟合所用的基础估计器</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">没有指明时，默认使用决策树</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">n_estimators</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">创建的基础估计器数量</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">要小心微调这个参数，因为数字越大运行时间越长，相反太小的数字可能无法提供最优结果</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_samples</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">该参数控制子集的大小</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它是训练每个基础估计器的最大样本数量</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_features</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">控制从数据集中提取多少个特征</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它是训练每个基础估计器的最大特征数量</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">n_jobs</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">同时运行的job数量</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">将这个值设为你系统的CPU核数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">如果设为-1，这个值会被设为你系统的CPU核数</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">random_state</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义了随机分割的方法。当两个模型的random_state值一样时，它们的随机选择也一样</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">如果你想对比不同的模型，这个参数很有用</span></p></li></ul></li></ul> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">4.2 随机森林</span></strong></h4> 
 <p><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">随机森林是另一种遵循bagging技术的集成机器学习算法。它是bagging-estimator算法的扩展。随机森林中的基础估计器是决策树。与bagging meta-estimator不同，随机森林随机选择一组特征，这些特征用于决定决策树的每个节点处的最佳分割。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">随机森林的具体步骤如下:</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第一步：</span></strong><span style="font-size:15px;letter-spacing:1px;">从原始数据集（Bootstrapping）创建随机子集。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第二步：</span></strong><span style="font-size:15px;letter-spacing:1px;">在决策树中的每个节点处，仅考虑一组随机特征来决定最佳分割。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第三步：</span></strong><span style="font-size:15px;letter-spacing:1px;">在每个子集上拟合决策树模型。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第四步：</span></strong><span style="font-size:15px;letter-spacing:1px;">通过对所有决策树的预测求平均来计算最终预测。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">注意：</span></strong><span style="font-size:15px;letter-spacing:1px;">随机林中的决策树可以构建在数据和特征的子集上。特别地，sklearn中的随机森林使用所有特征作为候选，并且候选特征的随机子集用于在每个节点处分裂。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">总而言之，随机森林随机选择数据点和特征，并构建多个树（森林）。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong></p> 
 <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">from sklearn.ensemble import RandomForestClassifier</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model= RandomForestClassifier(random_state=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">0.77297297297297296</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;text-align:left;"><span style="font-size:15px;letter-spacing:1px;">你可以通过在随机林中使用<span style="font-size:15px;letter-spacing:normal;">model.feature_importances_</span>来查看特征重要性。</span></p> 
 <p style="line-height:1.5em;text-align:left;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">for i, j in sorted(zip(x_train.columns, model.feature_importances_)):</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">    print(i, j)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">结果如下：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">ApplicantIncome 0.180924483743</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">CoapplicantIncome 0.135979758733</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">Credit_History 0.186436670523</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">.</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">.</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">.</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">Property_Area_Urban 0.0167025290557</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">Self_Employed_No 0.0165385567137</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">Self_Employed_Yes 0.0134763695267</span></p> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">回归问题示例代码：</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">from sklearn.ensemble import RandomForestRegressor</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model= RandomForestRegressor()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">参数：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">n_estimators</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义随机森林中要创建的决策树数量</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">通常，越高的值会让预测更强大更稳定，但是过高的值会让训练时间很长</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">criterion</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义了分割用的函数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">该函数用来衡量使用每个特征分割的质量从而选择最佳分割</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_features</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义了每个决策树中可用于分割的最大特征数量</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">增加最大特征数通常可以改善性能，但是一个非常高的值会减少各个树之间的差异性</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_depth</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">随机森林有多个决策树，此参数定义树的最大深度</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">min_samples_split</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">用于在尝试拆分之前定义叶节点中所需的最小样本数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">如果样本数小于所需数量，则不分割节点</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">min_samples_leaf</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义了叶子节点所需的最小样本数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">较小的叶片尺寸使得模型更容易捕获训练数据中的噪声</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_leaf_nodes</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">此参数指定每个树的最大叶子节点数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">当叶节点的数量变得等于最大叶节点时，树停止分裂</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">n_jobs</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">这表示并行运行的作业数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">如果要在系统中的所有核心上运行，请将值设置为-1</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">random_state</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">此参数用于定义随机选择</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它用于各种模型之间的比较</span></p></li></ul></li></ul> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></h4> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">4.3 AdaBoost</span></strong></h4> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">自适应增强或AdaBoost是最简单的boosting算法之一。通常用决策树来建模。创建多个顺序模型，每个模型都校正上一个模型的错误。AdaBoost为错误预测的观测值分配权重，后续模型来正确预测这些值。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">以下是执行AdaBoost算法的步骤：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第一步：</span></strong><span style="font-size:15px;letter-spacing:1px;">最初，数据集中的所有观察值都具有相同的权重。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第二步：</span></strong><span style="font-size:15px;letter-spacing:1px;">在数据子集上建立一个模型。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第三步：</span></strong><span style="font-size:15px;letter-spacing:1px;">使用此模型，可以对整个数据集进行预测。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第四步：</span></strong><span style="font-size:15px;letter-spacing:1px;">通过比较预测值和实际值来计算误差。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第五步：</span></strong><span style="font-size:15px;letter-spacing:1px;">在创建下一个模型时，会给预测错误的数据点赋予更高的权重。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第六步：</span></strong><span style="font-size:15px;letter-spacing:1px;">可以使用误差值确定权重。例如，误差越大，分配给观察值的权重越大。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第七步：</span></strong><span style="font-size:15px;letter-spacing:1px;">重复该过程直到误差函数没有改变，或达到估计器数量的最大限制。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong></p> 
 <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;"><strong><span style="color:rgb(136,136,136);font-size:14px;"><br></span></strong></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">from sklearn.ensemble import AdaBoostClassifier</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model = AdaBoostClassifier(random_state=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">0.81081081081081086</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">回归问题示例代码：</span></p> 
 <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">from sklearn.ensemble import AdaBoostRegressor</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model = AdaBoostRegressor()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">参数：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">base_estimators</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它用于指定基础估计器的类型，即用作基础学习器的机器学习算法</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">n_estimators</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它定义了基础估计器的数量</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">默认值为10，但可以设为较高的值以获得更好的性能</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">learning_rate</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p><span style="font-size:15px;letter-spacing:1px;"><span style="line-height:0px;">‍</span>此参数控制估计器在最终组合中的贡献</span></p></li><li><p style="line-height:1.5em;"><span style="line-height:0px;">‍</span><span style="font-size:15px;letter-spacing:1px;">在learning_rate和n_estimators之间需要进行权衡</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_depth</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义单个估计器的最大深度</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">调整此参数以获得最佳性能</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">n_jobs</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">指定允许使用的处理器数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">将值设为-1，可以使用允许的最大处理器数量</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">random_state</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">用于指定随机数据拆分的整数值</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">如果给出相同的参数和训练数据，random_state的确定值将始终产生相同的结果</span></p></li></ul></li></ul> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">4.4 Gradient Boosting（梯度提升GBM）</span></strong></h4> 
 <p><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">Gradient Boosting或GBM是另一种集成机器学习算法，适用于回归和分类问题。GBM使用boosting技术，结合了许多弱学习器，以形成一个强大的学习器。回归树用作基础学习器，每个后续的树都是基于前一棵树计算的错误构建的。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">我们将使用一个简单的例子来理解GBM算法。我们会使用以下数据预测一群人的年龄：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p><img style="width:553px;" src="https://images2.imgbox.com/1e/e0/xa919JYL_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;"></span><br></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;"><strong>第一步：</strong></span><span style="font-size:15px;letter-spacing:1px;">假设平均年龄是数据集中所有观测值的预测值。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第二步：</span></strong><span style="font-size:15px;letter-spacing:1px;">使用该平均预测值和年龄的实际值来计算误差：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p><img src="https://images2.imgbox.com/6c/0d/F1AIFDLB_o.png" alt="640?wx_fmt=png"></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第三步：</span></strong><span style="font-size:15px;letter-spacing:1px;">使用上面计算的误差作为目标变量创建树模型。我们的目标是找到最佳分割以最小化误差。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第四步：</span></strong><span style="font-size:15px;letter-spacing:1px;">该模型的预测与预测1相结合：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p><img style="width:553px;" src="https://images2.imgbox.com/51/b4/NYIXjF3f_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第五步：</span></strong><span style="font-size:15px;letter-spacing:1px;">上面计算的这个值是新的预测。</span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第六步：</span></strong><span style="font-size:15px;letter-spacing:1px;">使用此预测值和实际值计算新误差：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p><img src="https://images2.imgbox.com/f3/93/GutpD2l9_o.png" alt="640?wx_fmt=png"></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span><br></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">第七步：</span></strong><span style="font-size:15px;letter-spacing:1px;">重复步骤2到6，直到最大迭代次数（或误差函数不再改变）</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">from sklearn.ensemble import GradientBoostingClassifier</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">model= GradientBoostingClassifier(learning_rate=0.01,random_state=1)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">model.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">model.score(x_test,y_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;letter-spacing:normal;color:rgb(136,136,136);">0.81621621621621621</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">回归问题示例代码：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">from sklearn.ensemble import GradientBoostingRegressor</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">model= GradientBoostingRegressor()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">model.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;color:rgb(136,136,136);font-size:14px;">model.score(x_test,y_test)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">参数：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">min_samples_split</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义考虑被拆分的节点中所需的最小样本数（或观察值数）</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">用于控制过配合。较高的值会阻止模型学习关系，这种关系可能对为一棵树选择的特定样本高度特定</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">min_samples_leaf</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义终端或叶节点中所需的最小样本数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">一般来说，应该为不平衡的分类问题选择较低的值，因为少数群体占大多数的地区将非常小</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">min_weight_fraction_leaf</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><span style="line-height:0px;">‍</span>与min_samples_leaf类似，但定义为观察总数的一个比例而不是整数</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="line-height:0px;">‍</span><span style="font-size:15px;letter-spacing:1px;">max_depth</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">树的最大深度。</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">用于控制过拟合，因为更高的深度将让模型学习到非常特定于某个样本的关系</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">应该使用CV进行调整</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_leaf_nodes</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">树中终端节点或叶子的最大数量</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">可以用于代替max_depth。由于创建了二叉树，因此深度'n'将产生最多2 ^ n个叶子</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">如果它被定义，则GBM会忽略max_depth</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_features</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">搜索最佳拆分时要考虑的特征数量。这些特征将被随机选择。</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">作为一个经验法则，特征总数的平方根效果很好，但我们可以尝试直到特征总数的30-40％。</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">较高的值可能导致过度拟合，但通常取决于具体情况。</span></p></li></ul></li></ul> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></h4> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">4.5 XGBoost</span></strong></h4> 
 <h4 style="line-height:1.5em;"><br></h4> 
 <h4 style="line-height:1.5em;">XGBoost（extreme Gradient Boosting）是梯度提升算法的高级实现。实践证明，XGBoost是一种高效的ML算法，广泛应用于机器学习竞赛和黑客马拉松。 XGBoost具有很高的预测能力，几乎比其他梯度提升技术快10倍。它还包括各种正规化，可减少过拟合并提高整体性能。因此，它也被称为“正则化提升”技术。</h4> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">让我们看看XGBoost为何比其他技术更好：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">正则化：</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">标准GBM实现没有像XGBoost那样的正则化</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">因此，XGBoost还有助于减少过拟合</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">并行处理：</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">XGBoost实现并行处理，并且比GBM更快</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">XGBoost还支持Hadoop上的实现</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">高灵活性：</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">XGBoost允许用户自定义优化目标和评估标准，为模型添加全新维度</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">处理缺失值：</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">XGBoost有一个内置的例程来处理缺失值</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">树剪枝：</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">XGBoost先进行分割，直到指定的max_depth，然后开始向后修剪树并删除没有正向增益的分割</span></p></li></ul></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:disc;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">内置交叉验证：</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">XGBoost允许用户在提升过程的每次迭代中运行交叉验证，因此很容易在一次运行中获得精确的最佳提升迭代次数</span></p></li></ul></li></ul> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">由于XGBoost会自行处理缺失值，因此你不必再处理。你可以跳过上述代码中缺失值插补的步骤。如下展示了如何应用xgboost：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">import xgboost as xgb</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">0.82702702702702702</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">回归问题示例代码：</span></p> 
 <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">import xgboost as xgb</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model=xgb.XGBRegressor()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model.fit(x_train, y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:14px;letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">参数：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">nthread</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">这用于并行处理，应输入系统中的核心数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">如果你希望在所有核心上运行，请不要输入此值。该算法将自动检测</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">eta</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">类似于GBM中的学习率</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">通过缩小每一步的权重，使模型更加健壮</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">min_child_weight</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义子节点中所有观察值的最小权重和</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">用于控制过拟合。较高的值会阻止模型学习关系，这种关系可能高度特定于为某个树所选的具体样本</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_depth</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它用于定义最大深度</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">更高的深度将让模型学习到非常特定于某个样本的关系</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_leaf_nodes</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">树中终端节点或叶子的最大数量</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">可以用来代替max_depth。由于创建了二叉树，因此深度'n'将产生最多2 ^ n个叶子</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">如果已定义，则GBM将忽略max_depth</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">gamma</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">仅当产生的分割能给出损失函数的正向减少时，才分割节点。Gamma指定进行分割所需的最小损失减少量。</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">使算法保守。值可能会根据损失函数而有所不同，因此应进行调整</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">subsample</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">与GBM的子样本相同。表示用于每棵树随机采样的观察值的比例。</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">较低的值使算法更加保守并防止过拟合，但是太小的值可能导致欠拟合。</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">colsample_bytree</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它类似于GBM中的max_features</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">表示要为每个树随机采样的列的比例</span></p></li></ul></li></ul> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">4.6 Light GBM</span></strong></h4> 
 <h4 style="line-height:1.5em;"><br></h4> 
 <h4 style="line-height:1.5em;"><span style="font-size:15px;">在讨论Light GBM如何工作之前，先理解为什么在我们有如此多其他算法时（例如我们上面看到的算法）我们还需要这个算法。当数据集非常大时，Light GBM会击败所有其他算法。与其他算法相比，Light GBM在较大的数据集上运行所需的时间较短。</span></h4> 
 <p style="line-height:1.5em;"><span style="letter-spacing:1px;font-size:15px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">LightGBM是一个梯度提升框架，它使用基于树的算法并遵循逐叶子的方式（leaf-wise），而其他算法以逐层级（level-wise）模式工作。下图帮助你更好地理解二者差异：</span></p> 
 <p><img src="https://images2.imgbox.com/81/92/t8cjkAZQ_o.png" alt="640?wx_fmt=png"></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"></span></p> 
 <p><img style="width:553px;" src="https://images2.imgbox.com/95/9e/8eRUsCau_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">逐叶子方式可能在较小的数据集上导致过拟合，但可以通过使用'max_depth'参数来避免这种情况。你可以在本文中阅读有关Light GBM及其与XGB比较的更多信息。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong></p> 
 <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;"><strong><br></strong></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">import lightgbm as lgb</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">train_data=lgb.Dataset(x_train,label=y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">#define parameters</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">params = {'learning_rate':0.001}</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">model= lgb.train(params, train_data, 100) </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">y_pred=model.predict(x_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">for i in range(0,185):</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">   if y_pred[i]&gt;=0.5: </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">   y_pred[i]=1</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">else: </span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">   y_pred[i]=0</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="letter-spacing:normal;font-size:14px;color:rgb(136,136,136);">0.81621621621621621</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">回归问题示例代码：</span></p> 
 <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">import lightgbm as lgb</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">train_data=lgb.Dataset(x_train,label=y_train)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">params = {'learning_rate':0.001}</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model= lgb.train(params, train_data, 100)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">from sklearn.metrics import mean_squared_error</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">rmse=mean_squared_error(y_pred,y_test)**0.5</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">参数：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">num_iterations</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它定义了要执行的提升迭代次数</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">num_leaves</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">此参数用于设置要在树中形成的叶子数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">在Light GBM的情况下，由于拆分是按逐叶子方式而不是深度方式进行的，因此num_leaves必须小于2 ^（max_depth），否则可能导致过拟合</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">min_data_in_leaf</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">非常小的值可能导致过拟合</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它也是处理过拟合的最重要的参数之一</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_depth</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它指定树可以生长到的最大深度或级别</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">此参数的值非常高可能会导致过拟合</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">bagging_fraction</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它用于指定每次迭代使用的数据比例</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">此参数通常用于加速训练</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">max_bin</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义特征值将被分桶的最大分箱数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">较小的max_bin值可以节省大量时间，因为它在离散分箱中存储特征值，这在计算开销上是便宜的</span></p></li></ul></li></ul> 
 <h4 style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></h4> 
 <h4 style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">4.7 CatBoost</span></strong></h4> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">处理类别型变量是一个繁琐的过程，尤其是你有大量此类变量时。当你的类别变量有很多标签（即它们是高度基数）时，对它们执行one-hot编码会指数级的增加维度，会让数据集的使用变得非常困难。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">CatBoost可以自动处理类别型变量，并且不需要像其他机器学习算法那样进行大量数据预处理。这篇文章详细解释了CatBoost。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><strong><span style="font-size:15px;letter-spacing:1px;">示例代码：</span></strong></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">CatBoost算法有效地处理类别型变量。因此，无需对变量执行one-hot编码。只需加载文件，估算缺失值，就可以了：</span></p> 
 <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">from catboost import CatBoostClassifier</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model=CatBoostClassifier()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">categorical_features_indices = np.where(df.dtypes != np.float)[0]</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.fit(x_train,y_train,cat_features=([ 0,  1, 2, 3, 4, 10]),eval_set=(x_test, y_test))</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">0.80540540540540539</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">回归问题示例代码：</span></p> 
 <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:15px;letter-spacing:normal;"><br></span></p> 
 <blockquote> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:15px;letter-spacing:normal;">from catboost import CatBoostRegressor</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:15px;letter-spacing:normal;">model=CatBoostRegressor()</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:15px;letter-spacing:normal;">categorical_features_indices = np.where(df.dtypes != np.float)[0]</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:15px;letter-spacing:normal;">model.fit(x_train,y_train,cat_features=([ 0,  1, 2, 3, 4, 10]),eval_set=(x_test, y_test))</span></p> 
  <pre></pre> 
  <p style="line-height:normal;"><span style="color:rgb(136,136,136);font-size:15px;letter-spacing:normal;">model.score(x_test,y_test)</span></p> 
 </blockquote> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"><br></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">参数：</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">loss_function</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义用于训练的度量标准</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">iterations</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">可以构建最多多少棵树</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">树的最终数量可能小于或等于此数字</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">learning_rate</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义学习率</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">用于减少梯度步骤</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">border_count</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它指定数值型特征的拆分数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它类似于max_bin参数</span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">depth</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">定义树的深度   </span></p></li></ul></li></ul> 
 <ul style="list-style-type:disc;" class="list-paddingleft-2"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">random_seed</span></p></li></ul> 
 <ul class="list-paddingleft-2" style="list-style-type:square;"><li> 
   <ul class="list-paddingleft-2" style="list-style-type:circle;"><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">此参数类似于我们之前看到的'random_state'参数</span></p></li><li><p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">它是一个整数值，用于定义训练的随机种子</span></p></li></ul></li></ul> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">现在来到了集成算法这一章节的末尾。我们在这篇文章中已经涵盖了很多内容！</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <h3 style="line-height:1.5em;text-align:center;"><span style="color:rgb(166,91,203);"><strong><span style="font-size:15px;letter-spacing:1px;">结语</span></strong></span></h3> 
 <p><span style="color:rgb(166,91,203);"><strong><span style="font-size:15px;letter-spacing:1px;"><br></span></strong></span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">集成模型可以指数级地提升模型的性能，有时可以成为第一名和第二名之间的决定因素！在本文中，我们介绍了各种集成学习技术，并了解了这些技术如何应用于机器学习算法。此外，我们在贷款预测数据集上运用了算法。</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;">本文为你提供了此主题的扎实理解。如果还有任何建议或问题，请分享在下面的评论部分。此外，我鼓励你实现这些算法，并与我们分享你的结果！</span></p> 
 <p style="line-height:1.5em;"><span style="font-size:15px;letter-spacing:1px;"> </span></p> 
 <h3 style="text-align:left;line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">原文标题：</span></h3> 
 <h3 style="text-align:left;line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">A Comprehensive Guide to Ensemble Learning(with Python codes)</span></h3> 
 <p style="text-align:left;line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">原文链接：</span></p> 
 <p style="text-align:left;line-height:normal;"><span style="font-size:14px;color:rgb(136,136,136);letter-spacing:normal;">https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/</span></p> 
 <p style="min-height:1em;"><strong>译者简介</strong></p> 
 <img src="https://images2.imgbox.com/8c/b3/xvqsWpo4_o.png" alt="640?wx_fmt=jpeg"> 
 <p style="clear:none;min-height:1em;"><strong>和中华，</strong><span style="letter-spacing:0px;">留德软件工程硕士。由于对机器学习感兴趣，硕士论文选择了利用遗传算法思想改进传统kmeans。目前在杭州进行大数据相关实践。加入数据派THU希望为IT同行们尽自己一份绵薄之力，也希望结交许多志趣相投的小伙伴。</span><br></p> 
 <p style="min-height:1em;"><strong>翻译组招募信息</strong></p> 
 <p style="min-height:1em;line-height:normal;"><strong style="letter-spacing:0px;line-height:1.6;">工作内容：</strong><span style="line-height:1.6;">将选取好的外文前沿文章准确地翻译成流畅的中文。如果你是数据科学/统计学/计算机专业的留学生，或在海外从事相关工作，或对自己外语水平有信心的朋友，数据派翻译组欢迎你们加入！</span></p> 
 <p style="min-height:1em;line-height:normal;"><strong style="line-height:1.6;">你能得到：</strong><span style="line-height:1.6;">提高对于数据科学前沿的认知，提高对外文新闻来源渠道的认知，海外的朋友可以和国内技术应用发展保持联系，数据派团队产学研的背景为志愿者带来好的发展机遇。</span><br><strong style="letter-spacing:0px;line-height:1.6;"></strong></p> 
 <p style="min-height:1em;line-height:normal;"><strong style="line-height:1.6;">其他福利：</strong><span style="line-height:1.6;">和来自于名企的数据科学工作者，北大清华以及海外等名校学生共同合作、交流。</span><br><strong></strong></p> 
 <p style="min-height:1em;"><strong></strong></p> 
 <p style="min-height:1em;text-align:center;"><strong>点击文末<span style="color:rgb(166,91,203);">“阅读原文”</span>加入数据派团队~</strong></p> 
 <p style="min-height:1em;text-align:center;"><span style="color:rgb(166,91,203);letter-spacing:1px;"><strong>转载须知</strong></span></p> 
 <p style="min-height:1em;">如需转载，请在开篇显著位置注明作者和出处（转自：数据派THU ID：DatapiTHU），并在文章结尾放置数据派醒目二维码。有原创标识文章，请发送【文章名称-待授权公众号名称及ID】至联系邮箱，申请白名单授权并按要求编辑。</p> 
 <p style="min-height:1em;">发布后请将链接反馈至联系邮箱（见下方）。未经许可的转载以及改编者，我们将依法追究其法律责任。</p> 
 <br> 
 <p style="min-height:1em;"><img style="color:rgb(51,51,51);" src="https://images2.imgbox.com/ca/dd/UOu9Pslm_o.png" alt="640?wx_fmt=png"></p> 
 <p style="min-height:1em;"><img width="556" src="https://images2.imgbox.com/7d/c9/hccuIOXn_o.png" alt="640?wx_fmt=jpeg"></p> 
 <p style="min-height:1em;">点击<strong>“阅读原文”</strong>拥抱组织</p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0103e250bf04dd678b7035babc3c53df/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">线性插值、Sin插值、震荡插值</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4c945aa07365ac61696cbc1955ac5a47/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">VS2015 用附加进程的方式进行调试-遇到的问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>