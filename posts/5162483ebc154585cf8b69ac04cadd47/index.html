<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Oracle Linux7.6安装Oracle19c RAC - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Oracle Linux7.6安装Oracle19c RAC" />
<meta property="og:description" content="数据库规划 1、操作系统：Oracle Enterprise Linux 7.6，内存8G 2、集群软件：Grid Insfrastructer 19.3.0 3、数据库软件：Database 19.3.0 4、数据库名：cwdb 5、实例名：cwdb1/cwdb2 6、数据块大小：8192 7、数据库字符集：UTF8 网络规划 主机名
IP
IP类型
网关
网卡
cwdb01
192.168.6.101
public ip
192.168.6.1
eth0
cwdb02
192.168.6.102
public ip
eth0
cwdb01-priv
10.0.0.101
private ip
10.0.0.1
eth1
cwdb02-priv
10.0.0.102
private ip
eth1
cwdb01-vip
192.168.6.103
virtual ip
192.168.6.1
eth2
cwdb02-vip
192.168.6.104
virtual ip
eth2
cwdb-scan
192.168.6.105
scan ip
192.168.6.1
存储规划 磁盘组
OS
ORACLE
&#43;DGOCR
&#43;DGDATA
&#43;DGFRA
存储类型
文件系统
文件系统
ASM" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/5162483ebc154585cf8b69ac04cadd47/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-11T18:36:15+08:00" />
<meta property="article:modified_time" content="2023-09-11T18:36:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Oracle Linux7.6安装Oracle19c RAC</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>数据库规划</h2> 
<pre><code class="language-bash">1、操作系统：Oracle Enterprise Linux 7.6，内存8G
2、集群软件：Grid Insfrastructer 19.3.0
3、数据库软件：Database 19.3.0
4、数据库名：cwdb
5、实例名：cwdb1/cwdb2
6、数据块大小：8192
7、数据库字符集：UTF8</code></pre> 
<h2>网络规划</h2> 
<table><tbody><tr><td> <p>主机名</p> </td><td> <p>IP</p> </td><td> <p>IP类型</p> </td><td> <p>网关</p> </td><td> <p>网卡</p> </td></tr><tr><td> <p>cwdb01</p> </td><td> <p>192.168.6.101</p> </td><td> <p>public ip</p> </td><td> <p>192.168.6.1</p> </td><td> <p>eth0</p> </td></tr><tr><td> <p>cwdb02</p> </td><td> <p>192.168.6.102</p> </td><td> <p>public ip</p> </td><td></td><td> <p>eth0</p> </td></tr><tr><td> <p>cwdb01-priv</p> </td><td> <p>10.0.0.101</p> </td><td> <p>private ip</p> </td><td> <p>10.0.0.1</p> </td><td> <p>eth1</p> </td></tr><tr><td> <p>cwdb02-priv</p> </td><td> <p>10.0.0.102</p> </td><td> <p>private ip</p> </td><td></td><td> <p>eth1</p> </td></tr><tr><td> <p>cwdb01-vip</p> </td><td> <p>192.168.6.103</p> </td><td> <p>virtual ip</p> </td><td> <p>192.168.6.1</p> </td><td> <p>eth2</p> </td></tr><tr><td> <p>cwdb02-vip</p> </td><td> <p>192.168.6.104</p> </td><td> <p>virtual ip</p> </td><td></td><td> <p>eth2</p> </td></tr><tr><td> <p>cwdb-scan</p> </td><td> <p>192.168.6.105</p> </td><td> <p>scan ip</p> </td><td> <p>192.168.6.1</p> </td><td></td></tr></tbody></table> 
<h2>存储规划</h2> 
<table><tbody><tr><td> <p>磁盘组</p> </td><td> <p>OS</p> </td><td> <p>ORACLE</p> </td><td> <p>+DGOCR</p> </td><td> <p>+DGDATA</p> </td><td> <p>+DGFRA</p> </td></tr><tr><td> <p>存储类型</p> </td><td> <p>文件系统</p> </td><td> <p>文件系统</p> </td><td> <p>ASM</p> </td><td> <p>ASM</p> </td><td> <p>ASM</p> </td></tr><tr><td> <p>磁盘组容量</p> </td><td> <p>100G</p> </td><td> <p>200G</p> </td><td> <p>9G</p> </td><td> <p>8G</p> </td><td> <p>4G</p> </td></tr><tr><td> <p>磁盘数量</p> </td><td> <p>1</p> </td><td> <p>1</p> </td><td> <p>3</p> </td><td> <p>2</p> </td><td> <p>1</p> </td></tr><tr><td> <p>每个磁盘大小</p> </td><td> <p>100G</p> </td><td> <p>200G</p> </td><td> <p>3G</p> </td><td> <p>4G</p> </td><td> <p>4G</p> </td></tr></tbody></table> 
<h2> 关闭防火墙</h2> 
<pre><code class="language-bash">systemctl stop firewalld.service
systemctl disable firewalld.service
systemctl stop NetworkManager.service
systemctl disable NetworkManager.service</code></pre> 
<h2>禁用selinux</h2> 
<pre><code class="language-bash">sed -n '/SELINUX=enforcing/c SELINUX=disabled' /etc/sysconfig/selinux</code></pre> 
<h2>修改hosts配置文件</h2> 
<pre><code>vim /etc/hosts

#public ip
192.168.6.101 cwdb01
192.168.6.102 cwdb02

#private ip

10.0.0.101 cwdb01-priv
10.0.0.102 cwdb02-priv

#virtual ip

192.168.6.103 cwdb01-vip
192.168.6.104 cwdb02-vip

#scan ip

192.168.6.105 cluster-scan</code></pre> 
<h2>创建组、用户、目录</h2> 
<pre><code>1、创建组
groupadd -g 54321 oinstall
groupadd -g 54322 dba
groupadd -g 54323 oper
groupadd -g 54324 asmdba
groupadd -g 54325 asmoper
groupadd -g 54326 asmadmin

groupadd -g 54327 backupdba
groupadd -g 54328 dgdba
groupadd -g 54329 kmdba

2、创建用户oracle和grid
useradd -u 54321 -g oinstall -G dba,oper,asmdba,backupdba,dgdba,kmdba oracle
echo "oracle" | passwd --stdin oracle
useradd -u 54322 -g oinstall -G dba,asmdba,asmoper,asmadmin grid
echo "oracle" | passwd --stdin grid

3、创建目录
mkdir -p /u01/app/grid  
mkdir -p /u01/app/19.3.0/grid
mkdir -p /u01/app/oracle
mkdir -p /u01/app/oracle/product/19.3.0/dbhome_1
chown -R grid:oinstall /u01
chown -R oracle:oinstall /u01/app/oracle
chmod -R 775 /u01</code></pre> 
<h2>配置yum源</h2> 
<pre><code>1、挂载光盘
mount /dev/sr0 /mnt
cd /etc/yum.repos.d/
mv * /root

2、创建yum源
vim yum.repo

cat&lt;&lt;EOF&gt;&gt;yum.repo
[yum]
name=yum
baseurl=file:///mnt
gpgcheck=0
enabled=1
EOF

3、清理缓存
yum clean all
yum makecache
yum repolist

4、安装测试
yum install xorg-x11-apps.x86_64 -y

5、执行xclock如果出现时钟说明安装成功</code></pre> 
<h2>修改资源限制参数</h2> 
<pre><code>cat&lt;&lt;EOF&gt;&gt;/etc/security/limits.conf
grid soft nproc 16384
grid hard nproc 16384
grid soft nofile 65536
grid hard nofile 65536
grid soft stack 32768
grid hard stack 32768
oracle soft nproc 16384
oracle hard nproc 16384
oracle soft nofile 65536
oracle hard nofile 65536
oracle soft stack 32768
oracle hard stack 32768
oracle soft memlock 6000000
oracle hard memlock 6000000
EOF

ulimit -a</code></pre> 
<h2>控制给用户分配的资源</h2> 
<pre><code>echo "session    required     pam_limits.so" &gt;&gt; /etc/pam.d/login</code></pre> 
<h2>修改内核参数</h2> 
<pre><code>cat&lt;&lt;EOF&gt;&gt;/etc/sysctl.conf
fs.aio-max-nr = 1048576
fs.file-max = 6815744
kernel.sem = 250 32000 100 128
net.ipv4.ip_local_port_range = 9000 65500
net.ipv4.conf.all.rp_filter = 2
net.ipv4.conf.default.rp_filter = 2
net.ipv4.ip_forward = 1
net.core.rmem_default = 262144
net.core.rmem_max = 4194304
net.core.wmem_default = 262144
net.core.wmem_max = 1048586
kernel.panic_on_oops = 1
kernel.shmmax = 5033164800
kernel.shmall = 1228800
kernel.shmmni = 4096    
vm.nr_hugepages = 2500
EOF

让参数生效
sysctl -p

</code></pre> 
<h2>nproc参数</h2> 
<pre><code class="language-bash">echo "*          soft    nproc     16384"&gt;&gt;/etc/security/limits.d/90-nproc.conf</code></pre> 
<h2>关闭透明大页</h2> 
<pre><code class="language-bash">开启大内存后，需要关闭透明大页

cat&lt;&lt;EOF&gt;&gt;/etc/rc.d/rc.local
if test -f /sys/kernel/mm/transparent_hugepage/enabled; then
echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled
fi
if test -f /sys/kernel/mm/transparent_hugepage/defrag; then
echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag
fi
EOF

chmod +x /etc/rc.d/rc.local</code></pre> 
<h2>关闭numa功能</h2> 
<pre><code class="language-bash">yum install numactl -y

vim /etc/default/grub 
GRUB_CMDLINE_LINUX="rhgb quiet numa=off"
重新编译
grub2-mkconfig -o /etc/grub2.cfg </code></pre> 
<h2>共享内存段/dev/shm</h2> 
<pre><code class="language-bash">mount -o remount,size=8g /dev/shm/</code></pre> 
<h2>修改时区</h2> 
<pre><code class="language-bash">ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
hwclock</code></pre> 
<h2>配置NOZEROCONF</h2> 
<pre><code class="language-bash">防止169.254.0.0/255.255.0.0自动加入到路由表（Doc ID 1161144.1）
vim /etc/sysconfig/network
NOZEROCONF=yes

cat&lt;&lt;EOF&gt;&gt;/etc/sysconfig/network
NOZEROCONF=yes
EOF</code></pre> 
<h2>修改nsswitch.conf</h2> 
<pre><code class="language-bash">IS可能会引起scan域名解析异常

vim /etc/nsswitch.conf
hosts:      files dns myhostname
改为
hosts:      files dns myhostname nis</code></pre> 
<h2>关闭avahi-daemon守护进程</h2> 
<pre><code class="language-bash">systemctl stop avahi-daemon.socket avahi-daemon.service 
systemctl disable avahi-daemon.socket avahi-daemon.service </code></pre> 
<h2>禁用NTP</h2> 
<pre><code class="language-bash">systemctl stop ntpdate
systemctl disable ntpdate</code></pre> 
<h2>配置grid用户环境变量</h2> 
<pre><code class="language-bash">
su - grid
vim .bash_profile 

PS1="[`whoami`@`hostname`:"'$PWD]$ '
export PS1
umask 022
#alias sqlplus="rlwrap sqlplus"
export TMP=/tmp
export LANG=en_US.UTF8
export TMPDIR=$TMP
export TZ=Asia/Shanghai
ORACLE_SID=+ASM; export ORACLE_SID
ORACLE_TERM=xterm; export ORACLE_TERM
ORACLE_BASE=/u01/app/grid; export ORACLE_BASE
ORACLE_HOME=/u01/app/19.3.0/grid; export ORACLE_HOME
NLS_DATE_FORMAT="yyyy-mm-dd HH24:MI:SS"; export NLS_DATE_FORMAT
PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin; export PATH
THREADS_FLAG=native; export THREADS_FLAG
if [ $USER = "oracle" ] || [ $USER = "grid" ]; then
        if [ $SHELL = "/bin/ksh" ]; then
            ulimit -p 16384
              ulimit -n 65536
  else
   ulimit -u 16384 -n 65536
      fi
    umask 022
fi</code></pre> 
<h2>配置oracle用户环境变量</h2> 
<pre><code class="language-bash">su - oracle
vim .bash_profile 

PS1="[`whoami`@`hostname`:"'$PWD]$ '
#alias sqlplus="rlwrap sqlplus"
#alias rman="rlwrap rman"
export PS1
export TMP=/tmp
export LANG=en_US.UTF8
export TMPDIR=$TMP
export TZ=Asia/Shanghai
export ORACLE_UNQNAME=cwdb
ORACLE_SID=cwdb; export ORACLE_SID
ORACLE_BASE=/u01/app/oracle; export ORACLE_BASE
ORACLE_HOME=$ORACLE_BASE/product/19.3.0/dbhome_1; export ORACLE_HOME
ORACLE_TERM=xterm; export ORACLE_TERM
NLS_DATE_FORMAT="yyyy-mm-dd HH24:MI:SS"; export NLS_DATE_FORMAT
NLS_LANG=AMERICAN_AMERICA.UTF8;export NLS_LANG
PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin; export PATH
THREADS_FLAG=native; export THREADS_FLAG
if [ $USER = "oracle" ] || [ $USER = "grid" ]; then
        if [ $SHELL = "/bin/ksh" ]; then
            ulimit -p 16384
              ulimit -n 65536
  else
   ulimit -u 16384 -n 65536
      fi
    umask 022
fi</code></pre> 
<h2>添加磁盘</h2> 
<pre><code class="language-bash">两台虚拟机都要添加以下配置信息

diskLib.dataCacheMaxSize = "0"
diskLib.dataCacheMaxReadAheadSize = "0"
diskLib.DataCacheMinReadAheadSize = "0"
diskLib.dataCachePageSize = "4096"
diskLib.maxUnsyncedWrites = "0"

##参数必须设为TRUE，否则UUDI获取失败
disk.EnableUUID="TRUE"
disk.locking = "FALSE"

####注意是scsi0不是scsi1，否则ASM肯定有问题
scsi0.sharedBus = "virtual"

scsi1节点2执行root脚本报错，找不到共享磁盘dgocr

判断scsi0还是scsi1
通过创建的磁盘虚拟设备节点来确定</code></pre> 
<h2>磁盘分区规划</h2> 
<pre><code class="language-bash">1、节点cwdb01
[root@cwdb01 ~]# fdisk -l | grep /dev/sd | grep "3221 MB"
Disk /dev/sdd: 3221 MB, 3221225472 bytes, 6291456 sectors
Disk /dev/sdc: 3221 MB, 3221225472 bytes, 6291456 sectors
Disk /dev/sde: 3221 MB, 3221225472 bytes, 6291456 sectors

[root@cwdb01 ~]# fdisk -l | grep /dev/sd | grep "6442 MB"
Disk /dev/sdf: 6442 MB, 6442450944 bytes, 12582912 sectors

[root@cwdb01 ~]# fdisk -l | grep /dev/sd | grep "4294 MB"
Disk /dev/sdg: 4294 MB, 4294967296 bytes, 8388608 sectors

[root@cwdb01 ~]# fdisk -l | grep /dev/sd | grep "5368 MB"
Disk /dev/sdh: 5368 MB, 5368709120 bytes, 10485760 sectors

2、节点cwdb02
[root@cwdb02 ~]# fdisk -l | grep /dev/sd | grep "3221 MB"
Disk /dev/sdc: 3221 MB, 3221225472 bytes, 6291456 sectors
Disk /dev/sdd: 3221 MB, 3221225472 bytes, 6291456 sectors
Disk /dev/sde: 3221 MB, 3221225472 bytes, 6291456 sectors

[root@cwdb02 ~]# fdisk -l | grep /dev/sd | grep "6442 MB"
Disk /dev/sdf: 6442 MB, 6442450944 bytes, 12582912 sectors

[root@cwdb02 ~]# fdisk -l | grep /dev/sd | grep "4294 MB"
Disk /dev/sdg: 4294 MB, 4294967296 bytes, 8388608 sectors

[root@cwdb02 ~]# fdisk -l | grep /dev/sd | grep "5368 MB"
Disk /dev/sdh: 5368 MB, 5368709120 bytes, 10485760 sectors</code></pre> 
<h2>配置udev</h2> 
<pre><code class="language-bash">1、查看配置文件
[root@cwdb01 ~]# ll -h /etc/scsi_id.config
ls: cannot access /etc/scsi_id.config: No such file or directory

2、创建配置文件
[root@cwdb01 ~]# echo "options=--whitelisted --replace-whitespace"&gt;&gt;/etc/scsi_id.config
[root@cwdb02 ~]# echo "options=--whitelisted --replace-whitespace"&gt;&gt;/etc/scsi_id.config

3、获取UUID
[root@cwdb01 ~]# for i in c d e;
&gt; do
&gt; echo "sd$i" "`/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i`";
&gt; done
sdc 36000c295a1cb4a415ff58c9aafb4b819
sdd 36000c2953fcc4a1939d9f3e5799e54f3
sde 36000c29f394a3c1202c9e3706fc77444

[root@cwdb02 ~]# for i in c d e;
&gt; do
&gt; echo "sd$i" "`/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i`";
&gt; done
sdc 36000c295a1cb4a415ff58c9aafb4b819
sdd 36000c2953fcc4a1939d9f3e5799e54f3
sde 36000c29f394a3c1202c9e3706fc77444

4、生成udev路径
[root@cwdb01 ~]# for i in c d e;
&gt; do  
&gt; echo "KERNEL==\"sd?\",SUBSYSTEM==\"block\", PROGRAM==\"/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/\$name\",RESULT==\"`/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i`\", SYMLINK+=\"asm-disk$i\",OWNER=\"grid\", GROUP=\"asmadmin\",MODE=\"0660\""
&gt; done 
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c295a1cb4a415ff58c9aafb4b819", SYMLINK+="asm-diskc",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c2953fcc4a1939d9f3e5799e54f3", SYMLINK+="asm-diskd",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29f394a3c1202c9e3706fc77444", SYMLINK+="asm-diske",OWNER="grid", GROUP="asmadmin",MODE="0660"

[root@cwdb02 ~]# for i in c d e;
&gt; do  
&gt; echo "KERNEL==\"sd?\",SUBSYSTEM==\"block\", PROGRAM==\"/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/\$name\",RESULT==\"`/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i`\", SYMLINK+=\"asm-disk$i\",OWNER=\"grid\", GROUP=\"asmadmin\",MODE=\"0660\""
&gt; done 
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c295a1cb4a415ff58c9aafb4b819", SYMLINK+="asm-diskc",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c2953fcc4a1939d9f3e5799e54f3", SYMLINK+="asm-diskd",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29f394a3c1202c9e3706fc77444", SYMLINK+="asm-diske",OWNER="grid", GROUP="asmadmin",MODE="0660"

[root@cwdb01 ~]# for i in f g h;
&gt; do  
&gt; echo "KERNEL==\"sd?\",SUBSYSTEM==\"block\", PROGRAM==\"/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/\$name\",RESULT==\"`/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i`\", SYMLINK+=\"asm-disk$i\",OWNER=\"grid\", GROUP=\"asmadmin\",MODE=\"0660\""
&gt; done
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29e0760a588ce2eaa6dd59398e0", SYMLINK+="asm-diskf",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29fd42b869540f2625b5065c6b9", SYMLINK+="asm-diskg",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29e46541f9d0272e147e85f20be", SYMLINK+="asm-diskh",OWNER="grid", GROUP="asmadmin",MODE="0660"

[root@cwdb02 ~]# for i in f g h;
&gt; do  
&gt; echo "KERNEL==\"sd?\",SUBSYSTEM==\"block\", PROGRAM==\"/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/\$name\",RESULT==\"`/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i`\", SYMLINK+=\"asm-disk$i\",OWNER=\"grid\", GROUP=\"asmadmin\",MODE=\"0660\""
&gt; done
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29e0760a588ce2eaa6dd59398e0", SYMLINK+="asm-diskf",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29fd42b869540f2625b5065c6b9", SYMLINK+="asm-diskg",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29e46541f9d0272e147e85f20be", SYMLINK+="asm-diskh",OWNER="grid", GROUP="asmadmin",MODE="0660"

5、将所有的路径写入到/etc/udev/rules.d/99-oracle-asmdevices.rules文件中
[root@cwdb01 ~]# vi /etc/udev/rules.d/99-oracle-asmdevices.rules
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c295a1cb4a415ff58c9aafb4b819", SYMLINK+="asm-ocr01",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c2953fcc4a1939d9f3e5799e54f3", SYMLINK+="asm-ocr02",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29f394a3c1202c9e3706fc77444", SYMLINK+="asm-ocr03",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29e0760a588ce2eaa6dd59398e0", SYMLINK+="asm-system",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29fd42b869540f2625b5065c6b9", SYMLINK+="asm-data",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29e46541f9d0272e147e85f20be", SYMLINK+="asm-fra",OWNER="grid", GROUP="asmadmin",MODE="0660"

[root@cwdb02 ~]# vi /etc/udev/rules.d/99-oracle-asmdevices.rules
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c295a1cb4a415ff58c9aafb4b819", SYMLINK+="asm-ocr01",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c2953fcc4a1939d9f3e5799e54f3", SYMLINK+="asm-ocr02",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29f394a3c1202c9e3706fc77444", SYMLINK+="asm-ocr03",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29e0760a588ce2eaa6dd59398e0", SYMLINK+="asm-system",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29fd42b869540f2625b5065c6b9", SYMLINK+="asm-data",OWNER="grid", GROUP="asmadmin",MODE="0660"
KERNEL=="sd?",SUBSYSTEM=="block", PROGRAM=="/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name",RESULT=="36000c29e46541f9d0272e147e85f20be", SYMLINK+="asm-fra",OWNER="grid", GROUP="asmadmin",MODE="0660"

6、重新加载规则
[root@cwdb01 ~]# /sbin/udevadm control --reload-rules
[root@cwdb02 ~]# /sbin/udevadm control --reload-rules
[root@cwdb01 ~]# /sbin/udevadm trigger --type=devices --action=change
[root@cwdb02 ~]# /sbin/udevadm trigger --type=devices --action=change

[root@cwdb01 ~]# ll -h /dev/asm*
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-data -&gt; sdg
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-fra -&gt; sdh
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-ocr01 -&gt; sdc
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-ocr02 -&gt; sdd
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-ocr03 -&gt; sde
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-system -&gt; sdf

[root@cwdb02 ~]# ll -h /dev/asm*
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-data -&gt; sdg
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-fra -&gt; sdh
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-ocr01 -&gt; sdc
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-ocr02 -&gt; sdd
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-ocr03 -&gt; sde
lrwxrwxrwx 1 root root 3 Nov 14 14:00 /dev/asm-system -&gt; sdf

[root@cwdb02 ~]# ll -h /dev/sd*
brw-rw---- 1 root disk     8,   0 Nov 14 14:00 /dev/sda
brw-rw---- 1 root disk     8,   1 Nov 14 14:00 /dev/sda1
brw-rw---- 1 root disk     8,   2 Nov 14 14:00 /dev/sda2
brw-rw---- 1 root disk     8,  16 Nov 14 14:00 /dev/sdb
brw-rw---- 1 root disk     8,  17 Nov 14 14:00 /dev/sdb1
brw-rw---- 1 grid asmadmin 8,  32 Nov 14 14:00 /dev/sdc
brw-rw---- 1 grid asmadmin 8,  48 Nov 14 14:00 /dev/sdd
brw-rw---- 1 grid asmadmin 8,  64 Nov 14 14:00 /dev/sde
brw-rw---- 1 grid asmadmin 8,  80 Nov 14 14:00 /dev/sdf
brw-rw---- 1 grid asmadmin 8,  96 Nov 14 14:00 /dev/sdg
brw-rw---- 1 grid asmadmin 8, 112 Nov 14 14:00 /dev/sdh

[root@cwdb01 ~]# ll -h /dev/sd*
brw-rw---- 1 root disk     8,   0 Nov 14 14:00 /dev/sda
brw-rw---- 1 root disk     8,   1 Nov 14 14:00 /dev/sda1
brw-rw---- 1 root disk     8,   2 Nov 14 14:00 /dev/sda2
brw-rw---- 1 root disk     8,  16 Nov 14 14:00 /dev/sdb
brw-rw---- 1 root disk     8,  17 Nov 14 14:00 /dev/sdb1
brw-rw---- 1 grid asmadmin 8,  32 Nov 14 14:00 /dev/sdc
brw-rw---- 1 grid asmadmin 8,  48 Nov 14 14:00 /dev/sdd
brw-rw---- 1 grid asmadmin 8,  64 Nov 14 14:00 /dev/sde
brw-rw---- 1 grid asmadmin 8,  80 Nov 14 14:00 /dev/sdf
brw-rw---- 1 grid asmadmin 8,  96 Nov 14 14:00 /dev/sdg
brw-rw---- 1 grid asmadmin 8, 112 Nov 14 14:00 /dev/sdh</code></pre> 
<h2>安装GI</h2> 
<pre><code class="language-bash">1、上传安装介质
[oracle@cwdb01:/home/oracle]$ ll -h
total 5.6G
-rw-r--r--. 1 oracle oinstall  19K Nov 14 13:14 compat-libcap1-1.10-7.el7.x86_64.rpm
-rw-r--r--. 1 oracle oinstall 191K Nov 14 13:14 compat-libstdc++-33-3.2.3-72.el7.x86_64.rpm
-rw-r--r--. 1 oracle oinstall 2.9G Nov 14 13:34 LINUX.X64_193000_db_home.zip
-rw-r--r--. 1 oracle oinstall 2.7G Nov 14 13:33 LINUX.X64_193000_grid_home.zip

2、解压缩
[root@cwdb01 ~]# su - oracle 
[oracle@cwdb01:/home/oracle]$ ll -h
total 5.6G
-rw-r--r--. 1 oracle oinstall  19K Nov 14 13:14 compat-libcap1-1.10-7.el7.x86_64.rpm
-rw-r--r--. 1 oracle oinstall 191K Nov 14 13:14 compat-libstdc++-33-3.2.3-72.el7.x86_64.rpm
-rw-r--r--. 1 oracle oinstall 2.9G Nov 14 13:34 LINUX.X64_193000_db_home.zip
-rw-r--r--. 1 oracle oinstall 2.7G Nov 14 13:33 LINUX.X64_193000_grid_home.zip

[oracle@cwdb01:/home/oracle]$ cd /u01/app/19.3.0/grid/
[oracle@cwdb01:/u01/app/19.3.0/grid]$ unzip /home/oracle/LINUX.X64_193000_grid_home.zip

3、修改目录和用户
[root@cwdb01 ~]# chown -R grid:oinstall /u01/app/19.3.0/grid/

4、执行脚本
[grid@cwdb01:/home/grid]$ export DISPLAY=192.168.6.1:0.0
[grid@cwdb01:/home/grid]$ cd $ORACLE_HOME
[grid@cwdb01:/u01/app/19.3.0/grid]$ ./gridSetup.sh</code></pre> 
<h2>检查报错修复</h2> 
<pre><code class="language-bash">[root@cwdb01 ~]# mv /etc/resolv.conf /etc/resolv.conf.bak
[root@cwdb02 ~]# mv /etc/resolv.conf /etc/resolv.conf.bak

[root@cwdb01 ~]# systemctl status ntpdate
● ntpdate.service - Set time via NTP
   Loaded: loaded (/usr/lib/systemd/system/ntpdate.service; disabled; vendor preset: disabled)
   Active: inactive (dead)
   
[root@cwdb02 ~]# systemctl status ntpdate
● ntpdate.service - Set time via NTP
   Loaded: loaded (/usr/lib/systemd/system/ntpdate.service; disabled; vendor preset: disabled)
   Active: inactive (dead)

[root@cwdb01 ~]# rm -rf /etc/chrony.conf
[root@cwdb02 ~]# rm -rf /etc/chrony.conf </code></pre> 
<p><img alt="" height="924" src="https://images2.imgbox.com/29/03/QsrU4nS9_o.png" width="1200"> <img alt="" height="924" src="https://images2.imgbox.com/1a/84/tcU7edrB_o.png" width="1200"></p> 
<h2> 节点1执行root脚本</h2> 
<pre><code class="language-bash">[root@cwdb01 ~]# /u01/app/oraInventory/orainstRoot.sh
Changing permissions of /u01/app/oraInventory.
Adding read,write permissions for group.
Removing read,write,execute permissions for world.

Changing groupname of /u01/app/oraInventory to oinstall.
The execution of the script is complete.

[root@cwdb02 ~]# /u01/app/oraInventory/orainstRoot.sh
Changing permissions of /u01/app/oraInventory.
Adding read,write permissions for group.
Removing read,write,execute permissions for world.

Changing groupname of /u01/app/oraInventory to oinstall.
The execution of the script is complete.

[root@cwdb01 ~]# /u01/app/19.3.0/grid/root.sh
Performing root user operation.

The following environment variables are set as:
    ORACLE_OWNER= grid
    ORACLE_HOME=  /u01/app/19.3.0/grid

Enter the full pathname of the local bin directory: [/usr/local/bin]: 
   Copying dbhome to /usr/local/bin ...
   Copying oraenv to /usr/local/bin ...
   Copying coraenv to /usr/local/bin ...


Creating /etc/oratab file...
Entries will be added to the /etc/oratab file as needed by
Database Configuration Assistant when a database is created
Finished running generic part of root script.
Now product-specific root actions will be performed.
Relinking oracle with rac_on option
Using configuration parameter file: /u01/app/19.3.0/grid/crs/install/crsconfig_params
The log of current session can be found at:
  /u01/app/grid/crsdata/cwdb01/crsconfig/rootcrs_cwdb01_2022-11-14_03-06-32PM.log
2022/11/14 15:06:38 CLSRSC-594: Executing installation step 1 of 19: 'SetupTFA'.
2022/11/14 15:06:38 CLSRSC-594: Executing installation step 2 of 19: 'ValidateEnv'.
2022/11/14 15:06:38 CLSRSC-363: User ignored prerequisites during installation
2022/11/14 15:06:38 CLSRSC-594: Executing installation step 3 of 19: 'CheckFirstNode'.
2022/11/14 15:06:40 CLSRSC-594: Executing installation step 4 of 19: 'GenSiteGUIDs'.
2022/11/14 15:06:41 CLSRSC-594: Executing installation step 5 of 19: 'SetupOSD'.
2022/11/14 15:06:41 CLSRSC-594: Executing installation step 6 of 19: 'CheckCRSConfig'.
2022/11/14 15:06:41 CLSRSC-594: Executing installation step 7 of 19: 'SetupLocalGPNP'.
2022/11/14 15:06:53 CLSRSC-594: Executing installation step 8 of 19: 'CreateRootCert'.
2022/11/14 15:06:56 CLSRSC-594: Executing installation step 9 of 19: 'ConfigOLR'.
2022/11/14 15:07:02 CLSRSC-4002: Successfully installed Oracle Trace File Analyzer (TFA) Collector.
2022/11/14 15:07:07 CLSRSC-594: Executing installation step 10 of 19: 'ConfigCHMOS'.
2022/11/14 15:07:07 CLSRSC-594: Executing installation step 11 of 19: 'CreateOHASD'.
2022/11/14 15:07:11 CLSRSC-594: Executing installation step 12 of 19: 'ConfigOHASD'.
2022/11/14 15:07:11 CLSRSC-330: Adding Clusterware entries to file 'oracle-ohasd.service'
2022/11/14 15:07:32 CLSRSC-594: Executing installation step 13 of 19: 'InstallAFD'.
2022/11/14 15:07:36 CLSRSC-594: Executing installation step 14 of 19: 'InstallACFS'.
2022/11/14 15:07:40 CLSRSC-594: Executing installation step 15 of 19: 'InstallKA'.
2022/11/14 15:07:44 CLSRSC-594: Executing installation step 16 of 19: 'InitConfig'.

ASM has been created and started successfully.

[DBT-30001] Disk groups created successfully. Check /u01/app/grid/cfgtoollogs/asmca/asmca-221114PM030813.log for details.

2022/11/14 15:11:51 CLSRSC-482: Running command: '/u01/app/19.3.0/grid/bin/ocrconfig -upgrade grid oinstall'
CRS-4256: Updating the profile
Successful addition of voting disk 8345421d68544f40bff8859ef2407fec.
Successful addition of voting disk e665638af7e84f6fbf161d253be1c5e8.
Successful addition of voting disk 4a719a8bc1db4f2abf40bd02c74a281c.
Successfully replaced voting disk group with +DGOCR.
CRS-4256: Updating the profile
CRS-4266: Voting file(s) successfully replaced
##  STATE    File Universal Id                File Name Disk group
--  -----    -----------------                --------- ---------
 1. ONLINE   8345421d68544f40bff8859ef2407fec (/dev/asm-ocr02) [DGOCR]
 2. ONLINE   e665638af7e84f6fbf161d253be1c5e8 (/dev/asm-ocr03) [DGOCR]
 3. ONLINE   4a719a8bc1db4f2abf40bd02c74a281c (/dev/asm-ocr01) [DGOCR]
Located 3 voting disk(s).
2022/11/14 15:13:17 CLSRSC-594: Executing installation step 17 of 19: 'StartCluster'.
2022/11/14 15:15:36 CLSRSC-343: Successfully started Oracle Clusterware stack
2022/11/14 15:15:37 CLSRSC-594: Executing installation step 18 of 19: 'ConfigNode'.
2022/11/14 15:23:46 CLSRSC-594: Executing installation step 19 of 19: 'PostConfig'.
2022/11/14 15:25:40 CLSRSC-325: Configure Oracle Grid Infrastructure for a Cluster ... succeeded</code></pre> 
<h2>节点2执行root脚本报错</h2> 
<pre><code class="language-bash">[root@cwdb02 ~]# /u01/app/19.3.0/grid/root.sh
Performing root user operation.

The following environment variables are set as:
    ORACLE_OWNER= grid
    ORACLE_HOME=  /u01/app/19.3.0/grid

Enter the full pathname of the local bin directory: [/usr/local/bin]: 
   Copying dbhome to /usr/local/bin ...
   Copying oraenv to /usr/local/bin ...
   Copying coraenv to /usr/local/bin ...


Creating /etc/oratab file...
Entries will be added to the /etc/oratab file as needed by
Database Configuration Assistant when a database is created
Finished running generic part of root script.
Now product-specific root actions will be performed.
Relinking oracle with rac_on option
Using configuration parameter file: /u01/app/19.3.0/grid/crs/install/crsconfig_params
The log of current session can be found at:
  /u01/app/grid/crsdata/cwdb02/crsconfig/rootcrs_cwdb02_2022-11-14_03-26-54PM.log
2022/11/14 15:26:58 CLSRSC-594: Executing installation step 1 of 19: 'SetupTFA'.
2022/11/14 15:26:58 CLSRSC-594: Executing installation step 2 of 19: 'ValidateEnv'.
2022/11/14 15:26:58 CLSRSC-363: User ignored prerequisites during installation
2022/11/14 15:26:59 CLSRSC-594: Executing installation step 3 of 19: 'CheckFirstNode'.
2022/11/14 15:27:00 CLSRSC-594: Executing installation step 4 of 19: 'GenSiteGUIDs'.
2022/11/14 15:27:00 CLSRSC-594: Executing installation step 5 of 19: 'SetupOSD'.
2022/11/14 15:27:00 CLSRSC-594: Executing installation step 6 of 19: 'CheckCRSConfig'.
2022/11/14 15:27:01 CLSRSC-594: Executing installation step 7 of 19: 'SetupLocalGPNP'.
2022/11/14 15:27:02 CLSRSC-594: Executing installation step 8 of 19: 'CreateRootCert'.
2022/11/14 15:27:02 CLSRSC-594: Executing installation step 9 of 19: 'ConfigOLR'.
2022/11/14 15:27:20 CLSRSC-594: Executing installation step 10 of 19: 'ConfigCHMOS'.
2022/11/14 15:27:20 CLSRSC-594: Executing installation step 11 of 19: 'CreateOHASD'.
2022/11/14 15:27:21 CLSRSC-594: Executing installation step 12 of 19: 'ConfigOHASD'.
2022/11/14 15:27:22 CLSRSC-330: Adding Clusterware entries to file 'oracle-ohasd.service'
2022/11/14 15:27:34 CLSRSC-4002: Successfully installed Oracle Trace File Analyzer (TFA) Collector.
2022/11/14 15:27:41 CLSRSC-594: Executing installation step 13 of 19: 'InstallAFD'.
2022/11/14 15:27:42 CLSRSC-594: Executing installation step 14 of 19: 'InstallACFS'.
2022/11/14 15:27:44 CLSRSC-594: Executing installation step 15 of 19: 'InstallKA'.
2022/11/14 15:27:45 CLSRSC-594: Executing installation step 16 of 19: 'InitConfig'.
2022/11/14 15:27:53 CLSRSC-594: Executing installation step 17 of 19: 'StartCluster'.
CRS-4123: Starting Oracle High Availability Services-managed resources
CRS-2672: Attempting to start 'ora.mdnsd' on 'cwdb02'
CRS-2672: Attempting to start 'ora.evmd' on 'cwdb02'
CRS-2676: Start of 'ora.mdnsd' on 'cwdb02' succeeded
CRS-2676: Start of 'ora.evmd' on 'cwdb02' succeeded
CRS-2672: Attempting to start 'ora.gpnpd' on 'cwdb02'
CRS-2676: Start of 'ora.gpnpd' on 'cwdb02' succeeded
CRS-2672: Attempting to start 'ora.gipcd' on 'cwdb02'
CRS-2676: Start of 'ora.gipcd' on 'cwdb02' succeeded
CRS-2672: Attempting to start 'ora.crf' on 'cwdb02'
CRS-2672: Attempting to start 'ora.cssdmonitor' on 'cwdb02'
CRS-2676: Start of 'ora.cssdmonitor' on 'cwdb02' succeeded
CRS-2672: Attempting to start 'ora.cssd' on 'cwdb02'
CRS-2672: Attempting to start 'ora.diskmon' on 'cwdb02'
CRS-2676: Start of 'ora.diskmon' on 'cwdb02' succeeded
CRS-2676: Start of 'ora.crf' on 'cwdb02' succeeded
CRS-2672: Attempting to start 'ora.cssdmonitor' on 'cwdb02'
CRS-2676: Start of 'ora.cssdmonitor' on 'cwdb02' succeeded
CRS-1705: Found 0 configured voting files but 1 voting files are required, terminating to ensure data integrity; details at (:CSSNM00065:) in /u01/app/grid/diag/crs/cwdb02/crs/trace/ocssd.trc
CRS-2883: Resource 'ora.cssd' failed during Clusterware stack start.
CRS-4406: Oracle High Availability Services synchronous start failed.
CRS-41053: checking Oracle Grid Infrastructure for file permission issues
PRVH-0116 : Path "/u01/app/19.3.0/grid/crs/install/cmdllroot.sh" with permissions "rw-r--r--" does not have execute permissions for the owner, file's group, and others on node "cwdb02".
PRVG-2031 : Owner of file "/u01/app/19.3.0/grid/crs/install/cmdllroot.sh" did not match the expected value on node "cwdb02". [Expected = "grid(54322)" ; Found = "root(0)"]
PRVG-2032 : Group of file "/u01/app/19.3.0/grid/crs/install/cmdllroot.sh" did not match the expected value on node "cwdb02". [Expected = "oinstall(54321)" ; Found = "root(0)"]
CRS-4000: Command Start failed, or completed with errors.
2022/11/14 15:38:19 CLSRSC-117: Failed to start Oracle Clusterware stack
Died at /u01/app/19.3.0/grid/crs/install/crsinstall.pm line 1970.</code></pre> 
<h2>查看日志报错</h2> 
<pre><code class="language-bash">[root@cwdb02 ~]# more /u01/app/grid/diag/crs/cwdb02/crs/trace/ocssd.trc | grep ERR
2022-11-14 15:28:06.646 :    CSSD:1939897600: [    ERROR] clssscModifyEnvironment: unable to update wallet for IPMI
2022-11-14 15:28:06.650 :    CSSD:1939897600: [    ERROR] clssscGetODAType: Failed to get ODA type, res = 3
2022-11-14 15:28:06.651 :  CLSDMT:1776899840: [    ERROR] ERROR: Empty pid name for proc CSSD
2022-11-14 15:38:06.149 :    CSSD:1780053760: [    ERROR] ###################################
2022-11-14 15:38:06.149 :    CSSD:1780053760: [    ERROR] clssscExit: CSSD aborting from thread clssscAgListener
2022-11-14 15:38:06.149 :    CSSD:1780053760: [    ERROR] ###################################
2022-11-14 16:00:28.910 :    CSSD:2045713664: [    ERROR] clssscModifyEnvironment: unable to update wallet for IPMI
2022-11-14 16:00:28.913 :    CSSD:2045713664: [    ERROR] clssscGetODAType: Failed to get ODA type, res = 3
2022-11-14 16:00:28.913 :  CLSDMT:1881663232: [    ERROR] ERROR: Empty pid name for proc CSSD
2022-11-14 16:10:28.471 :    CSSD:1884817152: [    ERROR] ###################################
2022-11-14 16:10:28.471 :    CSSD:1884817152: [    ERROR] clssscExit: CSSD aborting from thread clssscAgListener
2022-11-14 16:10:28.471 :    CSSD:1884817152: [    ERROR] ###################################</code></pre> 
<h2>解决方案重新安装GI</h2> 
<pre><code class="language-bash">1、节点1卸载GI
[grid@cwdb01:/u01/app/19.3.0/grid]$ cd deinstall/
[grid@cwdb01:/u01/app/19.3.0/grid/deinstall]$ ./deinstall

2、节点1执行脚本
[root@cwdb01 ~]# /u01/app/19.3.0/grid/crs/install/rootcrs.sh -force  -deconfig -paramfile "/tmp/deinstall2022-11-14_04-39-38PM/response/deinstall_OraGI19Home1.rsp" -lastnode

[root@cwdb01 ~]# /u01/app/19.3.0/grid/crs/install/rootcrs.sh -force  -deconfig -paramfile "/tmp/deinstall2022-11-14_04-39-38PM/response/deinstall_OraGI19Home1.rsp" -lastnode
Using configuration parameter file: /tmp/deinstall2022-11-14_04-39-38PM/response/deinstall_OraGI19Home1.rsp
The log of current session can be found at:
  /tmp/deinstall2022-11-14_04-39-38PM/logs/crsdeconfig_cwdb01_2022-11-14_04-42-17PM.log
CRS-2673: Attempting to stop 'ora.crsd' on 'cwdb01'
CRS-2677: Stop of 'ora.crsd' on 'cwdb01' succeeded
ASM de-configuration trace file location: /tmp/deinstall2022-11-14_04-39-38PM/logs/asmcadc_clean2022-11-14_04-46-40PM.log
ASM Clean Configuration START
ASM Clean Configuration END

ASM instance deleted successfully. Check /tmp/deinstall2022-11-14_04-39-38PM/logs/asmcadc_clean2022-11-14_04-46-40PM.log for details.

2022/11/14 16:48:03 CLSRSC-4006: Removing Oracle Trace File Analyzer (TFA) Collector.
2022/11/14 16:50:00 CLSRSC-4007: Successfully removed Oracle Trace File Analyzer (TFA) Collector.
2022/11/14 16:50:02 CLSRSC-336: Successfully deconfigured Oracle Clusterware stack on this node
2022/11/14 16:50:02 CLSRSC-559: Ensure that the GPnP profile data under the 'gpnp' directory in /u01/app/19.3.0/grid is deleted on each node before using the software in the current Grid Infrastructure home for reconfiguration.

查看日志具体执行进度
[root@cwdb01 ~]# tail -100f /tmp/deinstall2022-11-14_04-39-38PM/logs/crsdeconfig_cwdb01_2022-11-14_04-42-17PM.log

2022-11-14 16:50:04: The path [/u01/app/grid/crsdata] is not shared
2022-11-14 16:50:04: Attempt to remove the node specific dir '/u01/app/grid/crsdata'
2022-11-14 16:50:04: Remove /u01/app/grid/crsdata
2022-11-14 16:50:04: deinstall or deconfig cleanup completed successfully

输入Enter继续执行grid
Press Enter after you finish running the above commands

&lt;----------------------------------------

Run the following command as the root user or the administrator on node "cwdb02".

/u01/app/19.3.0/grid/crs/install/rootcrs.sh -force  -deconfig -paramfile "/tmp/deinstall2022-11-14_04-39-38PM/response/deinstall_OraGI19Home1.rsp"

Press Enter after you finish running the above commands

&lt;----------------------------------------

2、节点2执行脚本
[root@cwdb02 ~]# /u01/app/19.3.0/grid/crs/install/rootcrs.sh -force  -deconfig -paramfile "/tmp/deinstall2022-11-14_04-39-38PM/response/deinstall_OraGI19Home1.rsp"

[root@cwdb02 ~]# /u01/app/19.3.0/grid/crs/install/rootcrs.sh -force  -deconfig -paramfile "/tmp/deinstall2022-11-14_04-39-38PM/response/deinstall_OraGI19Home1.rsp"
Using configuration parameter file: /tmp/deinstall2022-11-14_04-39-38PM/response/deinstall_OraGI19Home1.rsp
The log of current session can be found at:
  /tmp/deinstall2022-11-14_04-39-38PM/logs/crsdeconfig_cwdb02_2022-11-14_04-53-08PM.log
PRCR-1070 : Failed to check if resource ora.net1.network is registered
CRS-0184 : Cannot communicate with the CRS daemon.
PRCR-1070 : Failed to check if resource ora.helper is registered
CRS-0184 : Cannot communicate with the CRS daemon.
PRCR-1070 : Failed to check if resource ora.ons is registered
CRS-0184 : Cannot communicate with the CRS daemon.

2022/11/14 16:53:28 CLSRSC-180: An error occurred while executing the command '/u01/app/19.3.0/grid/bin/srvctl config nodeapps'
2022/11/14 16:53:42 CLSRSC-4006: Removing Oracle Trace File Analyzer (TFA) Collector.
2022/11/14 16:55:28 CLSRSC-4007: Successfully removed Oracle Trace File Analyzer (TFA) Collector.
2022/11/14 16:55:29 CLSRSC-336: Successfully deconfigured Oracle Clusterware stack on this node

查看进度
[root@cwdb02 ~]# tail -100f /tmp/deinstall2022-11-14_04-39-38PM/logs/crsdeconfig_cwdb02_2022-11-14_04-53-08PM.log
2022-11-14 16:55:30: The path [/u01/app/grid/crsdata] is not shared
2022-11-14 16:55:30: Attempt to remove the node specific dir '/u01/app/grid/crsdata'
2022-11-14 16:55:30: Remove /u01/app/grid/crsdata
2022-11-14 16:55:30: deinstall or deconfig cleanup completed successfully


grid输入Enter继续执行，执行完成

######################### DEINSTALL CLEAN OPERATION END #########################


####################### DEINSTALL CLEAN OPERATION SUMMARY #######################
Successfully detached Oracle home '/u01/app/19.3.0/grid' from the central inventory on the local node.
Successfully deleted directory '/u01/app/19.3.0/grid' on the local node.
Successfully deleted directory '/u01/app/oraInventory' on the local node.
Successfully deleted directory '/u01/app/grid' on the local node.
Successfully detached Oracle home '/u01/app/19.3.0/grid' from the central inventory on the remote nodes 'cwdb02'.
Successfully deleted directory '/u01/app/19.3.0/grid' on the remote nodes 'cwdb02'.
Successfully deleted directory '/u01/app/oraInventory' on the remote nodes 'cwdb02'.
Successfully deleted directory '/u01/app/grid' on the remote nodes 'cwdb02'.
Oracle Universal Installer cleanup was successful.


Run 'rm -r /etc/oraInst.loc' as root on node(s) 'cwdb01,cwdb02' at the end of the session.

Run 'rm -r /opt/ORCLfmap' as root on node(s) 'cwdb01,cwdb02' at the end of the session.
Oracle deinstall tool successfully cleaned up temporary directories.
#######################################################################


############# ORACLE DEINSTALL TOOL END #############</code></pre> 
<h2>删除文件和目录</h2> 
<pre><code class="language-bash">1、grid被完成删除
[root@cwdb01 ~]# ll -hd /u01/app/19.3.0/grid
ls: cannot access /u01/app/19.3.0/grid: No such file or directory

[root@cwdb02 ~]# ll -hd /u01/app/19.3.0/grid
ls: cannot access /u01/app/19.3.0/grid: No such file or directory

2、删除配置文件
[root@cwdb01 ~]# rm -rf /etc/oraInst.loc
[root@cwdb01 ~]# rm -rf /opt/ORCLfmap
[root@cwdb01 ~]# rm -rf /etc/oratab
[root@cwdb01 ~]# rm -rf /tmp/.oracle

[root@cwdb02 ~]# rm -rf /tmp/.oracle
[root@cwdb02 ~]# rm -rf /etc/oraInst.loc
[root@cwdb02 ~]# rm -rf /opt/ORCLfmap
[root@cwdb02 ~]# rm -rf /etc/oratab

[root@cwdb01 ~]# rm -rf /u01/*
[root@cwdb01 ~]# rm -rf /etc/ora*
[root@cwdb01 ~]# rm -rf /usr/local/bin

[root@cwdb02 ~]# rm -rf /u01/*
[root@cwdb02 ~]# rm -rf /etc/ora*
[root@cwdb02 ~]# rm -rf /usr/local/bin</code></pre> 
<h2>清理ASM磁盘</h2> 
<pre><code class="language-bash">[root@cwdb02 ~]# dd if=/dev/zero of=/dev/asm-ocr01 bs=8192 count=128000
128000+0 records in
128000+0 records out
1048576000 bytes (1.0 GB) copied, 0.576851 s, 1.8 GB/s
[root@cwdb02 ~]# dd if=/dev/zero of=/dev/asm-ocr02 bs=8192 count=128000
128000+0 records in
128000+0 records out
1048576000 bytes (1.0 GB) copied, 0.54297 s, 1.9 GB/s
[root@cwdb02 ~]# dd if=/dev/zero of=/dev/asm-ocr03 bs=8192 count=128000
128000+0 records in
128000+0 records out
1048576000 bytes (1.0 GB) copied, 0.622136 s, 1.7 GB/s
[root@cwdb02 ~]# dd if=/dev/zero of=/dev/asm-system bs=8192 count=128000
128000+0 records in
128000+0 records out
1048576000 bytes (1.0 GB) copied, 0.579514 s, 1.8 GB/s
[root@cwdb02 ~]# dd if=/dev/zero of=/dev/asm-data bs=8192 count=128000
128000+0 records in
128000+0 records out
1048576000 bytes (1.0 GB) copied, 0.58211 s, 1.8 GB/s
[root@cwdb02 ~]# dd if=/dev/zero of=/dev/asm-fra bs=8192 count=128000
128000+0 records in
128000+0 records out
1048576000 bytes (1.0 GB) copied, 0.473186 s, 2.2 GB/s

[root@cwdb02 ~]# ll -h /dev/asm*
lrwxrwxrwx 1 root root 3 Nov 14 17:14 /dev/asm-data -&gt; sdg
lrwxrwxrwx 1 root root 3 Nov 14 17:14 /dev/asm-fra -&gt; sdh
lrwxrwxrwx 1 root root 3 Nov 14 17:13 /dev/asm-ocr01 -&gt; sdc
lrwxrwxrwx 1 root root 3 Nov 14 17:13 /dev/asm-ocr02 -&gt; sdd
lrwxrwxrwx 1 root root 3 Nov 14 17:13 /dev/asm-ocr03 -&gt; sde
lrwxrwxrwx 1 root root 3 Nov 14 17:14 /dev/asm-system -&gt; sdf</code></pre> 
<h2>在节点1启用共享文件</h2> 
<p><img alt="" height="1114" src="https://images2.imgbox.com/a4/87/BY1MducT_o.png" width="1037"></p> 
<h2>重新创建目录</h2> 
<pre><code class="language-bash">[root@cwdb01 ~]# mkdir -p /u01/app/grid  
[root@cwdb01 ~]# mkdir -p /u01/app/19.3.0/grid
[root@cwdb01 ~]# mkdir -p /u01/app/oracle
[root@cwdb01 ~]# mkdir -p /u01/app/oracle/product/19.3.0/dbhome_1
[root@cwdb01 ~]# chown -R grid:oinstall /u01
[root@cwdb01 ~]# chown -R oracle:oinstall /u01/app/oracle
[root@cwdb01 ~]# chmod -R 775 /u01

[root@cwdb02 ~]# mkdir -p /u01/app/grid  
[root@cwdb02 ~]# mkdir -p /u01/app/19.3.0/grid
[root@cwdb02 ~]# mkdir -p /u01/app/oracle
[root@cwdb02 ~]# mkdir -p /u01/app/oracle/product/19.3.0/dbhome_1
[root@cwdb02 ~]# chown -R grid:oinstall /u01
[root@cwdb02 ~]# chown -R oracle:oinstall /u01/app/oracle
[root@cwdb02 ~]# chmod -R 775 /u01</code></pre> 
<h2>重新安装grid</h2> 
<pre><code class="language-bash">[root@cwdb01 ~]# /tmp/GridSetupActions2022-11-14_05-35-31PM/CVU_19.0.0.0.0_grid/runfixup.sh
All Fix-up operations were completed successfully.
[root@cwdb01 ~]# /tmp/GridSetupActions2022-11-14_05-35-31PM/CVU_19.0.0.0.0_grid/runfixup.sh
All Fix-up operations were completed successfully.

[root@cwdb02 ~]# /tmp/GridSetupActions2022-11-14_05-35-31PM/CVU_19.0.0.0.0_grid/runfixup.sh
All Fix-up operations were completed successfully.
[root@cwdb02 ~]# /tmp/GridSetupActions2022-11-14_05-35-31PM/CVU_19.0.0.0.0_grid/runfixup.sh
All Fix-up operations were completed successfully.

[root@cwdb01 ~]# /u01/app/19.3.0/grid/root.sh
Performing root user operation.

The following environment variables are set as:
    ORACLE_OWNER= grid
    ORACLE_HOME=  /u01/app/19.3.0/grid

Enter the full pathname of the local bin directory: [/usr/local/bin]: 
Creating /usr/local/bin directory...
   Copying dbhome to /usr/local/bin ...
   Copying oraenv to /usr/local/bin ...
   Copying coraenv to /usr/local/bin ...


Creating /etc/oratab file...
Entries will be added to the /etc/oratab file as needed by
Database Configuration Assistant when a database is created
Finished running generic part of root script.
Now product-specific root actions will be performed.
Relinking oracle with rac_on option
Using configuration parameter file: /u01/app/19.3.0/grid/crs/install/crsconfig_params
The log of current session can be found at:
  /u01/app/grid/crsdata/cwdb01/crsconfig/rootcrs_cwdb01_2022-11-14_05-43-11PM.log
2022/11/14 17:43:17 CLSRSC-594: Executing installation step 1 of 19: 'SetupTFA'.
2022/11/14 17:43:18 CLSRSC-594: Executing installation step 2 of 19: 'ValidateEnv'.
2022/11/14 17:43:18 CLSRSC-363: User ignored prerequisites during installation
2022/11/14 17:43:18 CLSRSC-594: Executing installation step 3 of 19: 'CheckFirstNode'.
2022/11/14 17:43:19 CLSRSC-594: Executing installation step 4 of 19: 'GenSiteGUIDs'.
2022/11/14 17:43:20 CLSRSC-594: Executing installation step 5 of 19: 'SetupOSD'.
2022/11/14 17:43:20 CLSRSC-594: Executing installation step 6 of 19: 'CheckCRSConfig'.
2022/11/14 17:43:20 CLSRSC-594: Executing installation step 7 of 19: 'SetupLocalGPNP'.
2022/11/14 17:43:32 CLSRSC-594: Executing installation step 8 of 19: 'CreateRootCert'.
2022/11/14 17:43:35 CLSRSC-594: Executing installation step 9 of 19: 'ConfigOLR'.
2022/11/14 17:43:40 CLSRSC-4002: Successfully installed Oracle Trace File Analyzer (TFA) Collector.
2022/11/14 17:43:46 CLSRSC-594: Executing installation step 10 of 19: 'ConfigCHMOS'.
2022/11/14 17:43:46 CLSRSC-594: Executing installation step 11 of 19: 'CreateOHASD'.
2022/11/14 17:43:50 CLSRSC-594: Executing installation step 12 of 19: 'ConfigOHASD'.
2022/11/14 17:43:50 CLSRSC-330: Adding Clusterware entries to file 'oracle-ohasd.service'
2022/11/14 17:44:11 CLSRSC-594: Executing installation step 13 of 19: 'InstallAFD'.
2022/11/14 17:44:14 CLSRSC-594: Executing installation step 14 of 19: 'InstallACFS'.
2022/11/14 17:44:18 CLSRSC-594: Executing installation step 15 of 19: 'InstallKA'.
2022/11/14 17:44:22 CLSRSC-594: Executing installation step 16 of 19: 'InitConfig'.

ASM has been created and started successfully.

[DBT-30001] Disk groups created successfully. Check /u01/app/grid/cfgtoollogs/asmca/asmca-221114PM054451.log for details.

2022/11/14 17:48:07 CLSRSC-482: Running command: '/u01/app/19.3.0/grid/bin/ocrconfig -upgrade grid oinstall'
CRS-4256: Updating the profile
Successful addition of voting disk 0f4c353d07944f54bf20deefe706cf00.
Successful addition of voting disk 0030293248bb4fadbffc40f38c87dffb.
Successful addition of voting disk 807739df23a24fdabf124a9c5585cc3a.
Successfully replaced voting disk group with +DGOCR.
CRS-4256: Updating the profile
CRS-4266: Voting file(s) successfully replaced
##  STATE    File Universal Id                File Name Disk group
--  -----    -----------------                --------- ---------
 1. ONLINE   0f4c353d07944f54bf20deefe706cf00 (/dev/asm-ocr01) [DGOCR]
 2. ONLINE   0030293248bb4fadbffc40f38c87dffb (/dev/asm-ocr02) [DGOCR]
 3. ONLINE   807739df23a24fdabf124a9c5585cc3a (/dev/asm-ocr03) [DGOCR]
Located 3 voting disk(s).
2022/11/14 17:51:19 CLSRSC-594: Executing installation step 17 of 19: 'StartCluster'.
2022/11/14 17:52:27 CLSRSC-343: Successfully started Oracle Clusterware stack
2022/11/14 17:52:27 CLSRSC-594: Executing installation step 18 of 19: 'ConfigNode'.
2022/11/14 18:03:28 CLSRSC-594: Executing installation step 19 of 19: 'PostConfig'.
2022/11/14 18:04:16 CLSRSC-325: Configure Oracle Grid Infrastructure for a Cluster ... succeeded

[root@cwdb02 ~]# /u01/app/19.3.0/grid/root.sh
Performing root user operation.

The following environment variables are set as:
    ORACLE_OWNER= grid
    ORACLE_HOME=  /u01/app/19.3.0/grid

Enter the full pathname of the local bin directory: [/usr/local/bin]: 
Creating /usr/local/bin directory...
   Copying dbhome to /usr/local/bin ...
   Copying oraenv to /usr/local/bin ...
   Copying coraenv to /usr/local/bin ...


Creating /etc/oratab file...
Entries will be added to the /etc/oratab file as needed by
Database Configuration Assistant when a database is created
Finished running generic part of root script.
Now product-specific root actions will be performed.
Relinking oracle with rac_on option
Using configuration parameter file: /u01/app/19.3.0/grid/crs/install/crsconfig_params
The log of current session can be found at:
  /u01/app/grid/crsdata/cwdb02/crsconfig/rootcrs_cwdb02_2022-11-14_06-08-39PM.log
2022/11/14 18:08:43 CLSRSC-594: Executing installation step 1 of 19: 'SetupTFA'.
2022/11/14 18:08:43 CLSRSC-594: Executing installation step 2 of 19: 'ValidateEnv'.
2022/11/14 18:08:43 CLSRSC-363: User ignored prerequisites during installation
2022/11/14 18:08:43 CLSRSC-594: Executing installation step 3 of 19: 'CheckFirstNode'.
2022/11/14 18:08:44 CLSRSC-594: Executing installation step 4 of 19: 'GenSiteGUIDs'.
2022/11/14 18:08:44 CLSRSC-594: Executing installation step 5 of 19: 'SetupOSD'.
2022/11/14 18:08:44 CLSRSC-594: Executing installation step 6 of 19: 'CheckCRSConfig'.
2022/11/14 18:08:45 CLSRSC-594: Executing installation step 7 of 19: 'SetupLocalGPNP'.
2022/11/14 18:08:45 CLSRSC-594: Executing installation step 8 of 19: 'CreateRootCert'.
2022/11/14 18:08:45 CLSRSC-594: Executing installation step 9 of 19: 'ConfigOLR'.
2022/11/14 18:08:53 CLSRSC-594: Executing installation step 10 of 19: 'ConfigCHMOS'.
2022/11/14 18:08:53 CLSRSC-594: Executing installation step 11 of 19: 'CreateOHASD'.
2022/11/14 18:08:54 CLSRSC-594: Executing installation step 12 of 19: 'ConfigOHASD'.
2022/11/14 18:08:54 CLSRSC-330: Adding Clusterware entries to file 'oracle-ohasd.service'
2022/11/14 18:09:05 CLSRSC-4002: Successfully installed Oracle Trace File Analyzer (TFA) Collector.
2022/11/14 18:09:12 CLSRSC-594: Executing installation step 13 of 19: 'InstallAFD'.
2022/11/14 18:09:13 CLSRSC-594: Executing installation step 14 of 19: 'InstallACFS'.
2022/11/14 18:09:14 CLSRSC-594: Executing installation step 15 of 19: 'InstallKA'.
2022/11/14 18:09:15 CLSRSC-594: Executing installation step 16 of 19: 'InitConfig'.
2022/11/14 18:09:22 CLSRSC-594: Executing installation step 17 of 19: 'StartCluster'.
2022/11/14 18:10:09 CLSRSC-343: Successfully started Oracle Clusterware stack
2022/11/14 18:10:09 CLSRSC-594: Executing installation step 18 of 19: 'ConfigNode'.
2022/11/14 18:10:20 CLSRSC-594: Executing installation step 19 of 19: 'PostConfig'.
2022/11/14 18:10:26 CLSRSC-325: Configure Oracle Grid Infrastructure for a Cluster ... succeeded</code></pre> 
<h2>节点2执行root成功</h2> 
<p><img alt="" height="736" src="https://images2.imgbox.com/f9/63/Gq4akwQ5_o.png" width="1200"></p> 
<p><img alt="" height="736" src="https://images2.imgbox.com/9a/8d/K7sn9rUH_o.png" width="1200"></p> 
<h2> 创建ASM磁盘组</h2> 
<pre><code class="language-bash">[grid@cwdb01:/home/grid]$ export DISPLAY=192.168.6.1:0.0
[grid@cwdb01:/home/grid]$ asmca</code></pre> 
<p><img alt="" height="924" src="https://images2.imgbox.com/27/f6/mELsXPDZ_o.png" width="1200"></p> 
<h2>集群状态</h2> 
<pre><code class="language-bash">[root@cwdb01 ~]# vim .bash_profile 
export PATH=/u01/app/19.3.0/grid/bin:$PATH
[root@cwdb01 ~]# source .bash_profile 

[root@cwdb01 ~]# crsctl check crs
CRS-4638: Oracle High Availability Services is online
CRS-4537: Cluster Ready Services is online
CRS-4529: Cluster Synchronization Services is online
CRS-4533: Event Manager is online

[root@cwdb02 ~]# crsctl check crs
CRS-4638: Oracle High Availability Services is online
CRS-4537: Cluster Ready Services is online
CRS-4529: Cluster Synchronization Services is online
CRS-4533: Event Manager is online

[root@cwdb01 ~]# crsctl stat res -t
--------------------------------------------------------------------------------
Name           Target  State        Server                   State details       
--------------------------------------------------------------------------------
Local Resources
--------------------------------------------------------------------------------
ora.LISTENER.lsnr
               ONLINE  ONLINE       cwdb01                   STABLE
               ONLINE  ONLINE       cwdb02                   STABLE
ora.chad
               ONLINE  ONLINE       cwdb01                   STABLE
               ONLINE  ONLINE       cwdb02                   STABLE
ora.net1.network
               ONLINE  ONLINE       cwdb01                   STABLE
               ONLINE  ONLINE       cwdb02                   STABLE
ora.ons
               ONLINE  ONLINE       cwdb01                   STABLE
               ONLINE  ONLINE       cwdb02                   STABLE
--------------------------------------------------------------------------------
Cluster Resources
--------------------------------------------------------------------------------
ora.ASMNET1LSNR_ASM.lsnr(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        ONLINE  OFFLINE                               STABLE
ora.DGDATA.dg(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.DGFRA.dg(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.DGOCR.dg(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.DGSYSTEM.dg(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.LISTENER_SCAN1.lsnr
      1        ONLINE  ONLINE       cwdb01                   STABLE
ora.asm(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   Started,STABLE
      2        ONLINE  ONLINE       cwdb02                   Started,STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.asmnet1.asmnetwork(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.cvu
      1        ONLINE  ONLINE       cwdb01                   STABLE
ora.cwdb01.vip
      1        ONLINE  ONLINE       cwdb01                   STABLE
ora.cwdb02.vip
      1        ONLINE  ONLINE       cwdb02                   STABLE
ora.qosmserver
      1        ONLINE  ONLINE       cwdb01                   STABLE
ora.scan1.vip
      1        ONLINE  ONLINE       cwdb01                   STABLE
--------------------------------------------------------------------------------

[root@cwdb02 ~]# crsctl stat res -t
--------------------------------------------------------------------------------
Name           Target  State        Server                   State details       
--------------------------------------------------------------------------------
Local Resources
--------------------------------------------------------------------------------
ora.LISTENER.lsnr
               ONLINE  ONLINE       cwdb01                   STABLE
               ONLINE  ONLINE       cwdb02                   STABLE
ora.chad
               ONLINE  ONLINE       cwdb01                   STABLE
               ONLINE  ONLINE       cwdb02                   STABLE
ora.net1.network
               ONLINE  ONLINE       cwdb01                   STABLE
               ONLINE  ONLINE       cwdb02                   STABLE
ora.ons
               ONLINE  ONLINE       cwdb01                   STABLE
               ONLINE  ONLINE       cwdb02                   STABLE
--------------------------------------------------------------------------------
Cluster Resources
--------------------------------------------------------------------------------
ora.ASMNET1LSNR_ASM.lsnr(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        ONLINE  OFFLINE                               STABLE
ora.DGDATA.dg(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.DGFRA.dg(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.DGOCR.dg(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.DGSYSTEM.dg(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.LISTENER_SCAN1.lsnr
      1        ONLINE  ONLINE       cwdb01                   STABLE
ora.asm(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   Started,STABLE
      2        ONLINE  ONLINE       cwdb02                   Started,STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.asmnet1.asmnetwork(ora.asmgroup)
      1        ONLINE  ONLINE       cwdb01                   STABLE
      2        ONLINE  ONLINE       cwdb02                   STABLE
      3        OFFLINE OFFLINE                               STABLE
ora.cvu
      1        ONLINE  ONLINE       cwdb01                   STABLE
ora.cwdb01.vip
      1        ONLINE  ONLINE       cwdb01                   STABLE
ora.cwdb02.vip
      1        ONLINE  ONLINE       cwdb02                   STABLE
ora.qosmserver
      1        ONLINE  ONLINE       cwdb01                   STABLE
ora.scan1.vip
      1        ONLINE  ONLINE       cwdb01                   STABLE
--------------------------------------------------------------------------------

[grid@cwdb01:/home/grid]$ asmcmd -p
ASMCMD [+] &gt; lsdg
State    Type    Rebal  Sector  Logical_Sector  Block       AU  Total_MB  Free_MB  Req_mir_free_MB  Usable_file_MB  Offline_disks  Voting_files  Name
MOUNTED  EXTERN  N         512             512   4096  4194304      4096     3964                0            3964              0             N  DGDATA/
MOUNTED  EXTERN  N         512             512   4096  4194304      5120     4988                0            4988              0             N  DGFRA/
MOUNTED  NORMAL  N         512             512   4096  4194304      9216     8300             3072            2614              0             Y  DGOCR/
MOUNTED  EXTERN  N         512             512   4096  4194304      6144     6012                0            6012              0             N  DGSYSTEM/
ASMCMD [+] &gt; 

[grid@cwdb01:/home/grid]$ lsnrctl status

LSNRCTL for Linux: Version 19.0.0.0.0 - Production on 14-NOV-2022 19:17:44

Copyright (c) 1991, 2019, Oracle.  All rights reserved.

Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER)))
STATUS of the LISTENER
------------------------
Alias                     LISTENER
Version                   TNSLSNR for Linux: Version 19.0.0.0.0 - Production
Start Date                14-NOV-2022 19:11:31
Uptime                    0 days 0 hr. 6 min. 13 sec
Trace Level               off
Security                  ON: Local OS Authentication
SNMP                      OFF
Listener Parameter File   /u01/app/19.3.0/grid/network/admin/listener.ora
Listener Log File         /u01/app/grid/diag/tnslsnr/cwdb01/listener/alert/log.xml
Listening Endpoints Summary...
  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=LISTENER)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=192.168.1.66)(PORT=1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=192.168.1.68)(PORT=1521)))
Services Summary...
Service "+ASM" has 1 instance(s).
  Instance "+ASM1", status READY, has 1 handler(s) for this service...
Service "+ASM_DGDATA" has 1 instance(s).
  Instance "+ASM1", status READY, has 1 handler(s) for this service...
Service "+ASM_DGFRA" has 1 instance(s).
  Instance "+ASM1", status READY, has 1 handler(s) for this service...
Service "+ASM_DGOCR" has 1 instance(s).
  Instance "+ASM1", status READY, has 1 handler(s) for this service...
Service "+ASM_DGSYSTEM" has 1 instance(s).
  Instance "+ASM1", status READY, has 1 handler(s) for this service...
The command completed successfully</code></pre> 
<h2>安装数据库软件</h2> 
<pre><code class="language-bash">[oracle@cwdb01:/home/oracle]$ cd $ORACLE_HOME
[oracle@cwdb01:/u01/app/oracle/product/19.3.0/dbhome_1]$ unzip /home/oracle/LINUX.X64_193000_db_home.zip 

[oracle@cwdb01:/u01/app/oracle/product/19.3.0/dbhome_1]$ export DISPLAY=192.168.6.1:0.0
[oracle@cwdb01:/u01/app/oracle/product/19.3.0/dbhome_1]$ ./runInstaller </code></pre> 
<h2><img alt="" height="924" src="https://images2.imgbox.com/84/3a/gBzMSEDo_o.png" width="1200">报错解决方案</h2> 
<pre><code class="language-bash">[root@cwdb01 ~]# ll -h /u01/app/oraInventory/
total 12K
drwxrwx--- 3 grid oinstall   35 Nov 14 18:41 backup
drwxrwx--- 2 grid oinstall   81 Nov 14 17:41 ContentsXML
drwxrwx--- 3 grid oinstall 4.0K Nov 14 18:44 logs
-rw-rw---- 1 grid oinstall   56 Nov 14 18:41 oraInst.loc
-rwxrwx--- 1 grid oinstall 1.6K Nov 14 18:41 orainstRoot.sh

[root@cwdb02 ~]# ll -h /u01/app/oraInventory/
total 12K
drwxrwx--- 3 grid oinstall   35 Nov 14 18:41 backup
drwxrwx--- 2 grid oinstall   60 Nov 14 17:42 ContentsXML
drwxrwx--- 2 grid oinstall 4.0K Nov 14 18:41 logs
-rw-rw---- 1 grid oinstall   56 Nov 14 18:41 oraInst.loc
-rwxrwx--- 1 grid oinstall 1.6K Nov 14 18:41 orainstRoot.sh

[root@cwdb01 ~]# rm -rf /u01/app/oraInventory/*
[root@cwdb02 ~]# rm -rf /u01/app/oraInventory/*

[root@cwdb01 ~]# ll -d /u01/app/oraInventory/
drwxrwx--- 2 grid oinstall 6 Nov 14 19:27 /u01/app/oraInventory/


[root@cwdb02 ~]# ll -d /u01/app/oraInventory/
drwxrwx--- 2 grid oinstall 6 Nov 14 19:28 /u01/app/oraInventory/


[root@cwdb01 ~]# chown -R oracle:oinstall /u01/app/oraInventory/
[root@cwdb01 ~]# ll -d /u01/app/oraInventory/
drwxrwx--- 2 oracle oinstall 6 Nov 14 19:27 /u01/app/oraInventory/


[root@cwdb02 ~]# chown -R oracle:oinstall /u01/app/oraInventory/
[root@cwdb02 ~]# ll -d /u01/app/oraInventory/
drwxrwx--- 2 oracle oinstall 6 Nov 14 19:28 /u01/app/oraInventory/</code></pre> 
<h2>执行脚本</h2> 
<pre><code class="language-bash">[root@cwdb01 ~]# /tmp/InstallActions2022-11-14_07-21-49PM/CVU_19.0.0.0.0_oracle/runfixup.sh
All Fix-up operations were completed successfully.

[root@cwdb02 ~]# /tmp/InstallActions2022-11-14_07-21-49PM/CVU_19.0.0.0.0_oracle/runfixup.sh
All Fix-up operations were completed successfully.
[root@cwdb02 ~]# 

[root@cwdb01 ~]# /u01/app/oraInventory/orainstRoot.sh
Changing permissions of /u01/app/oraInventory.
Adding read,write permissions for group.
Removing read,write,execute permissions for world.

Changing groupname of /u01/app/oraInventory to oinstall.
The execution of the script is complete.

[root@cwdb02 ~]# /u01/app/oraInventory/orainstRoot.sh
Changing permissions of /u01/app/oraInventory.
Adding read,write permissions for group.
Removing read,write,execute permissions for world.

Changing groupname of /u01/app/oraInventory to oinstall.
The execution of the script is complete.

[root@cwdb01 ~]# /u01/app/oracle/product/19.3.0/dbhome_1/root.sh
Performing root user operation.

The following environment variables are set as:
    ORACLE_OWNER= oracle
    ORACLE_HOME=  /u01/app/oracle/product/19.3.0/dbhome_1

Enter the full pathname of the local bin directory: [/usr/local/bin]: 
The contents of "dbhome" have not changed. No need to overwrite.
The contents of "oraenv" have not changed. No need to overwrite.
The contents of "coraenv" have not changed. No need to overwrite.

Entries will be added to the /etc/oratab file as needed by
Database Configuration Assistant when a database is created
Finished running generic part of root script.
Now product-specific root actions will be performed.

[root@cwdb02 ~]# /u01/app/oracle/product/19.3.0/dbhome_1/root.sh
Performing root user operation.

The following environment variables are set as:
    ORACLE_OWNER= oracle
    ORACLE_HOME=  /u01/app/oracle/product/19.3.0/dbhome_1

Enter the full pathname of the local bin directory: [/usr/local/bin]: 
The contents of "dbhome" have not changed. No need to overwrite.
The contents of "oraenv" have not changed. No need to overwrite.
The contents of "coraenv" have not changed. No need to overwrite.

Entries will be added to the /etc/oratab file as needed by
Database Configuration Assistant when a database is created
Finished running generic part of root script.
Now product-specific root actions will be performed.</code></pre> 
<p><strong>dbca建库</strong></p> 
<pre><code class="language-bash">[oracle@cwdb01:/u01/app/oracle/product/19.3.0/dbhome_1]$ export DISPLAY=192.168.6.1:0.0
[oracle@cwdb01:/u01/app/oracle/product/19.3.0/dbhome_1]$ dbca</code></pre> 
<p><img alt="" height="924" src="https://images2.imgbox.com/37/5c/ml0ky7H8_o.png" width="1200"></p> 
<h2>配置归档</h2> 
<pre><code class="language-bash">1、节点2关闭实例
[oracle@cwdb02:/u01/app/oracle/product/19.3.0/dbhome_1/dbs]$ sqlplus / as sysdba
SQL&gt; archive log list
Database log mode              No Archive Mode
Automatic archival             Disabled
Archive destination            /u01/app/oracle/product/19.3.0/dbhome_1/dbs/arch
Oldest online log sequence     1
Current log sequence           1

SQL&gt; shutdown immediate
Database closed.
Database dismounted.
ORACLE instance shut down.

2、节点1修改cluster参数
[oracle@oadb01:/u01/app/oracle/product/19.3.0/dbhome_1/dbs]$ sqlplus / as sysdba
SQL&gt; show parameter cluster

NAME                                 TYPE                              VALUE
------------------------------------ --------------------------------- ------------------------------
cluster_database                     boolean                           TRUE
cluster_database_instances           integer                           2
cluster_interconnects                string

SQL&gt; alter system set cluster_database=false;
alter system set cluster_database=false
                 *
ERROR at line 1:
ORA-02095: specified initialization parameter cannot be modified


SQL&gt; alter system set cluster_database=false scope=spfile;

System altered.


2、修改参数
SQL&gt; show parameter db_recovery

NAME                                 TYPE                              VALUE
------------------------------------ --------------------------------- ------------------------------
db_recovery_file_dest                string
db_recovery_file_dest_size           big integer                       0
db_recycle_cache_size                big integer                       0
SQL&gt; alter system set db_recovery_file_dest_size=3g;

System altered.

SQL&gt; alter system set db_recovery_file_dest='+DGFRA';

System altered.

3、节点1启动mount
SQL&gt; shutdown immediate
Database closed.
Database dismounted.
ORACLE instance shut down.
SQL&gt; startup mount
ORACLE instance started.

Total System Global Area 1258291200 bytes
Fixed Size                  2923920 bytes
Variable Size             452985456 bytes
Database Buffers          788529152 bytes
Redo Buffers               13852672 bytes
Database mounted.

4、节点1开归档
SQL&gt; alter database archivelog;

Database altered.

SQL&gt; alter database flashback on;

Database altered.


5、将cluster参数修改回来
SQL&gt; alter system set cluster_database=true;
alter system set cluster_database=true
                 *
ERROR at line 1:
ORA-02095: specified initialization parameter cannot be modified


SQL&gt; alter system set cluster_database=true scope=spfile;

System altered.

5、重启
SQL&gt; shutdown immediate
ORA-01109: database not open


Database dismounted.
ORACLE instance shut down.
SQL&gt; startup   
ORACLE instance started.

Total System Global Area 1258291200 bytes
Fixed Size                  2923920 bytes
Variable Size             452985456 bytes
Database Buffers          788529152 bytes
Redo Buffers               13852672 bytes
Database mounted.
Database opened.
SQL&gt; archive log list
Database log mode              Archive Mode
Automatic archival             Enabled
Archive destination            USE_DB_RECOVERY_FILE_DEST
Oldest online log sequence     5
Next log sequence to archive   6
Current log sequence           6

6、节点2启动
SQL&gt; startup
ORACLE instance started.

Total System Global Area 1258291200 bytes
Fixed Size                  2923920 bytes
Variable Size             520094320 bytes
Database Buffers          721420288 bytes
Redo Buffers               13852672 bytes
Database mounted.
Database opened.

SQL&gt; archive log list
Database log mode              Archive Mode
Automatic archival             Enabled
Archive destination            USE_DB_RECOVERY_FILE_DEST
Oldest online log sequence     1
Next log sequence to archive   2
Current log sequence           2</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f8877777b823209c3a6b03da28be5600/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">稳定的 Glance 来了，安卓小部件有救了！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dd3b8e31818fd97b5bff68e17442d925/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">面试题一：前端去重方法汇总你知道多少？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>