<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>11-09 周四 CNN 卷积神经网络基础知识 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="11-09 周四 CNN 卷积神经网络基础知识" />
<meta property="og:description" content="11-09 周四 CNN 卷积神经网络 时间版本修改人描述2023年11月9日09:38:12V0.1宋全恒新建文档 简介 学习一下CNN，卷积神经网络。使用的视频课程。视觉相关的任务：
人脸识别 卷积网络与传统网络的区别：
&lt;img alt=image-20231109094400591 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109094400591.png&amp;pos_id=img-Z35hmB60-1699522025179)&gt;
&lt;img alt=image-20231109094414779 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109094414779.png&amp;pos_id=img-08hzm0rf-1699522028665)&gt;
卷积神经网络是一个三维的数据，是h*w*c
整体架构 &lt;img alt=image-20231109094649673 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109094649673.png&amp;pos_id=img-AGVXtOFG-1699522031824)&gt;
输入层卷积层池化层全连接层 卷积层 调度卷积核是5*5*3，也是一个立方体的。
卷积神经网络也是使用一组权重参数进行加权求和得出的。
&lt;img alt=image-20231109094831385 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109094831385.png&amp;pos_id=img-pBCi31QD-1699522034969)&gt;
注： 上图仅演示了一个通道，图像是3通道。
相当于权重参数矩阵为:
&lt;img alt=image-20231109095218835 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109095218835.png&amp;pos_id=img-ZZahJ8Qu-1699522038141)&gt;
卷积神经网络的目的也是找到一组最佳的权重参数。
注： 卷积核的第三个维度一定要一样才行。卷积采用内积实现。Filter的尺寸一般为3， 5，7。 在进行卷积核的时候与卷积核的第三个维度数量相等。
&lt;img alt=image-20231109105238890 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109105238890.png&amp;pos_id=img-41nSowP4-1699522038975)&gt;
5x5x3代表一个卷积核，该卷积核的深度为3，与输入的深度相同。得到一个特征图，深度与输入图相同。卷积核可以有多个，则可以得到多个特征图。即Feature W0， Feature W1, … 经过多个卷积核得到多个特征图feture picture。
如下图所示：
上图经过卷积层得到了28 * 28 * 6个特征图。
将经过卷积核卷积之后的图堆叠在一起，得到了特征图堆。并且，卷积应该经过多次，依次得到Low-level Feature， Mid-Level Feature， High-Level Feature。也就是说，一次卷积是不够的。
上图说明卷积核5 * 5 * 3得到的是一个值，一个立方体得到一个值。也就是说，一个图如果一个卷积核扫描完全部得到的是一个28 * 28 * 1的图。使用6个卷积核，则得到的卷积图是28 * 28 * 6." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/5ed1e09a866e2adfc28ae165a87d27d7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-09T17:27:20+08:00" />
<meta property="article:modified_time" content="2023-11-09T17:27:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">11-09 周四 CNN 卷积神经网络基础知识</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <center>
  11-09 周四 CNN 卷积神经网络 
</center> 
<table><thead><tr><th>时间</th><th>版本</th><th>修改人</th><th>描述</th></tr></thead><tbody><tr><td>2023年11月9日09:38:12</td><td>V0.1</td><td>宋全恒</td><td>新建文档</td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr></tbody></table> 
<h2><a id="_8"></a>简介</h2> 
<p> 学习一下CNN，卷积神经网络。使用的<a href="https://www.bilibili.com/video/BV1zF411V7xu/?spm_id_from=333.337.search-card.all.click&amp;vd_source=d0b3156b49e79e2abe93c6d16e28bbf9" rel="nofollow">视频课程</a>。视觉相关的任务：</p> 
<ul><li>人脸识别</li></ul> 
<p> 卷积网络与传统网络的区别：</p> 
<p>&lt;img alt=image-20231109094400591 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109094400591.png&amp;pos_id=img-Z35hmB60-1699522025179)&gt;</p> 
<p>&lt;img alt=image-20231109094414779 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109094414779.png&amp;pos_id=img-08hzm0rf-1699522028665)&gt;</p> 
<blockquote> 
 <p>卷积神经网络是一个三维的数据，是h*w*c</p> 
</blockquote> 
<h3><a id="_23"></a>整体架构</h3> 
<p>&lt;img alt=image-20231109094649673 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109094649673.png&amp;pos_id=img-AGVXtOFG-1699522031824)&gt;</p> 
<ul><li>输入层</li><li>卷积层</li><li>池化层</li><li>全连接层</li></ul> 
<h4><a id="_33"></a>卷积层</h4> 
<p>调度卷积核是5*5*3，也是一个立方体的。</p> 
<p> 卷积神经网络也是使用一组权重参数进行加权求和得出的。</p> 
<p>&lt;img alt=image-20231109094831385 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109094831385.png&amp;pos_id=img-pBCi31QD-1699522034969)&gt;</p> 
<blockquote> 
 <p>注： 上图仅演示了一个通道，图像是3通道。</p> 
</blockquote> 
<p> 相当于权重参数矩阵为:</p> 
<p>&lt;img alt=image-20231109095218835 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109095218835.png&amp;pos_id=img-ZZahJ8Qu-1699522038141)&gt;</p> 
<p> 卷积神经网络的目的也是找到一组最佳的权重参数。</p> 
<blockquote> 
 <p>注： 卷积核的第三个维度一定要一样才行。卷积采用内积实现。Filter的尺寸一般为3， 5，7。 在进行卷积核的时候与卷积核的第三个维度数量相等。</p> 
</blockquote> 
<p>&lt;img alt=image-20231109105238890 src=https://img-home.csdnimg.cn/images/20230724024159.png?origin_url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fyanchenmochen%2Fimgs%2Fimgsimage-20231109105238890.png&amp;pos_id=img-41nSowP4-1699522038975)&gt;</p> 
<p> 5x5x3代表一个卷积核，该卷积核的深度为3，与输入的深度相同。得到一个特征图，深度与输入图相同。卷积核可以有多个，则可以得到多个特征图。即Feature W0， Feature W1, … 经过多个卷积核得到多个特征图feture picture。</p> 
<p> 如下图所示：</p> 
<img alt="image-20231109105404933" src="https://images2.imgbox.com/35/68/i63p9yV5_o.png"> 
<p> 上图经过卷积层得到了28 * 28 * 6个特征图。</p> 
<blockquote> 
 <p>将经过卷积核卷积之后的图堆叠在一起，得到了特征图堆。并且，卷积应该经过多次，依次得到Low-level Feature， Mid-Level Feature， High-Level Feature。也就是说，一次卷积是不够的。</p> 
</blockquote> 
<img alt="image-20231109110748134" src="https://images2.imgbox.com/d1/ea/T1VusxC9_o.png"> 
<p> 上图说明卷积核5 * 5 * 3得到的是一个值，一个立方体得到一个值。也就是说，一个图如果一个卷积核扫描完全部得到的是一个28 * 28 * 1的图。使用6个卷积核，则得到的卷积图是28 * 28 * 6.</p> 
<p> 第二卷积是10个 5x5x6得到就是24 * 24 * 10。</p> 
<h4><a id="_71"></a>卷积核涉及参数</h4> 
<img alt="image-20231109111654745" src="https://images2.imgbox.com/cf/49/dkTUm9PJ_o.png"> 
<h5><a id="_75"></a>步长</h5> 
<blockquote> 
 <p>步长为1，得到5 * 5， 而步长为2， 得到3 *3 。 相当于步长越小，得到的特征较多，越丰富。一般视觉任务使用的步长为1，但相应的计算量较大，文本类任务，也有使用步长为2.</p> 
</blockquote> 
<img alt="image-20231109111744195" src="https://images2.imgbox.com/1b/cc/QPpoJf1R_o.png"> 
<h5><a id="_81"></a>卷积核尺寸</h5> 
<p>卷积核尺寸越小，越细粒度。 一般是3 * 3。</p> 
<h5><a id="_85"></a>边缘填充</h5> 
<p>+pad,边缘填充属性。</p> 
<blockquote> 
 <p>越往边界的点，被利用的次数越少。下图中原始输入是5 * 5，通过边缘填充在边缘上变成了7 * 7. 又不希望添加的值影响计算。所以一般使用zero padding。</p> 
</blockquote> 
<img alt="image-20231109112224568" src="https://images2.imgbox.com/fd/bb/nqgPejYX_o.png"> 
<h5><a id="_93"></a>卷积计算公式</h5> 
<img alt="image-20231109113033603" src="https://images2.imgbox.com/e7/f8/yiORJxHW_o.png"> 
<p> 对于下面的案例，可以得到输出的尺寸：</p> 
<p><strong><img alt="image-20231109113251254" src="https://images2.imgbox.com/b0/fc/URnl9Svc_o.png"></strong></p> 
<blockquote> 
 <p>在听这个课程的时候，学习了卷积核的作用。卷积核的深度与输入是相同的，因此，卷积核是一个立方体。但是得到的结果确实一个平面。因为一个输入图像区域只得到了一个值</p> 
</blockquote> 
<p> 具体可以参见 <a href="https://thomelane.github.io/convolutions/2DConvRGB.html" rel="nofollow">3D</a></p> 
<p> 2D卷积可以参见 <a href="https://ezyang.github.io/convolution-visualizer/index.html" rel="nofollow">2D卷积</a></p> 
<h5><a id="_107"></a>卷积参数共享</h5> 
<blockquote> 
 <p>卷积参数共享一个巨大的好处就是参数共享，同样的一组参数对图像中每个小区域进行处理。相对于传统的神经网络，参数降低了非常多。</p> 
</blockquote> 
<img alt="image-20231109134400604" src="https://images2.imgbox.com/03/f6/rL5VEUAP_o.png"> 
<blockquote> 
 <p>10个 5 * 5 * 3卷积核，共75 * 10 =750个卷积参数 再加上10个偏置项共760个参数。</p> 
</blockquote> 
<h5><a id="_117"></a>池化层</h5> 
<blockquote> 
 <p>卷积层的特征点太多，会导致计算量过大。而且有些特征对于任务并不重要。因此可以通过池化进行瘦身。降采样 downsample。</p> 
</blockquote> 
<img alt="image-20231109134807557" src="https://images2.imgbox.com/c6/d3/ER9p14iR_o.png"> 
<p> 降采样的方式有最大值采样，平均值采样。 降采样也有区域和步长。2 * 2 并且步长为2.池化层不涉及矩阵操作，而是仅仅筛选动作。</p> 
<ul><li>max pooling 最好的特征。</li><li>平均值池化 average pooling 用的比较少。</li></ul> 
<h2><a id="_130"></a>任务</h2> 
<p> 如下图，卷积层要经过relu， 非线性变换。卷积层和relu是一组。经过卷积组，池化，然后最后一个全连接FC进行分类。</p> 
<p> 每个卷积组：</p> 
<ul><li>卷积</li><li>Relu</li></ul> 
<p> 在卷积层最后进行全连接时，需要将特征图进行拉长操作，将图拉成一个特征向量。最后与分类数量个神经元进行全连接。</p> 
<p> 一层神经网络： <code>带参数计算</code>。relu是没有参数计算的。即激活没有参数。即POOL也没有参数计算的。如下图一共是7层神经网络。</p> 
<img alt="image-20231109135323230" src="https://images2.imgbox.com/8d/fa/rlBshJlm_o.png"> 
<p> 特征图变化如下：</p> 
<img alt="image-20231109135810731" src="https://images2.imgbox.com/f3/5b/F6sVtRvU_o.png"> 
<p> 上图中转换即拉伸成向量。</p> 
<h4><a id="Alexnet2012_151"></a>Alexnet-2012</h4> 
<p> 227 * 227 * 3</p> 
<img alt="image-20231109135941294" src="https://images2.imgbox.com/f3/03/YbDNkrhm_o.png"> 
<h4><a id="VGG2014_157"></a>VGG-经典网络-2014</h4> 
<p> VGG filter均为3 * 3，卷积核比较小，网络层数为16。在池化后，通过增加卷积次数，即增加特征图的数量来弥补池化的损失。但Alexnet训练8小时，VGG可能需要3天才能训练完成。</p> 
<img alt="image-20231109140119211" src="https://images2.imgbox.com/fd/52/p3o5oDn9_o.png"> 
<p> VGG 在实验室 16层的网络，比30层的时候效果好，因为深度学习，越深越好，但实验结果令人失望，深度学习进入低谷。</p> 
<h4><a id="Resnet2015_165"></a>Resnet残差网络-2015</h4> 
<p> 何凯明的工作，将增加层数中具有促进效果的层数保留，网络训练的结果一定不会比之前差。</p> 
<img alt="image-20231109140556245" src="https://images2.imgbox.com/7e/5f/hgSEwnIj_o.png"> 
<p> 相当于残差网络拯救了深度学习神经网络。Resnet更加经典，更主流。</p> 
<img alt="image-20231109141059014" src="https://images2.imgbox.com/ac/de/KiP8hnIQ_o.png"> 
<p> </p> 
<p> 下图中橙色为Resnet，误差更小。</p> 
<img alt="image-20231109141243759" src="https://images2.imgbox.com/c4/24/zOERxLne_o.png"> 
<h5><a id="_181"></a>感受野</h5> 
<p> 感受野有什么作用：希望感受野越来越大。3个3 * 3 得到的感受野为7 * 7， 那么与直接使用7 * 7的卷积核进行卷积需要的区别。</p> 
<img alt="image-20231109141341031" src="https://images2.imgbox.com/ac/93/UgCQ2yfe_o.png"> 
<p> 堆叠小的卷积核需要的参数越少，训练更快。而且小卷积核由于经过的relu次数多，非线性特征保存的更好。</p> 
<img alt="image-20231109141930649" src="https://images2.imgbox.com/05/b3/0Nm0EpxT_o.png"> 
<h2><a id="_191"></a>项目实战</h2> 
<h3><a id="_193"></a>构造神经网络</h3> 
<p> conv + relu 是一个组合。</p> 
<img alt="image-20231109142448589" src="https://images2.imgbox.com/a3/56/y4AyRk9L_o.png"> 
<ul><li> <p>in_channels : 通道数。</p> </li><li> <p>out_channels: 16,使用16个特征图。</p> </li><li> <p>kernel_size=5; 卷积核尺寸5 * 5</p> </li><li> <p>stride = 1； 步长。</p> </li><li> <p>padding=2 ； 边缘填充。</p> </li><li> <h3><a id="_209"></a>前向传播得到预测结果</h3> </li></ul> 
<img alt="image-20231109143420839" src="https://images2.imgbox.com/db/52/MvGL4W7Q_o.png"> 
<h3><a id="_213"></a>训练</h3> 
<p> 使用pytorch进行训练。</p> 
<img alt="image-20231109143610085" src="https://images2.imgbox.com/f5/f3/C6HL7PZJ_o.png"> 
<h2><a id="Vision_219"></a>Vision模块</h2> 
<p> TorchVision有许多的数据集。</p> 
<ul><li> <p>数据预处理</p> 
  <ul><li>dataset数据集</li></ul> </li><li> <p>网络模块设置</p> 
  <blockquote> 
   <p>分类任务</p> 
   <p>semantic segmentation</p> 
   <p>object detection， instance segmentation and Person Keypoint Detection</p> 
   <p>Video classfication</p> 
  </blockquote> 
  <ul><li>甚至可以拿到别人的预训练模型</li></ul> </li></ul> 
<img alt="image-20231109144332156" src="https://images2.imgbox.com/6e/16/siF7PyxV_o.png"> 
<ul><li>网络模型保存和测试 
  <ul><li>transforms 
    <ul><li>PIL Image</li></ul> </li></ul> </li></ul> 
<h2><a id="_247"></a>任务</h2> 
<h3><a id="_249"></a>任务介绍</h3> 
<p> flowers 一共102种分类。</p> 
<p> 要把数据和标签读进来。ImageFolder工具。</p> 
<ul><li>数据预处理 
  <ul><li>DataLoader模块直接读取batch数据</li></ul> </li><li>网络模块设置 
  <ul><li>迁移学习</li><li>需要把head层改一改 256 * 256 ， 224 * 224</li><li>训练时可以全部重新训练，也可以只训练咱们任务的层，本质目标是一致的。</li></ul> </li><li>网络模型保存与测试</li></ul> 
<h3><a id="Data_Augmentation_265"></a>数据增强Data Augmentation</h3> 
<p> 让数据量更多。</p> 
<p> 数据不够时，这样做。</p> 
<p> 如何更好的利用数据，倾斜，水平和垂直翻转，旋转，放大和缩小，即得到一个新的数据。</p> 
<img alt="image-20231109145738260" src="https://images2.imgbox.com/e6/93/YXqTHAqI_o.png"> 
<blockquote> 
 <p>一般，网络的输入大小是固定的，因此，需要resize成预期大小。</p> 
</blockquote> 
<p> 下面代码中CenterCrop(224)中心裁剪。</p> 
<p> RandomhorizontalFlip(p=0.5)概率值，是随机翻转的概率。</p> 
<p> 亮度，对比度，饱和度 色相。</p> 
<p> transforms.Normalize() 即要进行标准化，参数1为均值， 参数2为标准差</p> 
<p> 具体的样例代码：</p> 
<img alt="image-20231109150211101" src="https://images2.imgbox.com/4e/cb/J1Nd5WcK_o.png"> 
<blockquote> 
 <p>训练集做了标准化，则测试集也要做相同的标准化。</p> 
</blockquote> 
<h4><a id="_291"></a>数据加载</h4> 
<img alt="image-20231109151656003" src="https://images2.imgbox.com/a9/a9/8yhoZYMe_o.png"> 
<h4><a id="_295"></a>读取标签对应的名字</h4> 
<img alt="image-20231109154444863" src="https://images2.imgbox.com/6f/f6/GJLFQt61_o.png"> 
<h4><a id="_299"></a>展示下数据</h4> 
<img alt="image-20231109154714475" src="https://images2.imgbox.com/1a/66/S0sp8Zt2_o.png"> 
<img alt="image-20231109154834989" src="https://images2.imgbox.com/2b/bb/IHTDV0kE_o.png"> 
<h3><a id="_305"></a>迁移学习</h3> 
<img alt="image-20231109155033175" src="https://images2.imgbox.com/11/ee/DU3R3fo8_o.png"> 
<blockquote> 
 <p>迁移学习的目标是用别人训练好的参数来执行任务。尽可能差异比较少一些。</p> 
</blockquote> 
<p> 那么迁移学习，学那个部分呢：</p> 
<ul><li>A: 使用卷积层的权重参数进行初始化。</li><li>B： 将人家训练好的参数冻住。对全连接层进行重新定义。 
  <ul><li>数据量越小，冻住的参数越多。不到10000.</li><li>数据量10000多，两万。挑出来一些。</li></ul> </li></ul> 
<blockquote> 
 <p>迁移学习，学习的非常快。迁移学习拿过来的模型都是经过大量实验的结果，经典网络结构，得到的结果更快也更好。如VGG， ResNet。</p> 
</blockquote> 
<h3><a id="_320"></a>模型加载</h3> 
<p> 需要指定模型名称</p> 
<img alt="image-20231109160756278" src="https://images2.imgbox.com/b3/33/NJtoMOPq_o.png"> 
<pre><code class="prism language-python">
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
</code></pre> 
<img alt="image-20231109160950304" src="https://images2.imgbox.com/04/96/lK9UZOgd_o.png"> 
<blockquote> 
 <p>需要修改最后全连接层，为当前用户的任务分类数目。</p> 
</blockquote> 
<p> 加载模型，并使用预训练模型。</p> 
<pre><code class="prism language-python"><span class="token operator">~</span><span class="token operator">/</span><span class="token punctuation">.</span>cache<span class="token operator">/</span>checkpoints<span class="token operator">/</span>resnet152<span class="token operator">-</span>b121ed2d<span class="token punctuation">.</span>pth
</code></pre> 
<pre><code class="prism language-python">model_ft <span class="token operator">=</span> models<span class="token punctuation">.</span>resnet152<span class="token punctuation">(</span>pretrained<span class="token operator">=</span>use_pretrained<span class="token punctuation">)</span>
set_parameter_requires_grad<span class="token punctuation">(</span>model_ft<span class="token punctuation">,</span> feature_extract<span class="token punctuation">)</span>
num_ftrs<span class="token operator">=</span>model_ft<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>in_features
model_ft<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_ftrs<span class="token punctuation">,</span><span class="token number">102</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
input_size<span class="token operator">=</span> <span class="token number">224</span>
</code></pre> 
<img alt="image-20231109161238856" src="https://images2.imgbox.com/10/ed/IT4b8rAJ_o.png"> 
<h3><a id="_353"></a>设置那些层需要训练</h3> 
<p> 如下的参数中：</p> 
<ul><li>model_name 指定了要使用的模型</li><li>102 指定了目标分类数</li><li>feature_extract: 是否要冻住某些模型</li><li>use_pretrained: 是否要使用预训练模型。</li></ul> 
<img alt="image-20231109162034134" src="https://images2.imgbox.com/14/e4/ShJHuUvG_o.png"> 
<p> 显示那些参数需要重新开始训练。</p> 
<img alt="image-20231109162256882" src="https://images2.imgbox.com/4c/a8/XAYHEZiz_o.png"> 
<h3><a id="_370"></a>优化器设置</h3> 
<blockquote> 
 <p>使用了学习率的衰减函数。效果会更稳定一些。</p> 
</blockquote> 
<img alt="image-20231109162434659" src="https://images2.imgbox.com/a8/6e/eddrSihv_o.png"> 
<h3><a id="_376"></a>训练模块</h3> 
<img alt="image-20231109162708803" src="https://images2.imgbox.com/99/f2/yfx3wqpz_o.png"> 
<img alt="image-20231109162807802" src="https://images2.imgbox.com/03/f2/mIz51nQO_o.png"> 
<img alt="image-20231109162853156" src="https://images2.imgbox.com/8d/be/1urlNGyt_o.png"> 
<img alt="image-20231109162948140" src="https://images2.imgbox.com/88/88/S3arDjaN_o.png"> 
<img alt="image-20231109163103654" src="https://images2.imgbox.com/95/0b/vrzErach_o.png"> 
<blockquote> 
 <p>保存模型参数权重字典</p> 
 <p>准确率</p> 
 <p>优化器参数权重字典</p> 
</blockquote> 
<img alt="image-20231109163159034" src="https://images2.imgbox.com/eb/5d/wi8OgI5D_o.png"> 
<img alt="image-20231109163341371" src="https://images2.imgbox.com/1d/df/40ymUUDz_o.png"> 
<h3><a id="_408"></a>开始训练</h3> 
<pre><code class="prism language-python">model_fit<span class="token punctuation">,</span> val_acc_history<span class="token punctuation">,</span> train_acc_history<span class="token punctuation">,</span> valid_losses<span class="token punctuation">,</span> train_losses<span class="token punctuation">,</span> LRs <span class="token operator">=</span> train_model<span class="token punctuation">(</span>model_ft<span class="token punctuation">,</span> dataloaders<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> num_epoches<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> is_inception<span class="token operator">=</span><span class="token punctuation">(</span>model_name<span class="token operator">==</span><span class="token string">'inception'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_414"></a>测试网络效果</h3> 
<h3><a id="_418"></a>完整训练</h3> 
<p> 将所有参数的<code>require_grad</code>设置为TRue，将学习率调整的小一些，以为之前用了别人的网络参数，学习率过大，可能会破坏掉之前的训练参数。</p> 
<p>&lt;img alt= src=https://cdn.jsdelivr.net/gh/yanchenmochen/imgs/imgsimage-20231109165735676.png&gt;</p> 
<h3><a id="Load_the_checkpoint_424"></a>Load the checkpoint</h3> 
<p> 加载之前保存的最好的模型继续开始训练。</p> 
<img alt="image-20231109165911702" src="https://images2.imgbox.com/ca/50/FO8acANA_o.png"> 
<h3><a id="_430"></a>实际测试</h3> 
<img alt="image-20231109170534039" src="https://images2.imgbox.com/96/fd/bNjktOGt_o.png"> 
<h4><a id="_434"></a>加载模型</h4> 
<img alt="image-20231109170632279" src="https://images2.imgbox.com/41/36/VFFDijCI_o.png"> 
<h4><a id="_438"></a>测试数据预处理</h4> 
<img alt="image-20231109170839775" src="https://images2.imgbox.com/c3/37/eImGIWRQ_o.png"> 
<p> 将一张图像处理成输入。</p> 
<h4><a id="_444"></a>得到处理结果</h4> 
<blockquote> 
 <p>8是因为batchsize。</p> 
</blockquote> 
<img alt="image-20231109171021606" src="https://images2.imgbox.com/0a/c6/hwzhCcr2_o.png"> 
<img alt="image-20231109171107236" src="https://images2.imgbox.com/ec/7c/Ro7yyHhv_o.png"> 
<img alt="image-20231109171137736" src="https://images2.imgbox.com/07/f5/AUIj8ioy_o.png"> 
<h2><a id="_458"></a>总结</h2> 
<p> 看了一天这个课程，终于看完了，对于卷积神经网络也算是有了更加进一步的理解了。现在就是要多多实战，敲代码就好了。现在还有点困惑的点包括：</p> 
<ul><li>优化器的选择</li><li>损失函数的选择<br>  不过，这个课程让自己对于卷积的理解加深了许多。</li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/da11c0e5585343e830ae09fff3c0ee12/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">BGP（Next-Hop）实验</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/00f676219903e5ddbf08a792cae1fa0d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">编译libigl笔记</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>