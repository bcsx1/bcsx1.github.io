<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>仿照FFmpeg在GLSL中处理HDR.ToneMapping（下） - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="仿照FFmpeg在GLSL中处理HDR.ToneMapping（下）" />
<meta property="og:description" content="FFmpeg 命令行 HDR 转 SDR ffmpeg -i planet_hdr.MP4 -vf zscale=t=linear:npl=100,format=gbrpf32le,zscale=p=bt709,tonemap=tonemap=hable:desat=0,zscale=t=bt709:m=bt709:r=tv,format=yuv420p planet_ff_hdr2sdr.MP4 ffmpeg -i planet_hdr.MP4 -vf zscale=t=linear:npl=100,format=gbrpf32le,zscale=p=bt709,tonemap=tonemap=hable:desat=0,zscale=t=bt709:m=bt709:r=tv,format=yuv420p planet_ff_hdr2sdr.MP4
一行行来拆解命令行内容，最主要的是 -vf video filter的一大串命令。 1、zscale=t=linear:npl=100 =&gt; 指定zscale模块的转换函数linear，输入参数npl=100
format=gbrpf32le =&gt; 转换格式gbr浮点32 little end zscale=p=bt709 =&gt; 指定zscale模块的设置色域bt709
2、tonemap=tonemap=hable:desat=0 =&gt; 指定tonemapping转换算法hable，输入参数desat=0
3、zscale=t=bt709:m=bt709:r=tv =&gt; 指定zscale模块的转换函数bt709，range=tv. limited
format=yuv420p =&gt; 转换格式yuv420p
zscale转换模块是ffmpeg内部引用第三方库zimg，官方介绍地址：FFmpeg Filters Documentation想利用zscale，必须确认ffmpeg编译是--enable-libzimg，zimg库源码：GitHub - sekrit-twc/zimg: Scaling, colorspace conversion, and dithering library
命令行是一个串联执行流程，顺序不能乱。接下来我们就从ffmpeg和zscale模块的源码当中寻求解决方案。
第一步，颜色数字信号经过EOTF转换为线性的模拟光信号
我们可以从zimg代码里面的src / zimg / colorspace / operation.cpp源文件中找到关键函数
std::unique_ptr&lt;Operation&gt; create_gamma_to_linear_operation(const ColorspaceDefinition &amp;in, const ColorspaceDefinition &amp;out, const OperationParams &amp;params, CPUClass cpu) { zassert_d(in." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/1ba3e929ec1a19da3bfd96fa11f934dd/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-09T17:49:45+08:00" />
<meta property="article:modified_time" content="2022-05-09T17:49:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">仿照FFmpeg在GLSL中处理HDR.ToneMapping（下）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>FFmpeg 命令行 HDR 转 SDR</h3> 
<pre><code class="language-cpp">ffmpeg -i planet_hdr.MP4 -vf zscale=t=linear:npl=100,format=gbrpf32le,zscale=p=bt709,tonemap=tonemap=hable:desat=0,zscale=t=bt709:m=bt709:r=tv,format=yuv420p planet_ff_hdr2sdr.MP4</code></pre> 
<blockquote> 
 <p>ffmpeg -i planet_hdr.MP4 -vf zscale=t=linear:npl=100,format=gbrpf32le,zscale=p=bt709,tonemap=tonemap=hable:desat=0,zscale=t=bt709:m=bt709:r=tv,format=yuv420p planet_ff_hdr2sdr.MP4</p> 
</blockquote> 
<p>一行行来拆解命令行内容，最主要的是 -vf  video filter的一大串命令。 </p> 
<blockquote> 
 <p><strong>1、zscale=t=linear:npl=100 </strong></p> 
 <p><strong>=&gt; 指定zscale模块的转换函数linear，输入参数npl=100</strong></p> 
 <p>format=gbrpf32le           </p> 
 <p>=&gt; 转换格式gbr浮点32 little end </p> 
 <p>zscale=p=bt709             </p> 
 <p>=&gt; 指定zscale模块的设置色域bt709</p> 
 <p><strong>2、tonemap=tonemap=hable:desat=0 </strong></p> 
 <p><strong>=&gt; 指定tonemapping转换算法hable，输入参数desat=0</strong></p> 
 <p><strong>3、zscale=t=bt709:m=bt709:r=tv         </strong></p> 
 <p><strong>=&gt; 指定zscale模块的转换函数bt709，range=tv. limited</strong></p> 
 <p>format=yuv420p                             </p> 
 <p>=&gt; 转换格式yuv420p</p> 
</blockquote> 
<p>zscale转换模块是ffmpeg内部引用第三方库zimg，官方介绍地址：<a href="https://www.ffmpeg.org/ffmpeg-filters.html#zscale-1" rel="nofollow" title="FFmpeg Filters Documentation">FFmpeg Filters Documentation</a>想利用zscale，必须确认ffmpeg编译是--enable-libzimg，zimg库源码：<a href="https://github.com/sekrit-twc/zimg" title="GitHub - sekrit-twc/zimg: Scaling, colorspace conversion, and dithering library">GitHub - sekrit-twc/zimg: Scaling, colorspace conversion, and dithering library</a></p> 
<p>命令行是一个串联执行流程，顺序不能乱。接下来我们就从ffmpeg和zscale模块的源码当中寻求解决方案。</p> 
<p></p> 
<p><strong>第一步，颜色数字信号经过EOTF转换为线性的模拟光信号</strong></p> 
<p>我们可以从zimg代码里面的src / zimg / colorspace / operation.cpp源文件中找到关键函数</p> 
<pre><code class="language-cpp">std::unique_ptr&lt;Operation&gt; create_gamma_to_linear_operation(const ColorspaceDefinition &amp;in, const ColorspaceDefinition &amp;out, const OperationParams &amp;params, CPUClass cpu)
{
	zassert_d(in.primaries == out.primaries, "primaries mismatch");
	zassert_d((in.matrix == MatrixCoefficients::RGB || in.matrix == MatrixCoefficients::REC_2100_LMS) &amp;&amp;
	          (out.matrix == MatrixCoefficients::RGB || out.matrix == MatrixCoefficients::REC_2100_LMS), "must be RGB or LMS");
	zassert_d(in.transfer != TransferCharacteristics::LINEAR &amp;&amp; out.transfer == TransferCharacteristics::LINEAR, "wrong transfer characteristics");

	if (in.transfer == TransferCharacteristics::ARIB_B67 &amp;&amp; use_display_referred_b67(in.primaries, params))
		return create_inverse_arib_b67_operation(ncl_rgb_to_yuv_matrix_from_primaries(in.primaries), params);
	else
		return create_inverse_gamma_operation(select_transfer_function(in.transfer, params.peak_luminance, params.scene_referred), params, cpu);
}


std::unique_ptr&lt;Operation&gt; create_inverse_gamma_operation(const TransferFunction &amp;transfer, const OperationParams &amp;params, CPUClass cpu)
{
	std::unique_ptr&lt;Operation&gt; ret;

#if defined(ZIMG_X86)
	ret = create_inverse_gamma_operation_x86(transfer, params, cpu);
#elif defined(ZIMG_ARM)
	ret = create_inverse_gamma_operation_arm(transfer, params, cpu);
#endif
	if (!ret)
		ret = std::make_unique&lt;GammaOperationC&gt;(transfer.to_linear, 1.0f, transfer.to_linear_scale);

	return ret;
}</code></pre> 
<p>因为现在是按照PQ感知量化曲线的标准做转换，所以in.transfer不等于ARIB_B67(这是HLG混合对数转换标准)，走else逻辑。暂时不考虑平台加速，参照纯C实现 GammaOperationC。配置GammaOperationC之前经过select_transfer_function组合传输函数，继续往下看。</p> 
<pre><code class="language-cpp">// src / zimg / colorspace / gamma.cpp
TransferFunction select_transfer_function(TransferCharacteristics transfer, double peak_luminance, bool scene_referred)
{
	zassert_d(!std::isnan(peak_luminance), "nan detected");

	TransferFunction func{};

	func.to_linear_scale = 1.0f;
	func.to_gamma_scale = 1.0f;

	switch (transfer) {
	// ... 
    case TransferCharacteristics::REC_709:
		func.to_linear = scene_referred ? rec_709_inverse_oetf : rec_1886_eotf;
		func.to_gamma = scene_referred ? rec_709_oetf : rec_1886_inverse_eotf;
		break;
	case TransferCharacteristics::ST_2084:
		func.to_linear = scene_referred ? st_2084_inverse_oetf : st_2084_eotf;
		func.to_gamma = scene_referred ? st_2084_oetf : st_2084_inverse_eotf;
		func.to_linear_scale = static_cast&lt;float&gt;(ST2084_PEAK_LUMINANCE / peak_luminance);
		func.to_gamma_scale = static_cast&lt;float&gt;(peak_luminance / ST2084_PEAK_LUMINANCE);
		break;
	case TransferCharacteristics::ARIB_B67:
		func.to_linear = scene_referred ? arib_b67_inverse_oetf : arib_b67_eotf;
		func.to_gamma = scene_referred ? arib_b67_oetf : arib_b67_inverse_eotf;
		func.to_linear_scale = scene_referred ? 12.0f : static_cast&lt;float&gt;(1000.0 / peak_luminance);
		func.to_gamma_scale = scene_referred ? 1.0f / 12.0f : static_cast&lt;float&gt;(peak_luminance / 1000.0);
		break;
	default:
		error::throw_&lt;error::InternalError&gt;("invalid transfer characteristics");
		break;
	}

	return func;
}</code></pre> 
<pre><code class="language-cpp">// src / zimg / colorspace / operation_impl.cpp
class GammaOperationC final : public Operation {
	gamma_func m_func;
	float m_prescale;
	float m_postscale;
public:
	GammaOperationC(gamma_func func, float prescale, float postscale) :
		m_func{ func },
		m_prescale{ prescale },
		m_postscale{ postscale }
	{}

	void process(const float * const *src, float * const *dst, unsigned left, unsigned right) const override
	{
		EnsureSinglePrecision x87;

		for (unsigned p = 0; p &lt; 3; ++p) {
			const float *src_p = src[p];
			float *dst_p = dst[p];

			for (unsigned i = left; i &lt; right; ++i) {
				dst_p[i] = m_postscale * m_func(src_p[i] * m_prescale);
			}
		}
	}
};</code></pre> 
<p>提醒一句，要注意组装GammaOperationC的两个参数prescale / postscale的入参是什么。</p> 
<p>PQ感知量化曲线的标准是SMPTE ST 2084，非线性光情况，所以传输函数是用st_2084_eotf。</p> 
<pre><code class="language-cpp">constexpr float ST2084_M1 = 0.1593017578125f;
constexpr float ST2084_M2 = 78.84375f;
constexpr float ST2084_C1 = 0.8359375f;
constexpr float ST2084_C2 = 18.8515625f;
constexpr float ST2084_C3 = 18.6875f;		
constexpr float FLT_MIN 1.17549435082228750797e-38F

float st_2084_eotf(float x) noexcept
{
	// Filter negative values to avoid NAN.
	if (x &gt; 0.0f) {
		float xpow = zimg_x_powf(x, 1.0f / ST2084_M2);
		float num = std::max(xpow - ST2084_C1, 0.0f);
		float den = std::max(ST2084_C2 - ST2084_C3 * xpow, FLT_MIN);
		x = zimg_x_powf(num / den, 1.0f / ST2084_M1);
	} else {
		x = 0.0f;
	}

	return x;
}
</code></pre> 
<p>关键代码都已经帖出来了，总结一下流程：</p> 
<pre><code class="language-cpp">create_gamma_to_linear_operation
    -&gt; create_inverse_gamma_operation
        -&gt; select_transfer_function
            case TransferCharacteristics::ST_2084:
                func.to_linear = scene_referred ? st_2084_inverse_oetf : st_2084_eotf;
                func.to_linear_scale = static_cast&lt;float&gt;(ST2084_PEAK_LUMINANCE / peak_luminance);
                break;</code></pre> 
<p></p> 
<p></p> 
<p><strong>第二步，HDR的线性模拟光信号 ToneMapping转换到 SDR的线性模拟光信号</strong></p> 
<p>此步骤就是对应的代码是在ffmpeg的video filter视频滤镜处理当中，具体文件路径是ffmpeg \ libavfilter \ vf_tonemap.c，静态方法tonemap，具体代码如下：</p> 
<pre><code class="language-cpp">
#define MIX(x,y,a) (x) * (1 - (a)) + (y) * (a)
static void tonemap(TonemapContext *s, AVFrame *out, const AVFrame *in,
                    const AVPixFmtDescriptor *desc, int x, int y, double peak)
{
    int map[3] = { desc-&gt;comp[0].plane, desc-&gt;comp[1].plane, desc-&gt;comp[2].plane };
    const float *r_in = (const float *)(in-&gt;data[map[0]] + x * desc-&gt;comp[map[0]].step + y * in-&gt;linesize[map[0]]);
    const float *g_in = (const float *)(in-&gt;data[map[1]] + x * desc-&gt;comp[map[1]].step + y * in-&gt;linesize[map[1]]);
    const float *b_in = (const float *)(in-&gt;data[map[2]] + x * desc-&gt;comp[map[2]].step + y * in-&gt;linesize[map[2]]);
    float *r_out = (float *)(out-&gt;data[map[0]] + x * desc-&gt;comp[map[0]].step + y * out-&gt;linesize[map[0]]);
    float *g_out = (float *)(out-&gt;data[map[1]] + x * desc-&gt;comp[map[1]].step + y * out-&gt;linesize[map[1]]);
    float *b_out = (float *)(out-&gt;data[map[2]] + x * desc-&gt;comp[map[2]].step + y * out-&gt;linesize[map[2]]);
    float sig, sig_orig;

    /* load values */
    *r_out = *r_in;
    *g_out = *g_in;
    *b_out = *b_in;

    /* desaturate to prevent unnatural colors */
    if (s-&gt;desat &gt; 0) {
        float luma = s-&gt;coeffs-&gt;cr * *r_in + s-&gt;coeffs-&gt;cg * *g_in + s-&gt;coeffs-&gt;cb * *b_in;
        float overbright = FFMAX(luma - s-&gt;desat, 1e-6) / FFMAX(luma, 1e-6);
        *r_out = MIX(*r_in, luma, overbright);
        *g_out = MIX(*g_in, luma, overbright);
        *b_out = MIX(*b_in, luma, overbright);
    }

    /* pick the brightest component, reducing the value range as necessary
     * to keep the entire signal in range and preventing discoloration due to
     * out-of-bounds clipping */
    sig = FFMAX(FFMAX3(*r_out, *g_out, *b_out), 1e-6);
    sig_orig = sig;

    switch(s-&gt;tonemap) {
    default:
    case TONEMAP_NONE:
        // do nothing
        break;
    case TONEMAP_LINEAR:
        sig = sig * s-&gt;param / peak;
        break;
    case TONEMAP_GAMMA:
        sig = sig &gt; 0.05f ? pow(sig / peak, 1.0f / s-&gt;param)
                          : sig * pow(0.05f / peak, 1.0f / s-&gt;param) / 0.05f;
        break;
    case TONEMAP_CLIP:
        sig = av_clipf(sig * s-&gt;param, 0, 1.0f);
        break;
    case TONEMAP_HABLE:
        sig = hable(sig) / hable(peak);
        break;
    case TONEMAP_REINHARD:
        sig = sig / (sig + s-&gt;param) * (peak + s-&gt;param) / peak;
        break;
    case TONEMAP_MOBIUS:
        sig = mobius(sig, s-&gt;param, peak);
        break;
    }

    /* apply the computed scale factor to the color,
     * linearly to prevent discoloration */
    *r_out *= sig / sig_orig;
    *g_out *= sig / sig_orig;
    *b_out *= sig / sig_orig;
}</code></pre> 
<p>逻辑不难理解，注释也很健全，命令行入参参数desat=0。直接看看hable和mobius两个tonemap算法的实现</p> 
<pre><code class="language-cpp">static float hable(float in)
{
    float a = 0.15f, b = 0.50f, c = 0.10f, d = 0.20f, e = 0.02f, f = 0.30f;
    return (in * (in * a + b * c) + d * e) / (in * (in * a + b) + d * f) - e / f;
}

static float mobius(float in, float j, double peak)
{
    float a, b;

    if (in &lt;= j)
        return in;

    a = -j * j * (peak - 1.0f) / (j * j - 2.0f * j + peak);
    b = (j * j - 2.0f * j * peak + peak) / FFMAX(peak - 1.0f, 1e-6);

    return (b * b + 2.0f * b * j + j * j) / (b - a) * (in + a) / (in + b);
}
</code></pre> 
<p>简单看着不太懂其数学含义，tonemap其实就是一个编码压缩曲线，可以简单的理解为把[0，1024]的空间范围如何较好的压缩映射到[0，255]的空间范围。ToneMapping映射算法不单只是hable和mobius，还有很多其他类型，可以看看这篇文章的结束 <a href="https://zhuanlan.zhihu.com/p/21983679" rel="nofollow" title="Tone mapping进化论 - 知乎">Tone mapping进化论 - 知乎</a></p> 
<p></p> 
<p><strong>第三步，线性的模拟光信号 经过OETF转换为 数字颜色电信号</strong></p> 
<p>对应命令行，zscale=t=bt709:m=bt709:r=tv，指定zscale模块的转换函数bt709，转换矩阵也是bt.709，yuv range为tv. limited。<strong>这里提醒一下，经过ToneMapping处理后的线性模拟光信号，已经是SDR范围的数据，所以不要再使用smpte st 2084的HDR标准，指定使用bt.709，线性光场景的光电转换函数rec_709_oetf</strong></p> 
<p>代码流程和第一步差不多，这里不在贴出具体代码，总结一下：</p> 
<pre><code class="language-cpp">create_linear_to_gamma_operation
    -&gt; create_gamma_operation
        -&gt; select_transfer_function
            case TransferCharacteristics::REC_709:
		        func.to_gamma = scene_referred ? rec_709_oetf : rec_1886_inverse_eotf;
		        break;	</code></pre> 
<pre><code class="language-cpp">constexpr float REC709_ALPHA = 1.09929682680944f;
constexpr float REC709_BETA = 0.018053968510807f;
float rec_709_oetf(float x) noexcept
{
	x = std::max(x, 0.0f);

	if (x &lt; REC709_BETA)
		x = x * 4.5f;
	else
		x = REC709_ALPHA * zimg_x_powf(x, 0.45f) - (REC709_ALPHA - 1.0f);

	return x;
}</code></pre> 
<p></p> 
<p></p> 
<h3>GLSL实现HDR.ToneMapping</h3> 
<p>逻辑流程上面已经分析的很清楚了，废话不多说，直接上GLSL. fragment shader的代码。</p> 
<pre><code class="language-cpp">#version 320 es
precision highp float;
uniform int bitMark; // 双字节(16bit)存储10位数据的 位掩码个数
uniform lowp float imgWidth;
uniform lowp float imgHeight;
uniform highp usampler2D tex_unsigned_y; // GL_R16UI、GL_RED_INTEGER、GL_UNSIGNED_SHORT
uniform highp usampler2D tex_unsigned_uv;// GL_RG16UI、GL_RG_INTEGER、GL_UNSIGNED_SHORT
in  vec2 vTextureCoord;
out vec4 _FragColor;
 
highp vec3 YuvConvertRGB_BT2020(highp uvec3 yuv, int normalize) {
    highp vec3 rgb;
    highp int y = highp int(yuv.x);
    highp int u = highp int(yuv.y);
    highp int v = highp int(yuv.z);
	// [64, 960]
    float r = float(y - 64) * 1.164384                             - float(v - 512) * -1.67867;
    float g = float(y - 64) * 1.164384 - float(u - 512) * 0.187326 - float(v - 512) * 0.65042;
    float b = float(y - 64) * 1.164384 - float(u - 512) * -2.14177;
    rgb.r = r;
    rgb.g = g;
    rgb.b = b;
    if (normalize == 1) { 
        rgb.r = r / 1024.0; 
        rgb.g = g / 1024.0; 
        rgb.b = b / 1024.0; 
    }// 归一化处理，10位数据共有1024个色阶
    return rgb;
}

highp float ST2084_M1 = 0.1593017578125f;
const float ST2084_M2 = 78.84375f;
const float ST2084_C1 = 0.8359375f;
const float ST2084_C2 = 18.8515625f;
const float ST2084_C3 = 18.6875f;
highp float FLT_MIN = 1.17549435082228750797e-38F;
highp float st_2084_eotf(highp float x)
{
    highp float xpow = pow(x, float(1.0 / ST2084_M2));
    highp float num = max(xpow - ST2084_C1, 0.0);
    highp float den = max(ST2084_C2 - ST2084_C3 * xpow, FLT_MIN);
    return pow(num/den, 1.0 / ST2084_M1);
}

const float REC709_ALPHA = 1.09929682680944f;
const float REC709_BETA = 0.018053968510807f;
highp float rec_709_oetf(highp float x)
{
    x = max(x, 0.0);
    if (x &lt; REC709_BETA )
        x = x * 4.5;
    else
        x = REC709_ALPHA * pow(x, 0.45f) - (REC709_ALPHA - 1.0);
    return x;
}

#define FFMAX(a,b) ((a) &gt; (b) ? (a) : (b))
#define FFMAX3(a,b,c) FFMAX(FFMAX(a,b),c)
void main() {
    float samplerPosX = vTextureCoord.x * imgWidth;
    float samplerPosY = vTextureCoord.y * imgHeight;
    highp uint unsigned_y = texelFetch(tex_unsigned_y, ivec2(int(samplerPosX), int(samplerPosY)), 0).x;
    highp uint unsigned_u = texelFetch(tex_unsigned_uv, ivec2(int(samplerPosX / 2.0), int(samplerPosY / 2.0)), 0).r;
    highp uint unsigned_v = texelFetch(tex_unsigned_uv, ivec2(int(samplerPosX / 2.0), int(samplerPosY / 2.0)), 0).g;
    highp uvec3 yuv10bit = uvec3(unsigned_y &gt;&gt; bitMark, unsigned_u &gt;&gt; bitMark, unsigned_v &gt;&gt; bitMark);
    highp vec3 rgb10bit = YuvConvertRGB_BT2020(yuv10bit, 1);

    // 第一步、电 转线性光信号
	float ST2084_PEAK_LUMINANCE = 10000.0f;
	float peak_luminance = 800.0f
	// 参考zscale源代码参数ST2084_PEAK_LUMINANCE固定1w，peak_luminance视频元数据-标峰亮度值，静态元数据的全视频用一个peak，动态元数据的每一帧一个peak
	// 参考zscale源代码to_linear的GammaOperationC，to_linear_scale赋值是postscale，后处理缩放。
    float to_linear_scale = ST2084_PEAK_LUMINANCE / peak_luminance;
    highp vec3 fragColor = to_linear_scale * vec3(st_2084_eotf(rgb10bit.r), st_2084_eotf(rgb10bit.g), st_2084_eotf(rgb10bit.b));
	
    // 第二步、HDR线性 ToneMapping映射转成 SDR线性
	// 参考ffmpeg的tonemap函数，hable算法。
    highp float sig;
    highp float sig_orig;
    sig = FFMAX(FFMAX3(fragColor.r, fragColor.g, fragColor.b), 1e-6);
    sig_orig = sig;
    float peak = 540.0f / 100.0f; // 手机设备的最大亮度值MaxCLL / REFERENCE_WHITE(固定100);
    sig = hableF(sig) / hableF(peak);
    fragColor.r = fragColor.r * (sig / sig_orig);
    fragColor.g = fragColor.g * (sig / sig_orig);
    fragColor.b = fragColor.b * (sig / sig_orig);
	
    // 第三步、逆线性光信号，变回电
	// 参考zscale源代码，rec_709的to_gamma，没有prescale和postscale.
    fragColor = vec3(rec_709_oetf(fragColor.r), rec_709_oetf(fragColor.g), rec_709_oetf(fragColor.b));
    _FragColor = vec4(fragColor + vec3(0.0)/*额外曝光调试用*/, 1.0);
}</code></pre> 
<p>所有代码参考来源自FFmpeg和Zimg。流程知识源自 <a class="link-info" href="https://blog.csdn.net/a360940265a/category_11625435.html" title="HDR in Android专栏">HDR in Android专栏</a></p> 
<p></p> 
<p>再次强调，本次HDR.ToneMapping是根据PQ感知量化曲线的思路方法，需要配合HDR元数据peak_luminance-标峰亮度值等参数食用，动态元数据效果更佳。接下来会研究探讨HLG混合对数曲线的映射方式，此方式是不需要元数据的，比较方便容易扩展。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/cd984b9cdc0db2670ce6c8399dafd553/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【demo】基于链表的通用queue</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0ad08136b4e68a5d25a867d1929d6647/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">kolla 部署 openstack v1.0</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>