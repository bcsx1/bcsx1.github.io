<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>全景图拼接【计算机视觉第三章】 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="全景图拼接【计算机视觉第三章】" />
<meta property="og:description" content="目录
全景图像拼接基本介绍
全景图拼接步骤
全景图拼接原理
RANSAC算法
图像配准
图割方法
图像融合
APAP算法
multi-band bleing算法​​​​​​​
全景图拼接代码实现 代码调试
报错1
解决方法
报错2
解决方法
运行代码拼接结果 数据集1（定点多角度拍摄的室外场景）
​特征匹配结果： 拼接结果图 数据集2（水平平移拍摄的室外场景） ​
特征匹配结果： 拼接结果图 数据集3（水平平移拍摄的室内场景） 特征匹配结果： 拼接结果图 总结
全景图像拼接基本介绍 图像拼接技术就是将数张有重叠部分的图像（可能是不同时间、不同视角或者不同传感器获得的）拼成一幅无缝的全景图或高分辨率图像的技术。图像拼接在医学成像、计算机视觉、卫星数据、军事目标自动识别等领域具有重要意义。图像拼接的输出是两个输入图像的并集。
图像配准（image alignment）和图像融合是图像拼接的两个关键技术。图像配准是图像融合的基础,而且图像配准算法的计算量一般非常大,因此图像拼接技术的发展很大程度上取决于图像配准技术的创新。早期的图像配准技术主要采用点匹配法,这类方法速度慢、精度低,而且常常需要人工选取初始匹配点,无法适应大数据量图像的融合。图像拼接的方法很多,不同的算法步骤会有一定差异,但大致的过程是相同的。
全景图拼接步骤 将SIFT应用到图像拼接上，根据特征点匹配的方式，则利用这些匹配的点来估算单应矩阵使用RANSAC算法，也就是把其中一张通过个关联性和另一张匹配的方法。通过单应矩阵H，可以将原图像中任意像素点坐标转换为新坐标点，转换后的图像即为适合拼接的结果图像。
可以简单分为以下几步:
1.根据给定图像/集，实现特征匹配。
2.通过匹配特征计算图像之间的变换结构。
3.利用图像变换结构，实现图像映射。
4.针对叠加后的图像，采用APAP之类的算法，对齐特征点。(图像配准)
5.通过图割方法，自动选取拼接缝。
6.根据multi-band blending策略实现融合。
全景图拼接原理 RANSAC算法 RANSAC[1] (随机抽样一致)是一种迭代算法，该算法从一组包含“外点(outlier)”的观测数据中估计数学模型的参数。“外点”指观测数据中的无效数据，通常为噪声或错误数据，比如图像匹配中的误匹配点和曲线拟合中的离群点。与“外点”相对应的是“内点(inlier)”，即用来估计模型参数的有效数据。因此，RANSAC也是一种“外点”检测算法。此外，RANSAC算法是一种非确定算法，它只能在一定概率下产生可信的结果，当迭代次数增加时，准确的概率也会增加。
RANSAC算法是用来找到正确模型来拟合带有噪声数据的迭代方法。
基本思想：数据中包含正确的点和噪声点，合理的模型应该能够在描述正确数据点的同时摈弃噪声点。
RANSAC的基本思想和算法流程如下：
随机采样K个点，K是求解模型参数的最少点个数使用K个点估计模型参数计算剩余点到估计模型的距离，距离小于阈值则为内点，统计内点的数目重复步骤1~3，重复次数M且保留数目最多的内点使用所有的内点重新估计模型
图像配准 图像配准是对图像进行变换，使变换后的图像能够在常见的坐标系中对齐。为了能够进行图像对比和更精细的图像分析，图像配准是一步非常重要的操作。图像配准的方法有很多，这里以APAP算法为例：
提取两张图片的sift特征点对两张图片的特征点进行匹配匹配后，仍有很多错误点，此时用RANSAC进行特征点对的筛选。筛选后的特征点基本能够一一对应。使用DLT算法，将剩下的特征点对进行透视变换矩阵的估计。因为得到的透视变换矩阵是基于全局特征点对进行的，即一个刚性的单应性矩阵完成配准。为提高配准的精度，Apap将图像切割成无数多个小方块，对每个小方块的变换矩阵逐一估计。
图割方法 最大流最小割算法原理，
1.最小割问题
一个有向图，并有一个源顶点（source vertex）和目标顶点（target vertex）.边的权值为正,又称之为容量（capacity）。如下图
一个st-cut(简称割cut)会把有向图的顶点分成两个不相交的集合，其中s在一个集合中，t在另外一个集合中。
这个割的容量（capacity of the cut）就是A到B所有边的容量和。注意这里不包含B到A的。最小割问题就是要找到割容量最小的情况。
2.最大流问题
跟mincut问题类似，maxflow要处理的情况也是一个有向图，并有一个原顶点（source vertex）和目标（target vertex），边的权值为正,又称之为容量（capacity）。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/0e31aa4be861654485cdde96e35c598c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-13T14:17:51+08:00" />
<meta property="article:modified_time" content="2022-04-13T14:17:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">全景图拼接【计算机视觉第三章】</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E5%85%A8%E6%99%AF%E5%9B%BE%E5%83%8F%E6%8B%BC%E6%8E%A5%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D-toc" style="margin-left:0px;"><a href="#%E5%85%A8%E6%99%AF%E5%9B%BE%E5%83%8F%E6%8B%BC%E6%8E%A5%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D" rel="nofollow">全景图像拼接基本介绍</a></p> 
<p id="%E5%85%A8%E6%99%AF%E5%9B%BE%E6%8B%BC%E6%8E%A5%E6%AD%A5%E9%AA%A4-toc" style="margin-left:0px;"><a href="#%E5%85%A8%E6%99%AF%E5%9B%BE%E6%8B%BC%E6%8E%A5%E6%AD%A5%E9%AA%A4" rel="nofollow">全景图拼接步骤</a></p> 
<p id="%E5%85%A8%E6%99%AF%E5%9B%BE%E6%8B%BC%E6%8E%A5%E5%8E%9F%E7%90%86-toc" style="margin-left:0px;"><a href="#%E5%85%A8%E6%99%AF%E5%9B%BE%E6%8B%BC%E6%8E%A5%E5%8E%9F%E7%90%86" rel="nofollow">全景图拼接原理</a></p> 
<p id="RANSAC%E7%AE%97%E6%B3%95-toc" style="margin-left:40px;"><a href="#RANSAC%E7%AE%97%E6%B3%95" rel="nofollow">RANSAC算法</a></p> 
<p id="%C2%A0%E5%9B%BE%E5%83%8F%E9%85%8D%E5%87%86-toc" style="margin-left:40px;"><a href="#%C2%A0%E5%9B%BE%E5%83%8F%E9%85%8D%E5%87%86" rel="nofollow"> 图像配准</a></p> 
<p id="%E5%9B%BE%E5%89%B2%E6%96%B9%E6%B3%95-toc" style="margin-left:40px;"><a href="#%E5%9B%BE%E5%89%B2%E6%96%B9%E6%B3%95" rel="nofollow">图割方法</a></p> 
<p id="%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88-toc" style="margin-left:40px;"><a href="#%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88" rel="nofollow">图像融合</a></p> 
<p id="APAP%E7%AE%97%E6%B3%95-toc" style="margin-left:40px;"><a href="#APAP%E7%AE%97%E6%B3%95" rel="nofollow">APAP算法</a></p> 
<p id="multi-band%20bleing%E7%AE%97%E6%B3%95-toc" style="margin-left:40px;"><a href="#multi-band%20bleing%E7%AE%97%E6%B3%95" rel="nofollow">multi-band bleing算法</a>​​​​​​​</p> 
<p id="%E5%85%A8%E6%99%AF%E5%9B%BE%E6%8B%BC%E6%8E%A5%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%C2%A0-toc" style="margin-left:0px;"><a href="#%E5%85%A8%E6%99%AF%E5%9B%BE%E6%8B%BC%E6%8E%A5%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%C2%A0" rel="nofollow">全景图拼接代码实现 </a></p> 
<p id="%E4%BB%A3%E7%A0%81%E8%B0%83%E8%AF%95-toc" style="margin-left:40px;"><a href="#%E4%BB%A3%E7%A0%81%E8%B0%83%E8%AF%95" rel="nofollow">代码调试</a></p> 
<p id="%E6%8A%A5%E9%94%991-toc" style="margin-left:80px;"><a href="#%E6%8A%A5%E9%94%991" rel="nofollow">报错1</a></p> 
<p id="%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95-toc" style="margin-left:80px;"><a href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95" rel="nofollow">解决方法</a></p> 
<p id="%E6%8A%A5%E9%94%992-toc" style="margin-left:80px;"><a href="#%E6%8A%A5%E9%94%992" rel="nofollow">报错2</a></p> 
<p id="%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95-toc" style="margin-left:80px;"><a href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95" rel="nofollow">解决方法</a></p> 
<p id="%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%C2%A0%20%C2%A0%20%C2%A0%20%C2%A0%20%C2%A0%20%C2%A0-toc" style="margin-left:40px;"><a href="#%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%C2%A0%20%C2%A0%20%C2%A0%20%C2%A0%20%C2%A0%20%C2%A0" rel="nofollow">运行代码拼接结果           </a></p> 
<p id="%E6%95%B0%E6%8D%AE%E9%9B%861%EF%BC%88%E5%AE%9A%E7%82%B9%E5%A4%9A%E8%A7%92%E5%BA%A6%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%A4%E5%A4%96%E5%9C%BA%E6%99%AF%EF%BC%89%C2%A0%E2%80%8B%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E7%BB%93%E6%9E%9C%EF%BC%9A%C2%A0-toc" style="margin-left:80px;"><a href="#%E6%95%B0%E6%8D%AE%E9%9B%861%EF%BC%88%E5%AE%9A%E7%82%B9%E5%A4%9A%E8%A7%92%E5%BA%A6%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%A4%E5%A4%96%E5%9C%BA%E6%99%AF%EF%BC%89%C2%A0%E2%80%8B%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E7%BB%93%E6%9E%9C%EF%BC%9A%C2%A0" rel="nofollow">数据集1（定点多角度拍摄的室外场景）</a></p> 
<p style="margin-left:80px;"><a href="#%E6%95%B0%E6%8D%AE%E9%9B%861%EF%BC%88%E5%AE%9A%E7%82%B9%E5%A4%9A%E8%A7%92%E5%BA%A6%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%A4%E5%A4%96%E5%9C%BA%E6%99%AF%EF%BC%89%C2%A0%E2%80%8B%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E7%BB%93%E6%9E%9C%EF%BC%9A%C2%A0" rel="nofollow"> ​特征匹配结果： </a></p> 
<p id="%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%E5%9B%BE%C2%A0-toc" style="margin-left:80px;"><a href="#%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%E5%9B%BE%C2%A0" rel="nofollow">拼接结果图 </a></p> 
<p id="%E6%95%B0%E6%8D%AE%E9%9B%862%EF%BC%88%E6%B0%B4%E5%B9%B3%E5%B9%B3%E7%A7%BB%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%A4%E5%A4%96%E5%9C%BA%E6%99%AF%EF%BC%89%C2%A0%E2%80%8B-toc" style="margin-left:80px;"><a href="#%E6%95%B0%E6%8D%AE%E9%9B%862%EF%BC%88%E6%B0%B4%E5%B9%B3%E5%B9%B3%E7%A7%BB%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%A4%E5%A4%96%E5%9C%BA%E6%99%AF%EF%BC%89%C2%A0%E2%80%8B" rel="nofollow">数据集2（水平平移拍摄的室外场景） ​</a></p> 
<p id="%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E7%BB%93%E6%9E%9C%EF%BC%9A%C2%A0%C2%A0-toc" style="margin-left:80px;"><a href="#%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E7%BB%93%E6%9E%9C%EF%BC%9A%C2%A0%C2%A0" rel="nofollow">特征匹配结果：  </a></p> 
<p id="%C2%A0%C2%A0%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%E5%9B%BE%C2%A0-toc" style="margin-left:80px;"><a href="#%C2%A0%C2%A0%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%E5%9B%BE%C2%A0" rel="nofollow">  拼接结果图 </a></p> 
<p id="%E6%95%B0%E6%8D%AE%E9%9B%863%EF%BC%88%E6%B0%B4%E5%B9%B3%E5%B9%B3%E7%A7%BB%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%A4%E5%86%85%E5%9C%BA%E6%99%AF%EF%BC%89%C2%A0-toc" style="margin-left:80px;"><a href="#%E6%95%B0%E6%8D%AE%E9%9B%863%EF%BC%88%E6%B0%B4%E5%B9%B3%E5%B9%B3%E7%A7%BB%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%A4%E5%86%85%E5%9C%BA%E6%99%AF%EF%BC%89%C2%A0" rel="nofollow">数据集3（水平平移拍摄的室内场景） </a></p> 
<p id="%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E7%BB%93%E6%9E%9C%EF%BC%9A%C2%A0%C2%A0-toc" style="margin-left:80px;"><a href="#%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E7%BB%93%E6%9E%9C%EF%BC%9A%C2%A0%C2%A0" rel="nofollow">特征匹配结果：  </a></p> 
<p id="%C2%A0%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%E5%9B%BE%C2%A0-toc" style="margin-left:80px;"><a href="#%C2%A0%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%E5%9B%BE%C2%A0" rel="nofollow"> 拼接结果图 </a></p> 
<p id="%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E6%80%BB%E7%BB%93" rel="nofollow">总结</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E5%85%A8%E6%99%AF%E5%9B%BE%E5%83%8F%E6%8B%BC%E6%8E%A5%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D">全景图像拼接基本介绍</h2> 
<p>图像拼接技术就是将数张有重叠部分的图像（可能是不同时间、不同视角或者不同传感器获得的）拼成一幅无缝的全景图或高分辨率图像的技术。图像拼接在医学成像、计算机视觉、卫星数据、军事目标自动识别等领域具有重要意义。图像拼接的输出是两个输入图像的并集。<br> 图像配准（image alignment）和图像融合是图像拼接的两个关键技术。图像配准是图像融合的基础,而且图像配准算法的计算量一般非常大,因此图像拼接技术的发展很大程度上取决于图像配准技术的创新。早期的图像配准技术主要采用点匹配法,这类方法速度慢、精度低,而且常常需要人工选取初始匹配点,无法适应大数据量图像的融合。图像拼接的方法很多,不同的算法步骤会有一定差异,但大致的过程是相同的。</p> 
<p></p> 
<h2 id="%E5%85%A8%E6%99%AF%E5%9B%BE%E6%8B%BC%E6%8E%A5%E6%AD%A5%E9%AA%A4">全景图拼接步骤</h2> 
<p>将SIFT应用到图像拼接上，根据特征点匹配的方式，则利用这些匹配的点来估算单应矩阵使用RANSAC算法，也就是把其中一张通过个关联性和另一张匹配的方法。通过单应矩阵H，可以将原图像中任意像素点坐标转换为新坐标点，转换后的图像即为适合拼接的结果图像。<br> 可以简单分为以下几步:<br> 1.根据给定图像/集，实现特征匹配。<br> 2.通过匹配特征计算图像之间的变换结构。<br> 3.利用图像变换结构，实现图像映射。<br> 4.针对叠加后的图像，采用APAP之类的算法，对齐特征点。(图像配准)<br> 5.通过图割方法，自动选取拼接缝。<br> 6.根据multi-band blending策略实现融合。<br>  </p> 
<h2 id="%E5%85%A8%E6%99%AF%E5%9B%BE%E6%8B%BC%E6%8E%A5%E5%8E%9F%E7%90%86">全景图拼接原理</h2> 
<h3 id="RANSAC%E7%AE%97%E6%B3%95">RANSAC算法</h3> 
<p></p> 
<p>RANSAC[1] (随机抽样一致)是一种迭代算法，该算法从一组包含“外点(outlier)”的观测数据中估计数学模型的参数。“外点”指观测数据中的无效数据，通常为噪声或错误数据，比如图像匹配中的误匹配点和曲线拟合中的离群点。与“外点”相对应的是“内点(inlier)”，即用来估计模型参数的有效数据。因此，RANSAC也是一种“外点”检测算法。此外，RANSAC算法是一种非确定算法，它只能在一定概率下产生可信的结果，当迭代次数增加时，准确的概率也会增加。</p> 
<p>RANSAC算法是用来找到正确模型来拟合带有噪声数据的迭代方法。<br> 基本思想：数据中包含正确的点和噪声点，合理的模型应该能够在描述正确数据点的同时摈弃噪声点。</p> 
<p>RANSAC的基本思想和算法流程如下：</p> 
<ol><li>随机采样K个点，K是求解模型参数的最少点个数</li><li>使用K个点估计模型参数</li><li>计算剩余点到估计模型的距离，距离小于阈值则为内点，统计内点的数目</li><li>重复步骤1~3，重复次数M且保留数目最多的内点</li><li>使用所有的内点重新估计模型<br>  </li></ol> 
<h3 id="%C2%A0%E5%9B%BE%E5%83%8F%E9%85%8D%E5%87%86"> 图像配准</h3> 
<p>图像配准是对图像进行变换，使变换后的图像能够在常见的坐标系中对齐。为了能够进行图像对比和更精细的图像分析，图像配准是一步非常重要的操作。图像配准的方法有很多，这里以APAP算法为例：</p> 
<ol><li>提取两张图片的sift特征点</li><li>对两张图片的特征点进行匹配</li><li>匹配后，仍有很多错误点，此时用RANSAC进行特征点对的筛选。筛选后的特征点基本能够一一对应。</li><li>使用DLT算法，将剩下的特征点对进行透视变换矩阵的估计。</li><li>因为得到的透视变换矩阵是基于全局特征点对进行的，即一个刚性的单应性矩阵完成配准。为提高配准的精度，Apap将图像切割成无数多个小方块，对每个小方块的变换矩阵逐一估计。<br>  </li></ol> 
<h3 id="%E5%9B%BE%E5%89%B2%E6%96%B9%E6%B3%95">图割方法</h3> 
<p>最大流最小割算法原理，<br> 1.最小割问题<br> 一个有向图，并有一个源顶点（source vertex）和目标顶点（target vertex）.边的权值为正,又称之为容量（capacity）。如下图</p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/ea/1b/zOgGX7xh_o.png"></p> 
<p>一个st-cut(简称割cut)会把有向图的顶点分成两个不相交的集合，其中s在一个集合中，t在另外一个集合中。<br> 这个割的容量（capacity of the cut）就是A到B所有边的容量和。注意这里不包含B到A的。最小割问题就是要找到割容量最小的情况。<br> 2.最大流问题<br> 跟mincut问题类似，maxflow要处理的情况也是一个有向图，并有一个原顶点（source vertex）和目标（target vertex），边的权值为正,又称之为容量（capacity）。<br> （1）初始化，所有边的flow都初始化为0。<br> （2）沿着增广路径增加flow。增广路径是一条从s到t的无向路径，但也有些条件，可以经过没有满容量的前向路径（s到t）或者是不为空的反向路径(t-&gt;s)。<br>  </p> 
<h3 id="%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88">图像融合</h3> 
<p>图像拼接之后可以发现，在拼接的交界处有明显的衔接痕迹，存在边缘效应，因为光照色泽的原因使得图片交界处的过渡很糟糕，所以需要特定的处理解决这种不自然。那么这时候可以采用blending方法。multi-band blending是目前图像融和方面比较好的方法。<br> 原理：</p> 
<ol><li>建立两幅图像的拉普拉斯金字塔</li><li>求高斯金字塔（掩模金字塔-为了拼接左右两幅图像）因为其具有尺度不变性</li><li>进行拼接blendLapPyrs() ; 在每一层上将左右laplacian图像直接拼起来得结果金字塔resultLapPyr</li><li>重建图像: 从最高层结果图</li></ol> 
<p>将左右laplacian图像拼成的resultLapPyr金字塔中每一层，从上到下插值放大并和下一层相加，即得blend图像结果（reconstructImgFromLapPyramid）<br> 且我们可以将拉普拉斯金字塔理解为高斯金字塔的逆形式。</p> 
<h3 id="APAP%E7%AE%97%E6%B3%95">APAP算法</h3> 
<p>在图像拼接融合的过程中，受客观因素的影响，拼接融合后的图像可能会存在“鬼影现象”以及图像间过度不连续等问题。下图就是图像拼接的一种“鬼影现象”。而APAP算法可以解决鬼影现象。</p> 
<p><img alt="" height="805" src="https://images2.imgbox.com/e8/a1/HWBop9Ai_o.png" width="1200"></p> 
<p>APAP算法流程:<br> 1.SIFT得到两幅图像的匹配点对<br> 2.通过RANSAC剔除外点，得到N对内点<br> 3.利用DLT和SVD计算全局单应性<br> 4.将源图划分网格，取网格中心点，计算每个中心点和源图上内点之间的欧式距离和权重<br> 5.将权重放到DLT算法的A矩阵中，构建成新的W*A矩阵，重新SVD分解，自然就得到了当前网格的局部单应性矩阵<br> 6.遍历每个网格，利用局部单应性矩阵映射到全景画布上，就得到了APAP变换后的源图<br> 7.最后就是进行拼接线的加权融合</p> 
<p>APAP算法虽然能够较好地完成配准，但非常依赖于特征点对。若图像高频信息较少，特征点对过少，配准将完全失效，并且对大尺度的图像进行配准，其效果也不是很好，一切都决定于特征点对的数量。</p> 
<h3 id="multi-band%20bleing%E7%AE%97%E6%B3%95">multi-band bleing算法</h3> 
<p>在找完拼接缝后，由于图像噪声、光照、曝光度、模型匹配误差等因素，直接进行图像合成会在图像重叠区域的拼接处出现比较明显的边痕迹。</p> 
<p><img alt="" src="https://images2.imgbox.com/6d/6b/opesilrJ_o.png"></p> 
<p>这些边痕迹需要使用图像融合算法来消除。这里介绍一种方法—multi-band bleing<br> 思想：<br> 采用的方法是直接对带拼接的两个图片进行拉普拉斯金字塔分解，后一半对前一半进行融合<br> 步骤：<br> 首先计算当前待拼接图像和已合成图像的重叠部分。并对图像A、B 重叠部分进行高斯金字塔和拉普拉斯金字塔分解<br><img alt="" height="611" src="https://images2.imgbox.com/34/94/dRLUc7un_o.png" width="1196"></p> 
<p>G0为原始图像，G1表示对G0做reduce操作。Reduce操作定义如下： </p> 
<p><img alt="" src="https://images2.imgbox.com/61/cc/vqx35oRp_o.png"></p> 
<p>对G1进行扩展后与G0相减，可以得到拉普拉斯金字塔的第一层L0。同理，拉普拉斯金字塔的L2、L3等层也可以按照这种方法来计算。<br> 两幅图像的融合过程：分别构建图像A、B的高斯金字塔和拉普拉斯金字塔，然后进行加权融合。<br> 对加权后的拉普拉斯金字塔进行重构</p> 
<h2 id="%E2%80%8B"><img alt="" height="667" src="https://images2.imgbox.com/25/72/t2XX4OCA_o.png" width="1195"></h2> 
<h2 id="%E5%85%A8%E6%99%AF%E5%9B%BE%E6%8B%BC%E6%8E%A5%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%C2%A0">全景图拼接代码实现 </h2> 
<p>估计出单应性矩阵H后，我们需要将所有图像扭曲到一个公共的图像平面上。通常，这里的公共平面为中心平面（否则，需要进行大量变形）。一种方法是创建一个很大的图像，比如将平面中全部填充为0，使其和中心图像平行，然后将所有的图像扭曲到上面。其基本步骤如下：</p> 
<p>（1）实现像素间的映射（计算像素和和单应性矩阵H相乘，然后对齐次坐标进行归一化）</p> 
<p>（2）判断图像填补位置（查看H中的平移量，左边为正，右边为负）</p> 
<p>（3）在单应性矩阵中加入平移量，进行alpha图填充</p> 
<p>图片集为五张的拼接</p> 
<pre><code class="language-python"># -*- codeing =utf-8 -*-
from pylab import *
from numpy import *
from PIL import Image

# If you have PCV installed, these imports should work
from PCV.geometry import homography, warp
from PCV.localdescriptors import sift
np.seterr(invalid='ignore')


# 设置数据文件夹的路径
featname = ['D:\\全景拼接\\' + str(i + 1) + '.sift' for i in range(5)]
imname = ['D:\\全景拼接\\' + str(i + 1) + '.jpg' for i in range(5)]

# 提取特征并匹配使用sift算法
l = {}
d = {}
for i in range(5):
    sift.process_image(imname[i], featname[i])
    l[i], d[i] = sift.read_features_from_file(featname[i])

matches = {}
for i in range(4):
    matches[i] = sift.match(d[i + 1], d[i])

# 可视化匹配
for i in range(4):
    im1 = array(Image.open(imname[i]))
    im2 = array(Image.open(imname[i + 1]))
    figure()
    sift.plot_matches(im2, im1, l[i + 1], l[i], matches[i], show_below=True)


# 将匹配转换成齐次坐标点的函数
def convert_points(j):
    ndx = matches[j].nonzero()[0]
    fp = homography.make_homog(l[j + 1][ndx, :2].T)
    ndx2 = [int(matches[j][i]) for i in ndx]
    tp = homography.make_homog(l[j][ndx2, :2].T)

    # switch x and y - TODO this should move elsewhere
    fp = vstack([fp[1], fp[0], fp[2]])
    tp = vstack([tp[1], tp[0], tp[2]])
    return fp, tp


# 估计单应性矩阵
model = homography.RansacModel()

fp, tp = convert_points(1)
H_12 = homography.H_from_ransac(fp, tp, model)[0]  # im 1 to 2

fp, tp = convert_points(0)
H_01 = homography.H_from_ransac(fp, tp, model)[0]  # im 0 to 1

tp, fp = convert_points(2)  # NB: reverse order
H_32 = homography.H_from_ransac(fp, tp, model)[0]  # im 3 to 2

tp, fp = convert_points(3)  # NB: reverse order
H_43 = homography.H_from_ransac(fp, tp, model)[0]  # im 4 to 3

# 扭曲图像
delta = 2000  # for padding and translation用于填充和平移

im1 = array(Image.open(imname[1]), "uint8")
im2 = array(Image.open(imname[2]), "uint8")
im_12 = warp.panorama(H_12, im1, im2, delta, delta)

im1 = array(Image.open(imname[0]), "f")
im_02 = warp.panorama(dot(H_12, H_01), im1, im_12, delta, delta)

im1 = array(Image.open(imname[3]), "f")
im_32 = warp.panorama(H_32, im1, im_02, delta, delta)

im1 = array(Image.open(imname[4]), "f")
im_42 = warp.panorama(dot(H_32, H_43), im1, im_32, delta, 2 * delta)

figure()
imshow(array(im_42, "uint8"))
axis('off')
show()

</code></pre> 
<p> 图片集为三张的拼接</p> 
<pre><code class="language-python"># -*- coding: utf-8 -*-
from pylab import *
from numpy import *
from PIL import Image
# If you have PCV installed, these imports should work
from PCV.geometry import homography, warp
from PCV.localdescriptors import sift
"""
This is the panorama example from section 3.3.
"""
# set paths to data folder
featname = ['D:\\全景拼接\\' + str(i + 1) + '.sift' for i in range(3)]
imname = ['D:\\全景拼接\\' + str(i + 1) + '.jpg' for i in range(3)]
# extract features and match
l = {}
d = {}
for i in range(3):
    sift.process_image(imname[i],featname[i])
    l[i],d[i] = sift.read_features_from_file(featname[i])
matches = {}
for i in range(2):
    matches[i] = sift.match(d[i+1],d[i])
    print(matches)
# visualize the matches (Figure 3-11 in the book)
for i in range(2):
    im1 = array(Image.open(imname[i]))
    im2 = array(Image.open(imname[i+1]))
    figure()
    sift.plot_matches(im2,im1,l[i+1],l[i],matches[i],show_below=True)
# function to convert the matches to hom. points
def convert_points(j):
    ndx = matches[j].nonzero()[0]
    fp = homography.make_homog(l[j+1][ndx,:2].T)
    ndx2 = [int(matches[j][i]) for i in ndx]
    tp = homography.make_homog(l[j][ndx2,:2].T)
    # switch x and y - TODO this should move elsewhere
    fp = vstack([fp[1],fp[0],fp[2]])
    tp = vstack([tp[1],tp[0],tp[2]])
    return fp,tp
# estimate the homographies
model = homography.RansacModel()
fp,tp = convert_points(0)
H_01 = homography.H_from_ransac(fp,tp,model)[0] #im 0 to 1
tp,fp = convert_points(1) #NB: reverse order
H_21 = homography.H_from_ransac(fp,tp,model)[0] #im 2 to 1
# warp the images
delta = 2000 # for padding and translation
im1 = array(Image.open(imname[0]), "uint8")
im2 = array(Image.open(imname[1]), "uint8")
im_01 = warp.panorama(H_01,im1,im2,delta,delta)
im1 = array(Image.open(imname[2]), "f")
im_21 = warp.panorama(H_21,im1,im_01,delta,delta)
figure()
imshow(array(im_21, "uint8"))
axis('off')
savefig("result.png",dpi=300)
show()</code></pre> 
<h3 id="%E4%BB%A3%E7%A0%81%E8%B0%83%E8%AF%95">代码调试</h3> 
<h4 id="%E6%8A%A5%E9%94%991">报错1</h4> 
<pre><code class="language-python">Traceback (most recent call last):
  File "F:PJ.py", line 7, in &lt;module&gt;
    from PCV.geometry import homography, warp
  File "F:warp.py", line 1, in &lt;module&gt;
    import matplotlib.delaunay as md 
ModuleNotFoundError: No module named 'matplotlib.delaunay'
[Finished in 4.8s]
</code></pre> 
<h4 id="%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95">解决方法</h4> 
<p>因为PCV下面的warp.py里面的matplotlib.delaunay不再被使用了，所以把它换成一个相同功能的就可以：<br> ①：把import matplotlib.delaunay as md 换成from scipy.spatial import Delaunay<br> ②：warp.py里面的centers,edges,tri,neighbors = md.delaunay(x,y)换成tri= Delaunay(np.c_[x,y]).simplices就好啦</p> 
<h4 id="%E6%8A%A5%E9%94%992">报错2</h4> 
<pre><code class="language-python">runtimewarning：invalid value encountered in divide</code></pre> 
<h4>解决方法</h4> 
<p>runtimewarning:在divide中遇到无效值通过网上查阅资料，了解到只要加一句代码:np.seterr(invalid=‘ignore’)  就可以忽略报错，继续运行得出结果   </p> 
<h3 id="%E8%BF%90%E8%A1%8C%E4%BB%A3%E7%A0%81%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%C2%A0%20%C2%A0%20%C2%A0%20%C2%A0%20%C2%A0%20%C2%A0">运行代码拼接结果           </h3> 
<p>这是由于照片的排列顺序是要求从右往左的，但是我一开始是从左往右排序，就会导致这样的结果。我们的照片集应该按照从右到左编号，因为匹配是从最右边的照片开始计算。 </p> 
<h4 id="%E6%95%B0%E6%8D%AE%E9%9B%861%EF%BC%88%E5%AE%9A%E7%82%B9%E5%A4%9A%E8%A7%92%E5%BA%A6%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%A4%E5%A4%96%E5%9C%BA%E6%99%AF%EF%BC%89%C2%A0%E2%80%8B%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E7%BB%93%E6%9E%9C%EF%BC%9A%C2%A0">数据集1（定点多角度拍摄的室外场景） <br><img alt="" height="261" src="https://images2.imgbox.com/75/ab/BLHDWyKq_o.png" width="878">特征匹配结果： </h4> 
<h4><img alt="" height="470" src="https://images2.imgbox.com/16/28/EhbZDm3y_o.png" width="632"></h4> 
<p><img alt="" height="477" src="https://images2.imgbox.com/fc/87/Cb5XbhjK_o.png" width="637"></p> 
<h4 id="%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%E5%9B%BE%C2%A0">拼接结果图 </h4> 
<p><img alt="" height="229" src="https://images2.imgbox.com/0d/2f/yBnpPISn_o.png" width="741"></p> 
<p> 可以看到，在景深差距小，只有拍摄角度变化下的图片，拼接效果还是很好的，图中操场的线扭曲不大，几乎对齐。不过拼接缝非常明显，这是拍摄照片时的曝光不一致导致的。</p> 
<h4 id="%E6%95%B0%E6%8D%AE%E9%9B%862%EF%BC%88%E6%B0%B4%E5%B9%B3%E5%B9%B3%E7%A7%BB%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%A4%E5%A4%96%E5%9C%BA%E6%99%AF%EF%BC%89%C2%A0%E2%80%8B">数据集2（水平平移拍摄的室外场景） <img alt="" height="260" src="https://images2.imgbox.com/42/21/V5aHDK8K_o.png" width="926"></h4> 
<h4 id="%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E7%BB%93%E6%9E%9C%EF%BC%9A%C2%A0%C2%A0">特征匹配结果：  </h4> 
<p><img alt="" height="482" src="https://images2.imgbox.com/56/16/uvvxDeAI_o.png" width="1200"></p> 
<h4 id="%C2%A0%C2%A0%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%E5%9B%BE%C2%A0">  拼接结果图 </h4> 
<p><img alt="" height="371" src="https://images2.imgbox.com/26/69/8nudklb3_o.png" width="861"></p> 
<p> 可以看到拼接效果并不好，这是由于景深不同，拍摄的景物过多，平移拍摄过程中远处建筑群有的被遮挡，有的显现造成的。</p> 
<h4 id="%E6%95%B0%E6%8D%AE%E9%9B%863%EF%BC%88%E6%B0%B4%E5%B9%B3%E5%B9%B3%E7%A7%BB%E6%8B%8D%E6%91%84%E7%9A%84%E5%AE%A4%E5%86%85%E5%9C%BA%E6%99%AF%EF%BC%89%C2%A0">数据集3（水平平移拍摄的室内场景） </h4> 
<p><img alt="" height="268" src="https://images2.imgbox.com/0b/f1/XMwRpal7_o.png" width="922"></p> 
<h4>特征匹配结果：  </h4> 
<p><img alt="" height="476" src="https://images2.imgbox.com/e5/00/At9i22a1_o.png" width="1200"></p> 
<h4 id="%C2%A0%E6%8B%BC%E6%8E%A5%E7%BB%93%E6%9E%9C%E5%9B%BE%C2%A0"> 拼接结果图 </h4> 
<p><img alt="" height="218" src="https://images2.imgbox.com/02/e4/g5PFjSeA_o.png" width="592"></p> 
<p> 室内水平平移拍摄的照片的拼接效果非常好，几乎看不到扭曲变形的地方，拼接缝也看不到。</p> 
<h2 id="%E6%80%BB%E7%BB%93">总结</h2> 
<p>在本次实验过程中得到如下总结：对比固定点位拍摄和视差变化大的场景可以得到结论：固定点位拍照的图像在进行拼接的时候没有发生鬼影现象，但较远处的拼接有略微偏差，而差变化大的场景在进行拼接时，其对于远景的拼接效果极好，细节处的拼接也处理得很到位。两种场景各有优劣。<br> 分别对比室内和室外场景得拼接结果可以得到结论：室外场景的拼接效果较好，其特征点丰富，在拼接时参考性很大；室内场景单一，特征点也较少，拼接的效果也较为不好。<br> 实验中，拼接图像的像素会影响运行速度，所以在拍摄图像上传到电脑后要进行处理，使得像素大小适当，这样对于运行时间会有较大的改变。<br> 代码中有个参数delta。这个参数是针对你拍摄图像时，你相对平移的距离的变量，当你拍摄近景时候，这个参数尽量该小，远景相反。<br> dpi是图像精细度的变量，可以通过修改来改变图像的分辨率，数值越大表示图像越精细，即分辨率越高。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c11936a76b2268d61b79d871558f80d9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">《勘测定界界址点坐标交换格式》解析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a5d12a5d3209e51c8286521964227b5a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">hive日期函数，求日期差等,datediff,date_add,date_sub,add_months</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>