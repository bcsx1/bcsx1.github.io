<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>springboot&#43;阿里云OSS分片上传、断点续传、秒传 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="springboot&#43;阿里云OSS分片上传、断点续传、秒传" />
<meta property="og:description" content="最近工作中有使用到OSS的分片上传API，整体流程就是前端将大文件进行分割，每个分片大小是1MB，分片个数是：(文件总大小 / 单个分片大小)，前端多线程处理上传分片到后端，后端接收到分片后调用OSS验证是否存在接口校验之前有没有传输过，如果分片在OSS上不存在则调用分片上传API进行上传，所有分片上传完成后调用OSS分片合并API，将所有分片在OSS上合并为我们最初的大文件，特此记录便于日后查阅。
目录
1、maven依赖
2、分片上传dto
3、OSS工具类
3、controller
4、前端js
1、maven依赖 &lt;!-- 阿里云OSS --&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun.oss&lt;/groupId&gt; &lt;artifactId&gt;aliyun-sdk-oss&lt;/artifactId&gt; &lt;version&gt;3.11.0&lt;/version&gt; &lt;/dependency&gt; 2、分片上传dto /** * @author Wxm */ @Data public class UploadChunkFileParam { /** * 文件传输任务ID * 文件MD5编码 */ private String identifier; /** * 文件全名称 例如：123.png */ private String filename; /** * 主体类型--这个字段是我项目中的其他业务逻辑可以忽略 */ private String objectType; /** * 分片总数 */ private int totalChunks; /** * 每个分块的大小 */ private long chunkSize; /** * 当前为第几分片 */ private int chunkNumber; /** * 当前分片大小 */ private long currentChunkSize; /** * 分块文件传输对象 */ private MultipartFile file; /** * oss上传时的上传id */ private String uploadId; /** * oss上传时的文件key */ private String key; } 3、OSS工具类 /** * @author wxm */ @Slf4j public class AliOSSManager { private static volatile OSSClient ossClient = null; private static volatile RedisManager redisManager = null; /** * 上传文件 * * @param file * @return */ public static String upload(MultipartFile file) { try { return putFile(getKey(FileUploadTypeEnum." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/f4086e558da718c36880544570991ec7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-09T15:01:51+08:00" />
<meta property="article:modified_time" content="2022-03-09T15:01:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">springboot&#43;阿里云OSS分片上传、断点续传、秒传</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>最近工作中有使用到OSS的分片上传API，整体流程就是前端将大文件进行分割，每个分片大小是1MB，分片个数是：(文件总大小 / 单个分片大小)，前端多线程处理上传分片到后端，后端接收到分片后调用OSS验证是否存在接口校验之前有没有传输过，如果分片在OSS上不存在则调用分片上传API进行上传，所有分片上传完成后调用OSS分片合并API，将所有分片在OSS上合并为我们最初的大文件，特此记录便于日后查阅。</p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="1%E3%80%81maven%E4%BE%9D%E8%B5%96-toc" style="margin-left:0px;"><a href="#1%E3%80%81maven%E4%BE%9D%E8%B5%96" rel="nofollow">1、maven依赖</a></p> 
<p id="2%E3%80%81OSS%E5%B7%A5%E5%85%B7%E7%B1%BB-toc" style="margin-left:0px;"><a href="#2%E3%80%81OSS%E5%B7%A5%E5%85%B7%E7%B1%BB" rel="nofollow">2、分片上传dto</a></p> 
<p id="3%E3%80%81OSS%E5%B7%A5%E5%85%B7%E7%B1%BB-toc" style="margin-left:0px;"><a href="#3%E3%80%81OSS%E5%B7%A5%E5%85%B7%E7%B1%BB" rel="nofollow">3、OSS工具类</a></p> 
<p id="3%E3%80%81controller-toc" style="margin-left:0px;"><a href="#3%E3%80%81controller" rel="nofollow">3、controller</a></p> 
<p id="4%E3%80%81%E5%89%8D%E7%AB%AFjs-toc" style="margin-left:0px;"><a href="#4%E3%80%81%E5%89%8D%E7%AB%AFjs" rel="nofollow">4、前端js</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p></p> 
<h2 id="1%E3%80%81maven%E4%BE%9D%E8%B5%96">1、maven依赖</h2> 
<pre><code class="language-XML">&lt;!-- 阿里云OSS --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.aliyun.oss&lt;/groupId&gt;
            &lt;artifactId&gt;aliyun-sdk-oss&lt;/artifactId&gt;
            &lt;version&gt;3.11.0&lt;/version&gt;
        &lt;/dependency&gt;</code></pre> 
<h2 id="2%E3%80%81OSS%E5%B7%A5%E5%85%B7%E7%B1%BB">2、分片上传dto</h2> 
<pre><code class="language-java">/**
 * @author Wxm
 */
@Data
public class UploadChunkFileParam {


    /**
     * 文件传输任务ID
     * 文件MD5编码
     */
    private String identifier;

    /**
     * 文件全名称 例如：123.png
     */
    private String filename;

    /**
     * 主体类型--这个字段是我项目中的其他业务逻辑可以忽略
     */
    private String objectType;
    /**
     * 分片总数
     */
    private int totalChunks;

    /**
     * 每个分块的大小
     */
    private long chunkSize;
    /**
     * 当前为第几分片
     */
    private int chunkNumber;
    /**
     * 当前分片大小
     */
    private long currentChunkSize;

    /**
     * 分块文件传输对象
     */
    private MultipartFile file;

    /**
     * oss上传时的上传id
     */
    private String uploadId;

    /**
     * oss上传时的文件key
     */
    private String key;

}
</code></pre> 
<h2 id="3%E3%80%81OSS%E5%B7%A5%E5%85%B7%E7%B1%BB">3、OSS工具类</h2> 
<pre><code class="language-java">/**
 * @author wxm
 */
@Slf4j
public class AliOSSManager {

    private static volatile OSSClient ossClient = null;

    private static volatile RedisManager redisManager = null;

    /**
     * 上传文件
     *
     * @param file
     * @return
     */
    public static String upload(MultipartFile file) {
        try {
            return putFile(getKey(FileUploadTypeEnum.DEF_TYPE.getType(), null, FileUtil.getSuffix(file)), file.getInputStream());
        } catch (Exception e) {
            e.printStackTrace();
            throw new ApiException("打开文件失败：" + e.getMessage());
        }
    }

    /**
     * 上传文件
     *
     * @param file
     * @param prefix
     * @return
     */
    public static String upload(MultipartFile file, String prefix) {
        try {
            return putFile(getKey(prefix, file.getName(), FileUtil.getSuffix(file)), file.getInputStream());
        } catch (Exception e) {
            e.printStackTrace();
            throw new ApiException("打开文件失败：" + e.getMessage());
        }
    }

    /**
     * 上传文件
     *
     * @param file
     * @param uploadType
     * @return
     */
    public static String upload(MultipartFile file, FileUploadTypeEnum uploadType) {
        try {
            return putFile(getKey(uploadType.getType(), file.getName(), FileUtil.getSuffix(file)), file.getInputStream());
        } catch (Exception e) {
            e.printStackTrace();
            throw new ApiException("打开文件失败：" + e.getMessage());
        }
    }

    /**
     * 分片上传
     *
     * @param param 上传参数
     * @return
     */
    public static Map uploadChunk(UploadChunkFileParam param) {
        if (ObjectUtil.isEmpty(param.getKey())) {
            String key = getKey(null, param.getIdentifier(), param.getFilename());
            param.setKey(key);
        }
        return uploadChunk(param.getUploadId(), param.getKey(), param.getFile(), param.getChunkNumber(),
                param.getCurrentChunkSize(), param.getTotalChunks());
    }

    /**
     * 分片上传
     * 1、检查文件是否上传
     * 2、检查文件是否第一次上传，第一次上传创建上传id uploadId
     * 3、检查是否是断点续传，如果是返回已上传的分片
     * 4、分片上传到阿里云OSS上，并记录上传信息到Redis
     * 5、判断是否已上传完成，已完成：合并所有分片为源文件
     *
     * @param uploadId   上传id
     * @param key        文件在OSS上的key
     * @param file       文件分片
     * @param chunkIndex 分片索引
     * @param chunkSize  分片大小
     * @param chunkCount 总分片数
     * @return
     */
    public static Map uploadChunk(String uploadId, String key, MultipartFile file, Integer chunkIndex,
                                  long chunkSize, Integer chunkCount) {
        if (ObjectUtil.isEmpty(key)) {
            key = getKey(FileUploadTypeEnum.DEF_TYPE.getType(), null, FileUtil.getSuffix(file));
        }
        ossClient = initOSS();
        try {
            Map&lt;String, Object&gt; map = MapUtil.newHashMap();
            // 判断是否上传
            if (checkExist(key)) {
                map.put("skipUpload", true);
                map.put("url", getUrl(key));
                return map;
            }
            // 判断是否第一次上传
            if (StringUtils.isBlank(uploadId)) {
                uploadId = uploadChunkInit(file, key);
                map.put("skipUpload", false);
                map.put("uploadId", uploadId);
                map.put("uploaded", null);
                return map;
            }
            RedisManager redisManager = initRedisManager();
            // 检查分片是否已上传 实现断点续传
            if (file == null) {
                Map&lt;String, String&gt; uploadedCache = redisManager.hmget(SysConstant.REDIS_ALI_OSS_KEY + uploadId);
                List&lt;Integer&gt; uploaded = Lists.newArrayList();
                for (Map.Entry&lt;String, String&gt; entry : uploadedCache.entrySet()) {
                    uploaded.add(JSONUtil.toBean(entry.getValue(), PartETag.class).getPartNumber());
                }
                map.put("skipUpload", false);
                map.put("uploadId", uploadId);
                map.put("uploaded", uploaded);
                return map;
            }
            // 上传分片
            PartETag partETag = uploadChunkPart(uploadId, key, file.getInputStream(), chunkIndex, chunkSize, chunkCount);
            // 分片上传完成缓存key
            redisManager.hset(SysConstant.REDIS_ALI_OSS_KEY + uploadId, chunkIndex + ",", JSONUtil.toJsonStr(partETag));
            // 取出所有已上传的分片信息
            Map&lt;String, String&gt; dataMap = redisManager.hmget(SysConstant.REDIS_ALI_OSS_KEY + uploadId);
            List&lt;PartETag&gt; partETagList = Lists.newArrayList();
            for (Map.Entry&lt;String, String&gt; entry : dataMap.entrySet()) {
                partETagList.add(JSONUtil.toBean(entry.getValue(), PartETag.class));
            }
            // 判断是否上传完成
            if (dataMap.keySet().size() == chunkCount) {
                uploadChunkComplete(uploadId, key, partETagList);
                for (String mapKey : dataMap.keySet()) {
                    redisManager.hdel(SysConstant.REDIS_ALI_OSS_KEY + uploadId, mapKey);
                }
                map.put("skipUpload", true);
                map.put("uploadId", uploadId);
                map.put("url", getUrl(key));
            } else {
                List&lt;Integer&gt; list = partETagList.stream().map(PartETag::getPartNumber).collect(Collectors.toList());
                map.put("uploaded", list);
                map.put("skipUpload", false);
                map.put("uploadId", uploadId);
            }
            return map;
        } catch (Exception e) {
            e.printStackTrace();
            throw new ApiException("上传失败：" + e.getMessage());
        }

    }

    /**
     * 初始化分片上传
     *
     * @param key
     * @return 分片上传的uploadId
     */
    public static String uploadChunkInit(MultipartFile file, String key) {
        if (ObjectUtil.isEmpty(key)) {
            key = getKey(FileUploadTypeEnum.DEF_TYPE.getType(), null, FileUtil.getSuffix(file));
        }
        return uploadChunkInit(key);
    }

    /**
     * 初始化上传id uploadId
     *
     * @param key
     * @return
     */
    public static String uploadChunkInit(String key) {
        if (ObjectUtil.isEmpty(key)) {
            throw new ApiException("key不能为空");
        }
        ossClient = initOSS();
        try {
            // 创建分片上传对象
            InitiateMultipartUploadRequest uploadRequest = new InitiateMultipartUploadRequest(AliOSSProperties.BUCKET_NAME, key);
            // 初始化分片
            InitiateMultipartUploadResult result = ossClient.initiateMultipartUpload(uploadRequest);
            // 返回uploadId，它是分片上传事件的唯一标识，您可以根据这个uploadId发起相关的操作，如取消分片上传、查询分片上传等。
            return result.getUploadId();
        } catch (Exception e) {
            e.printStackTrace();
            throw new ApiException("初始化分片失败：" + e.getMessage());
        }
    }

    /**
     * 上传分片文件
     *
     * @param uploadId   上传id
     * @param key        key
     * @param instream   文件分片流
     * @param chunkIndex 分片索引
     * @param chunkSize  分片大小
     * @return
     */
    public static PartETag uploadChunkPart(String uploadId, String key, InputStream instream,
                                           Integer chunkIndex, long chunkSize, Integer chunkCount) {
        ossClient = initOSS();
        try {
            UploadPartRequest partRequest = new UploadPartRequest();
            // 阿里云 oss 文件根目录
            partRequest.setBucketName(AliOSSProperties.BUCKET_NAME);
            // 文件key
            partRequest.setKey(key);
            // 分片上传uploadId
            partRequest.setUploadId(uploadId);
            // 分片文件
            partRequest.setInputStream(instream);
            // 分片大小。除了最后一个分片没有大小限制，其他的分片最小为100 KB。
            partRequest.setPartSize(chunkSize);
            System.out.println(chunkSize + "    " + chunkIndex + "   " + uploadId);
            // 分片号。每一个上传的分片都有一个分片号，取值范围是1~10000，如果超出这个范围，OSS将返回InvalidArgument的错误码。
            partRequest.setPartNumber(chunkIndex);
            // 每个分片不需要按顺序上传，甚至可以在不同客户端上传，OSS会按照分片号排序组成完整的文件。
            UploadPartResult uploadPartResult = ossClient.uploadPart(partRequest);
            // 每次上传分片之后，OSS的返回结果包含PartETag。PartETag将被保存在redis中。
            return uploadPartResult.getPartETag();
        } catch (Exception e) {
            e.printStackTrace();
            throw new ApiException("分片上传失败：" + e.getMessage());
        }
    }

    /**
     * 文件合并
     *
     * @param uploadId  上传id
     * @param key       key
     * @param chunkTags 分片上传信息
     * @return
     */
    public static CompleteMultipartUploadResult uploadChunkComplete(String uploadId, String key, List&lt;PartETag&gt; chunkTags) {
        ossClient = initOSS();
        try {
            CompleteMultipartUploadRequest completeMultipartUploadRequest =
                    new CompleteMultipartUploadRequest(AliOSSProperties.BUCKET_NAME, key, uploadId, chunkTags);
            CompleteMultipartUploadResult result = ossClient.completeMultipartUpload(completeMultipartUploadRequest);
            return result;
        } catch (Exception e) {
            e.printStackTrace();
            throw new ApiException("分片合并失败：" + e.getMessage());
        }
    }


    /**
     * 根据key生成文件的访问地址
     *
     * @param key
     * @return
     */
    public static String getUrl(String key) {
        // 拼接文件访问路径。由于拼接的字符串大多为String对象，而不是""的形式，所以直接用+拼接的方式没有优势
        StringBuffer url = new StringBuffer();
        url.append("http://")
                .append(AliOSSProperties.BUCKET_NAME)
                .append(".")
                .append(AliOSSProperties.END_POINT)
                .append("/").append(key);
        return url.toString();
    }

    /**
     * 根据key生成文件的访问地址（带过期时间）
     *
     * @param key
     * @return
     */
    public static String getUrlExpire(String key) {
        ossClient = initOSS();
        // 生成过期时间
        long expireEndTime = System.currentTimeMillis() + AliOSSProperties.URL_EXPIRE * 1000;
        Date expiration = new Date(expireEndTime);// 生成URL
        GeneratePresignedUrlRequest generatePresignedUrlRequest = new GeneratePresignedUrlRequest(AliOSSProperties.BUCKET_NAME, key);
        generatePresignedUrlRequest.setExpiration(expiration);
        URL url = ossClient.generatePresignedUrl(generatePresignedUrlRequest);
        return url.toString();
    }

    /**
     * 通过文件名获取文件流
     *
     * @param key 要下载的文件名（OSS服务器上的）
     */
    public static InputStream getInputStream(String key) {
        ossClient = initOSS();
        // 下载OSS文件到本地文件。如果指定的本地文件存在会覆盖，不存在则新建。
        return ossClient.getObject(new GetObjectRequest(AliOSSProperties.BUCKET_NAME, key)).getObjectContent();
    }

    /**
     * 根据key下载文件
     *
     * @param key
     */
    public static void download(String key) {
        ossClient = initOSS();
        GetObjectRequest request = new GetObjectRequest(AliOSSProperties.BUCKET_NAME, key);
        ossClient.getObject(request);
    }

    /**
     * 根据key下载文件
     *
     * @param key
     */
    public static void download(String key, String fileName) {
        ossClient = initOSS();
        GetObjectRequest request = new GetObjectRequest(AliOSSProperties.BUCKET_NAME, key);
        ossClient.getObject(request, new File(fileName));
    }

    /**
     * 删除
     *
     * @param key
     */
    public static void delete(String key) {
        if (StringUtils.isNotEmpty(key)) {
            ossClient = initOSS();
            GenericRequest request = new DeleteObjectsRequest(AliOSSProperties.BUCKET_NAME).withKey(key);
            ossClient.deleteBucket(request);
        }
    }

    /**
     * 删除
     *
     * @param keys
     */
    public static void delete(List&lt;String&gt; keys) {
        if (ObjectUtil.isNotEmpty(keys)) {
            ossClient = initOSS();
            GenericRequest request = new DeleteObjectsRequest(AliOSSProperties.BUCKET_NAME).withKeys(keys);
            ossClient.deleteBucket(request);
        }
    }

    /**
     * 上传文件&lt;&gt;基础方法&lt;/&gt;
     *
     * @param key         文件key
     * @param inputStream 输入流
     * @return
     */
    private static String putFile(String key, InputStream inputStream) {
        ossClient = initOSS();
        if (inputStream == null) {
            throw new CustomException("文件不能为空");
        }
        // 上传文件最大值 MB-&gt;bytes
        long maxSize = AliOSSProperties.MAX_SIZE * 1024 * 1024;
        long size = FileUtil.getInputStreamSize(inputStream);
        if (size &lt;= 0 || size &gt; maxSize) {
            throw new CustomException("请检查文件大小");
        }
        PutObjectResult result = null;
        try {
            // 创建上传Object的Metadata
            ObjectMetadata meta = new ObjectMetadata();
            //被下载时网页的缓存行为
            meta.setCacheControl("no-cache");
            PutObjectRequest request = new PutObjectRequest(AliOSSProperties.BUCKET_NAME, key, inputStream, meta);
            result = ossClient.putObject(request);
        } catch (Exception e) {
            e.printStackTrace();
            log.error(e.getMessage(), e);
        }
        if (result != null) {
            return getUrl(key);
        }
        return null;
    }


    public static Boolean checkExist(String key) {
        ossClient = initOSS();
        return ossClient.doesObjectExist(AliOSSProperties.BUCKET_NAME, key);
    }

    /**
     * 获取上传文件的key
     * 上传和删除时除了需要bucketName外还需要此值
     *
     * @param prefix   前缀（非必传），可以用于区分是哪个模块或子项目上传的文件,默认 file 文件夹
     * @param fileName 文件名称（非必传），如果为空默认生成文件名，格式：yyyyMMdd-UUID
     * @param suffix   后缀 , 可以是 png jpg
     * @return
     */
    private static String getKey(final String prefix, final String fileName, final String suffix) {
        StringBuffer keySb = new StringBuffer();
        // 前缀处理
        if (StringUtils.isNotEmpty(prefix)) {
            keySb.append(prefix);
        } else {
            keySb.append(FileUploadTypeEnum.DEF_TYPE.getType());
        }
        // 文件名处理
        if (StringUtils.isBlank(fileName)) {
            // 上传时间 因为后期可能会用 - 将key进行split，然后进行分类统计
            keySb.append(CommKit.Date2Str(LocalDateTime.now(), "yyyyMMdd"));
            keySb.append("-");
            // 生成uuid
            keySb.append(CommKit.genUUID());
        } else {
            keySb.append(fileName);
        }
        // 后缀处理
        if (StringUtils.isBlank(suffix)) {
            throw new NullPointerException("文件后缀不能为空");
        }
        if (suffix.contains(".")) {
            keySb.append(suffix.substring(suffix.lastIndexOf(".")));
        } else {
            keySb.append("." + suffix);
        }
        return keySb.toString();
    }

    private static OSSClient initOSS() {
        if (ossClient == null) {
            synchronized (OSSClient.class) {
                if (ossClient == null) {
                    ossClient = new OSSClient(AliOSSProperties.END_POINT,
                            new DefaultCredentialProvider(AliOSSProperties.ACCESS_KEY_ID, AliOSSProperties.ACCESS_KEY_SECRET),
                            new ClientConfiguration());
                }
            }
        }
        return ossClient;
    }

    private static RedisManager initRedisManager() {
        if (redisManager == null) {
            synchronized (RedisManager.class) {
                if (redisManager == null) {
                    return SpringUtils.getBean(RedisManager.class);
                }
            }
        }
        return redisManager;
    }
}
</code></pre> 
<h2 id="3%E3%80%81controller">3、controller</h2> 
<pre><code>/**
 * 通用请求处理
 *
 * @author wxm
 */
@RestController
@RequestMapping("/common/")
public class CommonController {
    
    /**
     * OSS普通上传
     *
     * @param file 文件
     */
    @PostMapping("/oss")
    public ApiResult uploadOSS(MultipartFile file) {
        String url = AliOSSManager.upload(file);
        if (url == null) {
            return ApiResult.fail("上传失败");
        }
        HashMap&lt;Object, Object&gt; map = MapUtil.newHashMap();
        map.put("url", url);
        return ApiResult.success(map);
    }


    /**
     * OSS分片上传
     *
     * @param param 文件上传对象
     * @return
     */
    @PostMapping("/oss/chunk/upload")
    public ApiResult uploadOSS(UploadChunkFileParam param) {
        Map&lt;String, Object&gt; map = AliOSSManager.uploadChunk(param);
        return ApiResult.success(map);
    }
}
</code></pre> 
<h2 id="4%E3%80%81%E5%89%8D%E7%AB%AFjs">4、前端js</h2> 
<pre><code class="language-javascript">import md5 from 'js-md5' //引入MD5加密
import UpApi from '@/api/common.js'
import axios from 'axios'
import { concurrentExecution } from '@/utils/jnxh'

/**
 * 文件分片上传
 * @params file {File} 文件
 * @params pieceSize {Number} 分片大小 默认3MB
 * @params concurrent {Number} 并发数量 默认2
 * @params process {Function} 进度回调函数
 * @params success {Function} 成功回调函数
 * @params error {Function} 失败回调函数
 */
export const uploadByPieces = ({
                                 file,
                                 pieceSize = 3,
                                 concurrent = 3,
                                 success,
                                 process,
                                 error
                               }) =&gt; {
  // 如果文件传入为空直接 return 返回
  if (!file || file.length &lt; 1) {
    return error('文件不能为空')
  }
  let fileMD5 = '' // 总文件列表
  const chunkSize = pieceSize * 1024 * 1024 // 1MB一片
  const chunkCount = Math.ceil(file.size / chunkSize) // 总片数
  const chunkList = [] // 分片列表
  let uploaded = [] // 已经上传的
  let fileType = '' // 文件类型
  let uploadId = '' // 上传id
  // 获取md5
  /***
   * 获取md5
   **/
  const readFileMD5 = () =&gt; {
    // 读取视频文件的md5
    fileType = file.name.substring(file.name.lastIndexOf('.') + 1, file.name.length)
    console.log('获取文件的MD5值')
    let fileRederInstance = new FileReader()
    console.log('file', file)
    fileRederInstance.readAsBinaryString(file)
    fileRederInstance.addEventListener('load', e =&gt; {
      let fileBolb = e.target.result
      fileMD5 = md5(fileBolb)
      let form = new FormData()
      form.append('filename', file.name)
      form.append('identifier', fileMD5)
      form.append('objectType', fileType)
      form.append('chunkNumber', 1)
      form.append('uploadId', uploadId)
      uploadChunks(form).then(res =&gt; {
        console.log(res, 'sdffffffs')
        if (res.data.skipUpload) {
          console.log('文件已被上传')
          success &amp;&amp; success(res)
        } else {
          uploadId = res.data.uploadId
          // 判断是否是断点续传
          if (res.data.uploaded &amp;&amp; res.data.uploaded.length != 0) {
            uploaded = [].concat(res.data.uploaded)
          }
          console.log('已上传的分片：' + uploaded)
          // 判断是并发上传或顺序上传
          if (concurrent == 1 || chunkCount == 1) {
            console.log('顺序上传')
            sequentialUplode(0)
          } else {
            console.log('并发上传')
            concurrentUpload()
          }
        }
      }).catch((e) =&gt; {
        console.log('文件合并错误')
        console.log(e)
      })
    })
  }
  /***
   * 获取每一个分片的详情
   **/
  const getChunkInfo = (file, currentChunk, chunkSize) =&gt; {
    let start = currentChunk * chunkSize
    let end = Math.min(file.size, start + chunkSize)
    let chunk = file.slice(start, end)
    return {
      start,
      end,
      chunk
    }
  }
  /***
   * 针对每个文件进行chunk处理
   **/
  const readChunkMD5 = () =&gt; {
    // 针对单个文件进行chunk上传
    for (var i = 0; i &lt; chunkCount; i++) {
      const {
        chunk
      } = getChunkInfo(file, i, chunkSize)

      // 判断已经上传的分片中是否包含当前分片
      if (uploaded.indexOf(i + '') == -1) {
        uploadChunk({
          chunk,
          currentChunk: i,
          chunkCount
        })
      }
    }
  }
  /***
   * 原始上传
   **/
  const uploadChunk = (chunkInfo) =&gt; {
    var sd = parseInt((chunkInfo.currentChunk / chunkInfo.chunkCount) * 100)
    console.log(sd, '进度')
    process(sd)
    console.log(chunkInfo, '分片大小')
    let inde = chunkInfo.currentChunk + 1
    if (uploaded.indexOf(inde + '') &gt; -1) {
      const {
        chunk
      } = getChunkInfo(file, chunkInfo.currentChunk + 1, chunkSize)
      uploadChunk({
        chunk,
        currentChunk: inde,
        chunkCount
      })
    } else {
      let uploadData = createUploadData(chunkInfo)
      // 执行分片上传
      let config = {
        headers: {
          'Content-Type': 'application/json',
          'Accept': '*/*'
        }
      }
      UpApi.uploadChunk(uploadData, config).then(res =&gt; {
        if (res.code == 200) {
          console.log('分片上传成功')
          uploaded.push(chunkInfo.currentChunk + 1)
          // 判断是否全部上传完
          if (uploaded.length == chunkInfo.chunkCount) {
            console.log('全部完成')
            success(res)
            process(100)
          } else {
            const {
              chunk
            } = getChunkInfo(file, chunkInfo.currentChunk + 1, chunkSize)
            uploadChunk({
              chunk,
              currentChunk: chunkInfo.currentChunk + 1,
              chunkCount
            })
          }

        } else {
          console.log(res.msg)
        }
      }).catch((e) =&gt; {
        error &amp;&amp; error(e)
      })
      // if (chunkInfo.currentChunk &lt; chunkInfo.chunkCount) {
      //   setTimeout(() =&gt; {
      //
      //   }, 1000)
      // }
    }
  }
  /***
   * 顺序上传
   **/
  const sequentialUplode = (currentChunk) =&gt; {
    const {
      chunk
    } = getChunkInfo(file, currentChunk, chunkSize)
    let chunkInfo = {
      chunk,
      currentChunk,
      chunkCount,
      uploadId
    }
    var sd = parseInt((chunkInfo.currentChunk / chunkInfo.chunkCount) * 100)
    process(sd)
    console.log('当前上传分片：' + currentChunk)
    let inde = chunkInfo.currentChunk + 1
    if (uploaded.indexOf(inde + '') &gt; -1) {
      console.log('分片【' + currentChunk + '】已上传')
      sequentialUplode(currentChunk + 1)
    } else {
      let uploadData = createUploadData(chunkInfo)
      let config = {
        headers: {
          'Content-Type': 'application/json',
          'Accept': '*/*'
        }
      }
      // 执行分片上传
      uploadChunks(uploadData, config).then(res =&gt; {
        console.log(res, 'sdfsdfsd')
        if (res.code == 200) {
          console.log('分片【' + currentChunk + '】上传成功')
          uploaded.push(chunkInfo.currentChunk + 1)
          // 判断是否全部上传完
          if (uploaded.length == chunkInfo.chunkCount) {
            console.log('全部完成')
            success(res)
            process(100)
          } else {
            sequentialUplode(currentChunk + 1)
          }

        } else {
          console.log(res.msg)
        }

      }).catch((e) =&gt; {
        error &amp;&amp; error(e)
      })
    }
  }
  /***
   * 并发上传
   **/
  const concurrentUpload = () =&gt; {
    for (var i = 0; i &lt; chunkCount; i++) {
      let index = Number(i) + 1
      if (uploaded.indexOf(index) === -1) {
        chunkList.push(Number(i))
      }
    }
    debugger
    console.log('需要上传的分片索引：' + chunkList)
    concurrentExecution(chunkList, concurrent, (curItem) =&gt; {
      return new Promise((resolve, reject) =&gt; {
        const {
          chunk
        } = getChunkInfo(file, curItem, chunkSize)
        let chunkInfo = {
          chunk,
          currentChunk: curItem,
          chunkCount
        }
        var sd = parseInt((chunkInfo.currentChunk / chunkInfo.chunkCount) * 100)
        process(sd)
        console.log('当前上传分片：' + curItem)
        let inde = chunkInfo.currentChunk + 1
        if (uploaded.indexOf(inde) == -1) {
          // 构建上传文件的formData
          let uploadData = createUploadData(chunkInfo)
          // 请求头
          let config = {
            headers: {
              'Content-Type': 'application/json',
              'Accept': '*/*'
            }
          }
          uploadChunks(uploadData, config).then(res =&gt; {
            if (res.code == 200) {
              uploaded.push(chunkInfo.currentChunk + 1)
              console.log('已经上传完成的分片：' + uploaded)
              // 判断是否全部上传完
              if (uploaded.length == chunkInfo.chunkCount) {
                success(res)
                process(100)
              }
              resolve()
            } else {
              reject(res)
              console.log(res.msg)
            }

          }).catch((e) =&gt; {
            console.log(e, 'erere')
            reject(e)
            error &amp;&amp; error(e)
          })
        } else {
          console.log('分片【' + chunkInfo.currentChunk + '】已上传')
          resolve()
        }
      })
    }).then(res =&gt; {
      console.log('finish', res)
    })
  }
  /***
   * 创建文件上传参数
   **/
  const createUploadData = (chunkInfo) =&gt; {
    let fetchForm = new FormData()
    fetchForm.append('identifier', fileMD5)
    fetchForm.append('chunkNumber', chunkInfo.currentChunk + 1)
    fetchForm.append('chunkSize', chunkSize)
    fetchForm.append('currentChunkSize', chunkInfo.chunk.size)
    const chunkfile = new File([chunkInfo.chunk], file.name)
    fetchForm.append('file', chunkfile)
    // fetchForm.append('file', chunkInfo.chunk)
    fetchForm.append('filename', file.name)
    fetchForm.append('relativePath', file.name)
    fetchForm.append('totalChunks', chunkInfo.chunkCount)
    fetchForm.append('totalSize', file.size)
    fetchForm.append('objectType', fileType)
    fetchForm.append('uploadId', uploadId)
    return fetchForm
  }

  const api = axios.create({
    baseURL: 'http://localhost:8902/',
    timeout: 100000
  })
  const uploadChunks = (data) =&gt; api({
    url: '/common/oss/chunk/upload',
    method: 'post',
    data: data
  }).then(res =&gt; {
    console.log(res, 'uploadChunks')
    return res.data
  })
  readFileMD5() // 开始执行代码
}</code></pre> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8cd067c1c336d64e46f51eb9532c087d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">npm报错Error: ENOENT: no such file or directory</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/910274bc7f65c5ee49a0e53cbc1004b6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python Numpy库教程(超详细)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>