<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop入门学习笔记——七、Hive语法 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Hadoop入门学习笔记——七、Hive语法" />
<meta property="og:description" content="视频课程地址：https://www.bilibili.com/video/BV1WY4y197g7
课程资料链接：https://pan.baidu.com/s/15KpnWeKpvExpKmOC8xjmtQ?pwd=5ay8
Hadoop入门学习笔记（汇总）
目录 七、Hive语法7.1. 数据库相关操作7.1.1. 创建数据库7.1.2. 选择数据库7.1.3. 描述数据库详细信息7.1.4. 创建数据库并指定其在HDFS系统中的存储位置7.1.5. 删除数据库7.1.6. 修改数据库存储位置7.1.7. 查询当前USE的数据库 7.2. 数据表操作7.2.1. Hive所支持的数据类型7.2.2. 创建数据表7.2.2.1. 基础建表语句7.2.2.2. 基于其他表的结构建表7.2.2.3. 基于查询结果建表7.2.2.4. 建表时指定Hive数据分隔符 7.2.3. 删除表7.2.4. 数据加载和导出7.2.4.1. 数据加载7.2.4.2. 数据导出 7.2.5. 分区表7.2.6. 分桶表7.2.6.1. 开启分桶的自动优化（自动匹配Reduce task数量和桶的数量一致）7.2.6.2. 创建分桶表7.2.6.3. 分桶表加载数据 7.2.7. 修改表7.2.7.1. 表重命名7.2.7.2. 修改表的属性7.2.7.3. 修改表的分区7.2.7.4. 修改表的列7.2.7.5. 删除表7.2.7.6. 清空表的数据 7.2.8. 复杂类型操作7.2.8.1. array（数组类型）7.2.8.2. map（Key-Value型）7.2.8.3. struct（复合类型）7.2.8.4. array、map、struct总结 7.3. 数据查询7.3.1. 基本查询7.3.2. RLIKE 正则匹配7.3.3. UNION联合7.3.4. Sampling采样7.3.5. Virtual Columns虚拟列 7.4. 函数7.4.1. 数字、集合、转换、日期函数7.4.2. 条件、字符串、脱敏、其它函数 七、Hive语法 7.1. 数据库相关操作 7.1.1. 创建数据库 CREATE DATABASE [IF NOT EXISTS] db_name [LOCATION &#39;path&#39;] [COMMENT database_comment]; IF NOT EXISTS，如存在同名数据库不执行任何操作，否则执行创建数据库操作[LOCATION]，自定义数据库存储位置，如不填写，默认数据库在HDFS的路径为：/user/hive/warehouse[COMMENT database_comment]，可选，数据库注释 例如：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/a7b201455f5ed0722fb2744d0c9c19c5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-25T23:29:07+08:00" />
<meta property="article:modified_time" content="2023-12-25T23:29:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop入门学习笔记——七、Hive语法</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>视频课程地址：<a href="https://www.bilibili.com/video/BV1WY4y197g7/" rel="nofollow">https://www.bilibili.com/video/BV1WY4y197g7</a><br> 课程资料链接：<a href="https://pan.baidu.com/s/15KpnWeKpvExpKmOC8xjmtQ?pwd=5ay8" rel="nofollow">https://pan.baidu.com/s/15KpnWeKpvExpKmOC8xjmtQ?pwd=5ay8</a></p> 
<p><a href="https://blog.csdn.net/faith306/article/details/134645258">Hadoop入门学习笔记（汇总）</a><br> </p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#Hive_6" rel="nofollow">七、Hive语法</a></li><li><ul><li><a href="#71__7" rel="nofollow">7.1. 数据库相关操作</a></li><li><ul><li><a href="#711__8" rel="nofollow">7.1.1. 创建数据库</a></li><li><a href="#712__23" rel="nofollow">7.1.2. 选择数据库</a></li><li><a href="#713__43" rel="nofollow">7.1.3. 描述数据库详细信息</a></li><li><a href="#714_HDFS_52" rel="nofollow">7.1.4. 创建数据库并指定其在HDFS系统中的存储位置</a></li><li><a href="#715__60" rel="nofollow">7.1.5. 删除数据库</a></li><li><a href="#716__80" rel="nofollow">7.1.6. 修改数据库存储位置</a></li><li><a href="#717_USE_87" rel="nofollow">7.1.7. 查询当前USE的数据库</a></li></ul> 
   </li><li><a href="#72__92" rel="nofollow">7.2. 数据表操作</a></li><li><ul><li><a href="#721_Hive_93" rel="nofollow">7.2.1. Hive所支持的数据类型</a></li><li><a href="#722__115" rel="nofollow">7.2.2. 创建数据表</a></li><li><ul><li><a href="#7221__116" rel="nofollow">7.2.2.1. 基础建表语句</a></li><li><a href="#7222__253" rel="nofollow">7.2.2.2. 基于其他表的结构建表</a></li><li><a href="#7223__259" rel="nofollow">7.2.2.3. 基于查询结果建表</a></li><li><a href="#7224_Hive_265" rel="nofollow">7.2.2.4. 建表时指定Hive数据分隔符</a></li></ul> 
    </li><li><a href="#723__276" rel="nofollow">7.2.3. 删除表</a></li><li><a href="#724__289" rel="nofollow">7.2.4. 数据加载和导出</a></li><li><ul><li><a href="#7241__290" rel="nofollow">7.2.4.1. 数据加载</a></li><li><a href="#7242__392" rel="nofollow">7.2.4.2. 数据导出</a></li></ul> 
    </li><li><a href="#725__470" rel="nofollow">7.2.5. 分区表</a></li><li><a href="#726__540" rel="nofollow">7.2.6. 分桶表</a></li><li><ul><li><a href="#7261_Reduce_task_545" rel="nofollow">7.2.6.1. 开启分桶的自动优化（自动匹配Reduce task数量和桶的数量一致）</a></li><li><a href="#7262__550" rel="nofollow">7.2.6.2. 创建分桶表</a></li><li><a href="#7263__558" rel="nofollow">7.2.6.3. 分桶表加载数据</a></li></ul> 
    </li><li><a href="#727__585" rel="nofollow">7.2.7. 修改表</a></li><li><ul><li><a href="#7271__586" rel="nofollow">7.2.7.1. 表重命名</a></li><li><a href="#7272__599" rel="nofollow">7.2.7.2. 修改表的属性</a></li><li><a href="#7273__616" rel="nofollow">7.2.7.3. 修改表的分区</a></li><li><a href="#7274__666" rel="nofollow">7.2.7.4. 修改表的列</a></li><li><a href="#7275__692" rel="nofollow">7.2.7.5. 删除表</a></li><li><a href="#7276__703" rel="nofollow">7.2.7.6. 清空表的数据</a></li></ul> 
    </li><li><a href="#728__724" rel="nofollow">7.2.8. 复杂类型操作</a></li><li><ul><li><a href="#7281_array_726" rel="nofollow">7.2.8.1. array（数组类型）</a></li><li><a href="#7282_mapKeyValue_766" rel="nofollow">7.2.8.2. map（Key-Value型）</a></li><li><a href="#7283_struct_833" rel="nofollow">7.2.8.3. struct（复合类型）</a></li><li><a href="#7284_arraymapstruct_869" rel="nofollow">7.2.8.4. array、map、struct总结</a></li></ul> 
   </li></ul> 
   </li><li><a href="#73__876" rel="nofollow">7.3. 数据查询</a></li><li><ul><li><a href="#731__931" rel="nofollow">7.3.1. 基本查询</a></li><li><a href="#732_RLIKE__990" rel="nofollow">7.3.2. RLIKE 正则匹配</a></li><li><a href="#733_UNION_1010" rel="nofollow">7.3.3. UNION联合</a></li><li><a href="#734_Sampling_1071" rel="nofollow">7.3.4. Sampling采样</a></li><li><a href="#735_Virtual_Columns_1130" rel="nofollow">7.3.5. Virtual Columns虚拟列</a></li></ul> 
   </li><li><a href="#74__1191" rel="nofollow">7.4. 函数</a></li><li><ul><li><a href="#741__1192" rel="nofollow">7.4.1. 数字、集合、转换、日期函数</a></li><li><a href="#742__1195" rel="nofollow">7.4.2. 条件、字符串、脱敏、其它函数</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="Hive_6"></a>七、Hive语法</h2> 
<h3><a id="71__7"></a>7.1. 数据库相关操作</h3> 
<h4><a id="711__8"></a>7.1.1. 创建数据库</h4> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token operator">NOT</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> db_name <span class="token punctuation">[</span>LOCATION <span class="token string">'path'</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> database_comment<span class="token punctuation">]</span><span class="token punctuation">;</span>
</code></pre> 
<ul><li><code>IF NOT EXISTS</code>，如存在同名数据库<code>不执行任何操作</code>，否则<code>执行创建数据库</code>操作</li><li><code>[LOCATION]</code>，自定义数据库存储位置，<code>如不填写</code>，默认数据库在HDFS的路径为：<code>/user/hive/warehouse</code></li><li><code>[COMMENT database_comment]</code>，可选，数据库注释</li></ul> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">database</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> myhive<span class="token punctuation">;</span>
</code></pre> 
<p>创建一个名字为myhive的数据库，如果该数据已存在，则不再执行创建动作。</p> 
<h4><a id="712__23"></a>7.1.2. 选择数据库</h4> 
<pre><code class="prism language-sql"><span class="token keyword">USE</span> db_name<span class="token punctuation">;</span>
</code></pre> 
<ul><li>选择数据库后，后续<code>SQL</code>操作基于当前选择的库执行</li><li>如不使用use，默认在<code>default</code>库执行</li></ul> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token keyword">use</span> myhive<span class="token punctuation">;</span>
</code></pre> 
<p>使用myhive数据库；</p> 
<p><strong>若想切换回使用default库</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">USE</span> <span class="token keyword">DEFAULT</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="713__43"></a>7.1.3. 描述数据库详细信息</h4> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> <span class="token keyword">database</span> myhive<span class="token punctuation">;</span>
</code></pre> 
<p>可以看到数据库名称、数据库存放路径、所属用户等信息。<br> <img src="https://images2.imgbox.com/62/81/ktzioPk7_o.png" alt="在这里插入图片描述"><br> 可以使用HDFS命令<code>hadoop fs -ls /user/hive/warehouse</code>查看对应的文件；<br> <img src="https://images2.imgbox.com/f2/14/MJaLOeMa_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="714_HDFS_52"></a>7.1.4. 创建数据库并指定其在HDFS系统中的存储位置</h4> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">database</span> myhive2 location <span class="token string">'/user/hive/myhive2'</span><span class="token punctuation">;</span>
</code></pre> 
<p>此时可以再次使用<code>desc database myhive2</code>查看myhive2数据库的详细信息，可以看到myhive2数据库的存放路径是按照指定的位置存放的。<br> <img src="https://images2.imgbox.com/bc/e3/MGdIKq19_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/13/9e/LPPJxArk_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="715__60"></a>7.1.5. 删除数据库</h4> 
<pre><code class="prism language-sql"><span class="token keyword">DROP</span> <span class="token keyword">DATABASE</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> db_name <span class="token punctuation">[</span><span class="token keyword">CASCADE</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
</code></pre> 
<ul><li><code>[IF EXISTS]</code>，可选，如果存在此数据库执行删除，不存在不执行任何操作</li><li><code>[CASCADE]</code>，可选，级联删除，即数据库内存在表，使用CASCADE可以强制删除数据库</li></ul> 
<p>例如：<br> 删除一个空的数据库（无数据、无表）</p> 
<pre><code class="prism language-sql"><span class="token keyword">drop</span>  <span class="token keyword">database</span>  myhive<span class="token punctuation">;</span>
</code></pre> 
<p>删除一个非空数据库（有表或有数据）/ 强制删除数据库</p> 
<pre><code class="prism language-sql"><span class="token keyword">drop</span> <span class="token keyword">database</span> myhive2 <span class="token keyword">cascade</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="716__80"></a>7.1.6. 修改数据库存储位置</h4> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">DATABASE</span> db_name <span class="token keyword">SET</span> LOCATION hdfs_path<span class="token punctuation">;</span>
</code></pre> 
<p><mark>不会在HDFS对数据库所在目录进行改名，只是修改location后，新创建的表在新的路径，旧的不变</mark></p> 
<h4><a id="717_USE_87"></a>7.1.7. 查询当前USE的数据库</h4> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> current_database<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="72__92"></a>7.2. 数据表操作</h3> 
<h4><a id="721_Hive_93"></a>7.2.1. Hive所支持的数据类型</h4> 
<table><thead><tr><th><strong>分类</strong></th><th><strong>类型</strong></th><th><strong>描述</strong></th><th><strong>字面量示例</strong></th></tr></thead><tbody><tr><td>原始类型</td><td>BOOLEAN</td><td>true/false</td><td>TRUE</td></tr><tr><td></td><td>TINYINT</td><td>1字节的有符号整数 -128~127</td><td>1Y</td></tr><tr><td></td><td>SMALLINT</td><td>2个字节的有符号整数，-32768~32767</td><td>1S</td></tr><tr><td></td><td><mark>INT</mark></td><td>4个字节的带符号整数</td><td>1</td></tr><tr><td></td><td>BIGINT</td><td>8字节带符号整数</td><td>1L</td></tr><tr><td></td><td>FLOAT</td><td>4字节单精度浮点数1.0</td><td></td></tr><tr><td></td><td><mark>DOUBLE</mark></td><td>8字节双精度浮点数</td><td>1.0</td></tr><tr><td></td><td>DEICIMAL</td><td>任意精度的带符号小数</td><td>1.0</td></tr><tr><td></td><td><mark>STRING</mark></td><td>字符串，变长</td><td>“a”,’b’</td></tr><tr><td></td><td><mark>VARCHAR</mark></td><td>变长字符串</td><td>“a”,’b’</td></tr><tr><td></td><td>CHAR</td><td>固定长度字符串</td><td>“a”,’b’</td></tr><tr><td></td><td>BINARY</td><td>字节数组</td><td></td></tr><tr><td></td><td><mark>TIMESTAMP</mark></td><td>时间戳，毫秒值精度</td><td>122327493795</td></tr><tr><td></td><td><mark>DATE</mark></td><td>日期</td><td>‘2016-03-29’</td></tr><tr><td></td><td></td><td>时间频率间隔</td><td></td></tr><tr><td>复杂类型</td><td>ARRAY</td><td>有序的的同类型的集合</td><td>array(1,2)</td></tr><tr><td></td><td>MAP</td><td>key-value,key必须为原始类型，value可以任意类型</td><td>map(‘a’,1,’b’,2)</td></tr><tr><td></td><td>STRUCT</td><td>字段集合,类型可以不同</td><td>struct(‘1’,1,1.0), named_stract(‘col1’,’1’,’col2’,1,’clo3’,1.0)</td></tr><tr><td></td><td>UNION</td><td>在有限取值范围内的一个值</td><td>create_union(1,’a’,63)</td></tr></tbody></table> 
<h4><a id="722__115"></a>7.2.2. 创建数据表</h4> 
<h5><a id="7221__116"></a>7.2.2.1. 基础建表语句</h5> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token punctuation">[</span>EXTERNAL<span class="token punctuation">]</span> <span class="token keyword">TABLE</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token operator">NOT</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> tb_name
	<span class="token punctuation">(</span>col_name col_type <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> col_comment<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
	<span class="token punctuation">[</span><span class="token keyword">COMMENT</span> tb_comment<span class="token punctuation">]</span>
	<span class="token punctuation">[</span>PARTITIONED <span class="token keyword">BY</span><span class="token punctuation">(</span>col_name col_type<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
	<span class="token punctuation">[</span><span class="token keyword">CLUSTERED</span> <span class="token keyword">BY</span><span class="token punctuation">(</span>col_name<span class="token punctuation">,</span> col_name<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
	<span class="token punctuation">[</span>SORTED <span class="token keyword">BY</span><span class="token punctuation">(</span>col_name <span class="token punctuation">[</span><span class="token keyword">ASC</span><span class="token operator">|</span><span class="token keyword">DESC</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">INTO</span> num_buckets BUCKETS<span class="token punctuation">]</span>
	<span class="token punctuation">[</span><span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">''</span><span class="token punctuation">]</span>
	<span class="token punctuation">[</span>STORED <span class="token keyword">AS</span> SEQUENCEFILE<span class="token operator">|</span>TEXTFILE<span class="token operator">|</span>RCFILE<span class="token punctuation">]</span>
	<span class="token punctuation">[</span>LOCATION <span class="token string">'path'</span><span class="token punctuation">]</span>
</code></pre> 
<ul><li>[IF NOT EXISTS]，若tb_name不存在则创建；</li><li>[COMMENT tb_comment]，表注释；</li><li>[EXTERNAL]，创建外部表，需与下列属性搭配： 
  <ul><li>[ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘’]，指定数据的分隔符；</li><li>[LOCATION ‘path’]，表在HDFS系统中的存放路径；</li></ul> </li><li>[PARTITIONED BY(col_name col_type, …)]，基于列进行分区存储，col_name为表中没有的列名，col_type为列的类型，支持依据多个列分区，这里的列不与表中的原始的数据列相同；</li><li>[CLUSTERED BY(col_name, col_name, …) INTO num_buckets BUCKETS]，基于列分桶，col_name为表中已有的列，num_buckets为分桶个数；</li><li>[STORED AS SEQUENCEFILE|TEXTFILE|RCFILE]，存储格式，如果文件数据是纯文本可以用TEXTFILE，如果数据需要压缩可以用SEQUENCEFILE；</li><li>[LOCATION ‘path’]，存储位置；</li></ul> 
<p><strong>1、内部表和外部表的区别</strong></p> 
<ul><li> <p>内部表（CREATE TABLE table_name …）<br> 未被external关键字修饰的即是内部表， 即普通表。内部表又称<mark>管理表</mark>,内部表数据存储的位置由hive.metastore.warehouse.dir参数决定（默认：/user/hive/warehouse），删除内部表会直接<mark>删除元数据（metadata）及存储数据</mark>，即在MySQL的Hive数据库的TBLS表中的数据和在HDFS系统中的文件都会被删除，因此内部表不适合和其他工具共享数据。</p> </li><li> <p>外部表（CREATE EXTERNAL TABLE table_name …LOCATION…）<br> 被external关键字修饰的即是外部表， 即关联表。外部表的数据可以放在任何位置，通过LOCATION关键字指定。数据存储的不同也代表了这个表在理念是并不是Hive内部管理的，而是可以随意临时链接到外部数据上的。在删除外部表的时候， <mark>仅删除元数据（表的信息），不会删除数据本身</mark>，即仅删除MySQL的Hive数据库的TBLS表中的数据，但HDFS系统中的文件不会被删除。</p> </li></ul> 
<table><thead><tr><th align="center">表类型</th><th align="center">创建</th><th align="center">存储位置</th><th align="left">删除数据</th><th align="left">理念</th></tr></thead><tbody><tr><td align="center">内部表</td><td align="center">CREATE TABLE …</td><td align="center">Hive管理，默认/user/hive/warehouse</td><td align="left">- 删除 元数据（表信息）<br> - 删除 数据</td><td align="left">Hiv管理表<br>持久使用</td></tr><tr><td align="center">外部表</td><td align="center">CREATE EXTERNAL TABLE … LOCATION …</td><td align="center">随意，LOCATION关键字指定</td><td align="left">- 进删除 元数据（表信息）<br>- 保留 数据</td><td align="left">临时链接外部数据用</td></tr></tbody></table> 
<p><strong>2、使用内部表</strong><br> 使用以下语句建库、建表、插入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">database</span> myhive<span class="token punctuation">;</span>
<span class="token keyword">use</span> myhive<span class="token punctuation">;</span>
<span class="token keyword">CREATE</span> <span class="token keyword">table</span> stu<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> stu <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'周杰轮'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'林君姐'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>插入之后，由于是内部表，可以在HDFS系统中的/user/hive/warehouse/myhive.db/stu文件下看到对应的数据表存储文件<br> <img src="https://images2.imgbox.com/94/73/oZ3BiRfG_o.png" alt="在这里插入图片描述"><br> 此时，使用<code>hadoop fs -cat</code>命令打开这个文件，查看其里面的内容，即是刚才插入的数据<br> <img src="https://images2.imgbox.com/6c/39/Z25EF9nb_o.png" alt="在这里插入图片描述"><br> 其他一些创建内部表的方式：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 基于其它表的结构建表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> tbl_name <span class="token operator">LIKE</span> other_tbl<span class="token punctuation">;</span>
<span class="token comment">-- 基于查询结果建表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> tbl_name <span class="token keyword">AS</span> <span class="token keyword">SELECT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>3、使用外部表，关联已有数据</strong><br> <strong>3.1、第一种情况：先有表，后有数据</strong><br> 先在Linux系统中创建一个test_external.txt文件，内容如下（使用\t做为分隔符）：</p> 
<blockquote> 
 <p>1 itheima<br> 2 itcast<br> 3 hadoop</p> 
</blockquote> 
<p>在创建外部表之前，需要确保外部表所指定的存储位置的目录不存在，在本例中，需要确保HDFS系统中<code>/tmp/test_ext1</code>目录不存在；<br> <img src="https://images2.imgbox.com/66/22/bwo6JEf5_o.png" alt="在这里插入图片描述"></p> 
<p>然后创建外部表：</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> external <span class="token keyword">table</span> test_ext1<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span> LOCATION <span class="token string">'/tmp/test_ext1'</span><span class="token punctuation">;</span>
</code></pre> 
<p>创建一个外部表，表名为test_ext1，由2个字段id和name构成，该表的数据分隔符为\t，在HDFS系统中的存储位置为<code>/tmp/test_ext1</code>文件夹；<br> <img src="https://images2.imgbox.com/ec/56/TWyOWuuc_o.png" alt="在这里插入图片描述"><br> 当前因为没有任何数据，所以该文件夹里面没有任何内容，这时，我们通过<code>hadoop fs -put</code>或<code>hdfs dfs -put</code>命令将前面在Linux中创建的test_external.txt文件上传到/tmp/test_ext1目录下；</p> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-put</span> test_external.txt /tmp/test_ext1/
</code></pre> 
<p>上传完成后，在Hive中执行<code>SELECT * FROM test_ext1;</code>语句，便可以看到刚才上传的文件中的数据了；<br> <img src="https://images2.imgbox.com/b9/55/VsIREdyl_o.png" alt="在这里插入图片描述"><br> <strong>3.2、第二种情况：先有数据，后有表</strong><br> 先在HDFS中创建一个test_ext2目录</p> 
<pre><code class="prism language-bash">hadoop fs <span class="token parameter variable">-mkdir</span> /tmp/test_ext2
</code></pre> 
<p>将数据文件上传到test_ext2目录下</p> 
<pre><code class="prism language-bash">hadoop fs <span class="token parameter variable">-put</span> test_external.txt /tmp/test_ext2
</code></pre> 
<p>然后创建同名（test_ext2）的外部表，并将其存储位置设置为/tmp/test_ext2</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> external <span class="token keyword">table</span> test_ext2<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span> LOCATION <span class="token string">'/tmp/test_ext2'</span><span class="token punctuation">;</span>
</code></pre> 
<p>然后使用<code>SELECT * FROM test_ext2;</code>语句查询数据，发现数据可以被Hive读取到。<br> <img src="https://images2.imgbox.com/73/5e/XPTxGlcX_o.png" alt="在这里插入图片描述"><br> <strong>3.3、删除外部表</strong><br> 在删除表之前，查看元数据库（MySQL的Hive库）中的TBLS表的数据和HDFS文件系统对应位置的文件夹；<br> <img src="https://images2.imgbox.com/c2/a0/66Z4gzjm_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/89/27/scUIZREh_o.png" alt="在这里插入图片描述"><br> 然后执行删表语句<code>drop table test_ext1;</code>，执行成功后，再次查看元数据库（MySQL的Hive库）中的TBLS表的数据和HDFS文件系统对应位置的文件夹；<br> <img src="https://images2.imgbox.com/56/ea/iiVSAtFv_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e7/b1/lOgEvZaV_o.png" alt="在这里插入图片描述"></p> 
<p>发现，元数据库中的表信息已被删除，但是HDFS系统中的数据文件仍然存在，未受影响。<mark>所以，删除外部表，完全不影响数据本身。</mark></p> 
<p><strong>4、内外部表转换</strong><br> 创建一个内部表，创建一个外部表</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 创建内部表t1</span>
<span class="token keyword">CREATE</span> <span class="token keyword">table</span> t1<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 创建外部表t2</span>
<span class="token keyword">CREATE</span> external <span class="token keyword">table</span> t2<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span> LOCATION <span class="token string">'/tmp/t2'</span><span class="token punctuation">;</span>
</code></pre> 
<p>使用<code>desc formatted t1;</code>语句查看t1表信息，可以看到，该表存储的位置在/user/hive/warehouse文件夹下，且其表类型为MANAGED_TABLE（即管理表，内部表）;<br> <img src="https://images2.imgbox.com/53/0f/p8Pao30N_o.png" alt="在这里插入图片描述"><br> 使用<code>desc formatted t2;</code>语句查看t2表信息，可以看到，该表存储的位置在/tmp/t2文件夹下，且其表类型为EXTERNAL_TABLE（即外部表）;<br> <img src="https://images2.imgbox.com/ac/60/4tSrBGMq_o.png" alt="在这里插入图片描述"><br> <strong>4.1、内部表转换成外部表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">table</span> t1 <span class="token keyword">set</span> TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">'EXTERNAL'</span><span class="token operator">=</span><span class="token string">'TRUE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>将t1表从内部表转换成外部表。</p> 
<p><strong>4.2、外部表转换成内部表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">table</span> t2 <span class="token keyword">set</span> TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">'EXTERNAL'</span><span class="token operator">=</span><span class="token string">'FALSE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>将t2表从外部表转换成内部表，<mark>注意括号里的EXTERNAL和TRUE、FALSE必须大写</mark>。</p> 
<h5><a id="7222__253"></a>7.2.2.2. 基于其他表的结构建表</h5> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> tbl_name <span class="token operator">LIKE</span> other_tbl<span class="token punctuation">;</span>
</code></pre> 
<h5><a id="7223__259"></a>7.2.2.3. 基于查询结果建表</h5> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> tbl_name <span class="token keyword">AS</span> <span class="token keyword">SELECT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>
</code></pre> 
<h5><a id="7224_Hive_265"></a>7.2.2.4. 建表时指定Hive数据分隔符</h5> 
<p>在HDFS系统中，通过<code>hadoop fs -cat</code>或<code>hdfs dfs -cat</code>命令查看Hive数据文件的内容时，在命令行里是看不到数据列的分隔符，这是因为，默认的分隔符是“\001”，是一个不可见的ASCII码，键盘打不出来，在有些文本编辑器中，其会显示为SOH，如下所示：<br> <img src="https://images2.imgbox.com/51/52/XEgnPIc7_o.png" alt="在这里插入图片描述"><br> 如果我们将Hive数据表文件下载到Linux服务器，然后使用<code>vim</code>工具打开查看，其会显示为^A，如下图所示：<br> <img src="https://images2.imgbox.com/fa/46/G9HKEYxE_o.png" alt="在这里插入图片描述"><br> 当然，数据分隔符也是可以指定的，在创建表的时候，通过<code>row format delimited fields terminated by</code>可以指定，如将分隔符设置为一个制表符，则建表时可以如下写：</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> stu2<span class="token punctuation">(</span>id <span class="token keyword">int</span> <span class="token punctuation">,</span>name string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="723__276"></a>7.2.3. 删除表</h4> 
<pre><code class="prism language-sql"><span class="token keyword">DROP</span> <span class="token keyword">TABLE</span> tbl<span class="token punctuation">;</span>
</code></pre> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token keyword">DROP</span> <span class="token keyword">table</span> test<span class="token punctuation">;</span>
<span class="token keyword">DROP</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>test<span class="token punctuation">;</span>
</code></pre> 
<p>删除test表。</p> 
<h4><a id="724__289"></a>7.2.4. 数据加载和导出</h4> 
<h5><a id="7241__290"></a>7.2.4.1. 数据加载</h5> 
<p><strong>1、LOAD语法（从文件向表导入数据）</strong><br> 在Hive客户端中执行以下语句：</p> 
<pre><code class="prism language-sql"><span class="token keyword">LOAD</span> <span class="token keyword">DATA</span> <span class="token punctuation">[</span><span class="token keyword">LOCAL</span><span class="token punctuation">]</span> INPATH <span class="token string">'path'</span> <span class="token punctuation">[</span>OVERWRITE<span class="token punctuation">]</span> <span class="token keyword">INTO</span> <span class="token keyword">TABLE</span> tb_name <span class="token punctuation">[</span><span class="token keyword">PARTITION</span><span class="token punctuation">(</span>partition_key<span class="token operator">=</span><span class="token string">'partition_value'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
</code></pre> 
<p>[LOCAL]，表示要加载的数据文件是否在Linux文件系统中，若在Linux文件系统则需要写上LOCAL，若在HDFS系统则不需要写LOCAL；<br> ‘path’，表示要加载的文件路径；<br> [OVERWRITE]，表示是否要覆盖表中已有的数据（即表中原有的数据都删除，只保留本次导入的数据）；<br> tb_name，为将数据加载进入的表名。</p> 
<p><strong>用法：</strong><br> 先创建一个内部表；</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>test_load<span class="token punctuation">(</span>
	dt string <span class="token keyword">comment</span> <span class="token string">'时间'</span><span class="token punctuation">,</span>
	user_id string <span class="token keyword">comment</span> <span class="token string">'用户id'</span><span class="token punctuation">,</span>
	search_word string <span class="token keyword">comment</span> <span class="token string">'搜索关键词'</span><span class="token punctuation">,</span>
	url string <span class="token keyword">comment</span> <span class="token string">'网址'</span>
<span class="token punctuation">)</span> <span class="token keyword">comment</span> <span class="token string">'搜索引擎日志表'</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
</code></pre> 
<p><strong>1.1、从Linux系统加载数据到Hive表中</strong><br> 将课程资料中的search_log.txt文件上传到node1服务器的/home/hadoop目录下；<br> 直接从Linux系统中加载数据到test_load表；</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/search_log.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> test_load<span class="token punctuation">;</span>
</code></pre> 
<p>此时，数据就已经加载到了test_load表（加载速度很快）；<br> <img src="https://images2.imgbox.com/16/1c/JDxZF5M6_o.png" alt="在这里插入图片描述"><br> <strong>1.2、从HDFS系统中加载数据到Hive表</strong><br> 将前面的search_log.txt文件上传到HDFS系统/tmp目录下；</p> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-put</span> search_log.txt /tmp/
</code></pre> 
<p>将HDFS文件系统中的search_log.txt文件加载到test_load表；</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'/tmp/search_log.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> test_load<span class="token punctuation">;</span>
</code></pre> 
<p>此时，数据已导入test_load表中；<br> <img src="https://images2.imgbox.com/cf/6b/AIBJpLHr_o.png" alt="在这里插入图片描述"><br> 可以看到，数据已经变成了2份，第一份是前面从Linux本地导入的，第二份是从HDFS文件系统导入的；<br> 此时，再次查看HDFS系统的/tmp目录，会发现之前上传的search_log.txt文件已经没有了，其实这个导入操作<mark>本质上是移动HDFS文件到Hive库表所在的目录</mark>。<br> <img src="https://images2.imgbox.com/5d/56/viWI3CQY_o.png" alt="在这里插入图片描述"><br> <strong>1.3、演示overwirte属性</strong><br> 再次执行从Linux本地加载数据，但本次带上overwrite属性</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/search_log.txt'</span> overwrite <span class="token keyword">into</span> <span class="token keyword">table</span> test_load<span class="token punctuation">;</span>
</code></pre> 
<p>执行完成后，再次查看test_load表的内容，会发现只剩了文件中的内容，而不像之前一样追加，这里是覆盖的写，该表中原有的数据全部被清空，只保留了本次导入的数据。<br> <img src="https://images2.imgbox.com/0a/23/4Fqt6gF9_o.png" alt="在这里插入图片描述"><br> <strong>2、INSERT SELECT语法（从其他表向表导入数据）</strong><br> 在Hive客户端中执行以下语句：</p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> <span class="token punctuation">[</span>OVERWRITE <span class="token operator">|</span> <span class="token keyword">INTO</span><span class="token punctuation">]</span> <span class="token keyword">TABLE</span> tb_name1 <span class="token punctuation">[</span><span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>partcol1<span class="token operator">=</span>val1<span class="token punctuation">,</span> partcol2<span class="token operator">=</span>val2 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token operator">NOT</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">SELECT</span> select_statement1 <span class="token keyword">FROM</span> from_statement<span class="token punctuation">;</span>
</code></pre> 
<p>将SELECT查询语句的结果插入到其它表中，被SELECT查询的表可以是内部表或外部表。<br> [OVERWRITE | INTO]，表示覆盖或追加数据，覆盖时用OVERWRITE，追加时用INTO；<br> tb_name1，表示数据导入目标表的表名；</p> 
<p><strong>用法：</strong><br> 先创建一个内部表；</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>test_load2<span class="token punctuation">(</span>
	dt string <span class="token keyword">comment</span> <span class="token string">'时间'</span><span class="token punctuation">,</span>
	user_id string <span class="token keyword">comment</span> <span class="token string">'用户id'</span><span class="token punctuation">,</span>
	search_word string <span class="token keyword">comment</span> <span class="token string">'搜索关键词'</span><span class="token punctuation">,</span>
	url string <span class="token keyword">comment</span> <span class="token string">'网址'</span>
<span class="token punctuation">)</span> <span class="token keyword">comment</span> <span class="token string">'搜索引擎日志表2'</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>将test_load表中的数据导入test_load2</p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> <span class="token keyword">table</span> test_load2 <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> test_load<span class="token punctuation">;</span>
</code></pre> 
<p>执行上述语句，会发现又被转换成MapReduce任务执行，所以在大规模数据下与LOAD DATA没有区别，但是在小规模数据下，使用LOAD DATA会更快一些。<br> 此时，test_load2表中已经有了数据。<br> <img src="https://images2.imgbox.com/54/de/POFMCV9D_o.png" alt="在这里插入图片描述"><br> 如果再次执行上面的SQL，会发现test_load2表里面的数据会被追加一份。<br> <img src="https://images2.imgbox.com/cf/11/B2sh7HYW_o.png" alt="在这里插入图片描述"><br> 如果将上面的SQL语句修改为：</p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> OVERWRITE <span class="token keyword">table</span> test_load2 <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> test_load<span class="token punctuation">;</span>
</code></pre> 
<p>执行完成后，查看数据，会发现之前的数据被覆盖了，只保留了本次SQL执行的结果。<br> <img src="https://images2.imgbox.com/27/27/MFl2etie_o.png" alt="在这里插入图片描述"><br> <strong>3、数据导入方式的选择</strong></p> 
<ul><li>数据在Linux本地 
  <ul><li>推荐使用load data local方式加载；</li></ul> </li><li>数据在HDFS系统 
  <ul><li>如果不需要保留源文件：推荐使用load data方式加载；</li><li>如果需要保留源文件：推荐使用外部表先关联数据，然后通过insert select方式加载；</li></ul> </li><li>数据已经在Hive表中 
  <ul><li>只能使用insert select方式加载。</li></ul> </li></ul> 
<h5><a id="7242__392"></a>7.2.4.2. 数据导出</h5> 
<p><strong>1、INSERT OVERWRITE方式</strong><br> 在Hive客户端中执行以下语句：</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token punctuation">[</span><span class="token keyword">local</span><span class="token punctuation">]</span> directory <span class="token string">'path'</span> <span class="token punctuation">[</span><span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">''</span><span class="token punctuation">]</span> <span class="token keyword">select</span> select_statement1 <span class="token keyword">FROM</span> from_statement<span class="token punctuation">;</span>
</code></pre> 
<p>将select语句的结果写入指定的文件中。<br> [local]，表示是否导出到Linux系统本地，若是，则带上该参数，若不是，则不用写；<br> ‘path’，表示Linux本地或HDFS系统中的路径，若前面有local，这里写的就是Linux系统路径，若没有local，这里写的就是HDFS文件系统路径，这里的path是一个文件夹；<br> [row format delimited fields terminated by ‘’]，表示指定导出数据时所使用的数据分隔符（与表所使用的数据分隔符无关），默认分隔符为ASCII码\001，不可见。</p> 
<p><strong>用法：</strong></p> 
<p><strong>1.1、导出数据到本地：</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/home/hadoop/export1'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> test_load<span class="token punctuation">;</span>
</code></pre> 
<p>将test_load表中的数据导出到Linux系统的/home/hadoop/export1文件夹中。<br> 执行时发现，该语句需要被转换成MapReduce任务执行；<br> 执行完成后，可以在/home/hadoop目录下看到export1文件夹；<br> <img src="https://images2.imgbox.com/c6/e8/oPJow0sw_o.png" alt="在这里插入图片描述"><br> 进入该文件夹，并查看其内文件的内容<br> <img src="https://images2.imgbox.com/df/d5/jJ8e5qTR_o.png" alt="在这里插入图片描述"><br> 上图可以看到导出的数据，但是由于导出时未指定数据分隔符，所以使用的是默认分隔符，是不可见内容；<br> 将上述导出语句中增加指定分隔符的参数：</p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/home/hadoop/export2'</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> test_load<span class="token punctuation">;</span>
</code></pre> 
<p>此时查看Linux本地的/home/hadoop/export2目录及其内容如下，可以看到导出的数据已通过\t进行了分割：<br> <img src="https://images2.imgbox.com/fc/8b/t3RKOLVM_o.png" alt="在这里插入图片描述"><br> <strong>1.2、导出数据到HDFS系统中</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> overwrite directory <span class="token string">'/tmp/export_to_hdfs1'</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> test_load<span class="token punctuation">;</span>
</code></pre> 
<p>执行完成后，查看HDFS文件/tmp目录下的内容<br> <img src="https://images2.imgbox.com/b2/ee/CqYP9TQ6_o.png" alt="在这里插入图片描述"><br> <strong>2、hive shell方式</strong><br> 在Linux的命令行下执行：</p> 
<pre><code class="prism language-bash">./hive <span class="token parameter variable">-e</span> <span class="token string">"select ... from ...;"</span> <span class="token operator">&gt;</span> <span class="token string">'local_path'</span>
<span class="token comment"># 或</span>
./hive <span class="token parameter variable">-f</span> <span class="token string">'sql_file_path'</span> <span class="token operator">&gt;</span> <span class="token string">'local_path'</span>
</code></pre> 
<p>“select … from …;”，表示要执行的SQL语句；<br> ‘local_path’，表示要导出的Linux文件路径；<br> ‘sql_file_path’，表示要执行的SQL脚本文件在Linux中的路径；</p> 
<p><strong>用法：</strong></p> 
<p><strong>2.1、通过SQL语句导出数据</strong></p> 
<pre><code class="prism language-bash"><span class="token comment"># 切换目录</span>
<span class="token builtin class-name">cd</span> /export/server/hive/bin
<span class="token comment"># 将Hive中的myhive库的test_load表的内容导出到Linux系统/home/hadoop/下的export3.txt文件中</span>
./hive <span class="token parameter variable">-e</span> <span class="token string">"select * from myhive.test_load;"</span> <span class="token operator">&gt;</span> /home/hadoop/export3.txt
<span class="token comment"># 查看/home/hadoop/export3.txt的</span>
<span class="token function">cat</span> /home/hadoop/export3.txt
</code></pre> 
<p><img src="https://images2.imgbox.com/63/eb/aFEcxTT2_o.png" alt="在这里插入图片描述"><br> <strong>2.2、通过SQL文件导出数据</strong><br> 在Linux系统/home/hadoop目录下创建一个<code>export.sql</code>文件，写入如下内容：</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> myhive<span class="token punctuation">.</span>test_load<span class="token punctuation">;</span>
</code></pre> 
<p>然后在Linux的命令行中执行如下命令：</p> 
<pre><code class="prism language-bash"><span class="token comment"># 使用hive -f命令，执行export.sql文件中的SQL语句，将其执行结果导出到当前目录下的export4.txt文件中</span>
/export/server/hive/bin/hive <span class="token parameter variable">-f</span> export.sql <span class="token operator">&gt;</span> export4.txt
<span class="token comment"># 查看export4.txt文件内容</span>
<span class="token function">cat</span> export4.txt
</code></pre> 
<p><img src="https://images2.imgbox.com/12/46/7cdM38VW_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="725__470"></a>7.2.5. 分区表</h4> 
<p>在大数据中，最常用的一种思想就是分治，我们可以把大的文件切割划分成一个个的小的文件，这样每次操作一个小的文件就会很容易了。<br> 在hive当中也是支持这种思想的，就是我们可以把大的数据，按照一定的规则（如每天、每小时等）切分成一个个小的文件。<br> 每一个分区，都是一个文件夹。同时，Hive也支持多个字段作为分区，多分区带有层级关系。<br> <img src="https://images2.imgbox.com/c2/f2/QNT7AX9t_o.png" alt="在这里插入图片描述"><br> <strong>1、创建一个按月进行单分区（按month分区）的学生成绩表，并指定数据分隔符为\t</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>score<span class="token punctuation">(</span>
	id STRING <span class="token keyword">COMMENT</span> <span class="token string">'学生ID'</span><span class="token punctuation">,</span>
	cid STRING <span class="token keyword">COMMENT</span> <span class="token string">'课程ID'</span><span class="token punctuation">,</span>
	score <span class="token keyword">int</span> <span class="token keyword">COMMENT</span> <span class="token string">'课程分数'</span>
<span class="token punctuation">)</span> <span class="token keyword">COMMENT</span> <span class="token string">'学生成绩表'</span>
partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span><span class="token keyword">month</span> STRING<span class="token punctuation">)</span>
<span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>将课程资料中score.txt文件加载到上表中，并指定分区的月份为202005；</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/score.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>score <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'202005'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>上面创建的表，相当于有4个列，前3个列从数据文件中获取，最后一个列是当数据插入时进行指定；<br> <img src="https://images2.imgbox.com/2c/fa/9S88t8OI_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/score.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>score <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'202006'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>再加载一次数据，本次指定month为 202006。<br> 然后查看HDFS系统中score表所对应目录的情况；<br> <img src="https://images2.imgbox.com/ae/29/E1pfW4Kw_o.png" alt="在这里插入图片描述"><br> 对Linux本地的score.txt文件修改一些内容，然后再次加载数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/score.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>score <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'202007'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/0d/66/bV925zJX_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d3/f0/AQ2N5R2x_o.png" alt="在这里插入图片描述"><br> <strong>2、创建一个按年、月、日，三个层次的多分区学生成绩表，并指定数据分隔符为\t</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>score2<span class="token punctuation">(</span>
	id STRING <span class="token keyword">COMMENT</span> <span class="token string">'学生ID'</span><span class="token punctuation">,</span>
	cid STRING <span class="token keyword">COMMENT</span> <span class="token string">'课程ID'</span><span class="token punctuation">,</span>
	score <span class="token keyword">int</span> <span class="token keyword">COMMENT</span> <span class="token string">'课程分数'</span>
<span class="token punctuation">)</span> <span class="token keyword">COMMENT</span> <span class="token string">'学生成绩表2'</span>
partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span><span class="token keyword">year</span> STRING<span class="token punctuation">,</span> <span class="token keyword">month</span> STRING<span class="token punctuation">,</span> <span class="token keyword">day</span> STRING<span class="token punctuation">)</span>
<span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>这个表实际有6个字段，其中前3个是数据列，后3个是在数据插入时指定的分区列<br> <img src="https://images2.imgbox.com/c5/60/25NpIbc7_o.png" alt="在这里插入图片描述"><br> 将Linux系统中score.txt的数据加载到上面的多分区表中</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/score.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>score2 <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">year</span><span class="token operator">=</span><span class="token string">"2022"</span><span class="token punctuation">,</span> <span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'01'</span><span class="token punctuation">,</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">"10"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>此时，score2表中的数据为，可以看到id,cid和score的数据来自score.txt文件的内容，而year,month,day三个字段的数据来自导入语句指定；<br> <img src="https://images2.imgbox.com/60/10/MX4wcT84_o.png" alt="在这里插入图片描述"><br> 然后再查看HDFS系统中的目录结构<br> <img src="https://images2.imgbox.com/7d/34/d136nrGK_o.png" alt="在这里插入图片描述"><br> 再导入几次数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/score.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>score2 <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">year</span><span class="token operator">=</span><span class="token string">"2022"</span><span class="token punctuation">,</span> <span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'01'</span><span class="token punctuation">,</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">"11"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/score.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>score2 <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">year</span><span class="token operator">=</span><span class="token string">"2023"</span><span class="token punctuation">,</span> <span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'01'</span><span class="token punctuation">,</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">"11"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/score.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>score2 <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">year</span><span class="token operator">=</span><span class="token string">"2022"</span><span class="token punctuation">,</span> <span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'02'</span><span class="token punctuation">,</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">"11"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>此时，再次查看HDFS系统中score2目录下的目录结构<br> <img src="https://images2.imgbox.com/44/9b/aHebqEdU_o.png" alt="在这里插入图片描述"><br> <strong>3、分区表在创建时指定的分区字段，在插入数据时必须都要传入，否则Hive会报错。</strong><br> <strong>4、分区表查询时，如果以分区列做为where条件，会极大的提高查询效率，因为只需要读取对应文件夹下的数据即可。</strong></p> 
<h4><a id="726__540"></a>7.2.6. 分桶表</h4> 
<p>分桶和分区一样，也是一种通过改变表的存储模式，从而完成对表优化的一种调优方式<br> 但和分区不同，分区是将表拆分到不同的子文件夹中进行存储，而分桶是将表拆分到固定数量的不同文件中进行存储。<br> <img src="https://images2.imgbox.com/2a/cc/6gaXodhH_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="7261_Reduce_task_545"></a>7.2.6.1. 开启分桶的自动优化（自动匹配Reduce task数量和桶的数量一致）</h5> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>enforce<span class="token punctuation">.</span>bucketing <span class="token operator">=</span> <span class="token boolean">TRUE</span><span class="token punctuation">;</span>
</code></pre> 
<h5><a id="7262__550"></a>7.2.6.2. 创建分桶表</h5> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>course<span class="token punctuation">(</span>c_id string<span class="token punctuation">,</span> c_name string<span class="token punctuation">,</span> t_id string<span class="token punctuation">)</span> <span class="token keyword">clustered</span> <span class="token keyword">by</span> <span class="token punctuation">(</span>c_id<span class="token punctuation">)</span>
<span class="token keyword">INTO</span> <span class="token number">3</span> buckets <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>创建一个course表，根据表中的c_id字段分三个桶；</p> 
<h5><a id="7263__558"></a>7.2.6.3. 分桶表加载数据</h5> 
<p>由于桶表的数据加载通过load data无法执行，只能通过insert select方式加载。<br> 1、创建一个临时表（外部表或内部表均可），通过load data把数据加载到临时表；</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 创建临时中转表(需要注意，中转表的分隔符需要与分桶表保持一致)</span>
<span class="token keyword">CREATE</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>course_temp<span class="token punctuation">(</span>c_id string<span class="token punctuation">,</span> c_name string<span class="token punctuation">,</span> t_id string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token comment">-- 将数据加载到中转表</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/course.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>course_temp<span class="token punctuation">;</span>
</code></pre> 
<p>2、从临时表通过insert select方式将数据加载到分桶表；</p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> overwrite <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>course <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> myhive<span class="token punctuation">.</span>course_temp cluster <span class="token keyword">by</span><span class="token punctuation">(</span>c_id<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这里需要注意，在向分桶表插入数据时，需要使用<code>cluster by</code>标明分桶依赖字段。<mark>注意，这里是cluster，而不是建表时缩写的clustered！</mark><br> 此时，我们可以查看HDFS系统中的文件情况<code>hadoop fs -ls /user/hive/warehouse/myhive.db/course</code>。<br> <img src="https://images2.imgbox.com/da/3f/5OBZPLS2_o.png" alt="在这里插入图片描述"><br> 会发现，course表的数据被放在了三个文件中，这里是因为最开始创建分桶表时，指定的分桶数量为3，如果指定其他数量的分桶数，那就会生成对应的文件个数。</p> 
<p>3、为什么不可以用load data，必须用insert select插入数据<br> 如果没有分桶设置，插入（加载）数据只是简单的将数据放入到：</p> 
<ul><li>表的数据存储文件夹中（没有分区）；</li><li>表指定分区的文件夹中（带有分区）。</li></ul> 
<p>一旦有了分桶设置，比如分桶数量为3，那么，表内文件或分区内数据文件的数量就限定为3。当数据插入的时候，需要一分为3，进入三个桶文件内。<br> 数据的三份划分<mark>基于分桶列的值进行hash取模</mark>来决定，<mark>由于load data不会触发MapReduce，也就是没有计算过程（无法执行Hash算法）</mark>，只是简单的移动数据而已，所以无法用于分桶表数据插入。</p> 
<h4><a id="727__585"></a>7.2.7. 修改表</h4> 
<h5><a id="7271__586"></a>7.2.7.1. 表重命名</h5> 
<p>语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span>  <span class="token keyword">table</span>  old_table_name  <span class="token keyword">rename</span>  <span class="token keyword">to</span>  new_table_name<span class="token punctuation">;</span>
</code></pre> 
<p>old_table_name，当前的表名；<br> new_table_name，新的表名。<br> 例如：</p> 
<pre><code class="prism language-sql"><span class="token comment">--将表score2重命名成score3</span>
<span class="token keyword">ALTER</span> <span class="token keyword">table</span> score2 <span class="token keyword">rename</span> <span class="token keyword">to</span> score3<span class="token punctuation">;</span>
</code></pre> 
<h5><a id="7272__599"></a>7.2.7.2. 修改表的属性</h5> 
<p>语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">SET</span> TBLPROPERTIES table_properties<span class="token punctuation">;</span>
table_properties:
  : <span class="token punctuation">(</span>property_name <span class="token operator">=</span> property_value<span class="token punctuation">,</span> property_name <span class="token operator">=</span> property_value<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">)</span>
</code></pre> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 将score3修改为外部表</span>
<span class="token keyword">ALTER</span> <span class="token keyword">table</span> score3 <span class="token keyword">set</span> TBLPROPERTIES<span class="token punctuation">(</span><span class="token string">"EXTERNAL"</span><span class="token operator">=</span><span class="token string">"TRUE"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 将score3表的注释修改为this is table comment</span>
<span class="token keyword">ALTER</span> <span class="token keyword">table</span> score3 <span class="token keyword">set</span> TBLPROPERTIES<span class="token punctuation">(</span><span class="token string">"comment"</span><span class="token operator">=</span><span class="token string">"this is table comment"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>其余属性可参见：<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-listTableProperties" rel="nofollow">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-listTableProperties</a></p> 
<h5><a id="7273__616"></a>7.2.7.3. 修改表的分区</h5> 
<p>1、添加分区<br> 语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> tablename  <span class="token keyword">ADD</span> <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span><span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'201101'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 给score3表添加一个year为2019，month为10，day为01的分区</span>
<span class="token keyword">ALTER</span> <span class="token keyword">table</span> score3 <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">year</span><span class="token operator">=</span><span class="token string">'2019'</span><span class="token punctuation">,</span> <span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'10'</span><span class="token punctuation">,</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'01'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>分区添加完成之后，因为新分区内还没有数据，所以在Hive中是看不到的，但是可以在HDFS中看到对应的目录；<br> <img src="https://images2.imgbox.com/1d/ee/lOAcPlsM_o.png" alt="在这里插入图片描述"><br> 可以通过手动添加数据文件或者加载数据的方式导入数据；<br> 例如，将另一个分区的数据文件复制一份过来<code>hadoop fs -cp /user/hive/warehouse/myhive.db/score3/year=2022/month=01/day=10/score.txt /user/hive/warehouse/myhive.db/score3/year=2019/month=10/day=01/</code>，这时，在DBeaver中就可以看到新分区中出现了数据<br> <img src="https://images2.imgbox.com/fa/04/oGteqjzL_o.png" alt="在这里插入图片描述"></p> 
<p>2、修改分区值（一般不要修改）<br> 语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> tablename <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span><span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'202005'</span><span class="token punctuation">)</span> <span class="token keyword">RENAME</span> <span class="token keyword">TO</span> <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span><span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'201105'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 将score3表year为2019,month为10,day为01的分区修改为year为2019,month为10,day为07</span>
<span class="token keyword">ALTER</span> <span class="token keyword">table</span> score3 <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">year</span><span class="token operator">=</span><span class="token string">'2019'</span><span class="token punctuation">,</span> <span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'10'</span><span class="token punctuation">,</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'01'</span><span class="token punctuation">)</span> <span class="token keyword">rename</span> <span class="token keyword">to</span> <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">year</span><span class="token operator">=</span><span class="token string">'2019'</span><span class="token punctuation">,</span> <span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'10'</span><span class="token punctuation">,</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'07'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>这时可以查看DBeaver中的数据，发现数据已经被修改了；<br> <img src="https://images2.imgbox.com/65/49/DqaaRexK_o.png" alt="在这里插入图片描述"><br> 同时，查看HDFS系统中的目录结构，发现文件目录并没有修改。这时因为，<mark>修改分区值本质上是修改元数据，而HDFS系统中的文件夹不会被重命名</mark>（默认元数据中的分区值和HDFS系统中的文件夹名字是一样的，但是也可以不同）。<br> <img src="https://images2.imgbox.com/38/37/6IUwSRHb_o.png" alt="在这里插入图片描述"><br> 此时，可以连接元数据库（node1服务器上的MySQL数据库），进入hive库，查看PARTITIONS表的内容，会发现分区名字已经变为了year=2019/month=10/day=07，其SD_ID为14，其TBL_ID为5，对应的字典为score3（表名）；<br> <img src="https://images2.imgbox.com/c3/6b/iJtKXbAC_o.png" alt="在这里插入图片描述"><br> 然后再查看SDS表中的数据，会发现SD_ID为14的数据，其对应的LOCATION的值为hdfs://node1:8020/user/hive/warehouse/myhive.db/score3/year=2019/month=10/day=01，通过这两个表实现了分区和HDFS系统中文件夹的对应，同时，也可以看到分区值已经变更了，但是HDFS中的物理存储路径没有变化。<br> <img src="https://images2.imgbox.com/3a/43/k9odRZXq_o.png" alt="在这里插入图片描述"><br> 当然，也可以先手动修改HDFS系统中对应路径的文件夹名，然后再来SDS表中修改LOCATION的值到新的路径，就可以实现分区值和HDFS路径一样了。</p> 
<p>3、删除分区<br> 语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> tablename <span class="token keyword">DROP</span> <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span><span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'201105'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 删除score3表中year为2019,month为10,day为07的分区</span>
<span class="token keyword">ALTER</span> <span class="token keyword">table</span> score3 <span class="token keyword">drop</span> <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">year</span><span class="token operator">=</span><span class="token string">'2019'</span><span class="token punctuation">,</span> <span class="token keyword">month</span><span class="token operator">=</span><span class="token string">'10'</span><span class="token punctuation">,</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'07'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>删除分区后，Hive表中对应分区的数据也会被删除，但是HDFS系统中的相关文件夹和数据文件不会被删除。<br> 这时因为<mark>删除分区只是删除了元数据，数据本身还在</mark>。</p> 
<h5><a id="7274__666"></a>7.2.7.4. 修改表的列</h5> 
<p>1、添加列<br> 语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">ADD</span> <span class="token keyword">COLUMNS</span> <span class="token punctuation">(</span>col_name col_type<span class="token punctuation">,</span> col_name col_type<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 给score3增加v1，v2两列，分别是int型和string型</span>
<span class="token keyword">ALTER</span> <span class="token keyword">table</span> score3 <span class="token keyword">add</span> <span class="token keyword">columns</span> <span class="token punctuation">(</span>v1 <span class="token keyword">int</span><span class="token punctuation">,</span> v2 string<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>可以看到执行后score3表增加了两个列<br> <img src="https://images2.imgbox.com/4a/45/iWZ9chwL_o.png" alt="在这里插入图片描述"></p> 
<p>2、修改列名<br> 语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name CHANGE old_col_name new_col_name old_col_type<span class="token punctuation">;</span>
</code></pre> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 将score3表中的v1列改为v1new列，int型（尽量不要修改类型，有可能会报错）</span>
<span class="token keyword">ALTER</span> <span class="token keyword">table</span> score3 change v1 v1new <span class="token keyword">int</span><span class="token punctuation">;</span>
</code></pre> 
<p>此时，查看score3表的结构，发现v1列已经改名为v1new列。<br> <img src="https://images2.imgbox.com/22/58/rDYYY7kG_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="7275__692"></a>7.2.7.5. 删除表</h5> 
<p>语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">DROP</span> <span class="token keyword">TABLE</span> tablename<span class="token punctuation">;</span>
</code></pre> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 删除myhive库下的score3表</span>
<span class="token keyword">DROP</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>score3<span class="token punctuation">;</span>
</code></pre> 
<h5><a id="7276__703"></a>7.2.7.6. 清空表的数据</h5> 
<p>语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">TRUNCATE</span> <span class="token keyword">TABLE</span> tablename<span class="token punctuation">;</span>
</code></pre> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 清空course表内的数据</span>
<span class="token keyword">TRUNCATE</span> <span class="token keyword">table</span> course<span class="token punctuation">;</span>
</code></pre> 
<p>尝试清空外部表：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 将test_load2表改成外部表</span>
<span class="token keyword">ALTER</span> <span class="token keyword">table</span> test_load2 <span class="token keyword">set</span> TBLPROPERTIES<span class="token punctuation">(</span><span class="token string">"EXTERNAL"</span><span class="token operator">=</span><span class="token string">"TRUE"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 清空test_load2表内的数据</span>
<span class="token keyword">TRUNCATE</span> <span class="token keyword">table</span> test_load2<span class="token punctuation">;</span>
</code></pre> 
<p>此时，会发现系统会报错。所以外部表无法被Hive清空。</p> 
<blockquote> 
 <p>SQL 错误 [10146] [42000]: Error while compiling statement: FAILED: SemanticException [Error 10146]: Cannot truncate non-managed table test_load2.</p> 
</blockquote> 
<h4><a id="728__724"></a>7.2.8. 复杂类型操作</h4> 
<p>Hive支持的数据类型很多，除了基本的：int、string、varchar、timestamp等，还有一些复杂的数据类型，如：array（数组类型）、map（映射类型）、struct（结构类型）等。</p> 
<h5><a id="7281_array_726"></a>7.2.8.1. array（数组类型）</h5> 
<p>Hive中的array类型与Java中的List非常相似，在定义Hive表结构是指定字段为array类型，同时，还需指定array内的元素的类型。</p> 
<p><strong>创建数据表：</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>test_array<span class="token punctuation">(</span>name string<span class="token punctuation">,</span> work_locations array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
COLLECTION ITEMS <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">','</span><span class="token punctuation">;</span>
</code></pre> 
<p>array&lt;string&gt;，表示work_locations字段的类型为array数组类型，数据内的元素为string型；<br> row format delimited fields terminated by ‘\t’， 表示数据分隔符是制表符\t；<br> COLLECTION ITEMS TERMINATED BY ‘,’， 表示集合（array）内元素的分隔符是英文逗号（,）；</p> 
<p><strong>加载数据：</strong><br> 将课程资料中的data_for_array_type.txt放到Linux系统/home/hadoop目录下，然后执行以下SQL：</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/data_for_array_type.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> test_array<span class="token punctuation">;</span>
</code></pre> 
<p>加载完成后，可以在Hive表中看到对应的数据<br> <img src="https://images2.imgbox.com/71/95/E79ygXo0_o.png" alt="在这里插入图片描述"><br> <strong>查询数据：</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 查询所有数据</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">from</span> test_array<span class="token punctuation">;</span>
<span class="token comment">-- 查询每个人工作的第一个城市</span>
<span class="token keyword">SELECT</span> name<span class="token punctuation">,</span> work_locations<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">from</span> test_array<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/f6/5d/cBpoak1y_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 查询array类型中的元素个数</span>
<span class="token keyword">SELECT</span> name<span class="token punctuation">,</span> SIZE<span class="token punctuation">(</span>work_locations<span class="token punctuation">)</span> <span class="token keyword">from</span> test_array<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/d2/6e/rXmqXXUQ_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 找出在tianjin工作过的人</span>
 <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> test_array <span class="token keyword">WHERE</span> ARRAY_CONTAINS<span class="token punctuation">(</span>work_locations<span class="token punctuation">,</span> <span class="token string">'tianjin'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/f7/fe/5YXKBho0_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="7282_mapKeyValue_766"></a>7.2.8.2. map（Key-Value型）</h5> 
<p>map类型其实就是简单的指代：Key-Value型数据格式。 有如下数据文件，其中members字段是key-value型数据。字段与字段分隔符: “,”；需要map字段之间的分隔符：“#”；map内部k-v分隔符：“:”。</p> 
<blockquote> 
 <p>id,name,members,age<br> 1,zhangsan,father:xiaoming#mother:xiaohuang#brother:xiaoxu,28<br> 2,lisi,father:mayun#mother:huangyi#brother:guanyu,22<br> 3,wangwu,father:wangjianlin#mother:ruhua#sister:jingtian,29<br> 4,mayun,father:mayongzhen#mother:angelababy,26</p> 
</blockquote> 
<p><strong>创建数据表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>test_map<span class="token punctuation">(</span>
	id <span class="token keyword">int</span><span class="token punctuation">,</span>
	name string<span class="token punctuation">,</span>
	members map<span class="token operator">&lt;</span>string<span class="token punctuation">,</span> string<span class="token operator">&gt;</span><span class="token punctuation">,</span>
	age <span class="token keyword">int</span>
<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
COLLECTION ITEMS <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'#'</span>
MAP <span class="token keyword">KEYS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">':'</span><span class="token punctuation">;</span>
</code></pre> 
<p>map&lt;string, string&gt;，指定members字段的类型为键为string型，值为string型的键值对；<br> row format delimited fields terminated by ‘,’，指定数据列之间的分隔符为英文逗号（,）；<br> COLLECTION ITEMS TERMINATED BY ‘#’，指定每个键值对之间的分隔符为#号；<br> MAP KEYS TERMINATED BY ‘:’，指定MAP键和值之间的分隔符为英文冒号（:）。</p> 
<p><strong>加载数据</strong><br> 将课程资料中的data_for_map_type.txt放到Linux系统/home/hadoop目录下，然后执行以下SQL：</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/data_for_map_type.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> test_map<span class="token punctuation">;</span>
</code></pre> 
<p>加载前，可以通过<code>cat data_for_map_type.txt</code>命令查看文件内容如下：<br> <img src="https://images2.imgbox.com/e3/bf/OcDMEVP1_o.png" alt="在这里插入图片描述"><br> 加载完成后，打开test_map表查看数据：<br> <img src="https://images2.imgbox.com/d1/07/tSgtqGJ6_o.png" alt="在这里插入图片描述"><br> <strong>数据查询</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 查看每行数据members字段中的father和monther元素</span>
<span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> members<span class="token punctuation">[</span><span class="token string">'father'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> members<span class="token punctuation">[</span><span class="token string">'mother'</span><span class="token punctuation">]</span> <span class="token keyword">FROM</span> myhive<span class="token punctuation">.</span>test_map<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/89/6d/T7C3g7d5_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 取出map的全部key，map_keys函数返回的类型是array</span>
<span class="token keyword">SELECT</span> map_keys<span class="token punctuation">(</span>members<span class="token punctuation">)</span> <span class="token keyword">from</span> myhive<span class="token punctuation">.</span>test_map<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/88/ca/79kXBOmA_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 取出map的全部value，map_values函数返回的类型是array</span>
<span class="token keyword">SELECT</span> map_values<span class="token punctuation">(</span>members<span class="token punctuation">)</span> <span class="token keyword">from</span> myhive<span class="token punctuation">.</span>test_map<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/f8/37/llwTvK2q_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 查看map的个数，size函数</span>
<span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> members<span class="token punctuation">,</span> SIZE<span class="token punctuation">(</span>members<span class="token punctuation">)</span><span class="token punctuation">,</span> age <span class="token keyword">from</span> myhive<span class="token punctuation">.</span>test_map<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/29/ff/5mOU6tDx_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 查看指定的数据是否包含在map中，array_contains函数，查看谁有sister这个key</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">from</span> myhive<span class="token punctuation">.</span>test_map <span class="token keyword">WHERE</span> ARRAY_CONTAINS<span class="token punctuation">(</span>map_keys<span class="token punctuation">(</span>members<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"sister"</span><span class="token punctuation">)</span> <span class="token punctuation">;</span>
<span class="token comment">-- 查看指定的数据是否包含在map中，array_contains函数，查看谁有“王林”这个value</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">from</span> myhive<span class="token punctuation">.</span>test_map <span class="token keyword">WHERE</span> ARRAY_CONTAINS<span class="token punctuation">(</span>map_values<span class="token punctuation">(</span>members<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"王林"</span><span class="token punctuation">)</span> <span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/f5/be/kQOucRVt_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/66/af/bJ1GJiQY_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="7283_struct_833"></a>7.2.8.3. struct（复合类型）</h5> 
<p>struct类型是一个复合类型，可以在一个列中存入多个子列，每个子列允许设置类型和名称。有如下数据文件，字段之间#分割，struct之间冒号分割。</p> 
<blockquote> 
 <p>1#周杰轮:11<br> 2#林均杰:16<br> 3#刘德滑:21<br> 4#张学油:26<br> 5#蔡依临:23</p> 
</blockquote> 
<p><strong>创建数据表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">table</span> myhive<span class="token punctuation">.</span>test_struct<span class="token punctuation">(</span>
	id string<span class="token punctuation">,</span>
	info struct<span class="token operator">&lt;</span>name:string<span class="token punctuation">,</span> age:<span class="token keyword">int</span><span class="token operator">&gt;</span>
<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'#'</span>
COLLECTION ITEMS <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">':'</span><span class="token punctuation">;</span>
</code></pre> 
<p>info struct&lt;name:string, age:int&gt;，指定info列为stuct型，其内部又分为两个子列，分别是name（string型）和age（int型）；<br> row format delimited fields terminated by ‘#’，指定表的每一列的数据分隔符为#号；<br> COLLECTION ITEMS TERMINATED BY ‘:’，指定struct型内，每个子列的数据分隔符为英文冒号（:）。</p> 
<p><strong>加载数据</strong><br> 将课程资料中的data_for_struct_type.txt放到Linux系统/home/hadoop目录下，然后执行以下SQL：</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/data_for_struct_type.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> test_struct<span class="token punctuation">;</span>
</code></pre> 
<p>加载前，可以通过<code>vim data_for_map_type.txt</code>命令查看文件内容如下：<br> <img src="https://images2.imgbox.com/ee/55/WCEmhOAG_o.png" alt="在这里插入图片描述"><br> 加载完成后，打开test_struct表查看数据：<br> <img src="https://images2.imgbox.com/01/dd/Vs0hQ2nd_o.png" alt="在这里插入图片描述"><br> <strong>数据查询</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 查询id和对应info中的name的值</span>
<span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> info<span class="token punctuation">.</span>name <span class="token keyword">from</span> myhive<span class="token punctuation">.</span>test_struct<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/78/42/uGlSPyff_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="7284_arraymapstruct_869"></a>7.2.8.4. array、map、struct总结</h5> 
<table><thead><tr><th>类型</th><th>定义</th><th align="left">示例</th><th align="left">内含元素类型</th><th align="left">元素个数</th><th align="left">取元素</th><th align="left">可用函数</th></tr></thead><tbody><tr><td>array</td><td>array&lt;类型&gt;</td><td align="left">如定义为：array&lt;int&gt;<br>数据为：1,2,3,4,5</td><td align="left">单值，类型取决于定义</td><td align="left">动态，不限制</td><td align="left">array[下标索引]<br>索引从0开始</td><td align="left">size()统计元素个数<br>array_contains()判断是否包含指定数据</td></tr><tr><td>map</td><td>map&lt;key类型, value类型&gt;</td><td align="left">如定义为：map&lt;string, int&gt;<br>数据为：{‘a’:1, ‘b’:2, ‘c’:3}</td><td align="left">键值对，K-V，K和V类型取决于定义</td><td align="left">动态，不限制</td><td align="left">map[key]取出对应key的value</td><td align="left">size()统计元素个数<br>map_keys()取出全部key，返回array<br>map_values()取出全部value，返回array<br>array_contains()判断是否包含指定数据，须与map_keys()或map_values()配合使用，在where子句中做搜索条件</td></tr><tr><td>struct</td><td>struct&lt;子列名1 子列类型1, 子列名2 子列类型2, …&gt;</td><td align="left">如定义为：struct&lt;c1 string, c2 int, c3 date&gt;<br>数据为：‘a’, 1, ‘2023-01-01’</td><td align="left">单值，类型取决于定义</td><td align="left">固定，取决于定义的子列数量</td><td align="left">struct.子列名<br>通过子列名取出子列的值</td><td align="left">暂无</td></tr></tbody></table> 
<h3><a id="73__876"></a>7.3. 数据查询</h3> 
<p><strong>准备数据</strong><br> 将课程资料中的itheima_orders.txt和itheima_users.txt放到Linux系统/home/hadoop目录下，然后执行以下SQL：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 创建新的库</span>
<span class="token keyword">CREATE</span> <span class="token keyword">database</span> itheima<span class="token punctuation">;</span>
<span class="token comment">-- 选择itheima库</span>
<span class="token keyword">use</span> itheima<span class="token punctuation">;</span>
<span class="token comment">-- 创建订单表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> itheima<span class="token punctuation">.</span>orders <span class="token punctuation">(</span>
    orderId <span class="token keyword">bigint</span> <span class="token keyword">COMMENT</span> <span class="token string">'订单id'</span><span class="token punctuation">,</span>
    orderNo string <span class="token keyword">COMMENT</span> <span class="token string">'订单编号'</span><span class="token punctuation">,</span>
    shopId <span class="token keyword">bigint</span> <span class="token keyword">COMMENT</span> <span class="token string">'门店id'</span><span class="token punctuation">,</span>
    userId <span class="token keyword">bigint</span> <span class="token keyword">COMMENT</span> <span class="token string">'用户id'</span><span class="token punctuation">,</span>
    orderStatus <span class="token keyword">tinyint</span> <span class="token keyword">COMMENT</span> <span class="token string">'订单状态 -3:用户拒收 -2:未付款的订单 -1：用户取消 0:待发货 1:配送中 2:用户确认收货'</span><span class="token punctuation">,</span>
    goodsMoney <span class="token keyword">double</span> <span class="token keyword">COMMENT</span> <span class="token string">'商品金额'</span><span class="token punctuation">,</span>
    deliverMoney <span class="token keyword">double</span> <span class="token keyword">COMMENT</span> <span class="token string">'运费'</span><span class="token punctuation">,</span>
    totalMoney <span class="token keyword">double</span> <span class="token keyword">COMMENT</span> <span class="token string">'订单金额（包括运费）'</span><span class="token punctuation">,</span>
    realTotalMoney <span class="token keyword">double</span> <span class="token keyword">COMMENT</span> <span class="token string">'实际订单金额（折扣后金额）'</span><span class="token punctuation">,</span>
    payType <span class="token keyword">tinyint</span> <span class="token keyword">COMMENT</span> <span class="token string">'支付方式,0:未知;1:支付宝，2：微信;3、现金；4、其他'</span><span class="token punctuation">,</span>
    isPay <span class="token keyword">tinyint</span> <span class="token keyword">COMMENT</span> <span class="token string">'是否支付 0:未支付 1:已支付'</span><span class="token punctuation">,</span>
    userName string <span class="token keyword">COMMENT</span> <span class="token string">'收件人姓名'</span><span class="token punctuation">,</span>
    userAddress string <span class="token keyword">COMMENT</span> <span class="token string">'收件人地址'</span><span class="token punctuation">,</span>
    userPhone string <span class="token keyword">COMMENT</span> <span class="token string">'收件人电话'</span><span class="token punctuation">,</span>
    createTime <span class="token keyword">timestamp</span> <span class="token keyword">COMMENT</span> <span class="token string">'下单时间'</span><span class="token punctuation">,</span>
    payTime <span class="token keyword">timestamp</span> <span class="token keyword">COMMENT</span> <span class="token string">'支付时间'</span><span class="token punctuation">,</span>
    totalPayFee <span class="token keyword">int</span> <span class="token keyword">COMMENT</span> <span class="token string">'总支付金额'</span>
<span class="token punctuation">)</span> <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token comment">-- 加载数据到orders表中</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/itheima_orders.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> itheima<span class="token punctuation">.</span>orders<span class="token punctuation">;</span>
<span class="token comment">-- 创建用户表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> itheima<span class="token punctuation">.</span>users <span class="token punctuation">(</span>
    userId <span class="token keyword">int</span><span class="token punctuation">,</span>
    loginName string<span class="token punctuation">,</span>
    loginSecret <span class="token keyword">int</span><span class="token punctuation">,</span>
    loginPwd string<span class="token punctuation">,</span>
    userSex <span class="token keyword">tinyint</span><span class="token punctuation">,</span>
    userName string<span class="token punctuation">,</span>
    trueName string<span class="token punctuation">,</span>
    brithday <span class="token keyword">date</span><span class="token punctuation">,</span>
    userPhoto string<span class="token punctuation">,</span>
    userQQ string<span class="token punctuation">,</span>
    userPhone string<span class="token punctuation">,</span>
    userScore <span class="token keyword">int</span><span class="token punctuation">,</span>
    userTotalScore <span class="token keyword">int</span><span class="token punctuation">,</span>
    userFrom <span class="token keyword">tinyint</span><span class="token punctuation">,</span>
    userMoney <span class="token keyword">double</span><span class="token punctuation">,</span>
    lockMoney <span class="token keyword">double</span><span class="token punctuation">,</span>
    createTime <span class="token keyword">timestamp</span><span class="token punctuation">,</span>
    payPwd string<span class="token punctuation">,</span>
    rechargeMoney <span class="token keyword">double</span>
<span class="token punctuation">)</span> <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token comment">-- 加载数据到users表中</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/itheima_users.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> itheima<span class="token punctuation">.</span>users<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="731__931"></a>7.3.1. 基本查询</h4> 
<p>Hive中使用基本查询SELECT、WHERE、GROUP BY、聚合函数、HAVING、JOIN和普通的SQL语句没有区别。<br> 查询语句的基本语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token punctuation">[</span><span class="token keyword">ALL</span> <span class="token operator">|</span> <span class="token keyword">DISTINCT</span><span class="token punctuation">]</span>select_expr<span class="token punctuation">,</span> select_expr<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">FROM</span> table_reference
<span class="token punctuation">[</span><span class="token keyword">WHERE</span> where_condition<span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">GROUP</span> BYcol_list<span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">HAVING</span> where_condition<span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">ORDER</span> BYcol_list<span class="token punctuation">]</span>
<span class="token punctuation">[</span>CLUSTER BYcol_list
  <span class="token operator">|</span> <span class="token punctuation">[</span>DISTRIBUTE <span class="token keyword">BY</span> col_list<span class="token punctuation">]</span> <span class="token punctuation">[</span>SORT <span class="token keyword">BY</span> col_list<span class="token punctuation">]</span>
<span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">LIMIT</span> number<span class="token punctuation">]</span>
</code></pre> 
<p>整体上和普通SQL差不多，部分有区别，如：CLUSTER BY、DISTRIBUTE BY、SORT BY等。</p> 
<p><strong>SELECT基础查询</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 查询全表数据</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders<span class="token punctuation">;</span>

<span class="token comment">-- 查询单列信息</span>
<span class="token keyword">SELECT</span> orderid<span class="token punctuation">,</span> userid<span class="token punctuation">,</span> totalmoney <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders<span class="token punctuation">;</span>

<span class="token comment">-- 查询表中总共有多少条数据（会转成MapReduce任务执行）</span>
<span class="token keyword">SELECT</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders<span class="token punctuation">;</span>

<span class="token comment">-- 查询表中广东省的订单</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders o <span class="token keyword">WHERE</span> o<span class="token punctuation">.</span>useraddress <span class="token operator">LIKE</span> <span class="token string">'广东%'</span><span class="token punctuation">;</span>

<span class="token comment">-- 找出广东省单笔金额最大的订单（会转成MapReduce任务执行）</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders o <span class="token keyword">WHERE</span> o<span class="token punctuation">.</span>useraddress <span class="token operator">LIKE</span> <span class="token string">'广东%'</span> <span class="token keyword">ORDER</span> <span class="token keyword">BY</span> o<span class="token punctuation">.</span>totalmoney <span class="token keyword">DESC</span> <span class="token keyword">LIMIT</span> <span class="token number">1</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>分组、聚合查询</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 统计未支付、已支付各自的人数（会转成MapReduce任务执行）</span>
<span class="token keyword">SELECT</span> ispay<span class="token punctuation">,</span> <span class="token function">COUNT</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders <span class="token keyword">GROUP</span> <span class="token keyword">BY</span> ispay<span class="token punctuation">;</span>

<span class="token comment">-- 在已付款的订单中，统计每个用户最高额度一笔消费金额（会转成MapReduce任务执行）</span>
<span class="token keyword">SELECT</span> userid<span class="token punctuation">,</span> <span class="token function">MAX</span><span class="token punctuation">(</span>totalmoney<span class="token punctuation">)</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders <span class="token keyword">WHERE</span> ispay <span class="token operator">=</span> <span class="token number">1</span> <span class="token keyword">GROUP</span> <span class="token keyword">BY</span> userid<span class="token punctuation">;</span>

<span class="token comment">-- 统计每个用户的平均订单消费额（会转成MapReduce任务执行）</span>
<span class="token keyword">SELECT</span> userid<span class="token punctuation">,</span> <span class="token function">AVG</span><span class="token punctuation">(</span>totalmoney<span class="token punctuation">)</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders <span class="token keyword">GROUP</span> <span class="token keyword">BY</span> userid<span class="token punctuation">;</span> 

<span class="token comment">-- 统计每个用户的平均订单消费额，并过滤大于10000的数据（会转成MapReduce任务执行）</span>
<span class="token keyword">SELECT</span> userid<span class="token punctuation">,</span> <span class="token function">AVG</span><span class="token punctuation">(</span>totalmoney<span class="token punctuation">)</span> <span class="token keyword">as</span> avg_totalmoney <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders <span class="token keyword">GROUP</span> <span class="token keyword">BY</span> userid <span class="token keyword">HAVING</span> avg_totalmoney <span class="token operator">&gt;</span> <span class="token number">10000</span><span class="token punctuation">;</span> 
</code></pre> 
<p><strong>JOIN查询</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">-- JOIN（内关联）订单表和用户表，找出用户名</span>
<span class="token keyword">SELECT</span> o<span class="token punctuation">.</span>orderid<span class="token punctuation">,</span> o<span class="token punctuation">.</span>userid<span class="token punctuation">,</span> u<span class="token punctuation">.</span>username <span class="token keyword">FROM</span> orders o <span class="token keyword">JOIN</span> users u <span class="token keyword">ON</span> u<span class="token punctuation">.</span>userid <span class="token operator">=</span> o<span class="token punctuation">.</span>userid<span class="token punctuation">;</span>

<span class="token comment">-- 左外关联，订单表和用户表，找出用户名</span>
<span class="token keyword">SELECT</span> o<span class="token punctuation">.</span>orderid<span class="token punctuation">,</span> o<span class="token punctuation">.</span>userid<span class="token punctuation">,</span> u<span class="token punctuation">.</span>username <span class="token keyword">FROM</span> orders o <span class="token keyword">LEFT</span> <span class="token keyword">JOIN</span> users u <span class="token keyword">ON</span> u<span class="token punctuation">.</span>userid <span class="token operator">=</span> o<span class="token punctuation">.</span>userid<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="732_RLIKE__990"></a>7.3.2. RLIKE 正则匹配</h4> 
<p>Hive中提供RLIKE关键字，可以供用户使用正则和数据进行匹配。</p> 
<p><strong>RLIKE匹配</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 查找广东省的数据</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders o <span class="token keyword">WHERE</span> o<span class="token punctuation">.</span>useraddress <span class="token operator">RLIKE</span> <span class="token string">'.*广东.*'</span><span class="token punctuation">;</span>

<span class="token comment">-- 查找用户地址是：XX省 XX市 XX区的数据</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders o <span class="token keyword">WHERE</span> o<span class="token punctuation">.</span>useraddress <span class="token operator">RLIKE</span> <span class="token string">'..省 ..市 ..区'</span><span class="token punctuation">;</span>

<span class="token comment">-- 查找用户姓为张、王、邓的数据</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders o <span class="token keyword">WHERE</span> o<span class="token punctuation">.</span>username <span class="token operator">RLIKE</span> <span class="token string">'[张王邓].+'</span><span class="token punctuation">;</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders o <span class="token keyword">WHERE</span> o<span class="token punctuation">.</span>username <span class="token operator">RLIKE</span> <span class="token string">'[张王邓]\\S+'</span><span class="token punctuation">;</span>

<span class="token comment">-- 查找手机号复合：188****0***规则的订单</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders o <span class="token keyword">WHERE</span> o<span class="token punctuation">.</span>userphone <span class="token operator">RLIKE</span> <span class="token string">'188.{4}0.{3}'</span><span class="token punctuation">;</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders o <span class="token keyword">WHERE</span> o<span class="token punctuation">.</span>userphone <span class="token operator">RLIKE</span> <span class="token string">'188\\S{4}0[0-9]{3}'</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="733_UNION_1010"></a>7.3.3. UNION联合</h4> 
<p>UNION 用于将多个 SELECT 语句的结果组合成单个结果集。但每个 select 语句返回的列的数量和名称必须相同。否则，将引发架构错误。<br> 语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token keyword">UNION</span> <span class="token punctuation">[</span><span class="token keyword">ALL</span><span class="token punctuation">]</span>
<span class="token keyword">SELECT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> 
<p>[ALL]，表示不对结果中完全一样的数据去重。</p> 
<p><strong>准备数据：</strong><br> 将课程资料中的course.txt放到Linux系统/home/hadoop目录下，然后执行以下SQL：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 创建数据表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> itheima<span class="token punctuation">.</span>course<span class="token punctuation">(</span>
	c_id string<span class="token punctuation">,</span> 
	c_name string<span class="token punctuation">,</span> 
	t_id string
<span class="token punctuation">)</span> <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token comment">-- 加载数据</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/hadoop/course.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> itheima<span class="token punctuation">.</span>course<span class="token punctuation">;</span>
</code></pre> 
<p><strong>union语句</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 基础UNION语句</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>course c <span class="token keyword">WHERE</span> c<span class="token punctuation">.</span>t_id<span class="token operator">=</span><span class="token string">"周杰轮"</span>
	<span class="token keyword">UNION</span> 
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>course c2 <span class="token keyword">WHERE</span> c2<span class="token punctuation">.</span>t_id<span class="token operator">=</span><span class="token string">"林均街"</span><span class="token punctuation">;</span>

<span class="token comment">-- 去重演示</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>course
	<span class="token keyword">UNION</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>course<span class="token punctuation">;</span>

<span class="token comment">-- 不去重</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>course
	<span class="token keyword">UNION</span> <span class="token keyword">ALL</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>course<span class="token punctuation">;</span>

<span class="token comment">-- UNION写在FROM，UNION写在子查询中</span>
<span class="token keyword">SELECT</span> t_id<span class="token punctuation">,</span> <span class="token function">COUNT</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> 
<span class="token punctuation">(</span>
	<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>course c <span class="token keyword">WHERE</span> c<span class="token punctuation">.</span>t_id<span class="token operator">=</span><span class="token string">"周杰轮"</span>
		<span class="token keyword">UNION</span> <span class="token keyword">ALL</span>
	<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>course c2 <span class="token keyword">WHERE</span> c2<span class="token punctuation">.</span>t_id<span class="token operator">=</span><span class="token string">"王力鸿"</span>
<span class="token punctuation">)</span> <span class="token keyword">AS</span> u <span class="token keyword">GROUP</span> <span class="token keyword">BY</span> t_id<span class="token punctuation">;</span>


<span class="token comment">-- 用于INSERT SELECT</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> itheima<span class="token punctuation">.</span>course2<span class="token punctuation">(</span>
	c_id string<span class="token punctuation">,</span> 
	c_name string<span class="token punctuation">,</span> 
	t_id string
<span class="token punctuation">)</span> <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>

<span class="token keyword">INSERT</span> OVERWRITE <span class="token keyword">TABLE</span> itheima<span class="token punctuation">.</span>course2 
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>course 
	<span class="token keyword">UNION</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>course<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="734_Sampling_1071"></a>7.3.4. Sampling采样</h4> 
<p><strong>1、为什么需要抽样表数据</strong><br> 大数据体系下，在真正的企业环境中，很容易出现很大的表，比如体积达到TB级别。对这种表一个简单的SELECT * 都会非常的慢，哪怕LIMIT 10想要看10条数据，也会走MapReduce流程，这个时间等待是不合适的。<br> Hive提供的快速抽样的语法，可以快速从大表中随机抽取一些数据供用户查看。使用TABLESAMPLE函数实现。</p> 
<p><strong>2、随机分桶抽样</strong><br> 语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">FROM</span> tbl TABLESAMPLE<span class="token punctuation">(</span>BUCKET x <span class="token keyword">OUT</span> <span class="token keyword">OF</span> y <span class="token keyword">ON</span><span class="token punctuation">(</span>colname <span class="token operator">|</span> rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>tbl，表示抽取数据的表名；</li><li>y，表示将tbl表中的数据划分成y份（即y个桶）；</li><li>x，表示从y份数据中取第x份数据作为取样样本；</li><li>colname，表示依据基于某个列（这里写的是列名）的值的hash取模结果分桶，<mark>只能是非分区列</mark>；</li><li>rand()，表示随机的基于基于整行，也就是完全随机了。</li></ul> 
<p>本节以之前创建并导入数据的itheima库，orders表为抽样的数据表。</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 对orders表进行抽样，依据username列将数据随机分为10份，并抽取其中的第3份</span>
<span class="token keyword">SELECT</span> username<span class="token punctuation">,</span> orderId<span class="token punctuation">,</span> totalmoney <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders tablesample<span class="token punctuation">(</span>bucket <span class="token number">3</span> <span class="token keyword">out</span> <span class="token keyword">of</span> <span class="token number">10</span> <span class="token keyword">on</span> username<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>基于列抽样，会发现运行多次，抽样的结果都是固定的。<mark>因为基于列的值进行hash取模分桶的结果是固定的</mark>！<br> <mark>若一个表本身就是分桶表的话，使用基于列的抽样，基于分桶列进行抽样，随机的份数与表的分桶数保持一致，效率会非常高。</mark><br> <img src="https://images2.imgbox.com/8c/55/MKk1I7Tw_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 对orders表进行抽样，完全随机将数据分为10份，并抽取其中的第3份</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders tablesample<span class="token punctuation">(</span>bucket <span class="token number">3</span> <span class="token keyword">out</span> <span class="token keyword">of</span> <span class="token number">10</span> <span class="token keyword">on</span> rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>基于rand()随机抽样，会发现，每次运行的结果都是不一样的。<br> <img src="https://images2.imgbox.com/c8/be/0bPM2k5K_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/23/36/azIy27Uw_o.png" alt="在这里插入图片描述"></p> 
<p><strong>3、 基于数据块抽样</strong><br> 语法：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">FROM</span> tbl TABLESAMPLE<span class="token punctuation">(</span>num <span class="token keyword">ROWS</span> <span class="token operator">|</span> num <span class="token keyword">PERCENT</span> <span class="token operator">|</span> num<span class="token punctuation">(</span>K<span class="token operator">|</span>M<span class="token operator">|</span>G<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<ul><li>tbl，表示抽取数据的表名；</li><li>num ROWS，表示总共抽取num条数据；</li><li>num PERCENT，表示抽取百分之num比例的数据（不是数据条数的百分比，而是数据大小的百分比）；</li><li>num(K|M|G)，表示抽取num大小的数据，单位可以是K、M、G分别代表KB、MB、GB。</li></ul> 
<p>注意：<br> 使用这种语法抽样，条件不变的话，每一次抽样的结果都一致。即无法做到随机，只是按照数据顺序从前到后取数据。</p> 
<p>例如：</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 抽取前100条数据</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders tablesample<span class="token punctuation">(</span><span class="token number">100</span> <span class="token keyword">rows</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 抽取前10%的数据</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders tablesample<span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">percent</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 抽取前1KB的数据</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders tablesample<span class="token punctuation">(</span><span class="token number">1</span>K<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="735_Virtual_Columns_1130"></a>7.3.5. Virtual Columns虚拟列</h4> 
<p>虚拟列是Hive内置的可以在查询语句中使用的特殊标记，可以查询数据本身的详细参数。<br> Hive目前可用3个虚拟列：</p> 
<ul><li>INPUT__FILE__NAME：显示数据行所在的具体文件；</li><li>BLOCK__OFFSET__INSIDE__FILE：显示数据行所在文件的偏移量；</li><li>ROW__OFFSET__INSIDE__BLOCK：显示数据所在的HDFS块的偏移量； 
  <ul><li>此虚拟列需要设置：<code>SET hive.exec.rowoffset=true</code>才能使用。</li></ul> </li></ul> 
<p>本节使用itheima库中的orders表进行演示。</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 开启ROW__OFFSET__INSIDE__BLOCK虚拟列</span>
<span class="token keyword">SET</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>rowoffset<span class="token operator">=</span><span class="token boolean">true</span>
<span class="token comment">-- 查询orders表中每行数据所处的文件、数据行文件偏移量和数据块偏移量</span>
<span class="token keyword">SELECT</span> orderid<span class="token punctuation">,</span> username<span class="token punctuation">,</span> INPUT__FILE__NAME<span class="token punctuation">,</span> BLOCK__OFFSET__INSIDE__FILE<span class="token punctuation">,</span> ROW__OFFSET__INSIDE__BLOCK <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/e2/3e/ROlXUWWd_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 在where子句中使用虚拟列，查询在HDFS文件中偏移量小于1000的数据</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span><span class="token punctuation">,</span> BLOCK__OFFSET__INSIDE__FILE <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders <span class="token keyword">WHERE</span> BLOCK__OFFSET__INSIDE__FILE <span class="token operator">&lt;</span> <span class="token number">1000</span><span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/f9/84/3fpQRD3C_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-sql"><span class="token comment">-- 开启分桶的自动优化功能</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>enforce<span class="token punctuation">.</span>bucketing <span class="token operator">=</span> <span class="token boolean">TRUE</span><span class="token punctuation">;</span>

<span class="token comment">-- 构建一个基于orders的分桶表，基于orderId字段的值，分10个桶</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> itheima<span class="token punctuation">.</span>orders_bucket <span class="token punctuation">(</span>
    orderId <span class="token keyword">bigint</span> <span class="token keyword">COMMENT</span> <span class="token string">'订单id'</span><span class="token punctuation">,</span>
    orderNo string <span class="token keyword">COMMENT</span> <span class="token string">'订单编号'</span><span class="token punctuation">,</span>
    shopId <span class="token keyword">bigint</span> <span class="token keyword">COMMENT</span> <span class="token string">'门店id'</span><span class="token punctuation">,</span>
    userId <span class="token keyword">bigint</span> <span class="token keyword">COMMENT</span> <span class="token string">'用户id'</span><span class="token punctuation">,</span>
    orderStatus <span class="token keyword">tinyint</span> <span class="token keyword">COMMENT</span> <span class="token string">'订单状态 -3:用户拒收 -2:未付款的订单 -1：用户取消 0:待发货 1:配送中 2:用户确认收货'</span><span class="token punctuation">,</span>
    goodsMoney <span class="token keyword">double</span> <span class="token keyword">COMMENT</span> <span class="token string">'商品金额'</span><span class="token punctuation">,</span>
    deliverMoney <span class="token keyword">double</span> <span class="token keyword">COMMENT</span> <span class="token string">'运费'</span><span class="token punctuation">,</span>
    totalMoney <span class="token keyword">double</span> <span class="token keyword">COMMENT</span> <span class="token string">'订单金额（包括运费）'</span><span class="token punctuation">,</span>
    realTotalMoney <span class="token keyword">double</span> <span class="token keyword">COMMENT</span> <span class="token string">'实际订单金额（折扣后金额）'</span><span class="token punctuation">,</span>
    payType <span class="token keyword">tinyint</span> <span class="token keyword">COMMENT</span> <span class="token string">'支付方式,0:未知;1:支付宝，2：微信;3、现金；4、其他'</span><span class="token punctuation">,</span>
    isPay <span class="token keyword">tinyint</span> <span class="token keyword">COMMENT</span> <span class="token string">'是否支付 0:未支付 1:已支付'</span><span class="token punctuation">,</span>
    userName string <span class="token keyword">COMMENT</span> <span class="token string">'收件人姓名'</span><span class="token punctuation">,</span>
    userAddress string <span class="token keyword">COMMENT</span> <span class="token string">'收件人地址'</span><span class="token punctuation">,</span>
    userPhone string <span class="token keyword">COMMENT</span> <span class="token string">'收件人电话'</span><span class="token punctuation">,</span>
    createTime <span class="token keyword">timestamp</span> <span class="token keyword">COMMENT</span> <span class="token string">'下单时间'</span><span class="token punctuation">,</span>
    payTime <span class="token keyword">timestamp</span> <span class="token keyword">COMMENT</span> <span class="token string">'支付时间'</span><span class="token punctuation">,</span>
    totalPayFee <span class="token keyword">int</span> <span class="token keyword">COMMENT</span> <span class="token string">'总支付金额'</span>
<span class="token punctuation">)</span> <span class="token keyword">CLUSTERED</span> <span class="token keyword">BY</span> <span class="token punctuation">(</span>orderId<span class="token punctuation">)</span> <span class="token keyword">INTO</span> <span class="token number">10</span> BUCKETS
<span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>

<span class="token comment">-- 从oredrs表中向分桶表加载数据</span>
<span class="token keyword">INSERT</span> overwrite <span class="token keyword">table</span> itheima<span class="token punctuation">.</span>orders_bucket <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders cluster <span class="token keyword">by</span><span class="token punctuation">(</span>orderId<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">-- 查询orders_bucket表中每行数据所处的文件、数据行文件偏移量和数据块偏移量</span>
<span class="token keyword">SELECT</span> orderid<span class="token punctuation">,</span> username<span class="token punctuation">,</span> INPUT__FILE__NAME<span class="token punctuation">,</span> BLOCK__OFFSET__INSIDE__FILE<span class="token punctuation">,</span> ROW__OFFSET__INSIDE__BLOCK <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders_bucket<span class="token punctuation">;</span>

<span class="token comment">-- 统计每个桶文件中各自存放了多少条数据（在GROUP BY子句中使用虚拟列）</span>
<span class="token keyword">SELECT</span> INPUT__FILE__NAME<span class="token punctuation">,</span> <span class="token function">COUNT</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> itheima<span class="token punctuation">.</span>orders_bucket <span class="token keyword">GROUP</span> <span class="token keyword">BY</span>  INPUT__FILE__NAME<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/a0/7e/PRMBMPfZ_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/52/25/U4zPMQfK_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="74__1191"></a>7.4. 函数</h3> 
<h4><a id="741__1192"></a>7.4.1. 数字、集合、转换、日期函数</h4> 
<h4><a id="742__1195"></a>7.4.2. 条件、字符串、脱敏、其它函数</h4>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a724d11cd87cf7fed7c6c925fee20000/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">返回按钮点击坐标</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/92ee35eaf20d6de455e2219aa8f6b289/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">HTML---定位</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>