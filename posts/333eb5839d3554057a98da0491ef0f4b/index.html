<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>头歌答案--爬虫实战 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="头歌答案--爬虫实战" />
<meta property="og:description" content="目录
urllib 爬虫 第1关：urllib基础
任务描述
第2关：urllib进阶 任务描述
requests 爬虫
第1关：requests 基础
任务描述
第2关：requests 进阶
任务描述
网页数据解析
第1关：XPath解析网页 任务描述
第2关：BeautifulSoup解析网页 任务描述
JSON数据解析
第1关：JSON解析 任务描述
爬虫实战——网页抓取及信息提取
第1关：利用URL获取超文本文件并保存至本地 任务描述
第2关：提取子链接 任务描述
第3关：网页数据分析 任务描述
urllib 爬虫 第1关：urllib基础 任务描述 本关任务：掌握 urlopen 函数的使用，完成一个简易的爬取程序。
import urllib.request def request(url): &#39;&#39;&#39; 一个参数 :param url:请求网址 :return:返回一个请求的字符串。编码为utf-8 &#39;&#39;&#39; # *************** Begin *************** # r=urllib.request.urlopen(url) return r.read().decode(&#39;utf-8&#39;) # *************** End ***************** # 第2关：urllib进阶 任务描述 本关任务：利用 Opener 方法，完成一个简易的爬取程序。
import urllib.request import http.cookiejar def request(url,headers): &#39;&#39;&#39; 两个参数 :param url:统一资源定位符,请求网址 :param headers:请求头 :return:html &#39;&#39;&#39; # ***************** Begin ******************** # cookie = http." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/333eb5839d3554057a98da0491ef0f4b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-12T11:59:44+08:00" />
<meta property="article:modified_time" content="2023-11-12T11:59:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">头歌答案--爬虫实战</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/87/9f/oKDrN0i9_o.png"></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="urllib%20%E7%88%AC%E8%99%AB%C2%A0-toc" style="margin-left:0px;"><a href="#urllib%20%E7%88%AC%E8%99%AB%C2%A0" rel="nofollow">urllib 爬虫 </a></p> 
<p id="%E7%AC%AC1%E5%85%B3%EF%BC%9Aurllib%E5%9F%BA%E7%A1%80-toc" style="margin-left:80px;"><a href="#%E7%AC%AC1%E5%85%B3%EF%BC%9Aurllib%E5%9F%BA%E7%A1%80" rel="nofollow">第1关：urllib基础</a></p> 
<p id="任务描述-toc" style="margin-left:120px;"><a href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0" rel="nofollow">任务描述</a></p> 
<p id="%E7%AC%AC2%E5%85%B3%EF%BC%9Aurllib%E8%BF%9B%E9%98%B6%C2%A0-toc" style="margin-left:80px;"><a href="#%E7%AC%AC2%E5%85%B3%EF%BC%9Aurllib%E8%BF%9B%E9%98%B6%C2%A0" rel="nofollow">第2关：urllib进阶 </a></p> 
<p id="%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0-toc" style="margin-left:120px;"><a href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0" rel="nofollow">任务描述</a></p> 
<p id="requests%20%E7%88%AC%E8%99%AB-toc" style="margin-left:0px;"><a href="#requests%20%E7%88%AC%E8%99%AB" rel="nofollow">requests 爬虫</a></p> 
<p id="%E7%AC%AC1%E5%85%B3%EF%BC%9Arequests%20%E5%9F%BA%E7%A1%80-toc" style="margin-left:80px;"><a href="#%E7%AC%AC1%E5%85%B3%EF%BC%9Arequests%20%E5%9F%BA%E7%A1%80" rel="nofollow">第1关：requests 基础</a></p> 
<p id="%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0-toc" style="margin-left:120px;"><a href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0" rel="nofollow">任务描述</a></p> 
<p id="%E7%AC%AC2%E5%85%B3%EF%BC%9Arequests%20%E8%BF%9B%E9%98%B6-toc" style="margin-left:80px;"><a href="#%E7%AC%AC2%E5%85%B3%EF%BC%9Arequests%20%E8%BF%9B%E9%98%B6" rel="nofollow">第2关：requests 进阶</a></p> 
<p id="%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0-toc" style="margin-left:120px;"><a href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0" rel="nofollow">任务描述</a></p> 
<p id="%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90-toc" style="margin-left:0px;"><a href="#%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90" rel="nofollow">网页数据解析</a></p> 
<p id="%E7%AC%AC1%E5%85%B3%EF%BC%9AXPath%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%C2%A0-toc" style="margin-left:80px;"><a href="#%E7%AC%AC1%E5%85%B3%EF%BC%9AXPath%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%C2%A0" rel="nofollow">第1关：XPath解析网页 </a></p> 
<p id="%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0-toc" style="margin-left:120px;"><a href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0" rel="nofollow">任务描述</a></p> 
<p id="%E7%AC%AC2%E5%85%B3%EF%BC%9ABeautifulSoup%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%C2%A0-toc" style="margin-left:80px;"><a href="#%E7%AC%AC2%E5%85%B3%EF%BC%9ABeautifulSoup%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%C2%A0" rel="nofollow">第2关：BeautifulSoup解析网页 </a></p> 
<p id="%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0-toc" style="margin-left:120px;"><a href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0" rel="nofollow">任务描述</a></p> 
<p id="JSON%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90-toc" style="margin-left:0px;"><a href="#JSON%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90" rel="nofollow">JSON数据解析</a></p> 
<p id="%E7%AC%AC1%E5%85%B3%EF%BC%9AJSON%E8%A7%A3%E6%9E%90%C2%A0-toc" style="margin-left:80px;"><a href="#%E7%AC%AC1%E5%85%B3%EF%BC%9AJSON%E8%A7%A3%E6%9E%90%C2%A0" rel="nofollow">第1关：JSON解析 </a></p> 
<p id="%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0-toc" style="margin-left:120px;"><a href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0" rel="nofollow">任务描述</a></p> 
<p id="%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96%E5%8F%8A%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96-toc" style="margin-left:0px;"><a href="#%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96%E5%8F%8A%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96" rel="nofollow">爬虫实战——网页抓取及信息提取</a></p> 
<p id="%E7%AC%AC1%E5%85%B3%EF%BC%9A%E5%88%A9%E7%94%A8URL%E8%8E%B7%E5%8F%96%E8%B6%85%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%B9%B6%E4%BF%9D%E5%AD%98%E8%87%B3%E6%9C%AC%E5%9C%B0%C2%A0-toc" style="margin-left:80px;"><a href="#%E7%AC%AC1%E5%85%B3%EF%BC%9A%E5%88%A9%E7%94%A8URL%E8%8E%B7%E5%8F%96%E8%B6%85%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%B9%B6%E4%BF%9D%E5%AD%98%E8%87%B3%E6%9C%AC%E5%9C%B0%C2%A0" rel="nofollow">第1关：利用URL获取超文本文件并保存至本地 </a></p> 
<p id="%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0-toc" style="margin-left:120px;"><a href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0" rel="nofollow">任务描述</a></p> 
<p id="%E7%AC%AC2%E5%85%B3%EF%BC%9A%E6%8F%90%E5%8F%96%E5%AD%90%E9%93%BE%E6%8E%A5%C2%A0-toc" style="margin-left:80px;"><a href="#%E7%AC%AC2%E5%85%B3%EF%BC%9A%E6%8F%90%E5%8F%96%E5%AD%90%E9%93%BE%E6%8E%A5%C2%A0" rel="nofollow">第2关：提取子链接 </a></p> 
<p id="%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0-toc" style="margin-left:120px;"><a href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0" rel="nofollow">任务描述</a></p> 
<p id="%E7%AC%AC3%E5%85%B3%EF%BC%9A%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%C2%A0-toc" style="margin-left:80px;"><a href="#%E7%AC%AC3%E5%85%B3%EF%BC%9A%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%C2%A0" rel="nofollow">第3关：网页数据分析 </a></p> 
<p id="%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0-toc" style="margin-left:120px;"><a href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0" rel="nofollow">任务描述</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p></p> 
<p></p> 
<h2 id="urllib%20%E7%88%AC%E8%99%AB%C2%A0" style="background-color:transparent;"><span style="color:#ff9900;"><strong>urllib 爬虫</strong> </span></h2> 
<h4 id="%E7%AC%AC1%E5%85%B3%EF%BC%9Aurllib%E5%9F%BA%E7%A1%80">第1关：urllib基础</h4> 
<h5 id="任务描述">任务描述</h5> 
<p>本关任务：掌握 urlopen 函数的使用，完成一个简易的爬取程序。</p> 
<pre><code class="language-python">import urllib.request
def request(url):
    '''
    一个参数
    :param url:请求网址
    :return:返回一个请求的字符串。编码为utf-8
    '''
    # *************** Begin *************** #
    r=urllib.request.urlopen(url) 
    return r.read().decode('utf-8')
    # *************** End ***************** #</code></pre> 
<p></p> 
<h4 id="%E7%AC%AC2%E5%85%B3%EF%BC%9Aurllib%E8%BF%9B%E9%98%B6%C2%A0">第2关：urllib进阶 </h4> 
<h5 id="%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0">任务描述</h5> 
<p>本关任务：利用 Opener 方法，完成一个简易的爬取程序。</p> 
<pre><code class="language-python">import urllib.request
import http.cookiejar
def request(url,headers):
    '''
    两个参数
    :param url:统一资源定位符,请求网址
    :param headers:请求头
    :return:html
    '''
    
    # ***************** Begin ******************** #
    cookie = http.cookiejar.CookieJar()
    handler = urllib.request.HTTPCookieProcessor(cookie) 
    opener = urllib.request.build_opener(handler)
    r=  opener.open(url)
    
    # ***************** End ******************** #
    html = r.read().decode('utf-8')
    return html</code></pre> 
<p></p> 
<h2 id="requests%20%E7%88%AC%E8%99%AB" style="background-color:transparent;"><span style="color:#ff9900;"><strong>requests 爬虫</strong></span></h2> 
<h4 id="%E7%AC%AC1%E5%85%B3%EF%BC%9Arequests%20%E5%9F%BA%E7%A1%80">第1关：requests 基础</h4> 
<h5>任务描述</h5> 
<p>本关任务：编写一个 requests 请求网页的程序。</p> 
<pre><code class="language-python">import requests
 
 
def get_html(url):
    '''
    两个参数
    :param url:统一资源定位符,请求网址
    :param headers:请求头
    :return:html
    '''
    
    # ***************** Begin ******************** #
 
    # 补充请求头
    headers={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/"
                  "537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36"}
    # get请求网页
    response = requests.get(url=url, headers=headers)  # 模拟登录请求
    response.encoding = "utf-8"  # 定义编码
    # 获取网页信息文本
    html = response.text
    # ***************** End ******************** #
    return html</code></pre> 
<p></p> 
<p></p> 
<h4 id="%E7%AC%AC2%E5%85%B3%EF%BC%9Arequests%20%E8%BF%9B%E9%98%B6">第2关：requests 进阶</h4> 
<h5>任务描述</h5> 
<p>本关任务：使用 session 编写爬取网页的小程序。</p> 
<pre><code class="language-python">import requests
 
 
def get_html(url):
    '''
    两个参数
    :param url:统一资源定位符,请求网址
    :param headers:请求头
    :return html 网页的源码
    :return sess 创建的会话
    '''
    
    # ***************** Begin ******************** #
    
    # 补充请求头
    headers={ 'User-Agent':'Mozilla/5.0 (Linux; Android 8.0.0; Pixel 2 XL Build/OPD1.170816.004) AppleWebKit/'
                  '537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Mobile Safari/537.36',
    "Cookie":"BAIDUID=53B7CC4BFCDC39D2EF625C13D285429D:FG=1; BIDUPSID=53B7CC4BFCDC39D2EF625C13D285429D; "
              "PSTM=1591665716; BD_UPN=12314753; BDUSS=2N2ajRYZnI2cVlZN1FRemlWNU9FV1lSZFM3SnZBS0dvRW44WFRCUTRWck1mUVpmR"
              "VFBQUFBJCQAAAAAAAAAAAEAAAAoKJzNMTIyMzM4ODQ1uNW41QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA"
              "AAAAAAAAAAAAMzw3l7M8N5eS; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; sug=3; sugstore=1; ORIGIN=0; bdime=0; "
              "H_PS_PSSID=1456_31672_32139_31253_32046_32230_31708_32295_26350_22160; delPer=0; BD_CK_SAM=1; PSINO=6; "
              "H_PS_645EC=3b86vFCd303Aw0wmqvkcAGpfxU4oXfwYcs6jRd1RnxihTsvhfqaVB%2BIoeBs; BDSVRTM=0"
              }
 
    # 创建Session, 并使用Session的get请求网页
    sess = requests.session()
    # 获取网页信息文本
    response = sess.get(url,headers=headers)
    response_home = sess.get(url=url)
    html=response.text
    # ****************** End ********************* #
    return html, sess</code></pre> 
<p></p> 
<h2 id="%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90"><span style="color:#ff9900;"><strong>网页数据解析</strong></span></h2> 
<h4 id="%E7%AC%AC1%E5%85%B3%EF%BC%9AXPath%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%C2%A0">第1关：XPath解析网页 </h4> 
<h5>任务描述</h5> 
<p>本关任务：在 <a href="https://www.educoder.net/shixuns/6l3kmew8/challenges" rel="nofollow" title="XPath 基础">XPath 基础</a>实训中，介绍了 XPath 的基础知识，本关需要使用 XPath 技术来编写解析网页的程序。</p> 
<pre><code class="language-python">import urllib.request
 
from lxml import etree
 
def get_data(url):
    '''
    :param url: 请求地址
    :return: None
    '''
    response=urllib.request.urlopen(url=url)
    html=response.read().decode("utf-8")
    # *************** Begin *************** #
    parse = etree.HTML(html)  
    # 写入xpath路径  
    item_list = parse.xpath("//div[@class='left']/ul/li/span/a/text()")   
    #item_list = parse.xpath("/html/body/div[2]/div[1]/ul/li/span/a.text()")   
    # *************** End ***************** #
 
    print(item_list)</code></pre> 
<p></p> 
<h4 id="%E7%AC%AC2%E5%85%B3%EF%BC%9ABeautifulSoup%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5%C2%A0">第2关：BeautifulSoup解析网页 </h4> 
<h5>任务描述</h5> 
<p>本关任务：使用 BeautifulSoup 解析网页爬取古诗词的内容部分。</p> 
<pre><code class="language-python">import requests
from bs4 import BeautifulSoup
def get_data(url, headers):
    '''
    两个参数
    :param url:统一资源定位符,请求网址
    :param headers:请求头
    :return data:list类型的所有古诗内容
    '''
    # ***************** Begin ******************** #
    response = requests.get(url, headers=headers)  
    response.encoding = "utf-8"  
    html = response.text  
    soup = BeautifulSoup(html, 'lxml')  
    data = soup.find('div', {'class': 'left'}).ul.find_all('li')  
    data = [i.p.text for i in data]
    # ****************** end ********************* #
    return data</code></pre> 
<p></p> 
<p></p> 
<h2 id="JSON%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90"><span style="color:#ff9900;"><strong>JSON数据解析</strong></span></h2> 
<h4 id="%E7%AC%AC1%E5%85%B3%EF%BC%9AJSON%E8%A7%A3%E6%9E%90%C2%A0">第1关：JSON解析 </h4> 
<h5>任务描述</h5> 
<p>本关任务：编写一个能用 JSON 解析爬虫数据的小程序。</p> 
<pre><code class="language-python">import urllib.request
from lxml import etree
import http.cookiejar
import json

def request_sess(url,headers):
    cj=http.cookiejar.CookieJar()
    opener=urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
    request = urllib.request.Request(url=url, headers=headers)
    r=opener.open(fullurl=request)
    html = r.read().decode('utf-8')
    return html
   
def save_data(path):
    '''
    :param path: 文件保存路径
    :return: 无
    '''
    url='http://127.0.0.1:8080/index'
    headers={
        'User-Agent':'Mozilla/5.0 (Linux; Android 8.0.0; Pixel 2 XL Build/OPD1.170816.004) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Mobile Safari/537.36'
    }
    # ********** Begin ************** #
    json_str = request_sess(url,headers)
   
    # 输出 JSON 数据中的 key 值为 code 对应的数据
    b = json.loads(json_str)
    print(b['code'])

    
    # 将爬取下来的 JSON 数据保存到本地
    with open(path,'w') as f:
         json.dump(b,f)
    # ********** End ************** #</code></pre> 
<p></p> 
<h2 id="%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96%E5%8F%8A%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96" style="background-color:transparent;"><span style="color:#ff9900;"><strong>爬虫实战——网页抓取及信息提取</strong></span></h2> 
<h4 id="%E7%AC%AC1%E5%85%B3%EF%BC%9A%E5%88%A9%E7%94%A8URL%E8%8E%B7%E5%8F%96%E8%B6%85%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%B9%B6%E4%BF%9D%E5%AD%98%E8%87%B3%E6%9C%AC%E5%9C%B0%C2%A0">第1关：利用URL获取超文本文件并保存至本地 </h4> 
<h5>任务描述</h5> 
<p>当我们想要在浏览器中打开一个网页时，需要在浏览器的地址栏中输入该网页的<code>url</code>，例如在地址栏中输入百度搜索网站的首页<code>url</code>：<a href="https://www.baidu.com/" rel="nofollow" title="百度一下，你就知道">百度一下，你就知道</a> ，点击确认后，浏览器将向服务器发出一个对该网的请求；服务器端收到请求后，会返回该网页的超文本文件，浏览器收到服务器端发来的网页超文本文件后，对其进行解析，然后在窗口中显示该超文本文件对应的网页。如下图所示。</p> 
<pre><code class="language-python"># -*- coding: utf-8 -*-
import urllib.request as req
import os
import hashlib
 
# 国防科技大学本科招生信息网中录取分数网页URL：
url = 'https://www.nudt.edu.cn/bkzs/xxgk/lqfs/index.htm'  # 录取分数网页URL
 
 
def step1():
# 请按下面的注释提示添加代码，完成相应功能
#********** Begin *********#
# 1.将网页内容保存到data
    x = req.urlopen(url)
    date = x.read()
 
 
 
# 2.将data以二进制写模式写入以学号命名的 “nudt.txt” 文件：
    with open('nudt.txt','wb') as f:
        f.write(date)
 
 
    
#********** End **********#</code></pre> 
<p></p> 
<p></p> 
<h4 id="%E7%AC%AC2%E5%85%B3%EF%BC%9A%E6%8F%90%E5%8F%96%E5%AD%90%E9%93%BE%E6%8E%A5%C2%A0">第2关：提取子链接 </h4> 
<h5>任务描述</h5> 
<p>上一关我们学习了如何访问给定的网页并保存信息到本地，本关我们要从上一关访问的网页中提取出嵌套的<code>url</code>地址，即实现子链接的提取。</p> 
<pre><code class="language-python"># -*- coding: utf-8 -*-
import urllib.request as req
# 国防科技大学本科招生信息网中录取分数网页URL：
url = 'https://www.nudt.edu.cn/bkzs/xxgk/lqfs/index.htm'  # 录取分数网页URL
webpage = req.urlopen(url)  # 按照类文件的方式打开网页
data = webpage.read()       # 一次性读取网页的所有数据
data = data.decode('utf-8')  # 将byte类型的data解码为字符串（否则后面查找就要另外处理了）
 
def step2():
    
# 建立空列表urls，来保存子网页的url
    urls = []
 
# 请按下面的注释提示添加代码，完成相应功能
#********** Begin *********#
# 从data中提取2014到2021每一年分数线子网站地址添加到urls列表中
    for i in range(2014,2021+1):
        string = f"{i}年录取分数统计"
        index = data.find(string)
        urls.insert(0,'https://www.nudt.edu.cn/bkzs/xxgk/lqfs/'+'"'+
        data[index-133:index-133+36])
 
 
# #********** End **********#
    return urls</code></pre> 
<p></p> 
<p></p> 
<h4 id="%E7%AC%AC3%E5%85%B3%EF%BC%9A%E7%BD%91%E9%A1%B5%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%C2%A0">第3关：网页数据分析 </h4> 
<h5>任务描述</h5> 
<p>下图是<code>2016</code>年国防科技大学分数线的网页，在浏览器中我们可以看到，各省的最高分、最低分、平均分都整齐地排列自在表格中。一个网页的源代码时常有成百上千行，其中很多代码都是为了布局页面样式服务的，而我们时常关心的是网页上的数据，而并不关心样式代码。所以如何从冗长的网页源代码中提取我们关心的数据，是这一关我们将要一起学习和体验的内容。</p> 
<pre><code class="language-python"># -*- coding: utf-8 -*-
import urllib.request as req
import re
 
# 国防科技大学本科招生信息网中2016年录取分数网页URL：
url = 'https://www.nudt.edu.cn/bkzs/xxgk/lqfs/6a4ee15ca795454083ed233f502b262b.htm'
 
webpage = req.urlopen(url)      # 根据超链访问链接的网页
data = webpage.read()           # 读取超链网页数据
data = data.decode('utf-8')     # byte类型解码为字符串
 
# 获取网页中的第一个表格中所有内容：
table = re.findall(r'&lt;table(.*?)&lt;/table&gt;', data, re.S)
firsttable = table[0]           # 取网页中的第一个表格
# 数据清洗，将表中的&amp;nbsp，\u3000，和空格号去掉
firsttable = firsttable.replace('&amp;nbsp;', '')
firsttable = firsttable.replace('\u3000', '')
firsttable = firsttable.replace(' ', '')
 
 
def step3():
    score = []
# 请按下面的注释提示添加代码，完成相应功能，若要查看详细html代码，可在浏览器中打开url，查看页面源代码。
#********** Begin *********#
# 1.按tr标签对获取表格中所有行，保存在列表rows中：
    rows = re.findall(r'&lt;tr(.*?)&lt;/tr&gt;', firsttable, re.S)
 
    
    
# 2.迭代rows中的所有元素，获取每一行的td标签内的数据，并把数据组成item列表，将每一个item添加到scorelist列表：
    count = 0
    for i in rows:
        count += 1
        if count == 1 or count == 2:
            continue
        item = []
        tds = re.findall(r'&lt;td(.*?)&lt;/td&gt;', i, re.S)
        count2 = 0
        for j in tds:
            count2 += 1
            p = re.findall(r'&lt;p(.*?)&lt;/p&gt;', j, re.S)
            if count2 == 1:
                sf = re.search(r'[\u4e00-\u9fa5]+', p[0]).group(0)
                item.append(sf)
            elif count2 == 8:
                break
            else:
                try:
                    fs = re.search(r'[1-9]\d*', p[0]).group(0)
                    item.append(fs)
                except:
                    item.append('/')
    
# 3.将由省份，分数组成的8元列表（分数不存在的用/代替）作为元素保存到新列表score中，不要保存多余信息
        score.append(item)
 
    
    
#********** End **********#
    
    return score</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1c5ac2714f0ce3f92f2ac856dcd06687/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">美团2024届秋招笔试第二场编程真题-小美的数组构造</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/448704b0517619131c57047099655fff/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">论文笔记-Deep Learning-Based Change Detection in Remote Sensing Images: A Review（基于深度学习的遥感图像变化检测研究进展）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>