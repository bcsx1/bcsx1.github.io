<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于深度学习的安全帽检测识别系统（含UI界面，yolov8、Python代码，数据集） - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于深度学习的安全帽检测识别系统（含UI界面，yolov8、Python代码，数据集）" />
<meta property="og:description" content="项目介绍 项目中所用到的算法模型和数据集等信息如下：
算法模型： yolov8
yolov8主要包含以下几种创新：
1. 添加注意力机制（SE、CBAM等）
2. 修改可变形卷积（DySnake-主干c3替换、DySnake-所有c3替换）
数据集： 网上下载的数据集，大约5000张左右，详细介绍见数据集介绍部分。
以上是本套代码的整体算法架构和对目标检测模型的修改说明，这些模型修改可以为您的 毕设、作业等提供创新点和增强模型性能的功能 。
如果要是需要更换其他的检测模型，请私信。
注：本项目提供所用到的所有资源，包含 环境安装包、训练代码、测试代码、数据集、视频文件、 界面UI文件等。
如果需要yolov5版本的系统，见此链接：https://blog.csdn.net/qq_28949847/article/details/134492438
项目简介 本文将详细介绍如何使用深度学习中的YOLOv8算法实现对安全帽的检测，并利用PyQt5设计了简约的系统UI界面。在界面中，您可以选择自己的视频文件、图片文件进行检测。此外，您还可以更换自己训练的yolov8模型，进行自己数据的检测。
该系统界面优美，检测精度高，功能强大。它具备多目标实时检测，同时可以自由选择感兴趣的检测目标。
本博文提供了完整的Python程序代码和使用教程，适合新入门的朋友参考。您可以在文末的下载链接中获取完整的代码资源文件。以下是本博文的目录：
目录 项目介绍项目简介效果展示：🌟一、环境安装🌟二、数据集介绍🌟三、 目标检测介绍yolov8相关介绍 四、 yolov8训练步骤五、 yolov8评估步骤六、 训练结果 🌟下载链接 效果展示： 功能：
1. 支持单张图片识别 2. 支持遍历文件夹识别 3. 支持识别视频文件 4. 支持结果导出（xls、csv两种格式） 5. 支持切换检测到的目标 基于深度学习的安全帽检测系统（yolov8）
🌟一、环境安装 本项目提供所有需要的环境安装包（python、pycharm、cuda、torch等），可以直接按照视频讲解进行安装。具体的安装流程见此视频：视频链接
环境安装视频是以车牌项目为例进行讲解的，但是可以适用于任何项目。
视频快进到 3:18 - 21:17，这段时间讲解的是环境安装，可直接快进到此处观看。
环境安装包可通过百度网盘下载：
链接：https://pan.baidu.com/s/17SZHeVZrpXsi513D-6KmQw?pwd=a0gi
提取码：a0gi
–来自百度网盘超级会员V6的分享
上面这个方法，是比较便捷的安装方式（省去了安装细节），按照我的视频步骤和提供的安装包安装即可，如果要是想要多学一点东西，可以按照下面的安装方式走一遍，会更加熟悉。
环境安装方法2: 追求快速安装环境的，只看上面即可！！！
下面列出了5个步骤，是完全从0开始安装（可以理解为是一台新电脑，没有任何环境），如果某些步骤已经安装过的可以跳过。下面的安装步骤带有详细的视频讲解和参考博客，一步一步来即可。另外视频中讲解的安装方法是通用的，可用于任何项目。
python环境安装：B站视频讲解cuda、cudnn安装：B站视频讲解torch安装： B站视频讲解pycharm安装： B站视频讲解第三方依赖包安装： B站视频讲解 按照上面的步骤安装完环境后，就可以直接运行程序，看到效果了。
🌟二、数据集介绍 我们使用的数据集是从网上下载的，其中大多数场景都是实际的工地作业场景。该数据集共有约5000张图像，包含两个类别：helmet（佩戴安全帽）和head（未佩戴安全帽）。这些数据已经转换为YOLO格式，并且已经按照train、val和test的划分进行了准备，因此可以直接拿来使用。
这个数据集采集了各种不同的场景，如建筑工地、工厂车间等，并包含了不同角度、光照条件和人员密集度的图像。这样的多样性使得模型能够在各种真实环境中进行准确的安全帽检测。
为了方便使用，数据集已经进行了标注，并且按照训练集、验证集和测试集的划分进行了组织。您可以直接使用这些数据集进行模型的训练和评估。
下面是一些数据集图片的截图，展示了不同场景下的安全帽和未佩戴安全帽的示例图像，以帮助您更好地了解数据集的内容和质量。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/fa66c0184c7d7e7c9f4794b3df3be9fb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-26T13:42:06+08:00" />
<meta property="article:modified_time" content="2023-12-26T13:42:06+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于深度学习的安全帽检测识别系统（含UI界面，yolov8、Python代码，数据集）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/9f/d6/E7HMbGoD_o.jpg" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/7c/8b/BtQREFml_o.gif" alt="在这里插入图片描述"></p> 
<h2><a id="_5"></a>项目介绍</h2> 
<p>项目中所用到的算法模型和数据集等信息如下：</p> 
<p><font color="blue" size="3"><b>算法模型：<b> </b></b></font><br>     <strong>yolov8</strong></p> 
<p>    yolov8主要包含以下几种创新：<br>         1. 添加注意力机制（<code>SE</code>、<code>CBAM</code>等）<br>         2. 修改可变形卷积（<code>DySnake</code>-主干<code>c3</code>替换、DySnake-所有c3替换）</p> 
<p><font color="green" size="3"><b>数据集：<b> </b></b></font><br>     <strong>网上下载的数据集，大约5000张左右</strong>，详细介绍见数据集介绍部分。</p> 
<p>以上是本套代码的整体算法架构和对目标检测模型的修改说明，这些模型修改可以为您的 <font color="red" size="3"><b>毕设、作业等提供创新点和增强模型性能的功能<b> </b></b></font> 。</p> 
<p><strong>如果要是需要更换其他的检测模型，请私信。</strong></p> 
<p><strong>注：本项目提供所用到的所有资源，包含 <code>环境安装包、训练代码、测试代码、数据集、视频文件、 界面UI文件</code>等。</strong></p> 
<p>如果需要yolov5版本的系统，见此链接：<a href="https://blog.csdn.net/qq_28949847/article/details/134492438">https://blog.csdn.net/qq_28949847/article/details/134492438</a></p> 
<hr> 
<h2><a id="_29"></a>项目简介</h2> 
<p>本文将详细介绍如何使用深度学习中的YOLOv8算法实现对安全帽的检测，并利用PyQt5设计了简约的系统UI界面。在界面中，您可以选择自己的视频文件、图片文件进行检测。此外，您还可以更换自己训练的yolov8模型，进行自己数据的检测。</p> 
<p>该系统界面优美，检测精度高，功能强大。它具备多目标实时检测，同时可以自由选择感兴趣的检测目标。</p> 
<p>本博文提供了完整的Python程序代码和使用教程，适合新入门的朋友参考。您可以在文末的下载链接中获取完整的代码资源文件。以下是本博文的目录：</p> 
<p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#_5" rel="nofollow">项目介绍</a></li><li><a href="#_29" rel="nofollow">项目简介</a></li><li><a href="#_40" rel="nofollow">效果展示：</a></li><li><a href="#_58" rel="nofollow">🌟一、环境安装</a></li><li><a href="#_92" rel="nofollow">🌟二、数据集介绍</a></li><li><a href="#__105" rel="nofollow">🌟三、 目标检测介绍</a></li><li><ul><li><a href="#yolov8_106" rel="nofollow">yolov8相关介绍</a></li></ul> 
  </li><li><a href="#_yolov8_129" rel="nofollow">四、 yolov8训练步骤</a></li><li><ul><li><a href="#_yolov8_163" rel="nofollow">五、 yolov8评估步骤</a></li><li><a href="#__174" rel="nofollow">六、 训练结果</a></li></ul> 
  </li><li><a href="#font_colorred_size5_bb_font_184" rel="nofollow"><font color="red" size="5"><b>🌟下载链接<b> </b></b></font></a></li></ul> 
</div> 
<p></p> 
<h2><a id="_40"></a>效果展示：</h2> 
<p><strong>功能：</strong><br> <font color="FF9900" size="3">1. 支持单张图片识别 </font><br> <font color="98C091" size="3">2. 支持遍历文件夹识别 </font><br> <font color="4DA8EE" size="3">3. 支持识别视频文件 </font><br> <font color="9D36EE" size="3">4. 支持结果导出（xls、csv两种格式） </font><br> <font color="F0678E" size="3">5. 支持切换检测到的目标 </font></p> 
<p></p> 
<div class="csdn-video-box"> 
 <iframe id="hl6DgVPr-1703569274517" frameborder="0" src="https://player.bilibili.com/player.html?aid=835347308" allowfullscreen="true" data-mediaembed="bilibili"></iframe> 
 <p>基于深度学习的安全帽检测系统（yolov8）</p> 
</div> 
<p></p> 
<hr> 
<h2><a id="_58"></a>🌟一、环境安装</h2> 
<p>本项目提供所有需要的环境安装包（<code>python、pycharm、cuda、torch</code>等），可以直接按照视频讲解进行安装。具体的安装流程见此视频：<a href="https://www.bilibili.com/video/BV1eu4y1E7zh/?spm_id_from=333.999.0.0&amp;vd_source=b183d959efa43298bb324ccf00fb30a5" rel="nofollow">视频链接</a><br> 环境安装视频是以车牌项目为例进行讲解的，但是可以适用于任何项目。</p> 
<p>视频快进到 <code>3:18 - 21:17</code>，这段时间讲解的是环境安装，可直接快进到此处观看。<br> <img src="https://images2.imgbox.com/64/6b/ZHgk0uHY_o.png" alt="在这里插入图片描述"></p> 
<p>环境安装包可通过百度网盘下载：<br> 链接：<a href="https://pan.baidu.com/s/17SZHeVZrpXsi513D-6KmQw?pwd=a0gi" rel="nofollow">https://pan.baidu.com/s/17SZHeVZrpXsi513D-6KmQw?pwd=a0gi</a><br> 提取码：a0gi<br> –来自百度网盘超级会员V6的分享</p> 
<p><strong>上面这个方法，是比较便捷的安装方式（省去了安装细节），按照我的视频步骤和提供的安装包安装即可，如果要是想要多学一点东西，可以按照下面的安装方式走一遍，会更加熟悉。</strong></p> 
<p><font color="E6B223" size="3"><strong>环境安装方法2:</strong> </font><br> 追求快速安装环境的，只看上面即可！！！</p> 
<p>下面列出了5个步骤，是完全从0开始安装（可以理解为是一台新电脑，没有任何环境），如果某些步骤已经安装过的可以跳过。下面的安装步骤带有详细的视频讲解和参考博客，一步一步来即可。<code>另外视频中讲解的安装方法是通用的，可用于任何项目</code>。</p> 
<ol><li>python环境安装：<a href="https://www.bilibili.com/video/BV1yw411m7je/?spm_id_from=333.999.0.0" rel="nofollow">B站视频讲解</a></li><li>cuda、cudnn安装：<a href="https://www.bilibili.com/video/BV1qu411u7jG/?spm_id_from=333.999.0.0" rel="nofollow">B站视频讲解</a></li><li>torch安装： <a href="https://www.bilibili.com/video/BV1VC4y1o7c4/?spm_id_from=333.999.0.0&amp;vd_source=b183d959efa43298bb324ccf00fb30a5" rel="nofollow">B站视频讲解</a></li><li>pycharm安装： <a href="https://www.bilibili.com/video/BV1P84y1S7gm/?spm_id_from=333.999.0.0&amp;vd_source=b183d959efa43298bb324ccf00fb30a5" rel="nofollow">B站视频讲解</a></li><li>第三方依赖包安装： <a href="https://www.bilibili.com/video/BV18h4y1h7F1/?spm_id_from=333.999.0.0&amp;vd_source=b183d959efa43298bb324ccf00fb30a5" rel="nofollow">B站视频讲解</a></li></ol> 
<p>按照上面的步骤安装完环境后，就可以直接运行程序，看到效果了。</p> 
<hr> 
<h2><a id="_92"></a>🌟二、数据集介绍</h2> 
<p>我们使用的数据集是从网上下载的，其中大多数场景都是实际的工地作业场景。该数据集共有约<code>5000</code>张图像，包含两个类别：<code>helmet（佩戴安全帽）和head（未佩戴安全帽）</code>。这些数据已经转换为<code>YOLO</code>格式，并且已经按照<code>train、val</code>和<code>test</code>的划分进行了准备，因此可以直接拿来使用。</p> 
<p>这个数据集采集了各种不同的场景，如建筑工地、工厂车间等，并包含了不同角度、光照条件和人员密集度的图像。这样的多样性使得模型能够在各种真实环境中进行准确的安全帽检测。</p> 
<p>为了方便使用，数据集已经进行了标注，并且按照训练集、验证集和测试集的划分进行了组织。您可以直接使用这些数据集进行模型的训练和评估。</p> 
<p>下面是一些数据集图片的截图，展示了不同场景下的安全帽和未佩戴安全帽的示例图像，以帮助您更好地了解数据集的内容和质量。</p> 
<p><img src="https://images2.imgbox.com/62/52/cgSOk4iQ_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<h2><a id="__105"></a>🌟三、 目标检测介绍</h2> 
<h3><a id="yolov8_106"></a>yolov8相关介绍</h3> 
<p>YOLOv8 是一个 SOTA 模型，它建立在以前 YOLO 版本的成功基础上，并引入了新的功能和改进，以进一步提升性能和灵活性。具体创新包括一个新的骨干网络、一个新的 Ancher-Free 检测头和一个新的损失函数，可以在从 CPU 到 GPU 的各种硬件平台上运行。</p> 
<p>不过 ultralytics 并没有直接将开源库命名为 YOLOv8，而是直接使用 ultralytics 这个词，原因是 ultralytics 将这个库定位为算法框架，而非某一个特定算法，一个主要特点是可扩展性。其希望这个库不仅仅能够用于 YOLO 系列模型，而是能够支持非 YOLO 模型以及分类分割姿态估计等各类任务。<br> 总而言之，ultralytics 开源库的两个主要优点是：</p> 
<ul><li> <p><strong>融合众多当前 SOTA 技术于一体</strong></p> </li><li> <p><strong>未来将支持其他 YOLO 系列以及 YOLO 之外的更多算法</strong></p> </li></ul> 
<p><img src="https://images2.imgbox.com/83/f7/trUPkJc7_o.png" alt="在这里插入图片描述"></p> 
<p><strong>网络结构如下：</strong><br> <img src="https://images2.imgbox.com/6b/08/5Se4RTw2_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<h2><a id="_yolov8_129"></a>四、 yolov8训练步骤</h2> 
<p>此代码的训练步骤极其简单，不需要修改代码，直接通过<code>cmd</code>就可以命令运行，命令都已写好，直接复制即可，命令如下图：<br> <img src="https://images2.imgbox.com/a0/ba/cQF684AS_o.png" alt="在这里插入图片描述"><br> 下面这条命令是 训练 添加 CBAM 注意力机制的命令，复制下来，直接就可以运行，看到训练效果（<strong>需要将coco_NEU-DET.yaml替换为自己的数据集的yaml文件</strong>）。</p> 
<pre><code class="prism language-python">python <span class="token punctuation">.</span><span class="token operator">/</span>train<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span>epochs <span class="token number">500</span> <span class="token operator">-</span><span class="token operator">-</span>cfg models<span class="token operator">/</span>yolov5s<span class="token operator">-</span>CBAM<span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span>yaml <span class="token operator">-</span><span class="token operator">-</span>hyp data<span class="token operator">/</span>hyps<span class="token operator">/</span>hyp<span class="token punctuation">.</span>scratch<span class="token operator">-</span>low<span class="token punctuation">.</span>yaml <span class="token operator">-</span><span class="token operator">-</span>data data<span class="token operator">/</span>coco_NEU<span class="token operator">-</span>DET<span class="token punctuation">.</span>yaml <span class="token operator">-</span><span class="token operator">-</span>weight weights<span class="token operator">/</span>yolov5s<span class="token punctuation">.</span>pt <span class="token operator">-</span><span class="token operator">-</span>workers <span class="token number">4</span> <span class="token operator">-</span><span class="token operator">-</span>batch <span class="token number">16</span>
</code></pre> 
<p><strong>执行完上述命令后，即可完成训练，训练过程如下：</strong><br> <img src="https://images2.imgbox.com/1f/48/dlQ4nGvL_o.png" alt="在这里插入图片描述"></p> 
<p><strong>下面是对命令中各个参数的详细解释说明：</strong></p> 
<ul><li> <p><code>python</code>: 这是Python解释器的命令行执行器，用于执行后续的Python脚本。</p> </li><li> <p><code>./train.py</code>: 这是要执行的Python脚本文件的路径和名称，它是用于训练目标检测模型的脚本。</p> </li><li> <p><code>--epochs 500</code>: 这是训练的总轮数（epochs），指定为500，表示训练将运行500个轮次。</p> </li><li> <p><code>--cfg models/yolov5s-CBAM-2.yaml</code>: 这是YOLOv5模型的配置文件的路径和名称，它指定了模型的结构和参数设置。</p> </li><li> <p><code>--hyp data/hyps/hyp.scratch-low.yaml</code>: 这是超参数文件的路径和名称，它包含了训练过程中的各种超参数设置，如学习率、权重衰减等。</p> </li><li> <p><code>--data data/coco_NEU-DET.yaml</code>: 这是数据集的配置文件的路径和名称，它指定了训练数据集的相关信息，如类别标签、图像路径等。</p> </li><li> <p><code>--weight weights/yolov5s.pt</code>: 这是预训练权重文件的路径和名称，用于加载已经训练好的模型权重以便继续训练或进行迁移学习。</p> </li><li> <p><code>--workers 4</code>: 这是用于数据加载的工作进程数，指定为4，表示使用4个工作进程来加速数据加载。</p> </li><li> <p><code>--batch 16</code>: 这是每个批次的样本数，指定为16，表示每个训练批次将包含16个样本。</p> </li></ul> 
<p>通过运行上面这个命令，您将使用YOLOv5模型对目标检测任务进行训练，训练500个轮次，使用指定的配置文件、超参数文件、数据集配置文件和预训练权重。同时，使用4个工作进程来加速数据加载，并且每个训练批次包含16个样本。</p> 
<hr> 
<h3><a id="_yolov8_163"></a>五、 yolov8评估步骤</h3> 
<p>评估步骤同训练步骤一样，执行1行语句即可，注意<code>--weights</code>需要变为自己想要测试的模型路径。</p> 
<pre><code class="prism language-python">python <span class="token punctuation">.</span><span class="token operator">/</span>val<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span>data  data<span class="token operator">/</span>VOC_helmet<span class="token punctuation">.</span>yaml <span class="token operator">-</span><span class="token operator">-</span>weights <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">/</span>weights<span class="token operator">/</span>yolov5s<span class="token punctuation">.</span>yaml<span class="token operator">/</span>weights<span class="token operator">/</span>best<span class="token punctuation">.</span>pt
</code></pre> 
<p><strong>评估结果如下：</strong><br> <img src="https://images2.imgbox.com/79/f4/sOgeJVaC_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<h3><a id="__174"></a>六、 训练结果</h3> 
<p>我们每次训练后，会在 <strong>run/train</strong> 文件夹下出现一系列的文件，如下图所示：<br> <img src="https://images2.imgbox.com/f9/44/8XLBnB1K_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<h2><a id="font_colorred_size5_bb_font_184"></a><font color="red" size="5"><b>🌟下载链接<b> </b></b></font></h2> 
<p>   该代码采用<code>Pycharm</code>+<code>Python3.8</code>开发，经过测试能成功运行，运行界面的主程序为<code>main.py</code>，提供用到的所有程序。为确保程序顺利运行，请按照<code>requirements.txt</code>配置Python依赖包的版本。Python版本：3.8，为避免出现运行报错，请勿使用其他版本，详见<code>requirements.txt</code>文件；</p> 
<p>    若您想获得博文中涉及的实现完整全部程序文件（包括<code>训练代码、测试代码、训练数据、测试数据、视频，py、 UI文件等</code>，如下图），这里已打包上传至博主的<code>面包多</code>平台，<code>可通过下方项目讲解链接中的视频简介部分下载</code>，完整文件截图如下：<br> <img src="https://images2.imgbox.com/31/8f/LSg02Q7b_o.png" alt="在这里插入图片描述"></p> 
<p><strong>项目演示讲解链接</strong>：<a href="https://www.bilibili.com/video/BV1bg4y1k7kH/?spm_id_from=333.999.0.0" rel="nofollow">B站</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4786f677b3df76152a13b298c3aafbc9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Docker安装mysql8.0</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f9460a4b530a2308a34d0430c15f9a29/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">fltk取消 ESC 关闭窗口的回调设置</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>