<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>详解keras中的Mask机制 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="详解keras中的Mask机制" />
<meta property="og:description" content="文章目录 一. Mask背景1.2 例子11.2 例子2 二. 原理三. 方式3.1 配置keras.layers.Embedding 层3.2 添加keras.layers.Masking层3.3 自定义 一. Mask背景 在NLP中，mask使用最为常见。在NLP中，许多句子都有着不同的长度，我们往往需要按照一定的长度, 对句子进行填补和截取操作。 一般使用keras.preprocessing.sequence包中的pad_sequences方法, 在句子前面或者后面补0. 但是这些零是我们不需要的, 只是为了组成可以计算的结构才填补的. 因此计算过程中, 我们希望用mask的思想, 既然所有样本现在都具有了统一长度，那就必须告知模型，数据的某些部分实际上是填充，应该忽略。这种机制就是遮盖（Mask）。
1.2 例子1 如图中所示，Hello world只有两个字符，而I am here有三个字符。因此在转化成list的时候，就需要在第一个list中加入0变成与第二个list相同长度。
1.2 例子2 这里用简单的向量来描述padding的原理。假设有一个长度为5的向量：
x=[1,0,3,4,5]
经过padding变成长度为8： x=[1,0,3,4,5,0,0,0]
当你将这个长度为8的向量输入到模型中时，模型并不知道你这个向量究竟是“长度为8的向量”还是“长度为5的向量，填充了3个无意义的0”。为了表示出哪些是有意义的，哪些是padding的，我们还需要一个mask向量（矩阵）：m=[1,1,1,1,1,0,0,0]
这是一个0/1向量（矩阵），用1表示有意义的部分(True)，用0表示无意义的padding部分(False)。
所谓mask，就是x和m的运算，来排除padding带来的效应。比如我们要求x的均值，本来期望的结果是：
a v g ( x ) = 1 &#43; 0 &#43; 3 &#43; 4 &#43; 55 5 = 12.6 avg(x)=\frac{1&#43;0&#43;3&#43;4&#43;55}{5}=12.6 avg(x)=51&#43;0&#43;3&#43;4&#43;55​=12.6
但是由于向量已经经过padding，直接算的话就得到：
a v g ( x ) = 1 &#43; 0 &#43; 3 &#43; 4 &#43; 55 &#43; 0 &#43; 0 &#43; 0 8 = 7." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/c3aac553423cc14137c4de171a8bd49c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-04-08T21:14:02+08:00" />
<meta property="article:modified_time" content="2021-04-08T21:14:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">详解keras中的Mask机制</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-github-gist">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_Mask_2" rel="nofollow">一. Mask背景</a></li><li><ul><li><a href="#12_1_5" rel="nofollow">1.2 例子1</a></li><li><a href="#12_2_9" rel="nofollow">1.2 例子2</a></li></ul> 
  </li><li><a href="#__27" rel="nofollow">二. 原理</a></li><li><a href="#__31" rel="nofollow">三. 方式</a></li><li><ul><li><a href="#31_keraslayersEmbedding__39" rel="nofollow">3.1 配置keras.layers.Embedding 层</a></li><li><a href="#32_keraslayersMasking_112" rel="nofollow">3.2 添加keras.layers.Masking层</a></li><li><a href="#33__184" rel="nofollow">3.3 自定义</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_Mask_2"></a>一. Mask背景</h2> 
<p>在NLP中，mask使用最为常见。在NLP中，许多句子都有着不同的长度，我们往往需要按照一定的长度, 对句子进行填补和截取操作。 一般使用keras.preprocessing.sequence包中的pad_sequences方法, 在句子前面或者后面补0. 但是这些零是我们不需要的, 只是为了组成可以计算的结构才填补的. <strong>因此计算过程中, 我们希望用mask的思想, 既然所有样本现在都具有了统一长度，那就必须告知模型，数据的某些部分实际上是填充，应该忽略。这种机制就是遮盖（Mask）</strong>。</p> 
<h3><a id="12_1_5"></a>1.2 例子1</h3> 
<p><img src="https://images2.imgbox.com/2f/d3/xnRM4tA7_o.png" alt="在这里插入图片描述"><br> 如图中所示，Hello world只有两个字符，而I am here有三个字符。因此在转化成list的时候，就需要在第一个list中加入0变成与第二个list相同长度。</p> 
<h3><a id="12_2_9"></a>1.2 例子2</h3> 
<p>这里用简单的向量来描述padding的原理。假设有一个长度为5的向量：<br> <code>x=[1,0,3,4,5]</code></p> 
<p>经过padding变成长度为8： <code>x=[1,0,3,4,5,0,0,0]</code></p> 
<p>当你将这个长度为8的向量输入到模型中时，模型并不知道你这个向量究竟是“<strong>长度为8的向量”还是“长度为5的向量，填充了3个无意义的0</strong>”。为了表示出哪些是有意义的，哪些是padding的，我们还需要一个mask向量（矩阵）：<code>m=[1,1,1,1,1,0,0,0]</code></p> 
<p>这是一个0/1向量（矩阵），用1表示有意义的部分(True)，用0表示无意义的padding部分(False)。<br> 所谓mask，就是<code>x</code>和<code>m</code>的运算，来排除padding带来的效应。比如我们要求x的均值，本来期望的结果是：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          a 
         
        
          v 
         
        
          g 
         
        
          ( 
         
        
          x 
         
        
          ) 
         
        
          = 
         
         
          
          
            1 
           
          
            + 
           
          
            0 
           
          
            + 
           
          
            3 
           
          
            + 
           
          
            4 
           
          
            + 
           
          
            55 
           
          
         
           5 
          
         
        
          = 
         
        
          12.6 
         
        
       
         avg(x)=\frac{1+0+3+4+55}{5}=12.6 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.03588em;">v</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.00744em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">5</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">0</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">3</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">4</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">5</span><span class="mord">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span><span class="mord">2</span><span class="mord">.</span><span class="mord">6</span></span></span></span></span></span><br> 但是由于向量已经经过padding，直接算的话就得到：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          a 
         
        
          v 
         
        
          g 
         
        
          ( 
         
        
          x 
         
        
          ) 
         
        
          = 
         
         
          
          
            1 
           
          
            + 
           
          
            0 
           
          
            + 
           
          
            3 
           
          
            + 
           
          
            4 
           
          
            + 
           
          
            55 
           
          
            + 
           
          
            0 
           
          
            + 
           
          
            0 
           
          
            + 
           
          
            0 
           
          
         
           8 
          
         
        
          = 
         
        
          7.875 
         
        
       
         avg(x)=\frac{1+0+3+4+55+0+0+0}{8}=7.875 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.03588em;">v</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.00744em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">8</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">0</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">3</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">4</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">5</span><span class="mord">5</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">0</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">0</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">7</span><span class="mord">.</span><span class="mord">8</span><span class="mord">7</span><span class="mord">5</span></span></span></span></span></span><br> 会带来偏差。更严重的是，对于同一个输入，每次padding的零的数目可能是不固定的，因此同一个样本每次可能得到不同的均值，这是很不合理的。有了mask向量m之后，我们可以重写求均值的运算：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          a 
         
        
          v 
         
        
          g 
         
        
          ( 
         
        
          x 
         
        
          ) 
         
        
          = 
         
         
          
          
            s 
           
          
            u 
           
          
            m 
           
          
            ( 
           
          
            x 
           
          
            ⊗ 
           
          
            m 
           
          
            ) 
           
          
          
          
            s 
           
          
            u 
           
          
            m 
           
          
            ( 
           
          
            m 
           
          
            ) 
           
          
         
        
       
         avg(x)=\frac{sum(x⊗m)}{sum(m)} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.03588em;">v</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.363em; vertical-align: -0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.427em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="mord mathdefault">u</span><span class="mord mathdefault">m</span><span class="mopen">(</span><span class="mord mathdefault">m</span><span class="mclose">)</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="mord mathdefault">u</span><span class="mord mathdefault">m</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">⊗</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord mathdefault">m</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.936em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 这里的⊗是逐位对应相乘的意思。这样一来，分子只对非padding部分求和，分母则是对非padding部分计数，不管你padding多少个零，最终算出来的结果都是一样的。</p> 
<h2><a id="__27"></a>二. 原理</h2> 
<p>在keras中, Tensor在各层之间传递, Layer对象接受的上层Layer得到的Tensor, 输出经过处理后的Tensor。<strong>Keras是用一个mask矩阵来参与到计算当中, 决定在计算中屏蔽哪些位置的值。</strong> 因此<strong>mask矩阵其中的值就是True/False</strong>, 其形状一般与对应的Tensor相同. 同样与Tensor相同的是, mask矩阵也会在每层Layer被处理, 得到传入到下一层的mask情况。</p> 
<p>mask矩阵如上文例2中，m=[1,1,1,1,1,0,0,0]所示，其中1为True，0为False。</p> 
<h2><a id="__31"></a>三. 方式</h2> 
<p>在 Keras 模型中引入输入掩码(Mask)有三种方式：</p> 
<ul><li>使用 mask_zero=True 配置一个keras.layers.Embedding 层。</li><li>添加一个 keras.layers.Masking 层</li><li>在调用支持 mask 参数的层（如 RNN 层）时，手动传递此参数。</li></ul> 
<h3><a id="31_keraslayersEmbedding__39"></a>3.1 配置keras.layers.Embedding 层</h3> 
<hr> 
<p>首先，先了解一下Embedding层<br> 假如现在有这么两句话</p> 
<pre><code class="prism language-python">Hope to see you soon
Nice to see you again
</code></pre> 
<p>在神经网络中，我们将这个作为输入，一般就会将每个单词用一个正整数代替，这样，上面的两句话在输入中是这样的</p> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>

<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span>
</code></pre> 
<p>在神经网络中，第一层是</p> 
<pre><code class="prism language-python">Embedding<span class="token punctuation">(</span>input_dim<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> output_dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> input_length<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>其中，第一个参数是input_dim，值为7，代表的是单词表的长度；第二个参数是output_dim，值为2，代表输出后向量长度为2；第三个参数是input_length，值为5，代表输入序列的长度。</strong></p> 
<p>一旦神经网络被训练了，Embedding层就会被赋予一个权重，计算出来的结果如下：</p> 
<pre><code class="prism language-python"><span class="token operator">+</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>   index    <span class="token operator">|</span>  Embedding <span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">+</span>
<span class="token operator">|</span>     <span class="token number">0</span>      <span class="token operator">|</span> <span class="token punctuation">[</span><span class="token number">1.2</span><span class="token punctuation">,</span> <span class="token number">3.1</span><span class="token punctuation">]</span> <span class="token operator">|</span>
<span class="token operator">|</span>     <span class="token number">1</span>      <span class="token operator">|</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">4.2</span><span class="token punctuation">]</span> <span class="token operator">|</span>
<span class="token operator">|</span>     <span class="token number">2</span>      <span class="token operator">|</span> <span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">3.1</span><span class="token punctuation">]</span> <span class="token operator">|</span>
<span class="token operator">|</span>     <span class="token number">3</span>      <span class="token operator">|</span> <span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">2.1</span><span class="token punctuation">]</span> <span class="token operator">|</span>
<span class="token operator">|</span>     <span class="token number">4</span>      <span class="token operator">|</span> <span class="token punctuation">[</span><span class="token number">2.2</span><span class="token punctuation">,</span> <span class="token number">1.4</span><span class="token punctuation">]</span> <span class="token operator">|</span>
<span class="token operator">|</span>     <span class="token number">5</span>      <span class="token operator">|</span> <span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">1.7</span><span class="token punctuation">]</span> <span class="token operator">|</span>
<span class="token operator">|</span>     <span class="token number">6</span>      <span class="token operator">|</span> <span class="token punctuation">[</span><span class="token number">4.1</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">]</span> <span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">+</span>
</code></pre> 
<p>根据这个权重，第二个输入计算出来的embedding vector就是下面这个，shape为(input_length，output_dim)=(5,2)：</p> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">1.7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">4.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">3.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">2.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4.1</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
<hr> 
<p><strong>来自<a href="https://blog.csdn.net/songbinxu/article/details/80150019">Keras Embedding层详解</a>的例子,解释其中迷惑的点。</strong><br> 若令mask_zero=True，则注意input_dim应该加一，例如原本ID类取值为0到5，为了实现padding，ID取值范围变成1到6，则此时input_dim=6+1=7。<br> 下面给出一个例子，我们准备了四个ID列表型样本，经过了padding补零到长度4，为了方便展示，我们让所有非零ID相同。在Embedding层中设置mask_zero=True，然后调用自定义的MeanPooling层（<a href="https://blog.csdn.net/songbinxu/article/details/80148856">见这里</a>）。如果masking起作用，则输出的result应该是一个4x3矩阵，且所有行向量相同。<br> MyMeanPool()层就是把每个样本按行求平均值，具体例子看上述的例子2。如果应用Masking机制（mask_zero=True），对四个样本直接按行求平均值：<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          M 
         
        
          e 
         
        
          a 
         
         
         
           n 
          
          
          
            s 
           
          
            e 
           
          
            q 
           
          
            0 
           
          
         
        
          = 
         
         
         
           1 
          
         
           1 
          
         
        
          = 
         
        
          1 
         
        
       
         Mean_{seq0}=\frac{1}{1}=1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">q</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.00744em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          M 
         
        
          e 
         
        
          a 
         
         
         
           n 
          
          
          
            s 
           
          
            e 
           
          
            q 
           
          
            1 
           
          
         
        
          = 
         
         
          
          
            1 
           
          
            + 
           
          
            1 
           
          
         
           2 
          
         
        
          = 
         
        
          1 
         
        
       
         Mean_{seq1}=\frac{1+1}{2}=1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">q</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.00744em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">2</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          M 
         
        
          e 
         
        
          a 
         
         
         
           n 
          
          
          
            s 
           
          
            e 
           
          
            q 
           
          
            2 
           
          
         
        
          = 
         
         
          
          
            1 
           
          
            + 
           
          
            1 
           
          
            + 
           
          
            1 
           
          
         
           3 
          
         
        
          = 
         
        
          1 
         
        
       
         Mean_{seq2}=\frac{1+1+1}{3}=1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">q</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.00744em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">3</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          M 
         
        
          e 
         
        
          a 
         
         
         
           n 
          
          
          
            s 
           
          
            e 
           
          
            q 
           
          
            3 
           
          
         
        
          = 
         
         
          
          
            1 
           
          
            + 
           
          
            1 
           
          
            + 
           
          
            1 
           
          
            + 
           
          
            1 
           
          
         
           4 
          
         
        
          = 
         
        
          1 
         
        
       
         Mean_{seq3}=\frac{1+1+1+1}{4}=1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">q</span><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.00744em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">4</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span></span> 则结果相同，都为1。先经过Embedding生成一个（4，3）的Embedding矩阵，维度为（4，3）是因为(input_length，output_dim)=(4,3)，再经过MyMeanPool(axis=1)后按行求平均值, 因此所有的行向量应该相同。</p> 
<pre><code class="prism language-python"><span class="token comment">#四个ID列表型样本，经过padding</span>
ID_seq0 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
ID_seq1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
ID_seq2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
ID_seq3 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>ID_seq0<span class="token punctuation">,</span> ID_seq1<span class="token punctuation">,</span> ID_seq2<span class="token punctuation">,</span> ID_seq3<span class="token punctuation">]</span><span class="token punctuation">)</span>

model <span class="token operator">=</span>  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_dim<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> output_dim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> input_length<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> mask_zero<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MyMeanPool<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

result <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token comment">#为输入样本生成输出预测</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
</code></pre> 
<p>输出结果如下，这些数值都是Embedding层随机生成的权值而已。</p> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00347356</span> <span class="token operator">-</span><span class="token number">0.03284906</span> <span class="token operator">-</span><span class="token number">0.03016986</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00347356</span> <span class="token operator">-</span><span class="token number">0.03284906</span> <span class="token operator">-</span><span class="token number">0.03016986</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00347356</span> <span class="token operator">-</span><span class="token number">0.03284906</span> <span class="token operator">-</span><span class="token number">0.03016986</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.00347356</span> <span class="token operator">-</span><span class="token number">0.03284906</span> <span class="token operator">-</span><span class="token number">0.03016986</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
<h3><a id="32_keraslayersMasking_112"></a>3.2 添加keras.layers.Masking层</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Input<span class="token punctuation">,</span> Masking
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Model
<span class="token keyword">from</span> MyMeanPooling <span class="token keyword">import</span> MyMeanPool

data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span> <span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span> <span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span> <span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">,</span><span class="token number">40</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

A <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># None * 4 * 2</span>
mA <span class="token operator">=</span> Masking<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span>
out <span class="token operator">=</span> MyMeanPool<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>mA<span class="token punctuation">)</span>

model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span><span class="token punctuation">[</span>A<span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span><span class="token punctuation">[</span>out<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span> model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre> 
<p>结果如下，每一行对应一个样本的结果，例如第一个样本只有第一个时刻有值，输出结果是[10. 10. ]，是正确的。</p> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">.</span> <span class="token number">15</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">.</span> <span class="token number">20</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">.</span> <span class="token number">25</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
<p>例2:</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

raw_inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">83</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">645</span><span class="token punctuation">,</span> <span class="token number">1253</span><span class="token punctuation">,</span> <span class="token number">927</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">73</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">3215</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">927</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">711</span><span class="token punctuation">,</span> <span class="token number">632</span><span class="token punctuation">,</span> <span class="token number">71</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
padded_input <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>raw_inputs<span class="token punctuation">,</span> maxlen<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                                                             dtype<span class="token operator">=</span><span class="token string">'int32'</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'post'</span><span class="token punctuation">,</span>
                                                             truncating<span class="token operator">=</span><span class="token string">'post'</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>padded_input<span class="token punctuation">)</span>

embedding_layer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_dim<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">,</span> output_dim<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> mask_zero<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

masked_output <span class="token operator">=</span> embedding_layer<span class="token punctuation">(</span>padded_input<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Shape of masked input passed through embedding: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>padded_input<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Shape of Embeding output: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>masked_output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Shape of mask attached to this input: {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>masked_output<span class="token punctuation">.</span>_keras_mask<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Original input: \n{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>padded_input<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'attached Mask: \n{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>masked_output<span class="token punctuation">.</span>_keras_mask<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Using Masking layer:</span>
masking_layer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Masking<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># simulate the embedding look up by expanding the 2D input to 3D</span>
<span class="token comment"># with embedding dimension of 10</span>
mask_value <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">.</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> mask_value

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nUsing masking layer...'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Unmasked embedding: \n {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>

masked_embedding <span class="token operator">=</span> masking_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>masked_embedding<span class="token punctuation">.</span>_keras_mask<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>masked_embedding<span class="token punctuation">.</span>_keras_mask<span class="token punctuation">)</span>
</code></pre> 
<p>输出：<br> <img src="https://images2.imgbox.com/e1/63/MdscfRlO_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="33__184"></a>3.3 自定义</h3> 
<p>更多的，我们还是在自定义的层中，需要支持mask的操作，因此需要对应的逻辑。<br> 如果我们希望自定义的这个层支持mask操作，就需要在__init__方法中指定</p> 
<pre><code class="prism language-python">self<span class="token punctuation">.</span>supports_masking <span class="token operator">=</span> <span class="token boolean">True</span>
</code></pre> 
<p>如果在本层计算中需要使用到mask，则call方法需要多传入一个mask参数，即</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>inputs<span class="token punctuation">,</span>mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">pass</span>
</code></pre> 
<p>然后，如果还要继续输出mask，供之后的层使用，如果不对mask矩阵进行变换，这不用进行任何操作，否则就需要实现compute_mask函数</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">compute_mask</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>inputs<span class="token punctuation">,</span>mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">pass</span>
	
</code></pre> 
<p>这里的inputs就是输入的Tensor,与call方法中接收到的一样，mask就是上层传入的mask矩阵。<br> 如果希望mask到此为止，之后的层不再使用，则该函数直接返回None即可。</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">compute_mask</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>inputs<span class="token punctuation">,</span>mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">return</span>  <span class="token boolean">None</span>
</code></pre> 
<p>例子：<strong>在上文中的MyMeanpooling层，就是自定义的Masking：</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> keras <span class="token keyword">import</span> backend <span class="token keyword">as</span> K
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>engine<span class="token punctuation">.</span>topology <span class="token keyword">import</span> Layer
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

<span class="token keyword">class</span> <span class="token class-name">MyMeanPool</span><span class="token punctuation">(</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> axis<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>supports_masking <span class="token operator">=</span> <span class="token boolean">True</span>
        self<span class="token punctuation">.</span>axis <span class="token operator">=</span> axis
        <span class="token builtin">super</span><span class="token punctuation">(</span>MyMeanPool<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">compute_mask</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> input_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># need not to pass the mask to next layers</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> mask <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            mask <span class="token operator">=</span> K<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>mask<span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            mask <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>mask<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            mask <span class="token operator">=</span> K<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>mask<span class="token punctuation">,</span> K<span class="token punctuation">.</span>floatx<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> x <span class="token operator">*</span> mask
            <span class="token keyword">return</span> K<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span>self<span class="token punctuation">.</span>axis<span class="token punctuation">)</span> <span class="token operator">/</span> K<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>mask<span class="token punctuation">,</span> axis<span class="token operator">=</span>self<span class="token punctuation">.</span>axis<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> K<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span>self<span class="token punctuation">.</span>axis<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">compute_output_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        output_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span>self<span class="token punctuation">.</span>axis<span class="token punctuation">:</span>
                output_shape<span class="token punctuation">.</span>append<span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token builtin">tuple</span><span class="token punctuation">(</span>output_shape<span class="token punctuation">)</span>
</code></pre> 
<p><strong>参考资料</strong></p> 
<ol><li><a href="https://blog.csdn.net/znevegiveup1/article/details/114552725?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-8.control&amp;dist_request_id=&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-8.control">keras中的compute_mask函数讲解</a></li><li><a href="https://blog.csdn.net/songbinxu/article/details/80148856">Keras自定义实现带masking的meanpooling层</a></li></ol>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/00cfce979831547c04343161e3546d98/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">cuda : 依赖: cuda-11-1 (＞= 11.1.0) 但是它将不会被安装</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2910522f0490a0134f5b3761843fd94c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux查看docker容器日志后退出</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>