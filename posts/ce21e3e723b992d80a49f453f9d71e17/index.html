<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>朴素贝叶斯中文分类 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="朴素贝叶斯中文分类" />
<meta property="og:description" content="朴素贝叶斯中文分类 朴素贝叶斯分类算法是基于概率的分类算法，实现思路相当简单，但是在某些情况下分类效果却十分理想，因此将介绍基于朴素贝叶斯分类算法实现中文分类的过程。
内容包括朴素贝叶斯分类算法概述、机器学习库sklearn及案例实现——朴素贝叶斯中文分类。
朴素贝叶斯分类算法 概述 朴素贝叶斯分类算法是在所有相关概率均已知的前提下，对未知类别的数据计算出最优类别标签的算法。因此，概率是朴素贝叶斯分类算法运行的基础，特别是随机变量的先验概率、条件概率及联合概率。
贝叶斯公式可以灵活应用在未知事物的分类当中，只要知道相应事件的概率，就可以计算出某一个事物属于某一个分类的概率。
一所学校里面有60%的学生为男生，40%的学生为女生。
已知男生总是穿裤子，女生则一半穿裤子，一半穿裙子。
假设走在该校园中遇到一位穿裤子的学生，请计算该学生为女生的概率。
该问题是一个已经知道结果，且知道相应概率，推测导致该结果的原因的典型问题，其中除了明显给出的数据P(Boy)=60%和P(Girl)=40%，还隐含着一些已知的数据，如穿裤子的男生概率P(Pants|Boy)=100%，穿裤子与穿裙子的女生概率为P(Pants|Girl)=P(Skirt|Girl)=50%，现分析如下。
设该学校的总人数为N，则有：
(1)男生中穿裤子的人数为N×P(Boy)×P(Pants|Boy)=N×60%×100%；
(2)女生中穿裤子的人数为N×P(Girl)×P(Pants|Girl)=N×40%×50%；
(3)穿裤子的总人数为N×P(Boy)×P(Pants|Boy)&#43;N×P(Girl)×P(Pants|Girl)。
我们的目的是求出P(Girl|Pants)，即：
将各数据代入式
同理
把相关数据代入式，可计算出P(Boy|Pants)=0.75。
那到底应该把该学生预测为男生还是女生呢？
从以上计算可看出，该学生为男生的概率要大于女生，因此可以大胆预测该学生为男生。
将以上问题一般化：当在该校园当中遇到一位穿裤子的学生时，可以计算出该学生为男生或女生的概率，概率大的则作为最终的决策结果，男生或女生可以理解为分类，即将穿裤子的学生分类为男生或女生两个类别，这就是贝叶斯分类器的理论基础。
应用 朴素贝叶斯可以用来过滤垃圾文本，如识别垃圾邮件、检测社区评论信息等；也可以用在情感判别方面，如微博的褒贬情绪、电商评论信息的情感判断等；还可以用在文本分类方面，如新闻文档的自动识别等。
机器学习库sklearn sklearn（全称为scikit-learn）是在numpy、scipy、matplotlib等数据科学工具包基础上构建的Python机器学习库，包括数据集获取、数据预处理、模型构建与验证、特征选择、分类、回归、聚类、降维等机器学习的多个方面，功能十分强大，是Python机器学习的首选库。
sklearn获取数据 为了快速便捷地搭建机器学习任务，sklearn库提供了多个经典的数据集，目前所提供的数据集主要针对分类与回归两个任务。要使用sklearn提供的数据集，首先要导入数据集模块datasets，语法为from sklearn import datasets，该模块可以使用“load_”开头的函数加载一些数据集，如：
(1)load_breast_cancer()，加载乳腺癌数据集，特征为连续数值，标签为0或1，可用于二分类任务；
(2)load_iris()，加载鸢尾花数据集，特征为连续数值，标签为0、1、2，各类样本数量均衡（均为50个），可用于三分类任务；
(3)load_wine()，红酒数据集，特征为连续数值，可用于三分类任务，各类样本数稍有区别；
(4)load_digits()，手写数字数据集，包含0～9共10个标签，各类样本数均衡，特征是离散数值；
(5)load_boston()，波士顿房价数据集，特征为连续数值，常用于回归任务。
还可以使用“make_”开头的函数自定义数据集，以及使用“fetch_”开头的函数额外下载数据集，为更多的学习任务提供便利。
sklearn数据预处理 在使用sklearn构建机器学习模型时，需要对输入数据的格式进行处理以满足模型输入对数据的要求，一般要处理成numpy的array格式或pandas的dataframe格式。此时，往往需要进行数据的预处理，包括将数据集当中字符串类型的标签转化为离散值，当各个特征数值量纲不同时要去除量纲，当特征数值差别较大时要进行标准化等。为此，sklearn提供了常用的数据预处理功能，包含在sklearn的preprocessing模块当中，简单举例如下：
(1)MinMaxScaler，最大最小值归一化，主要用于去除量纲，适用于数据有明显的跨度，且数据较为正常，不存在严重异常值的处理场景；
(2)StandardScaler，数据的标准化处理，将数据处理成符合标准正态分布的标准数据，同样可用于去除量纲，对于存在极大或极小值的情况尤为适用；
(3)Binarizer，二值化处理，可将连续特征值转化为离散值；
(4)OneHotEncoder，独热编码，经典的编码方式，可将离散标签转化为使用“0”或“1”构成的一系列二进制数值；
(5)Ordinary，数值编码方式，可用于将标签转化为常规数值。
sklearn构建模型 使用sklearn构建模型是十分方便的，因为其提供了丰富的机器学习算法，主要为分类和回归两个大类型。可以使用sklearn构建五种模型：
(1)线性模型，线性回归或逻辑回归，前者用于线性回归分析，后者通过线性回归拟合对数概率来实现二分类；
(2)K近邻模型，不需要进行训练，通过测试样本周围的多个样本判断类别或拟合数值结果；
(3)支持向量机模型，最经典的机器学习模型，通过最大化间隔寻找最佳的分类边界；
(4)朴素贝叶斯模型，基于贝叶斯公式，通过训练模型来拟合出数据集特征的概率分布，并计算出测试集可能属于的类别的概率，将概率最大的类别作为最终预测结果，是纯粹依据概率完成分类任务的模型；
(5)决策树模型，是强大的机器学习模型，模型的训练过程主要包括特征选择、数据划分、模型剪枝三个步骤，主要包括三个算法，分别是ID3、C4.5和CART。
(1)～(3)和(5)既可以用在分类任务上，也可以用在回归任务当中，但是朴素贝叶斯模型只能用于分类任务。
案例实现——朴素贝叶斯中文分类 使用sklearn构建朴素贝叶斯模型，完成对四种类型文本的分类，并实现对未来文档的分类预测。
案例目标 (1)理解文本分类数据的处理思路。
(2)理解朴素贝叶斯工作原理。
(3)掌握使用sklearn模块构建朴素贝叶斯模型的方法。
案例环境 jiebascikit-learn stop_word文件夹存放的是停用词文件stopword.txt。停用词是一些使用非常普遍的词语，对文档分析作用不大，如你、我、他、它、的、了等，一般在文档分析之前需要将停用词去除。可将停用词保存在一个文件中，当需要时读取。
train_data文件夹存放的是训练文本数据。
test_data文件夹存储的是测试数据。不管是训练数据还是测试数据，都是一些新闻数据，每条数据都包含了新闻类型和新闻标题，新闻类型包含财经类、娱乐类、健康类和体育类四种类型，数据以“—”分隔，左边为新闻类型，右边为新闻标题。
案例步骤 (1)text_classification.py构建文本分类模型；
# coding=utf-8 import os import jieba import joblib from sklearn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/ce21e3e723b992d80a49f453f9d71e17/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-07T22:43:14+08:00" />
<meta property="article:modified_time" content="2023-05-07T22:43:14+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">朴素贝叶斯中文分类</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>朴素贝叶斯中文分类</h2> 
<p>朴素贝叶斯分类算法是基于<strong>概率</strong>的分类算法，实现思路相当简单，但是在某些情况下分类效果却十分理想，因此将介绍基于朴素贝叶斯分类算法实现中文分类的过程。</p> 
<p>内容包括朴素贝叶斯分类算法概述、机器学习库sklearn及案例实现——朴素贝叶斯中文分类。</p> 
<h3><a id="_6"></a>朴素贝叶斯分类算法</h3> 
<h4><a id="_8"></a>概述</h4> 
<p>朴素贝叶斯分类算法是在所有相关概率均已知的前提下，对未知类别的数据计算出最优类别标签的算法。因此，概率是朴素贝叶斯分类算法运行的基础，特别是随机变量的先验概率、条件概率及联合概率。</p> 
<p>贝叶斯公式可以灵活应用在未知事物的分类当中，只要知道相应事件的概率，就可以计算出某一个事物属于某一个分类的概率。</p> 
<p><strong>一所学校里面有60%的学生为男生，40%的学生为女生。</strong></p> 
<p><strong>已知男生总是穿裤子，女生则一半穿裤子，一半穿裙子。</strong></p> 
<p><strong>假设走在该校园中遇到一位穿裤子的学生，请计算该学生为女生的概率。</strong></p> 
<p>该问题是一个已经知道结果，且知道相应概率，推测导致该结果的原因的典型问题，其中除了明显给出的数据P(Boy)=60%和P(Girl)=40%，还隐含着一些已知的数据，如穿裤子的男生概率P(Pants|Boy)=100%，穿裤子与穿裙子的女生概率为P(Pants|Girl)=P(Skirt|Girl)=50%，现分析如下。</p> 
<p>设该学校的总人数为N，则有：</p> 
<p>(1)男生中穿裤子的人数为N×P(Boy)×P(Pants|Boy)=N×60%×100%；</p> 
<p>(2)女生中穿裤子的人数为N×P(Girl)×P(Pants|Girl)=N×40%×50%；</p> 
<p>(3)穿裤子的总人数为N×P(Boy)×P(Pants|Boy)+N×P(Girl)×P(Pants|Girl)。</p> 
<p>我们的目的是求出P(Girl|Pants)，即：</p> 
<p><img src="https://images2.imgbox.com/62/fb/KGD7nUNK_o.png" alt="在这里插入图片描述"></p> 
<p>将各数据代入式</p> 
<p><img src="https://images2.imgbox.com/78/37/B3mqPXUV_o.png" alt="在这里插入图片描述"></p> 
<p>同理</p> 
<p><img src="https://images2.imgbox.com/a5/b1/EDFaRRYA_o.png" alt="在这里插入图片描述"></p> 
<p>把相关数据代入式，可计算出P(Boy|Pants)=0.75。</p> 
<p>那到底应该把该学生预测为男生还是女生呢？</p> 
<p>从以上计算可看出，<strong>该学生为男生的概率要大于女生，因此可以大胆预测该学生为男生。</strong></p> 
<p>将以上问题一般化：<strong>当在该校园当中遇到一位穿裤子的学生时，可以计算出该学生为男生或女生的概率，概率大的则作为最终的决策结果，男生或女生可以理解为分类，即将穿裤子的学生分类为男生或女生两个类别，这就是贝叶斯分类器的理论基础。</strong></p> 
<h4><a id="_53"></a>应用</h4> 
<p><strong>朴素贝叶斯可以用来过滤垃圾文本，如识别垃圾邮件、检测社区评论信息等；也可以用在情感判别方面，如微博的褒贬情绪、电商评论信息的情感判断等；还可以用在文本分类方面，如新闻文档的自动识别等。</strong></p> 
<h3><a id="sklearn_57"></a>机器学习库sklearn</h3> 
<p>sklearn（全称为scikit-learn）是在numpy、scipy、matplotlib等数据科学工具包基础上构建的Python机器学习库，包括数据集获取、数据预处理、模型构建与验证、特征选择、分类、回归、聚类、降维等机器学习的多个方面，功能十分强大，是Python机器学习的首选库。</p> 
<h4><a id="sklearn_61"></a>sklearn获取数据</h4> 
<p>为了快速便捷地搭建机器学习任务，sklearn库提供了多个经典的数据集，目前所提供的数据集主要针对分类与回归两个任务。要使用sklearn提供的数据集，首先要导入数据集模块datasets，语法为from sklearn import datasets，该模块可以使用“load_”开头的函数加载一些数据集，如：</p> 
<p>(1)<strong>load_breast_cancer()</strong>，加载乳腺癌数据集，特征为连续数值，标签为0或1，可用于二分类任务；</p> 
<p>(2)<strong>load_iris()</strong>，加载鸢尾花数据集，特征为连续数值，标签为0、1、2，各类样本数量均衡（均为50个），可用于三分类任务；</p> 
<p>(3)<strong>load_wine()</strong>，红酒数据集，特征为连续数值，可用于三分类任务，各类样本数稍有区别；</p> 
<p>(4)<strong>load_digits()</strong>，手写数字数据集，包含0～9共10个标签，各类样本数均衡，特征是离散数值；</p> 
<p>(5)<strong>load_boston()</strong>，波士顿房价数据集，特征为连续数值，常用于回归任务。</p> 
<p>还可以使用“make_”开头的函数自定义数据集，以及使用“fetch_”开头的函数额外下载数据集，为更多的学习任务提供便利。</p> 
<h4><a id="sklearn_77"></a>sklearn数据预处理</h4> 
<p>在使用sklearn构建机器学习模型时，需要对输入数据的格式进行处理以满足模型输入对数据的要求，一般要处理成numpy的array格式或pandas的dataframe格式。此时，往往需要进行数据的预处理，包括将数据集当中字符串类型的标签转化为离散值，当各个特征数值量纲不同时要去除量纲，当特征数值差别较大时要进行标准化等。为此，sklearn提供了常用的数据预处理功能，包含在sklearn的preprocessing模块当中，简单举例如下：</p> 
<p>(1)<strong>MinMaxScaler</strong>，最大最小值归一化，主要用于去除量纲，适用于数据有明显的跨度，且数据较为正常，不存在严重异常值的处理场景；</p> 
<p>(2)<strong>StandardScaler</strong>，数据的标准化处理，将数据处理成符合标准正态分布的标准数据，同样可用于去除量纲，对于存在极大或极小值的情况尤为适用；</p> 
<p>(3)<strong>Binarizer</strong>，二值化处理，可将连续特征值转化为离散值；</p> 
<p>(4)<strong>OneHotEncoder</strong>，独热编码，经典的编码方式，可将离散标签转化为使用“0”或“1”构成的一系列二进制数值；</p> 
<p>(5)<strong>Ordinary</strong>，数值编码方式，可用于将标签转化为常规数值。</p> 
<h4><a id="sklearn_91"></a>sklearn构建模型</h4> 
<p>使用sklearn构建模型是十分方便的，因为其提供了丰富的机器学习算法，主要为分类和回归两个大类型。可以使用sklearn构建五种模型：</p> 
<p>(1)<strong>线性模型</strong>，线性回归或逻辑回归，前者用于线性回归分析，后者通过线性回归拟合对数概率来实现二分类；</p> 
<p>(2)<strong>K近邻模型</strong>，不需要进行训练，通过测试样本周围的多个样本判断类别或拟合数值结果；</p> 
<p>(3)<strong>支持向量机模型</strong>，最经典的机器学习模型，通过最大化间隔寻找最佳的分类边界；</p> 
<p>(4)<strong>朴素贝叶斯模型</strong>，基于贝叶斯公式，通过训练模型来拟合出数据集特征的概率分布，并计算出测试集可能属于的类别的概率，将概率最大的类别作为最终预测结果，是纯粹依据概率完成分类任务的模型；</p> 
<p>(5)<strong>决策树模型</strong>，是强大的机器学习模型，模型的训练过程主要包括特征选择、数据划分、模型剪枝三个步骤，主要包括三个算法，分别是ID3、C4.5和CART。</p> 
<blockquote> 
 <p>(1)～(3)和(5)既可以用在分类任务上，也可以用在回归任务当中，但是朴素贝叶斯模型只能用于分类任务。</p> 
</blockquote> 
<h3><a id="_107"></a>案例实现——朴素贝叶斯中文分类</h3> 
<p>使用sklearn构建朴素贝叶斯模型，完成对四种类型文本的分类，并实现对未来文档的分类预测。</p> 
<h4><a id="_111"></a>案例目标</h4> 
<p>(1)理解文本分类数据的处理思路。</p> 
<p>(2)理解朴素贝叶斯工作原理。</p> 
<p>(3)掌握使用sklearn模块构建朴素贝叶斯模型的方法。</p> 
<h4><a id="_119"></a>案例环境</h4> 
<ul><li>jieba</li><li>scikit-learn</li></ul> 
<p><strong>stop_word</strong>文件夹存放的是停用词文件stopword.txt。停用词是一些使用非常普遍的词语，对文档分析作用不大，如你、我、他、它、的、了等，一般在文档分析之前需要将停用词去除。可将停用词保存在一个文件中，当需要时读取。</p> 
<p><strong>train_data</strong>文件夹存放的是训练文本数据。</p> 
<p><strong>test_data</strong>文件夹存储的是测试数据。不管是训练数据还是测试数据，都是一些新闻数据，每条数据都包含了新闻类型和新闻标题，新闻类型包含财经类、娱乐类、健康类和体育类四种类型，数据以“—”分隔，左边为新闻类型，右边为新闻标题。</p> 
<h4><a id="_130"></a>案例步骤</h4> 
<p>(1)text_classification.py构建文本分类模型；</p> 
<pre><code class="prism language-python"><span class="token comment"># coding=utf-8</span>


<span class="token keyword">import</span> os
<span class="token keyword">import</span> jieba
<span class="token keyword">import</span> joblib
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>naive_bayes <span class="token keyword">import</span> MultinomialNB  <span class="token comment"># 多项式模型的朴素贝叶斯分类器</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics  <span class="token comment"># 指标模块包括得分函数，性能指标和两两指标和距离计算</span>


<span class="token comment"># 分词</span>
<span class="token keyword">def</span> <span class="token function">load_file</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>

    titles <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 样本数据</span>
    labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 标签</span>

    <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
        line <span class="token operator">=</span> line<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">'unicode-escape'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'unicode-escape'</span><span class="token punctuation">)</span>
        line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

        _lines <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'---'</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>_lines<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">:</span>
            <span class="token keyword">continue</span>

        label<span class="token punctuation">,</span> title <span class="token operator">=</span> _lines
        words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>title<span class="token punctuation">)</span>

        s <span class="token operator">=</span> <span class="token string">''</span>
        <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">:</span>
            s <span class="token operator">+=</span> w <span class="token operator">+</span> <span class="token string">' '</span>

        s <span class="token operator">=</span> s<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>

        titles<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
        labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label<span class="token punctuation">)</span>

    <span class="token keyword">return</span> titles<span class="token punctuation">,</span> labels


<span class="token comment"># 加载数据</span>
<span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span>_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    file_list <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>_dir<span class="token punctuation">)</span>

    titles_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    labels_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> file_name <span class="token keyword">in</span> file_list<span class="token punctuation">:</span>
        file_path <span class="token operator">=</span> _dir <span class="token operator">+</span> <span class="token string">'/'</span> <span class="token operator">+</span> file_name

        titles<span class="token punctuation">,</span> labels <span class="token operator">=</span> load_file<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>

        titles_list <span class="token operator">+=</span> titles
        labels_list <span class="token operator">+=</span> labels

    <span class="token keyword">return</span> titles_list<span class="token punctuation">,</span> labels_list


<span class="token comment"># 加载停用词</span>
<span class="token keyword">def</span> <span class="token function">load_stopwords</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>

    words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
        line <span class="token operator">=</span> line<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">'unicode-escape'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'unicode-escape'</span><span class="token punctuation">)</span>
        line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
        words<span class="token punctuation">.</span>append<span class="token punctuation">(</span>line<span class="token punctuation">)</span>

    <span class="token keyword">return</span> words


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    stop_words <span class="token operator">=</span> load_stopwords<span class="token punctuation">(</span><span class="token string">'stop_word/stopword.txt'</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载训练数据</span>
    train_datas<span class="token punctuation">,</span> train_labels <span class="token operator">=</span> load_data<span class="token punctuation">(</span><span class="token string">'train_data'</span><span class="token punctuation">)</span>

    <span class="token comment"># 文本向量表示</span>
    tf <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span>stop_words<span class="token operator">=</span>stop_words<span class="token punctuation">,</span> max_df<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
    train_features <span class="token operator">=</span> tf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>train_datas<span class="token punctuation">)</span>
    train_features_arr <span class="token operator">=</span> train_features<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 多项式贝叶斯分类器</span>
    clf <span class="token operator">=</span> MultinomialNB<span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_features_arr<span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span>

    test_datas<span class="token punctuation">,</span> test_labels <span class="token operator">=</span> load_data<span class="token punctuation">(</span><span class="token string">'test_data'</span><span class="token punctuation">)</span>
    test_features <span class="token operator">=</span> tf<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>test_datas<span class="token punctuation">)</span>

    <span class="token comment"># 预测数据</span>
    predicted_labels <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_features<span class="token punctuation">)</span>

    <span class="token comment"># 计算准确率</span>
    score <span class="token operator">=</span> metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>test_labels<span class="token punctuation">,</span> predicted_labels<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>score<span class="token punctuation">)</span>

    joblib<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> <span class="token string">'nb.pkl'</span><span class="token punctuation">)</span>
    joblib<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>tf<span class="token punctuation">,</span> <span class="token string">'tf.pkl'</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/9e/43/13UEtmJr_o.png" alt="在这里插入图片描述"></p> 
<p>(2)use_nb.py使用所构建的文本分类模型进行文本预测。</p> 
<pre><code class="prism language-python"><span class="token comment">#!/usr/bin/env python</span>
<span class="token comment"># coding=utf-8</span>


<span class="token keyword">import</span> jieba
<span class="token keyword">import</span> warnings
<span class="token keyword">import</span> joblib

warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>

<span class="token comment"># 模型加载函数及测试函数</span>
MODEL <span class="token operator">=</span> <span class="token boolean">None</span>
TF <span class="token operator">=</span> <span class="token boolean">None</span>


<span class="token keyword">def</span> <span class="token function">load_model</span><span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> tf_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">global</span> MODEL 
    <span class="token keyword">global</span> TF

    MODEL <span class="token operator">=</span> joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
    TF <span class="token operator">=</span> joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span>tf_path<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">nb_predict</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">assert</span> MODEL <span class="token operator">!=</span> <span class="token boolean">None</span> <span class="token keyword">and</span> TF <span class="token operator">!=</span> <span class="token boolean">None</span>
    
    words <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>title<span class="token punctuation">)</span>
    s <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>words<span class="token punctuation">)</span>

    test_features <span class="token operator">=</span> TF<span class="token punctuation">.</span>transform<span class="token punctuation">(</span><span class="token punctuation">[</span>s<span class="token punctuation">]</span><span class="token punctuation">)</span> 
    predicted_labels <span class="token operator">=</span> MODEL<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_features<span class="token punctuation">)</span>

    <span class="token keyword">return</span> predicted_labels<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token comment"># 进行测试，打印测试结果</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    load_model<span class="token punctuation">(</span><span class="token string">'nb.pkl'</span><span class="token punctuation">,</span> <span class="token string">'tf.pkl'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span>nb_predict<span class="token punctuation">(</span><span class="token string">'东莞市场采购贸易联网信息平台参加部委首批联合验收'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span>nb_predict<span class="token punctuation">(</span><span class="token string">'留在中超了！踢进生死战决胜一球，武汉卓尔保级成功'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span>nb_predict<span class="token punctuation">(</span><span class="token string">'陈思诚全新系列电影《外太空的莫扎特》首曝海报 黄渤、荣梓杉演父子'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span>nb_predict<span class="token punctuation">(</span><span class="token string">'红薯的好处 常吃这种食物能够帮你减肥'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/11/8b/xJo4inPl_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_288"></a>案例小结</h4> 
<p>本案例通过朴素贝叶斯分类算法进行中文分类，训练精确率达到了96.79%，测试时全部预测正确，模型的效果相当不错，在实验过程中可参考以下经验：</p> 
<p>(1)要注意定义停用词；</p> 
<p>(2)可以分别将不用功能的代码模块定义成函数，以加强代码的重用度；</p> 
<p>(3)要注意训练数据与测试数据的格式保持一致；</p> 
<p>(4)要注意定义编码，以防止出现中文乱码的情况。</p> 
<pre><code>
</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2b789e25344f3988d48af9ffecefbcf5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">电容等效模型</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e0f9425386ed76a5ae4dcd5a8ee23456/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">pytorch scatter方法 在后向传播中遇到的问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>