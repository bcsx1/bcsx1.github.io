<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ocr的预处理--透视变换，重映射，仿射变换，水平矫正 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ocr的预处理--透视变换，重映射，仿射变换，水平矫正" />
<meta property="og:description" content="图像校正可以参考这个：https://blog.csdn.net/wsp_1138886114/article/details/83374333
透视变化：
#include&lt;opencv2/opencv.hpp&gt; using namespace cv; #define CV_SHOW(x) imshow(&#34;df&#34;,x);waitKey(0) static void testImageRectification(cv::Mat &amp;I); void main() { Mat I; //I = imread(&#34;D:\\test.bmp&#34;); I = imread(&#34;D:\\360安全浏览器下载\\790f419bb941d239b7f5ba70b0ce82fa\\7.png&#34;); testImageRectification(I); } static void testImageRectification(cv::Mat &amp;image_original) { CV_SHOW(image_original); // CV_SHOW是cv::imshow的一个自定义宏，忽略即可 cv::Mat &amp;&amp;image = image_original.clone(); cv::Mat image_gray; cv::cvtColor(image, image_gray, cv::COLOR_BGR2GRAY); //cv::threshold(image_gray, image_gray, g_threshVal, g_threshMax, cv::THRESH_BINARY); cv::threshold(image_gray, image_gray, 110, 250, cv::THRESH_BINARY); std::vector&lt; std::vector&lt;cv::Point&gt; &gt; contours_list; { std::vector&lt;cv::Vec4i&gt; hierarchy; // Since opencv 3.2 source image is not modified by this function cv::findContours(image_gray, contours_list, hierarchy, cv::RetrievalModes::RETR_EXTERNAL, cv::ContourApproximationModes::CHAIN_APPROX_NONE); } for (uint32_t index = 0; index &lt; contours_list." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/2307c11576020a90188cd93b11a56447/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-11-12T11:51:17+08:00" />
<meta property="article:modified_time" content="2019-11-12T11:51:17+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ocr的预处理--透视变换，重映射，仿射变换，水平矫正</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>图像校正可以参考这个：<a href="https://blog.csdn.net/wsp_1138886114/article/details/83374333">https://blog.csdn.net/wsp_1138886114/article/details/83374333</a></p> 
<p> </p> 
<p>透视变化：</p> 
<pre class="has"><code class="language-cpp">#include&lt;opencv2/opencv.hpp&gt;
using namespace cv;
#define CV_SHOW(x) imshow("df",x);waitKey(0)
static void testImageRectification(cv::Mat &amp;I);
void main()
{
	Mat I;
	//I = imread("D:\\test.bmp");
	I = imread("D:\\360安全浏览器下载\\790f419bb941d239b7f5ba70b0ce82fa\\7.png");
	testImageRectification(I);
}
static void testImageRectification(cv::Mat &amp;image_original)
{
	CV_SHOW(image_original); // CV_SHOW是cv::imshow的一个自定义宏，忽略即可
	cv::Mat &amp;&amp;image = image_original.clone();

	cv::Mat image_gray;
	cv::cvtColor(image, image_gray, cv::COLOR_BGR2GRAY);
	//cv::threshold(image_gray, image_gray, g_threshVal, g_threshMax, cv::THRESH_BINARY);
	cv::threshold(image_gray, image_gray, 110, 250, cv::THRESH_BINARY);

	std::vector&lt; std::vector&lt;cv::Point&gt; &gt; contours_list;
	{
		std::vector&lt;cv::Vec4i&gt; hierarchy;
		// Since opencv 3.2 source image is not modified by this function
		cv::findContours(image_gray, contours_list, hierarchy,
			cv::RetrievalModes::RETR_EXTERNAL, cv::ContourApproximationModes::CHAIN_APPROX_NONE);
	}

	for (uint32_t index = 0; index &lt; contours_list.size(); ++index) {
		cv::RotatedRect &amp;&amp;rect = cv::minAreaRect(contours_list[index]);
		if (rect.size.area() &gt; 1000) {
			if (rect.angle != 0.) {
				// 此处可通过cv::warpAffine进行旋转矫正，本例不需要
			} //if

			cv::Mat &amp;mask = image_gray;
			cv::drawContours(mask, contours_list, static_cast&lt;int&gt;(index), cv::Scalar(255), cv::FILLED);

			cv::Mat extracted(image_gray.rows, image_gray.cols, CV_8UC1, cv::Scalar(0));
			image.copyTo(extracted, mask);
			CV_SHOW(extracted);

			std::vector&lt;cv::Point2f&gt; poly;
			cv::approxPolyDP(contours_list[index], poly, 30, true); // 多边形逼近，精度(即最小边长)设为30是为了得到4个角点
			cv::Point2f pts_src[] = { // 此处顺序调整是为了和后面配对，仅作为示例
				poly[1],
				poly[0],
				poly[3],
				poly[2]
			};

			cv::Rect &amp;&amp;r = rect.boundingRect(); // 注意坐标可能超出图像范围
			cv::Point2f pts_dst[] = {
				cv::Point(r.x, r.y),
				cv::Point(r.x + r.width, r.y),
				cv::Point(r.x + r.width, r.y + r.height) ,
				cv::Point(r.x, r.y + r.height)
			};
			cv::Mat &amp;&amp;M = cv::getPerspectiveTransform(pts_dst, pts_src); // 我这里交换了输入，因为后面指定了cv::WARP_INVERSE_MAP，你可以试试不交换的效果是什么

			cv::Mat warp; cv::warpPerspective(image, warp, M, image.size(), cv::INTER_LINEAR + cv::WARP_INVERSE_MAP, cv::BORDER_REPLICATE);
			CV_SHOW(warp);
		} //if
	}
}</code></pre> 
<p>效果展示：</p> 
<p>              <img alt="" class="has" height="271" src="https://images2.imgbox.com/0a/32/4kucy3p0_o.png" width="319"><img alt="" class="has" height="273" src="https://images2.imgbox.com/fb/41/BTKxyfrY_o.png" width="312"></p> 
<p>                                                              <img alt="" class="has" height="276" src="https://images2.imgbox.com/47/44/volYGerh_o.png" width="314"></p> 
<p> </p> 
<p><strong>重映射</strong></p> 
<p>重映射就是把一幅图像中某个位置的像素放置到另一个图片中指定位置的过程。</p> 
<p>用一个数学公式来表示就是：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/f0/dc/iy7CGJjC_o.png"></p> 
<p>其中的 f 就是映射方式，也就说，像素点在另一个图像中的位置是由 f 来计算的。</p> 
<p>在OpenCV中，用的是remap函数实现重映射。就是把图的像素重新放一个位置</p> 
<pre class="has"><code class="language-cpp">#include &lt;iostream&gt;
#include &lt;opencv2\opencv.hpp&gt;
#include &lt;opencv2\imgproc\imgproc.hpp&gt;
#include &lt;opencv2\highgui\highgui.hpp&gt;

using namespace cv;
using namespace std;

//基本重映射实验

int main()
{
	Mat srcImage = imread("2.jpg");

	if (!srcImage.data)
	{
		cout &lt;&lt; "找不到这张图片！" &lt;&lt; endl;
		return -1;
	}

	imshow("Src Pic", srcImage);

	Mat dstImage, map_x, map_y;
	dstImage.create(srcImage.size(), srcImage.type());//创建和原图一样的效果图
	map_x.create(srcImage.size(), CV_32FC1);
	map_y.create(srcImage.size(), CV_32FC1);

	//遍历每一个像素点，改变map_x &amp; map_y的值,实现翻转180度
	for (int j = 0; j &lt; srcImage.rows; j++)
	{
		for (int i = 0; i &lt; srcImage.cols; i++)
		{
			map_x.at&lt;float&gt;(j, i) = static_cast&lt;float&gt;(i);
			map_y.at&lt;float&gt;(j, i) = static_cast&lt;float&gt;(srcImage.rows - j);
		}
	}

	//进行重映射操作
	remap(srcImage, dstImage, map_x, map_y, INTER_LINEAR, BORDER_CONSTANT, Scalar(0, 0, 0));
	imshow("重映射效果图", dstImage);

	waitKey();
	return 0;
}
</code></pre> 
<p> </p> 
<p>仿射变换</p> 
<pre class="has"><code class="language-cpp">#include&lt;iostream&gt;  
#include&lt;opencv2/highgui/highgui.hpp&gt;  
#include&lt;opencv2/imgproc/imgproc.hpp&gt;  

using namespace std;
using namespace cv;
//仿射变换实验
int main()
{
	Mat src = imread("2.jpg");
	Mat dst_warp, dst_warpRotateScale;
	Point2f srcPoints[3];//原图中的三点  
	Point2f dstPoints[3];//目标图中的三点  

	//第一种仿射变换的调用方式：三点法
	//三个点对的值,上面也说了，只要知道你想要变换后图的三个点的坐标，就可以实现仿射变换  
	srcPoints[0] = Point2f(0, 0);
	srcPoints[1] = Point2f(0, src.rows - 1);
	srcPoints[2] = Point2f(src.cols - 1, 0);
	//映射后的三个坐标值
	dstPoints[0] = Point2f(0, src.rows*0.3);
	dstPoints[1] = Point2f(src.cols*0.25, src.rows*0.75);
	dstPoints[2] = Point2f(src.cols*0.75, src.rows*0.25);

	Mat M1 = getAffineTransform(srcPoints, dstPoints);//由三个点对计算变换矩阵  
	warpAffine(src, dst_warp, M1, src.size());//仿射变换  


	//第二种仿射变换的调用方式：直接指定角度和比例                                          
	//旋转加缩放  
	Point2f center(src.cols / 2, src.rows / 2);//旋转中心  
	double angle = 45;//逆时针旋转45度  
	double scale = 0.5;//缩放比例  

	Mat M2 = getRotationMatrix2D(center, angle, scale);//计算旋转加缩放的变换矩阵  
	warpAffine(dst_warp, dst_warpRotateScale, M2, src.size());//仿射变换  

	imshow("原始图", src);
	imshow("仿射变换1", dst_warp);
	imshow("仿射变换2", dst_warpRotateScale);
	waitKey(0);

	return 0;</code></pre> 
<p> </p> 
<p><img alt="" class="has" height="415" src="https://images2.imgbox.com/63/f9/QWwTCCbw_o.png" width="1006"></p> 
<p>    改变颜色warpAffine(dst_warp, dst_warpRotateScale, M2, src.size(), 1, 0, Scalar(11, 111, 211));//仿射变换   </p> 
<p><img alt="" class="has" height="474" src="https://images2.imgbox.com/03/05/4JuZau4g_o.png" width="1010"></p> 
<p> </p> 
<p>基于文本的图像校正</p> 
<pre class="has"><code class="language-cpp">#include "opencv2/imgproc.hpp"
#include "opencv2/highgui.hpp"
#include &lt;iostream&gt;
#include &lt;opencv2/highgui/highgui_c.h&gt;
using namespace cv;
using namespace std;

#define ERROR 1234

//度数转换
double DegreeTrans(double theta)
{
	double res = theta / CV_PI * 180;
	return res;
}


//逆时针旋转图像degree角度（原尺寸）    
void rotateImage(Mat src, Mat&amp; img_rotate, double degree)
{
	//旋转中心为图像中心    
	Point2f center;
	center.x = float(src.cols / 2.0);
	center.y = float(src.rows / 2.0);
	int length = 0;
	length = sqrt(src.cols*src.cols + src.rows*src.rows);
	//计算二维旋转的仿射变换矩阵  
	Mat M = getRotationMatrix2D(center, degree, 1);
	warpAffine(src, img_rotate, M, Size(length, length), 1, 0, Scalar(255, 255, 255));//仿射变换，背景色填充为白色  
}

//通过霍夫变换计算角度
double CalcDegree(const Mat &amp;srcImage, Mat &amp;dst)
{
	Mat midImage, dstImage;

	Canny(srcImage, midImage, 50, 200, 3);
	cvtColor(midImage, dstImage, CV_GRAY2BGR);

	//通过霍夫变换检测直线
	vector&lt;Vec2f&gt; lines;
	HoughLines(midImage, lines, 1, CV_PI / 180, 300, 0, 0);//第5个参数就是阈值，阈值越大，检测精度越高
	//cout &lt;&lt; lines.size() &lt;&lt; endl;

	//由于图像不同，阈值不好设定，因为阈值设定过高导致无法检测直线，阈值过低直线太多，速度很慢
	//所以根据阈值由大到小设置了三个阈值，如果经过大量试验后，可以固定一个适合的阈值。

	if (!lines.size())
	{
		HoughLines(midImage, lines, 1, CV_PI / 180, 200, 0, 0);
	}
	//cout &lt;&lt; lines.size() &lt;&lt; endl;

	if (!lines.size())
	{
		HoughLines(midImage, lines, 1, CV_PI / 180, 150, 0, 0);
	}
	//cout &lt;&lt; lines.size() &lt;&lt; endl;
	if (!lines.size())
	{
		cout &lt;&lt; "没有检测到直线！" &lt;&lt; endl;
		return ERROR;
	}

	float sum = 0;
	//依次画出每条线段
	for (size_t i = 0; i &lt; lines.size(); i++)
	{
		float rho = lines[i][0];
		float theta = lines[i][1];
		Point pt1, pt2;
		//cout &lt;&lt; theta &lt;&lt; endl;
		double a = cos(theta), b = sin(theta);
		double x0 = a * rho, y0 = b * rho;
		pt1.x = cvRound(x0 + 1000 * (-b));
		pt1.y = cvRound(y0 + 1000 * (a));
		pt2.x = cvRound(x0 - 1000 * (-b));
		pt2.y = cvRound(y0 - 1000 * (a));
		//只选角度最小的作为旋转角度
		sum += theta;

		line(dstImage, pt1, pt2, Scalar(55, 100, 195), 1, LINE_AA); //Scalar函数用于调节线段颜色

		imshow("直线探测效果图", dstImage);
	}
	float average = sum / lines.size(); //对所有角度求平均，这样做旋转效果会更好

	cout &lt;&lt; "average theta:" &lt;&lt; average &lt;&lt; endl;

	double angle = DegreeTrans(average) - 90;

	rotateImage(dstImage, dst, angle);
	//imshow("直线探测效果图2", dstImage);
	return angle;
}


void ImageRecify(const char* pInFileName, const char* pOutFileName)
{
	double degree;
	Mat src = imread(pInFileName);
	imshow("原始图", src);
	Mat dst;
	//倾斜角度矫正
	degree = CalcDegree(src, dst);
	if (degree == ERROR)
	{
		cout &lt;&lt; "矫正失败！" &lt;&lt; endl;
		return;
	}
	rotateImage(src, dst, degree);
	cout &lt;&lt; "angle:" &lt;&lt; degree &lt;&lt; endl;
	imshow("旋转调整后", dst);

	Mat resulyImage = dst(Rect(0, 0, dst.cols, 500)); //根据先验知识，估计好文本的长宽，再裁剪下来
	imshow("裁剪之后", resulyImage);
	imwrite("recified.jpg", resulyImage);
}


int main()
{
	ImageRecify("G:\\source\\repos\\expression_recognition\\Project1\\7.jpg", "FinalImage.jpg");
	waitKey();
	return 0;
}</code></pre> 
<p> </p> 
<p><img alt="" class="has" height="967" src="https://images2.imgbox.com/97/3e/rSQTi1Ls_o.png" width="1200"></p> 
<p>但是这种只能识别这些简单的校正。 比如有红色印章，这个时候需要先处理印章。</p> 
<pre class="has"><code class="language-python">import cv2
import numpy as np

np.set_printoptions(threshold=np.inf)
image=cv2.imread(r'G:\source\repos\expression_recognition\Project1\22.jpg')

hue_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
low_range = np.array([150, 103, 100])
high_range = np.array([180, 255, 255])
th = cv2.inRange(hue_image, low_range, high_range)
index1 = th == 255

img = np.zeros(image.shape, np.uint8)
img[:, :] = (255,255,255)
img[index1] = image[index1]#(0,0,255)
cv2.imshow('original_img', image)
cv2.imshow('extract_img', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre> 
<p>效果图；</p> 
<p><img alt="" class="has" height="245" src="https://images2.imgbox.com/61/cc/VBsYMPWF_o.png" width="1200"></p> 
<p> </p> 
<pre class="has"><code class="language-python">#去除印章
import cv2
import numpy as np
import matplotlib.pyplot as plt


image0=cv2.imread("fapiao.png",cv2.IMREAD_COLOR)   # 以BGR色彩读取图片
image = cv2.resize(image0,None,fx=0.5,fy=0.5,
                   interpolation=cv2.INTER_CUBIC)  # 缩小图片0.5倍（图片太大了）
cols,rows,_=image.shape                            # 获取图片高宽
B_channel,G_channel,R_channel=cv2.split(image)     # 注意cv2.split()返回通道顺序

cv2.imshow('Blue channel',B_channel)
cv2.imshow('Green channel',G_channel)
cv2.imshow('Red channel',R_channel)

pixelSequence=R_channel.reshape([rows*cols,])     # 红色通道的histgram 变换成一维向量
numberBins=256                                    # 统计直方图的组数
plt.figure()                                      # 计算直方图
manager = plt.get_current_fig_manager()
histogram,bins,patch=plt.hist(pixelSequence,
                              numberBins,
                              facecolor='black',
                              histtype='bar')     # facecolor设置为黑色
#设置坐标范围
y_maxValue=np.max(histogram)
plt.axis([0,255,0,y_maxValue])
#设置坐标轴
plt.xlabel("gray Level",fontsize=20)
plt.ylabel('number of pixels',fontsize=20)
plt.title("Histgram of red channel", fontsize=25)
plt.xticks(range(0,255,10))
#显示直方图
plt.pause(0.05)
plt.savefig("histgram.png",dpi=260,bbox_inches="tight")
plt.show()


#红色通道阈值(调节好函数阈值为160时效果最好，太大一片白，太小干扰点太多)
_,RedThresh = cv2.threshold(R_channel,160,255,cv2.THRESH_BINARY)

#膨胀操作（可以省略）
element = cv2.getStructuringElement(cv2.MORPH_RECT,(3, 3)) 
erode = cv2.erode(RedThresh, element)

#显示效果
cv2.imshow('original color image',image)
cv2.imshow("RedThresh",RedThresh)
cv2.imshow("erode",erode)

# 保存图像
cv2.imwrite('scale_image.jpg',image)
cv2.imwrite('RedThresh.jpg',RedThresh)
cv2.imwrite("erode.jpg",erode)

cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre> 
<ul><li>读取原始图像A</li><li>提取图像的红色通道，得到红色通道灰度值图片B</li><li>计算B的统计直方图C，确定最佳的阈值threshold</li><li>根据阈值，对B进行二值化，得到最终图片D</li><li>（可选）应用膨胀算子对D进行操作，得到图片E</li></ul> 
<p><img alt="" class="has" height="696" src="https://images2.imgbox.com/40/3a/vvWIvCTY_o.png" width="864"></p> 
<p> 去掉印章来源：<a href="https://blog.csdn.net/wsp_1138886114/article/details/82858380">https://blog.csdn.net/wsp_1138886114/article/details/82858380</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4953983b49d296b8dc80c22aedcba72c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">markdown图片左对齐</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e99b9aaf5a5a9f1d78ad1b7227ca1dfb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">111. 二叉树的最小深度</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>