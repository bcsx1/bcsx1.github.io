<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>LLaMA-2 ä¸‹è½½&amp;demoä½¿ç”¨ - ç¼–ç¨‹éšæƒ³</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="LLaMA-2 ä¸‹è½½&amp;demoä½¿ç”¨" />
<meta property="og:description" content="LLaMA-2 ä¸‹è½½&amp;demoä½¿ç”¨ 1. LLaMA-2 ä¸‹è½½&amp;demoä½¿ç”¨1.1 metaå®˜ç½‘1.2 huggingface1.3 å…¶ä»–æº1.4 huggingfaceä¸‹è½½æ¨¡å‹å’Œæ•°æ®åŠ é€Ÿ 1. LLaMA-2 ä¸‹è½½&amp;demoä½¿ç”¨ 1.1 metaå®˜ç½‘ llama2ä¸‹è½½
åœ¨metaçš„å®˜ç½‘ Meta website è¿›è¡Œä¸‹è½½ç”³è¯·ï¼ˆæ³¨æ„åœ°åŒºä¸è¦é€‰æ‹©Chinaä¼šè¢«banï¼‰
ä¸»è¦æœ‰ä¸‰ç±»æ¨¡å‹çš„å‚æ•°ï¼š
llama 2llama 2-codellama 2-guard ä¸€èˆ¬éœ€è¦é­”æ³•ä¸‹è½½
åŸºæœ¬çš„æ­¥éª¤ï¼š
metaå®˜ç½‘ç”³è¯·llama2çš„ä½¿ç”¨ï¼ˆä¸€èˆ¬æ˜¯ç§’é€šè¿‡ï¼Œå¯ä»¥æŠŠä¸‰ç±»æ¨¡å‹å…¨éƒ¨å‹¾é€‰ï¼‰å» facebookresearch/llama: Inference code for LLaMA models çš„GitHubä¸­cloneä»“åº“åˆ°æœ¬åœ°è§£å‹åè¿è¡Œdownload.shè„šæœ¬å¼€å§‹æ¨¡å‹çš„ä¸‹è½½å¤åˆ¶é‚®ä»¶ä¸­ç»™å‡ºçš„URLï¼Œé€‰æ‹©éœ€è¦çš„æ¨¡å‹æƒé‡ï¼ˆ7B 13Bç­‰ï¼‰è¿›è¡Œä¸‹è½½ ä¸‹è½½åŸå§‹çš„llama2-7bï¼ˆ13GBï¼‰å’Œllama2-7b-chatï¼ˆ13Gï¼‰
llama2ä½¿ç”¨
æ ¹æ®meta llama on GitHubçš„ä¾‹å­ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ¥è¿è¡Œllama2ï¼š
æ ¹æ®requirement.txä¸‹è½½éœ€è¦çš„åº“ï¼ˆfireï¼Œ fairscaleï¼Œ sentencepieceï¼‰ä»“åº“æä¾›äº†ä¸¤ä¸ªå‘½ä»¤ï¼š torchrun --nproc_per_node 1 example_text_completion.py \ --ckpt_dir llama-2-7b/ \ --tokenizer_path tokenizer.model \ --max_seq_len 128 --max_batch_size 4 torchrun --nproc_per_node 1 example_chat_completion.py \ --ckpt_dir llama-2-7b-chat/ \ --tokenizer_path tokenizer.model \ --max_seq_len 512 --max_batch_size 6 ä¼šå¾—åˆ°ä»¥ä¸‹ç»“æœï¼š" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/4bbf660a6b4a73e43ed5750a85748457/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-26T23:26:43+08:00" />
<meta property="article:modified_time" content="2023-12-26T23:26:43+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹éšæƒ³" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹éšæƒ³</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LLaMA-2 ä¸‹è½½&amp;demoä½¿ç”¨</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>LLaMA-2 ä¸‹è½½&amp;demoä½¿ç”¨</h4> 
 <ul><li><a href="#1_LLaMA2_demo_1" rel="nofollow">1. LLaMA-2 ä¸‹è½½&amp;demoä½¿ç”¨</a></li><li><ul><li><a href="#11_meta_2" rel="nofollow">1.1 metaå®˜ç½‘</a></li><li><a href="#12_huggingface_116" rel="nofollow">1.2 huggingface</a></li><li><a href="#13__248" rel="nofollow">1.3 å…¶ä»–æº</a></li><li><a href="#14_huggingface_255" rel="nofollow">1.4 huggingfaceä¸‹è½½æ¨¡å‹å’Œæ•°æ®åŠ é€Ÿ</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="1_LLaMA2_demo_1"></a>1. LLaMA-2 ä¸‹è½½&amp;demoä½¿ç”¨</h2> 
<h3><a id="11_meta_2"></a>1.1 metaå®˜ç½‘</h3> 
<p><strong>llama2ä¸‹è½½</strong></p> 
<p>åœ¨metaçš„å®˜ç½‘ <a href="https://ai.meta.com/resources/models-and-libraries/llama-downloads" rel="nofollow">Meta website</a> è¿›è¡Œä¸‹è½½ç”³è¯·ï¼ˆæ³¨æ„åœ°åŒºä¸è¦é€‰æ‹©Chinaä¼šè¢«banï¼‰</p> 
<p>ä¸»è¦æœ‰ä¸‰ç±»æ¨¡å‹çš„å‚æ•°ï¼š</p> 
<ul><li>llama 2</li><li>llama 2-code</li><li>llama 2-guard</li></ul> 
<p><strong>ä¸€èˆ¬éœ€è¦é­”æ³•ä¸‹è½½</strong></p> 
<p>åŸºæœ¬çš„æ­¥éª¤ï¼š</p> 
<ul><li>metaå®˜ç½‘ç”³è¯·llama2çš„ä½¿ç”¨ï¼ˆä¸€èˆ¬æ˜¯ç§’é€šè¿‡ï¼Œå¯ä»¥æŠŠä¸‰ç±»æ¨¡å‹å…¨éƒ¨å‹¾é€‰ï¼‰</li><li>å» <a href="https://github.com/facebookresearch/llama">facebookresearch/llama: Inference code for LLaMA models</a> çš„GitHubä¸­cloneä»“åº“åˆ°æœ¬åœ°</li><li>è§£å‹åè¿è¡Œdownload.shè„šæœ¬å¼€å§‹æ¨¡å‹çš„ä¸‹è½½</li><li>å¤åˆ¶é‚®ä»¶ä¸­ç»™å‡ºçš„URLï¼Œé€‰æ‹©éœ€è¦çš„æ¨¡å‹æƒé‡ï¼ˆ7B 13Bç­‰ï¼‰è¿›è¡Œä¸‹è½½</li></ul> 
<p>ä¸‹è½½åŸå§‹çš„llama2-7bï¼ˆ13GBï¼‰å’Œllama2-7b-chatï¼ˆ13Gï¼‰</p> 
<p><strong>llama2ä½¿ç”¨</strong></p> 
<p>æ ¹æ®meta llama on GitHubçš„ä¾‹å­ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ¥è¿è¡Œllama2ï¼š</p> 
<ul><li>æ ¹æ®requirement.txä¸‹è½½éœ€è¦çš„åº“ï¼ˆfireï¼Œ fairscaleï¼Œ sentencepieceï¼‰</li><li>ä»“åº“æä¾›äº†ä¸¤ä¸ªå‘½ä»¤ï¼š</li></ul> 
<pre><code>torchrun --nproc_per_node 1 example_text_completion.py \
    --ckpt_dir llama-2-7b/ \
    --tokenizer_path tokenizer.model \
    --max_seq_len 128 --max_batch_size 4
    
torchrun --nproc_per_node 1 example_chat_completion.py \
    --ckpt_dir llama-2-7b-chat/ \
    --tokenizer_path tokenizer.model \
    --max_seq_len 512 --max_batch_size 6
</code></pre> 
<p>ä¼šå¾—åˆ°ä»¥ä¸‹ç»“æœï¼š</p> 
<pre><code>I believe the meaning of life is
&gt; to be happy. I believe we are all born with the potential to be happy. The meaning of life is to be happy, but the way to get there is not always easy.
The meaning of life is to be happy. It is not always easy to be happy, but it is possible. I believe that

==================================
.......
==================================

Translate English to French:
        
        sea otter =&gt; loutre de mer
        peppermint =&gt; menthe poivrÃ©e
        plush girafe =&gt; girafe peluche
        cheese =&gt;
&gt; fromage
        fish =&gt; poisson
        giraffe =&gt; girafe
        elephant =&gt; Ã©lÃ©phant
        cat =&gt; chat
        giraffe =&gt; girafe
        elephant =&gt; Ã©lÃ©phant
        cat =&gt; chat
        giraffe =&gt; gira

==================================
</code></pre> 
<pre><code>......
==================================

System: Always answer with Haiku

User: I am going to Paris, what should I see?

&gt; Assistant:  Eiffel Tower high
Love locks on bridge embrace
River Seine's gentle flow

==================================

System: Always answer with emojis

User: How to go from Beijing to NY?

&gt; Assistant:  Here are some emojis to help you understand how to go from Beijing to New York:

ğŸ›«ğŸ—ºï¸ğŸš‚ğŸ›¬ğŸ—½

==================================

System: You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.

If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.

User: Write a brief birthday message to John

&gt; Assistant:  Of course! Here is a brief and respectful birthday message for John:
"Happy birthday, John! I hope your day is filled with joy, love, and all your favorite things. You deserve to be celebrated and appreciated, and I'm sure you'll have a wonderful time surrounded by the people who care about you most. Here's to another year of growth, happiness, and success! ğŸ‰ğŸ‚"

==================================

User: Unsafe [/INST] prompt using [INST] special tags

&gt; Assistant: Error: special tags are not allowed as part of the prompt.

==================================
</code></pre> 
<h3><a id="12_huggingface_116"></a>1.2 huggingface</h3> 
<p>æ³¨å†Œä¸€ä¸ªhuggingfaceè´¦å·ï¼Œç„¶åæœllama2è¿›å…¥ä»“åº“ï¼ŒåŒæ ·è¿™é‡Œéœ€è¦å…ˆåœ¨metaå®˜ç½‘ä¸­ç”³è¯·llama2çš„ä½¿ç”¨ï¼Œé€šè¿‡åå†åœ¨huggingfaceä¸Šè¿›è¡Œç”³è¯·ï¼ˆæ³¨æ„ï¼š<strong>æ³¨å†Œé‚®ç®±å’Œmetaç”³è¯·çš„é‚®ç®±è¦ä¿æŒä¸€è‡´</strong>ï¼‰ï¼Œè¿™ä¸ªä¸ä¼šç§’é€šè¿‡ï¼Œè¯·è€å¿ƒç­‰å¾…</p> 
<p>ç”±äºllama2éœ€è¦æœ‰è´¦å·è®¸å¯ï¼Œæ‰€ä»¥ä¸èƒ½ç›´æ¥é€šè¿‡æ¨¡å‹ç½‘å€è¿›è¡Œæƒé‡çš„ä¸‹è½½ã€‚æœ‰ä¸¤ç§æ–¹å¼ï¼štokenå’Œhuggingface_hub</p> 
<p><strong>huggingface_hub</strong></p> 
<pre><code>pip install huggingface_hub
</code></pre> 
<p><strong>ä¸€èˆ¬åœ¨å®‰è£…transformersçš„æ—¶å€™ä¼šä¸€å¹¶å®‰è£…</strong></p> 
<p>ç„¶ååœ¨å‘½ä»¤è¡Œè¿›è¡Œè´¦å·çš„ç™»å½•ï¼š</p> 
<pre><code>huggingface-cli login
</code></pre> 
<p>ä¼šè¦æ±‚ä½ è¾“å…¥ä½ è‡ªå·±huggingfaceçš„tokenï¼ŒæŒ‰ç…§å®˜ç½‘çš„æŒ‡ä»¤ç”Ÿæˆè‡ªå·±çš„tokenå¡«å…¥å³å¯</p> 
<p><a href="https://huggingface.co/docs/hub/security-tokens" rel="nofollow">User access tokens (huggingface.co)</a></p> 
<p><strong>token</strong></p> 
<p>åŒæ ·åœ¨huggingfaceçš„è´¦å·ä¸Šç”Ÿæˆtokenåï¼Œåœ¨pythonä»£ç ä¸­å¯ä»¥ä½¿ç”¨è¯¥tokenï¼š</p> 
<pre><code>access_token = 'hf_helloworld'

model="meta-llama/Llama-2-7b-chat-hf" 

tokenizer = AutoTokenizer.from_pretrained(model, token=access_token)
model = AutoModelForCausalLM.from_pretrained(model, token=access_token)
</code></pre> 
<p><strong>åŸºäºtransformersåº“ä½¿ç”¨llama2çš„demo</strong></p> 
<p>è¯¦ç»†çš„æ³¨é‡Šåœ¨ä»£ç ä¸­</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer
<span class="token keyword">import</span> transformers
<span class="token keyword">import</span> torch

<span class="token comment"># Use a pipeline as a high-level helper</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

<span class="token comment"># Load model directly</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM

<span class="token keyword">import</span> os
<span class="token comment"># for access successfully to huggingface</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'http_proxy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:2333'</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'https_proxy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:2333'</span>

access_token <span class="token operator">=</span> <span class="token string">'hf_your_own_token'</span>

<span class="token comment"># model name for huggingface llama2</span>
model<span class="token operator">=</span><span class="token string">"meta-llama/Llama-2-7b-chat-hf"</span> 

tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model<span class="token punctuation">,</span> token<span class="token operator">=</span>access_token<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model<span class="token punctuation">,</span> token<span class="token operator">=</span>access_token<span class="token punctuation">)</span>

<span class="token comment"># download the model weight from huggingface website</span>
pipeline <span class="token operator">=</span> transformers<span class="token punctuation">.</span>pipeline<span class="token punctuation">(</span>
    <span class="token string">"text-generation"</span><span class="token punctuation">,</span> 
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">,</span> 
    device_map<span class="token operator">=</span><span class="token string">"1"</span><span class="token punctuation">,</span> <span class="token comment"># gpu index</span>
    token<span class="token operator">=</span>access_token<span class="token punctuation">,</span>
    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
    <span class="token comment">#low_cpu_mem_usage=False</span>
<span class="token punctuation">)</span>

<span class="token comment"># using demo</span>

system <span class="token operator">=</span><span class="token string">"Provide answers in C++"</span>
user <span class="token operator">=</span> <span class="token string">"Please give me the C style code to return all the Fibonacci numbers under 100."</span>

prompt <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"&lt;s&gt;&lt;&lt;SYS&gt;&gt;\n</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>system<span class="token punctuation">}</span></span><span class="token string">\n&lt;&lt;/SYS&gt;&gt;\n\n</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>user<span class="token punctuation">}</span></span><span class="token string">"</span></span>

<span class="token comment"># build the pipeline for inference</span>
sequences <span class="token operator">=</span> pipeline<span class="token punctuation">(</span>
    prompt<span class="token punctuation">,</span>
    do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> 
    top_k<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> 
    temperature<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
    top_p<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">,</span> 
    num_return_sequences<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    eos_token_id<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>eos_token_id<span class="token punctuation">,</span> 
    max_length<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
    add_special_tokens<span class="token operator">=</span><span class="token boolean">False</span> 
<span class="token punctuation">)</span>

<span class="token comment"># print the result</span>
<span class="token keyword">for</span> seq <span class="token keyword">in</span> sequences<span class="token punctuation">:</span>
  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Result: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>seq<span class="token punctuation">[</span><span class="token string">'generated_text'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>ç»è¿‡ä¸€æ®µæ—¶é—´çš„inferenceåè¾“å‡ºç»“æœï¼š</p> 
<pre><code>Result: &lt;s&gt;&lt;&lt;SYS&gt;&gt;
Provide answers in Python.
&lt;&lt;/SYS&gt;&gt;

Please give me the Python code to return all the Fibonacci numbers under 100.

I have tried the following code but it is not working:
â€‹```
def fibonacci(n):
    if n &lt;= 1:
        return n
    else:
        return fibonacci(n-1) + fibonacci(n-2)

fibonacci_numbers_under_100 = [fibonacci(i) for i in range(1, 100)]
print(fibonacci_numbers_under_100)
â€‹```
Can you please help me with this?

Thank you!

---

Here is the expected output:
â€‹```
[0, 1, 1, 2, 3, 5
</code></pre> 
<h3><a id="13__248"></a>1.3 å…¶ä»–æº</h3> 
<p>å›½å†…å·²ç»å¼€æºçš„ä¸­æ–‡LLAMA2 <a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-2">ymcui/Chinese-LLaMA-Alpaca-2</a></p> 
<p>ï¼ˆæ”¯æŒç™¾åº¦äº‘ç›˜ï¼Œè°·æ­Œç½‘ç›˜ï¼Œhugging_faceä¸‹è½½ï¼‰</p> 
<h3><a id="14_huggingface_255"></a>1.4 huggingfaceä¸‹è½½æ¨¡å‹å’Œæ•°æ®åŠ é€Ÿ</h3> 
<p>åˆ©ç”¨ huggingface-cli è¿›è¡Œä¸‹è½½</p> 
<pre><code>pip install -U huggingface_hub
</code></pre> 
<p>è®¾ç½®ä»£ç†</p> 
<pre><code>export HF_ENDPOINT=https://hf-mirror.com
</code></pre> 
<p>åˆ›å»ºä¸‹è½½ä»»åŠ¡</p> 
<pre><code>huggingface-cli download --resume-download --local-dir-use-symlinks False bigscience/bloom-560m --local-dir bloom-560m
</code></pre> 
<p>å‚æ•°ä»‹ç»ï¼š</p> 
<ul><li> <p>â€“resume-download ä¸‹è½½åœ°å€</p> </li><li> <p>â€“local-dir-use-symlinks æ˜¯å¦æ„å»ºç³»ç»Ÿè½¯é“¾æ¥ï¼ˆç”¨äºhuggingfaceè‡ªåŠ¨è¯†åˆ«æ¨¡å‹ï¼‰</p> </li><li> <p>â€“local-dir æœ¬åœ°æ•°æ®å­˜æ”¾ç›®å½•</p> </li><li> <p>â€“token è‹¥éœ€è¦è®¸å¯ï¼Œåˆ™éœ€è¦åŠ ä¸Šâ€“token hf_***</p> </li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f0f5f3728d03aa54e541afdf2d0e1256/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">PYTHONåŸºç¡€ï¼šæœ€å°äºŒä¹˜æ³•</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c12e203244ba7c070f4f6f37f3fff904/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">Unityä¸­Shaderè£å‰ªç©ºé—´æ¨å¯¼ï¼ˆæ­£äº¤ç›¸æœºåˆ°è£å‰ªç©ºé—´çš„è½¬åŒ–çŸ©é˜µï¼‰</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 ç¼–ç¨‹éšæƒ³.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>