<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>UNeXt：第一个基于卷积和MLP的快速医学图像分割网络 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="UNeXt：第一个基于卷积和MLP的快速医学图像分割网络" />
<meta property="og:description" content="点击下方卡片，关注“CVer”公众号
AI/CV重磅干货，第一时间送达
作者：Wildeur | 已授权转载（源：知乎）编辑：CVer
https://zhuanlan.zhihu.com/p/491798644
UNeXt: MLP-based Rapid Medical Image Segmentation Network
论文：https://arxiv.org/abs/2203.04967
代码（基于PyTorch，已开源）：
https://github.com/jeya-maria-jose/UNeXt-pytorch
1. 摘要 UNet及其最新的扩展如TransUNet是近年来领先的医学图像分割方法。然而，由于这些网络参数多、计算复杂、使用速度慢，因此不能有效地用于即时应用中的快速图像分割。为此，我们提出了一种基于卷积多层感知器(MLP)的图像分割网络unext。我们设计了一种有效的UNeXt方法，即在前期采用卷积阶段和在后期采用MLP阶段。我们提出了一个标记化的MLP块，在该块中，我们有效地标记和投射卷积特征，并使用MLP来建模表示。
为了进一步提高性能，我们建议在输入mlp时shift输入的channel，以便专注于学习局部依赖性。在潜在空间中使用标记化的mlp减少了参数的数量和计算复杂度，同时能够产生更好的表示，以帮助分割。该网络还包括各级编码器和解码器之间的跳跃连接。测试结果表明，与目前最先进的医学图像分割架构相比，UNeXt的参数数量减少了72x，计算复杂度降低了68x，推理速度提高了10x，同时也获得了更好的分割性能。
2. 网络结构 2.1 网络设计: UNeXt是一个编码器-解码器体系结构，有两个阶段: 1) 卷积阶段
2) tokenized MLP阶段。
输入图像通过编码器，其中前3个块是卷积，下2个是tokenized MLP块。解码器有2个tokenized MLP块，后面跟着3个卷积块。每个编码器块减少特征分辨率2倍，每个解码器块增加特征分辨率2。跳跃连接也被应用在了编码器和解码器之间
作者减少了每个stage的通道数。
每个stage的通道数，对比标准的Unet：
UNeXt：32 64 128 160 256
UNet：64 128 256 512 1024
在这里面就减少了很多的参数量
2.2 卷积阶段 有三个conv block，每个block都有一个卷积层（传统Unet是两个）、批量归一化层和ReLU激活。我们使用的内核大小为3×3, stride为1,padding为1。编码器的conv块使用带有池窗口2×2的max-pooling层，而解码器的conv块使用双线性插值层对特征图进行上采样。我们使用双线性插值而不是转置卷积，因为转置卷积基本上是可学习的上采样，会导致产生更多可学习的参数
2.3 Shifted MLP 在shifted MLP中，在tokenize之前，我们首先移动conv features通道的轴线。这有助于MLP只关注conv特征的某些位置，从而诱导块的位置。这里的直觉与Swin transformer类似，在swin中引入基于窗口的注意，以向完全全局的模型添加更多的局域性。由于Tokenized MLP块有2个mlp，我们在一个块中跨越宽度移动特征，在另一个块中跨越高度移动特征，就像轴向注意力中一样。我们对这些特征做了h个划分，并根据指定的轴通过j个位置移动它们。这有助于我们创建随机窗口，引入沿轴线的局部性。
Shift操作 图中灰色是特征块的位置，白色是移动之后的padding。
2.4 Tokenized MLP阶段 image-20220402001733482 在Tokenized MLP块中，我们首先shift features并将它们投射到token中。为了进行token化，我们首先使用3x3conv把特征投射到E维，其中E是embadding维度(token的数量)，它是一个超参数。然后我们将这些token传递给一个shifted MLP(跨越width)。接下来，特征通过 DW-Conv传递。然后我们使用GELU激活层。然后，我们通过另一个shifted MLP(跨越height)传递特征，该mlp把特征的尺寸从H转换为了O。我们在这里使用一个残差连接，并将原始标记添加为残差。然后我们利用layer norm（LN），并将输出特征传递到下一个块。LN比BN更可取，因为它更有意义的是沿着token进行规范化，而不是在Tokenized MLP块的整个批处理中进行规范化。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/03081d574e9444a227049e5672d559de/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-04T23:59:00+08:00" />
<meta property="article:modified_time" content="2022-04-04T23:59:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">UNeXt：第一个基于卷积和MLP的快速医学图像分割网络</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:center;">点击下方<strong>卡片</strong>，关注“<strong>CVer</strong>”公众号</p> 
 <p style="text-align:center;">AI/CV重磅干货，第一时间送达</p> 
 <p><strong>作者</strong><strong>：Wildeur  |  </strong><strong>已授权转载（源：知乎）编辑：CVer</strong></p> 
 <p><strong>https://zhuanlan.zhihu.com/p/491798644</strong></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/1a/74/X4Z5sP25_o.png" alt="0233aea59a694c6f050df3ccd65acba5.png"></p> 
 <p><strong>UNeXt: MLP-based Rapid Medical Image Segmentation Network</strong><br></p> 
 <p>论文：https://arxiv.org/abs/2203.04967</p> 
 <p>代码（基于PyTorch，已开源）：</p> 
 <p><strong>https://github.com/jeya-maria-jose/UNeXt-pytorch</strong></p> 
 <h3>1. 摘要</h3> 
 <p style="text-align:justify;"><a href="" rel="nofollow">UNet</a>及其最新的扩展如<a href="" rel="nofollow">TransUNet</a>是近年来领先的医学图像分割方法。然而，由于这些网络参数多、计算复杂、使用速度慢，因此不能有效地用于即时应用中的快速图像分割。为此，我们提出了一种基于卷积多层感知器(MLP)的图像分割网络unext。我们设计了一种有效的UNeXt方法，即在前期采用卷积阶段和在后期采用MLP阶段。我们提出了一个标记化的MLP块，在该块中，我们有效地标记和投射卷积特征，并使用MLP来建模表示。</p> 
 <p style="text-align:justify;">为了进一步提高性能，我们建议在输入mlp时shift输入的channel，以便专注于学习局部依赖性。在潜在空间中使用标记化的mlp减少了参数的数量和计算复杂度，同时能够产生更好的表示，以帮助分割。该网络还包括各级编码器和解码器之间的跳跃连接。测试结果表明，与目前最先进的医学图像分割架构相比，UNeXt的参数数量减少了72x，计算复杂度降低了68x，推理速度提高了10x，同时也获得了更好的分割性能。</p> 
 <h3>2. 网络结构</h3> 
 <h4>2.1 网络设计:</h4> 
 <h4>UNeXt是一个编码器-解码器体系结构，有两个阶段:</h4> 
 <p>  1) 卷积阶段</p> 
 <p>  2) tokenized MLP阶段。</p> 
 <p style="text-align:justify;">输入图像通过编码器，其中前3个块是卷积，下2个是tokenized MLP块。解码器有2个tokenized MLP块，后面跟着3个卷积块。每个编码器块减少特征分辨率2倍，每个解码器块增加特征分辨率2。跳跃连接也被应用在了编码器和解码器之间</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/59/2d/VOgbDL6X_o.png" alt="813be302d1d8181ada15a688f22e13f0.png"></p> 
 <p>作者减少了每个stage的通道数。<br></p> 
 <p>每个stage的通道数，对比标准的Unet：</p> 
 <ul><li> 
   <ul><li><p>UNeXt：32 64 128 160 256</p></li><li><p>UNet：64 128 256 512 1024</p></li></ul></li></ul> 
 <p>在这里面就减少了很多的参数量</p> 
 <h4>2.2 卷积阶段</h4> 
 <p style="text-align:justify;">有三个conv block，每个block都有一个卷积层（传统Unet是两个）、批量归一化层和ReLU激活。我们使用的内核大小为3×3, stride为1,padding为1。编码器的conv块使用带有池窗口2×2的max-pooling层，而解码器的conv块使用双线性插值层对特征图进行上采样。我们使用双线性插值而不是转置卷积，因为转置卷积基本上是可学习的上采样，会导致产生更多可学习的参数</p> 
 <h4>2.3 Shifted MLP</h4> 
 <p style="text-align:justify;">在shifted MLP中，在tokenize之前，我们首先移动conv features通道的轴线。这有助于MLP只关注conv特征的某些位置，从而诱导块的位置。这里的直觉与Swin transformer类似，在swin中引入基于窗口的注意，以向完全全局的模型添加更多的局域性。由于Tokenized MLP块有2个mlp，我们在一个块中跨越宽度移动特征，在另一个块中跨越高度移动特征，就像轴向注意力中一样。我们对这些特征做了h个划分，并根据指定的轴通过j个位置移动它们。这有助于我们创建随机窗口，引入沿轴线的局部性。</p> 
 <img width="1012" src="https://images2.imgbox.com/d6/06/JtO2EUie_o.png" alt="f0b6a0af65d0ce30138fbdd658dc4fed.png"> 
 <figcaption>
   Shift操作 
 </figcaption> 
 <p>图中灰色是特征块的位置，白色是移动之后的padding。</p> 
 <h4>2.4 Tokenized MLP阶段</h4> 
 <img width="1064" src="https://images2.imgbox.com/13/2c/xwHQtBzF_o.png" alt="e6f3b3c2c54800a652f9d51408b1912a.png"> 
 <figcaption>
   image-20220402001733482 
 </figcaption> 
 <p style="text-align:justify;">在Tokenized MLP块中，我们首先shift features并将它们投射到token中。为了进行token化，我们首先使用3x3conv把特征投射到E维，其中E是embadding维度(token的数量)，它是一个超参数。然后我们将这些token传递给一个shifted MLP(跨越width)。接下来，特征通过 DW-Conv传递。然后我们使用GELU激活层。然后，我们通过另一个shifted MLP(跨越height)传递特征，该mlp把特征的尺寸从H转换为了O。我们在这里使用一个残差连接，并将原始标记添加为残差。然后我们利用layer norm（LN），并将输出特征传递到下一个块。LN比BN更可取，因为它更有意义的是沿着token进行规范化，而不是在Tokenized MLP块的整个批处理中进行规范化。</p> 
 <h4>我们在这个块中使用DWConv有两个原因:</h4> 
 <p style="text-align:justify;">1)它有助于编码MLP特征的位置信息。从中可以看出，在一个MLP块中Conv层已经足够对位置信息进行编码，并且实际性能优于标准的位置编码技术。当测试或者训练分辨率不相同时，像ViT中的位置编码技术需要插值，这通常会导致性能下降。</p> 
 <p style="text-align:justify;">2)DWConv使用更少的参数，因此提高了效率。</p> 
 <h4>Tokenized block的计算流程</h4> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/ee/b7/J5JMra7B_o.png" alt="89c05e9064c3331523a56052c0030629.png"></p> 
 <p style="text-align:justify;">所有这些计算都是在嵌入维数h上执行的，这个维数明显小于特征的维数 (H/N)×(H/N) ,N是关于降维的2的因子。在我们的实验中，除非另有说明，否则我们使用768。这种设计tokenized MLP block的方法有助于编码有意义的特征信息，而不会对计算或参数贡献太多。</p> 
 <h3>3.实验结果</h3> 
 <p>在ISIC和BUSI数据集进行了实验</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/11/1d/pThCwpUN_o.png" alt="6cb5d3abce23758fe44440466a8aa995.png"></p> 
 <p>在ISIC数据集的对比</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/0e/f2/ylPJhQYM_o.png" alt="9ab86cc00b68d8de5128b2b1a96fc7e1.png"></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/07/0e/DiAcUTr2_o.png" alt="f3460664cafdcf72af230bb53bd8152d.png"></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/e2/4c/jnUkAqOa_o.png" alt="eeba85ba472208ef961665af14e40397.png"></p> 
 <h3>4. 个人感悟<br></h3> 
 <p style="text-align:justify;">首先每个convolutional阶段只有一个卷积层，极大的减少了运算量，是答主第一次见了。</p> 
 <p style="text-align:justify;">其次是把MLP的模块引入了Unet，算是很新颖了。</p> 
 <p style="text-align:justify;">在Tokenized MLP block中使用DW- CONV，让人眼前一亮。</p> 
 <p style="text-align:left;"><strong>UNeXT 论文和代码下载</strong></p> 
 <p style="text-align:left;">后台回复：<strong>UNeXT，</strong>即可下载上述论文和代码</p> 
 <p style="text-align:left;">后台回复：<strong>ICCV2021，</strong>即可下载ICCV 2021论文和代码开源的论文合集</p> 
 <p style="text-align:left;">后台回复：<strong>CVPR2021，</strong>即可下载CVPR 2021论文和代码开源的论文合集</p> 
 <pre class="has"><code class="language-go">重磅！医学图像 交流群成立
扫描下方二维码，或者添加微信：CVer6666，即可添加CVer小助手微信，便可申请加入CVer-医疗影像微信交流群。另外其他垂直方向已涵盖：目标检测、图像分割、目标跟踪、人脸检测&amp;识别、OCR、姿态估计、超分辨率、SLAM、医疗影像、Re-ID、GAN、NAS、深度估计、自动驾驶、强化学习、车道线检测、模型剪枝&amp;压缩、去噪、去雾、去雨、风格迁移、遥感图像、行为识别、视频理解、图像融合、图像检索、论文投稿&amp;交流、PyTorch、TensorFlow和Transformer等。
一定要备注：研究方向+地点+学校/公司+昵称（如医疗影像+上海+上交+卡卡），根据格式备注，可更快被通过且邀请进群

▲扫码或加微信: CVer6666，进交流群
CVer学术交流群（知识星球）来了！想要了解最新最快最好的CV/DL/ML论文速递、优质开源项目、学习教程和实战训练等资料，欢迎扫描下方二维码，加入CVer学术交流群，已汇集数千人！

▲扫码进群
▲点击上方卡片，关注CVer公众号

整理不易，请点赞和在看</code></pre> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b9c7ee3785588e68cd78dc19d9fc677d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">RuoYi若依打包发布与部署</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ec63aad47f496d26154237f051c70909/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">单链表 C&#43;&#43; 模板题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>