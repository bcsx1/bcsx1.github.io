<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>多视图点云配准算法综述 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="多视图点云配准算法综述" />
<meta property="og:description" content="作者：杨佳琪,张世坤,范世超等
转载自：华中科技大学学报（自然科学版）
编辑：东岸因为@一点人工一点智能
原文：​​多视图点云配准算法综述​​
摘要：以多视图点云配准为研究对象，对近二十余年的多视图点云配准相关研究工作进行了全面的分类归纳及总结。首先，阐述点云数据及多视图点云配准的概念。根据配准的任务不同，将多视图点云配准分为多视图点云粗配准和多视图点云精配准两大类，并对其各自算法的核心思想及算法改进进行介绍，其中，多视图点云粗配准算法进一步分为基于生成树和基于形状生成两类；多视图点云精配准算法进一步分为基于点云的点空间、基于点云的帧空间变换平均、基于深度学习和基于优化四类。然后，介绍了四种多视图点云配准数据集及主流多视图配准评价指标。最后，对该研究领域研究现状进行总结，指出存在的挑战，并给出了未来研究展望。
随着激光雷达(LiDAR)和Kinect等三维传感器的快速发展，点云已成为表征三维世界的主要数据格式。点云配准是计算机视觉、移动机器人学和计算机图形学等领域的一项基本任务，其在三维重建、三维定位、自动驾驶、位姿估计、逆向工程及虚拟现实等领域有着广泛应用。点云配准其实质是估计点云之间的刚体变换关系，通过变换关系将点云数据变换到统一参考坐标系。点云配准根据点云视图的数量，可分为两两视图点云配准和多视图点云配准。与两两视图点云配准相比，由于多视图点云配准须要求解大量的配准参数，其求解参数量远高于两两视图点云配准，因此难度更大，也是当前研究领域的热点问题。
然而，目前仍缺少全面的综述文献对多视图点云配准算法进行全面和系统的梳理，为了解决该问题，本研究对近二十余年的多视图点云配准算法研究进行了分类归纳及总结，旨在更加深入和全面地认识多视图点云配准算法的发展历程、算法思路、最新进展、常用​​数据库​​、评价指标、领域现存问题及未来潜在的发展趋势。
01 点云配准概述 随着计算机扫描技术与坐标测量技术的日益强大，获得包含物体几何属性与空间三维信息的海量离散点云数据，即离散点的集合，变得极为便捷。点云存储更加符合人对事物的观察习惯，以立体的形式直观展现。此外，点云数据结构简单，可以通过较小的存储代价精确地记录三维模型的几何结构和拓扑关系，避免了传统存储方式在处理过程中为了保持拓扑关系而强加的各种限制条件。
根据点云数据获取方式的不同，可分为接触式获取点云与非接触式获取点云。接触式获取点云[1]主要通过传感探头与被测模型的物理接触来获取三维点云数据，该方式不受物体表面颜色及光照等因素的限制，可以准确捕捉物体的轮廓边缘，但是速度很慢，且效率低。非接触式获取点云[2]主要是基于光学、磁学等领域的基本原理进行​​数据采集​​，其测量速度较快，效率较高，但是难以精确获得三维物体的轮廓边缘。基于光学方法的非接触式获取点云是目前主流的三维点云数据获取方法，图1展示了从不同角度所采集斯坦福大学数据集兔子模型10个视图的点云数据。
图1 斯坦福数据库兔子模型采集的多视图点云数据 点云配准旨在将不同坐标系获取的点云数据变换到同一坐标系，根据视图数量可分为两两视图点云配准和多视图点云配准。两两视图点云配准旨在将具有一定重叠区域的两组点云配准到一个坐标系，主要流程为：首先，将两组点云分别视为源点云与目标点云，提取两组点云的特征；然后，根据提取到的特征确定两组点云间的对应点；最后，根据对应点估计旋转平移参数，源点云根据旋转平移参数变换到目标点云坐标系。两两视图点云配准算法的研究已有较为全面的综述文献[3-6]。
相比之下，多视图点云配准因为求解参数量的增加及累积误差的存在，更具挑战性。多视图点云配准通过算法建立点云间的关联，将所有不同坐标系下的点云数据配准到参考坐标系。在多视图点云配准整个流程中，先进行多视图点云粗配准再进行多视图点云精配准是当前最广泛使用的多视图点云配准策略。多视图点云配准步骤如图2所示。
图2 多视图点云配准流程图 根据配准任务不同，可将多视图点云配准划分为多视图点云粗配准和多视图点云精配准，其中：多视图点云粗配准将所有视图点云数据初始对齐，为精配准提供良好的初始条件；多视图点云精配准则是在多视图点云粗配准的基础上，进一步消除所有视图点云间的累计误差，使得多个点云之间的配准累计误差尽最大可能被消除。鉴于目前尚无关于多视图点云刚性数据配准的综述工作，本研究首次对近二十余年的多视图点云配准算法进行归纳总结。如图3所示，本研究依据是否须要建立点云数据间的网络拓扑关系，将多视图点云粗配准算法分为基于生成树的多视图点云粗配准算法和基于形状生成的多视图点云粗配准算法；多视图精配准算法根据使用的点云和帧空间信息及核心算法不同，可进一步分为基于点空间多视图精配准算法、基于帧空间变换平均多视图精配准算法、基于深度学习的多视图精配准算法和基于优化的多视图精配准算法这四类。根据算法分类，本研究对该领域算法的发展历程、算法思路、最新进展、常用数据库、评价指标、领域现存问题及未来潜在的发展趋势进行介绍。
图3 多视图点云配准算法分类图 本研究的主要工作如下：a．针对多视图点云配准领域缺少全面综述的问题，对近二十余年的多视图点云配准算法进行分类、思路概述及优缺点总结；b．整理了四个当前主流的配准数据集及通用的多视图配准评价指标作为评判基准，为方法的公平对比提供参考，也揭示了该领域缺乏统一的数据库及方法评价指标的问题；c．根据算法综述，总结了领域的研究进展和现存挑战，并指出了未来发展趋势，为后续研究提供明确思路。
02 多视图点云粗配准 多视图点云粗配准在两两视图点云配准的基础上，直接或间接初始对齐多视图点云数据，其更多关注配准能否成功以及配准时间开销，该类算法只须要大致对齐多视图点云数据，在后续的多视图点云精配准中会消除多视图点云粗配准阶段所产生的配准累积误差。多视图粗配准算法根据是否建立点云数据间的网络拓扑关系，可分为基于生成树的多视图粗配准算法和基于形状生成的多视图粗配准算法。
2.1 基于生成树的多视图点云粗配准 基于生成树多视图点云粗配准算法的核心思想是把每个点云看作节点，首先根据节点间的关系构建生成树，根据生成树可以直接或间接配准任意两组点云；然后选择参考坐标系，通过相应点云间的运动变换将所有视图点云数据配准到参考坐标系。在基于生成树的多视图点云粗配准中，有三个关键问题须要在设计该类算法时考虑：a．判断两两视图点云配准成功与失败的评判依据；b．两两视图点云配准算法的选择；c．生成树根节点的选择。
基于生成树的多视图点云粗配准有两种方案获得生成树。第一种方案[7-9]：首先进行所有两两视图点云配准，若配准成功则建立连接，否则不建立连接；然后根据两两视图配准结果生成连通图；最后在连通图中根据一定的约束条件和最优条件获得生成树。虽然该类生成树算法能够得到较好的粗配准结果，但是生成树通过暴力穷举所有两两视图配准获得，假设有N片点云，使用同一种两两视图点云配准算法，该类生成树粗配准算法的时间复杂度高达O(N2)。
针对穷举两两视图点云配准来生成树算法存在的问题，于是便有了第二种方案，即改进的生成树多视图点云粗配准算法[10-12]：选择一点云作为生成树根节点，将剩余点云依次与根节点进行两两视图点云配准，若存在节点无法与根节点成功配准，则待所有节点与根节点完成配准，选择一个与根节点直接相连的节点作为新的根节点，继续两两视图点云进行配准，直到建立生成树。该算法相较于穷举两两视图点云配准来生成树的多视图粗配准算法，使用相同的两两配准算法，配准次数大幅度减少，从而大规模降低了粗配准时间开销。
改进的生成树多视图点云粗配准算法输入为个点云数据，输出为N个刚性变换矩阵。该算法首先选出根节点，放入根节点集合，剩余节点放入待配准集合。当待配准集合不空时，a．待配准集合的节点依次与根节点两两配准；b．若两两配准结果满足一定的条件，则与当前根节点建立连接，将当前节点从待配准集合移除并加入根节点集合，否则选择待配准集合中下一片点云；c．判断待配准集合的所有点云是否完成配准，若待配准集合为空，则该算法完成，否则从根节点的集合中选择一个节点作为新的根节点，返回步骤a。
文献[7]使用基于自旋图像特征描述子的生成树多视图点云粗配准算法。首先，该算法根据所有视图两两点云配准结果构建连通图；然后，根据连通图构建生成树；最后，通过生成树建立点云间关系完成多视图点云粗配准。由于该算法须要进行所有两两视图点云配准，因此非常耗时，不适用于大规模点云数据多视图点云配准。文献[8-9,13]使用相同构建生成树的方法，分别使用方向直方图特征、指数映射和极坐标映射算法进行两两视图点云配准。
针对第一类生成树算法时间复杂度高的问题，文献[14]首先将第一个读取点云作为根节点，设计双重评价标准判断两两视图点云配准的可靠性；然后依次添加点云进行两两视图点云配准，直到生成树构造完成；最后根据生成树完成多视图点云粗配准。随后，文献[10]进一步改进：使用点云间的重叠率作为判断一组点云是否进行两两视图点云配准的依据；依次将重叠率大于阈值的点云对进行两两视图点云配准，直到生成树构造完成；根据生成树完成多视图粗配准。
文献[11]提出连通图算法和超图算法来构建生成树，连接图算法将曲面面积最大的点云作为根节点，然后作为算法的输入，得到一颗生成树。超图算法与连接图算法类似，当根节点与所有点云配准完成后，从所有未能成功配准的点云中重新选择一个节点作为根节点来依次两两配准来生成连通图；通过子节点与其他连通图根节点连接得到生成树。文献[15]使用类似技术，基于三重旋转图像特征来完成多视图点云配准。文献[12]将点云中点数量最多的点云作为根节点替代曲面面积最大的点云，替代后配准效果不会明显变差，同时减少根节点选择所带来的时间开销，然后将根节点与其他节点划分到两个不同的集合；其他节点和根节点依次进行两两视图点云配准；通过随机抽样一致性算法的内点数来判断是否建立两节点之间的有向边。
文献[16]提出任意选择一点云作为根节点，将根节点的局部坐标系设置为全局参考坐标系；每个点云与根节点直接或间接完成两两视图点云配准，选取加权最短路径作为点云间接配准的最优路径；根据子节点到根节点的加权路径最短来构建最小生成树。
2.2 基于形状生成的多视图点云粗配准 基于形状生成的多视图点云粗配准算法核心是迭代生成种子性状点云数据，将其作为目标点云，增加源点云与目标点云的重叠率，从而提高配准成功的可能性。该类算法适用于点云之间重叠率较低的数据集。形状生成算法首先将所有点云初始化到搜索集合，然后任意选择一点云作为种子形状点云，并将种子形状点云从搜索集合移除；当搜索集合不为空集时，a．从搜索集合中选择一点云作为源点云与种子性状点云两两视图点云配准；b．若两两配准成功，则将种子形状点云更新，将源点云与种子性状点云非重叠部分点云数据加到种子形状点云中，并将源点云从搜索集合中移除，若两两配准失败，则选择搜索集合中的其他点云作为源点云。
文献[17]提出基于形状生成的多视图点云粗配准算法，该算法随机选择一个点云作为种子形状点云，剩余点云依次与种子形状点云两两配准，配准成功后更新种子形状点云，直到所有点云成功配准．该算法使用旋转投影统计特征提取匹配，根据设计的判断标准来寻找有效的两两点云配准进行点云形状生长。
与基于生成树多视图粗配准算法相比，形状生成多视图粗配准算法更适用于低重叠率的点云数据且不须要构造点云间网络拓扑结构。基于形状生成多视图粗配准示意图如图4所示。
图4 基于形状生成多视图粗配准示意图 ​03 多视图点云精配准算法 多视图点云粗配准得到一组点云初始对齐的变换矩阵作为多视图精配准的输入，多视图点云精配准则更多关注于多视图点云配准的精度。近年来，多视图点云精配准引起越来越多学者关注，陆续出现各种多视图点云精配准问题的解决方案。多视图点云精配准算法的关键是尽最大可能快速消除所有变换误差和配准累计误差。图5以时间顺序展示了多视图点云精配准研究历程中部分经典的算法。
图5 多视图点云精配准经典算法概述 ​3.1 基于点云的点空间变换多视图精配准算法 基于点云的点空间多视图精配准算法要求充分利用所有点云中可用点信息，考虑点云中对应点关系，将其作为约束优化变换参数。这里概述基于点云点空间的多视图精配准算法：基于正态分布变换，基于聚类，基于迭代最近点(ICP)及变种，基于信息熵理论的多视图精配准算法。基于点云的点空间多视图点云配准算法的分类如图6所示。
图6 基于点云点空间变换多视图精配准算法分类图 3.1.1 基于迭代最近点的多视图精配准 文献[18]提出ICP算法，后续众多基于迭代最近点的多视图点云精配准算法以该算法为核心展开研究。为找到点云间正确的点对应关系，该算法计算粗配准变换后源点云上所有点到目标点云的距离，将两片点云中距离最小的点对视为对应点；保证源点云上的点和目标点云的点相互对应，同时构造残差平方和目标函数；使用最小二乘法对误差函数进行最小化处理，经过反复迭代直到均方误差小于设定的阈值。ICP两两点云配准算法精度高，但该算法容易陷入局部最优解且容易受到噪声点的干扰。ICP算法选中两片点云分别作为源点云和目标点云，核心步骤如下：a．在目标点云Q中取点集；b．找出源点云P中对应点集，使对应点的距离最小；c．计算旋转矩阵和平移向量，使误差函数最小；d．对源点云进行刚性变换；e．计算对应点集的平均距离；f．若小于某一给定的阈值或大于预设的最大迭代次数，则停止迭代，否则返回步骤b，直到满足收敛条件为止。
文献[19]提出直接对两两ICP算法扩展，将多视图点云精配准视为两两点云ICP精配准；通过两个点云不断地用ICP精配准和合并点云数据的策略，依次配准和合并两个点云数据，直到所有点云数据合并到一个点云。该算法提供对齐和合并的多视图点云精配准框架，任意两两视图点云精配准算法都能直接应用到该框架，从而完成多视图点云精配准。该算法简单可行，但随着点云数据的合并，ICP精配准算法的对应点搜寻时间会增加，同时存在配准误差累计问题。
文献[20]首次提出针对多视图点云精配准的算法。该算法首先通过星形网络在所有点云间建立连接，星形网络的中心点云与其他点云互相寻找点对应关系；然后通过ICP算法估计点云数据间刚性变换；最后将配准误差最小作为目标函数优化每个点云的刚性变换参数。该算法同时考虑所有点云数据来优化配准参数，一定程度上解决误差累计问题，但须要为中心点云建立多个点对应关系，每个中心点云须要与其他所有点云数据进行两两配准，导致该算法耗时较长。
考虑到文献[20]提出的星网络ICP算法在建立点云间对应点关系过程中非常耗时，文献[21]使用高斯球型的多缓冲区来加速重叠区域点对应关系的建立，在建立点对应关系后，通过星网络ICP精配准算法来完成多视图精配准。
文献[22]提出利用颜色信息的ICP多视图点云精配准算法，同样使用两两点云ICP精配准和合并的方法。与之前方法不同的是：该方法不仅考虑点云数据中点空间的信息，而且考虑点云数据的颜色信息。由于该类算法使用点云数据的颜色信息，因此不适用于激光扫描等传感器获取不到颜色信息的点云数据。
文献[23]提出使用ICP算法配准多个点云，同时最小化所有点云的配准误差来获得全局最优刚性变换的算法。将配准问题转换为最小二乘配准误差函数最小化，将配准误差函数简化为包含未知矩阵和常数矩阵的二次表达式。
文献[24]提出使用广义普鲁克分析考虑同时配准所有点云数据，将其嵌入到ICP算法框架；在寻找匹配点对期间，只有两个点互相为最近邻点才是匹配点对；对于有多个匹配关系的点云，则忽略这些点对匹配；将每个匹配点对的质心求出，使用ICP算法求解最优刚性变换。
文献[17]将列文伯格-马奈尔特(LM)算法嵌入到ICP算法。该算法须要建立最小生成树，对所有点云沿最短加权路径，全局使用LM-ICP算法配准到全局参考坐标系。
文献[10]提出局部到全局多视图点云修剪迭代最近点精配准算法。该算法依次选中粗配准阶段生成树的第二层的一个节点作为源点云，根节点和第二层的其他节点点云合并作为目标点云，源点云和目标点云通过修剪迭代最近点算法(TrICP)进行配准；第二层点云经过层次遍历完成配准后；将根节点与第二层节点合并成为新的根节点；再进行新的根节点和第二层节点的局部多视图点云配准；直到所有节点合并到一个节点，局部多视图点云精配准完成。在此基础上进行全局多视图点云精配准，将每个点云依次作为源点云，其他所有点云数据作为目标点云，依次对源点云和目标点云通过TrICP进行多视图精配准。
文献[12]提出形状增长迭代最近点算法来消除多视图粗配准产生的累积误差。该算法将根节点作为形状生成的基准节点，通过对生成树的层次遍历依次将子节点与根节点进行两两ICP精配准，然后将子节点的点云数据非重叠部分添加到根节点合并，直到遍历完所有的节点。
文献[15]提出采用从粗到精的采样点云数据的方法以提高计算效率。当使用ICP算法时，只取源点云的一部分点，对点云进行随机采样和均匀采样，在ICP算法中配准性能相似。该算法使用随机采样获取点云，每次选取采样点的点数与配准误差相关，最初使用少量样本点以降低ICP算法的时间开销，当误差减小时，使用更多的样本点以提高配准精度。为进一步提高ICP算法的准确性和稳定性，在每次迭代中拒绝点到点距离大于平均网格分辨率两倍的所有异常点对。
3.1.2 基于聚类的多视图精配准 聚类可分为硬聚类和软聚类：硬聚类是指将数据确切地划分到一个确定的簇；软聚类是指将数据以一定概率分到各簇中。本研究将基于聚类的多视图精配准算法分为基于K均值(K-means)聚类多视图精配准算法和基于混合分布模型的多视图精配准算法。基于K-means聚类多视图精配准算法属于硬聚类，将所有点云数据的点划分到一个簇，簇内所有点跟对应的簇中心点进行对齐；基于混合分布模型的多视图精配准算法是软聚类问题，使用混合模型来表示点云数据，通过期望最大化算法来优化混合模型的参数，从而完成多视图点云精配准。基于聚类的多视图精配准算法精度高，且对噪声和异常值鲁棒，但由于须要建立大量的点对应关系，因此耗时较长。
a．基于K-means聚类的多视图精配准
K-means聚类算法最初由文献[25]引入点云配准领域，起初用于检测和合并点云重叠区域的对应点，不涉及更新刚性变换，后续便开始使用K-means聚类算法来完成多视图点云精配准。该类算法将不同视图点云配准问题转化为不同簇内点云对齐问题，将同一个簇内的点向簇中心逼近，没有考虑点云之间的一致性关系，一定程度上会影响配准精度。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/ca2bd4e56b43831e9091e4f6f1b915a6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-17T16:14:54+08:00" />
<meta property="article:modified_time" content="2023-02-17T16:14:54+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">多视图点云配准算法综述</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>作者：杨佳琪,张世坤,范世超等</p> 
<p>转载自：华中科技大学学报（自然科学版）</p> 
<p>编辑：东岸因为@一点人工一点智能</p> 
<p>原文：​<a href="https://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&amp;mid=2247508207&amp;idx=3&amp;sn=44c6adedadd0c5cccd02e7fda838bd54&amp;chksm=f9e634eace91bdfcf4626f862654ba3bc8ab055d0f1cc91e537b902304fb783c779a422ec338&amp;token=306214752&amp;lang=zh_CN#rd" rel="nofollow" title="​多视图点云配准算法综述​">​多视图点云配准算法综述​</a>​</p> 
<p><strong>摘要：</strong>以多视图点云配准为研究对象，对近二十余年的多视图点云配准相关研究工作进行了全面的分类归纳及总结。首先，阐述点云数据及多视图点云配准的概念。根据配准的任务不同，将多视图点云配准分为多视图点云粗配准和多视图点云精配准两大类，并对其各自算法的核心思想及算法改进进行介绍，其中，多视图点云粗配准算法进一步分为基于生成树和基于形状生成两类；多视图点云精配准算法进一步分为基于点云的点空间、基于点云的帧空间变换平均、基于深度学习和基于优化四类。然后，介绍了四种多视图点云配准数据集及主流多视图配准评价指标。最后，对该研究领域研究现状进行总结，指出存在的挑战，并给出了未来研究展望。</p> 
<hr> 
<p>随着激光雷达(LiDAR)和Kinect等三维传感器的快速发展，点云已成为表征三维世界的主要数据格式。点云配准是计算机视觉、移动机器人学和计算机图形学等领域的一项基本任务，其在三维重建、三维定位、自动驾驶、位姿估计、逆向工程及虚拟现实等领域有着广泛应用。点云配准其实质是估计点云之间的刚体变换关系，通过变换关系将点云数据变换到统一参考坐标系。点云配准根据点云视图的数量，可分为两两视图点云配准和多视图点云配准。与两两视图点云配准相比，由于多视图点云配准须要求解大量的配准参数，其求解参数量远高于两两视图点云配准，因此难度更大，也是当前研究领域的热点问题。</p> 
<p>然而，目前仍缺少全面的综述文献对多视图点云配准算法进行全面和系统的梳理，为了解决该问题，本研究对近二十余年的多视图点云配准算法研究进行了分类归纳及总结，旨在更加深入和全面地认识多视图点云配准算法的发展历程、算法思路、最新进展、常用​<a href="https://cloud.tencent.com/solution/database?from=10680" rel="nofollow" title="​数据库​">​数据库​</a>​、评价指标、领域现存问题及未来潜在的发展趋势。</p> 
<h3 id="h490b8bf-cjjOT6CW">01  点云配准概述</h3> 
<p>随着计算机扫描技术与坐标测量技术的日益强大，获得包含物体几何属性与空间三维信息的海量离散点云数据，即离散点的集合，变得极为便捷。点云存储更加符合人对事物的观察习惯，以立体的形式直观展现。此外，点云数据结构简单，可以通过较小的存储代价精确地记录三维模型的几何结构和拓扑关系，避免了传统存储方式在处理过程中为了保持拓扑关系而强加的各种限制条件。</p> 
<p>根据点云数据获取方式的不同，可分为接触式获取点云与非接触式获取点云。接触式获取点云[1]主要通过传感探头与被测模型的物理接触来获取三维点云数据，该方式不受物体表面颜色及光照等因素的限制，可以准确捕捉物体的轮廓边缘，但是速度很慢，且效率低。非接触式获取点云[2]主要是基于光学、磁学等领域的基本原理进行​<a href="https://cloud.tencent.com/solution/data-collect-and-label-service?from=10680" rel="nofollow" title="​数据采集​">​数据采集​</a>​，其测量速度较快，效率较高，但是难以精确获得三维物体的轮廓边缘。基于光学方法的非接触式获取点云是目前主流的三维点云数据获取方法，图1展示了从不同角度所采集斯坦福大学数据集兔子模型10个视图的点云数据。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/b2/4d/UpTRGquT_o.png"> 
  <figcaption>
    图1 斯坦福数据库兔子模型采集的多视图点云数据 
  </figcaption> 
 </figure> 
</div> 
<p>点云配准旨在将不同坐标系获取的点云数据变换到同一坐标系，根据视图数量可分为两两视图点云配准和多视图点云配准。两两视图点云配准旨在将具有一定重叠区域的两组点云配准到一个坐标系，主要流程为：首先，将两组点云分别视为源点云与目标点云，提取两组点云的特征；然后，根据提取到的特征确定两组点云间的对应点；最后，根据对应点估计旋转平移参数，源点云根据旋转平移参数变换到目标点云坐标系。两两视图点云配准算法的研究已有较为全面的综述文献[3-6]。</p> 
<p>相比之下，多视图点云配准因为求解参数量的增加及累积误差的存在，更具挑战性。多视图点云配准通过算法建立点云间的关联，将所有不同坐标系下的点云数据配准到参考坐标系。在多视图点云配准整个流程中，先进行多视图点云粗配准再进行多视图点云精配准是当前最广泛使用的多视图点云配准策略。多视图点云配准步骤如图2所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/b4/90/bkGUtD9N_o.png"> 
  <figcaption>
    图2 多视图点云配准流程图 
  </figcaption> 
 </figure> 
</div> 
<p>根据配准任务不同，可将多视图点云配准划分为多视图点云粗配准和多视图点云精配准，其中：多视图点云粗配准将所有视图点云数据初始对齐，为精配准提供良好的初始条件；多视图点云精配准则是在多视图点云粗配准的基础上，进一步消除所有视图点云间的累计误差，使得多个点云之间的配准累计误差尽最大可能被消除。鉴于目前尚无关于多视图点云刚性数据配准的综述工作，本研究首次对近二十余年的多视图点云配准算法进行归纳总结。如图3所示，本研究依据是否须要建立点云数据间的网络拓扑关系，将多视图点云粗配准算法分为基于生成树的多视图点云粗配准算法和基于形状生成的多视图点云粗配准算法；多视图精配准算法根据使用的点云和帧空间信息及核心算法不同，可进一步分为基于点空间多视图精配准算法、基于帧空间变换平均多视图精配准算法、基于深度学习的多视图精配准算法和基于优化的多视图精配准算法这四类。根据算法分类，本研究对该领域算法的发展历程、算法思路、最新进展、常用数据库、评价指标、领域现存问题及未来潜在的发展趋势进行介绍。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/f9/27/GV7oEJ2L_o.png"> 
  <figcaption>
    图3 多视图点云配准算法分类图 
  </figcaption> 
 </figure> 
</div> 
<p>本研究的主要工作如下：a．针对多视图点云配准领域缺少全面综述的问题，对近二十余年的多视图点云配准算法进行分类、思路概述及优缺点总结；b．整理了四个当前主流的配准数据集及通用的多视图配准评价指标作为评判基准，为方法的公平对比提供参考，也揭示了该领域缺乏统一的数据库及方法评价指标的问题；c．根据算法综述，总结了领域的研究进展和现存挑战，并指出了未来发展趋势，为后续研究提供明确思路。</p> 
<h3 id="h490b8bf-KR3inHcj">02  多视图点云粗配准</h3> 
<p>多视图点云粗配准在两两视图点云配准的基础上，直接或间接初始对齐多视图点云数据，其更多关注配准能否成功以及配准时间开销，该类算法只须要大致对齐多视图点云数据，在后续的多视图点云精配准中会消除多视图点云粗配准阶段所产生的配准累积误差。多视图粗配准算法根据是否建立点云数据间的网络拓扑关系，可分为基于生成树的多视图粗配准算法和基于形状生成的多视图粗配准算法。</p> 
<h4 id="h6f20189-8eYKXbC8">2.1 基于生成树的多视图点云粗配准</h4> 
<p>基于生成树多视图点云粗配准算法的核心思想是把每个点云看作节点，首先根据节点间的关系构建生成树，根据生成树可以直接或间接配准任意两组点云；然后选择参考坐标系，通过相应点云间的运动变换将所有视图点云数据配准到参考坐标系。在基于生成树的多视图点云粗配准中，有三个关键问题须要在设计该类算法时考虑：a．判断两两视图点云配准成功与失败的评判依据；b．两两视图点云配准算法的选择；c．生成树根节点的选择。</p> 
<p>基于生成树的多视图点云粗配准有两种方案获得生成树。第一种方案[7-9]：首先进行所有两两视图点云配准，若配准成功则建立连接，否则不建立连接；然后根据两两视图配准结果生成连通图；最后在连通图中根据一定的约束条件和最优条件获得生成树。虽然该类生成树算法能够得到较好的粗配准结果，但是生成树通过暴力穷举所有两两视图配准获得，假设有N片点云，使用同一种两两视图点云配准算法，该类生成树粗配准算法的时间复杂度高达O(N2)。</p> 
<p>针对穷举两两视图点云配准来生成树算法存在的问题，于是便有了第二种方案，即改进的生成树多视图点云粗配准算法[10-12]：选择一点云作为生成树根节点，将剩余点云依次与根节点进行两两视图点云配准，若存在节点无法与根节点成功配准，则待所有节点与根节点完成配准，选择一个与根节点直接相连的节点作为新的根节点，继续两两视图点云进行配准，直到建立生成树。该算法相较于穷举两两视图点云配准来生成树的多视图粗配准算法，使用相同的两两配准算法，配准次数大幅度减少，从而大规模降低了粗配准时间开销。</p> 
<p>改进的生成树多视图点云粗配准算法输入为<img alt="\{P_1,P_2,...,P_N\}" class="mathcode" src="https://images2.imgbox.com/1a/86/RBUoRh4G_o.png">个点云数据，输出为N个刚性变换矩阵<img alt="\{M_1,M_2,...,M_N\}" class="mathcode" src="https://images2.imgbox.com/05/a3/TuLofzcc_o.png">。该算法首先选出根节点，放入根节点集合，剩余节点放入待配准集合。当待配准集合不空时，a．待配准集合的节点依次与根节点两两配准；b．若两两配准结果满足一定的条件，则与当前根节点建立连接，将当前节点从待配准集合移除并加入根节点集合，否则选择待配准集合中下一片点云；c．判断待配准集合的所有点云是否完成配准，若待配准集合为空，则该算法完成，否则从根节点的集合中选择一个节点作为新的根节点，返回步骤a。</p> 
<p>文献[7]使用基于自旋图像特征描述子的生成树多视图点云粗配准算法。首先，该算法根据所有视图两两点云配准结果构建连通图；然后，根据连通图构建生成树；最后，通过生成树建立点云间关系完成多视图点云粗配准。由于该算法须要进行所有两两视图点云配准，因此非常耗时，不适用于大规模点云数据多视图点云配准。文献[8-9,13]使用相同构建生成树的方法，分别使用方向直方图特征、指数映射和极坐标映射算法进行两两视图点云配准。</p> 
<p>针对第一类生成树算法时间复杂度高的问题，文献[14]首先将第一个读取点云作为根节点，设计双重评价标准判断两两视图点云配准的可靠性；然后依次添加点云进行两两视图点云配准，直到生成树构造完成；最后根据生成树完成多视图点云粗配准。随后，文献[10]进一步改进：使用点云间的重叠率作为判断一组点云是否进行两两视图点云配准的依据；依次将重叠率大于阈值的点云对进行两两视图点云配准，直到生成树构造完成；根据生成树完成多视图粗配准。</p> 
<p>文献[11]提出连通图算法和超图算法来构建生成树，连接图算法将曲面面积最大的点云作为根节点，然后作为算法的输入，得到一颗生成树。超图算法与连接图算法类似，当根节点与所有点云配准完成后，从所有未能成功配准的点云中重新选择一个节点作为根节点来依次两两配准来生成连通图；通过子节点与其他连通图根节点连接得到生成树。文献[15]使用类似技术，基于三重旋转图像特征来完成多视图点云配准。文献[12]将点云中点数量最多的点云作为根节点替代曲面面积最大的点云，替代后配准效果不会明显变差，同时减少根节点选择所带来的时间开销，然后将根节点与其他节点划分到两个不同的集合；其他节点和根节点依次进行两两视图点云配准；通过随机抽样一致性算法的内点数来判断是否建立两节点之间的有向边。</p> 
<p>文献[16]提出任意选择一点云作为根节点，将根节点的局部坐标系设置为全局参考坐标系；每个点云与根节点直接或间接完成两两视图点云配准，选取加权最短路径作为点云间接配准的最优路径；根据子节点到根节点的加权路径最短来构建最小生成树。</p> 
<h4 id="h6f20189-CWhb03Wk">2.2 基于形状生成的多视图点云粗配准</h4> 
<p>基于形状生成的多视图点云粗配准算法核心是迭代生成种子性状点云数据，将其作为目标点云，增加源点云与目标点云的重叠率，从而提高配准成功的可能性。该类算法适用于点云之间重叠率较低的数据集。形状生成算法首先将所有点云初始化到搜索集合，然后任意选择一点云作为种子形状点云，并将种子形状点云从搜索集合移除；当搜索集合不为空集时，a．从搜索集合中选择一点云作为源点云与种子性状点云两两视图点云配准；b．若两两配准成功，则将种子形状点云更新，将源点云与种子性状点云非重叠部分点云数据加到种子形状点云中，并将源点云从搜索集合中移除，若两两配准失败，则选择搜索集合中的其他点云作为源点云。</p> 
<p>文献[17]提出基于形状生成的多视图点云粗配准算法，该算法随机选择一个点云作为种子形状点云，剩余点云依次与种子形状点云两两配准，配准成功后更新种子形状点云，直到所有点云成功配准．该算法使用旋转投影统计特征提取匹配，根据设计的判断标准来寻找有效的两两点云配准进行点云形状生长。</p> 
<p>与基于生成树多视图粗配准算法相比，形状生成多视图粗配准算法更适用于低重叠率的点云数据且不须要构造点云间网络拓扑结构。基于形状生成多视图粗配准示意图如图4所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/d6/6c/nEXQFLl1_o.png"> 
  <figcaption>
    图4 基于形状生成多视图粗配准示意图 
  </figcaption> 
 </figure> 
</div> 
<p></p> 
<h2>​03  多视图点云精配准算法</h2> 
<p>多视图点云粗配准得到一组点云初始对齐的变换矩阵作为多视图精配准的输入，多视图点云精配准则更多关注于多视图点云配准的精度。近年来，多视图点云精配准引起越来越多学者关注，陆续出现各种多视图点云精配准问题的解决方案。多视图点云精配准算法的关键是尽最大可能快速消除所有变换误差和配准累计误差。图5以时间顺序展示了多视图点云精配准研究历程中部分经典的算法。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/47/45/S8vyLGyB_o.jpg"> 
  <figcaption>
    图5 多视图点云精配准经典算法概述 
  </figcaption> 
 </figure> 
</div> 
<h3>​3.1 基于点云的点空间变换多视图精配准算法</h3> 
<p>基于点云的点空间多视图精配准算法要求充分利用所有点云中可用点信息，考虑点云中对应点关系，将其作为约束优化变换参数。这里概述基于点云点空间的多视图精配准算法：基于正态分布变换，基于聚类，基于迭代最近点(ICP)及变种，基于信息熵理论的多视图精配准算法。基于点云的点空间多视图点云配准算法的分类如图6所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/e7/a0/2Ugb0dLJ_o.jpg"> 
  <figcaption>
    图6 基于点云点空间变换多视图精配准算法分类图 
  </figcaption> 
 </figure> 
</div> 
<h4>3.1.1 基于迭代最近点的多视图精配准</h4> 
<p>文献[18]提出ICP算法，后续众多基于迭代最近点的多视图点云精配准算法以该算法为核心展开研究。为找到点云间正确的点对应关系，该算法计算粗配准变换后源点云上所有点到目标点云的距离，将两片点云中距离最小的点对视为对应点；保证源点云上的点和目标点云的点相互对应，同时构造残差平方和目标函数；使用最小二乘法对误差函数进行最小化处理，经过反复迭代直到均方误差小于设定的阈值。ICP两两点云配准算法精度高，但该算法容易陷入局部最优解且容易受到噪声点的干扰。ICP算法选中两片点云分别作为源点云和目标点云，核心步骤如下：a．在目标点云Q中取点集<img alt="q_i \in Q" class="mathcode" src="https://images2.imgbox.com/de/26/OXhNeRLD_o.png">；b．找出源点云P中对应点集<img alt="p_i \in P" class="mathcode" src="https://images2.imgbox.com/8d/dd/KiSY1069_o.png">，使对应点的距离最小；c．计算旋转矩阵<img alt="R" class="mathcode" src="https://images2.imgbox.com/d9/28/PLXSCE28_o.png">和平移向量<img alt="t" class="mathcode" src="https://images2.imgbox.com/f2/4c/2dRxq6bl_o.png">，使误差函数最小；d．对源点云进行刚性变换；e．计算对应点集的平均距离；f．若小于某一给定的阈值或大于预设的最大迭代次数，则停止迭代，否则返回步骤b，直到满足收敛条件为止。</p> 
<p>文献[19]提出直接对两两ICP算法扩展，将多视图点云精配准视为两两点云ICP精配准；通过两个点云不断地用ICP精配准和合并点云数据的策略，依次配准和合并两个点云数据，直到所有点云数据合并到一个点云。该算法提供对齐和合并的多视图点云精配准框架，任意两两视图点云精配准算法都能直接应用到该框架，从而完成多视图点云精配准。该算法简单可行，但随着点云数据的合并，ICP精配准算法的对应点搜寻时间会增加，同时存在配准误差累计问题。</p> 
<p>文献[20]首次提出针对多视图点云精配准的算法。该算法首先通过星形网络在所有点云间建立连接，星形网络的中心点云与其他点云互相寻找点对应关系；然后通过ICP算法估计点云数据间刚性变换；最后将配准误差最小作为目标函数优化每个点云的刚性变换参数。该算法同时考虑所有点云数据来优化配准参数，一定程度上解决误差累计问题，但须要为中心点云建立多个点对应关系，每个中心点云须要与其他所有点云数据进行两两配准，导致该算法耗时较长。</p> 
<p>考虑到文献[20]提出的星网络ICP算法在建立点云间对应点关系过程中非常耗时，文献[21]使用高斯球型的多缓冲区来加速重叠区域点对应关系的建立，在建立点对应关系后，通过星网络ICP精配准算法来完成多视图精配准。</p> 
<p>文献[22]提出利用颜色信息的ICP多视图点云精配准算法，同样使用两两点云ICP精配准和合并的方法。与之前方法不同的是：该方法不仅考虑点云数据中点空间的信息，而且考虑点云数据的颜色信息。由于该类算法使用点云数据的颜色信息，因此不适用于激光扫描等传感器获取不到颜色信息的点云数据。</p> 
<p>文献[23]提出使用ICP算法配准多个点云，同时最小化所有点云的配准误差来获得全局最优刚性变换的算法。将配准问题转换为最小二乘配准误差函数最小化，将配准误差函数简化为包含未知矩阵和常数矩阵的二次表达式。</p> 
<p>文献[24]提出使用广义普鲁克分析考虑同时配准所有点云数据，将其嵌入到ICP算法框架；在寻找匹配点对期间，只有两个点互相为最近邻点才是匹配点对；对于有多个匹配关系的点云，则忽略这些点对匹配；将每个匹配点对的质心求出，使用ICP算法求解最优刚性变换。</p> 
<p>文献[17]将列文伯格-马奈尔特(LM)算法嵌入到ICP算法。该算法须要建立最小生成树，对所有点云沿最短加权路径，全局使用LM-ICP算法配准到全局参考坐标系。</p> 
<p>文献[10]提出局部到全局多视图点云修剪迭代最近点精配准算法。该算法依次选中粗配准阶段生成树的第二层的一个节点作为源点云，根节点和第二层的其他节点点云合并作为目标点云，源点云和目标点云通过修剪迭代最近点算法(TrICP)进行配准；第二层点云经过层次遍历完成配准后；将根节点与第二层节点合并成为新的根节点；再进行新的根节点和第二层节点的局部多视图点云配准；直到所有节点合并到一个节点，局部多视图点云精配准完成。在此基础上进行全局多视图点云精配准，将每个点云依次作为源点云，其他所有点云数据作为目标点云，依次对源点云和目标点云通过TrICP进行多视图精配准。</p> 
<p>文献[12]提出形状增长迭代最近点算法来消除多视图粗配准产生的累积误差。该算法将根节点作为形状生成的基准节点，通过对生成树的层次遍历依次将子节点与根节点进行两两ICP精配准，然后将子节点的点云数据非重叠部分添加到根节点合并，直到遍历完所有的节点。</p> 
<p>文献[15]提出采用从粗到精的采样点云数据的方法以提高计算效率。当使用ICP算法时，只取源点云的一部分点，对点云进行随机采样和均匀采样，在ICP算法中配准性能相似。该算法使用随机采样获取点云，每次选取采样点的点数与配准误差相关，最初使用少量样本点以降低ICP算法的时间开销，当误差减小时，使用更多的样本点以提高配准精度。为进一步提高ICP算法的准确性和稳定性，在每次迭代中拒绝点到点距离大于平均网格分辨率两倍的所有异常点对。</p> 
<h4>3.1.2 基于聚类的多视图精配准</h4> 
<p>聚类可分为硬聚类和软聚类：硬聚类是指将数据确切地划分到一个确定的簇；软聚类是指将数据以一定概率分到各簇中。本研究将基于聚类的多视图精配准算法分为基于K均值(K-means)聚类多视图精配准算法和基于混合分布模型的多视图精配准算法。基于K-means聚类多视图精配准算法属于硬聚类，将所有点云数据的点划分到一个簇，簇内所有点跟对应的簇中心点进行对齐；基于混合分布模型的多视图精配准算法是软聚类问题，使用混合模型来表示点云数据，通过期望最大化算法来优化混合模型的参数，从而完成多视图点云精配准。基于聚类的多视图精配准算法精度高，且对噪声和异常值鲁棒，但由于须要建立大量的点对应关系，因此耗时较长。</p> 
<p><strong>a．基于K-means聚类的多视图精配准</strong></p> 
<p>K-means聚类算法最初由文献[25]引入点云配准领域，起初用于检测和合并点云重叠区域的对应点，不涉及更新刚性变换，后续便开始使用K-means聚类算法来完成多视图点云精配准。该类算法将不同视图点云配准问题转化为不同簇内点云对齐问题，将同一个簇内的点向簇中心逼近，没有考虑点云之间的一致性关系，一定程度上会影响配准精度。</p> 
<p>文献[26]首次使用K-means聚类算法实现多视图点云精配准。对所有粗配准的点云数据K-means聚类，随机选取K个点作为聚类中心点，对所有点云数据进行聚类；所有点云的点跟簇中心点对齐，不断地重复迭代聚类、对齐；通过簇内所有点跟簇中心点的平均差值最小求解变换矩阵。该算法的缺点是利用一个簇中心来逼近同一个聚类中所有数据点，难以避免地丢失点云数据间的大量相关信息，导致配准精度降低。其流程如图7所示，图中Ri和ti分别为第i次到质心点云的旋转和平移的估计值。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/71/46/tdWy1seB_o.jpg"> 
  <figcaption>
    图7 K-means多视图精配准流程图 
  </figcaption> 
 </figure> 
</div> 
<p>文献[27]提出一种分层K-means聚类精配准算法。首先使用少量点云数据进行K-means聚类，然后根据层次遍历对每一层的点云数据进行K-means聚类，随着点云数量的增加，可以获得更健壮、精确的多视图点云精配准结果。</p> 
<p><strong>b．基于混合分布模型的多视图精配准</strong></p> 
<p>基于混合分布模型的多视图精配准算法通过多个分布模型混合，将所有点云数据用混合分布模型表示，将配准问题转化为混合分布模型对齐问题，通过期望最大化算法将分布模型之间的统计差异量最小化。该类算法配准精度高且具有鲁棒性，但由于须要建立大量的点对应关系，因此基于混合分布模型的多视图精配准非常耗时，须要通过期望最大化算法迭代求解分布模型的估计参数。期望最大化算法分为两个步骤：第一步为期望步，利用对隐变量计算配准参数最大似然估计值；第二步为极大化步，通过最大似然估计来计算高斯混合模型参数值并更新高斯混合模型，然后继续期望步，直到目标函数收敛。期望最大化算法的框架如图8所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/d3/81/YMLEPJB4_o.jpg"> 
  <figcaption>
    图8 期望最大化算法框架 
  </figcaption> 
 </figure> 
</div> 
<p>文献[28]假设点云中每个点都由同一个高斯混合模型(GMM)生成，其质心集合通过聚类生成；通过期望最大化算法来估计GMM的均值、协方差及点云数据间的刚性变换参数；其高斯混合分布的均值用来选择对应点对，方差提供了配准效果的信息。该算法能够非常稳健地处理噪声数据和异常值，在配准过程中结合所有点云同时配准，避免累计误差产生。</p> 
<p>此外，文献[29]提出了多点云联合配准算法(JRMPC)。JRMPC假设多视图点云精配准过程中的所有点都来自单一高斯混合模型，使用期望最大化算法来估计混合高斯混合模型参数以及配准点云最优刚性变换，利用GMM和期望最大化算法来估计配准参数。该算法须要使用配准参数重新估计许多GMM参数，且须要估计与所有点相关的大量模型参数，容易陷入局部最小值，同时计算成本较高。</p> 
<p>文献[30]使用高斯分布函数表示点云数据之间点到点距离关系。不同点对赋予不同权重，从而减少噪声点干扰，并提高了配准精度；每个点由模型数据和形状数据之间距离有关的正态分布决定；使用期望最大化算法优化高斯分布表示的似然函数参数。该算法在准确性和鲁棒性方面相较于之前一些GMM方法有更好的性能，但对每一个点都要用高斯分布函数来表示并进行迭代优化，与MAICP算法相比，其配准精度更高，但随着点云数量的增加，时间开销更大，算法的时间复杂度相对较高。</p> 
<p>文献[31]提出基于T分布混合模型的多视图点云精配准算法。T分布的尾部比高斯分布尾部更重，可以通过厚尾稳健地记录点云噪声数据。该算法因软聚类会损失部分点云信息，故导致配准精度降低，且设置质心越多，配准结果越精确，同时计算复杂度越高。</p> 
<p>文献[32]提出结合高斯分布和冯米塞斯分布混合模型，高斯分布和冯米塞斯分布分别表示点云中点的位置信息和法向量信息。在期望步中，计算点对应置信度的后验概率；在极大步中，更新变换矩阵、位置方差和法向信息。</p> 
<p>文献[33]提出一种分层高斯混合分布模型配准算法来解决混合分布模型配准算法耗时长的问题。通过递归配准许多小规模的点云，构建自上而下的多尺度混合分布模型，自适应地找到最佳尺度来执行空间之间的数据关联点云数据子集，动态调整点云尺度，以更好匹配局部场景几何的复杂性和空间分布特征。与之前的方法不同，该算法使用完全各向异性的高斯协方差。</p> 
<p>文献[34]假设所有点云中的点都由唯一高斯分布模型生成，每个点在其他点云中的对应点被视为协方差和概率相同的高斯质心。由于配准过程中很难得到真实的对应点对，因此该算法通过K维二叉树将彼此对应点集中最近邻近似为对应点，并通过期望最大化算法来估计刚性变换。相较之前的基于混合分布模型的算法，该算法只须要估计点云间的刚性变换和一个协方差，减少了期望最大化算法须要估计的参数量。与JRMPC[29]，TMM[35]和K-means[26]算法相比，该算法在相同粗配准输入条件下的旋转误差和平移误差都有一定程度降低。随后，文献[26]对该算法进行了改进，使用T混合分布模型来代替高斯混合分布模型，相比于高斯混合分布多视图精配准算法，该算法对噪声数据和异常数据具有更好的鲁棒性。</p> 
<p>文献[36]提出基于局部几何曲面点漂移算法。该算法自适应地计算点到面的距离来更新GMM的参数，导致其GMM具有各向异性协方差；将点云配准、转化为最大似然估计问题，使用期望最大化算法求解；在期望步中，由于对应点的计算时空开销大，因此将计算点云之间点对应关系重新定义为简单的矩阵操作；在极大步中，通过执行李群矩阵的无约束优化，以有效更新刚性变换矩阵。</p> 
<p>文献[37]提出基于拉普拉斯混合分布模型(LMM)的多视图精配准算法。假设每个数据点由LMM生成，其中心由其他点云中的对应点确定。不同于之前的基于GMM方法，LMM使点与高斯概率分布密度中心之间的二次型距离最小，从而使稀疏诱导的曼哈顿距离最小，对噪声和异常值具有更强的鲁棒性。采用期望最大化算法来求解LMM的参数，通过李代数中的指数映射近似为线性规划问题，并通过内点法有效求解线性规划问题。为提高效率，采用交替方向乘子法解决曼哈顿距离优化问题。</p> 
<h4>3.1.3 基于正态分布变换的多视图精配准</h4> 
<p>正态分布变换(NDT)算法的核心思想为：将一定范围内的点云用正态分布表示，将三维点云数据划分成固定大小的三维立方体单元格，使用正态分布表示单元格中每个三维点的概率分布，即通过正态分布来表示原本离散的点云。相较于ICP算法，NDT算法在很大程度上降低了配准算法的运行时间，降低了配准误差，提高了配准精度．由于须要对所有的点云数据进行网格化处理，因此该算法应用到范围大、点云密集程度高场景中的配准耗时问题依旧得不到有效解决。</p> 
<p>文献[38]提出3DNDT算法，该算法是对二维NDT算法的泛化和改进，通过与ICP算法进行定量和定性的比较，发现该算法相较于已经广泛应用于多视图精配准的ICP算法，其速度较快，可靠性更高。文献[39]提出一种改进的基于NDT的三维多视图精配准算法。该算法首先通过K-means聚类和李代数求解器实现多视图精配准，将多视图配准问题转化为最大似然估计问题，用K-means聚类算法将所有点云数据划分为不同的簇，每个簇的点云用正态分布来表示点云数据；然后使用NDT的似然函数来解决多视图点云精配准问题。为最大化该似然函数，通过开发李代数求解器顺序优化每个刚性变换。该算法通过交替实现点云数据K-means聚类、NDT算法和似然最大化来得到多视图精配准结果，其流程图如图9所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/13/d9/XUjH7WnN_o.png"> 
  <figcaption>
    图9 改进的基于NDT三维多视图精配准流程图 
  </figcaption> 
 </figure> 
</div> 
<h4>3.1.4　基于信息熵理论的多视图精配准</h4> 
<p>基于信息熵理论的多视图精配准算法是基于互信息的方法。互信息的概念最早出现在香农的信息论中，用来度量两个随机变量包含对方信息量多少。该类方法通过对累积分布函数(CDF)求散度，来度量点云之间的配准参数，不须要寻找对应点，而是寻找表示点云数据函数对应关系。</p> 
<p>文献[35]提出一种利用信息理论测度的鲁棒配准算法，即基于CDF的延森-香农(JS)散度分组点云配准，使用概率分布表示点云数据来配准多个点云．点云配准主要技术挑战是寻找正确的点对应关系问题，通过最小化点云间的CDF-JS散度，避免寻找对应点问题，该算法对噪声具有鲁棒性．</p> 
<p>文献[40]提出了一种鲁棒的未知对应点云的群配准技术。首先定义了一个有效于CDF的Havrva-Charvat(HC)熵，称为HC累积残差熵；然后提出了一种新的度量，称为CDF-HC散度，用于量化所有点云中每个点云估计的CDF之间的相似性。CDF-HC相较于CDF-JS在完成多视图精配准方面更高效、更简单。数学分析和实验结果表明，CDF-HC配准算法在效率、准确性和鲁棒性方面均优于CDF-JS分组点云配准算法。</p> 
<p>文献[41]提出一种同时配准多个点云的鲁棒算法。该算法通过将点云表示为概率密度函数，通过多重分布对齐完成配准，不须要在点云之间建立点对应关系，提供了简单、快速和准确的算法来计算配准多个点云所需的空间转换函数。将该算法与CDF-HC点云配准算法进行比较，结果表明配准精度有所提高。</p> 
<h3>3.2 基于点云帧空间的多视图精配准算法</h3> 
<p>基于点云帧空间多视图精配准算法应用于优化局部坐标系的空间内部一致性，与直接使用对应点的关系作为约束的优化方法截然不同，该类算法不使用点云的对应点关系，而是通过点云间相对变换之间关系完成帧空间内部一致性优化，大大减少了时间开销。本研究概述了基于点云帧空间的四类多视图精配准算法，即基于闭环检测、基于低秩稀疏矩阵分解、基于四元数和基于李代数的多视图精配准算法。基于帧空间变换平均多视图精配准算法分类如图10所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/6e/ec/nKZ5wana_o.png"> 
  <figcaption>
    图10 基于帧空间变换平均多视图精配准图 
  </figcaption> 
 </figure> 
</div> 
<h4><strong>3.2.1 基于四元数的多视图精配准</strong></h4> 
<p>四元数可以用来表示旋转变换，与使用旋转矩阵表示旋转变换相比，四元数表示具有更好的性质，便于开始使用四元数表示旋转变换。部分学者提出对点云间旋转变换的四元数优化算法，该类方法不涉及点，时间开销较低。</p> 
<p>文献[42]使用四元数表示旋转，四元数适用于基于迭代梯度的旋转和平移搜索。由于该算法不使用数据点，只占用少量内存，因此和基于点空间中点的算法相比，配准的速度更快。</p> 
<p>文献[43]提出基于对偶四元数的精配准算法。旋转变换和平移变换使用对偶四元数表示，通过对偶四元数将点云配准变换矩阵投影到一个公共参考系，其中对偶四元数是一种与三维刚性变换相关的代数结构。该算法在坐标帧之间传递配准误差，使用对偶四元数迭代混合算法，通过最小化单位对偶四元数黎曼流形中平方距离来平均对偶四元数，从而达到累积配准误差消除的效果。</p> 
<h4>3.2.2 基于低秩稀疏矩阵分解的多视图精配准</h4> 
<p>基于低秩稀疏矩阵分解多视图精配准算法将多视图点云精配准转换成低秩稀疏(LRS)矩阵分解问题。LRS矩阵分解算法根据不同坐标系间的空间一致性优化变换矩阵，相较基于点云中点空间的精配准算法，只对矩阵进行优化，时间开销小；通过低秩稀疏矩阵分解将变换矩阵与噪声分离，能够较好地消除噪声数据对配准的影响。</p> 
<p>文献[44-45]首次将帧空间多视图点云精配准定义为LRS矩阵分解问题，将多个相对变换矩阵分解，得到缺失的相对运动变换矩阵并分离出异常值和噪声矩阵，从块相对变换矩阵中恢复相对运动。LRS矩阵分解精配准算法能够较好消除不可靠相对运动产生的噪声，虽然每个相对运动可信赖程度都不同，但是该算法认为所有相对运动可信赖程度都相等，这不可避免会降低配准精度。</p> 
<p>于是，文献[46]提出加权LRS矩阵分解多视图精配准算法。根据点云相对运动的逆对称性，提出降低重建矩阵稀疏性的完备方法，提高了LRS矩阵分解算法的鲁棒性和效率，其中每个相对运动的变换矩阵分配权重来表示其可靠性；将可靠相对运动视为块来重建稀疏矩阵，在稀疏矩阵重建完成后，对稀疏矩阵进行LRS矩阵分解。由于该算法更加关注可靠相对运动，因此更加精确和鲁棒。相比于MAICP[47-48]和LRS[45]多视图点云精配准算法，该算法配准误差更低、配准时间更短，其流程如图11所示，图中：<img alt="M_i" class="mathcode" src="https://images2.imgbox.com/e1/87/H7ErHWvd_o.png">和<img alt="M_j" class="mathcode" src="https://images2.imgbox.com/f0/d5/ePu4hA50_o.png">分别为第<img alt="i" class="mathcode" src="https://images2.imgbox.com/4b/3f/LtZ448K0_o.png">和第<img alt="j" class="mathcode" src="https://images2.imgbox.com/63/be/zZgIQHbr_o.png">片点云到全局参考坐标系的变换矩阵；<img alt="M_{ij}" class="mathcode" src="https://images2.imgbox.com/dd/8b/gojdRL6b_o.png">为由第<img alt="i" class="mathcode" src="https://images2.imgbox.com/c9/2a/MY5CXhDa_o.png">片点云到第<img alt="j" class="mathcode" src="https://images2.imgbox.com/32/cf/Y3a0TzR9_o.png">片点云的变换矩阵。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/b9/a4/IkcjlRAx_o.png"> 
  <figcaption>
    图11 加权LRS多视图精配准算法流程图 
  </figcaption> 
 </figure> 
</div> 
<p>文献[49]通过空间光栅网格化方法提取点云的空间分布特征，通过点云空间分布特征相似度完成闭环检测；根据空间分布特征的相似性建立相应的权重矩阵；评价相邻配准变换精度，提高了低秩稀疏矩阵分解算法的鲁棒性。</p> 
<p>文献[50]提出基于多视图角度约束的帧空间LRS矩阵分解算法。该算法利用柯西核函数及点云重叠率构造误差函数中的加权矩阵，通过定义角度约束，建立加权LRS矩阵分解模型；在原来的误差函数中加入附加项；通过增广拉格朗日乘子法解决优化问题；解决加权LRS矩阵分解算法过于依赖初始变换矩阵值的问题；在优化过程中，将角度约束作为附加项添加到误差函数中，最后通过增广拉格朗日乘子法得到损失函数的快速鲁棒迭代解。</p> 
<h4>3.2.3 基于李代数的多视图精配准</h4> 
<p>基于李代数的多视图精配准算法，将变换矩阵对应的李群用代数方法转换为李代数，根据一定的约束条件来平均多视图点云变换所产生的配准累计误差。该类算法使用变换平均算法来完成多视图点云精配准。</p> 
<p>文献[51]提出变换平均(MA)算法。通过李群表示点云间运动，利用特殊正交群和特殊欧几里得群的李代数来定义李群的平均值，从而得到具有高效准确的运动平均算法。该算法具有线性计算所有可能相对运动并快速平均相对运动估计值的能力。根据冗余两两点云相对运动变换矩阵的评估值，产生全局一致的快速变换平均估计算法。</p> 
<p>随后，文献[52]将基于图形的采样方案和随机抽样一致性算法方法相结合去除异常的点云相对运动变换，点云间的相对运动变换作为输入，使用变换平均算法产生鲁棒的全局运动，提供固有统计不确定性的经验估计，使得该算法更加鲁棒、效率更高。文献[47-48]提出结合变换平均和ICP的多视图点云精配准(MAICP)算法，每个迭代步骤定义为等价的对应步和变换步。在对应步中，使用距离阈值来避免选择点云边界上的点对应关系；在变换步中，首先根据一组点对应信息得到对应的刚性变换，可靠冗余的刚性变换矩阵，通过基于李代数的变换平均算法优化刚性变换，得到高精度的配准结果。</p> 
<p>文献[53]首先估计多视图配准中所有点云对的重叠百分比；然后提出一种修剪尺度迭代最近点算法(TsICP)来计算包含高重叠率的两两点云的相对运动，可以计算出精确的尺度变换；最后用MA算法得到多视图点云精配准结果。</p> 
<p>文献[54]提出加权变换平均多视图精配准(WMA)算法．运动平均算法是解决多视图配准问题的有效方法之一，但它没有考虑每个相对运动的可靠性和准确性。加权变换平均多视图精配准算法首先利用两两点云TrICP精配准算法来估计具有一定重叠程度的点云对的相对运动变换和重叠百分比，然后将重叠百分比视为每个点云对的权重，每个点云对使用加权变换平均算法。该算法更加关注可靠、准确的相对运动，从而提高配准精度，实验结果表明该方法在精度、鲁棒性和效率方面具有优越性。</p> 
<p>文献[55]提出基于图的变换平均算法。在执行变换平均前过滤异常变换值；根据每个相对运动与全局运动和其他相对运动的空间一致性，来分配变换平均权重；使用基于图的算法来识别异常值。该算法可以简单有效地过滤异常值，使用迪杰斯特拉最短路径算法来获得绝对运动变换，更加鲁棒。</p> 
<p>文献[56]提出一种新的计算点云间的对应点方法来提高两两配准的精度。首先通过使用二次曲面拟合方法有效地估计几何形状，从而更准确地估计点云的点对应关系；然后通过变换平均算法计算多个点云的相对运动刚性变换。</p> 
<p>文献[57]提出基于最大连通子图的变换平均算法。首先利用两两点云配准来估计相对运动，从可靠的相对运动的最小集合估计初始全局运动；然后通过其他相对运动随机采样和评估，以消除不可靠相对运动；再将变换平均算法应用于可靠的相对运动，从而获得准确的全局运动。随后，文献[58]又通过两两匹配、闭环检测和加权变换平均算法交互作用，提出一种有效的多视图配准算法，首先设计一种闭环检测方法来生成和验证回环闭合，从而在位姿图中添加更多的约束；然后通过循环顺序的倒数分配给每个相对运动的权重，恢复空间变换运动的一致性。</p> 
<p>文献[59]提出结合变换平均和TrICP的多视图点云精配准(MATrICP)算法，利用李代数实现相对运动变换平均，应用TrICP算法来获得高重叠百分比的点云对，利用TrICP算法获得精确的相对运动。该方法可以实现多视图点云精配准，具有良好的效率、精度和鲁棒性。由于TrICP算法比较耗时，因此采用​<a href="https://cloud.tencent.com/product/gpu?from=10680" rel="nofollow" title="​并行计算​">​并行计算​</a>​的方式来减少时耗。</p> 
<p>文献[60]提出基于最大相关熵准则的鲁棒变换平均算法。变换平均算法在优化步骤中使用F范数计算误差，该误差对异常值敏感；使用相关熵度量代替F范数计算误差来提高变换平均算法对异常值的鲁棒性；根据半二次技术，基于熵测度的优化问题可通过交替极小化过程解决，该过程包括权重分配和加权运动平均操作；还设计了一种自适应核宽度选择策略，利用相关熵来平衡算法的精度和收敛速度；利用半二次技术将问题转化为半二次优化问题。与F范数相比，相关熵测度可以降低异常值对精配准的影响。</p> 
<p>文献[61]提出自适应LRS加权运动平均算法。首先用LRS矩阵分解算法来计算初始全局运动；通过一组相对运动来恢复初始全局运动；随后通过拉格朗日乘子法优化策略扩展具有自适应权重计算的变换平均算法，该优化策略可自适应地计算每个成对相对运动的可靠性权重。该算法用LRS矩阵分解估计初始全局运动，通过权重计算和变换平均算法步骤重复迭代直到收敛。在6个评估数据集上，相较于MA，LRS和JRMPC方法，该算法在大多数情况下的旋转误差和平移误差都更小，且与MA和LRS时间开销是一个数量级，而JRMPC算法比较耗时。</p> 
<h4>3.2.4 基于闭环检测的多视图精配准</h4> 
<p>基于闭环检测的多视图精配准算法通过闭环建立多视图点云配准的约束条件，在闭环内优化多视图点云间的运动变换参数。</p> 
<p>文献[62]提出基于运动变换参数的一致性框架，处理多视图点云配准闭环检测问题。通过点云对产生可逆转换的双向运动变换参数进行配准，收集局部重叠信息，从而产生可逆变换；将配准问题转换为从所有其他坐标系到一个参考坐标系的优化；为避免点对的错误对应，采用一种参数双向方法，在成对重叠区域中生成可逆变换，从而消除多视图点云精配准累积误差。</p> 
<p>文献[63]提出一种小环闭合的最小解循环配准算法。在小循环中点云联合计算摄像机的初始位姿，使用最少数量的点对应来联合计算小环中的所有刚性变换。与两两点云视图配准相比，所提出方法使用较少的点对，提供获得多视图点云对应点对的新方法。</p> 
<p>文献[64]提出基于环约束的多视图精配准算法，将旋转矩阵和平移向量完全解耦，进一步推导点云旋转变换的影响是如何传播到整个循环。利用拉格朗日乘子来满足闭环约束，并采用矩阵指数梯度法来优化旋转矩阵解。该算法通过迭代方式实现，其中旋转矩阵在流形上进行迭代更新，以便在每次迭代中都可以很好地保持正交性。随后，文献[65]提出一种闭环约束的多视图配准算法，通过将选定点云关联其前后的点云，将平移分量和旋转分量的解耦，简化优化问题；闭环的累积误差可以通过循环因子有效分布到所有视图中，并且只需要几次迭代；最重要的是对于每次迭代，都是线性计算复杂度；该算法不仅高效并且有较高的精度。</p> 
<h3 id="h6f20189-Wd5gZmWA">3.3 基于优化的多视图精配准算法</h3> 
<p>在基于优化的算法中，将多视图配准问题转换成非线性最优解问题，其关键思想为研究一种复杂优化策略来实现非线性最优解。本研究概述了基于半正定优化、基于二次规划、基于流形优化和基于图优化这四种优化算法。基于优化理论多视图精配准算法分类如图12所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/c7/fa/wEaKsQfL_o.jpg"> 
  <figcaption>
    图12 基于优化的多视图精配准分类图 
  </figcaption> 
 </figure> 
</div> 
<h4>3.3.1 基于二次规划的多视图精配准</h4> 
<p>基于二次规划的多视图精配准算法，将矩阵运动变换问题转换为李代数参数的二次规划求解问题，通过二次规划消除全局配准累计误差。</p> 
<p>文献[66]提出多视图配准误差松弛方法。从图的循环中获得约束来消除全局配准累积误差；根据二次规划模型的规定，提出一种将累积误差分布到图中适当位置的线性解决方案；由于该算法不涉及原始的三维点云数据，因此具有较低的时空复杂度。</p> 
<h4>3.3.2 基于半正定规划的多视图精配准</h4> 
<p>基于半正定规划的多视图精配准主要思想是通过复杂近似策略来完成优化。配准的对应优化是考虑成对对应点约束的问题，通过半正定规划(SDP)可以较好地近似对应全局最优解。</p> 
<p>文献[67]提出秩松弛半正定规划全局配准优化框架，使用交替方向乘子法非凸变体来优化求解，该算法是高效的迭代方法，对错误点对匹配具有鲁棒性，配准精度显著高于ICP算法，与MAICP效果相似。随后，文献[68]提出将非凸优化简化为半正定规划问题，其中优化目标为线性目标，但优化约束为非凸约束；最小二乘问题解可以通过线性映射从SDP解导出，使用变量分离和交替方向乘子法解决SDP问题。</p> 
<p>文献[69]提出通过计算拉格朗日对偶进行秩松弛，将多视图配准视为SDP问题。给定局部极小值，SDP对偶变量计算闭式解，从而提供使用SDP计算最优解的可能性；此外，通过谱分析，研究秩松弛紧密约束条件；若最优解误差有界，则SDP公式能消除配准累计误差，得到最优变换矩阵。</p> 
<h4>3.3.3 基于图优化的多视图精配准</h4> 
<p>该类算法基于图拓扑结构优化多视图点云精配准，从图中点云数据具有一定的空间联系、约束和点云间误差最小来完成基于图优化的多视图精配准。</p> 
<p>文献[70]将多视图点云网络视为一个整体，同时最小化所有视图配准误差；图中点云间变换由一系列矩阵乘法计算得到；若点云间变换矩阵存在配准误差，则矩阵乘法计算会产生配准累计误差；获得节点间路径长度最小网络拓扑结构至关重要；该算法提出改进一组点云视图配准变换的通用方法，使所有视图间配准累计误差最小。</p> 
<p>文献[71]提出利用点云两两配准结果作为约束。在多视图配准中均匀消除点云两两配准误差，顺序估计相邻点云的刚性变换；将成对配准误差分散到多个视图点云中；在配准误差足够小的情况下将相邻视图合并成一个点云，直到所有点云数据合并到一起；配准误差在循环视图对之间均匀扩散。</p> 
<p>文献[7]提出基于生成树多视图点云精配准。搜索两两配准阶段匹配获得全局一致解；将全局配准问题转换为离散和连续混合优化问题；通过多视图曲面匹配算法将输入点云数据转换为曲面网格；全局优化过程搜索成对匹配构造的图，寻找仅包含正确匹配的连通子图，使用全局一致性度量来消除不正确匹配。</p> 
<p>文献[72]提出基于图拓扑结构分层多视图精配准算法，其中每个节点和边分别表示点云集和具有大重叠区域点云之间连接；在图优化的基础上，对边、循环和整个图进行层次优化；由于该算法须要使用所有的小循环，在图中构建一定数量的循环。</p> 
<h4>3.3.4 基于流形优化的多视图精配准</h4> 
<p>基于流形优化的多视图点云精配准优化目标为一组旋转非凸函数。目标函数优化算法必须在迭代过程中保持旋转矩阵的流形约束。通过导数和切线微分几何推广，将该旋转变换矩阵优化转换为基于流形目标函数优化。</p> 
<p>文献[73]首次提出使用流形优化完成多视图精配准，首先在所有点云之间建立点对应关系，然后同时估计所有运动变换，以优化配准误差，该算法须要在所有点云之间建立点对应关系，非常耗时。不过，使用流形优化可以同时优化所有刚性变换。为了获得较好的精配准结果，须要为所有点云建立精确地点对应关系，点对应关系却很难保证完全正确。</p> 
<p>随后，文献[74]又提出将多视图点云配准描述为约束流形迭代损失函数约简。基于约束流形的局部二次收敛牛顿型迭代同时配准多个点云，该算法是局部二次收敛的，提供了基于奇异值分解的闭式解。在无噪声情况下的精确解，可作为迭代算法的良好初始估计。</p> 
<p>文献[75]提出基于流形优化改进算法，使用误差最小化旋转流形，不依赖静态点对应．提出的算法更新优化迭代，动态修改对应点集合计算的有效方式，可提高局部的配准精度和收敛速度，在不牺牲配准性能的情况下大幅降低计算负担。</p> 
<h3>3.4 基于深度学习的多视图精配准算法</h3> 
<p>随着深度学习广泛应用到各视觉领域并取得显著效果，部分学者开始将深度学习应用到多视图点云配准领域，一方面使用深度学习提取点云特征完成多视图点云精配准；另一方面使用深度学习方法建立全新的端到端的多视图点云精配准框架，完成多视图点云精配准。</p> 
<p>文献[76]提出一种多视图点云深度学习的特征描述子和融合残差网络结构。该特征描述子从多个视图点云中学习，用于描述三维关键点。该算法利用多个点云视图融合来描述三维关键点，提出一种基于图形模型的高效离群值滤波器，显著提高三维点匹配的鲁棒性；同时提出鲁棒置信度匹配算法，在图形匹配模型上传播进行有效推理来拒绝异常匹配。</p> 
<p>文献[77]提出深度映射配准框架，使用深度神经网络将多个点云配准到全局一致的坐标系；使用两个网络完成全局点云配准，其中一个网络用于位姿估计，另一个网络通过估计全局坐标的占用状态来对场景结构建模。将配准问题转化为二进制占用分类问题，使用基于梯度优化来有效解决多视图点云精配准。该方法的新颖之处在于使用神经网络解决配准问题，使用两个深度神经网络来进行无监督端到端训练，对多视图粗配准初始对齐的依赖性小。</p> 
<p>文献[78]提出一种全新端到端可学习的多视图三维点云配准算法。将多视图配准分为两个阶段：第一个阶段完成两两点云配准，求解两两点云间的初始变换关系；第二个阶段在全局上进行精配准．由于点云之间的低重叠率、对称性或者重复的点云场景片段，导致第一个阶段配准精度不高，因此第二个阶段的全局优化目标是在多个点云间建立一种循环一致性。该算法将两个阶段融合在一起进行端到端的交替学习；提出置信度估计块，该块使用新的重叠池层来预测估计成对变换参数的置信度；将多视图三维点云配准问题转化成迭代加权最小二乘法问题，并迭代确定成对和绝对变换估计。</p> 
<p>文献[79]提出一种同时考虑局部空间相关性和长期时间序列信息共享的方法。每一个点云都有一个相应的可学习潜在向量作为时间记忆分量，目的是将其之前观测到的相关信息传递给其他点云，从点云的时间序列中进行无监督的全局配准学习。该算法新颖之处在于引入了一个深度时空表示特征，该特征描述了在未知环境中通过传感器获得的点云序列的时间和空间关系的几何本质。与之前单独处理每个成对配准的时间步长相比，无监督模型优化一个潜在的特征序列，并将其解码为一个时间和空间连续的几何转换序列，以全局配准多视图点云。</p> 
<h3>3.5 其他多视图精配准算法</h3> 
<p>除本研究归纳分类的四大类多视图点云精配准算法，还存在部分算法不能归入四类多视图点云精配准算法，称为其他多视图精配准算法。通过粒子动力学原理、李群的几何性质、贝叶斯估计和轮廓一致性等原理完成多视图点云精配准。这里对其他多视图精配准算法进行介绍。</p> 
<p>文献[80]提出利用李群几何性质及迭代加权最小二乘优化完成多视图点云精配准。三维运动的李群包含点云丰富几何结构信息，将鲁棒运动估计合并到ICP局部算法，实现多视图点云精配准。</p> 
<p>文献[81]提出基于贝叶斯的多视图精配准算法。通过期望最大化算法将全局多视图精配准问题嵌入到贝叶斯框架，将点对应视为缺失数据，通过最大后验概率过程推断，同时考虑点对应和噪声的不确定性，能够容忍一定数量的错误对应点；利用不同权值来表示视图间对应相对运动关系的可靠性，该算法最大限度地减少了全局不可靠相对运动变换的影响，但须要计算大量参数和变量，时间开销大。</p> 
<p>文献[82]提出基于引力粒子动力学的多视图点云精配准算法。将多视图点云精配准问题视为粒子群在相互诱导的力场中刚性运动；在相互感应和交替的重力场中移动；在引力作用下，点云合并和刚性运动变换交替进行．该算法对噪声和缺失数据具有鲁棒性。</p> 
<p>文献[83]利用轮廓一致性完成多视图精配准。在外观轮廓上构建鲁棒的对应点对，以迭代方法最小化不同视图点云距离来最大化轮廓一致性。在多视图刚性配准框架下使用该算法，配准精度较高且具有一定的鲁棒性。该算法适用于有明显轮廓的点云数据。</p> 
<p>文献[84]提出根据原始密集点对应直接在所有曲面上优化全局配准目标。在内部循环中不执行对应点更新，因此该算法速度快，避免了优化配准循环中的最近邻查找过程，相较于ICP算法，时间效率大幅提升。</p> 
<p>文献[85]提出自适应核密度估计的多视图精配准算法。给定多个视图估计点云的角密度函数，以确定采样表面的精确近似，隐式地同时考虑所有点云中点的误差函数，使用角密度函数来引导变换空间中的误差最小化，稳健地配准所有视图点云。</p> 
<p>文献[86]提出几何对齐算法的局部不确定性框架。针对多视图点云配准的不确定性量化问题，利用变换海森矩阵的逆来估计从最小化误差函数得到的输出之间协方差矩阵的近似误差．该算法结果是稳健的不确定性度量。</p> 
<p>文献[87]提出基于变分贝叶斯的变换平均算法。设计了一个连续近似估计变换后验分布的滤波器；将变分贝叶斯方法与绝对变换的相对参数化相关联，使得该算法具有低计算时间、检测闭合的能力，配准精度更高；使用绝对变换相对参数化产生后验分布，可以有效地近似假设独立的相对变换。</p> 
<h2 id="h490b8bf-453cST7N">04  数据集及评价指标</h2> 
<p>根据多视图点云配准算法相关文献，总结多视图点云精配准领域主流数据集和评价指标，并依次介绍多视图点云配准常用目标、场景数据集、多视图点云配准算法定量评价指标及定性评价指标。</p> 
<h3 id="h6f20189-5oHOZleh">4.1 多视图点云配准数据集</h3> 
<p>点云配准数据集可分为目标点云数据集和场景点云数据集。有四种数据集在多视图精配准算法中使用频率较高，分别为斯坦福3D扫描模型库[88]、UWA3M数据集[89]、3DMatch数据集[90]和Augmented ICL-NUIM[91]数据集．多视图配准主流的目标数据集包括斯坦福3D扫描模型库和UWA3M数据集。多视图配准主流的场景数据集有3DMatch数据集和Augmented ICL-NUIM数据集。以下分别对这四个数据集进行介绍，数据库部分样例点云可视化结果如图13所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/25/02/b94HjHSq_o.jpg"> 
  <figcaption>
    图13 常用数据集的部分多视图点云可视化 
  </figcaption> 
 </figure> 
</div> 
<h4>4.1.1 目标数据</h4> 
<p><strong>a．斯坦福3D扫描模型库[88]。</strong>该模型库由斯坦福大学计算机图形学实验室发布，其中的点云数据除了Lucy使用斯坦福大型雕塑扫描仪获得，其余均用Cyber ware 3030 MS扫描仪得到；该模型库包含9种不同目标的多视图扫描点云数据，其中Bunny，Armadillo，Dragon和Happy Buddha四个点云目标数据集常用于评估多视图点云配准算法的性能。每个数据集中包含了该目标多个视图的点云数据、标准参考坐标系对齐的平移向量和旋转四元数真值。将通过算法求解的评估变换矩阵与变换真值比较，判断配准效果的好坏。斯坦福3D扫描模型库详细信息如表1所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/d2/27/WQrNAgOL_o.png"> 
  <figcaption>
    表1 斯坦福3D扫描模型库 
  </figcaption> 
 </figure> 
</div> 
<p><strong>b．UWA3M数据集[89]。</strong>UWA3M数据由Konica Minolta Vivid 910 Scanner传感器从不同视角扫描模型获得。通过手动标注点云间的对应关系，ICP算法求解的变换参数作为真值数据。该数据集包含Chef，Chicken，T-rex及Parasaurolophus模型的22，16，16和21个视角的点云数据．UWA3M数据集详细信息如表2所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/3a/47/66Wm83Pr_o.png"> 
  <figcaption>
    表2 UWA3M数据集 
  </figcaption> 
 </figure> 
</div> 
<h4>4.1.2 场景数据</h4> 
<p><strong>a．3DMatch数据集[90]。</strong>3DMatch数据集包括8个场景数据，包括场景点云的数据及评估场景点云的变换矩阵真值。3DMatch收集62个场景数据，其中54个场景数据用于训练，8个场景数据用于评估。其评估集包含8个场景点云序列，分别由60，60，60，55，57，37和38个视角点云组成。3DMatch评估基准数据集详细信息如表3所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/05/53/eCEbnnfY_o.png"> 
  <figcaption>
    表3 3DMatch基准数据集 
  </figcaption> 
 </figure> 
</div> 
<p><strong>b．Augmented ICL-NUIM数据集[91]。</strong>该数据集基于原始ICL-NUIM的RGB-D数据集，提供客厅和办公室两种室内场景的模型。其点云数据由Kinect传感器收集得到，是大型的室内场景数据集，包含Living room 1，Living room 2，Office 1和Office 2四个场景序列，分别由57，47，53和50个视角点云组成，该数据集是合成数据集。Augmented ICL-NUIM数据库详细信息如表4所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/20/d1/bzIKCHv6_o.png"> 
  <figcaption>
    表4 Augmented ICL-NUIM数据集 
  </figcaption> 
 </figure> 
</div> 
<h3 id="h6f20189-V4kkREr9">4.2 多视图点云配准评价指标</h3> 
<p>为公平有效地评价多视图点云配准算法性能的优劣，从定量分析和定性分析两方面设置统一评价指标来度量配准精度高低。多视图点云配准的定量分析评价指标主要是配准误差和运行时间。多视图点云配准完成后将配准完成的点云数据横截面作为多视图定性分析评价指标。</p> 
<h4>4.2.1 定量指标</h4> 
<p>常用定量指标包含配准误差和运行时间，其中：配准误差为多视图配准算法估计的变换和变换真值之间的差值，又可分为旋转误差和平移误差；运行时间指的是从多视图点云配准开始到结束所需要的时间。时间指标较为直观，这里将主要介绍配准误差指标。</p> 
<p>常用配准误差的评价指标分为两种。第一种是基于配准过程中所有的正确点对之间的欧式距离计算配准误差。该误差常用于评价两两点云配准精度，通过变换矩阵真值来提供正确的点对，计算刚性估计变换后的点对误差的平均值。两两点云的配准误差公式为</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/ca/09/al3dlGPE_o.png"></p> 
<p>式中：<img alt="P_a" class="mathcode" src="https://images2.imgbox.com/e9/18/jEcJkQ5r_o.png">为源点云上的一个点；<img alt="q_{c(a)}" class="mathcode" src="https://images2.imgbox.com/47/29/lWiHGtvZ_o.png">为<img alt="P_a" class="mathcode" src="https://images2.imgbox.com/16/62/4Heypv7L_o.png">在目标点云上的对应点；<img alt="R" class="mathcode" src="https://images2.imgbox.com/f3/be/qTpvsIFN_o.png">和<img alt="t" class="mathcode" src="https://images2.imgbox.com/20/e2/e6qZPGSX_o.png">分别为到目标点云旋转和平移的估计值；<img alt="\varepsilon" class="mathcode" src="https://images2.imgbox.com/a4/10/WvzzvHmf_o.png">为源点云中目标点云存在对应点的点数占源点云总点数的百分比；<img alt="|p_\varepsilon |" class="mathcode" src="https://images2.imgbox.com/0f/a7/2MbclnGE_o.png">为目标点云中存在对应点的总点数；<img alt="\gamma" class="mathcode" src="https://images2.imgbox.com/80/a0/JpA8vx40_o.png">为数值参数，在同一对比实验中取值相同即可。</p> 
<p>在多视图配准过程中，两两配准误差之和的平均即为多视图点云配准的误差，其定义为</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/bc/17/FNxPJeiA_o.png"></p> 
<p>式中：<img alt="N" class="mathcode" src="https://images2.imgbox.com/eb/5c/AY6WRnVZ_o.png">为多视图点云配准的视图数；<img alt="\varphi (\varepsilon _i,R_i,t_i)" class="mathcode" src="https://images2.imgbox.com/1b/84/xW7XgzPe_o.png">为第<img alt="i" class="mathcode" src="https://images2.imgbox.com/c6/16/R9aMwH3u_o.png">片点云作为源点云到目标点云的配准误差。该指标常用于评估基于点的多视图精配准算法。</p> 
<p>第二种是根据刚性变换真值和评估的刚性变换直接对比来计算配准误差，分为平移误差和旋转误差，其中，评估的变换和刚性变换真值须要统一参考系。旋转误差<img alt="e_R" class="mathcode" src="https://images2.imgbox.com/b8/05/mZhiGBZV_o.png">和平移误差<img alt="e_t" class="mathcode" src="https://images2.imgbox.com/04/00/kawwWxct_o.png">分别定义为</p> 
<p>式中：</p> 
<p class="img-center"><img alt="" height="270" src="https://images2.imgbox.com/e8/ce/q6PWaSN1_o.png" width="561"></p> 
<p> <img alt="(R_g,i,t_g,i)" class="mathcode" src="https://images2.imgbox.com/01/ed/Ar2O8kmx_o.png">为第<img alt="i" class="mathcode" src="https://images2.imgbox.com/ff/36/JFj1Mafq_o.png">个刚性变换的真值；<img alt="(R_m,i,t_m,i)" class="mathcode" src="https://images2.imgbox.com/a2/d6/FHXQTTKi_o.png">为第<img alt="i" class="mathcode" src="https://images2.imgbox.com/41/6c/l1gGxd9i_o.png">个通过多视图配准算法估计的刚性变换；<img alt="M" class="mathcode" src="https://images2.imgbox.com/7d/e4/7oEy26sr_o.png">为多视图点云配准的视图个数。</p> 
<h4>4.2.2 定性指标</h4> 
<p>常用定性评价指标为点云配准模型的横截面图，该指标可以直观地反映多视图点云配准结果精度的高低。</p> 
<p>点云配准模型横截面图获取流程如下：首先读取多视图配准完成的点云数据，然后固定横截面并将其区域内的点云数据单独读取，最后将该区域点云数据投影到二维平面进行可视化。若横截面是平滑的曲线构成，则配准精度较高；若存在断裂或者交叉，则表示配准精度较低。配准点云定性横截面分析示例如图14所示。</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" src="https://images2.imgbox.com/a0/01/cCJY7omf_o.png"> 
  <figcaption>
    图14 配准点云定性分析横截面示例图 
  </figcaption> 
 </figure> 
</div> 
<h3>4.3 常用数据集算法选择</h3> 
<p>针对目标数据集，其特点是点云的点数不多，搜寻对应点关系相对容易，根据对应点完成配准的精度高，故通常使用基于点的多视图精配准算法；而针对场景数据集，基于帧的多视图配准算法根据点云间的旋转平移变换矩阵间的关系来优化，时间开销极小，同时一定程度上会降低配准精度，对于点云初始配准条件要求更高。</p> 
<h3 id="h490b8bf-6UAocBma">05  总结与展望</h3> 
<h4 id="h6f20189-EU6q5JTe">5.1 总结</h4> 
<p>针对三维多视图点云配准问题，本研究首先对近二十余年的方法进行了系统分类，然后依据分类对方法进行归纳总结，随后介绍了该领域的主流数据库与评价指标，最后对本研究工作进行总结如下。</p> 
<p>a．本研究对多视图点云配准算法进行了全面的分类归纳。各类方法的发展历程总结如下：</p> 
<p>①在研究初期，领域的主要关注点在基于点云的点空间精配准算法，然而该类算法对点云数据噪声敏感；同时随着点云点数量的增加，时间开销急剧增加。</p> 
<p>②之后，便有学者提出基于帧空间变换平均的多视图精配准算法，通过到同一参考坐标系下的全局一致性来完成精配准，近十几年备受关注，其中的MA算法和LRS矩阵分解算法常用于该类精配准任务。</p> 
<p>③随后，鉴于帧空间中相对变换的可靠性不同，部分学者尝试为不同相对运动赋予不同的权值来提高配准精度，该类算法能显著降低精配准的时间开销，但对初始对齐的要求较高。</p> 
<p>④近年来，随着深度学习技术在各视觉领域的成果应用，基于深度学习的多视图精配准算法被陆续提出，一方面是利用深度学习提取点云相关特征；另一方面将粗配准变换矩阵作为输入，通过训练好的网络优化多个视图变换矩阵的空间一致性，从而完成多视图精配准。</p> 
<p>b．本研究根据算法分类，总结了每类算法的共性思路，为每类算法中的典型算法提炼了核心步骤，总结了同一类算法的异同，既便于读者对已有算法的核心技术进行宏观了解，也为后续学者针对某一类算法的改进提供思路。</p> 
<p>c．本研究总结了多视图点云配准领域的主流数据库和评价指标。目前，大部分多视图点云配准算法缺乏统一的实验数据库和评价体系，无法对现有各类算法进行公平对比，本研究关于数据库与评价指标的总结能为后续评估对比现有算法的性能提供借鉴与指导。</p> 
<h4 id="h6f20189-okaASjSX">5.2 展望</h4> 
<p>多视图点云配准研究历经二十余年，在取得了一定进展的同时仍存在如下问题有待进一步研究。</p> 
<p><strong>a．高精度、快速的多视图点云配准算法。</strong>当前多视图点云配准算法仍须要在配准精度和效率两者间进行取舍，例如基于帧空间的算法时效性强，但精度不高且对配准初始化要求严格，而基于点空间的算法精度高但较为耗时。基于点空间的算法搜寻所有对应点的开销大，通常采用点云降采样的方法，虽然提高了该类算法的效率，但是一定程度上降低了配准的精度。基于帧空间的算法仅根据变换矩阵之间的关系进行优化，忽略了点云之间点的对应关系，配准精度较低。因此，如何同时保证算法的精度和时效性是今后值得研究的问题之一。</p> 
<p><strong>b．鲁棒的多视图点云配准算法。</strong>当获取点云数据时，由于设备缺陷、场景变化等因素，点云数据中通常存在着大量的噪点，现有方法主要在预处理后的点云中进行配准，很难应对带有大量真实噪声的数据，因此研究对噪声等常见干扰鲁棒的算法是将来提高多目点云配准技术实用性和应用范围的关键。</p> 
<p><strong>c．基于深度学习的多视图点云配准算法。</strong>尽管深度学习在众多视觉领域已广泛应用并取得了显著的效果，但是深度学习在多视图精配准问题的应用仍处于起步阶段。未来结合深度学习的方向主要有三个：第一，构建更大规模的多视图点云配准数据集来满足网络的有效训练；第二，研究泛化性强的深度学习技术来应对不同应用场景条件下的多视图点云配准问题；第三，在现有数据集体量基础上，研究小样本条件下的深度学习技术来实现快速、高精度的多视图点云配准。</p> 
<p><strong>d．非刚性点云数据的多视图点云配准算法</strong>．现有算法主要研究刚性目标或场景的多视图点云配准问题，但动态目标、人体等非刚性目标的配准重建具有广泛的应用场景，因此非刚性点云数据的多视图配准将是未来极具研究价值的开放问题。</p> 
<ol><li>​<a href="http://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&amp;mid=2247508021&amp;idx=1&amp;sn=83a565ffa64eca51aa8fb33c6bbd88af&amp;chksm=f9e63430ce91bd26ef35e26a1958c1a4b2917e6aff01096b0bd2565e840970c5d8522ea4b6a9&amp;scene=21#wechat_redirect" rel="nofollow" title="​轻量级实时三维激光雷达SLAM，面向大规模城市环境自动驾驶​">​轻量级实时三维激光雷达SLAM，面向大规模城市环境自动驾驶​</a>​</li><li>​<a href="http://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&amp;mid=2247505464&amp;idx=1&amp;sn=ff217f19cc281b8bb7f4ca6b56c2bb18&amp;chksm=f9e6423dce91cb2b42d42585cd662372266db40e7a6580068399a50006358db37dcc28b730e2&amp;scene=21#wechat_redirect" rel="nofollow" title="​现实虚拟化：从三维重建到逆渲染（Inverse Rendering）​">​现实虚拟化：从三维重建到逆渲染（Inverse Rendering）​</a>​</li><li>​<a href="http://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&amp;mid=2247507528&amp;idx=1&amp;sn=5c7c6a8f4718c8b284b6169808a83bc0&amp;chksm=f9e64a4dce91c35b019c076969c864ec805d4bd78fe45c83423cd21fdf24747f292385b0d1f1&amp;scene=21#wechat_redirect" rel="nofollow" title="​书籍推荐-《3D计算机视觉》​">​书籍推荐-《3D计算机视觉》​</a>​</li><li>​<a href="http://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&amp;mid=2247506937&amp;idx=1&amp;sn=82719d019d12e1b9d63fb4a094c07e07&amp;chksm=f9e64ffcce91c6eaaa1eca0af5e0ef8c016dda43556781dc55bba901f7f8823e81eb3ec6b5a7&amp;scene=21#wechat_redirect" rel="nofollow" title="​动态场景下基于自适应语义分割的RGB-D SLAM算法​">​动态场景下基于自适应语义分割的RGB-D SLAM算法​</a>​</li><li>​<a href="http://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&amp;mid=2247504583&amp;idx=1&amp;sn=d4acd077760aa211884992757b5774eb&amp;chksm=f9e646c2ce91cfd4ab2ac1cd694aaa0e68099231a20baf66eea2f4b819b28a5371c8a3b1f8c6&amp;scene=21#wechat_redirect" rel="nofollow" title="​书籍推荐-《基于Python的3D深度学习》​">​书籍推荐-《基于Python的3D深度学习》​</a>​</li></ol>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8c797c1b809a8d96a186a27286eb4621/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">配置samba服务实现Linux(CentOS7)与Windows之间的文件共享</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/af0173b87cf4735e7bc890ccbacba1ce/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">雪花算法的原理和实现Java</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>