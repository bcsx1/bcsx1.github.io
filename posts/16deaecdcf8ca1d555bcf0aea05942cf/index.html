<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark优化最全解析 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Spark优化最全解析" />
<meta property="og:description" content="Spark 优化 资源调优 在部署spark集群中指定资源分配的默认参数 在spark安装包的conf下spark-env.sh文件
SPARK_WORKER_CORES SPARK_WORKER_MEMORY SPARK_WORKER_INSTANCES #每台机器启动worker数 在提交Application的时候给当前的Application分配更多的资源 提交命令选项：（在提交Application的时候使用选项） --executor-cores --executor-memory --total-executor-cores 配置信息：（Application的代码中设置或在Spark-default.conf中设置） spark.executor.cores spark.executor.memory spark.max.cores 动态分配资源 spark.shuffle.service.enabled true //启用External shuffle Service服务 spark.shuffle.service.port 7337 //Shuffle Service服务端口，必须和yarn-site中的一致 spark.dynamicAllocation.enabled true //开启动态资源分配 spark.dynamicAllocation.minExecutors 1 //每个Application最小分配的executor数 spark.dynamicAllocation.maxExecutors 30 //每个Application最大并发分配的executor数 spark.dynamicAllocation.schedulerBacklogTimeout 1s spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 5s 并行度调优 并行度的合理调整，可以降低资源浪费提高spark任务的运行效率。
task的数量应该设置为sparkCPU cores的2-3倍。
如果读取的数据在HDFS中，降低block大小，相当于提高了RDD中partition个数sc.textFile(xx,numPartitions)sc.parallelize(xxx, numPartitions)sc.makeRDD(xxx, numPartitions)sc.parallelizePairs(xxx, numPartitions)repartitions/coalesceredecByKey/groupByKey/join —(xxx, numPartitions)spark.default.parallelism 500spark.sql.shuffle.partitions—200自定义分区器如果读取数据是在SparkStreaming中
Receiver: spark.streaming.blockInterval—200ms定义的是max
Direct:读取的topic的分区数 代码调优 避免创建重复的RDD val rdd1 = sc.textFile(path1) val rdd2 = sc.textFile(path1) 这就是创建了重复的RDD
有什么问题？ 对于执行性能来说没有问题，但是呢，代码乱。
对多次使用的RDD进行持久化 如何选择一种最合适的持久化策略?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/16deaecdcf8ca1d555bcf0aea05942cf/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-12-14T17:22:20+08:00" />
<meta property="article:modified_time" content="2021-12-14T17:22:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark优化最全解析</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Spark__0"></a>Spark 优化</h2> 
<h3><a id="_2"></a>资源调优</h3> 
<h4><a id="spark_4"></a>在部署spark集群中指定资源分配的默认参数</h4> 
<p>在spark安装包的conf下spark-env.sh文件</p> 
<pre><code class="prism language-xml">SPARK_WORKER_CORES
SPARK_WORKER_MEMORY
SPARK_WORKER_INSTANCES #每台机器启动worker数
</code></pre> 
<h4><a id="ApplicationApplication_14"></a>在提交Application的时候给当前的Application分配更多的资源</h4> 
<h5><a id="Application_16"></a>提交命令选项：（在提交Application的时候使用选项）</h5> 
<pre><code class="prism language-xml">--executor-cores
--executor-memory
--total-executor-cores
</code></pre> 
<h5><a id="ApplicationSparkdefaultconf_24"></a>配置信息：（Application的代码中设置或在Spark-default.conf中设置）</h5> 
<pre><code class="prism language-xml">spark.executor.cores
spark.executor.memory
spark.max.cores
</code></pre> 
<h5><a id="_32"></a>动态分配资源</h5> 
<pre><code class="prism language-xml">spark.shuffle.service.enabled true //启用External shuffle Service服务
spark.shuffle.service.port 7337 //Shuffle Service服务端口，必须和yarn-site中的一致
spark.dynamicAllocation.enabled true //开启动态资源分配
spark.dynamicAllocation.minExecutors 1 //每个Application最小分配的executor数
spark.dynamicAllocation.maxExecutors 30 //每个Application最大并发分配的executor数
spark.dynamicAllocation.schedulerBacklogTimeout 1s
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 5s
</code></pre> 
<h3><a id="_44"></a>并行度调优</h3> 
<p>并行度的合理调整，可以降低资源浪费提高spark任务的运行效率。<br> task的数量应该设置为sparkCPU cores的2-3倍。</p> 
<ol><li>如果读取的数据在HDFS中，降低block大小，相当于提高了RDD中partition个数sc.textFile(xx,numPartitions)</li><li>sc.parallelize(xxx, numPartitions)</li><li>sc.makeRDD(xxx, numPartitions)</li><li>sc.parallelizePairs(xxx, numPartitions)</li><li>repartitions/coalesce</li><li>redecByKey/groupByKey/join —(xxx, numPartitions)</li><li>spark.default.parallelism 500</li><li>spark.sql.shuffle.partitions—200</li><li>自定义分区器</li><li>如果读取数据是在SparkStreaming中<br> Receiver: spark.streaming.blockInterval—200ms定义的是max<br> Direct:读取的topic的分区数</li></ol> 
<h3><a id="_62"></a>代码调优</h3> 
<h4><a id="RDD_64"></a>避免创建重复的RDD</h4> 
<pre><code class="prism language-scala"><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span>path1<span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span>path1<span class="token punctuation">)</span>
</code></pre> 
<p>这就是创建了重复的RDD<br> 有什么问题？ 对于执行性能来说没有问题，但是呢，代码乱。</p> 
<h4><a id="RDD_74"></a>对多次使用的RDD进行持久化</h4> 
<p>如何选择一种最合适的持久化策略?</p> 
<p>默认情况下，性能最高的当然是MEMORY_ONLY，但前提是你的内存必须足够足够大，可以绰绰有余地<br> 存放下整个RDD的所有数据。因为不进行序列化与反序列化操作，就避免了这部分的性能开销；对这个<br> RDD的后续算子操作，都是基于纯内存中的数据的操作，不需要从磁盘文件中读取数据，性能也很高；<br> 而且不需要复制一份数据副本，并远程传送到其他节点上。但是这里必须要注意的是，在实际的生产环<br> 境中，恐怕能够直接用这种策略的场景还是有限的，如果RDD中数据比较多时（比如几十亿），直接用<br> 这种持久化级别，会导致JVM的OOM内存溢出异常。<br> 如果使用MEMORY_ONLY级别时发生了内存溢出，那么建议尝试使用MEMORY_ONLY_SER级别。该级<br> 别会将RDD数据序列化后再保存在内存中，此时每个partition仅仅是一个字节数组而已，大大减少了对<br> 象数量，并降低了内存占用。这种级别比MEMORY_ONLY多出来的性能开销，主要就是序列化与反序列<br> 化的开销。但是后续算子可以基于纯内存进行操作，因此性能总体还是比较高的。此外，可能发生的问<br> 题同上，如果RDD中的数据量过多的话，还是可能会导致OOM内存溢出的异常。<br> 如果纯内存的级别都无法使用，那么建议使用MEMORY_AND_DISK_SER策略，而不是<br> MEMORY_AND_DISK策略。因为既然到了这一步，就说明RDD的数据量很大，内存无法完全放下。序列<br> 化后的数据比较少，可以节省内存和磁盘的空间开销。同时该策略会优先尽量尝试将数据缓存在内存<br> 中，内存缓存不下才会写入磁盘。<br> 通常不建议使用DISK_ONLY和后缀为2的级别：因为完全基于磁盘文件进行数据的读写，会导致性能急<br> 剧降低，有时还不如重新计算一次所有RDD。后缀为2的级别，必须将所有数据都复制一份副本，并发送<br> 到其他节点上，数据复制以及网络传输会导致较大的性能开销，除非是要求作业的高可用性，否则不建<br> 议使用。</p> 
<h4><a id="_98"></a>持久化算子</h4> 
<ul><li>cache:<br> MEMORY_ONLY</li><li>persist：<br> MEMORY_ONLY<br> MEMORY_ONLY_SER<br> MEMORY_AND_DISK_SER</li><li>checkpoint: 
  <ul><li>如果一个RDD的计算时间比较长或者计算起来比较复杂，一般将这个RDD的计算结果保存到HDFS<br> 上，这样数据会更加安全。</li><li>如果一个RDD的依赖关系非常长，也会使用checkpoint,会切断依赖关系，提高容错的效率</li></ul> </li></ul> 
<h4><a id="shuffle_111"></a>尽量避免使用shuffle类的算子</h4> 
<p>使用广播变量来模拟使用join,使用情况：一个RDD比较大，一个RDD比较小。<br> join算子=广播变量+filter、广播变量+map、广播变量+flatMap</p> 
<h4><a id="mapsideshuffle_116"></a>使用map-side预聚合的shuffle操作</h4> 
<p>即尽量使用有combiner的shuffle类算子。<br> combiner概念：<br> 在map端，每一个map task计算完毕后进行的局部聚合。<br> combiner好处：<br> 1) 降低shuffle write写磁盘的数据量。<br> 2) 降低shuffle read拉取数据量的大小。<br> 3) 降低reduce端聚合的次数。</p> 
<p>有combiner的shuffle类算子：<br> 1) reduceByKey:这个算子在map端是有combiner的，在一些场景中可以使用reduceByKey代替<br> groupByKey。<br> 2) aggregateByKey<br> 3) combinerByKey</p> 
<h4><a id="_132"></a>尽量使用高性能的算子</h4> 
<p>使用reduceByKey替代groupByKey<br> 使用mapPartition替代map<br> 使用foreachPartition替代foreach<br> filter后使用coalesce减少分区数<br> 使用repartitionAndSortWithinPartitions替代repartition与sort类操作</p> 
<p>使用repartition和coalesce算子操作分区。</p> 
<h4><a id="_142"></a>使用广播变量</h4> 
<p>开发过程中，会遇到需要在算子函数中使用外部变量的场景（尤其是大变量，比如100M以上的大集<br> 合），那么此时就应该使用Spark的广播(Broadcast）功能来提升性能，函数中使用到外部变量时，默<br> 认情况下，Spark会将该变量复制多个副本，通过网络传输到task中，此时每个task都有一个变量副本。<br> 如果变量本身比较大的话（比如100M，甚至1G），那么大量的变量副本在网络中传输的性能开销，以<br> 及在各个节点的Executor中占用过多内存导致的频繁GC，都会极大地影响性能。如果使用的外部变量比<br> 较大，建议使用Spark的广播功能，对该变量进行广播。广播后的变量，会保证每个Executor的内存<br> 中，只驻留一份变量副本，而Executor中的task执行时共享该Executor中的那份变量副本。这样的话，<br> 可以大大减少变量副本的数量，从而减少网络传输的性能开销，并减少对Executor内存的占用开销，降<br> 低GC的频率。<br> 广播大变量发送方式：Executor一开始并没有广播变量，而是task运行需要用到广播变量，会找<br> executor的blockManager要，bloackManager找Driver里面的blockManagerMaster要。<br> 使用广播变量可以大大降低集群中变量的副本数。不使用广播变量，变量的副本数和task数一致。使用<br> 广播变量变量的副本和Executor数一致。</p> 
<h4><a id="Kryo_158"></a>使用Kryo优化序列化性能</h4> 
<p>在Spark中，主要有三个地方涉及到了序列化：<br> 1) 在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输。<br> 2) 将自定义的类型作为RDD的泛型类型时（比如JavaRDD，SXT是自定义类型），所有自定义类型对<br> 象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现Serializable接口。<br> 3) 使用可序列化的持久化策略时（比如MEMORY_ONLY_SER），Spark会将RDD中的每个partition都序<br> 列化成一个大的字节数组。</p> 
<p>Kryo序列化器介绍：</p> 
<p>​ Spark支持使用Kryo序列化机制。Kryo序列化机制，比默认的Java序列化机制，速度要快，序列化后的<br> ​ 数据要更小，大概是Java序列化机制的1/10。所以Kryo序列化优化以后，可以让网络传输的数据变少；<br> ​ 在集群中耗费的内存资源大大减少。</p> 
<h4><a id="_173"></a>优化数据结构</h4> 
<p>java中有三种类型比较消耗内存：<br> 1) 对象，每个Java对象都有对象头、引用等额外的信息，因此比较占用内存空间。<br> 2) 字符串，每个字符串内部都有一个字符数组以及长度等额外信息。<br> 3) 集合类型，比如HashMap、LinkedList等，因为集合类型内部通常会使用一些内部类来封装集合元<br> 素，比如Map.Entry。<br> 因此Spark官方建议，在Spark编码实现中，特别是对于算子函数中的代码，尽量不要使用上述三种数据<br> 结构，尽量使用字符串替代对象，使用原始类型（比如Int、Long）替代字符串，使用数组替代集合类<br> 型，这样尽可能地减少内存占用，从而降低GC频率，提升性能。</p> 
<h4><a id="fastutil_184"></a>使用高性能的库fastutil</h4> 
<p>fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提<br> 供了特殊类型的map、set、list和queue；fastutil能够提供更小的内存占用，更快的存取速度</p> 
<h3><a id="_189"></a>数据本地化</h3> 
<h4><a id="_191"></a>数据本地化的级别</h4> 
<h5><a id="PROCESS_LOCAL_193"></a>PROCESS_LOCAL</h5> 
<p>task要计算的数据在本进程（Executor）的内存中。<br> <img src="https://images2.imgbox.com/57/eb/hC9OVTOX_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="NODE_LOCAL_199"></a>NODE_LOCAL</h5> 
<p>① task所计算的数据在本节点所在的磁盘上。<br> ② task所计算的数据在本节点其他Executor进程的内存中。</p> 
<p><img src="https://images2.imgbox.com/7f/9d/xNQ6lO4K_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="NO_PREF_207"></a>NO_PREF</h5> 
<p>task所计算的数据在关系型数据库中，如mysql。</p> 
<p><img src="https://images2.imgbox.com/83/cf/3Ge0cxBU_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="RACK_LOCAL_214"></a>RACK_LOCAL</h5> 
<p>ask所计算的数据在同机架的不同节点的磁盘或者Executor进程的内存中</p> 
<p><img src="https://images2.imgbox.com/66/42/qT6TN0Gt_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="ANY_221"></a>ANY</h5> 
<p>跨机架。</p> 
<h4><a id="Spark_225"></a>Spark数据本地化调优</h4> 
<p><img src="https://images2.imgbox.com/29/47/5jQhC7Ao_o.png" alt="在这里插入图片描述"></p> 
<p>Spark中任务调度时，TaskScheduler在分发之前需要依据数据的位置来分发，最好将task分发到数据所<br> 在的节点上，如果TaskScheduler分发的task在默认3s依然无法执行的话，TaskScheduler会重新发送这<br> 个task到相同的Executor中去执行，会重试5次，如果依然无法执行，那么TaskScheduler会降低一级数<br> 据本地化的级别再次发送task。<br> 如上图中，会先尝试1,PROCESS_LOCAL数据本地化级别，如果重试5次每次等待3s,会默认这个Executor<br> 计算资源满了，那么会降低一级数据本地化级别到2，NODE_LOCAL,如果还是重试5次每次等待3s还是<br> 失败，那么还是会降低一级数据本地化级别到3，RACK_LOCAL。这样数据就会有网络传输，降低了执行<br> 效率。</p> 
<h5><a id="_239"></a>如何提高数据本地化的级别？</h5> 
<p>可以增加每次发送task的等待时间（默认都是3s），将3s倍数调大， 结合WEBUI来调节：</p> 
<p>​ • spark.locality.wait<br> ​ • spark.locality.wait.process<br> ​ • spark.locality.wait.node<br> ​ • spark.locality.wait.rack</p> 
<p>注意：等待时间不能调大很大，调整数据本地化的级别不要本末倒置，虽然每一个task的本地化级别是<br> 最高了，但整个Application的执行时间反而加长。</p> 
<h5><a id="_251"></a>如何查看数据本地化的级别？</h5> 
<p>通过日志或者WEBUI</p> 
<h3><a id="_255"></a>内存调优</h3> 
<p><img src="https://images2.imgbox.com/02/8e/hX5jERPe_o.png" alt="在这里插入图片描述"></p> 
<p>JVM堆内存分为一块较大的Eden和两块较小的Survivor，每次只使用Eden和其中一块Survivor，当回收<br> 时将Eden和Survivor中还存活着的对象一次性复制到另外一块Survivor上，最后清理掉Eden和刚才用过<br> 的Survivor。也就是说当task创建出来对象会首先往Eden和survivor1中存放，survivor2是空闲的，当<br> Eden和survivor1区域放满以后就会触发minor gc小型垃圾回收，清理掉不再使用的对象。会将存活下<br> 来的对象放入survivor2中。<br> 如果存活下来的对象大小大于survivor2的大小，那么JVM就会将多余的对象直接放入到老年代中。<br> 如果这个时候年轻代的内存不是很大的话，就会经常的进行minor gc，频繁的minor gc会导致短时间内<br> 有些存活的对象（多次垃圾回收都没有回收掉，一直在用的又不能被释放,这种对象每经过一次minor gc<br> 都存活下来）频繁的倒来倒去，会导致这些短生命周期的对象（不一定长期使用）每进行一次垃圾回收<br> 就会长一岁。年龄过大，默认15岁，垃圾回收还是没有回收回去就会跑到老年代里面去了。<br> 这样会导致在老年代中存放大量的短生命周期的对象，老年代应该存放的是数量比较少并且会长期使用<br> 的对象，比如数据库连接池对象。这样的话，老年代就会满溢（full gc 因为本来老年代中的对象很少，<br> 很少进行full gc 因此采取了不太复杂但是消耗性能和时间的垃圾回收算法）。不管minor gc 还是 full gc<br> 都会导致JVM的工作线程停止。</p> 
<h4><a id="_275"></a>总结堆内存不足造成的影响</h4> 
<h5><a id="minor_gc_277"></a>频繁的minor gc</h5> 
<h5><a id="full_gc_279"></a>老年代中大量的短声明周期的对象会导致full gc</h5> 
<h5><a id="gc_Spark_281"></a>gc 多了就会影响Spark的性能和运行的速度</h5> 
<p>Spark JVM调优主要是降低gc时间，可以修改Executor内存的比例参数。<br> RDD缓存、task定义运行的算子函数，可能会创建很多对象，这样会占用大量的堆内存。堆内存满了之<br> 后会频繁的GC，如果GC还不能够满足内存的需要的话就会报OOM。比如一个task在运行的时候会创建<br> N个对象，这些对象首先要放入到JVM年轻代中。比如在存数据的时候我们使用了foreach来将数据写入<br> 到内存，每条数据都会封装到一个对象中存入数据库中，那么有多少条数据就会在JVM中创建多少个对<br> 象。</p> 
<h4><a id="Spark_290"></a>Spark中如何内存调优？</h4> 
<p>Spark Executor堆内存中存放（以静态内存管理为例）：RDD的缓存数据和广播变量<br> （spark.storage.memoryFraction 0.6），shuffle聚合内存（spark.shuffle.memoryFraction<br> 0.2）,task的运行（0.2）那么如何调优呢？<br> 1) 提高Executor总体内存的大小<br> 2) 降低储存内存比例或者降低聚合内存比例<br> 如何查看gc？<br> Spark WEBUI中job-&gt;stage-&gt;task</p> 
<h4><a id="Executor_300"></a>调节Executor的堆外内存</h4> 
<h3><a id="Spark_Shuffle_302"></a>Spark Shuffle调优</h3> 
<ol><li>buffer大小——32KB</li><li>shuffle read拉取数据量的大小——48M</li><li>shuffle聚合内存的比例——20%</li><li>拉取数据重试次数——5次</li><li>重试间隔时间60s</li><li>Spark Shuffle的种类</li><li>SortShuffle bypass机制 200次调大</li></ol> 
<h3><a id="_312"></a>解决数据倾斜</h3> 
<h4><a id="Hive_ETL_314"></a>使用Hive ETL预处理数据</h4> 
<p>方案适用场景：<br> 如果导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀（比如某个key对应了100万数据，<br> 其他key才对应了10条数据），而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较<br> 适合使用这种技术方案。<br> 方案实现思路：<br> 此时可以评估一下，是否可以通过Hive来进行数据预处理（即通过Hive ETL预先对数据按照key进行聚<br> 合，或者是预先和其他表进行join），然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预<br> 处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用<br> 原先的shuffle类算子执行这类操作了。<br> 方案实现原理：<br> 这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有<br> 数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在<br> 分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导<br> 致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜<br> 而已。</p> 
<h4><a id="key_332"></a>过滤少数导致倾斜的key</h4> 
<p>方案适用场景：<br> 如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比<br> 如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。<br> 方案实现思路：<br> 如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就<br> 直接过滤掉那少数几个key。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark<br> Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最<br> 多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量<br> 最多的key过滤掉即可。<br> 方案实现原理：</p> 
<p>​ 将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。</p> 
<h4><a id="shuffle_347"></a>提高shuffle操作的并行度</h4> 
<p>方案实现思路：<br> 在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了<br> 这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、<br> join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行<br> 度，该值默认是200，对于很多场景来说都有点过小。<br> 方案实现原理：<br> 增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task<br> 处理比原来更少的数据。举例来说，如果原本有5个不同的key，每个key对应10条数据，这5个key都是<br> 分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分<br> 配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。<br> 缺点：不是万能的，没有从根本上改变数据的格式所以数据倾斜问题还是可能存在。<br> 例如极端情况，有一个key对应数据就是100w，别的key对应1w，你再怎么增加task，相同的可以还是<br> 会分配到一个task中去计算。<br> 不能根本解决问题，可以缓解一波。</p> 
<h4><a id="_364"></a>双重聚合</h4> 
<p>方案适用场景：<br> 对RDD执行reduceByKey、groupByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进<br> 行分组聚合时，比较适用这种方案。<br> 方案实现思路：<br> 这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比<br> 如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello,<br> 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行<br> reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然<br> 后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果<br> 了，比如(hello, 4)。<br> 方案实现原理：<br> 将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据<br> 分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再<br> 次进行全局聚合，就可以得到最终的结果。<br> <img src="https://images2.imgbox.com/e2/6f/wGdzOWpD_o.png" alt="在这里插入图片描述"></p> 
<p>如果一个RDD中有一个key导致数据倾斜，同时还有其他的key，那么一般先对数据集进行抽样，然后找<br> 出倾斜的key,再使用filter对原始的RDD进行分离为两个RDD，一个是由倾斜的key组成的RDD1，一个是<br> 由其他的key组成的RDD2，那么对于RDD1可以使用加随机前缀进行多分区多task计算，对于另一个<br> RDD2正常聚合计算，最后将结果再合并起来。<br> 只适用于聚合类的shuffle操作，join这类不太适合。</p> 
<h4><a id="reduce_joinmap_join_389"></a>将reduce join转为map join</h4> 
<p>BroadCast+filter(或者map)<br> 方案适用场景：<br> 在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数<br> 据量比较小（比如几百M或者一两G），比较适用此方案。<br> 方案实现思路：<br> 不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉<br> shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到<br> Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算<br> 子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比<br> 对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。<br> 方案实现原理：<br> 普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read<br> task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量<br> 数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发<br> 生数据倾斜。</p> 
<h4><a id="keyjoin_407"></a>采样倾斜key并分拆join操作</h4> 
<p>方案适用场景：<br> 两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下<br> 两个RDD/Hive表中的key分布情况。如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个<br> key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较<br> 合适的。<br> 方案实现思路:</p> 
<p>​ 对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个<br> ​ key的数量，计算出来数据量最大的是哪几个key。然后将这几个key对应的数据从原来的RDD中拆分出<br> ​ 来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key<br> ​ 形成另外一个RDD。接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单<br> ​ 独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部<br> ​ 分key也形成另外一个RDD。再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此<br> ​ 时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。而另外两个普通的RDD就照常<br> ​ join即可。最后将两次join的结果使用union算子合并起来即可，就是最终的join结果 。<br> <img src="https://images2.imgbox.com/42/8a/JULRwLQI_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="RDDjoin_427"></a>使用随机前缀和扩容RDD进行join</h4> 
<p>方案适用场景：<br> 如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只<br> 能使用最后一种方案来解决问题了。<br> 方案实现思路：<br> 该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数<br> 据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。然后将该RDD的每条数据都打上一个n<br> 以内的随机前缀。同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每<br> 条数据都依次打上一个0~n的前缀。最后将两个处理后的RDD进行join即可。</p> 
<p><img src="https://images2.imgbox.com/1a/ab/M5tXOdRF_o.png" alt="在这里插入图片描述"></p> 
<p>rdd中数据倾斜，sample抽样取出样本(key)，统计key对应的数量，以及最大的数据量的key。<br> 把这些key从rdd中抽取出去，形成单独的rdd，给key打上随机数作为前缀，另一部分没有抽出去的数据<br> 在形成另外一个rdd。<br> 另一个rdd（join），也将上次抽取出来的key过滤出一个单独的rdd，但是需要做扩容（数据量的膨<br> 胀）。在这些数据上追加上随机数，和之前的rdd加随机数的规则一致，没有抽离的数据也还是形成一<br> 个新的rdd。<br> 两两join，有随机数的记得去掉前缀，然后最终结果union得出。</p> 
<h3><a id="Sparktroubleshooting_449"></a>Spark故障解决（troubleshooting）</h3> 
<h4><a id="shuffle_file_cannot_find_451"></a>shuffle file cannot find：磁盘小文件找不到。</h4> 
<h5><a id="connection_timeout_shuffle_file_cannot_find_453"></a>connection timeout ----shuffle file cannot find</h5> 
<p>提高建立连接的超时时间，或者降低gc，降低gc了那么spark不能堆外提供服务的时间就少了，那么超<br> 时的可能就会降低。</p> 
<h5><a id="fetch_data_fail__shuffle_file_cannot_find_458"></a>fetch data fail ---- shuffle file cannot find</h5> 
<p>提高拉取数据的重试次数以及间隔时间。</p> 
<h5><a id="OOMexecutor_lost__shuffle_file_cannot_find_462"></a>OOM/executor lost ---- shuffle file cannot find</h5> 
<p>提高堆外内存大小，提高堆内内存大小。</p> 
<h4><a id="reduce_OOM_466"></a>reduce OOM</h4> 
<p>BlockManager拉取的数据量大，reduce task处理的数据量小<br> 解决方法：<br> 1) 降低每次拉取的数据量<br> 2) 提高shuffle聚合的内存比例<br> 3) 提高Executor的内存比例</p> 
<h4><a id="_474"></a>序列化问题</h4> 
<h4><a id="Null_476"></a>Null值问题</h4> 
<pre><code class="prism language-xml">val rdd = rdd.map{x=&gt;{ x+”~”; -1}}filter(-1).coalescerdd.foreach{x=&gt;{
System.out.println(x.getName())}}
</code></pre> 
<p>c，降低gc了那么spark不能堆外提供服务的时间就少了，那么超<br> 时的可能就会降低。</p> 
<h5><a id="fetch_data_fail__shuffle_file_cannot_find_488"></a>fetch data fail ---- shuffle file cannot find</h5> 
<p>提高拉取数据的重试次数以及间隔时间。</p> 
<h5><a id="OOMexecutor_lost__shuffle_file_cannot_find_492"></a>OOM/executor lost ---- shuffle file cannot find</h5> 
<p>提高堆外内存大小，提高堆内内存大小。</p> 
<h4><a id="reduce_OOM_496"></a>reduce OOM</h4> 
<p>BlockManager拉取的数据量大，reduce task处理的数据量小<br> 解决方法：<br> 1) 降低每次拉取的数据量<br> 2) 提高shuffle聚合的内存比例<br> 3) 提高Executor的内存比例</p> 
<h4><a id="_504"></a>序列化问题</h4> 
<h4><a id="Null_506"></a>Null值问题</h4> 
<pre><code class="prism language-xml">val rdd = rdd.map{x=&gt;{ x+”~”; -1}}filter(-1).coalescerdd.foreach{x=&gt;{
System.out.println(x.getName())}}
</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5563d00e8892d86b4f953b218bc2e520/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Docker教程：解决Docker容器内不能使用vim命令的问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6cee49c899eaf59a55b17529b62c3663/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Vue 前端 put 或 post 请求发送到 Spring Boot 后端无法接收到数据的解决方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>