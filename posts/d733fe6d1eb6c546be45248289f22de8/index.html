<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>RNN以及其改进版（附2个代码案列） - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="RNN以及其改进版（附2个代码案列）" />
<meta property="og:description" content="感谢阅读 RNN简介传统RNN内部结构过程演示内部计算公式RNN輸出激活函数tanhPytorch构建传统RNN梯度计算 LSTM介绍遗忘门结构分析：输入门结构分析:细胞状态更新分析:输出门结构分析:结构图梯度公式现实生活列子加强理解代码示例 GRU介绍结构图个人对GRU的理解LSTM难以比拟的两个地方 RNN示例（人名分类问题）案例介绍数据集下载与解释导包查看常用字符数量构建国家名字，并获取国家数量读数据到内存构建数据源并进行迭代对异常索引的处理的改良 构建三种RNN模型构建传统RNN构建LSTM构建GRU 对三个模型进行测试与训练测试训练传统RNNLSTMGRU 进行预测构建预测函数传统RNNLSTMGRU调用 注意力机制注意力机制简介注意力概念注意力计算规则作用生活场景帮助理解 bmm运算简介代码实现 RNN案例 seq2seq英译法seq2seq介绍seq2seq模型架构模型解释 数据集下载导包并进行文件清洗思路分析数据预处理构建数据源对象并测试编码器和解码器构建基于GRU的编码器思路分析代码实现 基于GRU和Attention的解码器结构图代码实现 训练模型teacher_forcing内部迭代训练函数设置参数代码实现 训练 模型评估与测试评估函数书写评估 关于服务器调试python的说明操作前需要知道的知识点nohuptail 首先进入python文件所在目录并进行编译转后台进程启动一个SSH连接看训练输出执行结果 RNN简介 RNN(Recurrent Neural Network), 中文称作循环神经网络, 它一般以序列数据为输入, 通过网络内部的结构设计有效捕捉序列之间的关系特征, 一般也是以序列形式进行输出
传统RNN 内部结构过程演示 两个黑点一起到达蓝色区域（并在之前形成整体）
内部计算公式 RNN輸出 激活函数tanh 于帮助调节流经网络的值, tanh函数将值压缩在-1和1之间
Pytorch构建传统RNN def dm_run_for_hiddennum(): &#39;&#39;&#39; 第一个参数：input_size(输入张量x的维度) 第二个参数：hidden_size(隐藏层的维度， 隐藏层的神经元个数) 第三个参数：num_layer(隐藏层的数量) &#39;&#39;&#39; rnn = nn.RNN(5, 6, 2) # A 隐藏层个数从1--&gt;2 下面程序需要修改的地方？ &#39;&#39;&#39; 第一个参数：sequence_length(输入序列的长度) 第二个参数：batch_size(批次的样本数量) 第三个参数：input_size(输入张量的维度) &#39;&#39;&#39; input = torch.randn(1, 3, 5) # B &#39;&#39;&#39; 第一个参数：num_layer * num_directions(层数*网络方向) 第二个参数：batch_size(批次的样本数) 第三个参数：hidden_size(隐藏层的维度， 隐藏层神经元的个数) &#39;&#39;&#39; h0 = torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/d733fe6d1eb6c546be45248289f22de8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-07T02:08:47+08:00" />
<meta property="article:modified_time" content="2022-06-07T02:08:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">RNN以及其改进版（附2个代码案列）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>感谢阅读</h4> 
 <ul><li><a href="#RNN_1" rel="nofollow">RNN简介</a></li><li><ul><li><a href="#RNN_3" rel="nofollow">传统RNN</a></li><li><ul><li><a href="#_4" rel="nofollow">内部结构过程演示</a></li><li><a href="#_7" rel="nofollow">内部计算公式</a></li><li><a href="#RNN_9" rel="nofollow">RNN輸出</a></li><li><a href="#tanh_12" rel="nofollow">激活函数tanh</a></li><li><a href="#PytorchRNN_15" rel="nofollow">Pytorch构建传统RNN</a></li><li><a href="#_45" rel="nofollow">梯度计算</a></li></ul> 
   </li><li><a href="#LSTM_47" rel="nofollow">LSTM介绍</a></li><li><ul><li><a href="#_50" rel="nofollow">遗忘门结构分析：</a></li><li><a href="#_52" rel="nofollow">输入门结构分析:</a></li><li><a href="#_54" rel="nofollow">细胞状态更新分析:</a></li><li><a href="#_56" rel="nofollow">输出门结构分析:</a></li><li><a href="#_58" rel="nofollow">结构图</a></li><li><a href="#_67" rel="nofollow">梯度公式</a></li><li><a href="#_70" rel="nofollow">现实生活列子加强理解</a></li><li><a href="#_73" rel="nofollow">代码示例</a></li></ul> 
   </li><li><a href="#GRU_112" rel="nofollow">GRU介绍</a></li><li><ul><li><a href="#_114" rel="nofollow">结构图</a></li><li><a href="#GRU_116" rel="nofollow">个人对GRU的理解</a></li><li><a href="#LSTM_120" rel="nofollow">LSTM难以比拟的两个地方</a></li></ul> 
  </li></ul> 
  </li><li><a href="#RNN_123" rel="nofollow">RNN示例（人名分类问题）</a></li><li><ul><li><a href="#_124" rel="nofollow">案例介绍</a></li><li><a href="#_126" rel="nofollow">数据集下载与解释</a></li><li><a href="#_130" rel="nofollow">导包</a></li><li><a href="#_149" rel="nofollow">查看常用字符数量</a></li><li><a href="#_168" rel="nofollow">构建国家名字，并获取国家数量</a></li><li><a href="#_185" rel="nofollow">读数据到内存</a></li><li><a href="#_211" rel="nofollow">构建数据源并进行迭代</a></li><li><ul><li><a href="#_283" rel="nofollow">对异常索引的处理的改良</a></li></ul> 
   </li><li><a href="#RNN_310" rel="nofollow">构建三种RNN模型</a></li><li><ul><li><a href="#RNN_311" rel="nofollow">构建传统RNN</a></li><li><a href="#LSTM_348" rel="nofollow">构建LSTM</a></li><li><a href="#GRU_390" rel="nofollow">构建GRU</a></li></ul> 
   </li><li><a href="#_426" rel="nofollow">对三个模型进行测试与训练</a></li><li><ul><li><a href="#_427" rel="nofollow">测试</a></li><li><a href="#_477" rel="nofollow">训练</a></li><li><ul><li><a href="#RNN_478" rel="nofollow">传统RNN</a></li><li><a href="#LSTM_566" rel="nofollow">LSTM</a></li><li><a href="#GRU_651" rel="nofollow">GRU</a></li></ul> 
   </li></ul> 
   </li><li><a href="#_734" rel="nofollow">进行预测</a></li><li><ul><li><a href="#_735" rel="nofollow">构建预测函数</a></li><li><ul><li><a href="#RNN_756" rel="nofollow">传统RNN</a></li><li><a href="#LSTM_797" rel="nofollow">LSTM</a></li><li><a href="#GRU_832" rel="nofollow">GRU</a></li><li><a href="#_864" rel="nofollow">调用</a></li></ul> 
   </li></ul> 
  </li></ul> 
  </li><li><a href="#_872" rel="nofollow">注意力机制</a></li><li><ul><li><a href="#_873" rel="nofollow">注意力机制简介</a></li><li><ul><li><a href="#_874" rel="nofollow">注意力概念</a></li><li><a href="#_876" rel="nofollow">注意力计算规则</a></li><li><a href="#_878" rel="nofollow">作用</a></li><li><a href="#_881" rel="nofollow">生活场景帮助理解</a></li></ul> 
   </li><li><a href="#bmm_883" rel="nofollow">bmm运算简介</a></li><li><a href="#_894" rel="nofollow">代码实现</a></li></ul> 
  </li><li><a href="#RNN_seq2seq_985" rel="nofollow">RNN案例 seq2seq英译法</a></li><li><ul><li><a href="#seq2seq_986" rel="nofollow">seq2seq介绍</a></li><li><ul><li><a href="#seq2seq_987" rel="nofollow">seq2seq模型架构</a></li><li><a href="#_989" rel="nofollow">模型解释</a></li></ul> 
   </li><li><a href="#_992" rel="nofollow">数据集下载</a></li><li><a href="#_994" rel="nofollow">导包并进行文件清洗</a></li><li><a href="#_1033" rel="nofollow">思路分析</a></li><li><a href="#_1049" rel="nofollow">数据预处理</a></li><li><a href="#_1096" rel="nofollow">构建数据源对象并测试</a></li><li><a href="#_1160" rel="nofollow">编码器和解码器</a></li><li><ul><li><a href="#GRU_1161" rel="nofollow">构建基于GRU的编码器</a></li><li><ul><li><a href="#_1162" rel="nofollow">思路分析</a></li><li><a href="#_1176" rel="nofollow">代码实现</a></li></ul> 
    </li><li><a href="#GRUAttention_1206" rel="nofollow">基于GRU和Attention的解码器</a></li><li><ul><li><a href="#_1207" rel="nofollow">结构图</a></li><li><a href="#_1210" rel="nofollow">代码实现</a></li></ul> 
   </li></ul> 
   </li><li><a href="#_1284" rel="nofollow">训练模型</a></li><li><ul><li><a href="#teacher_forcing_1285" rel="nofollow">teacher_forcing</a></li><li><a href="#_1287" rel="nofollow">内部迭代训练函数</a></li><li><ul><li><a href="#_1288" rel="nofollow">设置参数</a></li><li><a href="#_1298" rel="nofollow">代码实现</a></li></ul> 
    </li><li><a href="#_1357" rel="nofollow">训练</a></li></ul> 
   </li><li><a href="#_1422" rel="nofollow">模型评估与测试</a></li><li><ul><li><a href="#_1423" rel="nofollow">评估函数书写</a></li><li><a href="#_1474" rel="nofollow">评估</a></li></ul> 
  </li></ul> 
  </li><li><a href="#python_1526" rel="nofollow">关于服务器调试python的说明</a></li><li><ul><li><a href="#_1528" rel="nofollow">操作前需要知道的知识点</a></li><li><ul><li><a href="#nohup_1529" rel="nofollow">nohup</a></li><li><a href="#tail_1535" rel="nofollow">tail</a></li></ul> 
   </li><li><a href="#python_1546" rel="nofollow">首先进入python文件所在目录并进行编译</a></li><li><a href="#_1548" rel="nofollow">转后台进程</a></li><li><a href="#SSH_1552" rel="nofollow">启动一个SSH连接看训练输出</a></li><li><a href="#_1557" rel="nofollow">执行结果</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="RNN_1"></a>RNN简介</h2> 
<p>RNN(Recurrent Neural Network), 中文称作循环神经网络, 它一般以序列数据为输入, 通过网络内部的结构设计有效捕捉序列之间的关系特征, 一般也是以序列形式进行输出</p> 
<h3><a id="RNN_3"></a>传统RNN</h3> 
<h4><a id="_4"></a>内部结构过程演示</h4> 
<p><img src="https://images2.imgbox.com/86/5e/ck4AWvow_o.png" alt="在这里插入图片描述"><br> 两个黑点一起到达蓝色区域（并在之前形成整体）</p> 
<h4><a id="_7"></a>内部计算公式</h4> 
<p><img src="https://images2.imgbox.com/6e/32/mFXmo0sC_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="RNN_9"></a>RNN輸出</h4> 
<p><img src="https://images2.imgbox.com/9f/dd/giB5UPwD_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="tanh_12"></a>激活函数tanh</h4> 
<p><img src="https://images2.imgbox.com/43/c8/QS3zoCBD_o.png" alt="在这里插入图片描述"><br> 于帮助调节流经网络的值, tanh函数将值压缩在-1和1之间</p> 
<h4><a id="PytorchRNN_15"></a>Pytorch构建传统RNN</h4> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">dm_run_for_hiddennum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    第一个参数：input_size(输入张量x的维度)
    第二个参数：hidden_size(隐藏层的维度， 隐藏层的神经元个数)
    第三个参数：num_layer(隐藏层的数量)
    '''</span>
    rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># A 隐藏层个数从1--&gt;2 下面程序需要修改的地方？</span>
    <span class="token triple-quoted-string string">'''
    第一个参数：sequence_length(输入序列的长度)
    第二个参数：batch_size(批次的样本数量)
    第三个参数：input_size(输入张量的维度)
    '''</span>
    <span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>  <span class="token comment"># B</span>
    <span class="token triple-quoted-string string">'''
    第一个参数：num_layer * num_directions(层数*网络方向)
    第二个参数：batch_size(批次的样本数)
    第三个参数：hidden_size(隐藏层的维度， 隐藏层神经元的个数)
    '''</span>
    h0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>  <span class="token comment"># C</span>

    output<span class="token punctuation">,</span> hn <span class="token operator">=</span> rnn<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> h0<span class="token punctuation">)</span>	  <span class="token comment">#</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output--&gt;'</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> output<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'hn--&gt;'</span><span class="token punctuation">,</span> hn<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> hn<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'rnn模型---&gt;'</span><span class="token punctuation">,</span> rnn<span class="token punctuation">)</span>  <span class="token comment"># nn模型---&gt; RNN(5, 6, num_layers=11)</span>

    <span class="token comment"># 结论：若只有一个隐藏次 output输出结果等于hn</span>
    <span class="token comment"># 结论：如果有2个隐藏层，output的输出结果有2个，hn等于最后一个隐藏层</span>
</code></pre> 
<h4><a id="_45"></a>梯度计算</h4> 
<p><img src="https://images2.imgbox.com/07/f5/wazffe3e_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="LSTM_47"></a>LSTM介绍</h3> 
<p>优点：LSTM的门结构能够有效减缓长序列问题中可能出现的梯度消失或爆炸, 虽然并不能杜绝这种现象, 但在更长的序列问题上表现优于传统RNN.<br> 缺点：由于内部结构相对较复杂, 因此训练效率在同等算力下较传统RNN低很多</p> 
<h4><a id="_50"></a>遗忘门结构分析：</h4> 
<p>与传统RNN的内部结构计算非常相似, 首先将当前时间步输入x(t)与上一个时间步隐含状态h(t-1)拼接, 得到[x(t), h(t-1)], 然后通过一个全连接层做变换, 最后通过sigmoid函数进行激活得到f(t), 我们可以将f(t)看作是门值, 好比一扇门开合的大小程度, 门值都将作用在通过该扇门的张量, 遗忘门门值将作用的上一层的细胞状态上, 代表遗忘过去的多少信息, 又因为遗忘门门值是由x(t), h(t-1)计算得来的, 因此整个公式意味着根据当前时间步输入和上一个时间步隐含状态h(t-1)来决定遗忘多少上一层的细胞状态所携带的过往信息.</p> 
<h4><a id="_52"></a>输入门结构分析:</h4> 
<p>我们看到输入门的计算公式有两个, 第一个就是产生输入门门值的公式, 它和遗忘门公式几乎相同, 区别只是在于它们之后要作用的目标上. 这个公式意味着输入信息有多少需要进行过滤. 输入门的第二个公式是与传统RNN的内部结构计算相同. 对于LSTM来讲, 它得到的是当前的细胞状态, 而不是像经典RNN一样得到的是隐含状态.</p> 
<h4><a id="_54"></a>细胞状态更新分析:</h4> 
<p>细胞更新的结构与计算公式非常容易理解, 这里没有全连接层, 只是将刚刚得到的遗忘门门值与上一个时间步得到的C(t-1)相乘, 再加上输入门门值与当前时间步得到的未更新C(t)相乘的结果. 最终得到更新后的C(t)作为下一个时间步输入的一部分. 整个细胞状态更新过程就是对遗忘门和输入门的应用.</p> 
<h4><a id="_56"></a>输出门结构分析:</h4> 
<p>输出门部分的公式也是两个, 第一个即是计算输出门的门值, 它和遗忘门，输入门计算方式相同. 第二个即是使用这个门值产生隐含状态h(t), 他将作用在更新后的细胞状态C(t)上, 并做tanh激活, 最终得到h(t)作为下一时间步输入的一部分. 整个输出门的过程, 就是为了产生隐含状态h(t).</p> 
<h4><a id="_58"></a>结构图</h4> 
<p><img src="https://images2.imgbox.com/d4/80/BTDKmgo2_o.png" alt="在这里插入图片描述"></p> 
<p>C表示某时刻的记忆细胞<br> h表示某时刻的状态<br> f遗忘门<br> i更新门<br> o输出门<br> ht流向下一个时刻以及直接输出</p> 
<h4><a id="_67"></a>梯度公式</h4> 
<p><img src="https://images2.imgbox.com/1b/6d/gilmOI8V_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_70"></a>现实生活列子加强理解</h4> 
<p>我们以考试为例子：我们马上要期末考试了，第一门是高数，第二门线代。这个图的Xt就是考线代，h(t-1)就是考高数的状态，c(t-1)就是考高数的记忆，ht包含了考线代结束的状态以及分数，分数那一部分作为输出从上面输出，状态传给下一门考试（比如英语）。为什么遗忘？因为并不是所有东西都是线代需要关心的，这就是遗忘门的作用。为什么要保留上一门知识，比如高数用到的运算能力是我们需要保留的。<br> 同样的，传统RNN就是要记住所有的东西，效率就会变低。</p> 
<h4><a id="_73"></a>代码示例</h4> 
<pre><code class="prism language-python"><span class="token comment"># 定义LSTM的参数含义: (input_size, hidden_size, num_layers)</span>
<span class="token comment"># 定义输入张量的参数含义: (sequence_length, batch_size, input_size)</span>
<span class="token comment"># 定义隐藏层初始张量和细胞初始状态张量的参数含义:</span>
<span class="token comment"># (num_layers * num_directions, batch_size, hidden_size)</span>

<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword">import</span> torch
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> h0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> c0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> output<span class="token punctuation">,</span> <span class="token punctuation">(</span>hn<span class="token punctuation">,</span> cn<span class="token punctuation">)</span> <span class="token operator">=</span> rnn<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>h0<span class="token punctuation">,</span> c0<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> output
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0447</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0335</span><span class="token punctuation">,</span>  <span class="token number">0.1454</span><span class="token punctuation">,</span>  <span class="token number">0.0438</span><span class="token punctuation">,</span>  <span class="token number">0.0865</span><span class="token punctuation">,</span>  <span class="token number">0.0416</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">0.0105</span><span class="token punctuation">,</span>  <span class="token number">0.1923</span><span class="token punctuation">,</span>  <span class="token number">0.5507</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1742</span><span class="token punctuation">,</span>  <span class="token number">0.1569</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0548</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1186</span><span class="token punctuation">,</span>  <span class="token number">0.1835</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0022</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1388</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0877</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4007</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>StackBackward<span class="token operator">&gt;</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> hn
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.4647</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2364</span><span class="token punctuation">,</span>  <span class="token number">0.0645</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3996</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0500</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0152</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">0.3852</span><span class="token punctuation">,</span>  <span class="token number">0.0704</span><span class="token punctuation">,</span>  <span class="token number">0.2103</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2524</span><span class="token punctuation">,</span>  <span class="token number">0.0243</span><span class="token punctuation">,</span>  <span class="token number">0.0477</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">0.2571</span><span class="token punctuation">,</span>  <span class="token number">0.0608</span><span class="token punctuation">,</span>  <span class="token number">0.2322</span><span class="token punctuation">,</span>  <span class="token number">0.1815</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0513</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0291</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

        <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.0447</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0335</span><span class="token punctuation">,</span>  <span class="token number">0.1454</span><span class="token punctuation">,</span>  <span class="token number">0.0438</span><span class="token punctuation">,</span>  <span class="token number">0.0865</span><span class="token punctuation">,</span>  <span class="token number">0.0416</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">0.0105</span><span class="token punctuation">,</span>  <span class="token number">0.1923</span><span class="token punctuation">,</span>  <span class="token number">0.5507</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1742</span><span class="token punctuation">,</span>  <span class="token number">0.1569</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0548</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1186</span><span class="token punctuation">,</span>  <span class="token number">0.1835</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0022</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1388</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0877</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4007</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>StackBackward<span class="token operator">&gt;</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> cn
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.8083</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5500</span><span class="token punctuation">,</span>  <span class="token number">0.1009</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5806</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0668</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1161</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">0.7438</span><span class="token punctuation">,</span>  <span class="token number">0.0957</span><span class="token punctuation">,</span>  <span class="token number">0.5509</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7725</span><span class="token punctuation">,</span>  <span class="token number">0.0824</span><span class="token punctuation">,</span>  <span class="token number">0.0626</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">0.3131</span><span class="token punctuation">,</span>  <span class="token number">0.0920</span><span class="token punctuation">,</span>  <span class="token number">0.8359</span><span class="token punctuation">,</span>  <span class="token number">0.9187</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4826</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0717</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

        <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.1240</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0526</span><span class="token punctuation">,</span>  <span class="token number">0.3035</span><span class="token punctuation">,</span>  <span class="token number">0.1099</span><span class="token punctuation">,</span>  <span class="token number">0.5915</span><span class="token punctuation">,</span>  <span class="token number">0.0828</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">0.0203</span><span class="token punctuation">,</span>  <span class="token number">0.8367</span><span class="token punctuation">,</span>  <span class="token number">0.9832</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4454</span><span class="token punctuation">,</span>  <span class="token number">0.3917</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1983</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2976</span><span class="token punctuation">,</span>  <span class="token number">0.7764</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0074</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1965</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1343</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6683</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>StackBackward<span class="token operator">&gt;</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="GRU_112"></a>GRU介绍</h3> 
<p>GRU（Gated Recurrent Unit）也称门控循环单元结构, 它也是传统RNN的变体, 同LSTM一样能够有效捕捉长序列之间的语义关联, 缓解梯度消失或爆炸现象.</p> 
<h4><a id="_114"></a>结构图</h4> 
<p><img src="https://images2.imgbox.com/0a/b6/O7DFO2C1_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="GRU_116"></a>个人对GRU的理解</h4> 
<p>鄙人不才，如有理解错误之处，还望海涵斧正，先行谢过。<br> 其实，个人感觉GRU是LSTM的改进版，把记忆、h二者功能进行了合并，其核心是上图最后一个式子，这就决定了记忆和遗忘的强度。<br> 我还是以上学为例子。h（t-1）相当于我们在学校期间所学的所有东西，现在我们要搞毕设（以软件工程为例子，因为不才是软件工程专业出身，其他专业不是很了解）。Xt就是我们要搞毕设.h(t)就是我们学到的东西可以提供给做毕设的，比如python语言、软件体系结构、软件工程导论等。rt是什么呢？就是各学科可以提供给做毕设的东西的比列，比如python语言提供70%，软件体系提供10%。当然也有可能有0，比如选修课中的外国历史。h(上面带波浪线)的就相当于需要新学习的东西，比如我们做毕设的时候，想搞个反向代理服务器，学校没有教我们，我们是不是要自学？</p> 
<h4><a id="LSTM_120"></a>LSTM难以比拟的两个地方</h4> 
<p>1.由于参数的减少，模型训练速度将会提升，同时可解释性也略微提升了一些。<br> 2.由于运算的改良，降低了过拟合的风险。</p> 
<h2><a id="RNN_123"></a>RNN示例（人名分类问题）</h2> 
<h3><a id="_124"></a>案例介绍</h3> 
<p>以一个人名为输入, 使用模型帮助我们判断它最有可能是来自哪一个国家的人名, 这在某些国际化公司的业务中具有重要意义, 在用户注册过程中, 会根据用户填写的名字直接给他分配可能的国家或地区选项, 以及该国家或地区的国旗, 限制手机号码位数等等。</p> 
<h3><a id="_126"></a>数据集下载与解释</h3> 
<p>在github上的name_decalre<br> <a href="https://github.com/GodOn514/dataset_download">点我下载</a><br> 数据格式说明 每一行第一个单词为人名，第二个单词为国家名。中间用制表符tab分割</p> 
<h3><a id="_130"></a>导包</h3> 
<pre><code class="prism language-python"><span class="token comment"># 导入torch工具</span>
<span class="token keyword">import</span> torch
<span class="token comment"># 导入nn准备构建模型</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token comment"># 导入torch的数据源 数据迭代器工具包</span>
<span class="token keyword">from</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader
<span class="token comment"># 用于获得常见字母及字符规范化</span>
<span class="token keyword">import</span> string
<span class="token comment"># 导入时间工具包</span>
<span class="token keyword">import</span> time
<span class="token comment"># 引入制图工具包  </span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token comment"># 从io中导入文件打开方法</span>
<span class="token keyword">from</span> io <span class="token keyword">import</span> <span class="token builtin">open</span>
</code></pre> 
<h3><a id="_149"></a>查看常用字符数量</h3> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">data_process</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 获取所有常用字符包括字母和常用标点</span>
    all_letters <span class="token operator">=</span> string<span class="token punctuation">.</span>ascii_letters <span class="token operator">+</span> <span class="token string">" .,;'"</span>
    <span class="token comment"># 获取常用字符数量</span>
    n_letters <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>all_letters<span class="token punctuation">)</span>
    <span class="token keyword">return</span> n_letters


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>data_process<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token number">0</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_168"></a>构建国家名字，并获取国家数量</h3> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">get_country</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 国家名 种类数</span>
    categorys <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Italian'</span><span class="token punctuation">,</span> <span class="token string">'English'</span><span class="token punctuation">,</span> <span class="token string">'Arabic'</span><span class="token punctuation">,</span> <span class="token string">'Spanish'</span><span class="token punctuation">,</span> <span class="token string">'Scottish'</span><span class="token punctuation">,</span> <span class="token string">'Irish'</span><span class="token punctuation">,</span> <span class="token string">'Chinese'</span><span class="token punctuation">,</span> <span class="token string">'Vietnamese'</span><span class="token punctuation">,</span> <span class="token string">'Japanese'</span><span class="token punctuation">,</span>
                 <span class="token string">'French'</span><span class="token punctuation">,</span> <span class="token string">'Greek'</span><span class="token punctuation">,</span> <span class="token string">'Dutch'</span><span class="token punctuation">,</span> <span class="token string">'Korean'</span><span class="token punctuation">,</span> <span class="token string">'Polish'</span><span class="token punctuation">,</span> <span class="token string">'Portuguese'</span><span class="token punctuation">,</span> <span class="token string">'Russian'</span><span class="token punctuation">,</span> <span class="token string">'Czech'</span><span class="token punctuation">,</span> <span class="token string">'German'</span><span class="token punctuation">]</span>
    <span class="token comment"># 国家名 个数</span>
    categorynum <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>categorys<span class="token punctuation">)</span>
    <span class="token keyword">return</span> categorys<span class="token punctuation">,</span>categorynum


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># print(data_process())</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>get_country<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token number">0</span>
</code></pre> 
<h3><a id="_185"></a>读数据到内存</h3> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">read_data</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    :param filename:
    :return:
    # 思路分析
    1 打开数据文件 open(filename, mode='r', encoding='utf-8')
    2 按行读文件、提取样本x 样本y line.strip().split('\t')
    3 返回样本x的列表、样本y的列表 my_list_x, my_list_y
    """</span>
    my_list_x<span class="token punctuation">,</span> my_list_y<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment"># 打开文件</span>
    <span class="token keyword">with</span>  <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token comment"># 按照行读数据</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> <span class="token number">5</span><span class="token punctuation">:</span>
                <span class="token keyword">continue</span>
            <span class="token comment"># 按照行提取样本x 样本y</span>
            <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
            my_list_x<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            my_list_y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    <span class="token comment"># 返回样本x的列表、样本y的列表</span>
    <span class="token keyword">return</span> my_list_x<span class="token punctuation">,</span> my_list_y
</code></pre> 
<h3><a id="_211"></a>构建数据源并进行迭代</h3> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">read_data</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    :param filename:
    :return:
    # 思路分析
    1 打开数据文件 open(filename, mode='r', encoding='utf-8')
    2 按行读文件、提取样本x 样本y line.strip().split('\t')
    3 返回样本x的列表、样本y的列表 my_list_x, my_list_y
    """</span>
    my_list_x<span class="token punctuation">,</span> my_list_y<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment"># 打开文件</span>
    <span class="token keyword">with</span>  <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token comment"># 按照行读数据</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> <span class="token number">5</span><span class="token punctuation">:</span>
                <span class="token keyword">continue</span>
            <span class="token comment"># 按照行提取样本x 样本y</span>
            <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
            my_list_x<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            my_list_y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    <span class="token comment"># 返回样本x的列表、样本y的列表</span>
    <span class="token keyword">return</span> my_list_x<span class="token punctuation">,</span> my_list_y
<span class="token keyword">class</span> <span class="token class-name">NameClassDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> my_list_x<span class="token punctuation">,</span> my_list_y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 样本x</span>
        self<span class="token punctuation">.</span>my_list_x <span class="token operator">=</span> my_list_x
        <span class="token comment"># 样本y</span>
        self<span class="token punctuation">.</span>my_list_y <span class="token operator">=</span> my_list_y
        <span class="token comment"># 样本条目数</span>
        self<span class="token punctuation">.</span>sample_len <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>my_list_x<span class="token punctuation">)</span>

    <span class="token comment"># 获取样本条数</span>
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>sample_len

    <span class="token comment"># 获取第几条 样本数据</span>
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 对index异常值进行修正 [0, self.sample_len-1]</span>
        index <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>sample_len<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 按索引获取 数据样本 x y</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>my_list_x<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>my_list_y<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        <span class="token comment"># print(x, y)</span>
        <span class="token comment"># 样本x one-hot张量化</span>
        tensor_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> n_letters<span class="token punctuation">)</span>
        <span class="token comment"># 遍历人名 的 每个字母 做成one-hot编码</span>
        <span class="token keyword">for</span> li<span class="token punctuation">,</span> letter <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># letter2indx 使用all_letters.find(letter)查找字母在all_letters表中的位置</span>
            <span class="token comment"># 给one-hot赋值</span>
            tensor_x<span class="token punctuation">[</span>li<span class="token punctuation">]</span><span class="token punctuation">[</span>all_letters<span class="token punctuation">.</span>find<span class="token punctuation">(</span>letter<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
        <span class="token comment"># 样本y 张量化</span>
        tensor_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>categorys<span class="token punctuation">.</span>index<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
        <span class="token comment"># 返回结果</span>
        <span class="token keyword">return</span> tensor_x<span class="token punctuation">,</span> tensor_y
<span class="token keyword">def</span> <span class="token function">dm_test_NameClassDataset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># 1 获取数据</span>
    myfilename <span class="token operator">=</span> <span class="token string">'../data/name_classfication.txt'</span>
    my_list_x<span class="token punctuation">,</span> my_list_y <span class="token operator">=</span> read_data<span class="token punctuation">(</span>myfilename<span class="token punctuation">)</span>
    <span class="token comment"># 2 实例化dataset对象</span>
    nameclassdataset <span class="token operator">=</span> NameClassDataset<span class="token punctuation">(</span>my_list_x<span class="token punctuation">,</span> my_list_y<span class="token punctuation">)</span>
    <span class="token comment"># 3 实例化dataloader</span>
    mydataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>nameclassdataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span>  i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span> <span class="token punctuation">(</span>mydataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x.shape'</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y.shape'</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token keyword">break</span>
</code></pre> 
<h4><a id="_283"></a>对异常索引的处理的改良</h4> 
<p>python语言支持我们的索引，所以我们的索引也应该如此，但是程序也会复杂一些，这个代码想替换的可以把NameClassDataset的__getitem__替换为下面的代码：</p> 
<pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 对index异常值进行修正 [0, self.sample_len-1]</span>
        <span class="token keyword">if</span> index <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            index <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>sample_len<span class="token punctuation">,</span> index<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            index <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>sample_len<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>
        <span class="token comment"># 按索引获取 数据样本 x y</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>my_list_x<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>my_list_y<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        <span class="token comment"># print(x, y)</span>
        <span class="token comment"># 样本x one-hot张量化</span>
        tensor_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> n_letters<span class="token punctuation">)</span>
        <span class="token comment"># 遍历人名 的 每个字母 做成one-hot编码</span>
        <span class="token keyword">for</span> li<span class="token punctuation">,</span> letter <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># letter2indx 使用all_letters.find(letter)查找字母在all_letters表中的位置</span>
            <span class="token comment"># 给one-hot赋值</span>
            tensor_x<span class="token punctuation">[</span>li<span class="token punctuation">]</span><span class="token punctuation">[</span>all_letters<span class="token punctuation">.</span>find<span class="token punctuation">(</span>letter<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
        <span class="token comment"># 样本y 张量化</span>
        tensor_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>categorys<span class="token punctuation">.</span>index<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
        <span class="token comment"># 返回结果</span>
        <span class="token keyword">return</span> tensor_x<span class="token punctuation">,</span> tensor_y
</code></pre> 
<h3><a id="RNN_310"></a>构建三种RNN模型</h3> 
<h4><a id="RNN_311"></a>构建传统RNN</h4> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">RNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>RNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 1 init函数 准备三个层 self.rnn self.linear self.softmax=nn.LogSoftmax(dim=-1)</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>output_size <span class="token operator">=</span> output_size
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers

        <span class="token comment"># 定义rnn层</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">)</span>
        <span class="token comment"># 定义linear层（全连接线性层）</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span>
        <span class="token comment"># 定义softmax层</span>
        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 让数据经过三个层 返回softmax结果和hn</span>
        <span class="token comment"># 数据形状 [6,57] -&gt; [6,1,57]</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 把数据送给模型 提取事物特征</span>
        <span class="token comment"># 数据形状 [seqlen,1,57],[1,1,128]) -&gt; [seqlen,1,18],[1,1,128]</span>
        rr<span class="token punctuation">,</span> hn <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>
        <span class="token comment"># 数据形状 [seqlen,1,128] - [1, 128]</span>
        tmprr <span class="token operator">=</span> rr<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        tmprr <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>tmprr<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>tmprr<span class="token punctuation">)</span><span class="token punctuation">,</span> hn

    <span class="token keyword">def</span> <span class="token function">inithidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 初始化隐藏层输入数据 inithidden()</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="LSTM_348"></a>构建LSTM</h4> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">LSTM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LSTM<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 1 init函数 准备三个层 self.rnn self.linear self.softmax=nn.LogSoftmax(dim=-1)</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>output_size <span class="token operator">=</span> output_size
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers

        <span class="token comment"># 定义rnn层</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">)</span>

        <span class="token comment"># 定义linear层</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span>

        <span class="token comment"># 定义softmax层</span>
        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 让数据经过三个层 返回softmax结果和 hn c</span>
        <span class="token comment"># 数据形状 [6,57] -&gt; [6,1,52]</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 把数据送给模型 提取事物特征</span>
        <span class="token comment"># 数据形状 [seqlen,1,57],[1,1,128], [1,1,128]) -&gt; [seqlen,1,18],[1,1,128],[1,1,128]</span>
        rr<span class="token punctuation">,</span> <span class="token punctuation">(</span>hn<span class="token punctuation">,</span> c<span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>hidden<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 数据形状 [seqlen,1,128] - [1, 128]</span>
        tmprr <span class="token operator">=</span> rr<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

        tmprr <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>tmprr<span class="token punctuation">)</span>

        <span class="token keyword">return</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>tmprr<span class="token punctuation">)</span><span class="token punctuation">,</span> hn<span class="token punctuation">,</span> c

    <span class="token keyword">def</span> <span class="token function">inithidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 初始化隐藏层输入数据 inithidden()</span>
        hidden <span class="token operator">=</span> c <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>
        <span class="token keyword">return</span> hidden<span class="token punctuation">,</span> c
</code></pre> 
<h4><a id="GRU_390"></a>构建GRU</h4> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">GRU</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GRU<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 1 init函数 准备三个层 self.rnn self.linear self.softmax=nn.LogSoftmax(dim=-1)</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>output_size <span class="token operator">=</span> output_size
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers

        <span class="token comment"># 定义rnn层</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">)</span>
        <span class="token comment"># 定义linear层</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span>
        <span class="token comment"># 定义softmax层</span>
        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 让数据经过三个层 返回softmax结果和hn</span>
        <span class="token comment"># 数据形状 [6,57] -&gt; [6,1,52]</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 把数据送给模型 提取事物特征</span>
        <span class="token comment"># 数据形状 [seqlen,1,57],[1,1,128]) -&gt; [seqlen,1,18],[1,1,128]</span>
        rr<span class="token punctuation">,</span> hn <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>
        <span class="token comment"># 数据形状 [seqlen,1,128] - [1, 128]</span>
        tmprr <span class="token operator">=</span> rr<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        tmprr <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>tmprr<span class="token punctuation">)</span>
        <span class="token comment"># 多分类softmax 二分类sigmoid</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>tmprr<span class="token punctuation">)</span><span class="token punctuation">,</span> hn

    <span class="token keyword">def</span> <span class="token function">inithidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 初始化隐藏层输入数据 inithidden()</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_426"></a>对三个模型进行测试与训练</h3> 
<h4><a id="_427"></a>测试</h4> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">dm_test_rnn_lstm_gru</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># one-hot编码特征57（n_letters），也是RNN的输入尺寸</span>
    input_size <span class="token operator">=</span> <span class="token number">57</span>

    <span class="token comment"># 定义隐层的最后一维尺寸大小</span>
    n_hidden <span class="token operator">=</span> <span class="token number">128</span>
    <span class="token comment"># 输出尺寸为语言类别总数n_categories # 1个字符预测成18个类别</span>
    output_size <span class="token operator">=</span> <span class="token number">18</span>
    <span class="token comment"># 1 获取数据</span>
    myfilename <span class="token operator">=</span> <span class="token string">'../data/name_classfication.txt'</span>
    my_list_x<span class="token punctuation">,</span> my_list_y <span class="token operator">=</span> read_data<span class="token punctuation">(</span>myfilename<span class="token punctuation">)</span>
    <span class="token comment"># 2 实例化dataset对象</span>
    nameclassdataset <span class="token operator">=</span> NameClassDataset<span class="token punctuation">(</span>my_list_x<span class="token punctuation">,</span> my_list_y<span class="token punctuation">)</span>
    <span class="token comment"># 3 实例化dataloader</span>
    mydataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>nameclassdataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    my_rnn <span class="token operator">=</span> RNN<span class="token punctuation">(</span>n_letters<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> categorynum<span class="token punctuation">)</span>
    my_lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>n_letters<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> categorynum<span class="token punctuation">)</span>
    my_gru <span class="token operator">=</span> GRU<span class="token punctuation">(</span>n_letters<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> categorynum<span class="token punctuation">)</span>


    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mydataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print('x.shape', x.shape, x)</span>
        <span class="token comment"># print('y.shape', y.shape, y)</span>
        <span class="token comment"># 初始化一个三维的隐层0张量, 也是初始的细胞状态张量</span>
        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> my_rnn<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"rnn output.shape---&gt;:"</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> output<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">break</span>

    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mydataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print('x.shape', x.shape, x)</span>
        <span class="token comment"># print('y.shape', y.shape, y)</span>
        hidden<span class="token punctuation">,</span> c <span class="token operator">=</span> my_lstm<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span>
        output<span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> c <span class="token operator">=</span> my_lstm<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> c<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"lstm output.shape---&gt;:"</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> output<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">break</span>

    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mydataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print('x.shape', x.shape, x)</span>
        <span class="token comment"># print('y.shape', y.shape, y)</span>
        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> my_gru<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> my_gru<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"gru output.shape---&gt;:"</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> output<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">break</span>
</code></pre> 
<h4><a id="_477"></a>训练</h4> 
<h5><a id="RNN_478"></a>传统RNN</h5> 
<pre><code class="prism language-python"><span class="token comment"># 模型训练参数</span>
mylr <span class="token operator">=</span> <span class="token number">1e-3</span>
epochs <span class="token operator">=</span> <span class="token number">1</span>

<span class="token keyword">def</span> <span class="token function">my_train_rnn</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># 获取数据</span>
    myfilename <span class="token operator">=</span> <span class="token string">'./data/name_classfication.txt'</span>
    my_list_x<span class="token punctuation">,</span> my_list_y <span class="token operator">=</span> read_data<span class="token punctuation">(</span>myfilename<span class="token punctuation">)</span>

    <span class="token comment"># 实例化dataset对象</span>
    nameclassdataset <span class="token operator">=</span> NameClassDataset<span class="token punctuation">(</span>my_list_x<span class="token punctuation">,</span> my_list_y<span class="token punctuation">)</span>

    <span class="token comment"># 实例化 模型</span>
    input_size <span class="token operator">=</span> <span class="token number">57</span>
    n_hidden <span class="token operator">=</span> <span class="token number">128</span>
    output_size <span class="token operator">=</span> <span class="token number">18</span>
    my_rnn <span class="token operator">=</span> RNN<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'my_rnn模型---&gt;'</span><span class="token punctuation">,</span> my_rnn<span class="token punctuation">)</span>

    <span class="token comment"># 实例化 损失函数 adam优化器</span>
    mycrossentropyloss <span class="token operator">=</span> nn<span class="token punctuation">.</span>NLLLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    myadam <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>my_rnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>mylr<span class="token punctuation">)</span>

    <span class="token comment"># 定义模型训练参数</span>
    starttime <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    total_iter_num <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 已训练的样本数</span>
    total_loss <span class="token operator">=</span> <span class="token number">0.0</span>  <span class="token comment"># 已训练的损失和</span>
    total_loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 每100个样本求一次平均损失 形成损失列表</span>
    total_acc_num <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 已训练样本预测准确总数</span>
    total_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 每100个样本求一次平均准确率 形成平均准确率列表</span>

    <span class="token comment"># 外层for循环 控制轮数</span>
    <span class="token keyword">for</span> epoch_idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 实例化dataloader</span>
        mydataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>nameclassdataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token comment"># 内层for循环 控制迭代次数</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mydataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 给模型喂数据</span>
            output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> my_rnn<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># 计算损失</span>
            myloss <span class="token operator">=</span> mycrossentropyloss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

            <span class="token comment"># 梯度清零</span>
            myadam<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 反向传播</span>
            myloss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 梯度更新</span>
            myadam<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 计算总损失</span>
            total_iter_num <span class="token operator">=</span> total_iter_num <span class="token operator">+</span> <span class="token number">1</span>
            total_loss <span class="token operator">=</span> total_loss <span class="token operator">+</span> myloss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 计算总准确率</span>
            i_predit_tag <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>
            total_acc_num <span class="token operator">=</span> total_acc_num <span class="token operator">+</span> i_predit_tag

            <span class="token comment"># 每100次训练 求一次平均损失 平均准确率</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>total_iter_num <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                tmploss <span class="token operator">=</span> total_loss<span class="token operator">/</span>total_iter_num
                total_loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmploss<span class="token punctuation">)</span>

                tmpacc <span class="token operator">=</span> total_acc_num<span class="token operator">/</span>total_iter_num
                total_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmpacc<span class="token punctuation">)</span>

            <span class="token comment"># 每2000次训练 打印日志</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>total_iter_num <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                tmploss <span class="token operator">=</span> total_loss <span class="token operator">/</span> total_iter_num
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'轮次:%d, 损失:%.6f, 时间:%d，准确率:%.3f'</span> <span class="token operator">%</span><span class="token punctuation">(</span>epoch_idx<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> tmploss<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> starttime<span class="token punctuation">,</span> tmpacc<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 每个轮次保存模型</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>my_rnn<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'./my_rnn_model_%d.bin'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch_idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 计算总时间</span>
    total_time <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> starttime<span class="token punctuation">)</span>

    <span class="token keyword">return</span> total_loss_list<span class="token punctuation">,</span> total_time<span class="token punctuation">,</span> total_acc_list
</code></pre> 
<h5><a id="LSTM_566"></a>LSTM</h5> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">my_train_lstm</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># 获取数据</span>
    myfilename <span class="token operator">=</span> <span class="token string">'./data/name_classfication.txt'</span>
    my_list_x<span class="token punctuation">,</span> my_list_y <span class="token operator">=</span> read_data<span class="token punctuation">(</span>myfilename<span class="token punctuation">)</span>

    <span class="token comment"># 实例化dataset对象</span>
    nameclassdataset <span class="token operator">=</span> NameClassDataset<span class="token punctuation">(</span>my_list_x<span class="token punctuation">,</span> my_list_y<span class="token punctuation">)</span>

    <span class="token comment"># 实例化 模型</span>
    input_size <span class="token operator">=</span> <span class="token number">57</span>
    n_hidden <span class="token operator">=</span> <span class="token number">128</span>
    output_size <span class="token operator">=</span> <span class="token number">18</span>
    my_lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'my_lstm模型---&gt;'</span><span class="token punctuation">,</span> my_lstm<span class="token punctuation">)</span>

    <span class="token comment"># 实例化 损失函数 adam优化器</span>
    mycrossentropyloss <span class="token operator">=</span> nn<span class="token punctuation">.</span>NLLLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    myadam <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>my_lstm<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>mylr<span class="token punctuation">)</span>

    <span class="token comment"># 定义模型训练参数</span>
    starttime <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    total_iter_num <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 已训练的样本数</span>
    total_loss <span class="token operator">=</span> <span class="token number">0.0</span>  <span class="token comment"># 已训练的损失和</span>
    total_loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 每100个样本求一次平均损失 形成损失列表</span>
    total_acc_num <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 已训练样本预测准确总数</span>
    total_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 每100个样本求一次平均准确率 形成平均准确率列表</span>

    <span class="token comment"># 外层for循环 控制轮数</span>
    <span class="token keyword">for</span> epoch_idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 实例化dataloader</span>
        mydataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>nameclassdataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token comment"># 内层for循环 控制迭代次数</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mydataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 给模型喂数据</span>
            hidden<span class="token punctuation">,</span> c <span class="token operator">=</span> my_lstm<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span>
            output<span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> c <span class="token operator">=</span> my_lstm<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> c<span class="token punctuation">)</span>

            <span class="token comment"># 计算损失</span>
            myloss <span class="token operator">=</span> mycrossentropyloss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

            <span class="token comment"># 梯度清零</span>
            myadam<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 反向传播</span>
            myloss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 梯度更新</span>
            myadam<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 计算总损失</span>
            total_iter_num <span class="token operator">=</span> total_iter_num <span class="token operator">+</span> <span class="token number">1</span>
            total_loss <span class="token operator">=</span> total_loss <span class="token operator">+</span> myloss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 计算总准确率</span>
            i_predit_tag <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>
            total_acc_num <span class="token operator">=</span> total_acc_num <span class="token operator">+</span> i_predit_tag

            <span class="token comment"># 每100次训练 求一次平均损失 平均准确率</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>total_iter_num <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                tmploss <span class="token operator">=</span> total_loss<span class="token operator">/</span>total_iter_num
                total_loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmploss<span class="token punctuation">)</span>

                tmpacc <span class="token operator">=</span> total_acc_num<span class="token operator">/</span>total_iter_num
                total_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmpacc<span class="token punctuation">)</span>

            <span class="token comment"># 每2000次训练 打印日志</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>total_iter_num <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                tmploss <span class="token operator">=</span> total_loss <span class="token operator">/</span> total_iter_num
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'轮次:%d, 损失:%.6f, 时间:%d，准确率:%.3f'</span> <span class="token operator">%</span><span class="token punctuation">(</span>epoch_idx<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> tmploss<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> starttime<span class="token punctuation">,</span> tmpacc<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 每个轮次保存模型</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>my_lstm<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'./my_lstm_model_%d.bin'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch_idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 计算总时间</span>
    total_time <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> starttime<span class="token punctuation">)</span>

    <span class="token keyword">return</span> total_loss_list<span class="token punctuation">,</span> total_time<span class="token punctuation">,</span> total_acc_list
</code></pre> 
<h5><a id="GRU_651"></a>GRU</h5> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">my_train_gru</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># 获取数据</span>
    myfilename <span class="token operator">=</span> <span class="token string">'./data/name_classfication.txt'</span>
    my_list_x<span class="token punctuation">,</span> my_list_y <span class="token operator">=</span> read_data<span class="token punctuation">(</span>myfilename<span class="token punctuation">)</span>

    <span class="token comment"># 实例化dataset对象</span>
    nameclassdataset <span class="token operator">=</span> NameClassDataset<span class="token punctuation">(</span>my_list_x<span class="token punctuation">,</span> my_list_y<span class="token punctuation">)</span>

    <span class="token comment"># 实例化 模型</span>
    input_size <span class="token operator">=</span> <span class="token number">57</span>
    n_hidden <span class="token operator">=</span> <span class="token number">128</span>
    output_size <span class="token operator">=</span> <span class="token number">18</span>
    my_gru <span class="token operator">=</span> GRU<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'my_gru模型---&gt;'</span><span class="token punctuation">,</span> my_gru<span class="token punctuation">)</span>

    <span class="token comment"># 实例化 损失函数 adam优化器</span>
    mycrossentropyloss <span class="token operator">=</span> nn<span class="token punctuation">.</span>NLLLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    myadam <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>my_gru<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>mylr<span class="token punctuation">)</span>

    <span class="token comment"># 定义模型训练参数</span>
    starttime <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    total_iter_num <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 已训练的样本数</span>
    total_loss <span class="token operator">=</span> <span class="token number">0.0</span>  <span class="token comment"># 已训练的损失和</span>
    total_loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 每100个样本求一次平均损失 形成损失列表</span>
    total_acc_num <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 已训练样本预测准确总数</span>
    total_acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 每100个样本求一次平均准确率 形成平均准确率列表</span>

    <span class="token comment"># 外层for循环 控制轮数</span>
    <span class="token keyword">for</span> epoch_idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 实例化dataloader</span>
        mydataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>nameclassdataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token comment"># 内层for循环 控制迭代次数</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mydataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 给模型喂数据</span>
            output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> my_gru<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> my_gru<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># 计算损失</span>
            myloss <span class="token operator">=</span> mycrossentropyloss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

            <span class="token comment"># 梯度清零</span>
            myadam<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 反向传播</span>
            myloss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 梯度更新</span>
            myadam<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 计算总损失</span>
            total_iter_num <span class="token operator">=</span> total_iter_num <span class="token operator">+</span> <span class="token number">1</span>
            total_loss <span class="token operator">=</span> total_loss <span class="token operator">+</span> myloss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 计算总准确率</span>
            i_predit_tag <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token number">0</span><span class="token punctuation">)</span>
            total_acc_num <span class="token operator">=</span> total_acc_num <span class="token operator">+</span> i_predit_tag

            <span class="token comment"># 每100次训练 求一次平均损失 平均准确率</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>total_iter_num <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                tmploss <span class="token operator">=</span> total_loss<span class="token operator">/</span>total_iter_num
                total_loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmploss<span class="token punctuation">)</span>

                tmpacc <span class="token operator">=</span> total_acc_num<span class="token operator">/</span>total_iter_num
                total_acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmpacc<span class="token punctuation">)</span>

            <span class="token comment"># 每2000次训练 打印日志</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>total_iter_num <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                tmploss <span class="token operator">=</span> total_loss <span class="token operator">/</span> total_iter_num
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'轮次:%d, 损失:%.6f, 时间:%d，准确率:%.3f'</span> <span class="token operator">%</span><span class="token punctuation">(</span>epoch_idx<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> tmploss<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> starttime<span class="token punctuation">,</span> tmpacc<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 每个轮次保存模型</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>my_gru<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'./my_gru_model_%d.bin'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch_idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 计算总时间</span>
    total_time <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> starttime<span class="token punctuation">)</span>

    <span class="token keyword">return</span> total_loss_list<span class="token punctuation">,</span> total_time<span class="token punctuation">,</span> total_acc_list
</code></pre> 
<h3><a id="_734"></a>进行预测</h3> 
<h4><a id="_735"></a>构建预测函数</h4> 
<pre><code class="prism language-python"><span class="token comment"># 1 构建传统RNN预测函数</span>
my_path_rnn <span class="token operator">=</span> <span class="token string">'./model/my_rnn_model_1.bin'</span>
my_path_lstm <span class="token operator">=</span> <span class="token string">'./model/my_lstm_model_1.bin'</span>
my_path_gru <span class="token operator">=</span> <span class="token string">'./model/my_gru_model_1.bin'</span>

<span class="token comment"># 将人名转化为onehot张量</span>
<span class="token comment"># eg 'bai' --&gt; [3,57]</span>
<span class="token keyword">def</span> <span class="token function">lineToTensor</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 文本张量化x</span>
    tensor_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> n_letters<span class="token punctuation">)</span>
    <span class="token comment"># 遍历这个人名中的每个字符索引和字符</span>
    <span class="token keyword">for</span> li<span class="token punctuation">,</span> letter <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># letter在字符串all_letters中的位置 就是onehot张量1索引的位置</span>
        <span class="token comment"># letter在字符串all_letters中的位置 使用字符串find()方法获取</span>
        tensor_x<span class="token punctuation">[</span>li<span class="token punctuation">]</span><span class="token punctuation">[</span>all_letters<span class="token punctuation">.</span>find<span class="token punctuation">(</span>letter<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> tensor_x
</code></pre> 
<h5><a id="RNN_756"></a>传统RNN</h5> 
<pre><code class="prism language-python"><span class="token comment"># 思路分析</span>
<span class="token comment"># 1 输入文本数据 张量化one-hot</span>
<span class="token comment"># 2 实例化模型 加载已训练模型参数 m.load_state_dict(torch.load(my_path_rnn))</span>
<span class="token comment"># 3 模型预测 with torch.no_grad()</span>
<span class="token comment"># 4 从预测结果中取出前3名,显示打印结果 output.topk(3, 1, True)</span>
<span class="token comment">#   category_idx = topi[0][i] category = categorys[category_idx]</span>

<span class="token comment"># 构建rnn预测函数</span>
<span class="token keyword">def</span> <span class="token function">my_predict_rnn</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    n_letters <span class="token operator">=</span> <span class="token number">57</span>
    n_hidden <span class="token operator">=</span> <span class="token number">128</span>
    n_categories <span class="token operator">=</span> <span class="token number">18</span>


    <span class="token comment"># 输入文本, 张量化one-hot</span>
    x_tensor <span class="token operator">=</span> lineToTensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    <span class="token comment"># 实例化模型 加载已训练模型参数</span>
    my_rnn <span class="token operator">=</span> RNN<span class="token punctuation">(</span>n_letters<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> n_categories<span class="token punctuation">)</span>
    my_rnn<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>my_path_rnn<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 模型预测</span>
        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> my_rnn<span class="token punctuation">(</span>x_tensor<span class="token punctuation">,</span> my_rnn<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 从预测结果中取出前3名</span>
        <span class="token comment"># 3表示取前3名, 1表示要排序的维度, True表示是否返回最大或是最下的元素</span>
        topv<span class="token punctuation">,</span> topi <span class="token operator">=</span> output<span class="token punctuation">.</span>topk<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'rnn =&gt;'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            value <span class="token operator">=</span> topv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            category_idx <span class="token operator">=</span> topi<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            category <span class="token operator">=</span> categorys<span class="token punctuation">[</span>category_idx<span class="token punctuation">]</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\t value:%d  category:%s'</span> <span class="token operator">%</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> category<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="LSTM_797"></a>LSTM</h5> 
<pre><code class="prism language-python"><span class="token comment"># 构建LSTM 预测函数</span>
<span class="token keyword">def</span> <span class="token function">my_predict_lstm</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    n_letters <span class="token operator">=</span> <span class="token number">57</span>
    n_hidden <span class="token operator">=</span> <span class="token number">128</span>
    n_categories <span class="token operator">=</span> <span class="token number">18</span>

    <span class="token comment"># 输入文本, 张量化one-hot</span>
    x_tensor <span class="token operator">=</span> lineToTensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    <span class="token comment"># 实例化模型 加载已训练模型参数</span>
    my_lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>n_letters<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> n_categories<span class="token punctuation">)</span>
    my_lstm<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>my_path_lstm<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 模型预测</span>
        hidden<span class="token punctuation">,</span> c <span class="token operator">=</span> my_lstm<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span>
        output<span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> c <span class="token operator">=</span> my_lstm<span class="token punctuation">(</span>x_tensor<span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> c<span class="token punctuation">)</span>

        <span class="token comment"># 从预测结果中取出前3名</span>
        <span class="token comment"># 3表示取前3名, 1表示要排序的维度, True表示是否返回最大或是最下的元素</span>
        topv<span class="token punctuation">,</span> topi <span class="token operator">=</span> output<span class="token punctuation">.</span>topk<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'rnn =&gt;'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            value <span class="token operator">=</span> topv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            category_idx <span class="token operator">=</span> topi<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            category <span class="token operator">=</span> categorys<span class="token punctuation">[</span>category_idx<span class="token punctuation">]</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\t value:%d  category:%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>value<span class="token punctuation">,</span> category<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\t value:%d  category:%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>value<span class="token punctuation">,</span> category<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="GRU_832"></a>GRU</h5> 
<pre><code class="prism language-python"><span class="token comment"># 构建GRU 预测函数</span>
<span class="token keyword">def</span> <span class="token function">my_predict_gru</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>

    n_letters <span class="token operator">=</span> <span class="token number">57</span>
    n_hidden <span class="token operator">=</span> <span class="token number">128</span>
    n_categories <span class="token operator">=</span> <span class="token number">18</span>

    <span class="token comment"># 输入文本, 张量化one-hot</span>
    x_tensor <span class="token operator">=</span> lineToTensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    <span class="token comment"># 实例化模型 加载已训练模型参数</span>
    my_gru <span class="token operator">=</span> GRU<span class="token punctuation">(</span>n_letters<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> n_categories<span class="token punctuation">)</span>
    my_gru<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>my_path_gru<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 模型预测</span>
        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> my_gru<span class="token punctuation">(</span>x_tensor<span class="token punctuation">,</span> my_gru<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 从预测结果中取出前3名</span>
        <span class="token comment"># 3表示取前3名, 1表示要排序的维度, True表示是否返回最大或是最下的元素</span>
        topv<span class="token punctuation">,</span> topi <span class="token operator">=</span> output<span class="token punctuation">.</span>topk<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'rnn =&gt;'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            value <span class="token operator">=</span> topv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            category_idx <span class="token operator">=</span> topi<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            category <span class="token operator">=</span> categorys<span class="token punctuation">[</span>category_idx<span class="token punctuation">]</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\t value:%d  category:%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>value<span class="token punctuation">,</span> category<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="_864"></a>调用</h5> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">dm_test_predic_rnn_lstm_gru</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 把三个函数的入口地址 组成列表，统一输入数据进行测试</span>
    <span class="token keyword">for</span> func <span class="token keyword">in</span> <span class="token punctuation">[</span>my_predict_rnn<span class="token punctuation">,</span> my_predict_lstm<span class="token punctuation">,</span> my_predict_gru<span class="token punctuation">]</span><span class="token punctuation">:</span>
        func<span class="token punctuation">(</span><span class="token string">'zhang'</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="_872"></a>注意力机制</h2> 
<h3><a id="_873"></a>注意力机制简介</h3> 
<h4><a id="_874"></a>注意力概念</h4> 
<p>我们观察事物时，之所以能够快速判断一种事物(当然允许判断是错误的), 是因为我们大脑能够很快把注意力放在事物最具有辨识度的部分从而作出判断，而并非是从头到尾的观察一遍事物后，才能有判断结果. 正是基于这样的理论，就产生了注意力机制.</p> 
<h4><a id="_876"></a>注意力计算规则</h4> 
<p>它需要三个指定的输入Q(query), K(key), V(value), 然后通过计算公式得到注意力的结果, 这个结果代表query在key和value作用下的注意力表示. 当输入的Q=K=V时, 称作自注意力计算规则.</p> 
<h4><a id="_878"></a>作用</h4> 
<p>在解码器端的注意力机制: 能够根据模型目标有效的聚焦编码器的输出结果, 当其作为解码器的输入时提升效果. 改善以往编码器输出是单一定长张量, 无法存储过多信息的情况.<br> 在编码器端的注意力机制: 主要解决表征问题, 相当于特征提取过程, 得到输入的注意力表示. 一般使用自注意力(self-attention).</p> 
<h4><a id="_881"></a>生活场景帮助理解</h4> 
<p>我们做英语的阅读理解时，4个选项只有1个是对的，其余都是干扰项。注意力机制就是把焦点集中在正确选项的获取上。</p> 
<h3><a id="bmm_883"></a>bmm运算简介</h3> 
<pre><code class="prism language-python"><span class="token comment"># 如果参数1形状是(b × n × m), 参数2形状是(b × m × p), 则输出为(b × n × p)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> mat2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> res <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> mat2<span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> res<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_894"></a>代码实现</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token comment"># MyAtt类实现思路分析</span>
<span class="token comment"># 1 init函数 (self, query_size, key_size, value_size1, value_size2, output_size)</span>
<span class="token comment"># 准备2个线性层 注意力权重分布self.attn 注意力结果表示按照指定维度进行输出层 self.attn_combine</span>
<span class="token comment"># 2 forward(self, Q, K, V):</span>
<span class="token comment"># 求查询张量q的注意力权重分布, attn_weights[1,32]</span>
<span class="token comment"># 求查询张量q的注意力结果表示 bmm运算, attn_applied[1,1,64]</span>
<span class="token comment"># q 与 attn_applied 融合，再按照指定维度输出 output[1,1,32]</span>
<span class="token comment"># 返回注意力结果表示output:[1,1,32], 注意力权重分布attn_weights:[1,32]</span>

<span class="token keyword">class</span> <span class="token class-name">MyAtt</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#                   32          32          32              64      32</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> value_size1<span class="token punctuation">,</span> value_size2<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MyAtt<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>query_size <span class="token operator">=</span> query_size
        self<span class="token punctuation">.</span>key_size <span class="token operator">=</span> key_size
        self<span class="token punctuation">.</span>value_size1 <span class="token operator">=</span> value_size1
        self<span class="token punctuation">.</span>value_size2 <span class="token operator">=</span> value_size2
        self<span class="token punctuation">.</span>output_size <span class="token operator">=</span> output_size

        <span class="token comment"># 线性层1 注意力权重分布</span>
        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>query_size <span class="token operator">+</span> self<span class="token punctuation">.</span>key_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>value_size1<span class="token punctuation">)</span>

        <span class="token comment"># 线性层2 注意力结果表示按照指定维度输出层 self.attn_combine</span>
        self<span class="token punctuation">.</span>attn_combine <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>query_size<span class="token operator">+</span>self<span class="token punctuation">.</span>value_size2<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> Q<span class="token punctuation">,</span> K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 1 求查询张量q的注意力权重分布, attn_weights[1,32]</span>
        <span class="token comment"># [1,1,32],[1,1,32]--&gt; [1,32],[1,32]-&gt;[1,64]</span>
        <span class="token comment"># [1,64] --&gt; [1,32]</span>
        <span class="token comment"># tmp1 = torch.cat( (Q[0], K[0]), dim=1)</span>
        <span class="token comment"># tmp2 = self.attn(tmp1)</span>
        <span class="token comment"># tmp3 = F.softmax(tmp2, dim=1)</span>
        attn_weights <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span> self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span> <span class="token punctuation">(</span>Q<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> K<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 2 求查询张量q的结果表示 bmm运算, attn_applied[1,1,64]</span>
        <span class="token comment"># [1,1,32] * [1,32,64] ---&gt; [1,1,64]</span>
        attn_applied <span class="token operator">=</span>  torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>attn_weights<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> V<span class="token punctuation">)</span>

        <span class="token comment"># 3 q 与 attn_applied 融合，再按照指定维度输出 output[1,1,64]</span>
        <span class="token comment"># 3-1 q与结果表示拼接 [1,32],[1,64] ---&gt; [1,96]</span>
        output <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>Q<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> attn_applied<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 3-2 shape [1,96] ---&gt; [1,32]</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>attn_combine<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token comment"># 4 返回注意力结果表示output:[1,1,32], 注意力权重分布attn_weights:[1,32]</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span> attn_weights
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment"># 为什么引入注意力机制：</span>
    <span class="token comment"># rnn系列循环神经网络，随着时间步的增长，会对前面单词的特征遗忘，造成对句子特征提取不充分</span>
    <span class="token comment"># rnn系列循环神经网络是一个时间步一个时间步的提取句子特征，效率低下</span>
    <span class="token comment"># 能不能对32个单词同时提取事物特征，而且还是并行的，这就是注意力机制！</span>

    <span class="token comment"># 任务描述</span>
    <span class="token comment"># v是内容比如32个单词每个单词64个特征，k是32个单词的索引，q是查询张量</span>
    <span class="token comment"># 我们的任务：输入查询张量q，通过注意力机制来计算如下信息：</span>
    <span class="token comment"># 1、查询张量q的注意力权重分布：查询张量q和其他32个单词相关性（相识度）</span>
    <span class="token comment"># 2、查询张量q的结果表示：有一个普通的q升级成一个更强大q；用q和v做bmm运算</span>
    <span class="token comment"># 3 注意：查询张量q查询的目标是谁，就是谁的查询张量。</span>
    <span class="token comment">#   eg：比如查询张量q未来就是来查询单词"我"，则q就是"我"的查询张量</span>

    query_size <span class="token operator">=</span> <span class="token number">32</span>
    key_size <span class="token operator">=</span> <span class="token number">32</span>
    value_size1 <span class="token operator">=</span> <span class="token number">32</span> <span class="token comment"># 32个单词</span>
    value_size2 <span class="token operator">=</span> <span class="token number">64</span> <span class="token comment"># 64个特征</span>
    output_size <span class="token operator">=</span> <span class="token number">32</span>

    Q <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
    K <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
    V <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
    <span class="token comment"># V = torch.randn(1, value_size1, value_size2)</span>

    <span class="token comment"># 1 实例化注意力类 对象</span>
    myattobj <span class="token operator">=</span> MyAtt<span class="token punctuation">(</span>query_size<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> value_size1<span class="token punctuation">,</span> value_size2<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>

    <span class="token comment"># 2 把QKV数据扔给注意机制，求查询张量q的注意力结果表示、注意力权重分布</span>
    <span class="token punctuation">(</span>output<span class="token punctuation">,</span> attn_weights<span class="token punctuation">)</span> <span class="token operator">=</span> myattobj<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> K<span class="token punctuation">,</span> V<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'查询张量q的注意力结果表示output---&gt;'</span><span class="token punctuation">,</span> output<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> output<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'查询张量q的注意力权重分布attn_weights---&gt;'</span><span class="token punctuation">,</span> attn_weights<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> attn_weights<span class="token punctuation">)</span>
</code></pre> 
<h2><a id="RNN_seq2seq_985"></a>RNN案例 seq2seq英译法</h2> 
<h3><a id="seq2seq_986"></a>seq2seq介绍</h3> 
<h4><a id="seq2seq_987"></a>seq2seq模型架构</h4> 
<p><img src="https://images2.imgbox.com/95/63/DNzQiOet_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_989"></a>模型解释</h4> 
<p>seq2seq模型架构包括三部分，分别是encoder(编码器)、decoder(解码器)、中间语义张量c。其中编码器和解码器的内部实现都使用了GRU模型<br> 图中表示的是一个中文到英文的翻译：欢迎 来 北京 → welcome to BeiJing。编码器首先处理中文输入"欢迎 来 北京"，通过GRU模型获得每个时间步的输出张量，最后将它们拼接成一个中间语义张量c；接着解码器将使用这个中间语义张量c以及每一个时间步的隐层张量, 逐个生成对应的翻译语言</p> 
<h3><a id="_992"></a>数据集下载</h3> 
<p><a href="https://github.com/GodOn514/dataset_download">eng_transfor_fra下载</a></p> 
<h3><a id="_994"></a>导包并进行文件清洗</h3> 
<pre><code class="prism language-python"><span class="token comment"># 用于正则表达式</span>
<span class="token keyword">import</span> re
<span class="token comment"># 用于构建网络结构和函数的torch工具包</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader
<span class="token comment"># torch中预定义的优化方法工具包</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> time
<span class="token comment"># 用于随机生成数据</span>
<span class="token keyword">import</span> random
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 设备选择, 我们可以选择在cuda或者cpu上运行你的代码</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
<span class="token comment"># 起始标志</span>
SOS_token <span class="token operator">=</span> <span class="token number">0</span>
<span class="token comment"># 结束标志</span>
EOS_token <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment"># 最大句子长度不能超过10个 (包含标点)</span>
MAX_LENGTH <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment"># 数据文件路径</span>
data_path <span class="token operator">=</span> <span class="token string">'../data/eng-fra-v2.txt'</span>

<span class="token comment"># 文本清洗工具函数</span>
<span class="token keyword">def</span> <span class="token function">normalizeString</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""字符串规范化函数, 参数s代表传入的字符串"""</span>
    s <span class="token operator">=</span> s<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 在.!?前加一个空格  这里的\1表示第一个分组   正则中的\num</span>
    s <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"([.!?])"</span><span class="token punctuation">,</span> <span class="token string">r" \1"</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>
    <span class="token comment"># s = re.sub(r"([.!?])", r" ", s)</span>
    <span class="token comment"># 使用正则表达式将字符串中 不是 大小写字母和正常标点的都替换成空格</span>
    s <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"[^a-zA-Z.!?]+"</span><span class="token punctuation">,</span> <span class="token string">r" "</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>
    <span class="token keyword">return</span> s
</code></pre> 
<h3><a id="_1033"></a>思路分析</h3> 
<pre><code class="prism language-python">my_getdata<span class="token punctuation">(</span><span class="token punctuation">)</span> 清洗文本构建字典思路分析
<span class="token number">1</span> 按行读文件 <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span>\n<span class="token punctuation">)</span> my_lines
<span class="token number">2</span> 按行清洗文本 构建语言对 my_pairs
<span class="token number">2</span><span class="token operator">-</span><span class="token number">1</span>格式 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'英文'</span><span class="token punctuation">,</span> <span class="token string">'法文'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'英文'</span><span class="token punctuation">,</span> <span class="token string">'法文'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'英文'</span><span class="token punctuation">,</span> <span class="token string">'法文'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'英文'</span><span class="token punctuation">,</span> <span class="token string">'法文'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
<span class="token number">2</span><span class="token operator">-</span><span class="token number">2</span>调用清洗文本工具函数normalizeString<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
<span class="token number">3</span> 遍历语言对 构建英语单词字典 法语单词字典
<span class="token number">3</span><span class="token operator">-</span><span class="token number">1</span> english_word2index english_word_n french_word2index french_word_n
其中 english_word2index <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"SOS"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"EOS"</span><span class="token punctuation">}</span>  english_word_n<span class="token operator">=</span><span class="token number">2</span>
<span class="token number">3</span><span class="token operator">-</span><span class="token number">2</span> english_index2word french_index2word
<span class="token number">4</span> 返回数据的<span class="token number">7</span>个结果
english_word2index<span class="token punctuation">,</span> english_index2word<span class="token punctuation">,</span> english_word_n<span class="token punctuation">,</span>
french_word2index<span class="token punctuation">,</span> french_index2word<span class="token punctuation">,</span> french_word_n<span class="token punctuation">,</span> my_pairs
</code></pre> 
<h3><a id="_1049"></a>数据预处理</h3> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">my_getdata</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># 1 按行读文件 open().read().strip().split(\n)</span>
    my_lines <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
    <span class="token comment"># 2 按行清洗文本 构建语言对 my_pairs</span>
    my_pairs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>normalizeString<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token keyword">for</span> s <span class="token keyword">in</span> l<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> l <span class="token keyword">in</span> my_lines<span class="token punctuation">]</span>

    <span class="token comment"># 3 遍历语言对 构建英语单词字典 法语单词字典</span>
    <span class="token comment"># 3-1 english_word2index english_word_n french_word2index french_word_n</span>
    english_word2index <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"SOS"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"EOS"</span><span class="token punctuation">}</span>
    english_word_n <span class="token operator">=</span> <span class="token number">2</span>

    french_word2index <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"SOS"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"EOS"</span><span class="token punctuation">}</span>
    french_word_n <span class="token operator">=</span> <span class="token number">2</span>

    <span class="token comment"># 遍历语言对 获取英语单词字典 法语单词字典</span>
    <span class="token keyword">for</span> pair <span class="token keyword">in</span> my_pairs<span class="token punctuation">:</span>

        <span class="token keyword">for</span> word <span class="token keyword">in</span> pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> english_word2index<span class="token punctuation">:</span>
                english_word2index<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> english_word_n
                <span class="token comment"># print(english_word2index)</span>
                english_word_n <span class="token operator">+=</span> <span class="token number">1</span>

        <span class="token keyword">for</span> word <span class="token keyword">in</span> pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> french_word2index<span class="token punctuation">:</span>
               french_word2index<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> french_word_n
               french_word_n <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token comment"># 3-2 english_index2word french_index2word</span>
    english_index2word <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>v<span class="token punctuation">:</span>k <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> english_word2index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
    french_index2word <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>v<span class="token punctuation">:</span>k <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> french_word2index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

    <span class="token keyword">return</span> english_word2index<span class="token punctuation">,</span> english_index2word<span class="token punctuation">,</span> english_word_n<span class="token punctuation">,</span>\
           french_word2index<span class="token punctuation">,</span> french_index2word<span class="token punctuation">,</span> french_word_n<span class="token punctuation">,</span> my_pairs


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 全局函数 获取英语单词字典 法语单词字典 语言对列表my_pairs</span>
    english_word2index<span class="token punctuation">,</span> english_index2word<span class="token punctuation">,</span> english_word_n<span class="token punctuation">,</span> \
    french_word2index<span class="token punctuation">,</span> french_index2word<span class="token punctuation">,</span> french_word_n<span class="token punctuation">,</span> \
    my_pairs <span class="token operator">=</span> my_getdata<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> <span class="token number">0</span>
</code></pre> 
<h3><a id="_1096"></a>构建数据源对象并测试</h3> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">MyPairsDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> my_pairs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 样本x</span>
        self<span class="token punctuation">.</span>my_pairs <span class="token operator">=</span> my_pairs
        <span class="token comment"># 样本条目数</span>
        self<span class="token punctuation">.</span>sample_len <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>my_pairs<span class="token punctuation">)</span>

    <span class="token comment"># 获取样本条数</span>
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>sample_len

    <span class="token comment"># 获取第几条 样本数据</span>
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 对index异常值进行修正 [0, self.sample_len-1]</span>
        <span class="token keyword">if</span> index <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            index <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>sample_len<span class="token punctuation">,</span> index<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            index <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>sample_len <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>
        <span class="token comment"># 按索引获取 数据样本 x y</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>my_pairs<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>my_pairs<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token comment"># 样本x 文本数值化</span>
        x <span class="token operator">=</span> <span class="token punctuation">[</span>english_word2index<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token comment"># print(x)</span>
        x<span class="token punctuation">.</span>append<span class="token punctuation">(</span>EOS_token<span class="token punctuation">)</span>
        <span class="token comment"># print("x2: ", x)</span>
        tensor_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
        <span class="token comment"># 样本y 文本数值化</span>
        y <span class="token operator">=</span> <span class="token punctuation">[</span>french_word2index<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> y<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        y<span class="token punctuation">.</span>append<span class="token punctuation">(</span>EOS_token<span class="token punctuation">)</span>
        tensor_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
        <span class="token comment"># 注意 tensor_x tensor_y都是一维数组，通过DataLoader拿出数据是二维数据</span>
        <span class="token comment"># print('tensor_y.shape===&gt;', tensor_y.shape, tensor_y)</span>
        <span class="token comment"># 返回结果</span>
        <span class="token keyword">return</span> tensor_x<span class="token punctuation">,</span> tensor_y


<span class="token keyword">def</span> <span class="token function">dm_test_MyPairsDataset</span><span class="token punctuation">(</span>my_pairs<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># 1 实例化dataset对象</span>
    mypairsdataset <span class="token operator">=</span> MyPairsDataset<span class="token punctuation">(</span>my_pairs<span class="token punctuation">)</span>
    <span class="token comment"># 2 实例化dataloader</span>
    mydataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>mypairsdataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mydataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x.shape'</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y.shape'</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token keyword">break</span>


<span class="token comment"># 全局函数 获取英语单词字典 法语单词字典 语言对列表my_pairs</span>
english_word2index<span class="token punctuation">,</span> english_index2word<span class="token punctuation">,</span> english_word_n<span class="token punctuation">,</span> \
french_word2index<span class="token punctuation">,</span> french_index2word<span class="token punctuation">,</span> french_word_n<span class="token punctuation">,</span> \
my_pairs <span class="token operator">=</span> my_getdata<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    dm_test_MyPairsDataset<span class="token punctuation">(</span>my_pairs<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token number">0</span>
</code></pre> 
<h3><a id="_1160"></a>编码器和解码器</h3> 
<h4><a id="GRU_1161"></a>构建基于GRU的编码器</h4> 
<h5><a id="_1162"></a>思路分析</h5> 
<pre><code class="prism language-python">EncoderRNN类 实现思路分析：
<span class="token number">1</span> init函数 定义<span class="token number">2</span>个层 self<span class="token punctuation">.</span>embedding self<span class="token punctuation">.</span>gru <span class="token punctuation">(</span>batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 2803 256</span>

<span class="token number">2</span> forward<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>函数，返回output<span class="token punctuation">,</span> hidden
  数据经过词嵌入层 数据形状 <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">]</span>
  数据经过gru层 形状变化 gru<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">]</span>

<span class="token number">3</span> 初始化隐藏层输入数据 inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span>
  形状 torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
</code></pre> 
<h5><a id="_1176"></a>代码实现</h5> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">EncoderRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># input_size 编码器 词嵌入层单词数 eg：2803</span>
        <span class="token comment"># hidden_size 编码器 词嵌入层每个单词的特征数 eg 256</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>EncoderRNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size

        <span class="token comment"># 实例化nn.Embedding层</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>

        <span class="token comment"># 实例化nn.GRU层 注意参数batch_first=True</span>
        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 数据经过词嵌入层 数据形状 [1,6] --&gt; [1,6,256]</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>

        <span class="token comment"># 数据经过gru层 数据形状 gru([1,6,256],[1,1,256]) --&gt; [1,6,256] [1,1,256]</span>
        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>output<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden

    <span class="token keyword">def</span> <span class="token function">inithidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将隐层张量初始化成为1x1xself.hidden_size大小的张量</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="GRUAttention_1206"></a>基于GRU和Attention的解码器</h4> 
<h5><a id="_1207"></a>结构图</h5> 
<p><img src="https://images2.imgbox.com/b9/b1/fnZB8GKf_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="_1210"></a>代码实现</h5> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">AttnDecoderRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> dropout_p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span>MAX_LENGTH<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># output_size   编码器 词嵌入层单词数 eg：4345</span>
        <span class="token comment"># hidden_size   编码器 词嵌入层每个单词的特征数 eg 256</span>
        <span class="token comment"># dropout_p     置零比率，默认0.1,</span>
        <span class="token comment"># max_length    最大长度10</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AttnDecoderRNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>output_size <span class="token operator">=</span> output_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>dropout_p <span class="token operator">=</span> dropout_p
        self<span class="token punctuation">.</span>max_length <span class="token operator">=</span> max_length

        <span class="token comment"># 定义nn.Embedding层 nn.Embedding(4345,256)</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>

        <span class="token comment"># 定义线性层1：求q的注意力权重分布</span>
        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_length<span class="token punctuation">)</span>

        <span class="token comment"># 定义线性层2：q+注意力结果表示融合后，在按照指定维度输出</span>
        self<span class="token punctuation">.</span>attn_combine <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>

        <span class="token comment"># 定义dropout层</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout_p<span class="token punctuation">)</span>

        <span class="token comment"># 定义gru层</span>
        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token comment"># 定义out层 解码器按照类别进行输出(256,4345)</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span>

        <span class="token comment"># 实例化softomax层 数值归一化 以便分类</span>
        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> encoder_outputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># input代表q [1,1] 二维数据 hidden代表k [1,1,256] encoder_outputs代表v [10,256]</span>

        <span class="token comment"># 数据经过词嵌入层</span>
        <span class="token comment"># 数据形状 [1,1] --&gt; [1,1,256]</span>
        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>

        <span class="token comment"># 使用dropout进行随机丢弃，防止过拟合</span>
        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>embedded<span class="token punctuation">)</span>

        <span class="token comment"># 1 求查询张量q的注意力权重分布, attn_weights[1,10]</span>
        attn_weights <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>embedded<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 2 求查询张量q的注意力结果表示 bmm运算, attn_applied[1,1,256]</span>
        <span class="token comment"># [1,1,10],[1,10,256] ---&gt; [1,1,256]</span>
        attn_applied <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>attn_weights<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> encoder_outputs<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 3 q 与 attn_applied 融合，再按照指定维度输出 output[1,1,256]</span>
        output <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>embedded<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> attn_applied<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>attn_combine<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token comment"># 查询张量q的注意力结果表示 使用relu激活</span>
        output <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>output<span class="token punctuation">)</span>

        <span class="token comment"># 查询张量经过gru、softmax进行分类结果输出</span>
        <span class="token comment"># 数据形状[1,1,256],[1,1,256] --&gt; [1,1,256], [1,1,256]</span>
        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>output<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>
        <span class="token comment"># 数据形状[1,1,256]-&gt;[1,256]-&gt;[1,4345]</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 返回解码器分类output[1,4345]，最后隐层张量hidden[1,1,256] 注意力权重张量attn_weights[1,10]</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> attn_weights

    <span class="token keyword">def</span> <span class="token function">inithidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将隐层张量初始化成为1x1xself.hidden_size大小的张量</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_1284"></a>训练模型</h3> 
<h4><a id="teacher_forcing_1285"></a>teacher_forcing</h4> 
<p>teacher_forcing是一种用于序列生成任务的训练技巧, 在seq2seq架构中, 根据循环神经网络理论，解码器每次应该使用上一步的结果作为输入的一部分, 但是训练过程中，一旦上一步的结果是错误的，就会导致这种错误被累积，无法达到训练效果, 因此，我们需要一种机制改变上一步出错的情况，由此诞生teacher_forcing</p> 
<h4><a id="_1287"></a>内部迭代训练函数</h4> 
<h5><a id="_1288"></a>设置参数</h5> 
<pre><code class="prism language-python"><span class="token comment"># 模型训练参数</span>
mylr <span class="token operator">=</span> <span class="token number">1e-4</span>
epochs <span class="token operator">=</span> <span class="token number">2</span>
<span class="token comment"># 设置teacher_forcing比率为0.5</span>
teacher_forcing_ratio <span class="token operator">=</span> <span class="token number">0.5</span>
print_interval_num <span class="token operator">=</span> <span class="token number">1000</span>
plot_interval_num <span class="token operator">=</span> <span class="token number">100</span>
</code></pre> 
<h5><a id="_1298"></a>代码实现</h5> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">Train_Iters</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> my_encoderrnn<span class="token punctuation">,</span> my_attndecoderrnn<span class="token punctuation">,</span> myadam_encode<span class="token punctuation">,</span> myadam_decode<span class="token punctuation">,</span> mycrossentropyloss<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># 1 编码 encode_output, encode_hidden = my_encoderrnn(x, encode_hidden)</span>
    encode_hidden <span class="token operator">=</span> my_encoderrnn<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span>
    encode_output<span class="token punctuation">,</span> encode_hidden <span class="token operator">=</span> my_encoderrnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> encode_hidden<span class="token punctuation">)</span> <span class="token comment"># 一次性送数据</span>
    <span class="token comment"># [1,6],[1,1,256] --&gt; [1,6,256],[1,1,256]</span>

    <span class="token comment"># 2 解码参数准备和解码</span>
    <span class="token comment"># 解码参数1 encode_output_c [10,256]</span>
    encode_output_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>MAX_LENGTH<span class="token punctuation">,</span> my_encoderrnn<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
    <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        encode_output_c<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> encode_output_c<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> idx<span class="token punctuation">]</span>

    <span class="token comment"># 解码参数2</span>
    decode_hidden <span class="token operator">=</span> encode_hidden

    <span class="token comment"># 解码参数3</span>
    input_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>SOS_token<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>

    myloss <span class="token operator">=</span> <span class="token number">0.0</span>
    y_len <span class="token operator">=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

    use_teacher_forcing <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token keyword">if</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> teacher_forcing_ratio <span class="token keyword">else</span> <span class="token boolean">False</span>
    <span class="token keyword">if</span> use_teacher_forcing<span class="token punctuation">:</span>
        <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>y_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 数据形状数据形状 [1,1],[1,1,256],[10,256] ---&gt; [1,4345],[1,1,256],[1,10]</span>
            output_y<span class="token punctuation">,</span> decode_hidden<span class="token punctuation">,</span> attn_weight <span class="token operator">=</span> my_attndecoderrnn<span class="token punctuation">(</span>input_y<span class="token punctuation">,</span> decode_hidden<span class="token punctuation">,</span> encode_output_c<span class="token punctuation">)</span>
            target_y <span class="token operator">=</span> y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            myloss <span class="token operator">=</span> myloss <span class="token operator">+</span> mycrossentropyloss<span class="token punctuation">(</span>output_y<span class="token punctuation">,</span> target_y<span class="token punctuation">)</span>
            input_y <span class="token operator">=</span> y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>y_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 数据形状数据形状 [1,1],[1,1,256],[10,256] ---&gt; [1,4345],[1,1,256],[1,10]</span>
            output_y<span class="token punctuation">,</span> decode_hidden<span class="token punctuation">,</span> attn_weight <span class="token operator">=</span> my_attndecoderrnn<span class="token punctuation">(</span>input_y<span class="token punctuation">,</span> decode_hidden<span class="token punctuation">,</span> encode_output_c<span class="token punctuation">)</span>
            target_y <span class="token operator">=</span> y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            myloss <span class="token operator">=</span> myloss <span class="token operator">+</span> mycrossentropyloss<span class="token punctuation">(</span>output_y<span class="token punctuation">,</span> target_y<span class="token punctuation">)</span>

            topv<span class="token punctuation">,</span> topi <span class="token operator">=</span> output_y<span class="token punctuation">.</span>topk<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> topi<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> EOS_token<span class="token punctuation">:</span>
                <span class="token keyword">break</span>
            input_y <span class="token operator">=</span> topi<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 梯度清零</span>
    myadam_encode<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    myadam_decode<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 反向传播</span>
    myloss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 梯度更新</span>
    myadam_encode<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    myadam_decode<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 返回 损失列表myloss.item()/y_len</span>
    <span class="token keyword">return</span> myloss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> y_len
</code></pre> 
<h4><a id="_1357"></a>训练</h4> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">Train_seq2seq</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># 实例化 mypairsdataset对象  实例化 mydataloader</span>
    mypairsdataset <span class="token operator">=</span> MyPairsDataset<span class="token punctuation">(</span>my_pairs<span class="token punctuation">)</span>
    mydataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>mypairsdataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># 实例化编码器 my_encoderrnn 实例化解码器 my_attndecoderrnn</span>
    my_encoderrnn <span class="token operator">=</span> EncoderRNN<span class="token punctuation">(</span><span class="token number">2803</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
    my_attndecoderrnn <span class="token operator">=</span> AttnDecoderRNN<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token number">4345</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> dropout_p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token comment"># 实例化编码器优化器 myadam_encode 实例化解码器优化器 myadam_decode</span>
    myadam_encode <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>my_encoderrnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>mylr<span class="token punctuation">)</span>
    myadam_decode <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>my_attndecoderrnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>mylr<span class="token punctuation">)</span>

    <span class="token comment"># 实例化损失函数 mycrossentropyloss = nn.NLLLoss()</span>
    mycrossentropyloss <span class="token operator">=</span> nn<span class="token punctuation">.</span>NLLLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 定义模型训练的参数</span>
    plot_loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token comment"># 外层for循环 控制轮数 for epoch_idx in range(1, 1+epochs):</span>
    <span class="token keyword">for</span> epoch_idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">+</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>

        print_loss_total<span class="token punctuation">,</span> plot_loss_total <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span>
        starttime <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 内层for循环 控制迭代次数</span>
        <span class="token keyword">for</span> item<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mydataloader<span class="token punctuation">,</span> start<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 调用内部训练函数</span>
            myloss <span class="token operator">=</span> Train_Iters<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> my_encoderrnn<span class="token punctuation">,</span> my_attndecoderrnn<span class="token punctuation">,</span> myadam_encode<span class="token punctuation">,</span> myadam_decode<span class="token punctuation">,</span> mycrossentropyloss<span class="token punctuation">)</span>
            print_loss_total <span class="token operator">+=</span> myloss
            plot_loss_total <span class="token operator">+=</span> myloss

            <span class="token comment"># 计算打印屏幕间隔损失-每隔1000次</span>
            <span class="token keyword">if</span> item <span class="token operator">%</span> print_interval_num <span class="token operator">==</span><span class="token number">0</span> <span class="token punctuation">:</span>
                print_loss_avg <span class="token operator">=</span> print_loss_total <span class="token operator">/</span> print_interval_num
                <span class="token comment"># 将总损失归0</span>
                print_loss_total <span class="token operator">=</span> <span class="token number">0</span>
                <span class="token comment"># 打印日志，日志内容分别是：训练耗时，当前迭代步，当前进度百分比，当前平均损失</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'轮次%d  损失%.6f 时间:%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch_idx<span class="token punctuation">,</span> print_loss_avg<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> starttime<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># 计算画图间隔损失-每隔100次</span>
            <span class="token keyword">if</span> item <span class="token operator">%</span> plot_interval_num <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token comment"># 通过总损失除以间隔得到平均损失</span>
                plot_loss_avg <span class="token operator">=</span> plot_loss_total <span class="token operator">/</span> plot_interval_num
                <span class="token comment"># 将平均损失添加plot_loss_list列表中</span>
                plot_loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>plot_loss_avg<span class="token punctuation">)</span>
                <span class="token comment"># 总损失归0</span>
                plot_loss_total <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token comment"># 每个轮次保存模型</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>my_encoderrnn<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'./my_encoderrnn_%d.pth'</span> <span class="token operator">%</span> epoch_idx<span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>my_attndecoderrnn<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'./my_attndecoderrnn_%d.pth'</span> <span class="token operator">%</span> epoch_idx<span class="token punctuation">)</span>

    <span class="token comment"># 所有轮次训练完毕 画损失图</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>plot_loss_list<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'./s2sq_loss.png'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> plot_loss_list
</code></pre> 
<h3><a id="_1422"></a>模型评估与测试</h3> 
<h4><a id="_1423"></a>评估函数书写</h4> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">Seq2Seq_Evaluate</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> my_encoderrnn<span class="token punctuation">,</span> my_attndecoderrnn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    模型评估代码与模型预测代码类似，需要注意使用with torch.no_grad()
    模型预测时，第一个时间步使用SOS_token作为输入 后续时间步采用预测值作为输入，也就是自回归机制
    """</span><span class="token string">""</span>"
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 1 编码：一次性的送数据</span>
        encode_hidden <span class="token operator">=</span> my_encoderrnn<span class="token punctuation">.</span>inithidden<span class="token punctuation">(</span><span class="token punctuation">)</span>
        encode_output<span class="token punctuation">,</span> encode_hidden <span class="token operator">=</span> my_encoderrnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> encode_hidden<span class="token punctuation">)</span>

        <span class="token comment"># 2 解码参数准备</span>
        <span class="token comment"># 解码参数1 固定长度中间语义张量c</span>
        encoder_outputs_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>MAX_LENGTH<span class="token punctuation">,</span> my_encoderrnn<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
        x_len <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>x_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            encoder_outputs_c<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> encode_output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> idx<span class="token punctuation">]</span>

        <span class="token comment"># 解码参数2 最后1个隐藏层的输出 作为 解码器的第1个时间步隐藏层输入</span>
        decode_hidden <span class="token operator">=</span> encode_hidden

        <span class="token comment"># 解码参数3 解码器第一个时间步起始符</span>
        input_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>SOS_token<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>

        <span class="token comment"># 3 自回归方式解码</span>
        <span class="token comment"># 初始化预测的词汇列表</span>
        decoded_words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment"># 初始化attention张量</span>
        decoder_attentions <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>MAX_LENGTH<span class="token punctuation">,</span> MAX_LENGTH<span class="token punctuation">)</span>
        <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>MAX_LENGTH<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># note:MAX_LENGTH=10</span>
            output_y<span class="token punctuation">,</span> decode_hidden<span class="token punctuation">,</span> attn_weights <span class="token operator">=</span> my_attndecoderrnn<span class="token punctuation">(</span>input_y<span class="token punctuation">,</span> decode_hidden<span class="token punctuation">,</span> encoder_outputs_c<span class="token punctuation">)</span>
            <span class="token comment"># 预测值作为为下一次时间步的输入值</span>
            topv<span class="token punctuation">,</span> topi <span class="token operator">=</span> output_y<span class="token punctuation">.</span>topk<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            decoder_attentions<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> attn_weights

            <span class="token comment"># 如果输出值是终止符，则循环停止</span>
            <span class="token keyword">if</span> topi<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> EOS_token<span class="token punctuation">:</span>
                decoded_words<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'&lt;EOS&gt;'</span><span class="token punctuation">)</span>
                <span class="token keyword">break</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                decoded_words<span class="token punctuation">.</span>append<span class="token punctuation">(</span>french_index2word<span class="token punctuation">[</span>topi<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

            <span class="token comment"># 将本次预测的索引赋值给 input_y，进行下一个时间步预测</span>
            input_y <span class="token operator">=</span> topi<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 返回结果decoded_words， 注意力张量权重分布表(把没有用到的部分切掉)</span>
        <span class="token keyword">return</span> decoded_words<span class="token punctuation">,</span> decoder_attentions<span class="token punctuation">[</span><span class="token punctuation">:</span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
</code></pre> 
<h4><a id="_1474"></a>评估</h4> 
<pre><code class="prism language-python"><span class="token comment"># 加载模型</span>
PATH1 <span class="token operator">=</span> <span class="token string">'./gpumodel/my_encoderrnn.pth'</span>
PATH2 <span class="token operator">=</span> <span class="token string">'./gpumodel/my_attndecoderrnn.pth'</span>
<span class="token keyword">def</span> <span class="token function">dm_test_Seq2Seq_Evaluate</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 实例化dataset对象</span>
    mypairsdataset <span class="token operator">=</span> MyPairsDataset<span class="token punctuation">(</span>my_pairs<span class="token punctuation">)</span>
    <span class="token comment"># 实例化dataloader</span>
    mydataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>mypairsdataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment"># 实例化模型</span>
    input_size <span class="token operator">=</span> english_word_n
    hidden_size <span class="token operator">=</span> <span class="token number">256</span>  <span class="token comment"># 观察结果数据 可使用8</span>
    my_encoderrnn <span class="token operator">=</span> EncoderRNN<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
    <span class="token comment"># my_encoderrnn.load_state_dict(torch.load(PATH1))</span>
    my_encoderrnn<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH1<span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token keyword">lambda</span> storage<span class="token punctuation">,</span> loc<span class="token punctuation">:</span> storage<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'my_encoderrnn模型结构---&gt;'</span><span class="token punctuation">,</span> my_encoderrnn<span class="token punctuation">)</span>

    <span class="token comment"># 实例化模型</span>
    input_size <span class="token operator">=</span> french_word_n
    hidden_size <span class="token operator">=</span> <span class="token number">256</span>  <span class="token comment"># 观察结果数据 可使用8</span>
    my_attndecoderrnn <span class="token operator">=</span> AttnDecoderRNN<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
    <span class="token comment"># my_attndecoderrnn.load_state_dict(torch.load(PATH2))</span>
    my_attndecoderrnn<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH2<span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token keyword">lambda</span> storage<span class="token punctuation">,</span> loc<span class="token punctuation">:</span> storage<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'my_decoderrnn模型结构---&gt;'</span><span class="token punctuation">,</span> my_attndecoderrnn<span class="token punctuation">)</span>

    my_samplepairs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'i m impressed with your french .'</span><span class="token punctuation">,</span> <span class="token string">'je suis impressionne par votre francais .'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                      <span class="token punctuation">[</span><span class="token string">'i m more than a friend .'</span><span class="token punctuation">,</span> <span class="token string">'je suis plus qu une amie .'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                      <span class="token punctuation">[</span><span class="token string">'she is beautiful like her mother .'</span><span class="token punctuation">,</span> <span class="token string">'vous gagnez n est ce pas ?'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'my_samplepairs---&gt;'</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>my_samplepairs<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> index<span class="token punctuation">,</span> pair <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>my_samplepairs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        y <span class="token operator">=</span> pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

        <span class="token comment"># 样本x 文本数值化</span>
        tmpx <span class="token operator">=</span> <span class="token punctuation">[</span>english_word2index<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        tmpx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>EOS_token<span class="token punctuation">)</span>
        tensor_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>tmpx<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 模型预测</span>
        decoded_words<span class="token punctuation">,</span> attentions <span class="token operator">=</span> Seq2Seq_Evaluate<span class="token punctuation">(</span>tensor_x<span class="token punctuation">,</span> my_encoderrnn<span class="token punctuation">,</span> my_attndecoderrnn<span class="token punctuation">)</span>
        <span class="token comment"># print('decoded_words-&gt;', decoded_words)</span>
        output_sentence <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>decoded_words<span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'&gt;'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'='</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'&lt;'</span><span class="token punctuation">,</span> output_sentence<span class="token punctuation">)</span>
</code></pre> 
<h2><a id="python_1526"></a>关于服务器调试python的说明</h2> 
<p>以刚才的代码为例子（py文件为"翻译.py"），勿喷，我考虑到有人可能会用中文命名出问题，特此尝试，顺便解决问题。大家千万不要编程用中文！大家千万不要编程用中文！大家千万不要编程用中文！</p> 
<h3><a id="_1528"></a>操作前需要知道的知识点</h3> 
<h4><a id="nohup_1529"></a>nohup</h4> 
<p>nohup 命令运行由 Command参数和任何相关的 Arg参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （ 表示“and”的符号）到命令的尾部。<br> 参数说明：<br> Command：要执行的命令。<br> Arg：一些参数，可以指定输出文件。<br> &amp;：让命令在后台执行，终端退出后命令仍旧执行。</p> 
<h4><a id="tail_1535"></a>tail</h4> 
<p>tail 命令可用于查看文件的内容，有一个常用的参数 -f 常用于查阅正在改变的日志文件<br> 参数：<br> -f 循环读取<br> -q 不显示处理信息<br> -v 显示详细的处理信息<br> -c&lt;数目&gt; 显示的字节数<br> -n&lt;行数&gt; 显示文件的尾部 n 行内容<br> –pid=PID 与-f合用,表示在进程ID,PID死掉之后结束<br> -q, --quiet, --silent 从不输出给出文件名的首部<br> -s, --sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒</p> 
<h3><a id="python_1546"></a>首先进入python文件所在目录并进行编译</h3> 
<p><img src="https://images2.imgbox.com/65/61/Rr51gJR1_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_1548"></a>转后台进程</h3> 
<pre><code class="prism language-python">nohup python <span class="token operator">-</span>u 翻译<span class="token punctuation">.</span>py <span class="token operator">&gt;</span> run<span class="token punctuation">.</span>log <span class="token number">2</span><span class="token operator">&gt;</span><span class="token operator">&amp;</span><span class="token number">1</span> <span class="token operator">&amp;</span>
</code></pre> 
<h3><a id="SSH_1552"></a>启动一个SSH连接看训练输出</h3> 
<p>声明：过大的模型生成需要时间，如果没有请先耐心等待</p> 
<pre><code class="prism language-python">tail <span class="token operator">-</span>f run<span class="token punctuation">.</span>log
</code></pre> 
<h3><a id="_1557"></a>执行结果</h3> 
<p><img src="https://images2.imgbox.com/10/6b/D0u3yWRB_o.png" alt="在这里插入图片描述"><br> 成了</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7d5002a437fb643f62308542f0bec88f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue生命周期详细全过程（含图解）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/059bd1d45c569ac9f653b22fd8420b3c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">数组的小结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>