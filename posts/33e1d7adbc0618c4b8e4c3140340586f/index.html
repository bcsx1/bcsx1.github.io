<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>TensorRT基础知识及应用【学习笔记（十）】 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="TensorRT基础知识及应用【学习笔记（十）】" />
<meta property="og:description" content="文章目录 一、准备知识1.1 环境配置A. CUDA DriverB. CUDAC. cuDNND. TensorRT 1.2 编程模型 二、构建阶段2.1 创建网络定义2.2 配置参数2.3 生成Engine2.4 保存为模型文件2.5 释放资源 三、运行时阶段3.1 反序列化并创建Engine3.2 创建一个ExecutionContext3.3 为推理填充输入3.4 调用enqueueV2来执行推理3.5 释放资源 四、编译和运行 一、准备知识 NVIDIA® TensorRT™是一个用于高性能深度学习的推理框架。它可以与TensorFlow、PyTorch和MXNet等训练框架相辅相成地工作。
1.1 环境配置 A. CUDA Driver 使用CUDA前，要求GPU驱动与cuda 的版本要匹配，匹配关系如下：
参考：https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#cuda-major-component-versions__table-cuda-toolkit-driver-versions
检查机器建议的驱动 有recommended这一行中的是系统推荐安装的nvidia-driver-525驱动版本
$ ubuntu-drivers devices // 比如我的机器输出如下 (base) enpei@enpei-ubutnu-desktop:~$ ubuntu-drivers devices == /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0 == modalias : pci:v000010DEd00001C03sv000010DEsd000011D7bc03sc00i00 vendor : NVIDIA Corporation model : GP106 [GeForce GTX 1060 6GB] driver : nvidia-driver-525 - distro non-free recommended driver : nvidia-driver-510 - distro non-free driver : nvidia-driver-390 - distro non-free driver : nvidia-driver-520 - third-party non-free driver : nvidia-driver-515-server - distro non-free driver : nvidia-driver-470 - distro non-free driver : nvidia-driver-418-server - distro non-free driver : nvidia-driver-470-server - distro non-free driver : nvidia-driver-525-server - distro non-free driver : nvidia-driver-515 - distro non-free driver : nvidia-driver-450-server - distro non-free driver : xserver-xorg-video-nouveau - distro free builtin 上面信息提示了，当前我使用的GPU是[GeForce GTX 1060 6GB]，他推荐的（recommended）驱动是nvidia-driver-525。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/33e1d7adbc0618c4b8e4c3140340586f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-13T17:14:08+08:00" />
<meta property="article:modified_time" content="2023-12-13T17:14:08+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">TensorRT基础知识及应用【学习笔记（十）】</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#_1" rel="nofollow">一、准备知识</a></li><li><ul><li><a href="#11__5" rel="nofollow">1.1 环境配置</a></li><li><ul><li><a href="#A_CUDA_Driver_7" rel="nofollow">A. CUDA Driver</a></li><li><a href="#B_CUDA_88" rel="nofollow">B. CUDA</a></li><li><a href="#C_cuDNN_118" rel="nofollow">C. cuDNN</a></li><li><a href="#D_TensorRT_170" rel="nofollow">D. TensorRT</a></li></ul> 
    </li><li><a href="#12__250" rel="nofollow">1.2 编程模型</a></li></ul> 
   </li><li><a href="#_259" rel="nofollow">二、构建阶段</a></li><li><ul><li><a href="#21__275" rel="nofollow">2.1 创建网络定义</a></li><li><a href="#22__322" rel="nofollow">2.2 配置参数</a></li><li><a href="#23_Engine_340" rel="nofollow">2.3 生成Engine</a></li><li><a href="#24__348" rel="nofollow">2.4 保存为模型文件</a></li><li><a href="#25__360" rel="nofollow">2.5 释放资源</a></li></ul> 
   </li><li><a href="#_518" rel="nofollow">三、运行时阶段</a></li><li><ul><li><a href="#31_Engine_539" rel="nofollow">3.1 反序列化并创建Engine</a></li><li><a href="#32_ExecutionContext_549" rel="nofollow">3.2 创建一个ExecutionContext</a></li><li><a href="#33__559" rel="nofollow">3.3 为推理填充输入</a></li><li><a href="#34_enqueueV2_591" rel="nofollow">3.4 调用enqueueV2来执行推理</a></li><li><a href="#35__606" rel="nofollow">3.5 释放资源</a></li></ul> 
   </li><li><a href="#_749" rel="nofollow">四、编译和运行</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_1"></a>一、准备知识</h3> 
<p>NVIDIA® TensorRT™是一个用于高性能深度学习的推理框架。它可以与TensorFlow、PyTorch和MXNet等训练框架相辅相成地工作。</p> 
<h4><a id="11__5"></a>1.1 环境配置</h4> 
<h5><a id="A_CUDA_Driver_7"></a>A. CUDA Driver</h5> 
<ul><li> <p>使用CUDA前，要求GPU驱动与<code>cuda</code> 的版本要匹配，匹配关系如下：</p> 
  <blockquote> 
   <p>参考：https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html#cuda-major-component-versions__table-cuda-toolkit-driver-versions</p> 
  </blockquote> </li></ul> 
<img src="https://images2.imgbox.com/b6/11/Y5YYdKPH_o.jpg"> 
<ul><li>检查机器建议的驱动</li></ul> 
<blockquote> 
 <p>有recommended这一行中的是系统推荐安装的nvidia-driver-525驱动版本</p> 
</blockquote> 
<pre><code class="prism language-bash">$ ubuntu-drivers devices

// 比如我的机器输出如下

<span class="token punctuation">(</span>base<span class="token punctuation">)</span> enpei@enpei-ubutnu-desktop:~$ ubuntu-drivers devices
<span class="token operator">==</span> /sys/devices/pci0000:00/0000:00:01.0/0000:01:00.0 <span class="token operator">==</span>
modalias <span class="token builtin class-name">:</span> pci:v000010DEd00001C03sv000010DEsd000011D7bc03sc00i00
vendor   <span class="token builtin class-name">:</span> NVIDIA Corporation
model    <span class="token builtin class-name">:</span> GP106 <span class="token punctuation">[</span>GeForce GTX <span class="token number">1060</span> 6GB<span class="token punctuation">]</span>
driver   <span class="token builtin class-name">:</span> nvidia-driver-525 - distro non-free recommended
driver   <span class="token builtin class-name">:</span> nvidia-driver-510 - distro non-free
driver   <span class="token builtin class-name">:</span> nvidia-driver-390 - distro non-free
driver   <span class="token builtin class-name">:</span> nvidia-driver-520 - third-party non-free
driver   <span class="token builtin class-name">:</span> nvidia-driver-515-server - distro non-free
driver   <span class="token builtin class-name">:</span> nvidia-driver-470 - distro non-free
driver   <span class="token builtin class-name">:</span> nvidia-driver-418-server - distro non-free
driver   <span class="token builtin class-name">:</span> nvidia-driver-470-server - distro non-free
driver   <span class="token builtin class-name">:</span> nvidia-driver-525-server - distro non-free
driver   <span class="token builtin class-name">:</span> nvidia-driver-515 - distro non-free
driver   <span class="token builtin class-name">:</span> nvidia-driver-450-server - distro non-free
driver   <span class="token builtin class-name">:</span> xserver-xorg-video-nouveau - distro <span class="token function">free</span> <span class="token builtin class-name">builtin</span>
</code></pre> 
<p>上面信息提示了，当前我使用的GPU是[GeForce GTX 1060 6GB]，他推荐的（recommended）驱动是<code>nvidia-driver-525</code>。</p> 
<ul><li> <p>安装指定版本</p> <pre><code class="prism language-bash">$ <span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> nvidia-driver-525
</code></pre> </li><li> <p>重启</p> <pre><code class="prism language-bash">$ <span class="token function">sudo</span> <span class="token function">reboot</span>
</code></pre> </li><li> <p>检查安装</p> <pre><code class="prism language-bash">$ nvidia-smi

<span class="token punctuation">(</span>base<span class="token punctuation">)</span> enpei@enpei-ubutnu-desktop:~$ nvidia-smi
Mon Feb  <span class="token number">2</span> <span class="token number">12</span>:23:45 <span class="token number">2023</span>
+-----------------------------------------------------------------------------+
<span class="token operator">|</span> NVIDIA-SMI <span class="token number">525.78</span>.01    Driver Version: <span class="token number">525.78</span>.01    CUDA Version: <span class="token number">12.0</span>     <span class="token operator">|</span>
<span class="token operator">|</span>-------------------------------+----------------------+----------------------+
<span class="token operator">|</span> GPU  Name        Persistence-M<span class="token operator">|</span> Bus-Id        Disp.A <span class="token operator">|</span> Volatile Uncorr. ECC <span class="token operator">|</span>
<span class="token operator">|</span> Fan  Temp  Perf  Pwr:Usage/Cap<span class="token operator">|</span>         Memory-Usage <span class="token operator">|</span> GPU-Util  Compute M. <span class="token operator">|</span>
<span class="token operator">|</span>                               <span class="token operator">|</span>                      <span class="token operator">|</span>               MIG M. <span class="token operator">|</span>
<span class="token operator">|</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">+=</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">+=</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">|</span>
<span class="token operator">|</span>   <span class="token number">0</span>  NVIDIA GeForce <span class="token punctuation">..</span>.  Off  <span class="token operator">|</span> 00000000:01:00.0  On <span class="token operator">|</span>                  N/A <span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">40</span>%   29C    P8     9W / 120W <span class="token operator">|</span>    239MiB /  6144MiB <span class="token operator">|</span>      <span class="token number">0</span>%      Default <span class="token operator">|</span>
<span class="token operator">|</span>                               <span class="token operator">|</span>                      <span class="token operator">|</span>                  N/A <span class="token operator">|</span>
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
<span class="token operator">|</span> Processes:                                                                  <span class="token operator">|</span>
<span class="token operator">|</span>  GPU   GI   CI        PID   Type   Process name                  GPU Memory <span class="token operator">|</span>
<span class="token operator">|</span>        ID   ID                                                   Usage      <span class="token operator">|</span>
<span class="token operator">|</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">0</span>   N/A  N/A      <span class="token number">1079</span>      G   /usr/lib/xorg/Xorg                102MiB <span class="token operator">|</span>
<span class="token operator">|</span>    <span class="token number">0</span>   N/A  N/A      <span class="token number">1387</span>      G   /usr/bin/gnome-shell              133MiB <span class="token operator">|</span>
+-----------------------------------------------------------------------------+
</code></pre> <p>可以看到当前安装的驱动版本是<code>525.78.01</code>，需要注意<code>CUDA Version: 12.0</code>指当前驱动支持的最高版本。</p> </li></ul> 
<h5><a id="B_CUDA_88"></a>B. CUDA</h5> 
<ul><li> <p>选择对应版本：https://developer.nvidia.com/cuda-toolkit-archive</p> <img src="https://images2.imgbox.com/61/28/7i6QI5MT_o.jpg"> </li><li> <p>根据提示安装，如我选择的11.8 版本的：https://developer.nvidia.com/cuda-11-8-0-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=20.04&amp;target_type=deb_local</p> <img src="https://images2.imgbox.com/40/16/X3mxVdJw_o.jpg"> <pre><code class="prism language-bash"><span class="token function">wget</span> https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
<span class="token function">sudo</span> <span class="token function">mv</span> cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
<span class="token function">wget</span> https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda-repo-ubuntu2004-11-8-local_11.8.0-520.61.05-1_amd64.deb
<span class="token function">sudo</span> dpkg <span class="token parameter variable">-i</span> cuda-repo-ubuntu2004-11-8-local_11.8.0-520.61.05-1_amd64.deb
<span class="token function">sudo</span> <span class="token function">cp</span> /var/cuda-repo-ubuntu2004-11-8-local/cuda-*-keyring.gpg /usr/share/keyrings/
<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token parameter variable">-y</span> <span class="token function">install</span> cuda
</code></pre> </li><li> <p>安装<code>nvcc</code></p> <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> nvidia-cuda-toolkit
</code></pre> </li><li> <p>重启</p> </li></ul> 
<h5><a id="C_cuDNN_118"></a>C. cuDNN</h5> 
<ul><li> <p>下载安装包：访问：https://developer.nvidia.com/zh-cn/cudnn，选择对应的版本，下载对应的安装包（建议使用Debian包安装）</p> <img src="https://images2.imgbox.com/21/8b/5SSejMrO_o.jpg"> <p>比如我下载的是：<a href="https://developer.nvidia.com/downloads/c118-cudnn-local-repo-ubuntu2004-8708410-1amd64deb" rel="nofollow">Local Installer for Ubuntu20.04 x86_64 (Deb)</a>，下载后的文件名为<code>cudnn-local-repo-ubuntu2004-8.7.0.84_1.0-1_amd64.deb</code>。</p> </li><li> <p>安装：</p> 
  <blockquote> 
   <p>参考链接：https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html</p> 
  </blockquote> <pre><code class="prism language-bash"><span class="token comment"># 注意，运行下面的命令前，将下面的 X.Y和v8.x.x.x 替换成自己具体的CUDA 和 cuDNN版本，如我的CUDA 版本是11.8，cuDNN 版本是 8.7.0.84</span>

<span class="token function">sudo</span> dpkg <span class="token parameter variable">-i</span> cudnn-local-repo-<span class="token variable">${OS}</span>-8.x.x.x_1.0-1_amd64.deb
<span class="token comment"># 我的：sudo dpkg -i cudnn-local-repo-ubuntu2004-8.7.0.84_1.0-1_amd64.deb</span>

<span class="token function">sudo</span> <span class="token function">cp</span> /var/cudnn-local-repo-*/cudnn-local-*-keyring.gpg /usr/share/keyrings/
<span class="token function">sudo</span> <span class="token function">apt-get</span> update


<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token assign-left variable">libcudnn8</span><span class="token operator">=</span><span class="token number">8</span>.x.x.x-1+cudaX.Y
<span class="token comment"># 我的：sudo apt-get install libcudnn8=8.7.0.84-1+cuda11.8</span>


<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libcudnn8-dev<span class="token operator">=</span><span class="token number">8</span>.x.x.x-1+cudaX.Y
<span class="token comment"># 我的：sudo apt-get install libcudnn8-dev=8.7.0.84-1+cuda11.8</span>


<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libcudnn8-samples<span class="token operator">=</span><span class="token number">8</span>.x.x.x-1+cudaX.Y
<span class="token comment"># 我的：sudo apt-get install libcudnn8-samples=8.7.0.84-1+cuda11.8</span>
</code></pre> </li><li> <p>验证</p> <pre><code class="prism language-bash"><span class="token comment"># 复制文件</span>
<span class="token function">cp</span> <span class="token parameter variable">-r</span> /usr/src/cudnn_samples_v8/ <span class="token environment constant">$HOME</span>
<span class="token builtin class-name">cd</span>  <span class="token environment constant">$HOME</span>/cudnn_samples_v8/mnistCUDNN
<span class="token function">make</span> clean <span class="token operator">&amp;&amp;</span> <span class="token function">make</span>
./mnistCUDNN
</code></pre> 
  <blockquote> 
   <p>可能报错：test.c:1:10: fatal error: FreeImage.h: No such file or directory</p> 
   <p>解决办法：sudo apt-get install libfreeimage3 libfreeimage-dev</p> 
  </blockquote> </li></ul> 
<h5><a id="D_TensorRT_170"></a>D. TensorRT</h5> 
<blockquote> 
 <p><strong>TensorRT是什么：</strong></p> 
 <ul><li>TensorRT是NVIDIA推出的深度学习推理SDK，能够在NVIDIA GPU上实现低延迟、⾼吞吐量的部署。</li><li>TensorRT包含⽤于训练好的模型的优化器，以及⽤于执⾏推理的runtime。</li></ul> 
</blockquote> 
<p><img src="https://images2.imgbox.com/e0/62/hco7yyj5_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p><strong>TensorRT优化策略：</strong></p> 
 <ul><li>消除不使⽤输出的层；</li><li>卷积、偏置和ReLU运算的融合；</li><li>具有⾜够相似的参数和相同的源张量的操作的集合(例如，GoogleNet v5的inception模块中的1x1卷积)；</li><li>通过将层输出定向到正确的最终⽬的地来合并连接层；</li><li>如果有必要，构造器还会修改权重的精度。当⽣成8位整数精度的⽹络时，它使⽤⼀个称为校准的过程来确定中间激活的动态范围，从⽽确定量化所需的适当⽐例因⼦；</li><li>此外，构建阶段还在虚拟数据上运⾏层，以从其内核⽬录中选择最快的，并在适当的地⽅执⾏权重预格式化和内存优化。</li></ul> 
</blockquote> 
<p><img src="https://images2.imgbox.com/fc/2d/yH8aLUCS_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<hr> 
<p><img src="https://images2.imgbox.com/a9/e3/FSutQeqF_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p><strong>TensorRT优化策略：</strong></p> 
 <ul><li>TensorRT需要在⽬标GPU设备上实际运⾏来选择最优算法和配置（根据硬件、软件环境版本等）</li><li>所以TensorRT⽣成的模型迁移到别的设备或其他版本的TensorRT下不⼀定能运⾏。</li></ul> 
</blockquote> 
<p><strong>如何使⽤TensorRT？</strong></p> 
<p><img src="https://images2.imgbox.com/75/1d/WoJW61lU_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<p><strong>模型转换：</strong><br> <img src="https://images2.imgbox.com/09/b5/NBQKMypE_o.png" alt="在这里插入图片描述"></p> 
<p><strong>插件Plugin</strong><br> <img src="https://images2.imgbox.com/71/e7/gcRtffAs_o.png" alt="在这里插入图片描述"></p> 
<ul><li> <p>访问：https://developer.nvidia.com/nvidia-tensorrt-8x-download 下载对应版本的TensorRT</p> <img src="https://images2.imgbox.com/64/40/Knr2ek8P_o.jpg"> <p>比如我选择的是 8.5.3版本，下载完文件名为：<code>nv-tensorrt-local-repo-ubuntu2004-8.5.3-cuda-11.8_1.0-1_amd64.deb</code></p> </li><li> <p>安装：</p> 
  <blockquote> 
   <p>参考地址：https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-debian</p> 
  </blockquote> <pre><code class="prism language-bash"><span class="token comment"># 替换成自己的OS 和 版本信息</span>
<span class="token assign-left variable">os</span><span class="token operator">=</span><span class="token string">"ubuntuxx04"</span>
<span class="token assign-left variable">tag</span><span class="token operator">=</span><span class="token string">"8.x.x-cuda-x.x"</span>
<span class="token function">sudo</span> dpkg <span class="token parameter variable">-i</span> nv-tensorrt-local-repo-<span class="token variable">${os}</span>-<span class="token variable">${tag}</span>_1.0-1_amd64.deb
<span class="token comment"># 我的：sudo dpkg -i nv-tensorrt-local-repo-ubuntu2004-8.5.3-cuda-11.8_1.0-1_amd64.deb</span>
<span class="token function">sudo</span> <span class="token function">cp</span> /var/nv-tensorrt-local-repo-<span class="token variable">${os}</span>-<span class="token variable">${tag}</span>/*-keyring.gpg /usr/share/keyrings/
<span class="token comment"># 我的：sudo cp /var/nv-tensorrt-local-repo-ubuntu2004-8.5.3-cuda-11.8/*-keyring.gpg /usr/share/keyrings/</span>

<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> tensorrt
</code></pre> </li><li> <p>验证：</p> <pre><code class="prism language-bash">dpkg <span class="token parameter variable">-l</span> <span class="token operator">|</span> <span class="token function">grep</span> TensorRT

<span class="token comment"># 输出</span>
ii  libnvinfer-bin                                    <span class="token number">8.5</span>.3-1+cuda11.8                    amd64        TensorRT binaries
ii  libnvinfer-dev                                    <span class="token number">8.5</span>.3-1+cuda11.8                    amd64        TensorRT development libraries and headers
ii  libnvinfer-plugin-dev                             <span class="token number">8.5</span>.3-1+cuda11.8                    amd64        TensorRT plugin libraries
ii  libnvinfer-plugin8                                <span class="token number">8.5</span>.3-1+cuda11.8                    amd64        TensorRT plugin libraries
ii  libnvinfer-samples                                <span class="token number">8.5</span>.3-1+cuda11.8                    all          TensorRT samples
ii  libnvinfer8                                       <span class="token number">8.5</span>.3-1+cuda11.8                    amd64        TensorRT runtime libraries
ii  libnvonnxparsers-dev                              <span class="token number">8.5</span>.3-1+cuda11.8                    amd64        TensorRT ONNX libraries
ii  libnvonnxparsers8                                 <span class="token number">8.5</span>.3-1+cuda11.8                    amd64        TensorRT ONNX libraries
ii  libnvparsers-dev                                  <span class="token number">8.5</span>.3-1+cuda11.8                    amd64        TensorRT parsers libraries
ii  libnvparsers8                                     <span class="token number">8.5</span>.3-1+cuda11.8                    amd64        TensorRT parsers libraries
ii  tensorrt                                          <span class="token number">8.5</span>.3.1-1+cuda11.8                  amd64        Meta package <span class="token keyword">for</span> TensorRT
</code></pre> 
  <blockquote> 
   <p>如果遇到<code>unmet dependencies</code>的问题, 一般是cuda cudnn没有安装好。TensorRT的<code>INCLUDE</code> 路径是 <code>/usr/include/x86_64-linux-gnu/</code>, <code>LIB</code>路径是<code>/usr/lib/x86_64-linux-gnu/</code>,Sample code在<code>/usr/src/tensorrt/samples</code>, <code>trtexec</code>在<code>/usr/src/tensorrt/bin</code>下。</p> 
  </blockquote> </li></ul> 
<h4><a id="12__250"></a>1.2 编程模型</h4> 
<p>TensorRT分两个阶段运行</p> 
<ul><li>构建（<code>Build</code>）阶段：你向TensorRT提供一个模型定义，TensorRT为目标GPU优化这个模型。这个过程可以离线运行。</li><li>运行时（<code>Runtime</code>）阶段：你使用优化后的模型来运行推理。</li></ul> 
<p>构建阶段后，我们可以将优化后的模型保存为模型文件，模型文件可以用于后续加载，以省略模型构建和优化的过程。</p> 
<h3><a id="_259"></a>二、构建阶段</h3> 
<blockquote> 
 <p><em>样例代码：<code>6.trt_basic/src/build.cpp</code></em></p> 
</blockquote> 
<p>构建阶段的最高级别接口是 <code>builder</code>。<code>builder</code>负责优化一个模型，并产生<code>Engine</code>。通过如下接口创建一个<code>builder</code> 。</p> 
<pre><code class="prism language-cpp">nvinfer1<span class="token double-colon punctuation">::</span>IBuilder<span class="token operator">*</span> builder <span class="token operator">=</span> nvinfer1<span class="token double-colon punctuation">::</span><span class="token function">createInferBuilder</span><span class="token punctuation">(</span>logger<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>要生成一个可以进行推理的<code>Engine</code>，一般需要以下三个步骤：</p> 
<ul><li>创建一个网络定义</li><li>填写<code>builder</code>构建配置参数，告诉构建器应该如何优化模型</li><li>调用<code>builder</code>生成<code>Engine</code></li></ul> 
<h4><a id="21__275"></a>2.1 创建网络定义</h4> 
<p><code>NetworkDefinition</code>接口被用来定义模型。如下所示：</p> 
<pre><code class="prism language-cpp"><span class="token comment">// bit shift，移位：y左移N位，相当于 y * 2^N</span>
<span class="token comment">// kEXPLICIT_BATCH（显性Batch）为0，1U &lt;&lt; 0 = 1</span>
<span class="token comment">// static_cast：强制类型转换</span>
<span class="token keyword">const</span> <span class="token keyword">auto</span> explicitBatch <span class="token operator">=</span> <span class="token number">1U</span> <span class="token operator">&lt;&lt;</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">uint32_t</span><span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>nvinfer1<span class="token double-colon punctuation">::</span>NetworkDefinitionCreationFlag<span class="token double-colon punctuation">::</span>kEXPLICIT_BATCH<span class="token punctuation">)</span><span class="token punctuation">;</span>
nvinfer1<span class="token double-colon punctuation">::</span>INetworkDefinition<span class="token operator">*</span> network <span class="token operator">=</span> builder<span class="token operator">-&gt;</span><span class="token function">createNetworkV2</span><span class="token punctuation">(</span>explicitBatch<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>接口<code>createNetworkV2</code>接受配置参数，参数用按位标记的方式传入。比如上面激活<code>explicitBatch</code>，是通过<code>1U &lt;&lt; static_cast&lt;uint32_t&gt;(nvinfer1::NetworkDefinitionCreationFlag::kEXPLICIT_BATCH);</code> 将explicitBatch对应的配置位设置为1实现的。在新版本中，请使用<code>createNetworkV2</code>而非其他任何创建<code>NetworkDefinition</code> 的接口。</p> 
<p>将模型转移到TensorRT的最常见的方式是以ONNX格式从框架中导出（将在后续课程进行介绍），并使用TensorRT的ONNX解析器来填充网络定义。同时，也可以使用TensorRT的<code>Layer</code>和<code>Tensor</code>等接口一步一步地进行定义。通过接口来定义网络的代码示例如下：</p> 
<ul><li>添加输入层</li></ul> 
<pre><code class="prism language-cpp">nvinfer1<span class="token double-colon punctuation">::</span>ITensor<span class="token operator">*</span> input <span class="token operator">=</span> network<span class="token operator">-&gt;</span><span class="token function">addInput</span><span class="token punctuation">(</span><span class="token string">"data"</span><span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>DataType<span class="token double-colon punctuation">::</span>kFLOAT<span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>Dims4<span class="token punctuation">{<!-- --></span><span class="token number">1</span><span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<ul><li>添加全连接层</li></ul> 
<pre><code class="prism language-cpp">nvinfer1<span class="token double-colon punctuation">::</span>IFullyConnectedLayer<span class="token operator">*</span> fc1 <span class="token operator">=</span> network<span class="token operator">-&gt;</span><span class="token function">addFullyConnected</span><span class="token punctuation">(</span><span class="token operator">*</span>input<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> fc1w<span class="token punctuation">,</span> fc1b<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<ul><li>添加激活层</li></ul> 
<pre><code class="prism language-cpp">nvinfer1<span class="token double-colon punctuation">::</span>IActivationLayer<span class="token operator">*</span> relu1 <span class="token operator">=</span> network<span class="token operator">-&gt;</span><span class="token function">addActivation</span><span class="token punctuation">(</span><span class="token operator">*</span>fc1<span class="token operator">-&gt;</span><span class="token function">getOutput</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>ActivationType<span class="token double-colon punctuation">::</span>kRELU<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>通过调用<code>network</code>的方法，我们可以构建网络的定义。</p> 
<p>无论你选择哪种方式，你还必须定义哪些张量是网络的输入和输出。没有被标记为输出的张量被认为是瞬时值，可以被构建者优化掉。输入和输出张量必须被命名，以便在运行时，TensorRT知道如何将输入和输出缓冲区绑定到模型上。示例代码如下：</p> 
<pre><code class="prism language-cpp"><span class="token comment">// 设置输出名字</span>
relu1<span class="token operator">-&gt;</span><span class="token function">getOutput</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">-&gt;</span><span class="token function">setName</span><span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 标记输出</span>
network<span class="token operator">-&gt;</span><span class="token function">markOutput</span><span class="token punctuation">(</span><span class="token operator">*</span>relu1<span class="token operator">-&gt;</span><span class="token function">getOutput</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>TensorRT的网络定义不会复制参数数组（如卷积的权重）。因此，在构建阶段完成之前，你不能释放这些数组的内存。</p> 
<h4><a id="22__322"></a>2.2 配置参数</h4> 
<p>下面我们来添加相关<code>Builder</code> 的配置。<code>createBuilderConfig</code>接口被用来指定TensorRT应该如何优化模型。如下：</p> 
<pre><code class="prism language-cpp">nvinfer1<span class="token double-colon punctuation">::</span>IBuilderConfig<span class="token operator">*</span> config <span class="token operator">=</span> builder<span class="token operator">-&gt;</span><span class="token function">createBuilderConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>在可用的配置选项中，你可以控制TensorRT降低计算精度的能力，控制内存和运行时执行速度之间的权衡，并限制CUDA®内核的选择。由于构建器的运行可能需要几分钟或更长时间，你也可以控制构建器如何搜索内核，以及缓存搜索结果以用于后续运行。在我们的示例代码中，我们仅配置<code>workspace</code>（workspace 就是 tensorrt 里面算子可用的内存空间 ）大小和运行时<code>batch size</code> ，如下：</p> 
<pre><code class="prism language-cpp"><span class="token comment">// 配置运行时batch size参数</span>
builder<span class="token operator">-&gt;</span><span class="token function">setMaxBatchSize</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 配置运行时workspace大小</span>
std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Workspace Size = "</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">28</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1024.0f</span> <span class="token operator">/</span> <span class="token number">1024.0f</span> <span class="token operator">&lt;&lt;</span> <span class="token string">"MB"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span> <span class="token comment">// 256Mib</span>
config<span class="token operator">-&gt;</span><span class="token function">setMaxWorkspaceSize</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="23_Engine_340"></a>2.3 生成Engine</h4> 
<p>在你有了网络定义和<code>Builder</code>配置后，你可以调用<code>Builder</code>来创建<code>Engine</code>。<code>Builder</code>以一种称为<code>plan</code>的序列化形式创建<code>Engine</code>，它可以立即反序列化，也可以保存到磁盘上供以后使用。需要注意的是，由TensorRT创建的<code>Engine</code>是特定于创建它们的TensorRT版本和创建它们的GPU的，当迁移到别的GPU和TensorRT版本时，不能保证模型能够被正确执行。生成<code>Engine</code>的示例代码如下：</p> 
<pre><code class="prism language-cpp">nvinfer1<span class="token double-colon punctuation">::</span>ICudaEngine<span class="token operator">*</span> engine <span class="token operator">=</span> builder<span class="token operator">-&gt;</span><span class="token function">buildEngineWithConfig</span><span class="token punctuation">(</span><span class="token operator">*</span>network<span class="token punctuation">,</span> <span class="token operator">*</span>config<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="24__348"></a>2.4 保存为模型文件</h4> 
<p>当有了<code>engine</code>后我们可以将其保存为文件，以供后续使用。代码如下：</p> 
<pre><code class="prism language-cpp"><span class="token comment">// 序列化</span>
nvinfer1<span class="token double-colon punctuation">::</span>IHostMemory<span class="token operator">*</span> engine_data <span class="token operator">=</span> engine<span class="token operator">-&gt;</span><span class="token function">serialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 保存至文件</span>
std<span class="token double-colon punctuation">::</span>ofstream <span class="token function">engine_file</span><span class="token punctuation">(</span><span class="token string">"mlp.engine"</span><span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>ios<span class="token double-colon punctuation">::</span>binary<span class="token punctuation">)</span><span class="token punctuation">;</span>
engine_file<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">char</span><span class="token operator">*</span><span class="token punctuation">)</span>engine_data<span class="token operator">-&gt;</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> engine_data<span class="token operator">-&gt;</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="25__360"></a>2.5 释放资源</h4> 
<pre><code class="prism language-cpp"><span class="token comment">// 理论上，前面申请的资源都应该在这里释放，但是这里只是为了演示，所以只释放了部分资源</span>
file<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>             <span class="token comment">// 关闭文件</span>
<span class="token keyword">delete</span> serialized_engine<span class="token punctuation">;</span> <span class="token comment">// 释放序列化的engine</span>
<span class="token keyword">delete</span> engine<span class="token punctuation">;</span>            <span class="token comment">// 释放engine</span>
<span class="token keyword">delete</span> config<span class="token punctuation">;</span>            <span class="token comment">// 释放config</span>
<span class="token keyword">delete</span> network<span class="token punctuation">;</span>           <span class="token comment">// 释放network</span>
<span class="token keyword">delete</span> builder<span class="token punctuation">;</span>           <span class="token comment">// 释放builder</span>
</code></pre> 
<p><strong>完整代码如下，build.cpp:</strong></p> 
<pre><code class="prism language-cpp"><span class="token comment">/*
TensorRT build engine的过程
1. 创建builder
2. 创建网络定义：builder ---&gt; network
3. 配置参数：builder ---&gt; config
4. 生成engine：builder ---&gt; engine (network, config)
5. 序列化保存：engine ---&gt; serialize
6. 释放资源：delete
*/</span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;iostream&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;fstream&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;cassert&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;vector&gt;</span></span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;NvInfer.h&gt;</span></span>

<span class="token comment">// logger用来管控打印日志级别</span>
<span class="token comment">// TRTLogger继承自nvinfer1::ILogger</span>
<span class="token keyword">class</span> <span class="token class-name">TRTLogger</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> nvinfer1<span class="token double-colon punctuation">::</span><span class="token class-name">ILogger</span></span>
<span class="token punctuation">{<!-- --></span>
    <span class="token keyword">void</span> <span class="token function">log</span><span class="token punctuation">(</span>Severity severity<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">char</span> <span class="token operator">*</span>msg<span class="token punctuation">)</span> <span class="token keyword">noexcept</span> <span class="token keyword">override</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token comment">// 屏蔽INFO级别的日志</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>severity <span class="token operator">!=</span> Severity<span class="token double-colon punctuation">::</span>kINFO<span class="token punctuation">)</span>
            std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> msg <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span> gLogger<span class="token punctuation">;</span>

<span class="token comment">// 保存权重</span>
<span class="token keyword">void</span> <span class="token function">saveWeights</span><span class="token punctuation">(</span><span class="token keyword">const</span> std<span class="token double-colon punctuation">::</span>string <span class="token operator">&amp;</span>filename<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>data<span class="token punctuation">,</span> <span class="token keyword">int</span> size<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    std<span class="token double-colon punctuation">::</span>ofstream <span class="token function">outfile</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>ios<span class="token double-colon punctuation">::</span>binary<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 以二进制的方式写入文件</span>
    <span class="token function">assert</span><span class="token punctuation">(</span>outfile<span class="token punctuation">.</span><span class="token function">is_open</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token string">"save weights failed"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// assert断言，如果条件不满足，就会报错</span>
    outfile<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">char</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>size<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment">// 保存权重的大小</span>
    outfile<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">char</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> size <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 保存权重的数据</span>
    outfile<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token comment">// 读取权重</span>
std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">&gt;</span> <span class="token function">loadWeights</span><span class="token punctuation">(</span><span class="token keyword">const</span> std<span class="token double-colon punctuation">::</span>string <span class="token operator">&amp;</span>filename<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    std<span class="token double-colon punctuation">::</span>ifstream <span class="token function">infile</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>ios<span class="token double-colon punctuation">::</span>binary<span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token comment">// 以二进制的方式读取文件</span>
    <span class="token function">assert</span><span class="token punctuation">(</span>infile<span class="token punctuation">.</span><span class="token function">is_open</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token string">"load weights failed"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">int</span> size<span class="token punctuation">;</span>
    infile<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">char</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>size<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token comment">// 读取权重的大小</span>
    std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">&gt;</span> <span class="token function">data</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>                            <span class="token comment">// 创建一个vector，大小为size</span>
    infile<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">char</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> size <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 读取权重的数据</span>
    infile<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">return</span> data<span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    <span class="token comment">// ======= 1. 创建builder =======</span>
    TRTLogger logger<span class="token punctuation">;</span>
    nvinfer1<span class="token double-colon punctuation">::</span>IBuilder <span class="token operator">*</span>builder <span class="token operator">=</span> nvinfer1<span class="token double-colon punctuation">::</span><span class="token function">createInferBuilder</span><span class="token punctuation">(</span>logger<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// ======= 2. 创建网络定义：builder ---&gt; network =======</span>

    <span class="token comment">// 1：显性batch</span>
    <span class="token comment">// 1 &lt;&lt; 0 = 1，&lt;&lt;是二进制移位操作符，左移0位，相当于1（y左移x位，相当于y乘以2的x次方）</span>
    <span class="token comment">// 1U:代表unsigned的1，uint32_t：unsigned int32</span>
    <span class="token keyword">auto</span> explicitBatch <span class="token operator">=</span> <span class="token number">1U</span> <span class="token operator">&lt;&lt;</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">uint32_t</span><span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>nvinfer1<span class="token double-colon punctuation">::</span>NetworkDefinitionCreationFlag<span class="token double-colon punctuation">::</span>kEXPLICIT_BATCH<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// kEXPLICIT_BATCH：0</span>
    <span class="token comment">// 调用createNetworkV2创建网络定义，参数是显性batch</span>
    nvinfer1<span class="token double-colon punctuation">::</span>INetworkDefinition <span class="token operator">*</span>network <span class="token operator">=</span> builder<span class="token operator">-&gt;</span><span class="token function">createNetworkV2</span><span class="token punctuation">(</span>explicitBatch<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 定义网络结构</span>
    <span class="token comment">// mlp多层感知机：input(1,3,1,1) --&gt; fc1 --&gt; sigmoid --&gt; output (2)</span>

    <span class="token comment">// 创建一个input tensor ，参数分别是：name, data type, dims</span>
    <span class="token keyword">const</span> <span class="token keyword">int</span> input_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>
    nvinfer1<span class="token double-colon punctuation">::</span>ITensor <span class="token operator">*</span>input <span class="token operator">=</span> network<span class="token operator">-&gt;</span><span class="token function">addInput</span><span class="token punctuation">(</span><span class="token string">"data"</span><span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>DataType<span class="token double-colon punctuation">::</span>kFLOAT<span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>Dims4<span class="token punctuation">{<!-- --></span><span class="token number">1</span><span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 创建全连接层fc1</span>
    <span class="token comment">// weight and bias</span>
    <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>fc1_weight_data <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token keyword">float</span><span class="token punctuation">[</span>input_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">}</span><span class="token punctuation">;</span>
    <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>fc1_bias_data <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token keyword">float</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">}</span><span class="token punctuation">;</span>

    <span class="token comment">// 将权重保存到文件中，演示从别的来源加载权重</span>
    <span class="token function">saveWeights</span><span class="token punctuation">(</span><span class="token string">"model/fc1.wts"</span><span class="token punctuation">,</span> fc1_weight_data<span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">saveWeights</span><span class="token punctuation">(</span><span class="token string">"model/fc1.bias"</span><span class="token punctuation">,</span> fc1_bias_data<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 读取权重</span>
    <span class="token keyword">auto</span> fc1_weight_vec <span class="token operator">=</span> <span class="token function">loadWeights</span><span class="token punctuation">(</span><span class="token string">"model/fc1.wts"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">auto</span> fc1_bias_vec <span class="token operator">=</span> <span class="token function">loadWeights</span><span class="token punctuation">(</span><span class="token string">"model/fc1.bias"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 转为nvinfer1::Weights类型，参数分别是：data type, data, size</span>
    <span class="token comment">// fc1_weight_vec.data()，其中vector类型获取指针用data()</span>
    nvinfer1<span class="token double-colon punctuation">::</span>Weights fc1_weight<span class="token punctuation">{<!-- --></span>nvinfer1<span class="token double-colon punctuation">::</span>DataType<span class="token double-colon punctuation">::</span>kFLOAT<span class="token punctuation">,</span> fc1_weight_vec<span class="token punctuation">.</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fc1_weight_vec<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">;</span>
    nvinfer1<span class="token double-colon punctuation">::</span>Weights fc1_bias<span class="token punctuation">{<!-- --></span>nvinfer1<span class="token double-colon punctuation">::</span>DataType<span class="token double-colon punctuation">::</span>kFLOAT<span class="token punctuation">,</span> fc1_bias_vec<span class="token punctuation">.</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fc1_bias_vec<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">;</span>

    <span class="token keyword">const</span> <span class="token keyword">int</span> output_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>
    <span class="token comment">// 调用addFullyConnected创建全连接层，参数分别是：input tensor, output size, weight, bias</span>
    nvinfer1<span class="token double-colon punctuation">::</span>IFullyConnectedLayer <span class="token operator">*</span>fc1 <span class="token operator">=</span> network<span class="token operator">-&gt;</span><span class="token function">addFullyConnected</span><span class="token punctuation">(</span><span class="token operator">*</span>input<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> fc1_weight<span class="token punctuation">,</span> fc1_bias<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 添加sigmoid激活层，参数分别是：input tensor, activation type（激活函数类型）</span>
    nvinfer1<span class="token double-colon punctuation">::</span>IActivationLayer <span class="token operator">*</span>sigmoid <span class="token operator">=</span> network<span class="token operator">-&gt;</span><span class="token function">addActivation</span><span class="token punctuation">(</span><span class="token operator">*</span>fc1<span class="token operator">-&gt;</span><span class="token function">getOutput</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>ActivationType<span class="token double-colon punctuation">::</span>kSIGMOID<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 设置输出名字</span>
    sigmoid<span class="token operator">-&gt;</span><span class="token function">getOutput</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">-&gt;</span><span class="token function">setName</span><span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 标记输出，没有标记会被当成顺时针优化掉</span>
    network<span class="token operator">-&gt;</span><span class="token function">markOutput</span><span class="token punctuation">(</span><span class="token operator">*</span>sigmoid<span class="token operator">-&gt;</span><span class="token function">getOutput</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 设定最大batch size</span>
    builder<span class="token operator">-&gt;</span><span class="token function">setMaxBatchSize</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// ====== 3. 配置参数：builder ---&gt; config ======</span>
    <span class="token comment">// 添加配置参数，告诉TensorRT应该如何优化网络</span>
    nvinfer1<span class="token double-colon punctuation">::</span>IBuilderConfig <span class="token operator">*</span>config <span class="token operator">=</span> builder<span class="token operator">-&gt;</span><span class="token function">createBuilderConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 设置最大工作空间大小，单位是字节</span>
    config<span class="token operator">-&gt;</span><span class="token function">setMaxWorkspaceSize</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 256MiB</span>

    <span class="token comment">// ====== 4. 创建engine：builder ---&gt; network ---&gt; config ======</span>
    nvinfer1<span class="token double-colon punctuation">::</span>ICudaEngine <span class="token operator">*</span>engine <span class="token operator">=</span> builder<span class="token operator">-&gt;</span><span class="token function">buildEngineWithConfig</span><span class="token punctuation">(</span><span class="token operator">*</span>network<span class="token punctuation">,</span> <span class="token operator">*</span>config<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>engine<span class="token punctuation">)</span>
    <span class="token punctuation">{<!-- --></span>
        std<span class="token double-colon punctuation">::</span>cerr <span class="token operator">&lt;&lt;</span> <span class="token string">"Failed to create engine!"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token comment">// ====== 5. 序列化engine ======</span>
    nvinfer1<span class="token double-colon punctuation">::</span>IHostMemory <span class="token operator">*</span>serialized_engine <span class="token operator">=</span> engine<span class="token operator">-&gt;</span><span class="token function">serialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 存入文件</span>
    std<span class="token double-colon punctuation">::</span>ofstream <span class="token function">outfile</span><span class="token punctuation">(</span><span class="token string">"model/mlp.engine"</span><span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>ios<span class="token double-colon punctuation">::</span>binary<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">assert</span><span class="token punctuation">(</span>outfile<span class="token punctuation">.</span><span class="token function">is_open</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token string">"Failed to open file for writing"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    outfile<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">char</span> <span class="token operator">*</span><span class="token punctuation">)</span>serialized_engine<span class="token operator">-&gt;</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> serialized_engine<span class="token operator">-&gt;</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
    <span class="token comment">// ====== 6. 释放资源 ======</span>
    <span class="token comment">// 理论上，这些资源都会在程序结束时自动释放，但是为了演示，这里手动释放部分</span>
    outfile<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">delete</span> serialized_engine<span class="token punctuation">;</span>
    <span class="token keyword">delete</span> engine<span class="token punctuation">;</span>
    <span class="token keyword">delete</span> config<span class="token punctuation">;</span>
    <span class="token keyword">delete</span> network<span class="token punctuation">;</span>
    <span class="token keyword">delete</span> builder<span class="token punctuation">;</span>

    std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"engine文件生成成功！"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
    
    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3><a id="_518"></a>三、运行时阶段</h3> 
<blockquote> 
 <p>样例代码: <em><code>6.trt_basic/src/runtime.cu</code></em></p> 
</blockquote> 
<p>TensorRT运行时的最高层级接口是<code>runtime</code> 如下：</p> 
<pre><code class="prism language-cpp">nvinfer1<span class="token double-colon punctuation">::</span>IRuntime <span class="token operator">*</span>runtime <span class="token operator">=</span> nvinfer1<span class="token double-colon punctuation">::</span><span class="token function">createInferRuntime</span><span class="token punctuation">(</span>logger<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>当使用<code>runtime</code>时，你通常会执行以下步骤：</p> 
<ul><li>反序列化一个计划以创建一个<code>Engine</code>。</li><li>从引擎中创建一个<code>ExecutionContext</code>。</li></ul> 
<p>然后，重复进行：</p> 
<ul><li>为Inference填充输入缓冲区。</li><li>在<code>ExecutionContext</code>调用<code>enqueueV2()</code>来运行Inference</li></ul> 
<h4><a id="31_Engine_539"></a>3.1 反序列化并创建Engine</h4> 
<p>通过读取模型文件并反序列化，我们可以利用runtime生成<code>Engine</code>。如下：</p> 
<pre><code class="prism language-cpp">nvinfer1<span class="token double-colon punctuation">::</span>ICudaEngine <span class="token operator">*</span>engine <span class="token operator">=</span> runtime<span class="token operator">-&gt;</span><span class="token function">deserializeCudaEngine</span><span class="token punctuation">(</span>engine_data<span class="token punctuation">.</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> engine_data<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">nullptr</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><code>Engine</code>接口代表一个优化的模型。你可以查询<code>Engine</code>关于网络的输入和输出张量的信息，如：预期尺寸、数据类型、数据格式等。</p> 
<h4><a id="32_ExecutionContext_549"></a>3.2 创建一个ExecutionContext</h4> 
<p>有了Engine后我们需要创建<code>ExecutionContext</code> 以用于后面的推理执行。</p> 
<pre><code class="prism language-cpp">nvinfer1<span class="token double-colon punctuation">::</span>IExecutionContext <span class="token operator">*</span>context <span class="token operator">=</span> engine<span class="token operator">-&gt;</span><span class="token function">createExecutionContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>从<code>Engine</code>创建的<code>ExecutionContext</code>接口是调用推理的主要接口。<code>ExecutionContext</code>包含与特定调用相关的所有状态，因此你可以有多个与单个引擎相关的上下文，且并行运行它们，在这里我们暂不展开了解，仅做介绍。</p> 
<h4><a id="33__559"></a>3.3 为推理填充输入</h4> 
<p>我们首先创建CUDA Stream用于推理的执行。</p> 
<blockquote> 
 <p>stream 可以理解为一个任务队列，调用以 async 结尾的 api 时，是把任务加到队列，但执行是异步的，当有多个任务且互相没有依赖时可以创建多个 stream 分别用于不同的任务，任务直接的执行可以被 cuda driver 调度，这样某个任务做 memcpy时 另外一个任务可以执行计算任务，这样可以提高 gpu利用率。</p> 
</blockquote> 
<pre><code class="prism language-cpp">cudaStream_t stream <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span>
<span class="token comment">// 创建CUDA Stream用于context推理</span>
<span class="token function">cudaStreamCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stream<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>然后我们同时在CPU和GPU上分配输入输出内存，并将输入数据从CPU拷贝到GPU上。</p> 
<pre><code class="prism language-cpp"><span class="token comment">// 输入数据</span>
<span class="token keyword">float</span><span class="token operator">*</span> h_in_data <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token keyword">float</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span><span class="token number">1.4</span><span class="token punctuation">,</span> <span class="token number">3.2</span><span class="token punctuation">,</span> <span class="token number">1.1</span><span class="token punctuation">}</span><span class="token punctuation">;</span>
<span class="token keyword">int</span> in_data_size <span class="token operator">=</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">;</span>
<span class="token keyword">float</span><span class="token operator">*</span> d_in_data <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span>
<span class="token comment">// 输出数据</span>
<span class="token keyword">float</span><span class="token operator">*</span> h_out_data <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token keyword">float</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">}</span><span class="token punctuation">;</span>
<span class="token keyword">int</span> out_data_size <span class="token operator">=</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">;</span>
<span class="token keyword">float</span><span class="token operator">*</span> d_out_data <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span>
<span class="token comment">// 申请GPU上的内存</span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_in_data<span class="token punctuation">,</span> in_data_size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_out_data<span class="token punctuation">,</span> out_data_size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 拷贝数据</span>
<span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>d_in_data<span class="token punctuation">,</span> h_in_data<span class="token punctuation">,</span> in_data_size<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">,</span> stream<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// enqueueV2中是把输入输出的内存地址放到bindings这个数组中，需要写代码时确定这些输入输出的顺序（这样容易出错，而且不好定位bug，所以新的接口取消了这样的方式，不过目前很多官方 sample 也在用v2）</span>
<span class="token keyword">float</span><span class="token operator">*</span> bindings<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>d_in_data<span class="token punctuation">,</span> d_out_data<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="34_enqueueV2_591"></a>3.4 调用enqueueV2来执行推理</h4> 
<p>将数据从CPU中拷贝到GPU上后，便可以调用<code>enqueueV2</code> 进行推理。代码如下：</p> 
<pre><code class="prism language-cpp"><span class="token comment">// 执行推理</span>
<span class="token keyword">bool</span> success <span class="token operator">=</span> context<span class="token operator">-&gt;</span><span class="token function">enqueueV2</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span>bindings<span class="token punctuation">,</span> stream<span class="token punctuation">,</span> <span class="token keyword">nullptr</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 把数据从GPU拷贝回host</span>
<span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>h_out_data<span class="token punctuation">,</span> d_out_data<span class="token punctuation">,</span> out_data_size<span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">,</span> stream<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// stream同步，等待stream中的操作完成</span>
<span class="token function">cudaStreamSynchronize</span><span class="token punctuation">(</span>stream<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 输出</span>
std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"输出信息: "</span> <span class="token operator">&lt;&lt;</span> host_output_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> <span class="token string">" "</span> <span class="token operator">&lt;&lt;</span> host_output_data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="35__606"></a>3.5 释放资源</h4> 
<pre><code class="prism language-cpp"><span class="token function">cudaStreamDestroy</span><span class="token punctuation">(</span>stream<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaFree</span><span class="token punctuation">(</span>device_input_data_address<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaFree</span><span class="token punctuation">(</span>device_output_data_address<span class="token punctuation">)</span><span class="token punctuation">;</span>   
<span class="token keyword">delete</span><span class="token punctuation">[</span><span class="token punctuation">]</span> host_input_data<span class="token punctuation">;</span>
<span class="token keyword">delete</span><span class="token punctuation">[</span><span class="token punctuation">]</span> host_output_data<span class="token punctuation">;</span>

<span class="token keyword">delete</span> context<span class="token punctuation">;</span>
<span class="token keyword">delete</span> engine<span class="token punctuation">;</span>
<span class="token keyword">delete</span> runtime<span class="token punctuation">;</span>
</code></pre> 
<p><strong>runtime.cu 的全部代码：</strong></p> 
<pre><code class="prism language-cpp"><span class="token comment">/*
使用.cu是希望使用CUDA的编译器NVCC，会自动连接cuda库

TensorRT runtime 推理过程

1. 创建一个runtime对象
2. 反序列化生成engine：runtime ---&gt; engine
3. 创建一个执行上下文ExecutionContext：engine ---&gt; context

    4. 填充数据
    5. 执行推理：context ---&gt; enqueueV2

6. 释放资源：delete

*/</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;iostream&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;vector&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;fstream&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;cassert&gt;</span></span>

<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"cuda_runtime.h"</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"NvInfer.h"</span></span>

<span class="token comment">// logger用来管控打印日志级别</span>
<span class="token comment">// TRTLogger继承自nvinfer1::ILogger</span>
<span class="token keyword">class</span> <span class="token class-name">TRTLogger</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> nvinfer1<span class="token double-colon punctuation">::</span><span class="token class-name">ILogger</span></span>
<span class="token punctuation">{<!-- --></span>
    <span class="token keyword">void</span> <span class="token function">log</span><span class="token punctuation">(</span>Severity severity<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">char</span> <span class="token operator">*</span>msg<span class="token punctuation">)</span> <span class="token keyword">noexcept</span> <span class="token keyword">override</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token comment">// 屏蔽INFO级别的日志</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>severity <span class="token operator">!=</span> Severity<span class="token double-colon punctuation">::</span>kINFO<span class="token punctuation">)</span>
            std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> msg <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span> gLogger<span class="token punctuation">;</span>

<span class="token comment">// 加载模型</span>
std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span><span class="token operator">&gt;</span> <span class="token function">loadEngineModel</span><span class="token punctuation">(</span><span class="token keyword">const</span> std<span class="token double-colon punctuation">::</span>string <span class="token operator">&amp;</span>fileName<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    std<span class="token double-colon punctuation">::</span>ifstream <span class="token function">file</span><span class="token punctuation">(</span>fileName<span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>ios<span class="token double-colon punctuation">::</span>binary<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">// 以二进制方式读取</span>
    <span class="token function">assert</span><span class="token punctuation">(</span>file<span class="token punctuation">.</span><span class="token function">is_open</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token string">"load engine model failed!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 断言</span>

    file<span class="token punctuation">.</span><span class="token function">seekg</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>ios<span class="token double-colon punctuation">::</span>end<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 定位到文件末尾</span>
    size_t size <span class="token operator">=</span> file<span class="token punctuation">.</span><span class="token function">tellg</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment">// 获取文件大小</span>

    std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span><span class="token operator">&gt;</span> <span class="token function">data</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 创建一个vector，大小为size</span>
    file<span class="token punctuation">.</span><span class="token function">seekg</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>ios<span class="token double-colon punctuation">::</span>beg<span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token comment">// 定位到文件开头</span>
    file<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">char</span> <span class="token operator">*</span><span class="token punctuation">)</span>data<span class="token punctuation">.</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 读取文件内容到data中</span>
    file<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">return</span> data<span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    <span class="token comment">// ==================== 1. 创建一个runtime对象 ====================</span>
    TRTLogger logger<span class="token punctuation">;</span>
    nvinfer1<span class="token double-colon punctuation">::</span>IRuntime <span class="token operator">*</span>runtime <span class="token operator">=</span> nvinfer1<span class="token double-colon punctuation">::</span><span class="token function">createInferRuntime</span><span class="token punctuation">(</span>logger<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// ==================== 2. 反序列化生成engine ====================</span>
    <span class="token comment">// 读取文件</span>
    <span class="token keyword">auto</span> engineModel <span class="token operator">=</span> <span class="token function">loadEngineModel</span><span class="token punctuation">(</span><span class="token string">"./model/mlp.engine"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 调用runtime的反序列化方法，生成engine，参数分别是：模型数据地址，模型大小，pluginFactory</span>
    nvinfer1<span class="token double-colon punctuation">::</span>ICudaEngine <span class="token operator">*</span>engine <span class="token operator">=</span> runtime<span class="token operator">-&gt;</span><span class="token function">deserializeCudaEngine</span><span class="token punctuation">(</span>engineModel<span class="token punctuation">.</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> engineModel<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">nullptr</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>engine<span class="token punctuation">)</span>
    <span class="token punctuation">{<!-- --></span>
        std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"deserialize engine failed!"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">// ==================== 3. 创建一个执行上下文 ====================</span>
    nvinfer1<span class="token double-colon punctuation">::</span>IExecutionContext <span class="token operator">*</span>context <span class="token operator">=</span> engine<span class="token operator">-&gt;</span><span class="token function">createExecutionContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// ==================== 4. 填充数据 ====================</span>

    <span class="token comment">// 设置stream 流</span>
    cudaStream_t stream <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span>
    <span class="token function">cudaStreamCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stream<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 数据流转：host --&gt; device ---&gt; inference ---&gt; host</span>

    <span class="token comment">// 输入数据</span>
    <span class="token keyword">float</span> <span class="token operator">*</span>host_input_data <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token keyword">float</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">}</span><span class="token punctuation">;</span> <span class="token comment">// host 输入数据</span>
    <span class="token keyword">int</span> input_data_size <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment">// 输入数据大小</span>
    <span class="token keyword">float</span> <span class="token operator">*</span>device_input_data <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span>             <span class="token comment">// device 输入数据</span>

    <span class="token comment">// 输出数据</span>
    <span class="token keyword">float</span> <span class="token operator">*</span>host_output_data <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token keyword">float</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">{<!-- --></span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">}</span><span class="token punctuation">;</span> <span class="token comment">// host 输出数据</span>
    <span class="token keyword">int</span> output_data_size <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment">// 输出数据大小</span>
    <span class="token keyword">float</span> <span class="token operator">*</span>device_output_data <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span>          <span class="token comment">// device 输出数据</span>

    <span class="token comment">// 申请device内存</span>
    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>device_input_data<span class="token punctuation">,</span> input_data_size<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>device_output_data<span class="token punctuation">,</span> output_data_size<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// host --&gt; device</span>
    <span class="token comment">// 参数分别是：目标地址，源地址，数据大小，拷贝方向</span>
    <span class="token comment">// 使用异步拷贝，提高利用率</span>
    <span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>device_input_data<span class="token punctuation">,</span> host_input_data<span class="token punctuation">,</span> input_data_size<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">,</span> stream<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// bindings告诉Context输入输出数据的位置</span>
    <span class="token keyword">float</span> <span class="token operator">*</span>bindings<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>device_input_data<span class="token punctuation">,</span> device_output_data<span class="token punctuation">}</span><span class="token punctuation">;</span>

    <span class="token comment">// ==================== 5. 执行推理 ====================</span>
    <span class="token keyword">bool</span> success <span class="token operator">=</span> context <span class="token operator">-&gt;</span> <span class="token function">enqueueV2</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span> bindings<span class="token punctuation">,</span> stream<span class="token punctuation">,</span> <span class="token keyword">nullptr</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 数据从device --&gt; host</span>
    <span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>host_output_data<span class="token punctuation">,</span> device_output_data<span class="token punctuation">,</span> output_data_size<span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">,</span> stream<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 等待流执行完毕</span>
    <span class="token function">cudaStreamSynchronize</span><span class="token punctuation">(</span>stream<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 输出结果</span>
    std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"输出结果: "</span> <span class="token operator">&lt;&lt;</span> host_output_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> <span class="token string">" "</span> <span class="token operator">&lt;&lt;</span> host_output_data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>

    <span class="token comment">// ==================== 6. 释放资源 ====================</span>
    <span class="token function">cudaStreamDestroy</span><span class="token punctuation">(</span>stream<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaFree</span><span class="token punctuation">(</span>device_input_data<span class="token punctuation">)</span><span class="token punctuation">;</span> 
    <span class="token function">cudaFree</span><span class="token punctuation">(</span>device_output_data<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">delete</span> host_input_data<span class="token punctuation">;</span>
    <span class="token keyword">delete</span> host_output_data<span class="token punctuation">;</span>

    <span class="token keyword">delete</span> context<span class="token punctuation">;</span>
    <span class="token keyword">delete</span> engine<span class="token punctuation">;</span>
    <span class="token keyword">delete</span> runtime<span class="token punctuation">;</span>
    
    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3><a id="_749"></a>四、编译和运行</h3> 
<blockquote> 
 <p>样例代码: <em><code>6.trt_basic/CMakeLists.txt</code></em></p> 
</blockquote> 
<p>利用我们前面cmake课程介绍的添加自定义模块的方法，创建<code>cmake/FindTensorRT.cmake</code>文件，我们运行下面的命令以编译示例代码：</p> 
<pre><code class="prism language-bash">cmake <span class="token parameter variable">-S</span> <span class="token builtin class-name">.</span> <span class="token parameter variable">-B</span> build 
cmake <span class="token parameter variable">--build</span> build
</code></pre> 
<p>然后执行下面命令，build将生成mlp.engine，而runtime将读取mlp.engine并执行：</p> 
<pre><code class="prism language-bash">./build/build
./build/runtime
</code></pre> 
<p>最后将看到输出结果：</p> 
<pre><code class="prism language-bash">输出信息: <span class="token number">0.970688</span> <span class="token number">0.999697</span>
</code></pre> 
<p><font color="red"><strong>备注：这篇博客为修改过后的转载，因为没有转载链接，所以选了原创</strong></font></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b7b970a8e8a5e8e6cc3040829b9441b4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">k8s探针</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/93db09936e3fb8f7eb423b00e9069074/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">为pixhawk4添加外置adis16470传感器</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>