<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>神经网络与深度学习（七）循环神经网络（3）LSTM的记忆能力实验 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="神经网络与深度学习（七）循环神经网络（3）LSTM的记忆能力实验" />
<meta property="og:description" content="目录
6.3 LSTM的记忆能力实验
6.3.1 模型构建
6.3.1.1 LSTM层
6.3.1.2 模型汇总 6.3.2 模型训练 6.3.2.1 训练指定长度的数字预测模型 6.3.2.2 多组训练 6.3.2.3 损失曲线展示 【思考题1】LSTM与SRN实验结果对比，谈谈看法。
6.3.3 模型评价 6.3.3.1 在测试集上进行模型评价 6.3.3.2 模型在不同长度的数据集上的准确率变化图 【思考题2】LSTM与SRN在不同长度数据集上的准确度对比，谈谈看法。 6.3.3.3 LSTM模型门状态和单元状态的变化 【思考题3】分析LSTM中单元状态和门数值的变化图，并用自己的话解释该图。 总结RNN
参考资料
使用LSTM模型重新进行数字求和实验，验证LSTM模型的长程依赖能力。 6.3 LSTM的记忆能力实验 长短期记忆网络（Long Short-Term Memory Network，LSTM）是一种可以有效缓解长程依赖问题的循环神经网络．LSTM 的特点是引入了一个新的内部状态（Internal State）和门控机制（Gating Mechanism）．不同时刻的内部状态以近似线性的方式进行传递，从而缓解梯度消失或梯度爆炸问题．同时门控机制进行信息筛选，可以有效地增加记忆能力．例如，输入门可以让网络忽略无关紧要的输入信息，遗忘门可以使得网络保留有用的历史信息．在上一节的数字求和任务中，如果模型能够记住前两个非零数字，同时忽略掉一些不重要的干扰信息，那么即时序列很长，模型也有效地进行预测.
LSTM 模型在第步时，循环单元的内部结构如下图所示． 假设一组输入序列为，其中为批大小，为序列长度，为输入特征维度，LSTM从从左到右依次扫描序列，并通过循环单元计算更新每一时刻的状态内部状态和输出状态。
具体计算分为三步：
1）计算三个“门”
在时刻，LSTM的循环单元将当前时刻的输入与上一时刻的输出状态，计算一组输入门、遗忘门和输出门，其计算公式为
其中,,为可学习的参数，表示Logistic函数，将“门”的取值控制在(0,1)区间。这里的“门”都是个样本组成的矩阵，每一行为一个样本的“门”向量。
2）计算内部状态
首先计算候选内部状态：
其中,,为可学习的参数。
使用遗忘门和输入门，计算时刻tt的内部状态：
其中⊙为逐元素积。
3）计算输出状态
当前LSTM单元状态（候选状态）的计算公式为:
LSTM单元状态向量和的计算公式为
LSTM循环单元结构的输入是时刻内部状态向量和隐状态向量，输出是当前时刻tt的状态向量和隐状态向量。通过LSTM循环单元，整个网络可以建立较长距离的时序依赖关系。
通过学习这些门的设置，LSTM可以选择性地忽略或者强化当前的记忆或是输入信息，帮助网络更好地学习长句子的语义信息。
在本节中，我们使用LSTM模型重新进行数字求和实验，验证LSTM模型的长程依赖能力。
6.3.1 模型构建 在本实验中，我们将使用第6.1.2.4节中定义Model_RNN4SeqClass模型，并构建 LSTM 算子．只需要实例化 LSTM 算，并传入Model_RNN4SeqClass模型，就可以用 LSTM 进行数字求和实验
6.3.1.1 LSTM层 LSTM层的代码与SRN层结构相似，只是在SRN层的基础上增加了内部状态、输入门、遗忘门和输出门的定义和计算。这里LSTM层的输出也依然为序列的最后一个位置的隐状态向量。代码实现如下： import torch import torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/1f28991c78bf02454dc30cc42ce7e92d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-02T14:56:27+08:00" />
<meta property="article:modified_time" content="2022-12-02T14:56:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">神经网络与深度学习（七）循环神经网络（3）LSTM的记忆能力实验</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="6.3%C2%A0LSTM%E7%9A%84%E8%AE%B0%E5%BF%86%E8%83%BD%E5%8A%9B%E5%AE%9E%E9%AA%8C-toc" style="margin-left:0px;"><a href="#6.3%C2%A0LSTM%E7%9A%84%E8%AE%B0%E5%BF%86%E8%83%BD%E5%8A%9B%E5%AE%9E%E9%AA%8C" rel="nofollow">6.3 LSTM的记忆能力实验</a></p> 
<p id="631-模型构建-toc" style="margin-left:40px;"><a href="#631-%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA" rel="nofollow">6.3.1 模型构建</a></p> 
<p id="6.3.1.1%20LSTM%E5%B1%82-toc" style="margin-left:80px;"><a href="#6.3.1.1%20LSTM%E5%B1%82" rel="nofollow">6.3.1.1 LSTM层</a></p> 
<p id="6.3.1.2%20%E6%A8%A1%E5%9E%8B%E6%B1%87%E6%80%BB%C2%A0-toc" style="margin-left:80px;"><a href="#6.3.1.2%20%E6%A8%A1%E5%9E%8B%E6%B1%87%E6%80%BB%C2%A0" rel="nofollow">6.3.1.2 模型汇总 </a></p> 
<p id="6.3.2%20%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%C2%A0%C2%A0-toc" style="margin-left:40px;"><a href="#6.3.2%20%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%C2%A0%C2%A0" rel="nofollow">6.3.2 模型训练  </a></p> 
<p id="6.3.2.1%20%E8%AE%AD%E7%BB%83%E6%8C%87%E5%AE%9A%E9%95%BF%E5%BA%A6%E7%9A%84%E6%95%B0%E5%AD%97%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B%C2%A0-toc" style="margin-left:80px;"><a href="#6.3.2.1%20%E8%AE%AD%E7%BB%83%E6%8C%87%E5%AE%9A%E9%95%BF%E5%BA%A6%E7%9A%84%E6%95%B0%E5%AD%97%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B%C2%A0" rel="nofollow">6.3.2.1 训练指定长度的数字预测模型 </a></p> 
<p id="6.3.2.2%20%E5%A4%9A%E7%BB%84%E8%AE%AD%E7%BB%83%C2%A0-toc" style="margin-left:80px;"><a href="#6.3.2.2%20%E5%A4%9A%E7%BB%84%E8%AE%AD%E7%BB%83%C2%A0" rel="nofollow">6.3.2.2 多组训练 </a></p> 
<p id="6.3.2.3%20%E6%8D%9F%E5%A4%B1%E6%9B%B2%E7%BA%BF%E5%B1%95%E7%A4%BA%C2%A0-toc" style="margin-left:80px;"><a href="#6.3.2.3%20%E6%8D%9F%E5%A4%B1%E6%9B%B2%E7%BA%BF%E5%B1%95%E7%A4%BA%C2%A0" rel="nofollow">6.3.2.3 损失曲线展示 </a></p> 
<p id="%E3%80%90%E6%80%9D%E8%80%83%E9%A2%981%E3%80%91LSTM%E4%B8%8ESRN%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E5%AF%B9%E6%AF%94%EF%BC%8C%E8%B0%88%E8%B0%88%E7%9C%8B%E6%B3%95%E3%80%82-toc" style="margin-left:80px;"><a href="#%E3%80%90%E6%80%9D%E8%80%83%E9%A2%981%E3%80%91LSTM%E4%B8%8ESRN%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E5%AF%B9%E6%AF%94%EF%BC%8C%E8%B0%88%E8%B0%88%E7%9C%8B%E6%B3%95%E3%80%82" rel="nofollow">【思考题1】LSTM与SRN实验结果对比，谈谈看法。</a></p> 
<p id="6.3.3%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%C2%A0-toc" style="margin-left:40px;"><a href="#6.3.3%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%C2%A0" rel="nofollow">6.3.3 模型评价 </a></p> 
<p id="6.3.3.1%20%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%C2%A0-toc" style="margin-left:80px;"><a href="#6.3.3.1%20%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%C2%A0" rel="nofollow">6.3.3.1 在测试集上进行模型评价 </a></p> 
<p id="6.3.3.2%20%E6%A8%A1%E5%9E%8B%E5%9C%A8%E4%B8%8D%E5%90%8C%E9%95%BF%E5%BA%A6%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87%E5%8F%98%E5%8C%96%E5%9B%BE%C2%A0-toc" style="margin-left:80px;"><a href="#6.3.3.2%20%E6%A8%A1%E5%9E%8B%E5%9C%A8%E4%B8%8D%E5%90%8C%E9%95%BF%E5%BA%A6%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87%E5%8F%98%E5%8C%96%E5%9B%BE%C2%A0" rel="nofollow">6.3.3.2 模型在不同长度的数据集上的准确率变化图 </a></p> 
<p id="%E3%80%90%E6%80%9D%E8%80%83%E9%A2%982%E3%80%91LSTM%E4%B8%8ESRN%E5%9C%A8%E4%B8%8D%E5%90%8C%E9%95%BF%E5%BA%A6%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%87%86%E7%A1%AE%E5%BA%A6%E5%AF%B9%E6%AF%94%EF%BC%8C%E8%B0%88%E8%B0%88%E7%9C%8B%E6%B3%95%E3%80%82%C2%A0-toc" style="margin-left:80px;"><a href="#%E3%80%90%E6%80%9D%E8%80%83%E9%A2%982%E3%80%91LSTM%E4%B8%8ESRN%E5%9C%A8%E4%B8%8D%E5%90%8C%E9%95%BF%E5%BA%A6%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%87%86%E7%A1%AE%E5%BA%A6%E5%AF%B9%E6%AF%94%EF%BC%8C%E8%B0%88%E8%B0%88%E7%9C%8B%E6%B3%95%E3%80%82%C2%A0" rel="nofollow">【思考题2】LSTM与SRN在不同长度数据集上的准确度对比，谈谈看法。 </a></p> 
<p id="6.3.3.3%20LSTM%E6%A8%A1%E5%9E%8B%E9%97%A8%E7%8A%B6%E6%80%81%E5%92%8C%E5%8D%95%E5%85%83%E7%8A%B6%E6%80%81%E7%9A%84%E5%8F%98%E5%8C%96%C2%A0-toc" style="margin-left:80px;"><a href="#6.3.3.3%20LSTM%E6%A8%A1%E5%9E%8B%E9%97%A8%E7%8A%B6%E6%80%81%E5%92%8C%E5%8D%95%E5%85%83%E7%8A%B6%E6%80%81%E7%9A%84%E5%8F%98%E5%8C%96%C2%A0" rel="nofollow">6.3.3.3 LSTM模型门状态和单元状态的变化 </a></p> 
<p id="%E3%80%90%E6%80%9D%E8%80%83%E9%A2%983%E3%80%91%E5%88%86%E6%9E%90LSTM%E4%B8%AD%E5%8D%95%E5%85%83%E7%8A%B6%E6%80%81%E5%92%8C%E9%97%A8%E6%95%B0%E5%80%BC%E7%9A%84%E5%8F%98%E5%8C%96%E5%9B%BE%EF%BC%8C%E5%B9%B6%E7%94%A8%E8%87%AA%E5%B7%B1%E7%9A%84%E8%AF%9D%E8%A7%A3%E9%87%8A%E8%AF%A5%E5%9B%BE%E3%80%82%C2%A0-toc" style="margin-left:80px;"><a href="#%E3%80%90%E6%80%9D%E8%80%83%E9%A2%983%E3%80%91%E5%88%86%E6%9E%90LSTM%E4%B8%AD%E5%8D%95%E5%85%83%E7%8A%B6%E6%80%81%E5%92%8C%E9%97%A8%E6%95%B0%E5%80%BC%E7%9A%84%E5%8F%98%E5%8C%96%E5%9B%BE%EF%BC%8C%E5%B9%B6%E7%94%A8%E8%87%AA%E5%B7%B1%E7%9A%84%E8%AF%9D%E8%A7%A3%E9%87%8A%E8%AF%A5%E5%9B%BE%E3%80%82%C2%A0" rel="nofollow">【思考题3】分析LSTM中单元状态和门数值的变化图，并用自己的话解释该图。 </a></p> 
<p id="%E6%80%BB%E7%BB%93RNN-toc" style="margin-left:0px;"><a href="#%E6%80%BB%E7%BB%93RNN" rel="nofollow">总结RNN</a></p> 
<p id="%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99-toc" style="margin-left:0px;"><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99" rel="nofollow">参考资料</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p>使用LSTM模型重新进行<strong>数字求和实验</strong>，验证LSTM模型的长程依赖能力。 </p> 
<h2 id="6.3%C2%A0LSTM%E7%9A%84%E8%AE%B0%E5%BF%86%E8%83%BD%E5%8A%9B%E5%AE%9E%E9%AA%8C">6.3 <a href="https://so.csdn.net/so/search?q=LSTM&amp;spm=1001.2101.3001.7020" title="LSTM">LSTM</a>的记忆能力实验</h2> 
<p>长短期记忆网络（Long Short-Term Memory Network，LSTM）是一种可以有效缓解长程依赖问题的循环神经网络．LSTM 的特点是引入了一个新的内部状态（Internal State）<img alt="c\in \mathbb{R} ^{D}" class="mathcode" src="https://images2.imgbox.com/2b/91/FzQxtHs1_o.png">和门控机制（Gating Mechanism）．不同时刻的内部状态以近似线性的方式进行传递，从而缓解梯度消失或梯度爆炸问题．同时门控机制进行信息筛选，可以有效地增加记忆能力．例如，输入门可以让网络忽略无关紧要的输入信息，遗忘门可以使得网络保留有用的历史信息．在上一节的数字求和任务中，如果模型能够记住前两个非零数字，同时忽略掉一些不重要的干扰信息，那么即时序列很长，模型也有效地进行预测.</p> 
<p>LSTM 模型在第<img alt="t" class="mathcode" src="https://images2.imgbox.com/1f/3e/CbTB8GGN_o.png">步时，循环单元的内部结构如下图所示． </p> 
<p class="img-center"><img alt="" height="290" src="https://images2.imgbox.com/86/d7/SkLJup1K_o.png" width="657"></p> 
<p>假设一组输入序列为<img alt="X\in \mathbb{R} ^{B\times L\times M}" class="mathcode" src="https://images2.imgbox.com/b5/d6/LTOI4eFS_o.png">，其中<img alt="B" class="mathcode" src="https://images2.imgbox.com/06/93/7V7YXXqu_o.png">为批大小，<img alt="L" class="mathcode" src="https://images2.imgbox.com/96/11/LvY8BdCh_o.png">为序列长度，<img alt="M" class="mathcode" src="https://images2.imgbox.com/ad/a2/9WUxdnb5_o.png">为输入特征维度，LSTM从从左到右依次扫描序列，并通过循环单元计算更新每一时刻的状态内部状态<img alt="C_{t}\in \mathbb{R} ^{B\times D}" class="mathcode" src="https://images2.imgbox.com/2b/d3/leUuMF6n_o.png">和输出状态<img alt="H_{t}\in \mathbb{R} ^{B\times D}" class="mathcode" src="https://images2.imgbox.com/a1/bf/ePsotHAS_o.png">。</p> 
<p>具体计算分为三步：</p> 
<p><strong>1）计算三个“门”</strong></p> 
<p>在时刻<img alt="t" class="mathcode" src="https://images2.imgbox.com/3d/0f/dBijC5l3_o.png">，LSTM的循环单元将当前时刻的输入<img alt="X_{t}\in \mathbb{R} ^{B\times M}" class="mathcode" src="https://images2.imgbox.com/b5/49/vEKeTeaT_o.png">与上一时刻的输出状态<img alt="H_{t-1}\in \mathbb{R} ^{B\times D}" class="mathcode" src="https://images2.imgbox.com/aa/d4/ngfC7uh1_o.png">，计算一组输入门<img alt="I_{t}" class="mathcode" src="https://images2.imgbox.com/9a/79/XiLdUjRI_o.png">、遗忘门<img alt="F_{t}" class="mathcode" src="https://images2.imgbox.com/80/1c/MT65sJyX_o.png">和输出门<img alt="O_{t}" class="mathcode" src="https://images2.imgbox.com/4d/25/crGRw3g8_o.png">，其计算公式为</p> 
<p style="text-align:center;"><img alt="I_{t}=\sigma (X_{t}W_{i}+H_{t-1}U_{i}+b_{i})\in \mathbb{\mathbb{R}^{B\times D}, }" class="mathcode" src="https://images2.imgbox.com/8b/0b/pgtY0k7X_o.png"></p> 
<p style="text-align:center;"><img alt="F_{t}=\sigma (X_{t}W_{f}+H_{t-1}U_{f}+b_{f})\in \mathbb{R}^{B\times D}," class="mathcode" src="https://images2.imgbox.com/d6/bd/foP0TxnM_o.png"></p> 
<p style="text-align:center;"><img alt="O_{t}=\sigma (X_{t}W_{o}+H_{t-1}U_{0}+b_{0})\in \mathbb{R}^{B\times D}," class="mathcode" src="https://images2.imgbox.com/2e/2a/XnqcvjEh_o.png"></p> 
<p>其中<img alt="W_{*}\in \mathbb{R} ^{M\times D}" class="mathcode" src="https://images2.imgbox.com/4c/9a/DVyYO0ds_o.png">,<img alt="U_{*}\in \mathbb{R} ^{D\times D}" class="mathcode" src="https://images2.imgbox.com/9c/5b/eRbbRnl7_o.png">,<img alt="b_{*}\in \mathbb{R} ^{D}" class="mathcode" src="https://images2.imgbox.com/3f/c4/mswtODnj_o.png">为可学习的参数，<img alt="\sigma" class="mathcode" src="https://images2.imgbox.com/80/47/8ZTUJwEL_o.png">表示Logistic函数，将“门”的取值控制在(0,1)区间。这里的“门”都是<img alt="B" class="mathcode" src="https://images2.imgbox.com/a4/86/0aQ6QsSv_o.png">个样本组成的矩阵，每一行为一个样本的“门”向量。</p> 
<p> <strong>2）计算内部状态</strong></p> 
<p>首先计算候选内部状态：</p> 
<p style="text-align:center;"><img alt="\tilde{C} _{t}=tanh(X_{t}W_{c}+H_{t-1}U_{c}+b_{c})\in \mathbb{R}^{B\times D}," class="mathcode" src="https://images2.imgbox.com/d1/92/iNovMktS_o.png"></p> 
<p>其中<img alt="W_{c}\in \mathbb{R}^{M\times D}" class="mathcode" src="https://images2.imgbox.com/53/f2/4fLsf9sS_o.png">,<img alt="U_{c}\in \mathbb{R}^{D\times D}" class="mathcode" src="https://images2.imgbox.com/78/90/C6IiLLdI_o.png">,<img alt="b_{c}\in \mathbb{R}^{D}" class="mathcode" src="https://images2.imgbox.com/2d/ad/O8tKTmOa_o.png">为可学习的参数。</p> 
<p>使用遗忘门和输入门，计算时刻tt的内部状态：</p> 
<p style="text-align:center;"><img alt="C_{t}=F_{t}\odot C_{t-1}+I_{t}\odot \tilde{C}_{t}" class="mathcode" src="https://images2.imgbox.com/e6/1d/AF7qr0Ju_o.png"></p> 
<p>其中⊙为逐元素积。</p> 
<p><strong>3）计算输出状态</strong></p> 
<p>当前LSTM单元状态（候选状态）的计算公式为:<br> LSTM单元状态向量<img alt="C_{t}" class="mathcode" src="https://images2.imgbox.com/65/da/nzaW2Zdr_o.png">和<img alt="H_{t}" class="mathcode" src="https://images2.imgbox.com/d0/6e/U8aizh7Q_o.png">的计算公式为</p> 
<p style="text-align:center;"><img alt="C_{t}=F_{t}\odot C_{t-1}+I_{t}\odot \tilde{C}_{t}" class="mathcode" src="https://images2.imgbox.com/c7/72/09TszvUA_o.png"></p> 
<p style="text-align:center;"><img alt="H_{t}=O_{t}\odot tanh(C_{t})" class="mathcode" src="https://images2.imgbox.com/c1/81/rTss0u70_o.png"></p> 
<p>LSTM循环单元结构的输入是<img alt="t-1" class="mathcode" src="https://images2.imgbox.com/27/b9/nsu1ZM2F_o.png">时刻内部状态向量<img alt="C_{t-1}\in \mathbb{R}^{B\times D}" class="mathcode" src="https://images2.imgbox.com/0f/da/o57dEMZi_o.png">和隐状态向量<img alt="H_{t-1}\in \mathbb{R}^{B\times D}" class="mathcode" src="https://images2.imgbox.com/d1/d6/X7IU0Wb2_o.png">，输出是当前时刻tt的状态向量<img alt="C_{t}\in \mathbb{R}^{B\times D}" class="mathcode" src="https://images2.imgbox.com/c3/68/94v5J5XC_o.png">和隐状态向量<img alt="H_{t}\in \mathbb{R}^{B\times D}" class="mathcode" src="https://images2.imgbox.com/54/6f/ydWTOd1i_o.png">。通过LSTM循环单元，整个网络可以建立较长距离的时序依赖关系。</p> 
<p>通过学习这些门的设置，LSTM可以选择性地忽略或者强化当前的记忆或是输入信息，帮助网络更好地学习长句子的语义信息。</p> 
<p>在本节中，我们使用LSTM模型重新进行数字求和实验，验证LSTM模型的长程依赖能力。</p> 
<h3 id="631-模型构建">6.3.1 模型构建</h3> 
<p>在本实验中，我们将使用第6.1.2.4节中定义Model_RNN4SeqClass模型，并构建 LSTM 算子．只需要实例化 LSTM 算，并传入Model_RNN4SeqClass模型，就可以用 LSTM 进行数字求和实验</p> 
<h4 id="6.3.1.1%20LSTM%E5%B1%82">6.3.1.1 LSTM层</h4> 
<p>LSTM层的代码与SRN层结构相似，只是在SRN层的基础上增加了内部状态、输入门、遗忘门和输出门的定义和计算。这里LSTM层的输出也依然为序列的最后一个位置的隐状态向量。代码实现如下： </p> 
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F


class LSTM(nn.Module):
    def __init__(self, input_size, hidden_size, Wi_attr=None, Wf_attr=None, Wo_attr=None, Wc_attr=None,
                 Ui_attr=None, Uf_attr=None, Uo_attr=None, Uc_attr=None, bi_attr=None, bf_attr=None,
                 bo_attr=None, bc_attr=None):
        super(LSTM, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        W_i = torch.randn([input_size, hidden_size])
        W_f = torch.randn([input_size, hidden_size])
        W_o = torch.randn([input_size, hidden_size])
        W_c = torch.randn([input_size, hidden_size])
        U_i = torch.randn([hidden_size, hidden_size])
        U_f = torch.randn([hidden_size, hidden_size])
        U_o = torch.randn([hidden_size, hidden_size])
        U_c = torch.randn([hidden_size, hidden_size])
        b_i = torch.randn([1, hidden_size])
        b_f = torch.randn([1, hidden_size])
        b_o = torch.randn([1, hidden_size])
        b_c = torch.randn([1, hidden_size])
        self.W_i = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(W_i, dtype=torch.float32), gain=1.0))
        # 初始化模型参数
        self.W_f = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(W_f, dtype=torch.float32), gain=1.0))
        self.W_o = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(W_o, dtype=torch.float32), gain=1.0))
        self.W_c = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(W_c, dtype=torch.float32), gain=1.0))
        self.U_i = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(U_i, dtype=torch.float32), gain=1.0))
        self.U_f = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(U_f, dtype=torch.float32), gain=1.0))
        self.U_o = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(U_o, dtype=torch.float32), gain=1.0))
        self.U_c = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(U_c, dtype=torch.float32), gain=1.0))
        self.b_i = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(b_i, dtype=torch.float32), gain=1.0))
        self.b_f = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(b_f, dtype=torch.float32), gain=1.0))
        self.b_o = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(b_o, dtype=torch.float32), gain=1.0))
        self.b_c = torch.nn.Parameter(torch.nn.init.xavier_uniform_(torch.as_tensor(b_c, dtype=torch.float32), gain=1.0))

    # 初始化状态向量和隐状态向量
    def init_state(self, batch_size):
        hidden_state = torch.zeros([batch_size, self.hidden_size])
        cell_state = torch.zeros([batch_size, self.hidden_size])
        return hidden_state, cell_state

    # 定义前向计算
    def forward(self, inputs, states=None):
        # inputs: 输入数据，其shape为batch_size x seq_len x input_size
        batch_size, seq_len, input_size = inputs.shape

        # 初始化起始的单元状态和隐状态向量，其shape为batch_size x hidden_size
        if states is None:
            states = self.init_state(batch_size)
        hidden_state, cell_state = states

        # 执行LSTM计算，包括：输入门、遗忘门和输出门、候选内部状态、内部状态和隐状态向量
        for step in range(seq_len):
            # 获取当前时刻的输入数据step_input: 其shape为batch_size x input_size
            step_input = inputs[:, step, :]
            # 计算输入门, 遗忘门和输出门, 其shape为：batch_size x hidden_size
            I_gate = F.sigmoid(torch.matmul(step_input, self.W_i) + torch.matmul(hidden_state, self.U_i) + self.b_i)
            F_gate = F.sigmoid(torch.matmul(step_input, self.W_f) + torch.matmul(hidden_state, self.U_f) + self.b_f)
            O_gate = F.sigmoid(torch.matmul(step_input, self.W_o) + torch.matmul(hidden_state, self.U_o) + self.b_o)
            # 计算候选状态向量, 其shape为：batch_size x hidden_size
            C_tilde = F.tanh(torch.matmul(step_input, self.W_c) + torch.matmul(hidden_state, self.U_c) + self.b_c)
            # 计算单元状态向量, 其shape为：batch_size x hidden_size
            cell_state = F_gate * cell_state + I_gate * C_tilde
            # 计算隐状态向量，其shape为：batch_size x hidden_size
            hidden_state = O_gate * F.tanh(cell_state)

        return hidden_state
    
    
Wi_attr = torch.nn.Parameter(torch.tensor([[0.1, 0.2], [0.1, 0.2]]))
Wf_attr = torch.nn.Parameter(torch.tensor([[0.1, 0.2], [0.1, 0.2]]))
Wo_attr = torch.nn.Parameter(torch.tensor([[0.1, 0.2], [0.1, 0.2]]))
Wc_attr = torch.nn.Parameter(torch.tensor([[0.1, 0.2], [0.1, 0.2]]))
Ui_attr = torch.nn.Parameter(torch.tensor([[0.0, 0.1], [0.1, 0.0]]))
Uf_attr = torch.nn.Parameter(torch.tensor([[0.0, 0.1], [0.1, 0.0]]))
Uo_attr = torch.nn.Parameter(torch.tensor([[0.0, 0.1], [0.1, 0.0]]))
Uc_attr = torch.nn.Parameter(torch.tensor([[0.0, 0.1], [0.1, 0.0]]))
bi_attr = torch.nn.Parameter(torch.tensor([[0.1, 0.1]]))
bf_attr = torch.nn.Parameter(torch.tensor([[0.1, 0.1]]))
bo_attr = torch.nn.Parameter(torch.tensor([[0.1, 0.1]]))
bc_attr = torch.nn.Parameter(torch.tensor([[0.1, 0.1]]))

lstm = LSTM(2, 2, Wi_attr=Wi_attr, Wf_attr=Wf_attr, Wo_attr=Wo_attr, Wc_attr=Wc_attr,
                 Ui_attr=Ui_attr, Uf_attr=Uf_attr, Uo_attr=Uo_attr, Uc_attr=Uc_attr,
                 bi_attr=bi_attr, bf_attr=bf_attr, bo_attr=bo_attr, bc_attr=bc_attr)

inputs = torch.tensor([[[1, 0]]], dtype=torch.float32)
hidden_state = lstm(inputs)
print(hidden_state)</code></pre> 
<p>运行结果：</p> 
<p class="img-center"><img alt="" height="65" src="https://images2.imgbox.com/ed/90/iWkU8sOM_o.png" width="541"></p> 
<blockquote> 
 <p>在飞桨框架已经内置了LSTM的API <code>paddle.nn.LSTM</code>，其与自己实现的SRN不同点在于其实现时采用了两个偏置，同时矩阵相乘时参数在输入数据前面，如下公式所示：</p> 
 <p style="text-align:center;"><img alt="I_{t}=\sigma (W_{ii}X_{t}+b_{ii}+U_{hi}H_{t-1}+b_{hi})" class="mathcode" src="https://images2.imgbox.com/b0/13/6Z7qA6zh_o.png"></p> 
 <p style="text-align:center;"><img alt="F_{t}=\sigma (W_{if}X_{t}+b_{if}+U_{hf}H_{t-1}+b_{hf})" class="mathcode" src="https://images2.imgbox.com/96/cb/7QWXGhEu_o.png"></p> 
 <p style="text-align:center;"><img alt="O_{t}=\sigma (W_{io}X_{t}+b_{io}+U_{ho}H_{t-1}+b_{ho})" class="mathcode" src="https://images2.imgbox.com/50/52/6SzL7r8L_o.png"></p> 
 <p style="text-align:center;"> <img alt="\tilde{C} _{t}=tanh (W_{ic}X_{t}+b_{ic}+U_{hc}H_{t-1}+b_{hc})" class="mathcode" src="https://images2.imgbox.com/63/b5/fntu3wd8_o.png"></p> 
 <p style="text-align:center;"><img alt="C _{t}=F_{t}\cdot C_{t-1}+I_{t}\cdot \tilde{C}_{t}" class="mathcode" src="https://images2.imgbox.com/65/90/1zoJCrSN_o.png"></p> 
 <p style="text-align:center;"><img alt="H _{t}=O_{t}\cdot tanh(C_{t})" class="mathcode" src="https://images2.imgbox.com/81/fb/CmXrhQOd_o.png"></p> 
 <p>其中<img alt="W_{*}\in \mathbb{R} ^{M\times D}" class="mathcode" src="https://images2.imgbox.com/20/c2/W17b7MCH_o.png">,<img alt="U_{*}\in \mathbb{R} ^{D\times D}" class="mathcode" src="https://images2.imgbox.com/f3/76/FfdU4lnn_o.png">,<img alt="b_{i*}\in \mathbb{R} ^{1\times D}" class="mathcode" src="https://images2.imgbox.com/ec/d5/PXpGbu3O_o.png">,<img alt="b_{h*}\in \mathbb{R} ^{1\times D}" class="mathcode" src="https://images2.imgbox.com/3c/75/MmwFBro6_o.png">是可学习参数。</p> 
 <p>另外，在Paddle内置LSTM实现时，对于参数<img alt="W_{ii}" class="mathcode" src="https://images2.imgbox.com/be/47/qL1gZQ9m_o.png">,<img alt="W_{if}" class="mathcode" src="https://images2.imgbox.com/45/43/sr5cjz67_o.png">,<img alt="W_{io}" class="mathcode" src="https://images2.imgbox.com/0a/05/XugNE3Cl_o.png">,<img alt="W_{ic}" class="mathcode" src="https://images2.imgbox.com/66/c7/icFj235U_o.png">，并不是分别申请这些矩阵，而是申请了一个大的矩阵<img alt="W_{ih}" class="mathcode" src="https://images2.imgbox.com/6e/c3/n8GxQPYw_o.png">，将这个大的矩阵分割为4份，便可以得到<img alt="W_{ii}" class="mathcode" src="https://images2.imgbox.com/3c/11/gPfcGyrj_o.png">,<img alt="W_{if}" class="mathcode" src="https://images2.imgbox.com/4d/d5/r4CbtzDQ_o.png">,<img alt="W_{ic}" class="mathcode" src="https://images2.imgbox.com/ee/01/orD490sO_o.png">,<img alt="W_{io}" class="mathcode" src="https://images2.imgbox.com/36/07/Qhm7bhKn_o.png">。 同理，将会得到<img alt="W_{hh}" class="mathcode" src="https://images2.imgbox.com/ad/f6/vnTAZvzZ_o.png">,<img alt="b_{ih}" class="mathcode" src="https://images2.imgbox.com/c4/41/0j287qmI_o.png">和<img alt="b_{hh}" class="mathcode" src="https://images2.imgbox.com/db/88/GqPmKp7N_o.png">.</p> 
 <p>最后，Paddle内置LSTM API将会返回参数序列向量outputs和最后时刻的状态向量，其中序列向量outputs是指最后一层SRN的输出向量，其shape为[batch_size, seq_len, num_directions * hidden_size]；最后时刻的状态向量是个元组，其包含了两个向量，分别是隐状态向量和单元状态向量，其shape均为[num_layers * num_directions, batch_size, hidden_size]。</p> 
</blockquote> 
<p>这里我们可以将自己实现的SRN和torch框架内置的SRN返回的结果进行打印展示，实现代码如下。</p> 
<pre><code class="language-python">batch_size, seq_len, input_size = 8, 20, 32
inputs = torch.randn([batch_size, seq_len, input_size])

# 设置模型的hidden_size
hidden_size = 32
torch_lstm = nn.LSTM(input_size, hidden_size)
self_lstm = LSTM(input_size, hidden_size)

self_hidden_state = self_lstm(inputs)
torch_outputs, (torch_hidden_state, torch_cell_state) = torch_lstm(inputs)

print("self_lstm hidden_state: ", self_hidden_state.shape)
print("torch_lstm outpus:", torch_outputs.shape)
print("torch_lstm hidden_state:", torch_hidden_state.shape)
print("torch_lstm cell_state:", torch_cell_state.shape)</code></pre> 
<p>运行结果：</p> 
<p class="img-center"><img alt="" height="142" src="https://images2.imgbox.com/6d/fb/QAnMRfRK_o.png" width="495"></p> 
<p>在进行实验时，首先定义输入数据<code>inputs</code>，然后将该数据分别传入torch内置的LSTM与自己实现的LSTM模型中，最后通过对比两者的隐状态输出向量。代码实现如下：</p> 
<pre><code class="language-python">import torch
torch.manual_seed(0)

# 这里创建一个随机数组作为测试数据，数据shape为batch_size x seq_len x input_size
batch_size, seq_len, input_size, hidden_size = 2, 5, 10, 10
inputs = torch.randn([batch_size, seq_len, input_size])

# 设置模型的hidden_size
# bih_attr = torch.nn.Parameter(torch.tensor(torch.zeros([4*hidden_size, ])))
torch_lstm = nn.LSTM(input_size, hidden_size, bias=True)

# 获取torch_lstm中的参数，并设置相应的paramAttr,用于初始化lstm
print(torch_lstm.weight_ih_l0.T.shape)
chunked_W = torch.split(torch_lstm.weight_ih_l0.T, 4, dim=-1)
chunked_U = torch.split(torch_lstm.weight_hh_l0.T, 4, dim=-1)
chunked_b = torch.split(torch_lstm.bias_hh_l0.T, 4, dim=-1)

Wi_attr = torch.nn.Parameter(torch.tensor(chunked_W[0].clone().detach().requires_grad_(True)))
Wf_attr = torch.nn.Parameter(torch.tensor(chunked_W[1].clone().detach().requires_grad_(True)))
Wc_attr = torch.nn.Parameter(torch.tensor(chunked_W[2].clone().detach().requires_grad_(True)))
Wo_attr = torch.nn.Parameter(torch.tensor(chunked_W[3].clone().detach().requires_grad_(True)))
Ui_attr = torch.nn.Parameter(torch.tensor(chunked_U[0].clone().detach().requires_grad_(True)))
Uf_attr = torch.nn.Parameter(torch.tensor(chunked_U[1].clone().detach().requires_grad_(True)))
Uc_attr = torch.nn.Parameter(torch.tensor(chunked_U[2].clone().detach().requires_grad_(True)))
Uo_attr = torch.nn.Parameter(torch.tensor(chunked_U[3].clone().detach().requires_grad_(True)))
bi_attr = torch.nn.Parameter(torch.tensor(chunked_b[0].clone().detach().requires_grad_(True)))
bf_attr = torch.nn.Parameter(torch.tensor(chunked_b[1].clone().detach().requires_grad_(True)))
bc_attr = torch.nn.Parameter(torch.tensor(chunked_b[2].clone().detach().requires_grad_(True)))
bo_attr = torch.nn.Parameter(torch.tensor(chunked_b[3].clone().detach().requires_grad_(True)))
self_lstm = LSTM(input_size, hidden_size, Wi_attr=Wi_attr, Wf_attr=Wf_attr, Wo_attr=Wo_attr, Wc_attr=Wc_attr,
                 Ui_attr=Ui_attr, Uf_attr=Uf_attr, Uo_attr=Uo_attr, Uc_attr=Uc_attr,
                 bi_attr=bi_attr, bf_attr=bf_attr, bo_attr=bo_attr, bc_attr=bc_attr)

# 进行前向计算，获取隐状态向量，并打印展示
self_hidden_state = self_lstm(inputs)
torch_outputs, (torch_hidden_state, _) = torch_lstm(inputs)
print("torch SRN:\n", torch_hidden_state.detach().numpy().squeeze(0))
print("self SRN:\n", self_hidden_state.detach().numpy())
</code></pre> 
<p>运行结果：</p> 
<pre><code class="language-python">torch.Size([10, 40])
torch SRN:
 [[ 0.05112648  0.0069804  -0.03931074  0.08884123  0.1154766  -0.13408035
   0.16033086  0.00135597 -0.063761   -0.2974773 ]
 [ 0.11241535  0.07274596  0.36305282 -0.06277131  0.01287347 -0.15761302
   0.22385652  0.01972566 -0.35233897 -0.20609131]
 [ 0.13069034 -0.03020173 -0.06369952  0.13535677  0.34181935 -0.11440603
   0.10832833  0.04234035  0.08991402 -0.15160468]
 [ 0.0727646   0.15715013  0.06807105  0.07414021  0.3629469  -0.06236503
  -0.11784356  0.00420525 -0.1500205   0.08434851]
 [ 0.07962178  0.01809997 -0.02799227 -0.0978313  -0.08596172 -0.13848482
   0.06129254  0.15295173 -0.14451738 -0.11927365]]
self SRN:
 [[ 0.25522318 -0.26233613  0.579096    0.21594535 -0.04982951 -0.2876913
   0.04644723 -0.10902733  0.10669092  0.4416803 ]
 [ 0.1569139  -0.07310869 -0.01197558  0.04463004 -0.15551823 -0.04395698
   0.08646112 -0.24415644 -0.34958637  0.22522162]]</code></pre> 
<p>可以看到，两者的输出基本是一致的。另外，还可以进行对比两者在运算速度方面的差异。代码实现如下：</p> 
<pre><code class="language-python">import time

# 这里创建一个随机数组作为测试数据，数据shape为batch_size x seq_len x input_size
batch_size, seq_len, input_size = 8, 20, 32
inputs = torch.randn([batch_size, seq_len, input_size])

# 设置模型的hidden_size
hidden_size = 32
self_lstm = LSTM(input_size, hidden_size)
torch_lstm = nn.LSTM(input_size, hidden_size)

# 计算自己实现的SRN运算速度
model_time = 0
for i in range(100):
    strat_time = time.time()
    hidden_state = self_lstm(inputs)
    # 预热10次运算，不计入最终速度统计
    if i &lt; 10:
        continue
    end_time = time.time()
    model_time += (end_time - strat_time)
avg_model_time = model_time / 90
print('self_lstm speed:', avg_model_time, 's')

# 计算torch内置的SRN运算速度
model_time = 0
for i in range(100):
    strat_time = time.time()
    outputs, (hidden_state, cell_state) = torch_lstm(inputs)
    # 预热10次运算，不计入最终速度统计
    if i &lt; 10:
        continue
    end_time = time.time()
    model_time += (end_time - strat_time)
avg_model_time = model_time / 90
print('torch_lstm speed:', avg_model_time, 's')
</code></pre> 
<p>运行结果：</p> 
<p class="img-center"><img alt="" height="90" src="https://images2.imgbox.com/c4/47/4kOtgjgY_o.png" width="430"></p> 
<p>可以看到，torch框架内置的LSTM运行效率远远高于自己实现的LSTM。</p> 
<h4 id="6.3.1.2%20%E6%A8%A1%E5%9E%8B%E6%B1%87%E6%80%BB%C2%A0">6.3.1.2 模型汇总 </h4> 
<p>在本节实验中，我们将使用6.1.2.4的Model_RNN4SeqClass作为预测模型，不同在于在实例化时将传入实例化的LSTM层。 </p> 
<pre><code class="language-python"># 基于RNN实现数字预测的模型
class Model_RNN4SeqClass(nn.Module):
    def __init__(self, model, num_digits, input_size, hidden_size, num_classes):
        super(Model_RNN4SeqClass, self).__init__()
        # 传入实例化的RNN层，例如SRN
        self.rnn_model = model
        # 词典大小
        self.num_digits = num_digits
        # 嵌入向量的维度
        self.input_size = input_size
        # 定义Embedding层
        self.embedding = Embedding(num_digits, input_size)
        # 定义线性层
        self.linear = nn.Linear(hidden_size, num_classes)

    def forward(self, inputs):
        # 将数字序列映射为相应向量
        inputs_emb = self.embedding(inputs)
        # 调用RNN模型
        hidden_state = self.rnn_model(inputs_emb)
        # 使用最后一个时刻的状态进行数字预测
        logits = self.linear(hidden_state)
        return logits
</code></pre> 
<h3 id="6.3.2%20%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%C2%A0%C2%A0">6.3.2 模型训练  </h3> 
<h4 id="6.3.2.1%20%E8%AE%AD%E7%BB%83%E6%8C%87%E5%AE%9A%E9%95%BF%E5%BA%A6%E7%9A%84%E6%95%B0%E5%AD%97%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B%C2%A0">6.3.2.1 训练指定长度的数字预测模型 </h4> 
<p>本节将基于RunnerV3类进行训练，首先定义模型训练的超参数，并保证和简单循环网络的超参数一致. 然后定义一个<span style="color:#fe2c24;"><code><span style="background-color:#f3f3f4;">train</span></code></span>函数，其可以通过指定长度的数据集，并进行训练. 在<span style="color:#fe2c24;"><code><span style="background-color:#f3f3f4;">train</span></code></span>函数中，首先加载长度为<span style="color:#fe2c24;"><code><span style="background-color:#f3f3f4;">length</span></code></span>的数据，然后实例化各项组件并创建对应的Runner，然后训练该Runner。同时在本节将使用4.5.4节定义的准确度（Accuracy）作为评估指标，代码实现如下： </p> 
<pre><code class="language-python">import os
import random
import torch
from nndl import load_data
import numpy as np
# 训练轮次
num_epochs = 500
# 学习率
lr = 0.001
# 输入数字的类别数
num_digits = 10
# 将数字映射为向量的维度
input_size = 32
# 隐状态向量的维度
hidden_size = 32
# 预测数字的类别数
num_classes = 19
# 批大小
batch_size = 8
# 模型保存目录
save_dir = "./"

# 可以设置不同的length进行不同长度数据的预测实验
def train(length):
    print(f"\n====&gt; Training LSTM with data of length {length}.")
    np.random.seed(0)
    random.seed(0)
    torch.manual_seed(0)
    # 加载长度为length的数据
    data_path = f"D:/datasets/{length}"
    train_examples, dev_examples, test_examples = load_data(data_path)
    train_set, dev_set, test_set = DigitSumDataset(train_examples), DigitSumDataset(dev_examples), DigitSumDataset(test_examples)
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)
    dev_loader = torch.utils.data.DataLoader(dev_set, batch_size=batch_size)
    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)
    # 实例化模型
    base_model = LSTM(input_size, hidden_size)
    model = Model_RNN4SeqClass(base_model, num_digits, input_size, hidden_size, num_classes)
    # 指定优化器
    optimizer = torch.optim.Adam(lr=lr, params=model.parameters())
    # 定义评价指标
    metric = Accuracy()
    # 定义损失函数
    loss_fn = torch.nn.CrossEntropyLoss()
    # 基于以上组件，实例化Runner
    runner = RunnerV3(model, optimizer, loss_fn, metric)

    # 进行模型训练
    model_save_path = os.path.join(save_dir, f"best_lstm_model_{length}.pdparams")
    runner.train(train_loader, dev_loader, num_epochs=num_epochs, eval_steps=100, log_steps=100, save_path=model_save_path)

    return runner</code></pre> 
<h4 id="6.3.2.2%20%E5%A4%9A%E7%BB%84%E8%AE%AD%E7%BB%83%C2%A0">6.3.2.2 多组训练 </h4> 
<p>接下来，分别进行数据长度为10, 15, 20, 25, 30, 35的数字预测模型训练实验，训练后的<span style="color:#fe2c24;"><code><span style="background-color:#f3f3f4;">runner</span></code></span>保存至<span style="color:#fe2c24;"><code><span style="background-color:#f3f3f4;">runners</span></code></span>字典中。 </p> 
<pre><code class="language-python"># LSTM训练
lstm_runners = {}
lengths = [10, 15, 20, 25, 30, 35]
for length in lengths:
    runner = train(length)
    lstm_runners[length] = runner
</code></pre> 
<p>运行结果：</p> 
<p class="img-center"><img alt="" height="307" src="https://images2.imgbox.com/dd/af/qIuPTgaM_o.png" width="607"></p> 
<h4 id="6.3.2.3%20%E6%8D%9F%E5%A4%B1%E6%9B%B2%E7%BA%BF%E5%B1%95%E7%A4%BA%C2%A0">6.3.2.3 损失曲线展示 </h4> 
<p>分别画出基于LSTM的各个长度的数字预测模型训练过程中，在训练集和验证集上的损失曲线，代码实现如下：</p> 
<pre><code class="language-python"># # 画出训练过程中的损失图
for length in lengths:
    runner = lstm_runners[length]
    fig_name = f"D:/datasets/images/6.11_{length}.pdf"
    plot_training_loss(runner, fig_name, sample_step=100)
</code></pre> 
<p>下图展示了LSTM模型在不同长度数据集上进行训练后的损失变化，同SRN模型一样，随着序列长度的增加，训练集上的损失逐渐不稳定，验证集上的损失整体趋向于变大，这说明当序列长度增加时，保持长期依赖的能力同样在逐渐变弱. 同图6.5相比，LSTM模型在序列长度增加时，收敛情况比SRN模型更好。 </p> 
<p class="img-center"><img alt="" height="315" src="https://images2.imgbox.com/57/80/SHIQJbd4_o.png" width="645"></p> 
<h4 id="%E3%80%90%E6%80%9D%E8%80%83%E9%A2%981%E3%80%91LSTM%E4%B8%8ESRN%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E5%AF%B9%E6%AF%94%EF%BC%8C%E8%B0%88%E8%B0%88%E7%9C%8B%E6%B3%95%E3%80%82">【思考题1】LSTM与SRN实验结果对比，谈谈看法。</h4> 
<p>LSTM的效果要优于SRN，这是因为在SRN中会出现梯度消失问题。</p> 
<h3 id="6.3.3%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%C2%A0">6.3.3 模型评价 </h3> 
<h4 id="6.3.3.1%20%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%C2%A0">6.3.3.1 在测试集上进行模型评价 </h4> 
<p>使用测试数据对在训练过程中保存的最好模型进行评价，观察模型在测试集上的准确率. 同时获取模型在训练过程中在验证集上最好的准确率，实现代码如下:</p> 
<pre><code class="language-python">#lstm
lstm_dev_scores = []
lstm_test_scores = []
for length in lengths:
    print(f"Evaluate LSTM with data length {length}.")
    runner = lstm_runners[length]
    # 加载训练过程中效果最好的模型
    model_path = os.path.join(save_dir, f"best_lstm_model_{length}.pdparams")
    runner.load_model(model_path)

    # 加载长度为length的数据
    data_path = f"D:/datasets/{length}"
    train_examples, dev_examples, test_examples = load_data(data_path)
    test_set = DigitSumDataset(test_examples)
    test_loader = DataLoader(test_set, batch_size=batch_size)

    # 使用测试集评价模型，获取测试集上的预测准确率
    score, _ = runner.evaluate(test_loader)
    lstm_test_scores.append(score)
    lstm_dev_scores.append(max(runner.dev_scores))

for length, dev_score, test_score in zip(lengths, lstm_dev_scores, lstm_test_scores):
    print(f"[LSTM] length:{length}, dev_score: {dev_score}, test_score: {test_score: .5f}")

#训练SRN模型
srn_runners = {}
lengths = [10, 15, 20, 25, 30, 35]
for length in lengths:
    runner = train(length)
    srn_runners[length] = runner
srn_dev_scores = []
srn_test_scores = []
for length in lengths:
    print(f"Evaluate SRN with data length {length}.")
    runner = srn_runners[length]
    # 加载训练过程中效果最好的模型
    model_path = os.path.join(save_dir, f"best_srn_model_{length}.pdparams")
    runner.load_model(model_path)

    # 加载长度为length的数据
    data_path = f"D:/datasets/{length}"
    train_examples, dev_examples, test_examples = load_data(data_path)
    test_set = DigitSumDataset(test_examples)
    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)

    # 使用测试集评价模型，获取测试集上的预测准确率
    score, _ = runner.evaluate(test_loader)
    srn_test_scores.append(score)
    srn_dev_scores.append(max(runner.dev_scores))

for length, dev_score, test_score in zip(lengths, srn_dev_scores, srn_test_scores):
    print(f"[SRN] length:{length}, dev_score: {dev_score}, test_score: {test_score: .5f}")

</code></pre> 
<h4 id="6.3.3.2%20%E6%A8%A1%E5%9E%8B%E5%9C%A8%E4%B8%8D%E5%90%8C%E9%95%BF%E5%BA%A6%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87%E5%8F%98%E5%8C%96%E5%9B%BE%C2%A0">6.3.3.2 模型在不同长度的数据集上的准确率变化图 </h4> 
<p>接下来，将SRN和LSTM在不同长度的验证集和测试集数据上的准确率绘制成图片，以方面观察。</p> 
<pre><code class="language-python">#绘制全部图
import matplotlib.pyplot as plt

plt.plot(lengths, lstm_dev_scores, '-o', color='#e8609b',  label="LSTM Dev Accuracy")
plt.plot(lengths, lstm_test_scores,'-o', color='#000000', label="LSTM Test Accuracy")

#绘制坐标轴和图例
plt.ylabel("accuracy", fontsize='large')
plt.xlabel("sequence length", fontsize='large')
plt.legend(loc='lower left', fontsize='x-large')

fig_name = "D:/datasets/images/6.12.pdf"
plt.savefig(fig_name)
plt.show()
</code></pre> 
<p>下图展示了LSTM模型与SRN模型在不同长度数据集上的准确度对比。随着数据集长度的增加，LSTM模型在验证集和测试集上的准确率整体也趋向于降低；同时LSTM模型的准确率显著高于SRN模型，表明LSTM模型保持长期依赖的能力要优于SRN模型. </p> 
<p class="img-center"><img alt="" height="415" src="https://images2.imgbox.com/33/53/D6siBj1Y_o.png" width="599"></p> 
<h4 id="%E3%80%90%E6%80%9D%E8%80%83%E9%A2%982%E3%80%91LSTM%E4%B8%8ESRN%E5%9C%A8%E4%B8%8D%E5%90%8C%E9%95%BF%E5%BA%A6%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%87%86%E7%A1%AE%E5%BA%A6%E5%AF%B9%E6%AF%94%EF%BC%8C%E8%B0%88%E8%B0%88%E7%9C%8B%E6%B3%95%E3%80%82%C2%A0">【思考题2】LSTM与SRN在不同长度数据集上的准确度对比，谈谈看法。 </h4> 
<p>LSTM在不同长度数据集上存在波动，但是可以看出的是，LSTM在长度较大的数据集上表现的结果也不逊色。而SRN的准确度则是随着数据集长度的增加反而不断下降，造成这种问题的原因为SRN已经遗忘了之前的关键信息从而造成了准确率不断下降。</p> 
<h4 id="6.3.3.3%20LSTM%E6%A8%A1%E5%9E%8B%E9%97%A8%E7%8A%B6%E6%80%81%E5%92%8C%E5%8D%95%E5%85%83%E7%8A%B6%E6%80%81%E7%9A%84%E5%8F%98%E5%8C%96%C2%A0">6.3.3.3 LSTM模型门状态和单元状态的变化 </h4> 
<p>LSTM模型通过门控机制控制信息的单元状态的更新，这里可以观察当LSTM在处理一条数字序列的时候，相应门和单元状态是如何变化的。首先需要对以上LSTM模型实现代码中，定义相应列表进行存储这些门和单元状态在每个时刻的向量。</p> 
<pre><code class="language-python">import torch.nn.functional as F



# 实例化模型
model = LSTM(input_size, hidden_size)
model = Model_RNN4SeqClass(model, num_digits, input_size, hidden_size, num_classes)
# 指定优化器
lr = 0.001
optimizer = torch.optim.Adam(model.parameters(),lr)
# 定义评价指标
metric = Accuracy()
# 定义损失函数
loss_fn = torch.nn.CrossEntropyLoss()
# 基于以上组件，重新实例化Runner
runner = RunnerV3(model, optimizer, loss_fn, metric)

length = 10
# 加载训练过程中效果最好的模型
model_path = os.path.join(save_dir, f"best_lstm_model_{length}.pdparams")
runner.load_model(model_path)

import seaborn as sns

def plot_tensor(inputs, tensor,  save_path, vmin=0, vmax=1):
    import matplotlib.pyplot as plt
    tensor = np.stack(tensor, axis=0)
    tensor = np.squeeze(tensor, 1).T

    plt.figure(figsize=(16,6))
    # vmin, vmax定义了色彩图的上下界
    ax = sns.heatmap(tensor, vmin=vmin, vmax=vmax)
    ax.set_xticklabels(inputs)
    ax.figure.savefig(save_path)


# 定义模型输入
inputs = [6, 7, 0, 0, 1, 0, 0, 0, 0, 0]
X = torch.tensor(inputs.copy())
X = X.unsqueeze(0)
# 进行模型预测，并获取相应的预测结果
logits = runner.predict(X)
predict_label = torch.argmax(logits, dim=-1)
print(f"predict result: {predict_label.numpy()[0]}")
# 输入门
Is= runner.model.rnn_model.Is
plot_tensor(inputs, Is, save_path="D:/datasets/images/6.13_I.pdf")
# 遗忘门
Fs = runner.model.rnn_model.Fs
plot_tensor(inputs, Fs, save_path="D:/datasets/images/6.13_F.pdf")
# 输出门
Os = runner.model.rnn_model.Os
plot_tensor(inputs, Os, save_path="D:/datasets/images/6.13_O.pdf")
# 单元状态
Cs = runner.model.rnn_model.Cs
plot_tensor(inputs, Cs, save_path="D:/datasets/images/6.13_C.pdf", vmin=-5, vmax=5)
</code></pre> 
<p class="img-center"><img alt="" height="303" src="https://images2.imgbox.com/ae/a5/NEtHc6j6_o.png" width="622"></p> 
<h4 id="%E3%80%90%E6%80%9D%E8%80%83%E9%A2%983%E3%80%91%E5%88%86%E6%9E%90LSTM%E4%B8%AD%E5%8D%95%E5%85%83%E7%8A%B6%E6%80%81%E5%92%8C%E9%97%A8%E6%95%B0%E5%80%BC%E7%9A%84%E5%8F%98%E5%8C%96%E5%9B%BE%EF%BC%8C%E5%B9%B6%E7%94%A8%E8%87%AA%E5%B7%B1%E7%9A%84%E8%AF%9D%E8%A7%A3%E9%87%8A%E8%AF%A5%E5%9B%BE%E3%80%82%C2%A0">【思考题3】分析LSTM中单元状态和门数值的变化图，并用自己的话解释该图。 </h4> 
<p class="img-center"><img alt="" height="422" src="https://images2.imgbox.com/a1/19/gayg825W_o.png" width="1140"></p> 
<p>上图中横坐标为输入数字，纵坐标为相应门或单元状态向量的维度，颜色的深浅代表数值的大小。<br> 输入门我们可以看到当输入不同的数字时，我们保持了输入相对一致的大小。<br> 遗忘门我们可以看到，相对于输入，一部分维度开始变浅，说明我们对这部分维度进行了遗忘。<br> 输出门和单元状态我们可以看到在某些维度上数值变小，某些维度上数值变大，表明输出门对于某些信息进行保留，对于某些信息进行遗忘，从而得到了该种形式的输出。</p> 
<p></p> 
<h2 id="%E6%80%BB%E7%BB%93RNN"><strong>总结RNN</strong></h2> 
<p class="img-center"><img alt="" height="727" src="https://images2.imgbox.com/9d/2a/wxkZeiQC_o.png" width="877"></p> 
<p></p> 
<h2 id="%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</h2> 
<p><a href="https://zhuanlan.zhihu.com/p/53051992" rel="nofollow" title="LSTM模型分析 - 知乎 (zhihu.com)">LSTM模型分析 - 知乎 (zhihu.com)</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1f899026660831f2bcbfc212d5135828/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【数据库高级】Mysql窗口函数的使用和练习</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6e48eedf2292db6dc327fb846551d55f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">算法设计与分析——两个序列的中位数（Java）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>