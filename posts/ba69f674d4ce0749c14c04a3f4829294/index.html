<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>2023年全国职业院校技能大赛-赛题第06套-GZ033 大数据应用开发 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="2023年全国职业院校技能大赛-赛题第06套-GZ033 大数据应用开发" />
<meta property="og:description" content="目录
任务A：大数据平台搭建（容器环境）（15分）
子任务一：Hadoop 完全分布式安装配置
子任务二：Spark on Yarn安装配置
子任务三：Hudi安装配置
任务B：离线数据处理（25分）
子任务一：数据抽取
子任务二：数据清洗
子任务三：指标计算
任务C：数据挖掘（10分）
子任务一：特征工程
子任务二：推荐系统
任务D：数据采集与实时计算（20分）
子任务一：实时数据采集
子任务二：使用Flink处理Kafka中的数据
任务E：数据可视化（15分）
子任务一：用柱状图展示消费额最高的省份
子任务二：用饼状图展示各地区消费能力
子任务三：用折线图展示每年上架商品数量的变化
子任务四：用条形图展示消费额最高的地区
子任务五：用散点图展示省份平均消费额
任务F：综合分析（10分）
子任务一：Spark中的HashShuffle的有哪些不足？
子任务二：请简述Flink的Slot和parallelism有什么区别。
子任务三：分析下一年度的建仓目的地。
2023年全国职业院校技能大赛
赛题第06套
赛项名称： 大数据应用开发 英文名称： Big Data Application Development 赛项组别： 高等职业教育组 赛项编号： GZ033 背景描述
大数据时代背景下，电商经营模式发生很大改变。在传统运营模式中，缺乏数据积累，人们在做出一些决策行为过程中，更多是凭借个人经验和直觉，发展路径比较自我封闭。而大数据时代，为人们提供一种全新的思路，通过大量的数据分析得出的结果将更加现实和准确。商家可以对客户的消费行为信息数据进行收集和整理，比如消费者购买产品的花费、选择产品的渠道、偏好产品的类型、产品回购周期、购买产品的目的、消费者家庭背景、工作和生活环境、个人消费观和价值观等。通过数据追踪，知道顾客从哪儿来，是看了某网站投放的广告还是通过朋友推荐链接，是新访客还是老用户，喜欢浏览什么产品，购物车有无商品，是否清空，还有每一笔交易记录，精准锁定一定年龄、收入、对产品有兴趣的顾客，对顾客进行分组、标签化，通过不同标签组合运用，获得不同目标群体，以此开展精准推送。
因数据驱动的零售新时代已经到来，没有大数据，我们无法为消费者提供这些体验，为完成电商的大数据分析工作，你所在的小组将应用大数据技术，以Scala作为整个项目的基础开发语言，基于大数据平台综合利用Hudi、Spark、Flink、Vue.js等技术，对数据进行处理、分析及可视化呈现，你们作为该小组的技术人员，请按照下面任务完成本次工作。
任务A：大数据平台搭建（容器环境）（15分） 环境说明：
服务端登录地址详见各任务服务端说明。
补充说明：宿主机及各容器节点可通过Asbru工具或SSH客户端进行SSH访问。
子任务一：Hadoop 完全分布式安装配置 本任务需要使用root用户完成相关配置，安装Hadoop需要配置前置环境。命令中要求使用绝对路径，具体要求如下:
从宿主机/opt目录下将文件hadoop-3.1.3.tar.gz、jdk-8u212-linux-x64.tar.gz复制到容器Master中的/opt/software路径中（若路径不存在，则需新建），将Master节点JDK安装包解压到/opt/module路径中(若路径不存在，则需新建)，将JDK解压命令复制并粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；
修改容器中/etc/profile文件，设置JDK环境变量并使其生效，配置完毕后在Master节点分别执行“java -version”和“javac”命令，将命令行执行结果分别截图并粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；
请完成host相关配置，将三个节点分别命名为master、slave1、slave2，并做免密登录，用scp命令并使用绝对路径从Master复制JDK解压后的安装文件到slave1、slave2节点（若路径不存在，则需新建），并配置slave1、slave2相关环境变量，将全部scp复制JDK的命令复制并粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；
在Master将Hadoop解压到/opt/module(若路径不存在，则需新建)目录下，并将解压包分发至slave1、slave2中，其中master、slave1、slave2节点均作为datanode，配置好相关环境，初始化Hadoop环境namenode，将初始化命令及初始化结果截图（截取初始化结果日志最后20行即可）粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；
启动Hadoop集群（包括hdfs和yarn），使用jps命令查看Master节点与slave1节点的Java进程，将jps命令与结果截图粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下。
子任务二：Spark on Yarn安装配置 本任务需要使用root用户完成相关配置，已安装Hadoop及需要配置前置环境，具体要求如下：
从宿主机/opt目录下将文件spark-3.1.1-bin-hadoop3.2.tgz复制到容器Master中的/opt/software（若路径不存在，则需新建）中，将Spark包解压到/opt/module路径中(若路径不存在，则需新建)，将完整解压命令复制粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；修改容器中/etc/profile文件，设置Spark环境变量并使环境变量生效，在/opt目录下运行命令spark-submit --version，将命令与结果截图粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；完成on yarn相关配置，使用spark on yarn 的模式提交$SPARK_HOME/examples/jars/spark-examples_2.12-3.1.1.jar 运行的主类为org.apache.spark.examples.SparkPi，将运行结果截图粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下（截取Pi结果的前后各5行）。 （运行命令为：spark-submit --master yarn --class org." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/ba69f674d4ce0749c14c04a3f4829294/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-28T09:08:12+08:00" />
<meta property="article:modified_time" content="2023-06-28T09:08:12+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">2023年全国职业院校技能大赛-赛题第06套-GZ033 大数据应用开发</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%BB%BB%E5%8A%A1A%EF%BC%9A%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%EF%BC%88%E5%AE%B9%E5%99%A8%E7%8E%AF%E5%A2%83%EF%BC%89%EF%BC%8815%E5%88%86%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E4%BB%BB%E5%8A%A1A%EF%BC%9A%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%EF%BC%88%E5%AE%B9%E5%99%A8%E7%8E%AF%E5%A2%83%EF%BC%89%EF%BC%8815%E5%88%86%EF%BC%89" rel="nofollow">任务A：大数据平台搭建（容器环境）（15分）</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9AHadoop%20%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9AHadoop%20%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE" rel="nofollow">子任务一：Hadoop 完全分布式安装配置</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9ASpark%20on%20Yarn%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9ASpark%20on%20Yarn%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE" rel="nofollow">子任务二：Spark on Yarn安装配置</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9AHudi%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9AHudi%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE" rel="nofollow">子任务三：Hudi安装配置</a></p> 
<p id="%E4%BB%BB%E5%8A%A1B%EF%BC%9A%E7%A6%BB%E7%BA%BF%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%8825%E5%88%86%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E4%BB%BB%E5%8A%A1B%EF%BC%9A%E7%A6%BB%E7%BA%BF%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%8825%E5%88%86%EF%BC%89" rel="nofollow">任务B：离线数据处理（25分）</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%8A%BD%E5%8F%96-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%8A%BD%E5%8F%96" rel="nofollow">子任务一：数据抽取</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97" rel="nofollow">子任务二：数据清洗</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9A%E6%8C%87%E6%A0%87%E8%AE%A1%E7%AE%97-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9A%E6%8C%87%E6%A0%87%E8%AE%A1%E7%AE%97" rel="nofollow">子任务三：指标计算</a></p> 
<p id="%E4%BB%BB%E5%8A%A1C%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%8810%E5%88%86%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E4%BB%BB%E5%8A%A1C%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%8810%E5%88%86%EF%BC%89" rel="nofollow">任务C：数据挖掘（10分）</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B" rel="nofollow">子任务一：特征工程</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F" rel="nofollow">子任务二：推荐系统</a></p> 
<p id="%E4%BB%BB%E5%8A%A1D%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E4%B8%8E%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%EF%BC%8820%E5%88%86%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E4%BB%BB%E5%8A%A1D%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E4%B8%8E%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%EF%BC%8820%E5%88%86%EF%BC%89" rel="nofollow">任务D：数据采集与实时计算（20分）</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86" rel="nofollow">子任务一：实时数据采集</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E4%BD%BF%E7%94%A8Flink%E5%A4%84%E7%90%86Kafka%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E4%BD%BF%E7%94%A8Flink%E5%A4%84%E7%90%86Kafka%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE" rel="nofollow">子任务二：使用Flink处理Kafka中的数据</a></p> 
<p id="%E4%BB%BB%E5%8A%A1E%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%8815%E5%88%86%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E4%BB%BB%E5%8A%A1E%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%8815%E5%88%86%EF%BC%89" rel="nofollow">任务E：数据可视化（15分）</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E7%94%A8%E6%9F%B1%E7%8A%B6%E5%9B%BE%E5%B1%95%E7%A4%BA%E6%B6%88%E8%B4%B9%E9%A2%9D%E6%9C%80%E9%AB%98%E7%9A%84%E7%9C%81%E4%BB%BD-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E7%94%A8%E6%9F%B1%E7%8A%B6%E5%9B%BE%E5%B1%95%E7%A4%BA%E6%B6%88%E8%B4%B9%E9%A2%9D%E6%9C%80%E9%AB%98%E7%9A%84%E7%9C%81%E4%BB%BD" rel="nofollow">子任务一：用柱状图展示消费额最高的省份</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E7%94%A8%E9%A5%BC%E7%8A%B6%E5%9B%BE%E5%B1%95%E7%A4%BA%E5%90%84%E5%9C%B0%E5%8C%BA%E6%B6%88%E8%B4%B9%E8%83%BD%E5%8A%9B-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E7%94%A8%E9%A5%BC%E7%8A%B6%E5%9B%BE%E5%B1%95%E7%A4%BA%E5%90%84%E5%9C%B0%E5%8C%BA%E6%B6%88%E8%B4%B9%E8%83%BD%E5%8A%9B" rel="nofollow">子任务二：用饼状图展示各地区消费能力</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9A%E7%94%A8%E6%8A%98%E7%BA%BF%E5%9B%BE%E5%B1%95%E7%A4%BA%E6%AF%8F%E5%B9%B4%E4%B8%8A%E6%9E%B6%E5%95%86%E5%93%81%E6%95%B0%E9%87%8F%E7%9A%84%E5%8F%98%E5%8C%96-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9A%E7%94%A8%E6%8A%98%E7%BA%BF%E5%9B%BE%E5%B1%95%E7%A4%BA%E6%AF%8F%E5%B9%B4%E4%B8%8A%E6%9E%B6%E5%95%86%E5%93%81%E6%95%B0%E9%87%8F%E7%9A%84%E5%8F%98%E5%8C%96" rel="nofollow">子任务三：用折线图展示每年上架商品数量的变化</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E5%9B%9B%EF%BC%9A%E7%94%A8%E6%9D%A1%E5%BD%A2%E5%9B%BE%E5%B1%95%E7%A4%BA%E6%B6%88%E8%B4%B9%E9%A2%9D%E6%9C%80%E9%AB%98%E7%9A%84%E5%9C%B0%E5%8C%BA-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E5%9B%9B%EF%BC%9A%E7%94%A8%E6%9D%A1%E5%BD%A2%E5%9B%BE%E5%B1%95%E7%A4%BA%E6%B6%88%E8%B4%B9%E9%A2%9D%E6%9C%80%E9%AB%98%E7%9A%84%E5%9C%B0%E5%8C%BA" rel="nofollow">子任务四：用条形图展示消费额最高的地区</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%94%EF%BC%9A%E7%94%A8%E6%95%A3%E7%82%B9%E5%9B%BE%E5%B1%95%E7%A4%BA%E7%9C%81%E4%BB%BD%E5%B9%B3%E5%9D%87%E6%B6%88%E8%B4%B9%E9%A2%9D-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%94%EF%BC%9A%E7%94%A8%E6%95%A3%E7%82%B9%E5%9B%BE%E5%B1%95%E7%A4%BA%E7%9C%81%E4%BB%BD%E5%B9%B3%E5%9D%87%E6%B6%88%E8%B4%B9%E9%A2%9D" rel="nofollow">子任务五：用散点图展示省份平均消费额</a></p> 
<p id="%E4%BB%BB%E5%8A%A1F%EF%BC%9A%E7%BB%BC%E5%90%88%E5%88%86%E6%9E%90%EF%BC%8810%E5%88%86%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E4%BB%BB%E5%8A%A1F%EF%BC%9A%E7%BB%BC%E5%90%88%E5%88%86%E6%9E%90%EF%BC%8810%E5%88%86%EF%BC%89" rel="nofollow">任务F：综合分析（10分）</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9ASpark%E4%B8%AD%E7%9A%84HashShuffle%E7%9A%84%E6%9C%89%E5%93%AA%E4%BA%9B%E4%B8%8D%E8%B6%B3%EF%BC%9F-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9ASpark%E4%B8%AD%E7%9A%84HashShuffle%E7%9A%84%E6%9C%89%E5%93%AA%E4%BA%9B%E4%B8%8D%E8%B6%B3%EF%BC%9F" rel="nofollow">子任务一：Spark中的HashShuffle的有哪些不足？</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E8%AF%B7%E7%AE%80%E8%BF%B0Flink%E7%9A%84Slot%E5%92%8Cparallelism%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%E3%80%82-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E8%AF%B7%E7%AE%80%E8%BF%B0Flink%E7%9A%84Slot%E5%92%8Cparallelism%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%E3%80%82" rel="nofollow">子任务二：请简述Flink的Slot和parallelism有什么区别。</a></p> 
<p id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9A%E5%88%86%E6%9E%90%E4%B8%8B%E4%B8%80%E5%B9%B4%E5%BA%A6%E7%9A%84%E5%BB%BA%E4%BB%93%E7%9B%AE%E7%9A%84%E5%9C%B0%E3%80%82-toc" style="margin-left:80px;"><a href="#%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9A%E5%88%86%E6%9E%90%E4%B8%8B%E4%B8%80%E5%B9%B4%E5%BA%A6%E7%9A%84%E5%BB%BA%E4%BB%93%E7%9B%AE%E7%9A%84%E5%9C%B0%E3%80%82" rel="nofollow">子任务三：分析下一年度的建仓目的地。</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p> </p> 
<p style="margin-left:.0001pt;text-align:center;"><strong><strong>2023年</strong></strong><strong><strong>全国职业院校技能大赛</strong></strong></p> 
<p style="margin-left:.0001pt;text-align:center;"><strong><strong>赛题第06套</strong></strong></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:center;"><strong><strong>赛项名称：</strong></strong><strong><u>        </u></strong><strong><u><strong><u> 大数据应用开发</u></strong></u></strong><strong><u>  </u></strong><strong><u>    </u></strong><strong><u>  </u></strong><strong><u> </u></strong></p> 
<p style="margin-left:.0001pt;text-align:center;"><strong><strong>英文名称：</strong></strong><u>  </u><u><u>Big Data Application Development</u></u><strong><u>  </u></strong></p> 
<p style="margin-left:.0001pt;text-align:center;"><strong><strong>赛项组别</strong></strong><strong><strong>：</strong></strong><strong><u>         </u></strong><strong><u><strong><u>高等职业教育组</u></strong></u></strong><strong><u>   </u></strong><strong><u>    </u></strong><strong><u>        </u></strong><strong><u> </u></strong></p> 
<p style="margin-left:.0001pt;text-align:center;"><strong><strong>赛项编号：</strong></strong><strong><u>           </u></strong><strong><u><strong><u>   GZ033</u></strong></u></strong><strong><u>       </u></strong><strong><u> </u></strong><strong><u> </u></strong><strong><u>  </u></strong><strong><u>  </u></strong></p> 
<p style="margin-left:.0001pt;text-align:left;"></p> 
<p style="margin-left:.0001pt;text-align:center;"><strong>背景描述</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">大数据时代背景下，电商经营模式发生很大改变。在传统运营模式中，缺乏数据积累，人们在做出一些决策行为过程中，更多是凭借个人经验和直觉，发展路径比较自我封闭。而大数据时代，为人们提供一种全新的思路，通过大量的数据分析得出的结果将更加现实和准确。商家可以对客户的消费行为信息数据进行收集和整理，比如消费者购买产品的花费、选择产品的渠道、偏好产品的类型、产品回购周期、购买产品的目的、消费者家庭背景、工作和生活环境、个人消费观和价值观等。通过数据追踪，知道顾客从哪儿来，是看了某网站投放的广告还是通过朋友推荐链接，是新访客还是老用户，喜欢浏览什么产品，购物车有无商品，是否清空，还有每一笔交易记录，精准锁定一定年龄、收入、对产品有兴趣的顾客，对顾客进行分组、标签化，通过不同标签组合运用，获得不同目标群体，以此开展精准推送。</p> 
<p style="margin-left:.0001pt;text-align:justify;">因数据驱动的零售新时代已经到来，没有大数据，我们无法为消费者提供这些体验，为完成电商的大数据分析工作，你所在的小组将应用大数据技术，以Scala作为整个项目的基础开发语言，基于大数据平台综合利用Hudi、Spark、Flink、Vue.js等技术，对数据进行处理、分析及可视化呈现，你们作为该小组的技术人员，请按照下面任务完成本次工作。</p> 
<h3 id="%E4%BB%BB%E5%8A%A1A%EF%BC%9A%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%EF%BC%88%E5%AE%B9%E5%99%A8%E7%8E%AF%E5%A2%83%EF%BC%89%EF%BC%8815%E5%88%86%EF%BC%89" style="text-align:center;"><strong><strong><strong>任务</strong></strong><strong><strong>A：大数据平台搭建（容器环境）（15分）</strong></strong></strong></h3> 
<p style="margin-left:.0001pt;text-align:left;"><strong>环境说明：</strong></p> 
<table align="center" border="1" cellspacing="0" style="width:417.95pt;"><tbody><tr><td style="vertical-align:bottom;width:417.95pt;"> <p style="margin-left:.0001pt;text-align:left;"><strong><strong>服务端登录地址详见各</strong></strong><strong><strong>任务</strong></strong><strong><strong>服务端说明。</strong></strong></p> <p style="margin-left:.0001pt;text-align:left;"><strong><strong>补充说明：</strong></strong>宿主机及各容器节点可通过Asbru工具或SSH客户端进行SSH访问。</p> </td></tr></tbody></table> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9AHadoop%20%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE" style="text-align:left;"><strong>子任务一：Hadoop 完全分布式安装配置</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">本任务需要使用root用户完成相关配置，安装Hadoop需要配置前置环境。命令中要求使用绝对路径，具体要求如下:</p> 
<p style="margin-left:.0001pt;text-align:justify;">从宿主机/opt目录下将文件hadoop-3.1.3.tar.gz、jdk-8u212-linux-x64.tar.gz复制到容器Master中的/opt/software路径中（若路径不存在，则需新建），将Master节点JDK安装包解压到/opt/module路径中(若路径不存在，则需新建)，将JDK解压命令复制并粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；</p> 
<p style="margin-left:.0001pt;text-align:justify;">修改容器中/etc/profile文件，设置JDK环境变量并使其生效，配置完毕后在Master节点分别执行“java -version”和“javac”命令，将命令行执行结果分别截图并粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；</p> 
<p style="margin-left:.0001pt;text-align:justify;">请完成host相关配置，将三个节点分别命名为master、slave1、slave2，并做免密登录，用scp命令并使用绝对路径从Master复制JDK解压后的安装文件到slave1、slave2节点（若路径不存在，则需新建），并配置slave1、slave2相关环境变量，将全部scp复制JDK的命令复制并粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；</p> 
<p style="margin-left:.0001pt;text-align:justify;">在Master将Hadoop解压到/opt/module(若路径不存在，则需新建)目录下，并将解压包分发至slave1、slave2中，其中master、slave1、slave2节点均作为datanode，配置好相关环境，初始化Hadoop环境namenode，将初始化命令及初始化结果截图（截取初始化结果日志最后20行即可）粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；</p> 
<p style="margin-left:.0001pt;text-align:justify;">启动Hadoop集群（包括hdfs和yarn），使用jps命令查看Master节点与slave1节点的Java进程，将jps命令与结果截图粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下。</p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9ASpark%20on%20Yarn%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE" style="text-align:left;"><strong>子任务二：Spark on Yarn安装配置</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">本任务需要使用root用户完成相关配置，已安装Hadoop及需要配置前置环境，具体要求如下：</p> 
<ol><li style="text-align:justify;">从宿主机/opt目录下将文件spark-3.1.1-bin-hadoop3.2.tgz复制到容器Master中的/opt/software（若路径不存在，则需新建）中，将Spark包解压到/opt/module路径中(若路径不存在，则需新建)，将完整解压命令复制粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；</li><li style="text-align:justify;">修改容器中/etc/profile文件，设置Spark环境变量并使环境变量生效，在/opt目录下运行命令spark-submit --version，将命令与结果截图粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；</li><li style="text-align:justify;">完成on yarn相关配置，使用spark on yarn 的模式提交$SPARK_HOME/examples/jars/spark-examples_2.12-3.1.1.jar 运行的主类为org.apache.spark.examples.SparkPi，将运行结果截图粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下（截取Pi结果的前后各5行）。</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;">（运行命令为：spark-submit --master yarn --class org.apache.spark.examples.SparkPi  $SPARK_HOME/examples/jars/spark-examples_2.12-3.1.1.jar）</p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9AHudi%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE" style="text-align:left;"><strong>子任务三：Hudi安装配置</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">本任务需要使用root用户完成相关配置，具体要求如下：</p> 
<ol><li style="text-align:justify;">从宿主机/opt目录下将maven相关安装包复制到容器Master中的/opt/software（若路径不存在，则需新建）中，将maven相关安装包解压到/opt/module/目录下（若路径不存在，则需新建）并配置maven本地库为/opt/software/RepMaven/，远程仓库使用阿里云镜像，配置maven的环境变量，并在/opt/下执行mvn -v，将运行结果截图粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；</li></ol> 
<p>   &lt;mirror&gt;</p> 
<p>     &lt;id&gt;nexus-aliyun&lt;/id&gt;</p> 
<p>     &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;</p> 
<p>     &lt;name&gt;Nexus aliyun&lt;/name&gt;</p> 
<p>     &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;</p> 
<p>   &lt;/mirror&gt;</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">从宿主机/opt目录下将Hudi相关安装包复制到容器Master中的/opt/software（若路径不存在，则需新建）中，将Hudi相关安装包解压到/opt/module/目录下（若路径不存在，则需新建），将命令复制并粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下；</li><li style="text-align:justify;">完成解压安装及配置后使用maven对Hudi进行构建（spark3.1,scala-2.12），编译完成后与Spark集成，集成后使用spark-shell操作Hudi，将spark-shell启动使用spark-shell运行下面给到的案例，并将最终查询结果截图粘贴至客户端桌面【Release\任务A提交结果.docx】中对应的任务序号下。</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;">（<strong><strong>提示</strong></strong>：编译需要替换以下内容：</p> 
<p style="margin-left:.0001pt;text-align:justify;">1.将父模块pom.xml替换；</p> 
<p style="margin-left:.0001pt;text-align:justify;">2.hudi-common/src/main/java/org/apache/hudi/common/table/log/block/HoodieParquetDataBlock.java替换；</p> 
<ol><li style="text-align:justify;">将packaging/hudi-spark-bundle/pom.xml替换；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;">3.将packaging/hudi-utilities-bundle/pom.xml替换）</p> 
<p>import org.apache.hudi.QuickstartUtils._</p> 
<p>import scala.collection.JavaConversions._</p> 
<p>import org.apache.spark.sql.SaveMode._</p> 
<p>import org.apache.hudi.DataSourceReadOptions._</p> 
<p>import org.apache.hudi.DataSourceWriteOptions._</p> 
<p>import org.apache.hudi.config.HoodieWriteConfig._</p> 
<p>import org.apache.hudi.common.model.HoodieRecord</p> 
<p></p> 
<p>val tableName = "hudi_trips_cow"</p> 
<p>val basePath = "file:///tmp/hudi_trips_cow"</p> 
<p>val dataGen = new DataGenerator</p> 
<p></p> 
<p>val inserts = convertToStringList(dataGen.generateInserts(10))</p> 
<p>val df = spark.read.json(spark.sparkContext.parallelize(inserts, 2))</p> 
<p>df.write.format("hudi").</p> 
<p>  options(getQuickstartWriteConfigs).</p> 
<p>  option(PRECOMBINE_FIELD_OPT_KEY, "ts").</p> 
<p>  option(RECORDKEY_FIELD_OPT_KEY, "uuid").</p> 
<p>  option(PARTITIONPATH_FIELD_OPT_KEY, "partitionpath").</p> 
<p>  option(TABLE_NAME, tableName).</p> 
<p>  mode(Overwrite).</p> 
<p>  save(basePath)</p> 
<p></p> 
<p>val tripsSnapshotDF = spark.read.format("hudi").load(basePath + "/*/*/*/*")</p> 
<p>tripsSnapshotDF.createOrReplaceTempView("hudi_trips_snapshot")</p> 
<p>spark.sql("select fare, begin_lon, begin_lat, ts from  hudi_trips_snapshot where fare &gt; 20.0").show()</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h3 id="%E4%BB%BB%E5%8A%A1B%EF%BC%9A%E7%A6%BB%E7%BA%BF%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%8825%E5%88%86%EF%BC%89" style="text-align:center;"><strong><strong><strong>任务</strong></strong><strong><strong>B：离线数据处理（25分）</strong></strong></strong></h3> 
<p style="margin-left:.0001pt;text-align:left;"><strong>环境说明：</strong></p> 
<table align="center" border="1" cellspacing="0" style="width:417.95pt;"><tbody><tr><td style="vertical-align:bottom;width:417.95pt;"> <p style="margin-left:.0001pt;text-align:left;"><strong><strong>服务端登录地址详见各</strong></strong><strong><strong>任务</strong></strong><strong><strong>服务端说明。</strong></strong></p> <p style="margin-left:.0001pt;text-align:left;"><strong><strong>补充说明：</strong></strong>各节点可通过Asbru工具或SSH客户端进行SSH访问；</p> <p style="margin-left:.0001pt;text-align:left;">主节点MySQL数据库用户名/密码：root/123456（已配置远程连接）；</p> <p style="margin-left:.0001pt;text-align:left;">Spark任务在Yarn上用Client运行，方便观察日志。</p> </td></tr></tbody></table> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%8A%BD%E5%8F%96" style="text-align:left;"><strong>子任务一：数据抽取</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">编写Scala代码，使用Spark将MySQL的shtd_store库中表user_info、sku_info、base_province、base_region、order_info、order_detail的数据增量抽取到<strong><strong>Hud</strong></strong><strong><strong>i</strong></strong>的ods_ds_hudi库（路径为/user/hive/warehouse/ods_ds_hudi.db）的user_info、sku_info、base_province、base_region、order_info、order_detail中。(若ods_ds_hudi库中部分表没有数据，正常抽取即可) </p> 
<p style="margin-left:.0001pt;text-align:justify;">抽取shtd_store库中user_info的增量数据进入Hudi的ods_ds_hudi库中表user_info。根据ods_ds_hudi.user_info表中operate_time或create_time作为增量字段(即MySQL中每条数据取这两个时间中较大的那个时间作为增量字段去和ods_ds_hudi里的这两个字段中较大的时间进行比较)，只将新增的数据抽入，字段名称、类型不变，同时添加分区，若operate_time为空，则用create_time填充，分区字段为etl_date，类型为String，且值为当前比赛日的前一天日期（分区字段格式为yyyyMMdd）。id作为primaryKey，operate_time作为preCombineField。使用spark-shell执行show partitions ods_ds_hudi.user_info命令，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">抽取shtd_store库中sku_info的增量数据进入Hudi的ods_ds_hudi库中表sku_info。根据ods_ds_hudi.sku_info表中create_time作为增量字段，只将新增的数据抽入，字段名称、类型不变，同时添加分区，分区字段为etl_date，类型为String，且值为当前比赛日的前一天日期（分区字段格式为yyyyMMdd）。id作为primaryKey，operate_time作为preCombineField。使用spark-shell执行show partitions ods_ds_hudi.sku_info命令，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">抽取shtd_store库中base_province的增量数据进入Hudi的ods_ds_hudi库中表base_province。根据ods_ds_hudi.base_province表中id作为增量字段，只将新增的数据抽入，字段名称、类型不变并添加字段create_time取当前时间，同时添加分区，分区字段为etl_date，类型为String，且值为当前比赛日的前一天日期（分区字段格式为yyyyMMdd）。id作为primaryKey，create_time作为preCombineField。使用spark-shell执行show partitions ods_ds_hudi.base_province命令，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">抽取shtd_store库中base_region的增量数据进入Hudi的ods_ds_hudi库中表base_region。根据ods_ds_hudi.base_region表中id作为增量字段，只将新增的数据抽入，字段名称、类型不变并添加字段create_time取当前时间，同时添加分区，分区字段为etl_date，类型为String，且值为当前比赛日的前一天日期（分区字段格式为yyyyMMdd）。id作为primaryKey，create_time作为preCombineField。使用spark-shell执行show partitions ods_ds_hudi.base_region命令，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">抽取shtd_store库中order_info的增量数据进入Hudi的ods_ds_hudi库中表order_info，根据ods_ds_hudi.order_info表中operate_time或create_time作为增量字段(即MySQL中每条数据取这两个时间中较大的那个时间作为增量字段去和ods_ds_hudi里的这两个字段中较大的时间进行比较)，只将新增的数据抽入，字段名称、类型不变，同时添加分区，分区字段为etl_date，类型为String，且值为当前比赛日的前一天日期（分区字段格式为yyyyMMdd）。id作为primaryKey，operate_time作为preCombineField。使用spark-shell执行show partitions ods_ds_hudi.order_info命令，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">抽取shtd_store库中order_detail的增量数据进入Hudi的ods_ds_hudi库中表order_detail，根据ods_ds_hudi.order_detail表中create_time作为增量字段，只将新增的数据抽入，字段名称、类型不变，同时添加分区，分区字段为etl_date，类型为String，且值为当前比赛日的前一天日期（分区字段格式为yyyyMMdd）。id作为primaryKey，create_time作为preCombineField。使用spark-shell执行show partitions ods_ds_hudi.order_detail命令，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下。</p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97" style="text-align:left;"><strong>子任务二：数据清洗</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">编写Scala代码，使用Spark将ods_ds_hudi库中相应表数据全量抽取到<strong><strong>Hudi</strong></strong>的dwd_ds_hudi库（路径为/user/hive/warehouse/dwd_ds_hudi.db）中对应表中。表中有涉及到timestamp类型的，均要求按照yyyy-MM-dd HH:mm:ss，不记录毫秒数，若原数据中只有年月日，则在时分秒的位置添加00:00:00，添加之后使其符合yyyy-MM-dd HH:mm:ss。(若dwd_ds_hudi库中部分表没有数据，正常抽取即可)</p> 
<ol><li style="text-align:justify;">抽取ods_ds_hudi库中user_info表中昨天的分区（子任务一生成的分区）数据，并结合dim_user_info最新分区现有的数据，根据id合并数据到dwd_ds_hudi库中dim_user_info的分区表（合并是指对dwd层数据进行插入或修改，需修改的数据以id为合并字段，根据operate_time排序取最新的一条），分区字段为etl_date且值与ods_ds_hudi库的相对应表该值相等，并添加dwd_insert_user、dwd_insert_time、dwd_modify_user、dwd_modify_time四列,其中dwd_insert_user、dwd_modify_user均填写“user1”。若该条记录第一次进入数仓dwd层则dwd_insert_time、dwd_modify_time均存当前操作时间，并进行数据类型转换。若该数据在进入dwd层时发生了合并修改，则dwd_insert_time时间不变，dwd_modify_time存当前操作时间，其余列存最新的值。id作为primaryKey，operate_time作为preCombineField。使用spark-shell执行show partitions dwd_ds_hudi.dim_user_info命令，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">抽取ods_ds_hudi库sku_info表中昨天的分区（子任务一生成的分区）数据，并结合dim_sku_info最新分区现有的数据，根据id合并数据到dwd_ds_hudi库中dim_sku_info的分区表（合并是指对dwd层数据进行插入或修改，需修改的数据以id为合并字段，根据create_time排序取最新的一条），分区字段为etl_date且值与ods_ds_hudi库的相对应表该值相等，并添加dwd_insert_user、dwd_insert_time、dwd_modify_user、dwd_modify_time四列,其中dwd_insert_user、dwd_modify_user均填写“user1”。若该条数据第一次进入数仓dwd层则dwd_insert_time、dwd_modify_time均填写当前操作时间，并进行数据类型转换。若该数据在进入dwd层时发生了合并修改，则dwd_insert_time时间不变，dwd_modify_time存当前操作时间，其余列存最新的值。id作为primaryKey，dwd_modify_time作为preCombineField。使用spark-shell查询表dim_sku_info的字段id、sku_desc、dwd_insert_user、dwd_modify_time、etl_date，条件为最新分区的数据，id大于等于15且小于等于20，并且按照id升序排序，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">抽取ods_ds_hudi库base_province表中昨天的分区（子任务一生成的分区）数据，并结合dim_province最新分区现有的数据，根据id合并数据到dwd_ds_hudi库中dim_province的分区表（合并是指对dwd层数据进行插入或修改，需修改的数据以id为合并字段，根据create_time排序取最新的一条），分区字段为etl_date且值与ods_ds_hudi库的相对应表该值相等，并添加dwd_insert_user、dwd_insert_time、dwd_modify_user、dwd_modify_time四列,其中dwd_insert_user、dwd_modify_user均填写“user1”。若该条数据第一次进入数仓dwd层则dwd_insert_time、dwd_modify_time均填写当前操作时间，并进行数据类型转换。若该数据在进入dwd层时发生了合并修改，则dwd_insert_time时间不变，dwd_modify_time存当前操作时间，其余列存最新的值。id作为primaryKey，dwd_modify_time作为preCombineField。使用spark-shell在表dwd_ds_hudi.dim_province最新分区中，查询该分区中数据的条数，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">抽取ods_ds_hudi库base_region表中昨天的分区（子任务一生成的分区）数据，并结合dim_region最新分区现有的数据，根据id合并数据到dwd_ds_hudi库中dim_region的分区表（合并是指对dwd层数据进行插入或修改，需修改的数据以id为合并字段，根据create_time排序取最新的一条），分区字段为etl_date且值与ods_ds_hudi库的相对应表该值相等，并添加dwd_insert_user、dwd_insert_time、dwd_modify_user、dwd_modify_time四列,其中dwd_insert_user、dwd_modify_user均填写“user1”。若该条数据第一次进入数仓dwd层则dwd_insert_time、dwd_modify_time均填写当前操作时间，并进行数据类型转换。若该数据在进入dwd层时发生了合并修改，则dwd_insert_time时间不变，dwd_modify_time存当前操作时间，其余列存最新的值。id作为primaryKey，dwd_modify_time作为preCombineField。使用spark-shell在表dwd_ds_hudi.dim_region最新分区中，查询该分区中数据的条数，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">将ods_ds_hudi库中order_info表昨天的分区（子任务一生成的分区）数据抽取到dwd_ds_hudi库中fact_order_info的动态分区表，分区字段为etl_date，类型为String，取create_time值并将格式转换为yyyyMMdd，同时若operate_time为空，则用create_time填充，并添加dwd_insert_user、dwd_insert_time、dwd_modify_user、dwd_modify_time四列，其中dwd_insert_user、dwd_modify_user均填写“user1”，dwd_insert_time、dwd_modify_time均填写当前操作时间，并进行数据类型转换。id作为primaryKey，operate_time作为preCombineField。使用spark-shell执行show partitions dwd_ds_hudi.fact_order_info命令，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">将ods_ds_hudi库中order_detail表昨天的分区（子任务一中生成的分区）数据抽取到dwd_ds_hudi库中fact_order_detail的动态分区表，分区字段为etl_date，类型为String，取create_time值并将格式转换为yyyyMMdd，并添加dwd_insert_user、dwd_insert_time、dwd_modify_user、dwd_modify_time四列，其中dwd_insert_user、dwd_modify_user均填写“user1”，dwd_insert_time、dwd_modify_time均填写当前操作时间，并进行数据类型转换。id作为primaryKey，dwd_modify_time作为preCombineField。使用spark-shell执行show partitions dwd_ds_hudi.fact_order_detail命令，将结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下。</li></ol> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9A%E6%8C%87%E6%A0%87%E8%AE%A1%E7%AE%97" style="text-align:left;"><strong>子任务三：指标计算</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">编写Scala代码，使用Spark计算相关指标。</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>注：在指标计算中，不考虑订单信息表中order_status字段的值，将所有订单视为有效订单。计算订单金额或订单总金额时只使用final_total_amount字段。需注意dwd_ds_hudi所有的维表取最新的分区。</strong></strong></p> 
<ol><li style="text-align:justify;">本任务基于以下2、3、4小题完成，使用Azkaban完成第2、3、4题任务代码的调度。工作流要求，使用shell输出“开始”作为工作流的第一个job（job1），2、3、4题任务为串行任务且它们依赖job1的完成（命名为job2、job3、job4），job2、job3、job4完成之后使用shell输出“结束”作为工作流的最后一个job（endjob），endjob依赖job2、job3、job4，并将最终任务调度完成后的工作流截图，将截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">根据dwd_ds_hudi层表统计每个省每月下单的数量和下单的总金额，并按照year，month，region_id进行分组,按照total_amount降序排序，形成sequence值，将计算结果存入Hudi的dws_ds_hudi数据库province_consumption_day_aggr表中（表结构如下），然后使用spark-shell根据订单总数、订单总金额、省份表主键均为降序排序，查询出前5条，在查询时对于订单总金额字段将其转为bigint类型（避免用科学计数法展示），将SQL语句复制粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下;</li></ol> 
<table align="center" border="1" cellspacing="0" style="margin-left:6.75pt;"><tbody><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">字段</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">类型</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">中文含义</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;">备注</p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">uuid</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">string</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">随机字符</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;">随机字符，保证不同即可，作为primaryKey</p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">province_id</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">省份主键</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">province_name</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">string</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">省份名称</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">region_id</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">地区主键</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">region_name</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">string</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">地区名称</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">total_amount</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">double</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">订单总金额</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;">当月订单总金额</p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">total_count</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">订单总数</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;">当月订单总数。同时可作为preCombineField（作为合并字段时，无意义，因为主键为随机生成）</p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">sequence</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">次序</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">year</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">年</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;">订单产生的年,为动态分区字段</p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">month</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:82.95pt;"> <p style="margin-left:.0001pt;text-align:justify;">月</p> </td><td style="vertical-align:top;width:124.45pt;"> <p style="margin-left:.0001pt;text-align:justify;">订单产生的月,为动态分区字段</p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">请根据dwd_ds_hudi层的相关表，计算2020年销售量前10的商品，销售额前10的商品，存入ClickHouse数据库shtd_result的topten表中（表结构如下），然后在Linux的ClickHouse命令行中根据排名升序排序，查询出前5条，将SQL语句复制粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下;</li></ol> 
<table align="center" border="1" cellspacing="0"><tbody><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">字段</p> </td><td style="vertical-align:top;width:72.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">类型</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">中文含义</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">备注</p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">topquantityid</p> </td><td style="vertical-align:top;width:72.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">商品id</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">销售量前10的商品</p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">topquantityname</p> </td><td style="vertical-align:top;width:72.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">text</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">商品名称</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">销售量前10的商品</p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">topquantity</p> </td><td style="vertical-align:top;width:72.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">该商品销售量</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">销售量前10的商品</p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">toppriceid</p> </td><td style="vertical-align:top;width:72.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">text</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">商品id</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">销售额前10的商品</p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">toppricename</p> </td><td style="vertical-align:top;width:72.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">text</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">商品名称</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">销售额前10的商品</p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">topprice</p> </td><td style="vertical-align:top;width:72.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">decimal</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">该商品销售额</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">销售额前10的商品</p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">sequence</p> </td><td style="vertical-align:top;width:72.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">排名</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">所属排名</p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">请根据dwd_ds_hudi层的相关表，计算出2020年每个省份所在地区的订单金额的中位数,存入ClickHouse数据库shtd_result的nationmedian表中（表结构如下），然后在Linux的ClickHouse命令行中根据地区表主键，省份表主键均为升序排序，查询出前5条，将SQL语句复制粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下，将执行结果截图粘贴至客户端桌面【Release\任务B提交结果.docx】中对应的任务序号下；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>提示：可用percentile函数求取中位数。</strong></strong></p> 
<table align="center" border="1" cellspacing="0"><tbody><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">字段</p> </td><td style="vertical-align:top;width:67.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">类型</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">中文含义</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">备注</p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">provinceid</p> </td><td style="vertical-align:top;width:67.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">省份表主键</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">provincename</p> </td><td style="vertical-align:top;width:67.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">text</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">省份名称</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">regionid</p> </td><td style="vertical-align:top;width:67.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">int</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">地区表主键</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">regionname</p> </td><td style="vertical-align:top;width:67.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">text</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">地区名称</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;"></p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">provincemedian</p> </td><td style="vertical-align:top;width:67.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">double</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">该省份中位数</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">该省份订单金额中位数</p> </td></tr><tr><td style="vertical-align:top;width:142pt;"> <p style="margin-left:.0001pt;text-align:justify;">regionmedian</p> </td><td style="vertical-align:top;width:67.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">double</p> </td><td style="vertical-align:top;width:81.35pt;"> <p style="margin-left:.0001pt;text-align:justify;">该省所在地区中位数</p> </td><td style="vertical-align:top;width:125.15pt;"> <p style="margin-left:.0001pt;text-align:justify;">该省所在地区订单金额中位数</p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h3 id="%E4%BB%BB%E5%8A%A1C%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%8810%E5%88%86%EF%BC%89" style="text-align:center;"><strong><strong><strong>任务</strong></strong><strong><strong>C：数据挖掘（10分）</strong></strong></strong></h3> 
<p style="margin-left:.0001pt;text-align:left;"><strong>环境说明：</strong></p> 
<table align="center" border="1" cellspacing="0" style="width:417.95pt;"><tbody><tr><td style="vertical-align:bottom;width:417.95pt;"> <p style="margin-left:.0001pt;text-align:left;"><strong><strong>服务端登录地址详见各</strong></strong><strong><strong>任务</strong></strong><strong><strong>服务端说明。</strong></strong></p> <p style="margin-left:.0001pt;text-align:left;"><strong><strong>补充说明：</strong></strong>各节点可通过Asbru工具或SSH客户端进行SSH访问；</p> <p style="margin-left:.0001pt;text-align:left;">主节点MySQL数据库用户名/密码：root/123456（已配置远程连接）；</p> <p style="margin-left:.0001pt;text-align:left;">Spark任务在Yarn上用Client运行，方便观察日志。</p> <p style="margin-left:.0001pt;text-align:left;">该任务均使用Scala编写，利用Spark相关库完成。</p> </td></tr></tbody></table> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B" style="text-align:left;"><strong>子任务一：特征工程</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">剔除订单信息表与订单详细信息表中用户id与商品id不存在于现有的维表中的记录，同时建议多利用缓存并充分考虑并行度来优化代码，达到更快的计算效果。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">据<strong><strong>Hudi</strong></strong>的dwd_ds_hudi库中相关表或MySQL数据库shtd_store中订单相关表（order_detail、order_info、sku_info），对用户购买过的商品进行去重，将其转换为以下格式：第一列为用户id mapping，第二列为用户购买过的商品id mapping，按照user_id与sku_id进行升序排序，输出前5行，将结果截图粘贴至客户端桌面【Release\任务C提交结果.docx】中对应的任务序号下；</li></ol> 
<table align="center" border="1" cellspacing="0"><tbody><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">字段</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">类型</p> </td><td style="vertical-align:top;width:139.65pt;"> <p style="margin-left:.0001pt;text-align:justify;">中文含义</p> </td><td style="vertical-align:top;width:67.75pt;"> <p style="margin-left:.0001pt;text-align:justify;">备注</p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">user_id</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">int</p> </td><td style="vertical-align:top;width:139.65pt;"> <p style="margin-left:0pt;text-align:left;">用户id的mapping对应键</p> </td><td style="vertical-align:top;width:67.75pt;"> <p style="text-align:left;"></p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">sku_id</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">int</p> </td><td style="vertical-align:top;width:139.65pt;"> <p style="margin-left:0pt;text-align:left;">商品id的mapping对应键</p> </td><td style="vertical-align:top;width:67.75pt;"> <p style="margin-left:.0001pt;text-align:left;"></p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:justify;">提示：</p> 
<p style="margin-left:.0001pt;text-align:justify;">Mapping操作：例如用户id：1、4、7、8、9，则做完mapping操作转为字典类型，键0对应用户id 1，键1对应用户id 4，以此类推</p> 
<p style="margin-left:.0001pt;text-align:justify;">结果格式如下：</p> 
<p style="margin-left:.0001pt;text-align:justify;">-------user_id_mapping与sku_id_mapping数据前5条如下：-------</p> 
<p style="margin-left:.0001pt;text-align:justify;">0:0</p> 
<p style="margin-left:.0001pt;text-align:justify;">0:89</p> 
<p style="margin-left:.0001pt;text-align:justify;">1:1</p> 
<p style="margin-left:.0001pt;text-align:justify;">1:2</p> 
<p style="margin-left:.0001pt;text-align:justify;">1:3</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">根据第1小题的结果，对其进行聚合，其中对sku_id进行one-hot转换，将其转换为以下格式矩阵：第一列为用户id，其余列名为商品id，按照用户id进行升序排序，展示矩阵第一行前5列数据，将结果截图粘贴至客户端桌面【Release\任务C提交结果.docx】中对应的任务序号下。</li></ol> 
<table align="center" border="1" cellspacing="0"><tbody><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">字段</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">类型</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">中文含义</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:justify;">备注</p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">user_id</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">double</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">客户key</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="text-align:left;"></p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">sku_id0</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">double</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">用户是否购买过商品1</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:left;">若用户购买过该商品，则值为1，否则为0</p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">sku_id1</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">double</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">用户是否购买过商品2</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:left;">若用户购买过该商品，则值为1，否则为0</p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">sku_id2</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">double</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">用户是否购买过商品3</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:.0001pt;text-align:left;">若用户购买过该商品，则值为1，否则为0</p> </td></tr><tr><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;">.....</p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;"></p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="margin-left:0pt;text-align:left;"></p> </td><td style="vertical-align:top;width:103.7pt;"> <p style="text-align:left;"></p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:justify;">结果格式如下：</p> 
<p style="margin-left:.0001pt;text-align:justify;">---------------第一行前5列结果展示为---------------</p> 
<p style="margin-left:.0001pt;text-align:justify;">0.0,1.0,0.0,0.0,0.0</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F" style="text-align:left;"><strong>子任务二：推荐系统</strong></h4> 
<ol><li style="text-align:justify;">根据子任务一的结果，对其进行SVD分解，对数据进行降维保留前5个奇异值信息，根据该用户已购买的商品分别与未购买的商品计算余弦相似度再进行累加求均值，将均值最大的5件商品id进行输出作为推荐使用。将输出结果截图粘贴至客户端桌面【Release\任务C提交结果.docx】中对应的任务序号下。</li></ol> 
<p style="margin-left:21pt;">结果格式如下：</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;">------------------------推荐Top5结果如下------------------------</p> 
<p style="margin-left:21pt;">相似度top1(商品id：1，平均相似度：0.983456)</p> 
<p style="margin-left:21pt;">相似度top2(商品id：71，平均相似度：0.782672)</p> 
<p style="margin-left:21pt;">相似度top3(商品id：22，平均相似度：0.7635246)</p> 
<p style="margin-left:21pt;">相似度top4(商品id：351，平均相似度：0.7335748)</p> 
<p style="margin-left:21pt;">相似度top5(商品id：14，平均相似度：0.522356)</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h3 id="%E4%BB%BB%E5%8A%A1D%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E4%B8%8E%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%EF%BC%8820%E5%88%86%EF%BC%89" style="text-align:center;"><strong><strong><strong>任务</strong></strong><strong><strong>D：数据采集与实时计算（20分）</strong></strong></strong></h3> 
<p style="margin-left:.0001pt;text-align:left;"><strong>环境说明：</strong></p> 
<table align="center" border="1" cellspacing="0" style="width:417.95pt;"><tbody><tr><td style="vertical-align:bottom;width:417.95pt;"> <p style="margin-left:.0001pt;text-align:left;"><strong><strong>服务端登录地址详见各</strong></strong><strong><strong>任务</strong></strong><strong><strong>服务端说明。</strong></strong></p> <p style="margin-left:.0001pt;text-align:left;"><strong><strong>补充说明：</strong></strong>各节点可通过Asbru工具或SSH客户端进行SSH访问；</p> <p style="margin-left:.0001pt;text-align:left;">Flink任务在Yarn上用per job模式（即Job分离模式，不采用Session模式），方便Yarn回收资源。</p> </td></tr></tbody></table> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86" style="text-align:left;"><strong>子任务一：实时数据采集</strong></h4> 
<ol><li style="text-align:justify;">在主节点使用Flume采集实时数据生成器10050端口的socket数据，将数据存入到Kafka的Topic中（Topic名称为order，分区数为4），使用Kafka自带的消费者消费order（Topic）中的数据，将前2条数据的结果截图粘贴至客户端桌面【Release\任务D提交结果.docx】中对应的任务序号下；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">采用多路复用模式，Flume接收数据注入kafka 的同时，将数据备份到HDFS目录/user/test/flumebackup下，将查看备份目录下的第一个文件的前2条数据的命令与结果截图粘贴至客户端桌面【Release\任务D提交结果.docx】中对应的任务序号下。</li></ol> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E4%BD%BF%E7%94%A8Flink%E5%A4%84%E7%90%86Kafka%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE" style="text-align:left;"><strong>子任务二：使用Flink处理Kafka中的数据</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">编写Scala代码，使用Flink消费Kafka中Topic为order的数据并进行相应的数据统计计算（订单信息对应表结构order_info,订单详细信息对应表结构order_detail（来源类型和来源编号这两个字段不考虑，所以在实时数据中不会出现），同时计算中使用order_info或order_detail表中create_time或operate_time取两者中值较大者作为EventTime，若operate_time为空值或无此列，则使用create_time填充，允许数据延迟5s，订单状态order_status分别为1001:创建订单、1002:支付订单、1003:取消订单、1004:完成订单、1005:申请退回、1006:退回完成。另外对于数据结果展示时，不要采用例如：1.9786518E7的科学计数法）。</p> 
<ol><li style="text-align:justify;">使用Flink消费Kafka中的数据，统计商城实时订单数量（需要考虑订单状态，若有取消订单、申请退回、退回完成则不计入订单数量，其他状态则累加），将key设置成totalcount存入Redis中。使用redis cli以get key方式获取totalcount值，将结果截图粘贴至客户端桌面【Release\任务D提交结果.docx】中对应的任务序号下，需两次截图，第一次截图和第二次截图间隔1分钟以上，第一次截图放前面，第二次截图放后面；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">在任务1进行的同时，使用侧边流，使用Flink消费Kafka中的订单详细信息的数据，实时统计商城中销售量前3的商品（不考虑订单状态，不考虑打折），将key设置成top3itemamount存入Redis中（value使用String数据格式，value为前3的商品信息并且外层用[]包裹，其中按排序依次存放商品id:销售量，并用逗号分割）。使用redis cli以get key方式获取top3itemamount值，将结果截图粘贴至客户端桌面【Release\任务D提交结果.docx】中对应的任务序号下，需两次截图，第一次截图和第二次截图间隔1分钟以上，第一次截图放前面，第二次截图放后面；</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;">示例如下：</p> 
<p style="margin-left:.0001pt;text-align:justify;">top3itemamount：[1:700,42:500,41:100]</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<ol><li style="text-align:justify;">在任务1进行的同时，使用侧边流，使用Flink消费Kafka中的订单详细信息的数据，实时统计商城中销售额前3的商品（不考虑订单状态，不考虑打折，销售额为order_price*sku_num），将key设置成top3itemconsumption存入Redis中（value使用String数据格式，value为前3的商品信息并且外层用[]包裹，其中按排序依次存放商品id:销售额，并用逗号分割）。使用redis cli以get key方式获取top3itemconsumption值，将结果截图粘贴至客户端桌面【Release\任务D提交结果.docx】中对应的任务序号下，需两次截图，第一次截图和第二次截图间隔1分钟以上，第一次截图放前面，第二次截图放后面。</li></ol> 
<p style="margin-left:.0001pt;text-align:justify;">示例如下：</p> 
<p style="margin-left:.0001pt;text-align:justify;">top3itemconsumption：[1:10020.2,42:4540.0,12:540]</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h3 id="%E4%BB%BB%E5%8A%A1E%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%8815%E5%88%86%EF%BC%89" style="text-align:center;"><strong><strong><strong>任务</strong></strong><strong><strong>E：数据可视化（15分）</strong></strong></strong></h3> 
<p style="margin-left:.0001pt;text-align:left;"><strong>环境说明：</strong></p> 
<table align="center" border="1" cellspacing="0" style="width:417.95pt;"><tbody><tr><td style="vertical-align:bottom;width:417.95pt;"> <p style="margin-left:.0001pt;text-align:left;"><strong><strong>数据接口地址及接口描述详见各</strong></strong><strong><strong>任务</strong></strong><strong><strong>服务端说明。</strong></strong></p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E7%94%A8%E6%9F%B1%E7%8A%B6%E5%9B%BE%E5%B1%95%E7%A4%BA%E6%B6%88%E8%B4%B9%E9%A2%9D%E6%9C%80%E9%AB%98%E7%9A%84%E7%9C%81%E4%BB%BD" style="text-align:left;"><strong>子任务一：用柱状图展示消费额最高的省份</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">编写Vue工程代码，根据接口，用柱状图展示2020年消费额最高的5个省份，同时将用于图表展示的数据结构在浏览器的console中进行打印输出，将图表可视化结果和浏览器console打印结果分别截图并粘贴至客户端桌面【Release\任务E提交结果.docx】中对应的任务序号下。</p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E7%94%A8%E9%A5%BC%E7%8A%B6%E5%9B%BE%E5%B1%95%E7%A4%BA%E5%90%84%E5%9C%B0%E5%8C%BA%E6%B6%88%E8%B4%B9%E8%83%BD%E5%8A%9B" style="text-align:left;"><strong>子任务二：用饼状图展示各地区消费能力</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">编写Vue工程代码，根据接口，用饼状图展示2020年各地区的消费总额占比，同时将用于图表展示的数据结构在浏览器的console中进行打印输出，将图表可视化结果和浏览器console打印结果分别截图并粘贴至客户端桌面【Release\任务E提交结果.docx】中对应的任务序号下。</p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9A%E7%94%A8%E6%8A%98%E7%BA%BF%E5%9B%BE%E5%B1%95%E7%A4%BA%E6%AF%8F%E5%B9%B4%E4%B8%8A%E6%9E%B6%E5%95%86%E5%93%81%E6%95%B0%E9%87%8F%E7%9A%84%E5%8F%98%E5%8C%96" style="text-align:left;"><strong>子任务三：用折线图展示每年上架商品数量的变化</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">编写Vue工程代码，根据接口，用折线图展示每年上架商品数量的变化情况，同时将用于图表展示的数据结构在浏览器的console中进行打印输出，将图表可视化结果和浏览器console打印结果分别截图并粘贴至客户端桌面【Release\任务E提交结果.docx】中对应的任务序号下。</p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E5%9B%9B%EF%BC%9A%E7%94%A8%E6%9D%A1%E5%BD%A2%E5%9B%BE%E5%B1%95%E7%A4%BA%E6%B6%88%E8%B4%B9%E9%A2%9D%E6%9C%80%E9%AB%98%E7%9A%84%E5%9C%B0%E5%8C%BA" style="text-align:left;"><strong>子任务四：用条形图展示消费额最高的地区</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">编写Vue工程代码，根据接口，用条形图展示2020年消费额最高的5个地区，同时将用于图表展示的数据结构在浏览器的console中进行打印输出，将图表可视化结果和浏览器console打印结果分别截图并粘贴至客户端桌面【Release\任务E提交结果.docx】中对应的任务序号下。</p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%94%EF%BC%9A%E7%94%A8%E6%95%A3%E7%82%B9%E5%9B%BE%E5%B1%95%E7%A4%BA%E7%9C%81%E4%BB%BD%E5%B9%B3%E5%9D%87%E6%B6%88%E8%B4%B9%E9%A2%9D" style="text-align:left;"><strong>子任务五：用散点图展示省份平均消费额</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">编写Vue工程代码，根据接口，用基础散点图展示2020年最高10个省份平均消费额（四舍五入保留两位小数），同时将用于图表展示的数据结构在浏览器的console中进行打印输出，将图表可视化结果和浏览器console打印结果分别截图并粘贴至客户端桌面【Release\任务E提交结果.docx】中对应的任务序号下。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h3 id="%E4%BB%BB%E5%8A%A1F%EF%BC%9A%E7%BB%BC%E5%90%88%E5%88%86%E6%9E%90%EF%BC%8810%E5%88%86%EF%BC%89" style="text-align:center;"><strong><strong><strong>任务</strong></strong><strong><strong>F：综合分析（10分）</strong></strong></strong></h3> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9ASpark%E4%B8%AD%E7%9A%84HashShuffle%E7%9A%84%E6%9C%89%E5%93%AA%E4%BA%9B%E4%B8%8D%E8%B6%B3%EF%BC%9F" style="text-align:left;"><strong>子任务一：Spark中的HashShuffle的有哪些不足？</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">请简述Spark中HashShuffle有哪些不足，将内容编写至客户端桌面【Release\任务F提交结果.docx】中对应的任务序号下。</p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%BA%8C%EF%BC%9A%E8%AF%B7%E7%AE%80%E8%BF%B0Flink%E7%9A%84Slot%E5%92%8Cparallelism%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%E3%80%82" style="text-align:left;"><strong>子任务二：请简述Flink的Slot和parallelism有什么区别。</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">请简述Flink的Slot和parallelism有什么区别，将内容编写至客户端桌面【Release\任务F提交结果.docx】中对应的任务序号下。</p> 
<h4 id="%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%89%EF%BC%9A%E5%88%86%E6%9E%90%E4%B8%8B%E4%B8%80%E5%B9%B4%E5%BA%A6%E7%9A%84%E5%BB%BA%E4%BB%93%E7%9B%AE%E7%9A%84%E5%9C%B0%E3%80%82" style="text-align:left;"><strong>子任务三：分析下一年度的建仓目的地。</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">根据任务E的图表，分析各省份的经济现状，公司决定挑选3个省份进行仓储建设，请问应该在哪些省份建设？将内容编写至客户端桌面【Release\任务F提交结果.docx】中对应的任务序号下。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1cd8da578d8b1e775d8fdaf6c02eaac5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">大语言模型微调和PEFT高效微调</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/aef82d5102a4ec8b04d87322d231c0a1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">蓝牙资讯|未来几年物联网迅猛发展，蓝牙发挥重要作用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>