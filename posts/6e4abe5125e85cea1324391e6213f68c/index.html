<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>（2022，FreGAN）利用频率分量在有限数据下训练 GAN - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="（2022，FreGAN）利用频率分量在有限数据下训练 GAN" />
<meta property="og:description" content="FreGAN: Exploiting Frequency Components for Training GANs under Limited Data
公众号：EDPJ
目录
0. 摘要
1. 简介
2. 相关工作
3. 方法
3.1 小波变换 3.2 高频鉴频器 3.3 跳频连接（Frequency Skip Connection，FSC） 3.4 高频对齐（High-Frequency Alignment，HFA）
3.5 优化
4. 实验
4.1 主要结果
4.2 消融研究 4.3 兼容性与 GAN 平衡（equilibrium）分析 5. 讨论 参考
A. 附录
A.1 更多实现细节
S. 总结
S.1 核心思想
S.2 方法
S.3 优化
0. 摘要 在有限数据下训练 GAN 通常会导致判别器过度拟合和记忆问题，从而导致训练发散。 现有方法通过使用数据扩充、模型正则化或注意力机制来减轻过度拟合。 然而，他们忽略了 GAN 的频率偏差，对频率信息尤其是包含丰富细节的高频信号考虑得很少。 为了充分利用有限数据的频率信息，本文提出了FreGAN，提高了模型的频率感知能力，更加关注高频信号的产生，有利于高质量的生成。 除了利用真实图像和生成图像的频率信息外，我们还将真实图像的频率信号作为自监督约束，这减轻了 GAN 的不平衡并鼓励生成器合成足够的而不是任意的频率信号。 广泛的结果证明了我们的 FreGAN 在改善低数据条件下的生成质量方面的优越性和有效性（尤其是当训练数据少于 100 时）。 此外，FreGAN 可以无缝应用于现有的正则化和注意机制模型，以进一步提升性能。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/6e4abe5125e85cea1324391e6213f68c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-03T16:24:13+08:00" />
<meta property="article:modified_time" content="2023-06-03T16:24:13+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">（2022，FreGAN）利用频率分量在有限数据下训练 GAN</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:center;"><strong>FreGAN: Exploiting Frequency Components for Training GANs under Limited Data</strong></p> 
<p style="text-align:center;">公众号：EDPJ</p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="-toc" style="margin-left:0px;"><a href="#0.%20%E6%91%98%E8%A6%81" rel="nofollow">0. 摘要</a></p> 
<p id="1.%20%E7%AE%80%E4%BB%8B-toc" style="margin-left:0px;"><a href="#1.%20%E7%AE%80%E4%BB%8B" rel="nofollow">1. 简介</a></p> 
<p id="2.%20%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C-toc" style="margin-left:0px;"><a href="#2.%20%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C" rel="nofollow">2. 相关工作</a></p> 
<p id="3.%20%E6%96%B9%E6%B3%95-toc" style="margin-left:0px;"><a href="#3.%20%E6%96%B9%E6%B3%95" rel="nofollow">3. 方法</a></p> 
<p id="3.1%20%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2%C2%A0-toc" style="margin-left:40px;"><a href="#3.1%20%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2%C2%A0" rel="nofollow">3.1 小波变换 </a></p> 
<p id="3.2%20%E9%AB%98%E9%A2%91%E9%89%B4%E9%A2%91%E5%99%A8%C2%A0-toc" style="margin-left:40px;"><a href="#3.2%20%E9%AB%98%E9%A2%91%E9%89%B4%E9%A2%91%E5%99%A8%C2%A0" rel="nofollow">3.2 高频鉴频器 </a></p> 
<p id="3.3%20%E8%B7%B3%E9%A2%91%E8%BF%9E%E6%8E%A5%EF%BC%88Frequency%20Skip%20Connection%EF%BC%8CFSC%EF%BC%89%C2%A0-toc" style="margin-left:40px;"><a href="#3.3%20%E8%B7%B3%E9%A2%91%E8%BF%9E%E6%8E%A5%EF%BC%88Frequency%20Skip%20Connection%EF%BC%8CFSC%EF%BC%89%C2%A0" rel="nofollow">3.3 跳频连接（Frequency Skip Connection，FSC） </a></p> 
<p id="3.4%20%E9%AB%98%E9%A2%91%E5%AF%B9%E9%BD%90%EF%BC%88High-Frequency%20Alignment%EF%BC%8CHFA%EF%BC%89-toc" style="margin-left:40px;"><a href="#3.4%20%E9%AB%98%E9%A2%91%E5%AF%B9%E9%BD%90%EF%BC%88High-Frequency%20Alignment%EF%BC%8CHFA%EF%BC%89" rel="nofollow">3.4 高频对齐（High-Frequency Alignment，HFA）</a></p> 
<p id="3.5%20%E4%BC%98%E5%8C%96-toc" style="margin-left:40px;"><a href="#3.5%20%E4%BC%98%E5%8C%96" rel="nofollow">3.5 优化</a></p> 
<p id="4.%20%E5%AE%9E%E9%AA%8C-toc" style="margin-left:0px;"><a href="#4.%20%E5%AE%9E%E9%AA%8C" rel="nofollow">4. 实验</a></p> 
<p id="4.1%20%E4%B8%BB%E8%A6%81%E7%BB%93%E6%9E%9C-toc" style="margin-left:40px;"><a href="#4.1%20%E4%B8%BB%E8%A6%81%E7%BB%93%E6%9E%9C" rel="nofollow">4.1 主要结果</a></p> 
<p id="4.2%20%E6%B6%88%E8%9E%8D%E7%A0%94%E7%A9%B6%C2%A0-toc" style="margin-left:40px;"><a href="#4.2%20%E6%B6%88%E8%9E%8D%E7%A0%94%E7%A9%B6%C2%A0" rel="nofollow">4.2 消融研究 </a></p> 
<p id="4.3%20%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8E%20GAN%20%E5%B9%B3%E8%A1%A1%EF%BC%88equilibrium%EF%BC%89%E5%88%86%E6%9E%90%C2%A0-toc" style="margin-left:40px;"><a href="#4.3%20%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8E%20GAN%20%E5%B9%B3%E8%A1%A1%EF%BC%88equilibrium%EF%BC%89%E5%88%86%E6%9E%90%C2%A0" rel="nofollow">4.3 兼容性与 GAN 平衡（equilibrium）分析 </a></p> 
<p id="5.%20%E8%AE%A8%E8%AE%BA%C2%A0-toc" style="margin-left:0px;"><a href="#5.%20%E8%AE%A8%E8%AE%BA%C2%A0" rel="nofollow">5. 讨论 </a></p> 
<p id="%E5%8F%82%E8%80%83-toc" style="margin-left:0px;"><a href="#%E5%8F%82%E8%80%83" rel="nofollow">参考</a></p> 
<p id="A.%20%E9%99%84%E5%BD%95-toc" style="margin-left:0px;"><a href="#A.%20%E9%99%84%E5%BD%95" rel="nofollow">A. 附录</a></p> 
<p id="A.1%20%E6%9B%B4%E5%A4%9A%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82-toc" style="margin-left:40px;"><a href="#A.1%20%E6%9B%B4%E5%A4%9A%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82" rel="nofollow">A.1 更多实现细节</a></p> 
<p id="S.%20%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#S.%20%E6%80%BB%E7%BB%93" rel="nofollow">S. 总结</a></p> 
<p id="S.1%20%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3-toc" style="margin-left:40px;"><a href="#S.1%20%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3" rel="nofollow">S.1 核心思想</a></p> 
<p id="S.2%20%E6%96%B9%E6%B3%95-toc" style="margin-left:40px;"><a href="#S.2%20%E6%96%B9%E6%B3%95" rel="nofollow">S.2 方法</a></p> 
<p id="S.3%20%E4%BC%98%E5%8C%96-toc" style="margin-left:40px;"><a href="#S.3%20%E4%BC%98%E5%8C%96" rel="nofollow">S.3 优化</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="0.%20%E6%91%98%E8%A6%81">0. 摘要</h2> 
<p>在有限数据下训练 GAN 通常会导致判别器过度拟合和记忆问题，从而导致训练发散。 现有方法通过使用数据扩充、模型正则化或注意力机制来减轻过度拟合。 然而，他们忽略了 GAN 的频率偏差，对频率信息尤其是包含丰富细节的高频信号考虑得很少。 为了充分利用有限数据的频率信息，本文提出了FreGAN，提高了模型的频率感知能力，更加关注高频信号的产生，有利于高质量的生成。 除了利用真实图像和生成图像的频率信息外，我们还将真实图像的频率信号作为自监督约束，这减轻了 GAN 的不平衡并鼓励生成器合成足够的而不是任意的频率信号。 广泛的结果证明了我们的 FreGAN 在改善低数据条件下的生成质量方面的优越性和有效性（尤其是当训练数据少于 100 时）。 此外，FreGAN 可以无缝应用于现有的正则化和注意机制模型，以进一步提升性能。</p> 
<h2 id="1.%20%E7%AE%80%E4%BB%8B">1. 简介</h2> 
<p><img alt="" height="461" src="https://images2.imgbox.com/af/08/CNWlA0NN_o.png" width="913"></p> 
<p>在有限数据下训练 GAN 通常会导致过度拟合和不稳定问题。 具体来说，当鉴别器 (D) 对有限的训练数据过度拟合时，它只会记住输入的真实图像并将其他图像分类为假图像，从而向生成器 (G) 提供无意义的反馈，从而导致训练发散和生成质量差。 在有限数据下改善合成质量仍然是一个未探索的问题。 最近解决这个问题的方法包括用不同的数据增强来扩大训练集，用附加约束正则化 D 的输出，以及设计新的网络架构。然而，现有的方法主要是从数据规模和模型容量的角度出发，而忽略了数据本身的一个关键属性，即频率信号。 GAN 已被证明在拟合频率信号时具有频谱偏差。 它们优先拟合低频信号并倾向于忽略高频信号（编码垂直和水平边缘等精细细节）。 缺少它们可能会导致不切实际的图像合成和不令人满意的伪影（见图 1）。 本文提出了一种称为 FreGAN 的频率感知模型，以提高 G 和 D 的频率感知能力。通过鼓励 G 生成更合理和足够的高频信号，我们的 FreGAN 在有限数据下改善了合成质量，如 图 1 所示 。</p> 
<p>为了充分利用有限训练数据的频率信息，我们首先通过 Haar 小波变换（wavelet transformation）将图像分解为不同的频率分量。与在图像级别使用的传统小波变换不同，我们对 D 和 G 的中间特征执行它。然后我们使用高频鉴别器 (high-frequency discriminator，HFD) 和频率跳跃连接 (frequency skip connection，FSC) 来分别提高 G 和 D 的频率感知。 然而，G 仍然不知道它应该合成哪些高频信号，并且 D 在看到真假图像后做出真/假决定时过于自信。 这种不平衡的竞争促使我们执行高频对齐 (high-frequency alignment，HFA) 以缓解 G 和 D 之间的信息不对称。创新地，我们明确地利用从 D 诱导的真实图像的频率信号作为自我监督约束来指导 G 正确利用频率知识。 此外，将 HFD 和 HFA 应用于多尺度特征，彻底挖掘有限数据的频率信号，减少频率偏差和高频信息丢失。 </p> 
<h2 id="2.%20%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C">2. 相关工作</h2> 
<p><strong>在有限数据下训练 GAN</strong>。 在有限数据下提高合成质量仍然是一个未被充分探索的问题，最近引起了广泛关注。 训练数据不足会导致鉴别器过度拟合，从而降低生成图像的质量。</p> 
<ul><li>解决这种数据稀缺的一种直接方法是通过各种增强来扩展训练集。</li><li>除了采用传统的增强技术（例如，翻转、裁剪）之外，ADA 和 DiffAug 分别提出了自适应和可微增强来扩大训练数据。</li><li>APA  基于自适应伪增强的过度拟合程度来欺骗 D。</li><li>InsGen 将实例判别作为一项辅助任务，以鼓励 D 区分每个单独的图像，从而提高判别器的判别能力。</li><li>Lecam 在整个训练过程中对鉴别器的输出进行正则化。</li><li>FastGAN 采用跳过层通道激励模块（skip-layer channel-wise excitation module）和自监督鉴别器来稳定和加速训练。</li><li>最近的 MoCA 使用带有注意机制的原型记忆提高了 few-shot 图像生成质量。</li><li>受益于大规模预训练视觉识别模型的重大进展，Vision-aided GAN 使用可用的现成模型来帮助 GAN 训练，ProjectedGAN 通过将生成的图像和真实图像投影到预训练特征空间来改进 GAN。</li><li>另一类方法从在大规模数据上预训练的模型中迁移和重用知识，即 few-shot GAN 自适应。</li></ul> 
<p><strong>GAN 中的小波变换（Wavelet Transformation）</strong>。Schwarz 等人证明 GAN 表现出频率偏差，并且解决频率伪影对于逼真的图像生成是必要的。 因此，GAN 往往会忽略难以生成的高频信号，从而影响生成质量。小波变换将图像分解为具有不同频带的频率分量，已广泛用于 GAN 的各种应用，例如风格转换、图像修复、图像编辑等。</p> 
<ul><li>HiFA 通过直接将高频分量馈入生成器来减轻生成器产生高频信号的压力。</li><li>WaveFill 解耦不同的频率信号并明确填充每个频带中的缺失区域，从而实现卓越的图像修复。</li><li>Zhang 等人提出小波知识蒸馏，以在不降低性能的情况下实现高效的图像到图像转换。</li><li>SWAGAN 将小波与 StyleGAN2 的分层训练相结合，并在图像级别执行小波。</li></ul> 
<p>我们的 FreGAN 更加灵活，通过直接将生成器和鉴别器的中间特征分解到小波域中，并且不需要像 SWAGAN 那样将图像转换为更高/更低分辨率的额外下/上采样，这使我们的方法更加高效。</p> 
<p>与在大量数据上执行的现有方法不同，本文解决了更具挑战性的 few-shot 生成问题。 除了提高模型的频率意识外，我们还通过缩小 G 和 D 之间的频率差距来缓解不健康的竞争。</p> 
<h2 id="3.%20%E6%96%B9%E6%B3%95">3. 方法</h2> 
<p><img alt="" height="691" src="https://images2.imgbox.com/c6/1c/fmOuJ2Z2_o.png" width="1200"></p> 
<p>我们的 FreGAN 的总体框架如图 2 所示。为了制定我们的方法，我们明确地利用小波变换将特征分解为不同的频率分量。 然后，我们使用高频鉴别器 (HFD) 和跳频连接 (FSC) 分别提高 D 和 G 的频率意识。 此外，我们执行高频对齐 (HFA) 以进一步引导 G 合成合理的频率信号。</p> 
<h3 id="3.1%20%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2%C2%A0">3.1 小波变换 </h3> 
<p>为了将图像分解成不同的频率分量，我们采用了一种简单但有效的小波变换，即 Haar 小波。 Haar小波由两个镜像操作组成：小波池化和小波反池化。 前者将图像转换到 hlwavelet 域，后者将频率分量逆重构到空间域。小波池化操作有四个核： </p> 
<p><img alt="" height="47" src="https://images2.imgbox.com/fb/76/W5BWS6Q9_o.png" width="815"></p> 
<p>L 和 H 分别表示低通和高通滤波器。 低通 (L) 滤波器捕捉图像的轮廓和表面，而高通 (H) 滤波器专注于边缘和精致纹理等细节信息。</p> 
<p><img alt="" height="339" src="https://images2.imgbox.com/71/c8/kb51kZlC_o.png" width="1200"></p> 
<p>图 3 说明了通过 Haar 小波获得的给定图像的频率分量。 我们可以观察到，低频分量 LL 包含图像的整体表面，而被高通滤波器分解的分量，即 LH、HL、HH，包含更精细的细节。 进一步，通过将三个高频分量相加，我们近似地获得了图像的所有细节信息，例如猫的眼睛。</p> 
<h3 id="3.2%20%E9%AB%98%E9%A2%91%E9%89%B4%E9%A2%91%E5%99%A8%C2%A0">3.2 高频鉴频器 </h3> 
<p>为了提高 D 的频率意识，我们设计了高频鉴别器 (HFD)。 HFD 负责从频域的角度区分真实图像和生成图像。 形式上，对于鉴别器中的第 i 层，我们对中间特征采用小波池化并得到</p> 
<p class="img-center"><img alt="" height="39" src="https://images2.imgbox.com/d6/0c/1f8tBnRa_o.png" width="322"></p> 
<p>然后我们通过张量加法组合三个高频分量，即</p> 
<p class="img-center"><img alt="" height="38" src="https://images2.imgbox.com/df/64/3BavXH54_o.png" width="411"></p> 
<p>其中包含足够的特征细节。 通过在原始鉴别器之后应用传统的卷积和下采样操作，我们将 HFD 的对抗性损失定义为：</p> 
<p><img alt="" height="163" src="https://images2.imgbox.com/4d/a2/eIMfqQv7_o.png" width="1200"></p> 
<p>其中 HF_real 和 HF_fake 分别是真实图像和假图像的高频信息。 DH 是高频鉴频器。 由于随着网络的加深，D 可能会避开高频信息，因此我们在鉴别器的多层上执行多尺度 HFD。 多尺度运算保证了有限数据中频率信息的充分挖掘和利用，进一步提高了 D 的频率感知能力。 值得注意的是，在 HFD 和等式 2 的指导下，G 也经过优化，产生丰富的高频细节。 </p> 
<h3 id="3.3%20%E8%B7%B3%E9%A2%91%E8%BF%9E%E6%8E%A5%EF%BC%88Frequency%20Skip%20Connection%EF%BC%8CFSC%EF%BC%89%C2%A0">3.3 跳频连接（Frequency Skip Connection，FSC） </h3> 
<p>在使用 HFD 后，生成器能够产生合理的频率信号（见表 5）。 然而，由于 GAN 从低频到高频拟合频率信号，随着网络的加深，高频信号可能会被忽略。 为了防止高频信息的丢失并进一步鼓励生成器产生丰富的细节，我们提出了频率跳跃连接（FSC）。 具体来说，对 G 的第 i 层特征进行小波变换得到频率分量</p> 
<p class="img-center"><img alt="" height="42" src="https://images2.imgbox.com/5c/e5/njP7TYnn_o.png" width="326"></p> 
<p>对于这些分量，我们利用小波反池化（unpooling），从而将高频表示（representation）重构为原始特征。 然后我们明确地将重建的频率表示提供给 G 的下一层。形式上， </p> 
<p><img alt="" height="44" src="https://images2.imgbox.com/8a/64/RiuNs4J7_o.png" width="944"></p> 
<p>其中 F_i 表示第 i 层的特征，Unpooling 是小波反池化操作。 F'_(i+1) 是FSC后得到的特征，将被送入后续层进行进一步运算。 这种跳过连接防止高频信息丢失并保持高频细节。</p> 
<h3 id="3.4%20%E9%AB%98%E9%A2%91%E5%AF%B9%E9%BD%90%EF%BC%88High-Frequency%20Alignment%EF%BC%8CHFA%EF%BC%89">3.4 高频对齐（High-Frequency Alignment，HFA）</h3> 
<p>添加 HFD 和 FSC 显式提高了 G 的频率感知能力，但 G 只能合成任意频率信号。 G 如何利用频率信号仍然不明确，而 D 仍然在竞争中占据主导地位，因为它从真实图像和生成的图像中学习了判别知识。 为了平衡 G 和 D 之间的恶性竞争，我们提出了高频对齐 (HFA)，它涉及从 D 诱导的真实图像的高频信号作为正则化器来引导 G，促进 G 合成更合理和逼真的精细细节。 具体来说，我们提取 G 在不同层的中间特征的频率表示。 对于 G 的第 i 层，我们获得频率分量</p> 
<p class="img-center"><img alt="" height="39" src="https://images2.imgbox.com/79/dd/EEAvYdlc_o.png" width="317"></p> 
<p>我们忽略第一个低频分量并组合后三个高频分量，即</p> 
<p class="img-center"><img alt="" height="37" src="https://images2.imgbox.com/99/71/FAT9pbYZ_o.png" width="395"></p> 
<p>然后我们使用鉴别器高频分量 HF_D 作为自监督约束。 除了骗过 D 之外，G 还要最小化生成图像和真实图像之间高频信息的距离。 对齐损失定义为： </p> 
<p class="img-center"><img alt="" height="36" src="https://images2.imgbox.com/da/c1/VN2abxrA_o.png" width="772"></p> 
<p>其中，||*||_1 表示 L1 范数。 这种对齐鼓励 G 合成接近真实频率信号的频率信号，从而减轻不健康的竞争并提高生成质量。 为了充分利用来自 D 的真实图像的频率信号，我们对多尺度特征（如 HFD）执行 HFA，如图 2 所示。 4.2 节论证在多尺度特征上采用 HFA 和 HFD 的合理性和有效性。 </p> 
<h3 id="3.5%20%E4%BC%98%E5%8C%96">3.5 优化</h3> 
<p>我们采用对抗性损失的铰链（hinge）版本来训练我们的模型。</p> 
<p><img alt="" height="97" src="https://images2.imgbox.com/a4/e6/9ZwIR33F_o.png" width="1039"></p> 
<p>我们还使用重建损失来鼓励鉴别器提取更具代表性的特征。</p> 
<p><img alt="" height="41" src="https://images2.imgbox.com/d2/a6/ROWVXcOA_o.png" width="890"></p> 
<p>其中，f 是 D 的中间特征，G 和 T 表示对特征 f 和输入图像 x 的处理。 总之，我们的判别器和生成器分别通过以下方式优化，每个损失的系数设置为1。</p> 
<p class="img-center"><img alt="" height="37" src="https://images2.imgbox.com/2d/c4/vhUeAv59_o.png" width="269"></p> 
<p class="img-center"><img alt="" height="41" src="https://images2.imgbox.com/36/58/hGOPeSrk_o.png" width="246"></p> 
<h2 id="4.%20%E5%AE%9E%E9%AA%8C">4. 实验</h2> 
<h3 id="4.1%20%E4%B8%BB%E8%A6%81%E7%BB%93%E6%9E%9C">4.1 主要结果</h3> 
<p><img alt="" height="892" src="https://images2.imgbox.com/eb/4a/iTdp92Ej_o.png" width="912"></p> 
<p>对数据量有限的数据集进行定量比较。 我们的 FreGAN 和基线方法在不同分辨率下的定量比较结果在表 1、表 2、表 3 中给出。我们保存每种方法的最佳训练快照并生成 5k 图像来计算 FID 和 KID。 采用整个训练集作为参考分布。</p> 
<ul><li>我们可以从结果中观察到，在具有不同分辨率和数据量的各种数据集上进行了评估，FreGAN 在所有这些数据集上都实现了卓越的性能。</li><li>我们的 FreGAN 在 15 个数据集中的 14 个上持续改进了 FID 和 KID 指标，证明了我们提出的技术的有效性和普遍性。</li><li>值得注意的是，对于数据极其有限（少于 100）的数据集，即 Flat（表 2）、贝壳（Shells）和头骨（Skulls）（表 3），我们的方法显着地提高了性能，例如，在 Flat 上 FID 从 216.27 提高到 178.10，在 Skulls 上从 101.94 到 86.12，相应的 KID 提高了一倍，进一步反映了我们的模型在极其有限的数据下训练 GANs 的潜力。更多定量结果见附录。 </li></ul> 
<p><img alt="" height="512" src="https://images2.imgbox.com/9f/1b/SMCkgC4O_o.png" width="911"></p> 
<p><strong>定性比较</strong>。 FastGAN 和我们的 FreGAN 在各种数据集上的定性结果如图 4 所示。对于图 4 中的每个数据集，从左到右是生成的图像、生成图像的低频和高频分量的可视化。</p> 
<ul><li>FastGAN 生成的图像包含不令人满意的伪影，其中一些是不协调的，例如图 4 右下角生成的猫和狗图像，猫的头部周围有伪影，狗的耳朵扭曲。</li><li>我们的 FreGAN 在协调性、合理性和精细细节方面显着提高了图像质量。 从图4可以看出，我们的 FreGAN 生成的人脸更逼真，动漫脸的眼睛颜色、毛发质地等细节更逼真，猫狗合成的动物脸更真实也更合理。</li><li>此外，我们的 FreGAN 生成的图像的频率分量包含更丰富的细节。 例如生成的 AnimalFace-Cat 图像背景更丰富，生成的 Skulls 图像有更清晰的眼鼻轮廓。 这种观察反映出所提出的 FreGAN：1）在有限数据下改善了生成图像的质量； 2) 提高合成高频信号的频率感知，图像细节更丰富； 3）充分利用有限数据的频率信息。 附录中给出了更多定性结果。 </li></ul> 
<p><img alt="" height="210" src="https://images2.imgbox.com/81/24/sOabueQJ_o.png" width="1200"></p> 
<p><strong>具有更多数据的数据集下的有效性</strong>。为了更全面地研究我们的 FreGAN 的有效性，我们评估了具有更多训练数据的数据集的性能，即 AnimalFace-HQ (AFHQ)，其中包括 3 个具有接近 5k 图像的子数据集，结果显示在表 4。同样，当使用更多数据进行训练时，我们的方法对 FID 和 KID 指标都产生了令人信服的改进。 结合图 4 中生成的图像，结果进一步验证了我们的 FreGAN 对合成质量的贡献。我们的方法提高了不同数据量下的性能，表明我们模型的泛化能力。</p> 
<h3 id="4.2%20%E6%B6%88%E8%9E%8D%E7%A0%94%E7%A9%B6%C2%A0">4.2 消融研究 </h3> 
<p><img alt="" height="335" src="https://images2.imgbox.com/89/39/rp0B1lkM_o.png" width="1200"></p> 
<p><strong>FreGAN 变体的消融研究</strong>。 我们的 FreGAN 包含三个组成部分，即高频鉴别器 (HFD)、高频对齐 (HFA) 和跳频连接 (FSC)。 我们通过从 FreGAN 的完整版本中删除每个组件来评估每个组件的功效。 我们从每个不同分辨率的数据集中选择一个，即 100-shot-OXXma、Anime face 和 pokemon，分别用于 256、512 和 1024 分辨率。 如表 5 所示，移除三种技术中的任何一种都会导致性能下降，反映出每个组件的贡献。 尽管如此，所有这些变体在 FID 和 KID 上都优于基线 FastGAN，这意味着我们方法的不同组件的组合始终如一地提高了模型性能。 而且，去除HFD模块时性能下降最多，这是合理的，因为 HFD 提高了 G 和 D 的频率感知，D 的频率感知作为自我监督，指导 G 合成足够合理的频率信号 . 附录中给出了消融研究的定性比较结果。</p> 
<p><img alt="" height="274" src="https://images2.imgbox.com/09/13/5cFdgup5_o.png" width="1200"></p> 
<p><strong>不同尺度特征的消融研究</strong>。 我们将我们提出的 HFD 和 HFA 应用于 G 和 D 的多尺度特征，即 8、16 和 32 尺度特征。 在这里，我们在表 6 中提供了不同尺度的消融研究。可以看出，对多尺度特征执行 HFD 和 HFA 可以提高模型性能。 此外，当仅对单尺度特征执行 HFD 和 HFA 时，获得的结果仍然优于 FastGAN 基线，表明 HFA 和 HFD 的有效性。 值得注意的是，尽管添加更多尺度的特征可能会带来进一步的性能提升，但对于更高尺度的特征（例如 128、256），所需的额外卷积和下采样层会增加，从而带来不可忽略的计算成本。    </p> 
<p><strong>不同频率分量的消融研究</strong>。 对特征进行小波变换得到三个高频分量，即 LH、HL 和 HH。 如图 3 所示，它们中的每一个都对特征的不同细节进行编码，我们将它们相加以融合所有细节信息，以便在我们的主要实验中进一步操作。 这里我们分别对这三个组件进行实验，以验证它们的贡献和融合它们的必要性。 如表 6 所示，与基线相比，每个高频分量都对模型性能有贡献，融合它们可以更好地提升生成质量。</p> 
<h3 id="4.3%20%E5%85%BC%E5%AE%B9%E6%80%A7%E4%B8%8E%20GAN%20%E5%B9%B3%E8%A1%A1%EF%BC%88equilibrium%EF%BC%89%E5%88%86%E6%9E%90%C2%A0">4.3 兼容性与 GAN 平衡（equilibrium）分析 </h3> 
<p><img alt="" height="303" src="https://images2.imgbox.com/4a/18/XqxHwkFd_o.png" width="1200"></p> 
<p><strong>我们模型的兼容性</strong>。 Lecam 和 MoCA 分别利用正则化和注意机制在有限数据下训练 GAN。 我们在它们上实施我们提出的技术来测试我们方法的兼容性。 我们保持原始设置不变，并将正则化权重设置为 0.1。 FID 结果在表 7 中给出。从中我们可以看出 FreGAN 可以进一步提升 MoCA 和 Lecam 的性能，证明我们的方法是对模型正则化和注意机制方法的补充。 </p> 
<p><img alt="" height="399" src="https://images2.imgbox.com/8a/ec/ZBJID0wT_o.png" width="1200"></p> 
<p><strong>GAN 平衡得到改善</strong>。 我们的 HFA 模块对齐真实图像和生成图像的频率分量，引导 G 合成精确而非任意的高频信号。 同时，作为副产品，HFA 缩小了 G 和 D 之间的域差距，缓解了恶性竞争。</p> 
<ul><li>如图 5 (a) 所示，我们的判别器收敛到一个更好的点，我们的生成器可以更好地欺骗判别器，而 FastGAN 的判别器超过生成器，从而提供较少的信息指导并降低合成质量。</li><li>我们在图 5（b）中绘制了整个训练过程中的 FID 和 KID 曲线，从中我们可以观察到我们的 FreGAN 始终更好。</li><li>我们在图 5（c）中绘制了多尺度 HFA 损失曲线，其中每条线表示每个尺度的损失。 这些曲线表明频率信号对齐良好，缩小了域间隙并促进了 GAN 平衡。 </li></ul> 
<h2 id="5.%20%E8%AE%A8%E8%AE%BA%C2%A0">5. 讨论 </h2> 
<p><strong>结论</strong>。 在本文中，提出了一种在有限数据下训练 GAN 的频率感知方法，即 FreGAN。FreGAN 通过提高模型的频率意识来改善合成质量，鼓励模型更加关注频率信号，尤其是高频信号，这些信号编码图像的精细细节。 我们对具有不同数据量和不同分辨率的各种数据集进行了大量实验，以证明我们提出的方法的有效性。 定性结果表明，我们的模型成功地使生成器生成精确的高频信号，促进了高质量图像的生成。 定量结果表明，我们的方法</p> 
<ul><li>显着提高了性能，尤其是在数据极其有限（少于 100）时</li><li>是对现有正则化和注意力模型的补充。</li><li>还可通过减少频率信息差距来缓解 GAN 的不平衡。</li></ul> 
<p>将来，我们计划在更多主干上实施我们的技术，例如 StyleGAN2，并将我们的方法应用于更多应用程序。 </p> 
<p><strong>限制</strong>。尽管在各种低数据数据集上取得了显着改进，但我们的 FreGAN 在给定数据有限但内容多样的数据集（例如，只有几十张图像，并且它们的内容差异很大）的情况下，仍然难以生成逼真的图像。 当低数据数据集不平衡甚至长尾时，FreGAN 可能无法泛化，这受到数据分布的内在原因的限制。 开发更有效的方法来训练训练数据不足的生成模型仍然需要付出更多的努力。 </p> 
<p></p> 
<h2 id="%E5%8F%82%E8%80%83">参考</h2> 
<p>Yang M, Wang Z, Chi Z, et al. FreGAN: Exploiting Frequency Components for Training GANs under Limited Data[J]. arXiv preprint arXiv:2210.05461, 2022.</p> 
<p></p> 
<h2 id="A.%20%E9%99%84%E5%BD%95">A. 附录</h2> 
<h3 id="A.1%20%E6%9B%B4%E5%A4%9A%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82">A.1 更多实现细节</h3> 
<p><strong>实现 FreGAN 的细节</strong>。 我们对 G 和 D 的中间 8x8, 16x16, 32x32 特征进行 Haar 小波变换。我们通过对分解的高频分量进行小波反池化，并将重建的特征馈送到后续层来执行 FSC。 对于 HFD，我们通过添加 LH、HL、HH 来聚合高频分量，然后使用额外的下采样和卷积层来计算输出分数。 具体来说，该架构类似于原始鉴别器。 在高频分量上添加的层包括 2d 卷积层、2d 批量归一化层和 LeakyReLU 层。 不同之处在于，HFD 对输入图像的频率信息进行了判别，提高了判别器的频率感知能力。 对于 HFA，我们通过最小化主论文中的等式 4 来对齐真实和生成的中间特征的求和频率信号。 值得注意的是，只需为每个高频分量添加 1-2 个附加层，而无需太多计算成本。 我们训练我们的模型进行 100k 次迭代，并每 10k 次迭代保存一次检查点。 保存的检查点用于生成用于评估的图像。 所有实验都在 2 个带有 PyTorch 框架的 Tesla V100 GPU 上运行，我们的代码将在线提供。</p> 
<p></p> 
<h2 id="S.%20%E6%80%BB%E7%BB%93">S. 总结</h2> 
<h3 id="S.1%20%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3">S.1 核心思想</h3> 
<p>为了提高数据有限情况下 GAN 的合成性能，作者考虑使用图像的频率信息。</p> 
<p>GAN 在拟合数据分布时，往往倾向于拟合低频信息（例如，颜色和亮度）而忽略高频信息（边缘等精细细节）。</p> 
<p>本文提出了一种称为 FreGAN 的频率感知模型，以提高 G 和 D 的频率感知能力。通过鼓励 G 生成更合理高频信号，从而提高合成性能。</p> 
<h3 id="S.2%20%E6%96%B9%E6%B3%95">S.2 方法</h3> 
<p><img alt="" height="797" src="https://images2.imgbox.com/e0/14/NpJH6b2Z_o.png" width="1200"></p> 
<p>FreGAN 的总体框架如上图所示。先利用 Haar 小波变换将特征分解为不同的频率分量。 然后，使用高频鉴别器 (HFD) 和跳频连接 (FSC) 分别提高 D 和 G 的频率意识，并使用高频对齐 (HFA) 进一步引导 G 合成合理的频率信号。 </p> 
<p><strong>小波变换</strong>。与在图像级别使用的传统小波变换不同，作者对 D 和 G 的中间特征执行它。</p> 
<p><strong>高频鉴别器（HFD）</strong>。从频域区分真实图像和虚假图像，如公式 1 和 2 所示。（对于公式 2，我认为因为作者的失误，而少添加一个负号）</p> 
<p><img alt="" height="163" src="https://images2.imgbox.com/cd/66/uEjI1Kaw_o.png" width="1200"></p> 
<p>随着网络的加深，D 可能会避开高频信息，因此需要在鉴别器的多层上执行多尺度 HFD，保证有限数据中频率信息被充分挖掘和利用，进一步提高 D 的频率感知能力。 </p> 
<p><strong>跳频连接（FSC）</strong>。GAN 从低频到高频拟合频率信号，随着网络的加深，高频信号可能会被忽略。为了防止高频信息的丢失并进一步鼓励生成器产生丰富的细节，提出了跳频连接（FSC）。</p> 
<p>具体操作是，把 G 每一层重建的频率表示（representation）送入的下一层。</p> 
<p><strong>高频对齐（HFA）</strong>。G 可以合成任意频率信号，为引导 G 利用频率信息，为损失函数添加如下正则化项，使用 D 中间特征频率表示的高频分量监督 G 生成合理的中间特征频率表示的高频分量。</p> 
<p class="img-center"><img alt="" height="36" src="https://images2.imgbox.com/dd/4f/JTsmHCZE_o.png" width="772"></p> 
<p>与 HFD 类似，同样在多层上执行多尺度 HFA。 </p> 
<h3 id="S.3%20%E4%BC%98%E5%8C%96">S.3 优化</h3> 
<p>基础损失函数如公式 5 和 6 所示。</p> 
<p><img alt="" height="97" src="https://images2.imgbox.com/f2/ea/N72vyOG7_o.png" width="1039"></p> 
<p>还使用重建损失来鼓励鉴别器提取更具代表性的特征。</p> 
<p><img alt="" height="41" src="https://images2.imgbox.com/46/c8/Q5QEOPM7_o.png" width="890"></p> 
<p>其中，f 是 D 的中间特征，G 和 T 表示对特征 f 和输入图像 x 的处理。 判别器和生成器分别通过以下方式优化，每个损失的系数设置为1。</p> 
<p class="img-center"><img alt="" height="37" src="https://images2.imgbox.com/d0/ae/PPxAudE2_o.png" width="269"></p> 
<p class="img-center"><img alt="" height="41" src="https://images2.imgbox.com/89/41/yv23BNqt_o.png" width="246"></p> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7a15c2c80a204dfd3697630bdef4444a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">升级pip——报错解决“You should consider upgrading via the ‘pip install --upgrade pip‘ command.”</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0271f79fd5a617559b39484fd6521483/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">（2021，FastGAN）用于高保真 few-shot 图像合成的更快、更稳定的 GAN 训练</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>