<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>NeurIPS 2023 | 用于多示例偏标记学习的消歧注意力嵌入 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="NeurIPS 2023 | 用于多示例偏标记学习的消歧注意力嵌入" />
<meta property="og:description" content="©作者 | 邱思超
单位 | IDEA Lab
来源 | AIforBio
论文标题：
Disambiguated Attention Embedding for Multi-Instance Partial-Label Learning
论文地址：
https://arxiv.org/abs/2305.16912
代码地址：
https://palm.seu.edu.cn/zhangml/files/DEMIPL.rar
今天给大家分享的是东南大学张敏灵教授团队发表在 NeurIPS 2023 的一篇论文“Disambiguated Attention Embedding for Multi-Instance Partial-Label Learning”。这篇文章提出了一种用于多示例偏标签学习的消歧注意力嵌入算法 DEMIPL，它引入了消歧注意力机制与注意力损失将多示例包映射到嵌入空间，进而通过基于动量的消歧策略从候选标签集中识别多示例包的真实标签。
论文介绍
在许多现实世界的任务中，相关对象可以表示为与候选标签集相关联的多示例包，该候选标签集由一个真实标签和几个假阳性标签组成。多示例偏标记学习（MIPL，Multi-Instance Partial-Label learning）是一种处理此类任务的学习范式，并取得了良好的性能。现有的 MIPL 方法遵循示例空间范式，将包的扩充候选标签集分配给每个示例，并从示例级标签聚合包级标签。
然而，该方案具有局限性，因为全局包级别信息被忽略，并且包的预测标签对负面情况的预测敏感。在本文中，作者提出算法 DEMIPL 用于多示例偏标签学习的消歧注意力嵌入。DEMIPL 采用消歧注意力机制将多示例包聚合到单个向量表示中，然后采用基于动量的消歧策略从候选标签集中识别真实标签。
此外，作者提出了一个用于结直肠癌癌症分类的真实 MIPL 数据集。在基准数据集和真实数据集上的实验结果表明，DEMIPL 在性能上优于其他 MIPL 和偏标记学习（PLL，Partial-Label Learning）方法。
方法
▲ 图1. DEMIPL框架图
2.1 DEMIPL框架 设表示示例空间，设表示包含个类标签的标签空间。MIPL 的目标是得到一个分类器。是由个包及其相关的候选标签集组成的训练数据集。
特别地，是第个多示例偏标签样本，其中构成一个带有个示例的包，其中每个示例, 。是隐藏了真实标签的候选标签集，即，在训练过程中真实标签是未知的。
假设中的潜在示例级别标签为，则，且 \ 。在 MIPL 的背景下，如果一个示例的标签与包的真实标签相同，则该示例被视为正示例；否则，它将被视为负示例。此外，负示例的类标签不属于标签空间。
DEMIPL 的框架主要包括三个主要步骤：首先，作者提取多示例包中的示例，并获得示例级别特征。接下来，使用消歧注意力机制将多示例包集成到单个特征向量中。最后，使用分类器来预测多示例包的分类置信度。为了提高分类性能，作者为模型训练引入了两个损失函数：注意力损失和基于动量的消歧损失。在训练过程中，注意力机制和分类器协同工作。
2.2 消歧注意机制 消歧注意机制是 DEMIPL 的关键组成部分，对于多示例包，使用由参数化的神经网络来提取其特征信息：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/8fddeb0ea05449f9071e298c1d558813/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-29T12:38:06+08:00" />
<meta property="article:modified_time" content="2023-12-29T12:38:06+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">NeurIPS 2023 | 用于多示例偏标记学习的消歧注意力嵌入</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/69/fc/JmIx507r_o.gif" alt="7d0a1d746e670957eeaf592a6eb74a9c.gif"></p> 
 <p style="text-align:right;"><strong>©作者 | </strong>邱思超</p> 
 <p style="text-align:right;"><strong>单位 | </strong>IDEA Lab</p> 
 <p style="text-align:right;"><strong>来源 | </strong>AIforBio</p> 
 <h2><br><img src="https://images2.imgbox.com/b8/5a/JS5cpnqI_o.png" alt="0dae35a2f21b70aada61f8abc1f7a6ac.png"></h2> 
 <p style="text-align:left;"><strong>论文标题：</strong></p> 
 <p style="text-align:left;">Disambiguated Attention Embedding for Multi-Instance Partial-Label Learning</p> 
 <p style="text-align:left;"><strong>论文地址：</strong></p> 
 <p style="text-align:left;">https://arxiv.org/abs/2305.16912</p> 
 <p style="text-align:left;"><strong>代码地址：</strong></p> 
 <p style="text-align:left;">https://palm.seu.edu.cn/zhangml/files/DEMIPL.rar</p> 
 <p style="text-align:justify;">今天给大家分享的是东南大学张敏灵教授团队发表在 NeurIPS 2023 的一篇论文“Disambiguated Attention Embedding for Multi-Instance Partial-Label Learning”。这篇文章提出了一种用于多示例偏标签学习的消歧注意力嵌入算法 DEMIPL，它引入了消歧注意力机制与注意力损失将多示例包映射到嵌入空间，进而通过基于动量的消歧策略从候选标签集中识别多示例包的真实标签。</p> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/e0/c9/hFi6k5Gz_o.png" alt="f031cd815a8118b6b69495b6104f6b8e.png"></p> 
 <p style="text-align:left;"><strong>论文介绍</strong></p> 
 <p style="text-align:justify;">在许多现实世界的任务中，相关对象可以表示为与候选标签集相关联的多示例包，该候选标签集由一个真实标签和几个假阳性标签组成。多示例偏标记学习（MIPL，Multi-Instance Partial-Label learning）是一种处理此类任务的学习范式，并取得了良好的性能。现有的 MIPL 方法遵循示例空间范式，将包的扩充候选标签集分配给每个示例，并从示例级标签聚合包级标签。</p> 
 <p style="text-align:justify;">然而，该方案具有局限性，因为全局包级别信息被忽略，并且包的预测标签对负面情况的预测敏感。在本文中，作者提出算法 DEMIPL 用于多示例偏标签学习的消歧注意力嵌入。DEMIPL 采用消歧注意力机制将多示例包聚合到单个向量表示中，然后采用基于动量的消歧策略从候选标签集中识别真实标签。</p> 
 <p style="text-align:justify;">此外，作者提出了一个用于结直肠癌癌症分类的真实 MIPL 数据集。在基准数据集和真实数据集上的实验结果表明，DEMIPL 在性能上优于其他 MIPL 和偏标记学习（PLL，Partial-Label Learning）方法。</p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/46/6a/aezGzlYT_o.png" alt="360c2e8d9289a669a58293ff0e90bca6.png"></p> 
 <p style="text-align:left;"><strong>方法</strong></p> 
 <p style="text-align:justify;"></p> 
 <figcaption> 
  <br> 
 </figcaption> 
 <img src="https://images2.imgbox.com/61/e8/DvnnJJYj_o.png" alt="ff28adda7c2fd650a11bf7bea7f4deba.png"> 
 <p style="text-align:justify;">▲ 图1. DEMIPL框架图</p> 
 <figcaption> 
  <br> 
 </figcaption> 
 <h4>2.1 DEMIPL框架</h4> 
 <p style="text-align:justify;">设表示示例空间，设表示包含个类标签的标签空间。MIPL 的目标是得到一个分类器。是由个包及其相关的候选标签集组成的训练数据集。</p> 
 <p style="text-align:justify;">特别地，是第个多示例偏标签样本，其中构成一个带有个示例的包，其中每个示例, 。是隐藏了真实标签的候选标签集，即，在训练过程中真实标签是未知的。</p> 
 <p style="text-align:justify;">假设中的潜在示例级别标签为，则，且 \ 。在 MIPL 的背景下，如果一个示例的标签与包的真实标签相同，则该示例被视为正示例；否则，它将被视为负示例。此外，负示例的类标签不属于标签空间。</p> 
 <p style="text-align:justify;">DEMIPL 的框架主要包括三个主要步骤：首先，作者提取多示例包中的示例，并获得示例级别特征。接下来，使用消歧注意力机制将多示例包集成到单个特征向量中。最后，使用分类器来预测多示例包的分类置信度。为了提高分类性能，作者为模型训练引入了两个损失函数：注意力损失和基于动量的消歧损失。在训练过程中，注意力机制和分类器协同工作。</p> 
 <h4>2.2 消歧注意机制</h4> 
 <p style="text-align:justify;">消歧注意机制是 DEMIPL 的关键组成部分，对于多示例包，使用由参数化的神经网络来提取其特征信息：</p> 
 <p>其中，是第个包中第个示例的特征。对于MIPL问题，作者提出了一种多类注意机制。首先，计算每个示例与所有类的相关性，然后通过可学习的线性模型将相关性转换为每个示例对包级特征的贡献。的注意力得分计算如下：</p> 
 <p>其中，，，是线性模型的参数。和分别为模型生成非线性输出的双曲正切函数和 Sigmoid 函数。表示按元素相乘。因此，可以通过示例级特征的加权和来聚合包级特征：</p> 
 <p>其中是的包级特征。为了确保聚合的特征准确地表示多示例包，保持注意力得分与示例级别标签的一致性（即正示例的注意力得分应显著高于负示例的注意力分数），注意力损失定义如下：</p> 
 <p>因此，消除歧义的注意力得分可以使包级向量表示具有鉴别性，从而使分类器能够准确地识别标签。</p> 
 <h4>2.3 基于动量的消歧策略</h4> 
 <p>在获得包级特征后，为了从候选标签集中准确识别真实标签，作者使用基于动量的消歧损失来计算每个类别的损失的加权和。具体而言，所提出的基于动量的消歧损失定义如下：</p> 
 <p>其中是指第个迭代轮次。是多示例包的包级特征，是第迭代轮次第类上的模型输出。是交叉熵损失，是第个迭代轮次第类的损失值的权重。</p> 
 <p>根据基于识别的消歧策略，候选标签集上损失值最小的标签可以被视为真实标签，这一过程的目标是为单个真实标签分配权重 1，为其余候选标签分配权重 0。然而，在训练过程中，真实标签是未知的。为了克服这个问题，作者根据类别概率分配权重，确保较大的类别概率与较高的权重相关联。初始化权重的方式如下：</p> 
 <p>其中，是候选标签集的基数。权重更新过程如下：</p> 
 <p>其中动量参数是上一个迭代轮次的权重和当前轮次的输出之间的权衡。T 是最大训练轮次。</p> 
 <h4>2.4 注意机制与消歧策略的协同作用</h4> 
 <p>将注意力损失和消歧损失相结合，得出损失函数如下：</p> 
 <p>其中是注意力损失的恒定权重。在每次迭代中，消歧注意力机制为每个多示例包聚合一个判别向量表示。随后，基于动量的消歧策略将该特征作为输入，并产生消歧的候选标签集，即类别概率。同时，注意力机制依赖于消歧的候选标签集来得到注意力得分。因此，消歧注意力机制和基于动量的消歧策略协同工作。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/36/5c/q3Ayc38j_o.png" alt="c98b450a58cb957e3109921ecff444a4.png"></p> 
 <h3>实验</h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <p>为了研究 DEMIPL 的性能，作者与一种 MIPL 算法和四种 PLL 算法进行对比，分别是 MIPL 算法 MIPLGP，特征感知消歧算法 PL-AGGD，和三种基于深度学习的算法 PRODEN、RC 和 LWS。作者使用了四个图像和生物领域基准 MIPL 数据集 MNIST-MIPL，FMNIST-MIPL，Birdsong-MIPL，和 SIVAL-MIPL。</p> 
 <p>此外，作者还提出了用于结直肠癌癌症分类（CRC）的真实数据集 CRC-MIPL。CRC-MIPL 包括 7000 张从结直肠癌癌症和正常组织拍摄的染色图像，并根据组织细胞类型分为七类之一。作者使用四个图像包生成器：Row、single blob with neighbors (SBN)、k-means segmentation (KMeansSeg) 和 scale-invariant feature transform (SIFT)，分别从每个图像中获得一个示例包。</p> 
 <h4>3.1 在基准数据集上的对比实验</h4> 
 <p>与 MIPLGP 相比，DEMIPL 在大多数情况下表现出更好的性能。与 PLL 算法相比，DEMIPL 在所有基准数据集上取得了最好的性能。实验结果证明了消歧注意机制和基于动量的消歧策略对提高模型性能的有效性。相比 PLL 算法，DEMIPL 能够处理包的原始多示例特征，这比通过 Mean 和 MaxMin 策略获得的退化特征具有更好的判别能力。</p> 
 <p>其次，所提出的基于动量的消歧策略比比较算法的消歧策略更具鲁棒性，并且与 PLL 问题相比，MIPL 问题涉及监督中的模糊性增加，突出了开发 MIPL 专用算法的必要性。</p> 
 <p>作者进一步进行了将 PLL 算法应用于 MIPL 数据的扩展实验，方法是直接将包级候选标签集指定为包内每个示例的候选标签集。然而，PLL 算法的性能都低于 MIPL。此外，大多数比较的 PLL 算法取得了较差的结果，这可能是由于在大多数情况下，真实标签在其各自的候选标签集中不存在。因此，真实标签的缺失阻碍了 MIPL 算法的消歧能力。</p> 
 <p><img src="https://images2.imgbox.com/09/0e/XJC7SDy7_o.png" alt="5cd963b0a0aef136bba5e8105f46d6de.png"></p> 
 <figcaption> 
  ▲ 
   表1 基准数据集上对比实验结果（r为假阳性标签数） 
 </figcaption> 
 <h4>3.2 在真实数据集上的对比实验</h4> 
 <p>与 MIPLGP 相比，DEMIPL 在 CRC-MIPL-SBN 和 CRC-MIPL-KMeansSeg 数据集上取得更好的性能，而在 CRC-MIPL-Row 数据集上仅落后于 MIPLGP。与 PLL 算法相比，DEMIPL 在 32 种情况中的 28 种情况下获得了更好的结果，仅在 CRC-MIPL-Row 和 CRC-MIPL-SBN 上的 2 种情况下表现不佳。</p> 
 <p>其中，CRC-MIPL-KMeansSeg 和 CRC-MIPL-SIFT 是由内容感知生成器生成的示例信息，能够产生语义上有意义的特征，更具信息性和鉴别性；而 CRC-MIPL-Row 和 CRC-MIPL-SBN 都使用固定网格分割图像，并基于它们的像素级颜色和相邻行或网格的颜色来表示示例。因此，CRC-MIPL-Row 和 CRC-MIPL-SBN 中的示例表现出相似的特征表示，在区分正示例和负示例时具有有限的判别能力。</p> 
 <p>实验结果表明，当与更强的包生成器（如 CRC-MIPL-KMeansSeg 和 CRC-MIPL-SIFT）相结合时，DEMIPL 的消歧注意力机制能够学习有意义的嵌入，进而具有显著的性能优势。此外，CRC-MIPL 数据集在每个图像中显示出组织细胞和背景之间的明显差异。平均值策略减少了差异和歧视，在大多数情况下，与平均值策略相比，MaxMin 策略的结果更好。</p> 
 <p><img src="https://images2.imgbox.com/f2/bb/1bqAjLo2_o.png" alt="ff238d985253daea4b99a9e8d7730ea0.png"></p> 
 <figcaption> 
  ▲ 
   表2. 真实数据集上对比实验结果 
  <br> 
 </figcaption> 
 <figcaption> 
   
 </figcaption> 
 <h4>3.3 进一步分析</h4> 
 <h5>注意力损失的有效性</h5> 
 <p>为了验证注意力损失的有效性，作者引入了变体 DEMIPL-MD，相比 DEMIPL 去除注意力损失。实验结果表明在 FMNIST-MIPL 和 SIVAL-MIPL 数据集上，与 DEMIPL-MD 相比，DEMIPL 实现了更高准确性，证明了注意力损失的有效性。</p> 
 <p>为了进一步研究注意力损失所获得的分数，作者可视化了整个训练过程中注意力分数的频率分布。在 epoch=10 时，DEMIPL 生成的注意力得分显示出更高的分散度，这表明 DEMIPL 比 DEMIPL MD 训练得更快。在 epoch=50 和 100 时，DEMIPL 计算的注意力得分倾向于向两个极端收敛：负示例的注意力得分趋向于 0，而正示例的注意力分数接近于 1。因此，所提出的注意力损失准确地将注意力分数分配给正示例和负示例，从而提高了分类的准确性。</p> 
 <p><img src="https://images2.imgbox.com/c9/48/fx3pKHrj_o.png" alt="23d59b4be241fcb4d711641064cc9725.png"></p> 
 <figcaption> 
  ▲ 
   表3. DEMIPL-MD和DEMIPL的分类精度对比 
  <br> 
 </figcaption> 
 <figcaption> 
  <br> 
 </figcaption> 
 <figcaption> 
   
 </figcaption> 
 <img src="https://images2.imgbox.com/43/a1/3IUNSwws_o.png" alt="b51f2a2998fdb0b4514bb960b6ce1603.png"> 
 <figcaption> 
  ▲ 
   图2. MNIST-MIPL数据集上注意力分数的频率分布 
  <br> 
 </figcaption> 
 <figcaption> 
   
 </figcaption> 
 <h5>基于动量的消歧策略的有效性</h5> 
 <p>为了进一步研究基于动量的消歧策略的有效性，作者引入了 DEMIPL-PR 和 DEMIPL-AV 两个变体，DEMIPL-PR 通过设置动量参数λ获得，对应于基于分类器当前输出逐步更新权重。DEMIPL-AV 通过设置动量参数λ获得，在整个训练过程中获得均匀的权重。</p> 
 <p>当假阳性标签的数量较少时，DEMIPL-PR 和 DEMIPL-AV 表现出与 DEMIPL 相似的性能。然而，随着假阳性标签数量的增加，DEMIPL 始终显著优于 DEMIPL-PR 和 DEMIPL-AV。这一结果表明，基于动量的消歧策略在处理更高级别的消歧复杂性时更稳健。此外，在各种场景中，DEMIPL-PR 通常优于DEMIPL-AV。</p> 
 <p>然而，当在 MNIST-MIPL 和 FMNIST-MIPL 数据集中时，DEMIPL-AV 性能超过 DEMIPL-PR。其原因是：在五种分类的背景下有三个假阳性标签代表了一种极端情况。DEMIPL-PR 可能会为假阳性标签分配更高的权重，而 DEMIPL-AV 会统一为每个候选标签分配权重，采用更保守的方法来避免为假阳性标记分配过多的权重。因此，与现有的消歧方法相比，基于动量的消歧策略表现出优越的鲁棒性。</p> 
 <p><img src="https://images2.imgbox.com/6d/ac/yJn9mscH_o.png" alt="3edb3711753043ff0e7a6a796a9921db.png"></p> 
 <p style="text-align:left;">▲ 图3. 不同r下的DEMIPL、DEMIPL-PR和DEMIPL-AV的性能对比<br></p> 
 <figcaption> 
   
 </figcaption> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <h3></h3> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/08/13/oKdbSdAm_o.png" alt="fd620a818a70afe0552cb371b7b94e26.png"></p> 
 <h3>结论</h3> 
 <p>本文提出了基于深度学习的多示例偏标记学习算法 DEMIPL，DEMIPL 利用消歧注意力机制将每个多示例包聚合为单个向量表示，该向量表示进一步与基于动量的消歧策略结合使用，以从候选标签集中确定真实标签。消歧注意力机制和基于动量的策略协同促进了示例空间和标签空间中的消歧。大量的实验结果表明，DEMIPL 的性能优于对比 MIPL 和 PLL 方法。</p> 
 <p><strong>更多阅读</strong></p> 
 <p style="text-align:center;"><a href="" rel="nofollow"><img src="https://images2.imgbox.com/9d/62/01czgKD5_o.png" alt="0caa9b5ca0c45f84aeb8353c6db59df6.png"></a></p> 
 <p style="text-align:center;"><a href="" rel="nofollow"><img src="https://images2.imgbox.com/72/56/tvyXO6TL_o.png" alt="39631872754affe4c561b5e764438edf.png"></a></p> 
 <p style="text-align:center;"><a href="" rel="nofollow"><img src="https://images2.imgbox.com/48/e6/u3CljvwV_o.png" alt="8eb87d5ddd3c250a44c646f8ab17e6bc.png"></a></p> 
 <p><img src="https://images2.imgbox.com/ba/99/CSJ6eilo_o.gif" alt="d4b637d9c834e80171d4f32f6c72263d.gif"></p> 
 <p><strong>#投 稿 通 道#</strong></p> 
 <p><strong> 让你的文字被更多人看到 </strong></p> 
 <p>如何才能让更多的优质内容以更短路径到达读者群体，缩短读者寻找优质内容的成本呢？<strong>答案就是：你不认识的人。</strong></p> 
 <p>总有一些你不认识的人，知道你想知道的东西。PaperWeekly 或许可以成为一座桥梁，促使不同背景、不同方向的学者和学术灵感相互碰撞，迸发出更多的可能性。 </p> 
 <p>PaperWeekly 鼓励高校实验室或个人，在我们的平台上分享各类优质内容，可以是<strong>最新论文解读</strong>，也可以是<strong>学术热点剖析</strong>、<strong>科研心得</strong>或<strong>竞赛经验讲解</strong>等。我们的目的只有一个，让知识真正流动起来。</p> 
 <p>📝 <strong>稿件基本要求：</strong></p> 
 <p>• 文章确系个人<strong>原创作品</strong>，未曾在公开渠道发表，如为其他平台已发表或待发表的文章，请明确标注 </p> 
 <p>• 稿件建议以 <strong>markdown</strong> 格式撰写，文中配图以附件形式发送，要求图片清晰，无版权问题</p> 
 <p>• PaperWeekly 尊重原作者署名权，并将为每篇被采纳的原创首发稿件，提供<strong>业内具有竞争力稿酬</strong>，具体依据文章阅读量和文章质量阶梯制结算</p> 
 <p>📬 <strong>投稿通道：</strong></p> 
 <p>• 投稿邮箱：hr@paperweekly.site </p> 
 <p>• 来稿请备注即时联系方式（微信），以便我们在稿件选用的第一时间联系作者</p> 
 <p>• 您也可以直接添加小编微信（<strong>pwbot02</strong>）快速投稿，备注：姓名-投稿</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/5c/04/elOGfMFe_o.png" alt="c3e6cf42dc987bb9ef39a9ccd711447b.png"></p> 
 <p style="text-align:center;"><strong>△长按添加PaperWeekly小编</strong></p> 
 <p style="text-align:center;">🔍</p> 
 <p style="text-align:center;">现在，在<strong>「知乎」</strong>也能找到我们了</p> 
 <p style="text-align:center;">进入知乎首页搜索<strong>「PaperWeekly」</strong></p> 
 <p style="text-align:center;">点击<strong>「关注」</strong>订阅我们的专栏吧</p> 
 <p>·</p> 
 <p>·</p> 
 <p style="text-align:right;"><img src="https://images2.imgbox.com/37/85/yfvJr6iV_o.jpg" alt="7fd317ab447d44fe5b179a97c9850cea.jpeg"></p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/520b9b52c1929377b2464126c211032c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">OpenLAM | 深度势能预训练大模型DPA-2发布</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3658d1bc455fcfc6655861fd7757af27/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">回归预测 | MATLAB实ZOA-LSTM基于斑马优化算法优化长短期记忆神经网络的多输入单输出数据回归预测模型 （多指标，多图）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>