<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【刘二大人】PyTorch深度学习实践 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【刘二大人】PyTorch深度学习实践" />
<meta property="og:description" content="文章目录 一、overview1 机器学习 二、Linear_Model（线性模型）1 例子引入 三、Gradient_Descent(梯度下降法)1 梯度下降2 梯度下降与随机梯度下降（SGD）对比3 Mini-Batch 四、Back Propagation（反向传播）1 线性模型叠加的神经网络2 反向传播3 在PyTorch中进行前馈和反馈的运算 五、PyTorch实现线性回归1、准备数据集2、设计模型3、构造损失函数和优化器4、训练过程5、代码实现 六、Logistics_Regression（逻辑回归）1 二分类和sigmoid函数2 逻辑回归3 代码实现 七、Multiple Dimension Input（多维特征的输入）1 多维逻辑回归模型2 线性层和人工神经网络3 例子：糖尿病是否恶化的预测3.1 数据集3.2 代码实现 八、Dataset（加载数据集） and Dataloader（Mini-batch）1 Dataloader2 定义Dataset3 代码实现 九、softmax classifier1 softmax层2 损失函数3 代码实现 十、CNN1 basic_CNN1.1 卷积神经网络1.2 卷积操作1.2.1 单通道输入卷积操作1.2.2 3通道输入卷积操作1.2.3 N通道输入 M通道输出卷积操作**1.2.4 卷积层 1.3 basic代码实现1.4 扩充（padding）1.5 步长（stride）1.6 池化（polling）1.7 如何把运算迁移至GPU1.7.1 代码实现 2 advanced_CNN ---- GoogLeNet2.1 GoogLeNet2.2 Inception Module2.2.1 1*1卷积2.2.2 拼接2.2.3 Inception Module代码 2.3 GoogLeNet代码实现 3 advanced_CNN ---- ResNet3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/14e4610e19fc44725adc53ae97c55d06/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-15T11:29:52+08:00" />
<meta property="article:modified_time" content="2023-01-15T11:29:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【刘二大人】PyTorch深度学习实践</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#overview_2" rel="nofollow">一、overview</a></li><li><ul><li><a href="#1__3" rel="nofollow">1 机器学习</a></li></ul> 
  </li><li><a href="#Linear_Model_11" rel="nofollow">二、Linear_Model（线性模型）</a></li><li><ul><li><a href="#1__15" rel="nofollow">1 例子引入</a></li></ul> 
  </li><li><a href="#Gradient_Descent_38" rel="nofollow">三、Gradient_Descent(梯度下降法)</a></li><li><ul><li><a href="#1__54" rel="nofollow">1 梯度下降</a></li><li><a href="#2_SGD_65" rel="nofollow">2 梯度下降与随机梯度下降（SGD）对比</a></li><li><a href="#3_MiniBatch_76" rel="nofollow">3 Mini-Batch</a></li></ul> 
  </li><li><a href="#Back_Propagation_84" rel="nofollow">四、Back Propagation（反向传播）</a></li><li><ul><li><a href="#1__86" rel="nofollow">1 线性模型叠加的神经网络</a></li><li><a href="#2__99" rel="nofollow">2 反向传播</a></li><li><a href="#3_PyTorch_113" rel="nofollow">3 在PyTorch中进行前馈和反馈的运算</a></li></ul> 
  </li><li><a href="#PyTorch_152" rel="nofollow">五、PyTorch实现线性回归</a></li><li><ul><li><a href="#1_154" rel="nofollow">1、准备数据集</a></li><li><a href="#2_163" rel="nofollow">2、设计模型</a></li><li><a href="#3_166" rel="nofollow">3、构造损失函数和优化器</a></li><li><a href="#4_172" rel="nofollow">4、训练过程</a></li><li><a href="#5_174" rel="nofollow">5、代码实现</a></li></ul> 
  </li><li><a href="#Logistics_Regression_215" rel="nofollow">六、Logistics_Regression（逻辑回归）</a></li><li><ul><li><a href="#1_sigmoid_223" rel="nofollow">1 二分类和sigmoid函数</a></li><li><a href="#2__237" rel="nofollow">2 逻辑回归</a></li><li><a href="#3__246" rel="nofollow">3 代码实现</a></li></ul> 
  </li><li><a href="#Multiple_Dimension_Input_303" rel="nofollow">七、Multiple Dimension Input（多维特征的输入）</a></li><li><ul><li><a href="#1__305" rel="nofollow">1 多维逻辑回归模型</a></li><li><a href="#2__312" rel="nofollow">2 线性层和人工神经网络</a></li><li><a href="#3__325" rel="nofollow">3 例子：糖尿病是否恶化的预测</a></li><li><ul><li><a href="#31__327" rel="nofollow">3.1 数据集</a></li><li><a href="#32__336" rel="nofollow">3.2 代码实现</a></li></ul> 
  </li></ul> 
  </li><li><a href="#Dataset_and_DataloaderMinibatch_408" rel="nofollow">八、Dataset（加载数据集） and Dataloader（Mini-batch）</a></li><li><ul><li><a href="#1_Dataloader_411" rel="nofollow">1 Dataloader</a></li><li><a href="#2_Dataset_413" rel="nofollow">2 定义Dataset</a></li><li><a href="#3__420" rel="nofollow">3 代码实现</a></li></ul> 
  </li><li><a href="#softmax_classifier_500" rel="nofollow">九、softmax classifier</a></li><li><ul><li><a href="#1_softmax_505" rel="nofollow">1 softmax层</a></li><li><a href="#2__508" rel="nofollow">2 损失函数</a></li><li><a href="#3__512" rel="nofollow">3 代码实现</a></li></ul> 
  </li><li><a href="#CNN_614" rel="nofollow">十、CNN</a></li><li><ul><li><a href="#1_basic_CNN_615" rel="nofollow">1 basic_CNN</a></li><li><ul><li><a href="#11__616" rel="nofollow">1.1 卷积神经网络</a></li><li><a href="#12__618" rel="nofollow">1.2 卷积操作</a></li><li><ul><li><a href="#121__623" rel="nofollow">1.2.1 单通道输入卷积操作</a></li><li><a href="#122_3_626" rel="nofollow">1.2.2 3通道输入卷积操作</a></li><li><a href="#123_N_M_628" rel="nofollow">1.2.3 N通道输入 M通道输出卷积操作**</a></li><li><a href="#124__630" rel="nofollow">1.2.4 卷积层</a></li></ul> 
    </li><li><a href="#13_basic_632" rel="nofollow">1.3 basic代码实现</a></li><li><a href="#14_padding_659" rel="nofollow">1.4 扩充（padding）</a></li><li><a href="#15_stride_667" rel="nofollow">1.5 步长（stride）</a></li><li><a href="#16_polling_671" rel="nofollow">1.6 池化（polling）</a></li><li><a href="#17_GPU_677" rel="nofollow">1.7 如何把运算迁移至GPU</a></li><li><ul><li><a href="#171__681" rel="nofollow">1.7.1 代码实现</a></li></ul> 
   </li></ul> 
   </li><li><a href="#2_advanced_CNN__GoogLeNet_801" rel="nofollow">2 advanced_CNN ---- GoogLeNet</a></li><li><ul><li><a href="#21_GoogLeNet_803" rel="nofollow">2.1 GoogLeNet</a></li><li><a href="#22_Inception_Module_809" rel="nofollow">2.2 Inception Module</a></li><li><ul><li><a href="#221_11_812" rel="nofollow">2.2.1 1*1卷积</a></li><li><a href="#222__817" rel="nofollow">2.2.2 拼接</a></li><li><a href="#223_Inception_Module_824" rel="nofollow">2.2.3 Inception Module代码</a></li></ul> 
    </li><li><a href="#23_GoogLeNet_863" rel="nofollow">2.3 GoogLeNet代码实现</a></li></ul> 
   </li><li><a href="#3_advanced_CNN__ResNet_991" rel="nofollow">3 advanced_CNN ---- ResNet</a></li><li><ul><li><a href="#31_ResNet_994" rel="nofollow">3.1 ResNet</a></li><li><ul><li><a href="#311_Residual_Block_1000" rel="nofollow">3.1.1 Residual Block(残差结构块)</a></li><li><a href="#312__1004" rel="nofollow">3.1.2 代码实现</a></li></ul> 
   </li></ul> 
  </li></ul> 
  </li><li><a href="#RNN_1122" rel="nofollow">十一、RNN</a></li><li><ul><li><a href="#1_basic_RNN_1123" rel="nofollow">1 basic_RNN</a></li><li><a href="#2_pytorchRNN_1133" rel="nofollow">2 在pytorch中实现RNN</a></li><li><ul><li><a href="#21_RNNCell_1134" rel="nofollow">2.1 定义RNNCell</a></li><li><ul><li><a href="#211__1140" rel="nofollow">2.1.1 代码实现</a></li></ul> 
    </li><li><a href="#22_RNN_1168" rel="nofollow">2.2 使用RNN模型</a></li><li><a href="#221_numlayers_1175" rel="nofollow">2.2.1 numlayers</a></li><li><a href="#222_batch_first_1177" rel="nofollow">2.2.2 batch_first</a></li><li><a href="#222__1181" rel="nofollow">2.2.2 代码实现</a></li></ul> 
   </li><li><a href="#3_helloohlol_1210" rel="nofollow">3 hello-&gt;ohlol</a></li><li><ul><li><a href="#31__1214" rel="nofollow">3.1 代码实现</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="overview_2"></a>一、overview</h2> 
<h3><a id="1__3"></a>1 机器学习</h3> 
<p><s>想写一点，但是不知道写啥，需要补充</s><br> <strong>机器学习（大多数基于统计）就是用算法代替大脑进行运算</strong><br> 合适的算法需要不断调整：设置模型-&gt;利用数据集训练-&gt;验证<br> prediction：将视觉接受的信息转化为抽象概念<br> <img src="https://images2.imgbox.com/ea/d1/BAHlHQH2_o.png" alt="在这里插入图片描述"><br> 机器学习与人工智能的关系<br> <img src="https://images2.imgbox.com/b4/c5/6NHM8jlx_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Linear_Model_11"></a>二、Linear_Model（线性模型）</h2> 
<p>DataSet(数据集) -&gt; Model(模型) -&gt; Training(训练) -&gt; inferring(推理)<br> 关于数据集的介绍：<a href="http://t.csdn.cn/JlSGC" rel="nofollow">训练集 测试集 验证集 </a></p> 
<h3><a id="1__15"></a>1 例子引入</h3> 
<p>已知数据集学习时间x[1，2，3] 成绩y[2，4，6]，测试数据集x=4,y=?<br> <img src="https://images2.imgbox.com/5c/12/LgkAxslo_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>此时数据集分为训练数据集和测试数据集<br> 一般情况下为了避免过拟合，会将测试数据集的一部分作为开发（验证）数据集，用来验证模型的准确程度<br> 监督学习：有标签的数据学习，根据输入值和输出值对模型进行调整；利用一组已知类别的样本调整分类器的参数，使其达到所要求性能的过程</p> 
</blockquote> 
<p><strong>线性模型</strong></p> 
<p><strong>获取最优的线性模型</strong>：因为此时数据集较少采用简单的线性模型。随机选取w以后，计算损失值，然后不停调整w的值（在某个范围内穷举）使得损失值最小<br> <img src="https://images2.imgbox.com/06/ea/4HHjlcGQ_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a7/85/qckTopjM_o.png" alt="在这里插入图片描述"><br> Training Loss针对一个样本<br> Mean Square Error（<strong>MSE平均平方误差</strong>）针对整个训练集<br> <img src="https://images2.imgbox.com/c9/cb/7OsRolkM_o.png" alt="请添加图片描述"></p> 
<p>代码实现<br> <img src="https://images2.imgbox.com/48/23/0GQNfO1a_o.png" alt="在这里插入图片描述"></p> 
<p>损失曲线<br> <img src="https://images2.imgbox.com/f7/9e/lcODf3t8_o.png" alt="请添加图片描述"></p> 
<h2><a id="Gradient_Descent_38"></a>三、Gradient_Descent(梯度下降法)</h2> 
<p><a href="http://t.csdn.cn/0FtxA" rel="nofollow">梯度下降法</a></p> 
<p>利用了贪心的思想，查找当前下降最快的位置</p> 
<p><strong>梯度下降法的基本思想可以类比为一个下山的过程。</strong><br> 假设这样一个场景：一个人被困在山上，要想快速下山就要寻找最陡峭的地方。首先以他当前的所处的位置为基准，寻找这个位置<strong>最陡峭</strong>的地方，然后朝着下降方向走一步，然后又继续以当前位置为基准，再找最陡峭的地方，再走直到最后到达最低处；同理上山也是如此，只是这时候就变成梯度上升算法了</p> 
<p>梯度下降的基本过程就和下山的场景很类似。<br> 首先，我们有一个可微分的函数。<strong>这个函数就代表着一座山</strong>。我们的目标就是找到这个<strong>函数的最小值，也就是山底</strong>。根据之前的场景假设，最快的下山的方式就是找到<strong>当前位置最陡峭的方向</strong>，然后沿着此方向向下走，对应到函数中，就是找到给定点的梯度 ，然后朝着梯度相反的方向，就能让函数值下降的最快！因为梯度的方向就是函数之变化最快的方向(在后面会详细解释)<br> 所以，我们重复利用这个方法，反复求取梯度，最后就能到达局部的最小值，这就类似于我们下山的过程。而求取梯度就确定了最陡峭的方向，也就是场景中测量方向的手段。那么为什么梯度的方向就是最陡峭的方向呢？<br> <em><strong>在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率<br> 在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向</strong></em><br> 到达山底，就需要在每一步观测到此时最陡峭的地方，梯度就恰巧告诉了我们这个方向。梯度的方向是函数在给定点上升最快的方向，那么梯度的反方向就是函数在给定点下降最快的方向，所以我们只要沿着梯度的方向一直走，就能走到<strong>局部的最低点</strong>！</p> 
<h3><a id="1__54"></a>1 梯度下降</h3> 
<p>在线性模型中采用了穷举法，但是对于数据集较大的时候穷举不可行，因此提出梯度下降进行优化。<br> 随机选取一个点，计算梯度，并朝着函数值下降最快的方向走，并且更新w值<br> <img src="https://images2.imgbox.com/81/b1/SQPUJEBa_o.png" alt="在这里插入图片描述"><br> 公式推导<br> <img src="https://images2.imgbox.com/aa/2d/lhlseAfm_o.png" alt="在这里插入图片描述"><br> 代码实现及曲线</p> 
<blockquote> 
 <p>若没有趋近于一个数值说明训练失败，可以适当调整学习率（α）的值</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/64/81/FTPv3TBz_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2_SGD_65"></a>2 梯度下降与随机梯度下降（SGD）对比</h3> 
<p>梯度下降法遇到鞍点无法跳出，但是随机梯度下降可能会跳跃鞍点<br> SGD算法是从<strong>样本中随机抽出一组，训练后按梯度更新一次，然后再抽取一组，再更新一次，在样本量及其大的情况下，可能不用训练完所有的样本就可以获得一个损失值在可接受范围之内的模型了。</strong><br> 这里的随机是指每次迭代过程中，样本都要被随机打乱，打乱是有效减小样本之间造成的参数更新抵消问题。<br> <img src="https://images2.imgbox.com/c7/41/zhgdkOmp_o.png" alt="请添加图片描述"><br> SGD代码实现<br> <img src="https://images2.imgbox.com/5d/b6/ez4DphDZ_o.png" alt="请添加图片描述"></p> 
<blockquote> 
 <p>对梯度下降和随机梯度下降综合一下获取更好的性能<br> 对数据进行分组mini-batch<br> ：组内梯度下降，组间随机梯度下降</p> 
</blockquote> 
<h3><a id="3_MiniBatch_76"></a>3 Mini-Batch</h3> 
<p>**full batch：**在梯度下降中需要对所有样本进行处理过后然后走一步，如果样本规模的特别大的话效率就会比较低。假如有500万，甚至5000万个样本(业务场景中，一般有几千万行，有些大数据有10亿行)的话走一轮迭代就会非常的耗时。</p> 
<p>为了提高效率，我们可以把样本分成等量的子集。 例如我们把100万样本分成1000份， 每份1000个样本， 这些子集就称为<strong>mini batch</strong>。mini-batch的大小一般取2<br> 的n次方<br> 然后我们分别用一个for循环遍历这1000个子集。 针对<strong>每一个子集做一次梯度下降</strong>。 然后更新参数w和b的值。接着到下一个子集中继续进行梯度下降。 这样在遍历完所有的mini batch之后我们相当于在梯度下降中做了1000次迭代。 我们将遍历一次所有样本的行为叫做一个 <strong>epoch</strong>，也就是一个世代。 在mini batch下的梯度下降中做的事情其实跟full batch一样，只不过我们训练的数据不再是所有的样本，而是一个个的子集。 这样在mini batch我们在一个epoch中就能进行1000次的梯度下降，而在full batch中只有一次。 这样就大大的提高了我们算法的运行速度。</p> 
<h2><a id="Back_Propagation_84"></a>四、Back Propagation（反向传播）</h2> 
<p>可以在图上进行梯度传播帮助我们建立一个更好的模型结构</p> 
<h3><a id="1__86"></a>1 线性模型叠加的神经网络</h3> 
<p>如图所示线性模型可以看做一个简单的神经网络<br> <img src="https://images2.imgbox.com/e7/36/ZJoR9gVt_o.png" alt="在这里插入图片描述"></p> 
<p>由线性模型组成的简单神经网络<br> <img src="https://images2.imgbox.com/9c/a6/vnxabAEJ_o.png" alt="请添加图片描述"></p> 
<blockquote> 
 <p>可以发现这个神经网络进行的运算无论叠加多少层一直都是线性运算，提高层数没有意义<br> 因此为了提高模型的复杂程度，我们为神经网络添加一个非线性因素，例如sigmoid函数<br> 在进行完加法运算以后对这个中间变量进行非线性的变换<br> <img src="https://images2.imgbox.com/fd/6a/priafyJg_o.png" alt="请添加图片描述"><br> 复杂的神经网络一般需要多层连接，其中主要是升维或降维的操作<br> <img src="https://images2.imgbox.com/2f/55/GxZm9W3q_o.png" alt="在这里插入图片描述"></p> 
</blockquote> 
<h3><a id="2__99"></a>2 反向传播</h3> 
<p>进行反向传播前先回顾一下链式求导法则：<a href="http://t.csdn.cn/NvJKr" rel="nofollow">链式求导</a><br> <img src="https://images2.imgbox.com/14/d9/E6u0X5yq_o.png" alt="请添加图片描述"><br> 反向传播的链式求导：<br> 1.创建计算图进行前馈运算，沿箭头方向进行运算<br> <img src="https://images2.imgbox.com/e5/cf/Up0Olk4x_o.png" alt="请添加图片描述"><br> 2.求z，同时算出z关于w，z关于x的偏导<img src="https://images2.imgbox.com/b0/8a/LD7b5IK5_o.png" alt="请添加图片描述"><br> 3.求最终的输出L，并得到最终的损失值关于输出z的偏导（前馈的过程就是一步一步算到loss,而loss再一步一步反向传播，就可以拿到上一层L对z的偏导）<img src="https://images2.imgbox.com/d7/32/i3oY0N9r_o.png" alt="请添加图片描述">4.利用链式法则反向求偏导（损失关于w和x的偏导）<br> <img src="https://images2.imgbox.com/08/99/XLC8hZJW_o.png" alt="请添加图片描述"></p> 
<p><strong>简单线性模型的完整计算图（包括前馈与反馈）</strong><br> <img src="https://images2.imgbox.com/8e/6c/dp8CDJHp_o.png" alt="请添加图片描述"></p> 
<h3><a id="3_PyTorch_113"></a>3 在PyTorch中进行前馈和反馈的运算</h3> 
<p>先了解一下Tensor：<a href="http://t.csdn.cn/dLsu3" rel="nofollow">Tensor</a><br> <img src="https://images2.imgbox.com/a1/f5/tvttBU4A_o.png" alt="请添加图片描述"><br> 代码实现：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch

x_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">3.0</span><span class="token punctuation">]</span>
y_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span>

w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># w 是tensor类型</span>
w<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token comment"># 为true表示需要计算梯度</span>

<span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x <span class="token operator">*</span> w <span class="token comment"># 此时w为tensor类型，会自动将x也转换成tensor类型</span>

<span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 失败函数 构建计算图直接用张量</span>
    y_pred <span class="token operator">=</span> forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"predict (before training"</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>forward<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> x<span class="token punctuation">,</span>y <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>x_data<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span> <span class="token comment"># 前馈，计算loss</span>
        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 反馈，l是张量，调用backward函数，可以把数据链路上所有需要梯度的地方都求出来并存到w.grad里</span>
        <span class="token comment"># 每进行一次反馈重新构造一个计算图</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\tgrad:'</span><span class="token punctuation">,</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># item 直接把数值拿出来做成标量</span>
        w<span class="token punctuation">.</span>data <span class="token operator">=</span> w<span class="token punctuation">.</span>data <span class="token operator">-</span> <span class="token number">0.01</span> <span class="token operator">*</span> w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data <span class="token comment"># 此时的w.grad还是一个张量，需要取到data值进行计算，这样不会建立计算图</span>

        w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 梯度数据清零</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"progress:"</span><span class="token punctuation">,</span>epoch<span class="token punctuation">,</span>l<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"predict (after training)"</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span>forward<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<h2><a id="PyTorch_152"></a>五、PyTorch实现线性回归</h2> 
<h3><a id="1_154"></a>1、准备数据集</h3> 
<p><img src="https://images2.imgbox.com/06/2e/NlIfAGBa_o.png" alt="请添加图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="2_163"></a>2、设计模型</h3> 
<p><img src="https://images2.imgbox.com/1b/65/WRvyItPP_o.png" alt="请添加图片描述"></p> 
<h3><a id="3_166"></a>3、构造损失函数和优化器</h3> 
<p><img src="https://images2.imgbox.com/aa/38/mUJKWxjr_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/53/63/3Cd8zq1X_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/3d/5c/9hEjUYbU_o.png" alt="请添加图片描述"></p> 
<h3><a id="4_172"></a>4、训练过程</h3> 
<p><img src="https://images2.imgbox.com/d7/f4/0N9ehxA0_o.jpg" alt="在这里插入图片描述"></p> 
<h3><a id="5_174"></a>5、代码实现</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 线性回归模型</span>
<span class="token keyword">class</span> <span class="token class-name">LinearModel</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 从module继承类</span>
     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
     <span class="token comment"># super调用父类构造</span>
         <span class="token builtin">super</span><span class="token punctuation">(</span>LinearModel<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
         self<span class="token punctuation">.</span>linear <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># （1,1）输入1维，输出也是1维</span>

     <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#只能写forward</span>
         y_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 实现一个可调用的对象</span>
         <span class="token keyword">return</span> y_pred

model <span class="token operator">=</span> LinearModel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># callable</span>

criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span> <span class="token comment"># MSEloss继承自nn.module</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 迭代100次</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span> <span class="token comment"># 前馈</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#此处要用loss.item() </span>
    <span class="token comment">#loss是个对象，调用时会自动调用__str__()函数，不会产生计算图</span>

    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 梯度归零</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 反向传播</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 更新</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w='</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b='</span><span class="token punctuation">,</span>model<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x_test <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_test <span class="token operator">=</span> model<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y_pred='</span><span class="token punctuation">,</span>y_test<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
</code></pre> 
<h2><a id="Logistics_Regression_215"></a>六、Logistics_Regression（逻辑回归）</h2> 
<p><a href="http://t.csdn.cn/15giG" rel="nofollow">逻辑回归和线性回归</a><br> <a href="http://t.csdn.cn/86WzE" rel="nofollow">“分类”和“回归”</a><br> <a href="http://t.csdn.cn/AVoYz" rel="nofollow">逻辑回归和线性回归异同</a><br> 逻辑回归中因变量是离散的，而线性回归中因变量是连续的这是两者最大的区别。因此分类问题中最好使用逻辑回归。<br> 逻辑回归本质是线性回归，但是它加了sigmoid函数</p> 
<h3><a id="1_sigmoid_223"></a>1 二分类和sigmoid函数</h3> 
<p><img src="https://images2.imgbox.com/e2/8b/7Eib83uf_o.png" alt="请添加图片描述"></p> 
<p><strong>二分类损失函数</strong><br> 利用交叉熵函数计算概率，计算的是分布的差异<br> <a href="http://t.csdn.cn/0Zi6U" rel="nofollow">KL散度</a><br> <a href="http://t.csdn.cn/KiwHH" rel="nofollow">交叉熵</a><br> <img src="https://images2.imgbox.com/1d/5d/xCGxCtSc_o.png" alt="请添加图片描述"><strong>Mini-Batch</strong><img src="https://images2.imgbox.com/b0/d7/eGctQWj1_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/14/65/8B7b8CN3_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/29/8a/Qyr5xNcA_o.png" alt="请添加图片描述"></p> 
<h3><a id="2__237"></a>2 逻辑回归</h3> 
<p><a href="http://t.csdn.cn/Rmsug" rel="nofollow">【BCE/MSE/CE】</a><br> 由于逻辑回归本质也是线性回归，所以利用pytorch解决逻辑回归时参考线性回归的四步。</p> 
<ol><li>准备数据集</li><li>设计模型</li><li>构造损失函数和优化器</li><li>训练周期<br> <img src="https://images2.imgbox.com/2c/fb/K4iottSl_o.png" alt="请添加图片描述"></li></ol> 
<h3><a id="3__246"></a>3 代码实现</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F <span class="token comment">#包含了许多函数，sigmoid tanh relu</span>

x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#表示分类，0和1两类</span>
<span class="token comment">#-----------------------#数据集准备</span>

<span class="token keyword">class</span> <span class="token class-name">LogisticRegressionModel</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
         <span class="token builtin">super</span><span class="token punctuation">(</span>LogisticRegressionModel<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
         self<span class="token punctuation">.</span>linear <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># linear做线性变换，求wx+b</span>

     <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
         y_pred <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#sigmoid函数无参，构造函数里不需要初始化，直接用就可以</span>
         <span class="token keyword">return</span> y_pred

model <span class="token operator">=</span> LogisticRegressionModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#-----------------------------------#创建模型</span>

criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
<span class="token comment"># 损失函数有所不同，BCE是二分类交叉熵，MSE是均方误差</span>
<span class="token comment"># loss是否乘1/N，影响学习率的取值</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
<span class="token comment">#-----------------------------------#构造损失函数和优化器</span>

loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
epoch_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#---------------------------------------#训练周期</span>

x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span> <span class="token comment"># 0-10小时，200个数据点</span>
x_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#200行一列的矩阵</span>
y_t <span class="token operator">=</span> model<span class="token punctuation">(</span>x_t<span class="token punctuation">)</span>
y <span class="token operator">=</span> y_t<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c <span class="token operator">=</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Hours'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Probability of Pass'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/5b/9d/Rl2XWtaW_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Multiple_Dimension_Input_303"></a>七、Multiple Dimension Input（多维特征的输入）</h2> 
<h3><a id="1__305"></a>1 多维逻辑回归模型</h3> 
<p><img src="https://images2.imgbox.com/12/cf/3Bo2bAI6_o.png" alt="请添加图片描述"><br> <em><strong>Mini-batch</strong></em><br> <img src="https://images2.imgbox.com/0b/8c/y0jvgOFQ_o.png" alt="请添加图片描述"></p> 
<h3><a id="2__312"></a>2 线性层和人工神经网络</h3> 
<blockquote> 
 <p>逻辑回归只有一层，多个类似逻辑回归的变换首尾相连就可以创建神经网络</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/c5/06/hirzPTUu_o.png" alt="请添加图片描述"></p> 
<blockquote> 
 <p>矩阵是空间变换的函数，所以可以改变维度<br> 神经网络是寻找一种非线性的空间变换的函数<br> linear可以做到空间维度的变换</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/1c/43/OAUo35Nc_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/05/6c/TrPWy3Y1_o.png" alt="请添加图片描述"></p> 
<h3><a id="3__325"></a>3 例子：糖尿病是否恶化的预测</h3> 
<h4><a id="31__327"></a>3.1 数据集</h4> 
<p>每个样本有好几个特征<br> <img src="https://images2.imgbox.com/d9/60/Gpyk0PHJ_o.png" alt="请添加图片描述"><br> <em><strong>四步走：</strong></em></p> 
<ol><li>准备数据集</li><li>设计模型</li><li>构造损失函数和优化器</li><li>训练周期</li></ol> 
<h4><a id="32__336"></a>3.2 代码实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

xy <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'D:\桌面文件\深度学习\刘二大人\PyTorch深度学习实践\diabetes.csv.gz'</span><span class="token punctuation">,</span>delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token comment">#32位浮点数</span>
x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 最后一列不要</span>
y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 只要最后一列 []保证得到矩阵</span>
<span class="token comment">#-------------------------#准备数据集</span>

<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Model<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 不同的地方就是多次降维</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span> <span class="token comment">#8维到6维</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 添加非线性的变化，此处是nn下的sigmoid，是一个模块</span>
        <span class="token comment"># 把此处sigmoid作为一个运算模块，继承自module，不需要传参，只构建一个</span>
        <span class="token comment"># 与functional下的没有区别</span>
        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>activate <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># x = self.sigmoid(self.linear1(x))</span>
        <span class="token comment"># x = self.sigmoid(self.linear2(x))</span>
        <span class="token comment"># x = self.sigmoid(self.linear3(x))</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>activate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>activate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#----------------------------------------#创建模型</span>

criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
<span class="token comment"># 损失函数有所不同，BCE是二分类交叉熵，MSE是均方误差</span>
<span class="token comment"># loss是否乘1/N，影响学习率的取值</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
<span class="token comment">#-----------------------------------#构造损失函数和优化器</span>

epoch_x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
loss_y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#前馈</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span> <span class="token comment"># 所有数据</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span>y_data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment">#画epoch-loss图，x和y轴的数据</span>
    epoch_x<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
    loss_y<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">#反馈</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">#更新</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#---------------------------------------#训练周期</span>
<span class="token comment"># 画图</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch_x<span class="token punctuation">,</span> loss_y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


</code></pre> 
<p><img src="https://images2.imgbox.com/49/f6/y86dE5aI_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Dataset_and_DataloaderMinibatch_408"></a>八、Dataset（加载数据集） and Dataloader（Mini-batch）</h2> 
<p><a href="http://t.csdn.cn/np6bg" rel="nofollow">epoch、Batch-Size、Iteration</a><br> <img src="https://images2.imgbox.com/b2/16/jdsni7NT_o.png" alt="请添加图片描述"></p> 
<h3><a id="1_Dataloader_411"></a>1 Dataloader</h3> 
<p><img src="https://images2.imgbox.com/88/f1/CUT8OGsm_o.png" alt="请添加图片描述"></p> 
<h3><a id="2_Dataset_413"></a>2 定义Dataset</h3> 
<p><img src="https://images2.imgbox.com/2b/f6/7jBedoRq_o.png" alt="请添加图片描述"><br> <em><strong>num_workers注意点</strong></em></p> 
<blockquote> 
 <p>Windows和linux多进程的库不一样，Windows下需要封装起来</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/0b/60/SuaNod3L_o.png" alt="请添加图片描述"></p> 
<h3><a id="3__420"></a>3 代码实现</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># Dataset是抽象类，不能实例化，只能继承dataset类以后才能实例化</span>
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token comment"># 1.创建数据集</span>
<span class="token keyword">class</span> <span class="token class-name">DiabetesDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filepath<span class="token punctuation">)</span><span class="token punctuation">:</span>
        xy <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span>filepath<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token comment"># xy是n行9列,shape得到的[N,9]元组,shape[0]得到的是N</span>
        self<span class="token punctuation">.</span><span class="token builtin">len</span> <span class="token operator">=</span> xy<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>x_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>y_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>xy<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 数据全部都读进来了，需要哪一条数据直接索引即可</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>x_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span><span class="token builtin">len</span>


dataset <span class="token operator">=</span> DiabetesDataset<span class="token punctuation">(</span><span class="token string">'D:\桌面文件\深度学习\刘二大人\PyTorch深度学习实践\diabetes.csv.gz'</span><span class="token punctuation">)</span>
<span class="token comment"># DataLoader构造加载器</span>
train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>
                          batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>
                          shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                          num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># 2.创建模型</span>
<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>linear3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


model <span class="token operator">=</span> Model<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 3.构造损失函数和优化器</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span>size_average<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>

<span class="token comment"># 4.训练周期</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment"># 外层循环</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># train_loader得到的(x,y)元组放入data，从0开始</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># data_x,data_y</span>
            inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
            <span class="token comment"># 前馈</span>
            y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> i<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># 反向传播</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 更新权重</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/5b/72/PnpEsL06_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="softmax_classifier_500"></a>九、softmax classifier</h2> 
<blockquote> 
 <p>将多分类的每个输出看成一个二分类用sigmoid解决的话，会导致输出概率相近<br> 因此引入softmax，softmax对概率归一化，使得输出大于0，概率和为1，可以解决抑制问题</p> 
</blockquote> 
<h3><a id="1_softmax_505"></a>1 softmax层</h3> 
<p><img src="https://images2.imgbox.com/f0/30/d4qIST4a_o.png" alt="请添加图片描述"></p> 
<h3><a id="2__508"></a>2 损失函数</h3> 
<p><img src="https://images2.imgbox.com/0f/36/0mLbHx0L_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/91/f1/KXv2DNbr_o.png" alt="请添加图片描述"></p> 
<h3><a id="3__512"></a>3 代码实现</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms <span class="token comment"># 针对图像处理</span>
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F  <span class="token comment">#使用ReLU</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim  <span class="token comment"># 优化器</span>
<span class="token comment"># 1.数据集准备</span>
batch_size <span class="token operator">=</span> <span class="token number">64</span>
<span class="token comment"># transform pytorch读图像时，神经网络希望输入比较小，</span>
<span class="token comment"># pillow把图像转化为图像张量，单通道转化为多通道</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>  <span class="token comment">#compose可以把[]里的数据进行pipline处理</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 转化成张量</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># normalize归一化，(均值，标准差)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># transform放到数据集里是为了对第i个数据集直接操作</span>
train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span>
                               train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                               download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                               transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span>
                          shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                          batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>

test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist/'</span><span class="token punctuation">,</span>
                              train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                              download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                              transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span>
                         shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                         batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>

<span class="token comment"># 2.构造模型</span>
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span> 
        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>l3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>l4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>l5 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 如果是x.view(1,-1),表示需要转化成一行的向量，但是不知道多少列，需要电脑计算</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span> <span class="token comment"># view改变张量的形式，把（N,1,28,28）变成二阶,-1表示0维度的数字不变</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l4<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>l5<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment">#最后一层不激活</span>


model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 3.损失函数和优化器</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 交叉熵损失</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token comment">#用带冲量的</span>

<span class="token comment"># 4.训练周期+测试集</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> batch_size<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs<span class="token punctuation">,</span> target <span class="token operator">=</span> data <span class="token comment"># x，y</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 在优化器优化之前，进行权重清零;</span>

        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 累计loss</span>
        <span class="token keyword">if</span> batch_size <span class="token operator">%</span> <span class="token number">300</span> <span class="token operator">==</span> <span class="token number">299</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> batch_size <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    correct <span class="token operator">=</span> <span class="token number">0</span>
    total <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 不需要计算梯度</span>
        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            <span class="token comment"># 求每一行最大值的下标，返回最大值，和下标</span>
            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> 
            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># batch_size</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 比较下标与预测值是否接近，求和表示猜对了几个</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy on test set: %d %%'</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
        test<span class="token punctuation">(</span><span class="token punctuation">)</span>



</code></pre> 
<h2><a id="CNN_614"></a>十、CNN</h2> 
<h3><a id="1_basic_CNN_615"></a>1 basic_CNN</h3> 
<h4><a id="11__616"></a>1.1 卷积神经网络</h4> 
<p><img src="https://images2.imgbox.com/0c/9b/vLXVVrTz_o.png" alt="请添加图片描述"></p> 
<h4><a id="12__618"></a>1.2 卷积操作</h4> 
<p>**CCD相机模型：**这是一种通过光敏电阻，利用光强对电阻的阻值影响，对应地影响色彩亮度实现不同亮度等级像素采集的原件。三色图像是采用不同敏感度的光敏电阻实现的。</p> 
<p>**矢量图像：**也就是PPT里通过圆心、边、填充信息描述而来的图像，而非采集的图像；<br> <img src="https://images2.imgbox.com/66/9a/tEdzAzaB_o.png" alt="请添加图片描述"></p> 
<h5><a id="121__623"></a>1.2.1 单通道输入卷积操作</h5> 
<p><img src="https://images2.imgbox.com/2b/99/ht3p7EZV_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/c2/d8/6VZ2XE8z_o.png" alt="请添加图片描述"></p> 
<h5><a id="122_3_626"></a>1.2.2 3通道输入卷积操作</h5> 
<p><img src="https://images2.imgbox.com/fa/4e/rGsDPat1_o.png" alt="请添加图片描述"><img src="https://images2.imgbox.com/5c/f9/eLgUz1y5_o.png" alt="请添加图片描述"></p> 
<h5><a id="123_N_M_628"></a>1.2.3 N通道输入 M通道输出卷积操作**</h5> 
<p><img src="https://images2.imgbox.com/56/80/XdfWlyd6_o.png" alt="请添加图片描述"></p> 
<h5><a id="124__630"></a>1.2.4 卷积层</h5> 
<p><img src="https://images2.imgbox.com/31/aa/9I9vbiFo_o.png" alt="请添加图片描述"></p> 
<h4><a id="13_basic_632"></a>1.3 basic代码实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch

in_channel<span class="token punctuation">,</span> out_channel <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span>
width<span class="token punctuation">,</span> height <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span>
kernel_size <span class="token operator">=</span> <span class="token number">3</span>  <span class="token comment"># 卷积核大小</span>
batch_size <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment"># 正态分布采样 随机生成</span>
<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>  
                    in_channel<span class="token punctuation">,</span>
                    width<span class="token punctuation">,</span>
                    height<span class="token punctuation">)</span>

conv_layer <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channel<span class="token punctuation">,</span>  <span class="token comment"># input n</span>
                             out_channel<span class="token punctuation">,</span> <span class="token comment"># output m </span>
                             kernel_size<span class="token operator">=</span>kernel_size<span class="token punctuation">)</span>

output <span class="token operator">=</span> conv_layer<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>conv_layer<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment">#[输出通道input，输入通道output，卷积核3*3]</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/a6/d2/yA6hB71J_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="14_padding_659"></a>1.4 扩充（padding）</h4> 
<p>padding是为了让源图像最外一圈或多圈像素（取决于kernel的尺寸），能够被卷积核中心取到。<br> 这里有个描述很重要：想要使源图像（1,1）的位置作为第一个与kernel中心重合，参与计算的像素，想想看padding需要扩充多少层，这样就很好计算了吧<br> <img src="https://images2.imgbox.com/3e/2d/dWy79DKW_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/82/35/b3UgF7B5_o.png" alt="请添加图片描述"></p> 
<h4><a id="15_stride_667"></a>1.5 步长（stride）</h4> 
<p>stride操作指的是每次kernel窗口滑动的步长，默认值是1<img src="https://images2.imgbox.com/5d/0d/S42MQhng_o.png" alt="请添加图片描述"><img src="https://images2.imgbox.com/2c/93/KJTCo3hj_o.png" alt="请添加图片描述"></p> 
<h4><a id="16_polling_671"></a>1.6 池化（polling）</h4> 
<p><img src="https://images2.imgbox.com/a3/f2/PHFvomCC_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/58/d8/DyFq29vd_o.png" alt="请添加图片描述"><br> <strong>简单卷积神经网络</strong><br> <img src="https://images2.imgbox.com/40/31/wahiqeu9_o.png" alt="请添加图片描述"></p> 
<h4><a id="17_GPU_677"></a>1.7 如何把运算迁移至GPU</h4> 
<ol><li>把模型迁移至GPU</li><li>用来计算的张量迁移至GPU</li></ol> 
<h5><a id="171__681"></a>1.7.1 代码实现</h5> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> torch

<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span> transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim  <span class="token comment"># (可有可无)</span>

<span class="token keyword">import</span> os

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'KMP_DUPLICATE_LIB_OK'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'TRUE'</span>

batch_size <span class="token operator">=</span> <span class="token number">64</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist/'</span><span class="token punctuation">,</span>
                               train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                               download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                               transform<span class="token operator">=</span>transform
                               <span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>
                          shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                          batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                          <span class="token punctuation">)</span>

test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist/'</span><span class="token punctuation">,</span>
                              train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                              download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                              transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span>
                         shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                         batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                         <span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pooling <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pooling<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pooling<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 选择是GPU CPU</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda:0'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
<span class="token comment"># 表示把整个模型涉及到的权重迁移到GPU</span>
model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> batch_index<span class="token punctuation">,</span> <span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 迁移至GPU(模型数据要在同一块显卡上)</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>

        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> batch_size <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">9</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> batch_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    correct <span class="token operator">=</span> <span class="token number">0</span>
    total <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            
            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> images<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> pred <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>pred <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'accuracy on test set: %d %%'</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> correct <span class="token operator">/</span> total


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    epoch_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
        acc <span class="token operator">=</span> test<span class="token punctuation">(</span><span class="token punctuation">)</span>
        epoch_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
        acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch_list<span class="token punctuation">,</span> acc_list<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/18/fb/uaMniteF_o.png" alt="请添加图片描述"></p> 
<h3><a id="2_advanced_CNN__GoogLeNet_801"></a>2 advanced_CNN ---- GoogLeNet</h3> 
<h4><a id="21_GoogLeNet_803"></a>2.1 GoogLeNet</h4> 
<p>GoogLeNet是一种串行结构的复杂网络；想要实现复杂网络，并且较少代码冗余和多次重写相同功能的程序，面向过程的语言使用函数，面向对象的语言使用类。<br> 在CNN当中，使用Module和block这种模块将具有复用价值的代码块封装成一块积木，供拼接使用。</p> 
<p><img src="https://images2.imgbox.com/40/d5/QPFxFKdJ_o.png" alt="请添加图片描述"><br> 其中一些重复出现的Module称为<strong>Inception</strong></p> 
<h4><a id="22_Inception_Module_809"></a>2.2 Inception Module</h4> 
<p><img src="https://images2.imgbox.com/5f/6b/NSG13aZY_o.png" alt="请添加图片描述"></p> 
<h5><a id="221_11_812"></a>2.2.1 1*1卷积</h5> 
<p>表面上看是1<em>1像素大小的卷积核，它的意义不过是<strong>调整输入和输出的通道数之间的关系</strong><br> 但是它可以<strong>加速运算</strong>，他的作用的确是加速运算，不过其中的原理是：通过1</em>1的核处理过的图像，可以减少后续卷积层的输入通道数<br> <img src="https://images2.imgbox.com/04/ed/BS6YERUq_o.png" alt="请添加图片描述"><br> <strong>加速运算</strong><img src="https://images2.imgbox.com/2b/e8/8wvf9kyb_o.png" alt="请添加图片描述"></p> 
<h5><a id="222__817"></a>2.2.2 拼接</h5> 
<p><strong>以通道的维度拼接</strong><br> <img src="https://images2.imgbox.com/2a/dd/fGCKN2Dz_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/01/90/djRXwvHI_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/46/90/3hr7RNGU_o.png" alt="请添加图片描述"></p> 
<h5><a id="223_Inception_Module_824"></a>2.2.3 Inception Module代码</h5> 
<pre><code class="prism language-python"><span class="token comment">#根据上面将结果的内容，一部分在__init__,一部分在forward</span>
<span class="token keyword">class</span> <span class="token class-name">InceptionA</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token comment">#初始通道未说明，为了在实例化的时候可以指明输入通道是多少</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 1</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>InceptionA<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>branch1x1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 乘号用字母x代替;</span>
        <span class="token comment"># 2</span>
        self<span class="token punctuation">.</span>branch5x5_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>branch5x5_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token comment"># 3</span>
        self<span class="token punctuation">.</span>branch3x3_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 第一个卷积核都是1x1，这个东西是减少操作数的，为了加速运算</span>
        self<span class="token punctuation">.</span>branch3x3_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>branch3x3_3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 4</span>
        self<span class="token punctuation">.</span>branch_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span>
                                     kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># branch 这个词儿，在S2D引用的laina的代码里见过，一个是upper——branch，一个是bottom——branch；</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 1</span>
        branch1x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch1x1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># 2</span>
        branch5x5 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch5x5_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        branch5x5 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch5x5_2<span class="token punctuation">(</span>branch5x5<span class="token punctuation">)</span>
        <span class="token comment"># 3</span>
        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_2<span class="token punctuation">(</span>branch3x3<span class="token punctuation">)</span>
        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_3<span class="token punctuation">(</span>branch3x3<span class="token punctuation">)</span>
        <span class="token comment"># 4</span>
        branch_pool <span class="token operator">=</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        branch_pool <span class="token operator">=</span> self<span class="token punctuation">.</span>branch_pool<span class="token punctuation">(</span>branch_pool<span class="token punctuation">)</span>
        <span class="token comment"># cat拼接</span>
        output <span class="token operator">=</span> <span class="token punctuation">[</span>branch1x1<span class="token punctuation">,</span> branch5x5<span class="token punctuation">,</span> branch3x3<span class="token punctuation">,</span> branch_pool<span class="token punctuation">]</span>

        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>output<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="23_GoogLeNet_863"></a>2.3 GoogLeNet代码实现</h4> 
<pre><code class="prism language-python"><span class="token comment"># advanced CNN</span>

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span> optim
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets  <span class="token comment"># dataset 引用位置</span>
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader  <span class="token comment"># DataLoader 引用位置</span>
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms

batch_size <span class="token operator">=</span> <span class="token number">64</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>

test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist/'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">InceptionA</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 1</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>InceptionA<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>branch1x1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 乘号用字母x代替;</span>
        <span class="token comment"># 2</span>
        self<span class="token punctuation">.</span>branch5x5_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>branch5x5_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token comment"># 3</span>
        self<span class="token punctuation">.</span>branch3x3_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 第一个卷积核都是1x1，这个东西是减少操作数的，为了加速运算</span>
        self<span class="token punctuation">.</span>branch3x3_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>branch3x3_3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 4</span>
        self<span class="token punctuation">.</span>branch_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span>
                                     kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># branch 这个词儿，在S2D引用的laina的代码里见过，一个是upper——branch，一个是bottom——branch；</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 1</span>
        branch1x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch1x1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># 2</span>
        branch5x5 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch5x5_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        branch5x5 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch5x5_2<span class="token punctuation">(</span>branch5x5<span class="token punctuation">)</span>
        <span class="token comment"># 3</span>
        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_2<span class="token punctuation">(</span>branch3x3<span class="token punctuation">)</span>
        branch3x3 <span class="token operator">=</span> self<span class="token punctuation">.</span>branch3x3_3<span class="token punctuation">(</span>branch3x3<span class="token punctuation">)</span>
        <span class="token comment"># 4</span>
        branch_pool <span class="token operator">=</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        branch_pool <span class="token operator">=</span> self<span class="token punctuation">.</span>branch_pool<span class="token punctuation">(</span>branch_pool<span class="token punctuation">)</span>
        <span class="token comment"># cat拼接</span>
        output <span class="token operator">=</span> <span class="token punctuation">[</span>branch1x1<span class="token punctuation">,</span> branch5x5<span class="token punctuation">,</span> branch3x3<span class="token punctuation">,</span> branch_pool<span class="token punctuation">]</span>

        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>output<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 构造两个卷积层，10,88</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">88</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
        <span class="token comment"># 输入通道不同的两个Inception</span>
        self<span class="token punctuation">.</span>incep1 <span class="token operator">=</span> InceptionA<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>incep2 <span class="token operator">=</span> InceptionA<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>mp <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1408</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># 可以先不写，通过报错查看答案填写数字</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        in_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token comment">#卷积-池化-ReLU</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 输入10个通道</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>incep1<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 输出88</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 输入20</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>incep2<span class="token punctuation">(</span>x<span class="token punctuation">)</span> 
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>in_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 1408</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>

criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs<span class="token punctuation">,</span> target <span class="token operator">=</span> data
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> <span class="token number">300</span> <span class="token operator">==</span> <span class="token number">299</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> batch_idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            running_loss <span class="token operator">=</span> <span class="token number">0.0</span>


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    correct <span class="token operator">=</span> <span class="token number">0</span>
    total <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'accuracy on test set: %d %% '</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
        test<span class="token punctuation">(</span><span class="token punctuation">)</span>


</code></pre> 
<p><img src="https://images2.imgbox.com/f8/3b/MuGLVxIi_o.png" alt="请添加图片描述"></p> 
<h3><a id="3_advanced_CNN__ResNet_991"></a>3 advanced_CNN ---- ResNet</h3> 
<p><img src="https://images2.imgbox.com/44/8a/RoQAxug7_o.png" alt="请添加图片描述"><br> <strong>层数越多不一定训练效果越好，有过拟合和梯度消失问题，提出了ResNet</strong><img src="https://images2.imgbox.com/86/0a/Fa09SRHB_o.png" alt="请添加图片描述"></p> 
<h4><a id="31_ResNet_994"></a>3.1 ResNet</h4> 
<p>以往的网络模型是这种<strong>Plain Net</strong>形式：输入数据x，经过Weight Layer(可以是卷积层，也可以是池化或者线性层)，再通过激活函数加入非线性影响因素，最后输出结果H(x)；这种方式使得H(x)对x的偏导数的值分布在（0,1）之间，这在反向传播、复合函数的偏导数逐步累乘的过程中，必然会导致损失函数L对x的偏导数的值，趋近于0，而且，网络层数越深，这种现象就会越明显，最终导致最开始的（也就是靠近输入的）层<strong>没有获得有效的权重更新</strong>，甚至模型失效；</p> 
<p><strong>ResNet</strong>采用了一个非常巧妙的方式解决了H(x)对x的偏导数的值分布在（0,1）之间这个问题：在以往的框架中，<strong>加入一个跳跃</strong>，再原有的网络输出F(x)的基础上，将输入x累加到上面，这样一来，在最终输出H(x)对输入数据x求偏导数的时候，这个结果就会分布在（1,2）之间，这样就<strong>不怕网络在更新权重梯度累乘的过程中，出现乘积越来越趋于0而导致的梯度消失问题</strong>；<br> <img src="https://images2.imgbox.com/58/ce/lJzos9iE_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/a1/63/KQRGUfWA_o.png" alt="请添加图片描述"></p> 
<h5><a id="311_Residual_Block_1000"></a>3.1.1 Residual Block(残差结构块)</h5> 
<p><img src="https://images2.imgbox.com/7b/ce/g5G9oJd9_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/fd/b5/M24FG1ws_o.png" alt="请添加图片描述"></p> 
<h5><a id="312__1004"></a>3.1.2 代码实现</h5> 
<p><img src="https://images2.imgbox.com/ed/4d/iQp9s36s_o.png" alt="请添加图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span> optim
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

batch_size <span class="token operator">=</span> <span class="token number">64</span>
transforms <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist/'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>

test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../dataset/mnist'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">ResidualBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> channels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ResidualBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>channels <span class="token operator">=</span> channels

        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>channels<span class="token punctuation">,</span> channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>channels<span class="token punctuation">,</span> channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x <span class="token operator">+</span> y<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mp <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token comment"># 两个残差结构块</span>
        self<span class="token punctuation">.</span>rbloch1 <span class="token operator">=</span> ResidualBlock<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rbloch2 <span class="token operator">=</span> ResidualBlock<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 可以逐步的测试，先输出第一个，再输出前两个，判断输出是否正确</span>
        in_size <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token comment"># 按照图片的顺行关系依次计算</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>rbloch1<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 使用残差结构块</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>mp<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>rbloch2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>in_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x


model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>

criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        inputs<span class="token punctuation">,</span> target <span class="token operator">=</span> data
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> <span class="token number">300</span> <span class="token operator">==</span> <span class="token number">299</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d, %5d] loss: %.3f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> batch_size <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> <span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            running_loss <span class="token operator">=</span> <span class="token number">0.0</span>


<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    correct <span class="token operator">=</span> <span class="token number">0</span>
    total <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data
            outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

            total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'accuracy on test set: %d %% '</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> correct <span class="token operator">/</span> total


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    epoch_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    acc_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
        acc <span class="token operator">=</span> test<span class="token punctuation">(</span><span class="token punctuation">)</span>
        epoch_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
        acc_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>acc<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch_list<span class="token punctuation">,</span> acc_list<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/23/78/6QQm4otb_o.png" alt="请添加图片描述"></p> 
<h2><a id="RNN_1122"></a>十一、RNN</h2> 
<h3><a id="1_basic_RNN_1123"></a>1 basic_RNN</h3> 
<p>对于一个<strong>全连接网络</strong>，即全部由线性层组成的网络，也称作dense(稠密型) 或者deep（深度型）网络<br> 对于一个卷积神经网络，卷积核对多层图像处理，卷积核不变，所以权重数量少，而全连接网络的线性模型，权重数多，计算量大。</p> 
<p>对于输入的特征具有<strong>明显的序列关系</strong>，如天气时间序列预测，就适合使用<strong>RNN循环神经网络</strong></p> 
<blockquote> 
 <p>注意<strong>信息融合和线性层共享</strong></p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/c7/cb/2HpmIN1R_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/71/3e/0JLaALCH_o.png" alt="请添加图片描述"></p> 
<h3><a id="2_pytorchRNN_1133"></a>2 在pytorch中实现RNN</h3> 
<h4><a id="21_RNNCell_1134"></a>2.1 定义RNNCell</h4> 
<p><img src="https://images2.imgbox.com/30/a1/gkKc0CBx_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/84/57/Ju8ynGHy_o.png" alt="请添加图片描述"></p> 
<p><strong>怎样使用RNNCell</strong><br> <img src="https://images2.imgbox.com/18/c4/Ljqk37m5_o.png" alt="请添加图片描述"></p> 
<h5><a id="211__1140"></a>2.1.1 代码实现</h5> 
<p><img src="https://images2.imgbox.com/2e/ee/fhRZxzcP_o.png" alt="请添加图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token comment"># 参数设置</span>
batch_size <span class="token operator">=</span> <span class="token number">1</span>
seq_len <span class="token operator">=</span> <span class="token number">3</span>
input_size <span class="token operator">=</span> <span class="token number">4</span>
hidden_size <span class="token operator">=</span> <span class="token number">2</span>

cell <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>RNNCell<span class="token punctuation">(</span>input_size <span class="token operator">=</span> input_size<span class="token punctuation">,</span>hidden_size<span class="token operator">=</span>hidden_size<span class="token punctuation">)</span>

<span class="token comment">#(seq,batch,features)</span>
dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>input_size<span class="token punctuation">)</span>
hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>

<span class="token keyword">for</span> idx<span class="token punctuation">,</span><span class="token builtin">input</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'='</span><span class="token operator">*</span><span class="token number">20</span><span class="token punctuation">,</span>idx<span class="token punctuation">,</span><span class="token string">'='</span><span class="token operator">*</span><span class="token number">20</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Input size'</span><span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    hidden <span class="token operator">=</span> cell<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span>hidden<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output size'</span><span class="token punctuation">,</span>hidden<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>hidden<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="22_RNN_1168"></a>2.2 使用RNN模型</h4> 
<p><img src="https://images2.imgbox.com/4d/d9/IRiuVRSl_o.png" alt="请添加图片描述"><br> <strong>数据维度</strong><br> <img src="https://images2.imgbox.com/e7/5c/HPPbpQi3_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/5b/e2/MwfuoVES_o.png" alt="请添加图片描述"></p> 
<h4><a id="221_numlayers_1175"></a>2.2.1 numlayers</h4> 
<p><img src="https://images2.imgbox.com/04/b4/fT1DxPYl_o.png" alt="请添加图片描述"></p> 
<h4><a id="222_batch_first_1177"></a>2.2.2 batch_first</h4> 
<p><img src="https://images2.imgbox.com/d0/af/8jOXiGJ0_o.png" alt="请添加图片描述"></p> 
<h4><a id="222__1181"></a>2.2.2 代码实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token comment"># 参数设置</span>
batch_size <span class="token operator">=</span> <span class="token number">1</span>
seq_len <span class="token operator">=</span> <span class="token number">3</span>
input_size <span class="token operator">=</span> <span class="token number">4</span>
hidden_size <span class="token operator">=</span> <span class="token number">2</span>
<span class="token comment">#比rnncell多一个numlayers</span>
num_layers <span class="token operator">=</span> <span class="token number">1</span>

cell <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size <span class="token operator">=</span> input_size<span class="token punctuation">,</span>hidden_size<span class="token operator">=</span>hidden_size<span class="token punctuation">,</span>
                        num_layers <span class="token operator">=</span> num_layers<span class="token punctuation">)</span>

<span class="token comment">#(seq,batch,features)</span>
<span class="token comment"># 指明维度</span>
inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>input_size<span class="token punctuation">)</span>
hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_layers<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>

out<span class="token punctuation">,</span>hidden <span class="token operator">=</span> cell<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Ouput size'</span><span class="token punctuation">,</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Output:'</span><span class="token punctuation">,</span>out<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'gidden size'</span><span class="token punctuation">,</span>hidden<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'hidden:'</span><span class="token punctuation">,</span>hidden<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="3_helloohlol_1210"></a>3 hello-&gt;ohlol</h3> 
<p><img src="https://images2.imgbox.com/04/8e/BJVxrIbv_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/c0/ef/jikO40IJ_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/09/f9/FY2p4v9f_o.png" alt="请添加图片描述"></p> 
<h4><a id="31__1214"></a>3.1 代码实现</h4> 
<pre><code class="prism language-python"><span class="token comment"># 使用RNN</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span> optim
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

input_size <span class="token operator">=</span> <span class="token number">4</span>
hidden_size <span class="token operator">=</span> <span class="token number">4</span>
num_layers <span class="token operator">=</span> <span class="token number">1</span>
batch_size <span class="token operator">=</span> <span class="token number">1</span>
seq_len <span class="token operator">=</span> <span class="token number">5</span>
<span class="token comment"># 准备数据</span>
idx2char <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'e'</span><span class="token punctuation">,</span> <span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'l'</span><span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">]</span>
x_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>  <span class="token comment"># hello</span>
y_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>  <span class="token comment"># ohlol</span>

one_hot_lookup <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                  <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>  <span class="token comment"># 分别对应0,1,2,3项</span>
x_one_hot <span class="token operator">=</span> <span class="token punctuation">[</span>one_hot_lookup<span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> x_data<span class="token punctuation">]</span>  <span class="token comment"># 组成序列张量</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x_one_hot:'</span><span class="token punctuation">,</span> x_one_hot<span class="token punctuation">)</span>

<span class="token comment"># 构造输入序列和标签</span>
inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>x_one_hot<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> input_size<span class="token punctuation">)</span>
labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>y_data<span class="token punctuation">)</span>  <span class="token comment"># labels维度是: (seqLen * batch_size ，1)</span>


<span class="token comment"># design model</span>
<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span>
                                hidden_size<span class="token operator">=</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>
                                num_layers<span class="token operator">=</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>
        out<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>
        <span class="token comment"># 为了能和labels做交叉熵，需要reshape一下:(seqlen*batchsize, hidden_size),即二维向量，变成一个矩阵</span>
        <span class="token keyword">return</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>


net <span class="token operator">=</span> Model<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">)</span>

<span class="token comment"># loss and optimizer</span>
criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span>

<span class="token comment"># train cycle</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    epoch_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># inputs维度是: (seqLen, batch_size, input_size) labels维度是: (seqLen * batch_size * 1)</span>
        <span class="token comment"># outputs维度是: (seqLen, batch_size, hidden_size)</span>
        outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        _<span class="token punctuation">,</span> idx <span class="token operator">=</span> outputs<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        idx <span class="token operator">=</span> idx<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Predicted: '</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>idx2char<span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">',Epoch [%d/20] loss=%.3f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        epoch_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
        loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epoch_list<span class="token punctuation">,</span> loss_list<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/84/7d/tg8NQcFH_o.png" alt="请添加图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7916cb163f67f5da7855364d6d3282da/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Windows 批处理 DOS命令小记</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bd170462253d9de057e7039a7d408b3e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【玩具代码】用C&#43;&#43;获取窗体进程对应的PID</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>