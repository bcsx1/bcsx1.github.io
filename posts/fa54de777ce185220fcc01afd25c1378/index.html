<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hive_UDF开发指南 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Hive_UDF开发指南" />
<meta property="og:description" content="最近在看 《Hive 编程指南》 其中提到了对Hive 自定义函数的几种扩展，
对于我们日常开发，这个功能还是非常有用的。
打算细致的研究一下，这里我们将研究结果整理成博客，方便大家理解 ：
参考文章：
Hive UDF教程（一）https://blog.csdn.net/u010376788/article/details/50532166Hive开发UDFhttps://blog.csdn.net/qq_33792843/article/details/74945718#commentBoxhive UDF 测试样例开发 https://blog.csdn.net/zwjzqqb/article/details/79042636Hive- UDF&amp;GenericUDF https://www.jianshu.com/p/ca9dce6b5c37[一起学Hive]之十八-Hive UDF开 https://www.cnblogs.com/1130136248wlxk/articles/5519276.htmlHive&#43;GenericUDF示例二 https://blog.csdn.net/wisgood/article/details/26169383Hive&#43;GenericUDF示例一 https://blog.csdn.net/wisgood/article/details/26169313将Hive统计分析结果导入到MySQL数据库表中（三）——使用Hive UDF或GenericUDF http://www.bubuko.com/infodetail-763295.html 本篇主要讲解 UDF , 对于 UDAF (用户自定义聚合函数) ， UDTF ( 用户自定义表生成函数 )
对于 这两个请参考问的其他博文
UDAF (用户自定义聚合函数) UDTF (用户自定义表生成函数)
本文大纲 1. UDF 实现的两种策略
2. UDF 中的注解
3. 简单的 UDF 实现
4. 更为复杂的 GenericUDF 实现
5. 打包,加入到集群中,进行测试。
1. UDF 实现的两种策略 Hive 的 UDF 主要分为2种类型的接口 UDF, GenericUDF 1) UDF 为一种比较简单的类，继承的基类为 org.apache.hadoop.hive.ql.exec.UDF;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/fa54de777ce185220fcc01afd25c1378/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-07-16T11:14:40+08:00" />
<meta property="article:modified_time" content="2018-07-16T11:14:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hive_UDF开发指南</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p></p> 
<p>    最近在看 《Hive 编程指南》 其中提到了对Hive 自定义函数的几种扩展，</p> 
<p>对于我们日常开发，这个功能还是非常有用的。</p> 
<p>    打算细致的研究一下，这里我们将研究结果整理成博客，方便大家理解 ：</p> 
<p></p> 
<p>参考文章：</p> 
<ul><li>Hive UDF教程（一）<a href="https://blog.csdn.net/u010376788/article/details/50532166">https://blog.csdn.net/u010376788/article/details/50532166</a></li><li>Hive开发UDF<a href="https://blog.csdn.net/qq_33792843/article/details/74945718#commentBox">https://blog.csdn.net/qq_33792843/article/details/74945718#commentBox</a></li><li>hive UDF 测试样例开发 <a href="https://blog.csdn.net/zwjzqqb/article/details/79042636">https://blog.csdn.net/zwjzqqb/article/details/79042636</a></li><li>Hive- UDF&amp;GenericUDF <a href="https://www.jianshu.com/p/ca9dce6b5c37" rel="nofollow">https://www.jianshu.com/p/ca9dce6b5c37</a></li><li>[一起学Hive]之十八-Hive UDF开 <a href="https://www.cnblogs.com/1130136248wlxk/articles/5519276.html" rel="nofollow">https://www.cnblogs.com/1130136248wlxk/articles/5519276.html</a></li><li>Hive+GenericUDF示例二 <a href="https://blog.csdn.net/wisgood/article/details/26169383">https://blog.csdn.net/wisgood/article/details/26169383</a></li><li>Hive+GenericUDF示例一 <a href="https://blog.csdn.net/wisgood/article/details/26169313">https://blog.csdn.net/wisgood/article/details/26169313</a></li><li>将Hive统计分析结果导入到MySQL数据库表中（三）——使用Hive UDF或GenericUDF <a href="http://www.bubuko.com/infodetail-763295.html" rel="nofollow">http://www.bubuko.com/infodetail-763295.html</a></li></ul> 
<p></p> 
<p>本篇主要讲解 UDF , 对于 UDAF (用户自定义聚合函数) ， UDTF ( 用户自定义表生成函数 )</p> 
<p>对于 这两个请参考问的其他博文</p> 
<p>UDAF  (用户自定义聚合函数) </p> 
<p>UDTF (用户自定义表生成函数)</p> 
<p></p> 
<h3>本文大纲</h3> 
<p>1. UDF 实现的两种策略</p> 
<p>2. UDF 中的注解</p> 
<p>3. 简单的 UDF 实现</p> 
<p>4. 更为复杂的 GenericUDF 实现</p> 
<p>5. 打包,加入到集群中,进行测试。</p> 
<p></p> 
<p></p> 
<h4><strong><span style="background-color:#a2e043;">1. UDF 实现的两种策略</span></strong></h4> 
<p>Hive 的 UDF  主要分为2种类型的接口 <strong><span style="background-color:#ffd900;">UDF,  GenericUDF </span></strong></p> 
<p>1)    UDF  为一种比较简单的类，继承的基类为 org.apache.hadoop.hive.ql.exec.UDF;</p> 
<p>2)   GenericUDF  相对复杂一些，主要针对于类型检查等具有更好的控制，</p> 
<p>继承的基类为 org.apache.hadoop.hive.ql.udf.generic.GenericUDF;</p> 
<h4></h4> 
<p></p> 
<h4><strong><span style="background-color:#a2e043;">2. UDF 中的注解</span></strong></h4> 
<p>     在对这接口进行讲解之前，我们先对基本的注解进行一下讲解。注解非常有利于我们程序的开发。</p> 
<p></p> 
<p>对于UDF 注解主要使用 @Description 注解</p> 
<p>@Description 注解</p> 
<p>    主要的3个属性： name ， value ,  extended </p> 
<p>    主要的宏 ：_FUNC_</p> 
<p>---------------------------------------------------------------------------------------</p> 
<p>还有一些其他的注解</p> 
<p>    public @interface UDFType {<!-- --></p> 
<p>        boolean deterministic() default true;</p> 
<p>        boolean stateful() default false;</p> 
<p>        boolean distinctLike() default false;</p> 
<p>    }</p> 
<p>=============================</p> 
<p>下面先对 @Description 注解 进行详细的讲解。</p> 
<p>@Description 是<strong>可选的</strong>。该注解主要<strong>注明了关于函数的文档说明。</strong></p> 
<p></p> 
<p>主要的3个属性： name ， value ,  extended </p> 
<p>name :  表明了该函数的名称。</p> 
<p>value :   描述了该函数在  DESCRIBE FUNCTION ... 时 显示的提示。</p> 
<p>extended : 主要用来编写示例，如 函数使用示例，DESCRIBE FUNCTION EXTENDED 显示的提示。</p> 
<p></p> 
<p>主要的宏 ：_FUNC_</p> 
<p>_FUN_ 会被替换为 这个函数定义的“临时”函数名称</p> 
<p></p> 
<p>下面是一些DESCRIBE FUNCTION / DESCRIBE FUNCTION EXTENDED 的例子：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/3b/d7/Ct04r6F2_o.png"></p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/57/76/gCcWfjkN_o.png"></p> 
<p></p> 
<p>下面是一个 @Description  注解使用的示例：</p> 
<pre class="has"><code class="language-html">/**
 * Created by szh on 2018/7/16.
 *
 * @author szh
 * @date 2018/7/16
 */
@Description(
        name = "zodiac",
        value = "_FUNC_ (date) - " +
                " from the input date string " +
                " or separate month and day arguments, \n" +
                " returns the sign of the Zodiac.",
        extended = "Example :\n" +
                "&gt; SELECT _FUNC_ (date_string) FROM src;\n" +
                "&gt; SELECT _FUNC_ (month, day) FROM src;")
public class HiveTestZodiacUDF extends UDF {<!-- --></code></pre> 
<p>===============================</p> 
<p></p> 
<p>    public @interface UDFType {<!-- --></p> 
<p>        boolean deterministic() default true;</p> 
<p>        boolean  stateful() default false;</p> 
<p>        boolean distinctLike() default false;</p> 
<p>    }</p> 
<p></p> 
<p><strong>deterministic 定数性标注：</strong></p> 
<p>    大多数函数都是定数性的，rand() 函数是个例外。如果rand() 是定数性的，那么结果只会在计算阶段计算一次。</p> 
<p>    如果一个UDF 是非定数性的，那么就不会包含在分区裁剪中。</p> 
<p>    因为包含rand() 是非定数性的，因此对于每一行数据，rand() 的值都会重新计算一次。</p> 
<p></p> 
<p><strong>stateful 状态性标注：</strong></p> 
<p>    几乎所有的UDF 默认都是有状态性的，rand() 函数是无状态性的，每次调用都会返回不同的值。</p> 
<p>stateful 适用以下场景：</p> 
<p>    1） 有状态性的UDF 只能使用在SELECT 语句后面， 而不能使用到其他如 WHERE, ON, ORDER, GROUP 语句后面。</p> 
<p>    2）当一个查询语句中存在有状态性的UDF时，其隐含信息是，SELECT 将会和 TRANSFORM (例如，DISTRIBUTE, </p> 
<p>CLUSTER, SORT 语句 ) 进行类似的处理，然会会在对应的Reducer 内部进行执行，以保证结果是预期的结果。    </p> 
<p>    3）如果状态性标记 statefule 设置为 true, 那么这个UDF 同样作为非定数性的。</p> 
<p>（ 即使此时定数性标记 deterministic 的值是显式设置为 true 的 ）。</p> 
<p></p> 
<p><strong>distinctLike 唯一性标注：</strong></p> 
<p>    有些函数，即使其输入的列的值是非排重值，其结果也是类似于使用了DISTINCT 进行了排重操作，这类场景可以定义为</p> 
<p>具有唯一性。</p> 
<p>    例子有min, max ，即使实际数据中有重复值，其最终结果也是唯一排重值。</p> 
<p></p> 
<p><strong>最新版本的 UDFType</strong></p> 
<pre class="has"><code class="language-html">//
// Source code recreated from a .class file by IntelliJ IDEA
// (powered by Fernflower decompiler)
//

package org.apache.hadoop.hive.ql.udf;

import java.lang.annotation.ElementType;
import java.lang.annotation.Inherited;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;
import org.apache.hadoop.hive.common.classification.InterfaceAudience.Public;
import org.apache.hadoop.hive.common.classification.InterfaceStability.Evolving;

@Target({ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Inherited
@Public
@Evolving
public @interface UDFType {
    boolean deterministic() default true;

    boolean stateful() default false;

    boolean distinctLike() default false;

    boolean impliesOrder() default false;
}
</code></pre> 
<p><strong>对于  impliesOrder 属性的作用，目前我不是特别的明确，欢迎清楚的朋友在评论区补充。 </strong></p> 
<p></p> 
<p></p> 
<h4><strong><span style="background-color:#a2e043;">3. 简单的 UDF 实现</span></strong></h4> 
<p>    UDF 主要需要实现evaluate() 函数。</p> 
<p>    并主要通过方法重载的方式实现对多种数据的支持。</p> 
<p>需要注意的是：</p> 
<p>   在查询执行过程中，查询中对应的每个应用到该函数的地方都会对这个类进行实例化。</p> 
<p></p> 
<p>示例如下：</p> 
<p>UDF 功能描述，该UDF 主要用于判断某一个日期属于哪一个星座。</p> 
<pre class="has"><code class="language-html">package com.test.hive.udf;

import org.apache.hadoop.hive.ql.exec.Description;
import org.apache.hadoop.hive.ql.exec.UDF;
import org.apache.hadoop.hive.ql.udf.UDFType;
import org.joda.time.DateTime;

import java.util.Date;

/**
 * Created by szh on 2018/7/16.
 *
 * @author szh
 * @date 2018/7/16
 */
@UDFType
@Description(
        name = "zodiac",
        value = "_FUNC_ (date) - " +
                " from the input date string " +
                " or separate month and day arguments, \n" +
                " returns the sign of the Zodiac.",
        extended = "Example :\n" +
                "&gt; SELECT _FUNC_ (date_string) FROM src;\n" +
                "&gt; SELECT _FUNC_ (month, day) FROM src;")
public class HiveTestZodiacUDF extends UDF {


    private static final String ERROR_DATE_OF_MONTH = "invalid date of specify month";

    private static final String ERROR_MONTH_ARGS = "invalid argument of month";

    private static final String ERROR_DATE_STRING = "invalid date format";

    public String evaluate(Date bday) {

        return this.evaluate(bday.getMonth(), bday.getDay());
    }

    public String evaluate(String dateString) {

        DateTime dateTime = null;
        try {
            dateTime = new DateTime(dateString);
        } catch (Exception e) {
            return ERROR_DATE_STRING;
        }
        return this.evaluate(dateTime.getMonthOfYear(), dateTime.getDayOfMonth());
    }


    public String evaluate(Integer month, Integer day) {

        switch (month) {
            //判断是几月
            case 1:
                //判断是当前月的哪一段时间；然后就可以得到星座了；下面代码都一样的
                if (day &gt; 0 &amp;&amp; day &lt; 20) {
                    return "魔蝎座";
                } else if (day &lt; 32) {
                    return "水瓶座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 2:
                if (day &gt; 0 &amp;&amp; day &lt; 19) {
                    return "水瓶座";
                } else if (day &lt; 29) {
                    return "双鱼座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 3:
                if (day &gt; 0 &amp;&amp; day &lt; 21) {
                    return "双鱼座";
                } else if (day &lt; 32) {
                    return "白羊座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 4:
                if (day &gt; 0 &amp;&amp; day &lt; 20) {
                    return "白羊座";
                } else if (day &lt; 31) {
                    return "金牛座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 5:
                if (day &gt; 0 &amp;&amp; day &lt; 21) {
                    return "金牛座";
                } else if (day &lt; 32) {
                    return "双子座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 6:
                if (day &gt; 0 &amp;&amp; day &lt; 22) {
                    return "双子座";
                } else if (day &lt; 31) {
                    return "巨蟹座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 7:
                if (day &gt; 0 &amp;&amp; day &lt; 23) {
                    return "巨蟹座";
                } else if (day &lt; 32) {
                    return "狮子座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 8:
                if (day &gt; 0 &amp;&amp; day &lt; 23) {
                    return "狮子座";
                } else if (day &lt; 32) {
                    return "处女座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 9:
                if (day &gt; 0 &amp;&amp; day &lt; 23) {
                    return "处女座";
                } else if (day &lt; 31) {
                    return "天平座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 10:
                if (day &gt; 0 &amp;&amp; day &lt; 24) {
                    return "天平座";
                } else if (day &lt; 32) {
                    return "天蝎座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 11:
                if (day &gt; 0 &amp;&amp; day &lt; 23) {
                    return "天蝎座";
                } else if (day &lt; 31) {
                    return "射手座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 12:
                if (day &gt; 0 &amp;&amp; day &lt; 22) {
                    return "射手座";
                } else if (day &lt; 32) {
                    return "摩羯座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            default:
                return ERROR_MONTH_ARGS;
        }

    }

}
</code></pre> 
<p></p> 
<p></p> 
<h4><strong><span style="background-color:#a2e043;">4. 更为复杂的 GenericUDF 实现</span></strong></h4> 
<p>   GenericUDF 是一个更为复杂的类，其主要对代码整理构建，使用了模板模式，规范了各个步奏应该完成的流程。</p> 
<p>我们先来看下 GenricUDF 的源码：</p> 
<pre class="has"><code class="language-java">//
// Source code recreated from a .class file by IntelliJ IDEA
// (powered by Fernflower decompiler)
//

package org.apache.hadoop.hive.ql.udf.generic;

import java.io.Closeable;
import java.io.IOException;
import java.sql.Timestamp;
import java.text.ParseException;
import java.util.Date;
import org.apache.hadoop.hive.ql.exec.FunctionRegistry;
import org.apache.hadoop.hive.ql.exec.MapredContext;
import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException;
import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;
import org.apache.hadoop.hive.ql.metadata.HiveException;
import org.apache.hadoop.hive.ql.udf.UDFType;
import org.apache.hadoop.hive.serde2.io.ByteWritable;
import org.apache.hadoop.hive.serde2.io.DateWritable;
import org.apache.hadoop.hive.serde2.io.DoubleWritable;
import org.apache.hadoop.hive.serde2.io.ShortWritable;
import org.apache.hadoop.hive.serde2.io.TimestampWritable;
import org.apache.hadoop.hive.serde2.objectinspector.ConstantObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils;
import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector.Category;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.Converter;
import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector.PrimitiveCategory;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorUtils.PrimitiveGrouping;
import org.apache.hadoop.io.BooleanWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hive.common.util.DateUtils;

@UDFType(
    deterministic = true
)
public abstract class GenericUDF implements Closeable {
    private static final String[] ORDINAL_SUFFIXES = new String[]{"th", "st", "nd", "rd", "th", "th", "th", "th", "th", "th"};

    public GenericUDF() {
    }

    public abstract ObjectInspector initialize(ObjectInspector[] var1) throws UDFArgumentException;

    public void configure(MapredContext context) {
    }

    public ObjectInspector initializeAndFoldConstants(ObjectInspector[] arguments) throws UDFArgumentException {
        ObjectInspector oi = this.initialize(arguments);
        if(this.getRequiredFiles() == null &amp;&amp; this.getRequiredJars() == null) {
            boolean allConstant = true;

            for(int ii = 0; ii &lt; arguments.length; ++ii) {
                if(!ObjectInspectorUtils.isConstantObjectInspector(arguments[ii])) {
                    allConstant = false;
                    break;
                }
            }

            if(allConstant &amp;&amp; !ObjectInspectorUtils.isConstantObjectInspector((ObjectInspector)oi) &amp;&amp; FunctionRegistry.isDeterministic(this) &amp;&amp; !FunctionRegistry.isStateful(this) &amp;&amp; ObjectInspectorUtils.supportsConstantObjectInspector((ObjectInspector)oi)) {
                GenericUDF.DeferredObject[] argumentValues = new GenericUDF.DeferredJavaObject[arguments.length];

                for(int ii = 0; ii &lt; arguments.length; ++ii) {
                    argumentValues[ii] = new GenericUDF.DeferredJavaObject(((ConstantObjectInspector)arguments[ii]).getWritableConstantValue());
                }

                try {
                    Object constantValue = this.evaluate(argumentValues);
                    oi = ObjectInspectorUtils.getConstantObjectInspector((ObjectInspector)oi, constantValue);
                } catch (HiveException var6) {
                    throw new UDFArgumentException(var6);
                }
            }

            return (ObjectInspector)oi;
        } else {
            return (ObjectInspector)oi;
        }
    }

    public String[] getRequiredJars() {
        return null;
    }

    public String[] getRequiredFiles() {
        return null;
    }

    public abstract Object evaluate(GenericUDF.DeferredObject[] var1) throws HiveException;

    public abstract String getDisplayString(String[] var1);

    public void close() throws IOException {
    }

    public GenericUDF flip() {
        return this;
    }

    public GenericUDF negative() {
        throw new UnsupportedOperationException("Negative function doesn't exist for " + this.getFuncName());
    }

    public String getUdfName() {
        return this.getClass().getName();
    }

    public void copyToNewInstance(Object newInstance) throws UDFArgumentException {
        if(this.getClass() != newInstance.getClass()) {
            throw new UDFArgumentException("Invalid copy between " + this.getClass().getName() + " and " + newInstance.getClass().getName());
        }
    }

    protected String getStandardDisplayString(String name, String[] children) {
        return this.getStandardDisplayString(name, children, ", ");
    }

    protected String getStandardDisplayString(String name, String[] children, String delim) {
        StringBuilder sb = new StringBuilder();
        sb.append(name);
        sb.append("(");
        if(children.length &gt; 0) {
            sb.append(children[0]);

            for(int i = 1; i &lt; children.length; ++i) {
                sb.append(delim);
                sb.append(children[i]);
            }
        }

        sb.append(")");
        return sb.toString();
    }

    protected String getFuncName() {
        return this.getClass().getSimpleName().substring(10).toLowerCase();
    }

    protected void checkArgsSize(ObjectInspector[] arguments, int min, int max) throws UDFArgumentLengthException {
        if(arguments.length &lt; min || arguments.length &gt; max) {
            StringBuilder sb = new StringBuilder();
            sb.append(this.getFuncName());
            sb.append(" requires ");
            if(min == max) {
                sb.append(min);
            } else {
                sb.append(min).append("..").append(max);
            }

            sb.append(" argument(s), got ");
            sb.append(arguments.length);
            throw new UDFArgumentLengthException(sb.toString());
        }
    }

    protected void checkArgPrimitive(ObjectInspector[] arguments, int i) throws UDFArgumentTypeException {
        Category oiCat = arguments[i].getCategory();
        if(oiCat != Category.PRIMITIVE) {
            throw new UDFArgumentTypeException(i, this.getFuncName() + " only takes primitive types as " + this.getArgOrder(i) + " argument, got " + oiCat);
        }
    }

    protected void checkArgGroups(ObjectInspector[] arguments, int i, PrimitiveCategory[] inputTypes, PrimitiveGrouping... grps) throws UDFArgumentTypeException {
        PrimitiveCategory inputType = ((PrimitiveObjectInspector)arguments[i]).getPrimitiveCategory();
        PrimitiveGrouping[] var6 = grps;
        int j = grps.length;

        for(int var8 = 0; var8 &lt; j; ++var8) {
            PrimitiveGrouping grp = var6[var8];
            if(PrimitiveObjectInspectorUtils.getPrimitiveGrouping(inputType) == grp) {
                inputTypes[i] = inputType;
                return;
            }
        }

        StringBuilder sb = new StringBuilder();
        sb.append(this.getFuncName());
        sb.append(" only takes ");
        sb.append(grps[0]);

        for(j = 1; j &lt; grps.length; ++j) {
            sb.append(", ");
            sb.append(grps[j]);
        }

        sb.append(" types as ");
        sb.append(this.getArgOrder(i));
        sb.append(" argument, got ");
        sb.append(inputType);
        throw new UDFArgumentTypeException(i, sb.toString());
    }

    protected void obtainStringConverter(ObjectInspector[] arguments, int i, PrimitiveCategory[] inputTypes, Converter[] converters) throws UDFArgumentTypeException {
        PrimitiveObjectInspector inOi = (PrimitiveObjectInspector)arguments[i];
        PrimitiveCategory inputType = inOi.getPrimitiveCategory();
        Converter converter = ObjectInspectorConverters.getConverter(arguments[i], PrimitiveObjectInspectorFactory.writableStringObjectInspector);
        converters[i] = converter;
        inputTypes[i] = inputType;
    }

    protected void obtainIntConverter(ObjectInspector[] arguments, int i, PrimitiveCategory[] inputTypes, Converter[] converters) throws UDFArgumentTypeException {
        PrimitiveObjectInspector inOi = (PrimitiveObjectInspector)arguments[i];
        PrimitiveCategory inputType = inOi.getPrimitiveCategory();
        switch(null.$SwitchMap$org$apache$hadoop$hive$serde2$objectinspector$PrimitiveObjectInspector$PrimitiveCategory[inputType.ordinal()]) {
        case 1:
        case 2:
        case 3:
        case 4:
            Converter converter = ObjectInspectorConverters.getConverter(arguments[i], PrimitiveObjectInspectorFactory.writableIntObjectInspector);
            converters[i] = converter;
            inputTypes[i] = inputType;
            return;
        default:
            throw new UDFArgumentTypeException(i, this.getFuncName() + " only takes INT/SHORT/BYTE types as " + this.getArgOrder(i) + " argument, got " + inputType);
        }
    }

    protected void obtainLongConverter(ObjectInspector[] arguments, int i, PrimitiveCategory[] inputTypes, Converter[] converters) throws UDFArgumentTypeException {
        PrimitiveObjectInspector inOi = (PrimitiveObjectInspector)arguments[i];
        PrimitiveCategory inputType = inOi.getPrimitiveCategory();
        switch(null.$SwitchMap$org$apache$hadoop$hive$serde2$objectinspector$PrimitiveObjectInspector$PrimitiveCategory[inputType.ordinal()]) {
        case 1:
        case 2:
        case 3:
        case 5:
            Converter converter = ObjectInspectorConverters.getConverter(arguments[i], PrimitiveObjectInspectorFactory.writableIntObjectInspector);
            converters[i] = converter;
            inputTypes[i] = inputType;
            return;
        case 4:
        default:
            throw new UDFArgumentTypeException(i, this.getFuncName() + " only takes LONG/INT/SHORT/BYTE types as " + this.getArgOrder(i) + " argument, got " + inputType);
        }
    }

    protected void obtainDoubleConverter(ObjectInspector[] arguments, int i, PrimitiveCategory[] inputTypes, Converter[] converters) throws UDFArgumentTypeException {
        PrimitiveObjectInspector inOi = (PrimitiveObjectInspector)arguments[i];
        PrimitiveCategory inputType = inOi.getPrimitiveCategory();
        Converter converter = ObjectInspectorConverters.getConverter(arguments[i], PrimitiveObjectInspectorFactory.writableDoubleObjectInspector);
        converters[i] = converter;
        inputTypes[i] = inputType;
    }

    protected void obtainDateConverter(ObjectInspector[] arguments, int i, PrimitiveCategory[] inputTypes, Converter[] converters) throws UDFArgumentTypeException {
        PrimitiveObjectInspector inOi = (PrimitiveObjectInspector)arguments[i];
        PrimitiveCategory inputType = inOi.getPrimitiveCategory();
        Object outOi;
        switch(null.$SwitchMap$org$apache$hadoop$hive$serde2$objectinspector$PrimitiveObjectInspector$PrimitiveCategory[inputType.ordinal()]) {
        case 4:
        case 9:
        case 10:
            outOi = PrimitiveObjectInspectorFactory.writableDateObjectInspector;
            break;
        case 5:
        default:
            throw new UDFArgumentTypeException(i, this.getFuncName() + " only takes STRING_GROUP or DATE_GROUP types as " + this.getArgOrder(i) + " argument, got " + inputType);
        case 6:
        case 7:
        case 8:
            outOi = PrimitiveObjectInspectorFactory.writableStringObjectInspector;
        }

        converters[i] = ObjectInspectorConverters.getConverter(inOi, (ObjectInspector)outOi);
        inputTypes[i] = inputType;
    }

    protected void obtainTimestampConverter(ObjectInspector[] arguments, int i, PrimitiveCategory[] inputTypes, Converter[] converters) throws UDFArgumentTypeException {
        PrimitiveObjectInspector inOi = (PrimitiveObjectInspector)arguments[i];
        PrimitiveCategory inputType = inOi.getPrimitiveCategory();
        switch(null.$SwitchMap$org$apache$hadoop$hive$serde2$objectinspector$PrimitiveObjectInspector$PrimitiveCategory[inputType.ordinal()]) {
        case 6:
        case 7:
        case 8:
        case 9:
        case 10:
            ObjectInspector outOi = PrimitiveObjectInspectorFactory.writableTimestampObjectInspector;
            converters[i] = ObjectInspectorConverters.getConverter(inOi, outOi);
            inputTypes[i] = inputType;
            return;
        default:
            throw new UDFArgumentTypeException(i, this.getFuncName() + " only takes STRING_GROUP or DATE_GROUP types as " + this.getArgOrder(i) + " argument, got " + inputType);
        }
    }

    protected String getStringValue(GenericUDF.DeferredObject[] arguments, int i, Converter[] converters) throws HiveException {
        Object obj;
        return (obj = arguments[i].get()) == null?null:converters[i].convert(obj).toString();
    }

    protected Integer getIntValue(GenericUDF.DeferredObject[] arguments, int i, Converter[] converters) throws HiveException {
        Object obj;
        if((obj = arguments[i].get()) == null) {
            return null;
        } else {
            Object writableValue = converters[i].convert(obj);
            int v = ((IntWritable)writableValue).get();
            return Integer.valueOf(v);
        }
    }

    protected Long getLongValue(GenericUDF.DeferredObject[] arguments, int i, Converter[] converters) throws HiveException {
        Object obj;
        if((obj = arguments[i].get()) == null) {
            return null;
        } else {
            Object writableValue = converters[i].convert(obj);
            long v = ((LongWritable)writableValue).get();
            return Long.valueOf(v);
        }
    }

    protected Double getDoubleValue(GenericUDF.DeferredObject[] arguments, int i, Converter[] converters) throws HiveException {
        Object obj;
        if((obj = arguments[i].get()) == null) {
            return null;
        } else {
            Object writableValue = converters[i].convert(obj);
            double v = ((DoubleWritable)writableValue).get();
            return Double.valueOf(v);
        }
    }

    protected Date getDateValue(GenericUDF.DeferredObject[] arguments, int i, PrimitiveCategory[] inputTypes, Converter[] converters) throws HiveException {
        Object obj;
        if((obj = arguments[i].get()) == null) {
            return null;
        } else {
            Object date;
            switch(null.$SwitchMap$org$apache$hadoop$hive$serde2$objectinspector$PrimitiveObjectInspector$PrimitiveCategory[inputTypes[i].ordinal()]) {
            case 6:
            case 7:
            case 8:
                String dateStr = converters[i].convert(obj).toString();

                try {
                    date = DateUtils.getDateFormat().parse(dateStr);
                    break;
                } catch (ParseException var9) {
                    return null;
                }
            case 9:
            case 10:
                Object writableValue = converters[i].convert(obj);
                date = ((DateWritable)writableValue).get();
                break;
            default:
                throw new UDFArgumentTypeException(0, this.getFuncName() + " only takes STRING_GROUP and DATE_GROUP types, got " + inputTypes[i]);
            }

            return (Date)date;
        }
    }

    protected Timestamp getTimestampValue(GenericUDF.DeferredObject[] arguments, int i, Converter[] converters) throws HiveException {
        Object obj;
        if((obj = arguments[i].get()) == null) {
            return null;
        } else {
            Object writableValue = converters[i].convert(obj);
            if(writableValue == null) {
                return null;
            } else {
                Timestamp ts = ((TimestampWritable)writableValue).getTimestamp();
                return ts;
            }
        }
    }

    protected String getConstantStringValue(ObjectInspector[] arguments, int i) {
        Object constValue = ((ConstantObjectInspector)arguments[i]).getWritableConstantValue();
        String str = constValue == null?null:constValue.toString();
        return str;
    }

    protected Boolean getConstantBooleanValue(ObjectInspector[] arguments, int i) throws UDFArgumentTypeException {
        Object constValue = ((ConstantObjectInspector)arguments[i]).getWritableConstantValue();
        if(constValue == null) {
            return Boolean.valueOf(false);
        } else if(constValue instanceof BooleanWritable) {
            return Boolean.valueOf(((BooleanWritable)constValue).get());
        } else {
            throw new UDFArgumentTypeException(i, this.getFuncName() + " only takes BOOLEAN types as " + this.getArgOrder(i) + " argument, got " + constValue.getClass());
        }
    }

    protected Integer getConstantIntValue(ObjectInspector[] arguments, int i) throws UDFArgumentTypeException {
        Object constValue = ((ConstantObjectInspector)arguments[i]).getWritableConstantValue();
        if(constValue == null) {
            return null;
        } else {
            int v;
            if(constValue instanceof IntWritable) {
                v = ((IntWritable)constValue).get();
            } else if(constValue instanceof ShortWritable) {
                v = ((ShortWritable)constValue).get();
            } else {
                if(!(constValue instanceof ByteWritable)) {
                    throw new UDFArgumentTypeException(i, this.getFuncName() + " only takes INT/SHORT/BYTE types as " + this.getArgOrder(i) + " argument, got " + constValue.getClass());
                }

                v = ((ByteWritable)constValue).get();
            }

            return Integer.valueOf(v);
        }
    }

    protected String getArgOrder(int i) {
        ++i;
        switch(i % 100) {
        case 11:
        case 12:
        case 13:
            return i + "th";
        default:
            return i + ORDINAL_SUFFIXES[i % 10];
        }
    }

    public static class DeferredJavaObject implements GenericUDF.DeferredObject {
        private final Object value;

        public DeferredJavaObject(Object value) {
            this.value = value;
        }

        public void prepare(int version) throws HiveException {
        }

        public Object get() throws HiveException {
            return this.value;
        }
    }

    public interface DeferredObject {
        void prepare(int var1) throws HiveException;

        Object get() throws HiveException;
    }
}</code></pre> 
<p>    可以看到对于GenericUDF 类，我们使用了  <strong>deterministic</strong> 定数性标注， </p> 
<p><strong>deterministic 定数性标注：</strong></p> 
<p>    大多数函数都是定数性的，rand() 函数是个例外。如果rand() 是定数性的，那么结果只会在计算阶段计算一次。</p> 
<p>    如果一个UDF 是非定数性的，那么就不会包含在分区裁剪中。</p> 
<p>    因为包含rand() 是非定数性的，因此对于每一行数据，rand() 的值都会重新计算一次。</p> 
<p></p> 
<p>我们继承一下 GenricUDF  类，看需要实现那几个方法</p> 
<pre class="has"><code class="language-html">/**
 * Created by szh on 2018/7/17.
 *
 * @author szh
 * @date 2018-07-17
 */
public class HiveTestGenericUDF extends GenericUDF {


    @Override
    public ObjectInspector initialize(ObjectInspector[] objectInspectors) throws UDFArgumentException {
        return null;
    }

    @Override
    public Object evaluate(DeferredObject[] deferredObjects) throws HiveException {
        return null;
    }

    @Override
    public String getDisplayString(String[] strings) {
        return null;
    }
}</code></pre> 
<p></p> 
<p></p> 
<p><strong>需要注意的几个方法：</strong></p> 
<p><strong>public void configure(MapredContext context) { } </strong></p> 
<p>//可选，该方法中可以通过context.getJobConf()获取job执行时候的Configuration；</p> 
<p>//可以通过Configuration传递参数值<br><br><strong>public ObjectInspector initialize(ObjectInspector[] arguments) { }</strong></p> 
<p>//必选，该方法用于函数初始化操作，并定义函数的返回值类型；</p> 
<p>//比如，在该方法中可以初始化对象实例，初始化数据库链接，初始化读取文件等；</p> 
<p></p> 
<p><strong>public Object evaluate(DeferredObject[] args){ }</strong></p> 
<p>//必选，函数处理的核心方法，用途和UDF中的evaluate一样；</p> 
<p></p> 
<p><strong>public String getDisplayString(String[] children) { }</strong></p> 
<p>//必选，显示函数的提示信息（当出现异常导致终止的时候）</p> 
<p></p> 
<p><strong>public void close(){ }</strong></p> 
<p>//可选，map完成后，执行关闭操作</p> 
<p></p> 
<p></p> 
<p><strong>一些开发注意事项：</strong></p> 
<p><strong>注意：</strong>在Hive-1.0.1估计之后的版本也是，evaluate()方法中从Object Inspectors取出的值，需要先保存为Lazy包中的数据类型（org.apache.hadoop.hive.serde2.lazy），然后才能转换成Java的数据类型进行处理。否则会报错，解决方案可以参考<a href="http://blog.csdn.net/u010376788/article/details/50492162">Hive报错集锦</a>中的第5个。</p> 
<p><span style="color:#fe2c24;"><strong>该提议经实际测试并未发生，目前不知道具体的原因 ，请知道原因的小伙伴踊跃留言 ！！！！</strong></span></p> 
<p></p> 
<p><br><strong> private GenericUDFUtils.ReturnObjectInspectorResolver  returnObjectInspectorResolver;</strong></p> 
<p>      returnObjectInspectorResolver 是一个内置的类，其通过获取非null 的值的变量并使用这个数据类型来确定返回值类型。</p> 
<p></p> 
<p>示例：</p> 
<p>     该函数功能与上面的UDF 函数功能一致。即计算某一个日期的星座。</p> 
<pre class="has"><code class="language-java">package com.test.hive.udf;

import org.apache.hadoop.hive.ql.exec.Description;
import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
import org.apache.hadoop.hive.ql.metadata.HiveException;
import org.apache.hadoop.hive.ql.udf.UDFType;
import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;
import org.apache.hadoop.hive.ql.udf.generic.GenericUDFUtils;
import org.apache.hadoop.hive.serde2.lazy.LazyDate;
import org.apache.hadoop.hive.serde2.lazy.LazyInteger;
import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
import org.apache.hadoop.hive.serde2.objectinspector.primitive.*;
import org.joda.time.DateTime;

import java.util.Date;


/**
 * Created by szh on 2018/7/17.
 *
 * @author szh
 * @date 2018-07-17
 */
@UDFType
@Description(
        name = "zodiac",
        value = "_FUNC_ (date) - " +
                " from the input date string " +
                " or separate month and day arguments, \n" +
                " returns the sign of the Zodiac.",
        extended = "Example :\n" +
                "&gt; SELECT _FUNC_ (date_string) FROM src;\n" +
                "&gt; SELECT _FUNC_ (month, day) FROM src;")
public class HiveTestZodiacGenericUDF extends GenericUDF {

    private static final Integer ONE_ARG = 1;

    private static final Integer TWO_ARG = 2;

    private StringObjectInspector dateString = null;

    private DateObjectInspector dateObject = null;

    private IntObjectInspector monthInt = null;

    private IntObjectInspector dayInt = null;

    private static final String ERROR_DATE_OF_MONTH = "invalid date of specify month";

    private static final String ERROR_MONTH_ARGS = "invalid argument of month";

    private static final String ERROR_DATE_STRING = "invalid date format";

    private GenericUDFUtils.ReturnObjectInspectorResolver returnObjectInspectorResolver;


    @Override
    //必选，该方法用于函数初始化操作，并定义函数的返回值类型；
    //比如，在该方法中可以初始化对象实例，初始化数据库链接，初始化读取文件等；
    public ObjectInspector initialize(ObjectInspector[] objectInspectors) throws UDFArgumentException {

        Integer len = objectInspectors.length;
        if (!len.equals(ONE_ARG) &amp;&amp; !len.equals(TWO_ARG)) {
            throw new UDFArgumentException("Not Invalid num of arguments");
        }

        if (len.equals(ONE_ARG)) {
            ObjectInspector tmpDate = objectInspectors[0];
            if (tmpDate instanceof DateObjectInspector) {
                this.dateObject = (DateObjectInspector) tmpDate;
            } else if (tmpDate instanceof StringObjectInspector) {
                this.dateString = (StringObjectInspector) tmpDate;
            } else {
                throw new UDFArgumentException("Not Invalid type of date (string or date)");
            }
        }


        if (len.equals(TWO_ARG)) {
            ObjectInspector tmpMonthInt = objectInspectors[0];
            ObjectInspector tmpDayInt = objectInspectors[1];
            if (!(tmpDayInt instanceof IntObjectInspector) || !(tmpMonthInt instanceof IntObjectInspector)) {
                throw new UDFArgumentException("Not Invalid type of month or day , please use int type");
            }
            this.monthInt = (IntObjectInspector) tmpMonthInt;
            this.dayInt = (IntObjectInspector) tmpDayInt;
        }

        //确定返回值类型
        return PrimitiveObjectInspectorFactory.javaStringObjectInspector;
    }

    @Override
    public Object evaluate(DeferredObject[] deferredObjects) throws HiveException {

        Integer length = deferredObjects.length;

        Integer month = null;
        Integer day = null;

        if (length.equals(ONE_ARG)) {

            if (this.dateObject != null) {

//                LazyDate dateObjTmp = (LazyDate) ((deferredObjects[0].get()));
//                Date date = (this.dateObject).getPrimitiveJavaObject(dateObjTmp);
                Date date = (this.dateObject).getPrimitiveJavaObject(deferredObjects[0].get());
                DateTime dateTime = new DateTime(date);

                month = dateTime.getMonthOfYear();
                day = dateTime.getDayOfMonth();
            } else if (this.dateString != null) {

//                LazyDate dateStringTmp = (LazyDate) (deferredObjects[0].get());
//                String dateString = (this.dateString).getPrimitiveJavaObject(dateStringTmp);

                String dateString = (this.dateString).getPrimitiveJavaObject(deferredObjects[0].get());
                DateTime dateTime = new DateTime(dateString);

                month = dateTime.getMonthOfYear();
                day = dateTime.getDayOfMonth();
            }
        }

        if (length.equals(TWO_ARG)) {

//            LazyInteger monthIntTmp = (LazyInteger) (deferredObjects[0].get());
//            LazyInteger dayIntTmp = (LazyInteger) ((deferredObjects[1].get()));
//            month = (this.monthInt).get(monthIntTmp);
//            day = (this.dayInt).get(dayIntTmp);

            month = this.monthInt.get(deferredObjects[0].get());
            day = this.dayInt.get(deferredObjects[1].get());
        }


        switch (month) {
            //判断是几月
            case 1:
                //判断是当前月的哪一段时间；然后就可以得到星座了；下面代码都一样的
                if (day &gt; 0 &amp;&amp; day &lt; 20) {
                    return "魔蝎座";
                } else if (day &lt; 32) {
                    return "水瓶座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 2:
                if (day &gt; 0 &amp;&amp; day &lt; 19) {
                    return "水瓶座";
                } else if (day &lt; 29) {
                    return "双鱼座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 3:
                if (day &gt; 0 &amp;&amp; day &lt; 21) {
                    return "双鱼座";
                } else if (day &lt; 32) {
                    return "白羊座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 4:
                if (day &gt; 0 &amp;&amp; day &lt; 20) {
                    return "白羊座";
                } else if (day &lt; 31) {
                    return "金牛座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 5:
                if (day &gt; 0 &amp;&amp; day &lt; 21) {
                    return "金牛座";
                } else if (day &lt; 32) {
                    return "双子座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 6:
                if (day &gt; 0 &amp;&amp; day &lt; 22) {
                    return "双子座";
                } else if (day &lt; 31) {
                    return "巨蟹座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 7:
                if (day &gt; 0 &amp;&amp; day &lt; 23) {
                    return "巨蟹座";
                } else if (day &lt; 32) {
                    return "狮子座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 8:
                if (day &gt; 0 &amp;&amp; day &lt; 23) {
                    return "狮子座";
                } else if (day &lt; 32) {
                    return "处女座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 9:
                if (day &gt; 0 &amp;&amp; day &lt; 23) {
                    return "处女座";
                } else if (day &lt; 31) {
                    return "天平座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 10:
                if (day &gt; 0 &amp;&amp; day &lt; 24) {
                    return "天平座";
                } else if (day &lt; 32) {
                    return "天蝎座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 11:
                if (day &gt; 0 &amp;&amp; day &lt; 23) {
                    return "天蝎座";
                } else if (day &lt; 31) {
                    return "射手座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            case 12:
                if (day &gt; 0 &amp;&amp; day &lt; 22) {
                    return "射手座";
                } else if (day &lt; 32) {
                    return "摩羯座";
                } else {
                    return ERROR_DATE_OF_MONTH;
                }
            default:
                return ERROR_MONTH_ARGS;
        }
    }

    @Override
    public String getDisplayString(String[] strings) {
        return "Please check your code, unknown Exception!!!";
    }
}
</code></pre> 
<p></p> 
<p></p> 
<h4><span style="color:#0d0016;"><strong><span style="background-color:#a2e043;">5. 打包,加入到集群中,进行测试。</span></strong></span></h4> 
<p></p> 
<p>为了方便大家确保环境一致，这里我贴出我编程环境的pom.xml</p> 
<pre class="has"><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;hive&lt;/groupId&gt;
    &lt;artifactId&gt;hive-udf-test&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;properties&gt;
        &lt;hadoop.version&gt;3.0.0&lt;/hadoop.version&gt;
        &lt;hive.version&gt;2.3.2&lt;/hive.version&gt;
    &lt;/properties&gt;


    &lt;dependencies&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hive&lt;/groupId&gt;
            &lt;artifactId&gt;hive-exec&lt;/artifactId&gt;
            &lt;version&gt;${hive.version}&lt;/version&gt;
        &lt;/dependency&gt;


        &lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
            &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
            &lt;version&gt;3.0.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- junit是java的单元测试框架 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
            &lt;version&gt;4.10&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;

    &lt;/dependencies&gt;


    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;2.3.2&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                    &lt;encoding&gt;UTF-8&lt;/encoding&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;</code></pre> 
<p></p> 
<p></p> 
<p>下面演示下如何打包，这里我使用的是IDEA , IDEA 中集成较好，</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/f4/c1/qBbaMTiv_o.png"></p> 
<p></p> 
<p>打完包如图所示：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/60/7d/YtTsExCY_o.png"></p> 
<p></p> 
<p>我们将这个包拷贝到 hive 目录下，另创建一个 my-jar 目录</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/c8/46/PMKiYjwM_o.png"></p> 
<p></p> 
<p>执行 hive 客户端进行测试，</p> 
<p>beeline -u jdbc:hive2://master:10000/test -n root</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/09/4a/YJUtDBF9_o.png"></p> 
<p></p> 
<p>将打好的jar 载入hive 客户端：</p> 
<p><span style="color:#fe2c24;"><strong>（注意，载入的jar 只在此连接生效，并不会跨客户端，也就是说另一个客户端需要重新 add jar）</strong></span></p> 
<p><span style="color:#fe2c24;"><strong>Hive 不仅将这个JAR文件加入到classpath 下，同时还将其加入到了分布式缓存中。</strong></span></p> 
<p>add jar /usr/local/hive/my-jar/hive-udf-test-1.0-SNAPSHOT.jar;</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/ae/1f/OKKvoEs6_o.png"></p> 
<p></p> 
<p>查看已经载入的jar </p> 
<p>list jars;</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/66/59/ncskr5bw_o.png"></p> 
<p></p> 
<p>注册函数：</p> 
<p>create temporary function zodiac as 'com.test.hive.udf.HiveTestZodiacUDF';</p> 
<p>create temporary function zodiacx as 'com.test.hive.udf.HiveTestZodiacGenericUDF';</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/9b/5a/cfINbtKY_o.png"></p> 
<p></p> 
<p>查看函数帮助文档：</p> 
<p></p> 
<p>describe function zodiac;</p> 
<p>describe function zodiacx;</p> 
<p>describe function extended zodiac;</p> 
<p>describe function extended zodiacx;</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/d6/36/xyOedcTt_o.png"></p> 
<p></p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/f0/1b/UKMfPAVN_o.png"></p> 
<p></p> 
<p><strong>构造测试用例：</strong></p> 
<p>先测试下函数功能：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/43/76/Eg70hKDs_o.png"></p> 
<p></p> 
<p>创建表 :</p> 
<p>create table date_one(day string);</p> 
<p></p> 
<p>构建正确的样例：</p> 
<p>insert into date_one values ('1992-12-25'),('2018-01-20'),('2018-07-20');<br>  </p> 
<p>查询：</p> 
<p>select zodiac(day) from date_one;</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/ff/ff/7lHnDUsJ_o.png"></p> 
<p></p> 
<p>select zodiacx(day) from date_one;</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/02/fa/scgQ6ugh_o.png"></p> 
<p></p> 
<p></p> 
<p>插入错误的数据：</p> 
<p>insert into date_one values ('2222-32'),('2018-04-20'),('2018-17-20');</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/7c/5b/bfbEQsvw_o.png"></p> 
<p></p> 
<p>查询数据：</p> 
<p>select zodiac(day) from date_one;</p> 
<p></p> 
<p>0: jdbc:hive2://master:10000/test&gt; select zodiac(day) from date_one;<br> +----------------------+--+<br> |         _c0          |<br> +----------------------+--+<br> | 摩羯座                  |<br> | 水瓶座                  |<br> | 巨蟹座                  |<br> | invalid date format  |<br> | 金牛座                  |<br> | invalid date format  |<br> +----------------------+--+<br> 6 rows selected (0.185 seconds)</p> 
<p><br> ========================================= </p> 
<p></p> 
<p>select zodiacx(day) from date_one;</p> 
<p>0: jdbc:hive2://master:10000/test&gt; select zodiacx(day) from date_one;<br> Error: java.io.IOException: org.apache.hadoop.hive.ql.metadata.HiveException: Error evaluating Please check your code, unknown Exception!!! (state=,code=0)<br> 0: jdbc:hive2://master:10000/test&gt; </p> 
<p><strong><span style="background-color:#ff9900;">Please check your code, unknown Exception!!!   就是之前在 getDisplayString 中定义的返回值！！</span></strong></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/98494072a29c9e4aa63d11bab0457cda/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">studio导入项目遇到的报错整理</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/90c735f9a08fea6e533b4cb7ac7c3733/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">使用redis中setnx保证资源的原子性操作</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>