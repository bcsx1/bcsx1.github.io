<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>èŠå¤©äº§ç”Ÿå™¨ - ç¼–ç¨‹éšæƒ³</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="èŠå¤©äº§ç”Ÿå™¨" />
<meta property="og:description" content="Is Artificial Intelligence(AI) making us lazy or efficient?
äººå·¥æ™ºèƒ½(AI)ä½¿æˆ‘ä»¬å˜å¾—æ‡’æƒ°è¿˜æ˜¯é«˜æ•ˆï¼Ÿ
I think itâ€™s making us efficient. Due to COVID-19, people are more often found interacting with their peers via social media and text messages. For instance, my push notifications are up by 37%, and positively enough I have reconnected with my school friends, old friends per se. However, this arose a problem of constantly sticking to my phone and suffering from Nomophobia and Phantom vibration syndrome." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/406a2c54414eecb80ba5e6e36cfd6619/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-10-09T23:19:17+08:00" />
<meta property="article:modified_time" content="2020-10-09T23:19:17+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹éšæƒ³" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹éšæƒ³</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">èŠå¤©äº§ç”Ÿå™¨</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <article style="font-size: 16px;"> 
 <div> 
  <section> 
   <div> 
    <div> 
     <p>Is Artificial Intelligence(AI) making us lazy or efficient?</p> 
     <p>äººå·¥æ™ºèƒ½(AI)ä½¿æˆ‘ä»¬å˜å¾—æ‡’æƒ°è¿˜æ˜¯é«˜æ•ˆï¼Ÿ</p> 
     <p>I think itâ€™s making us efficient. Due to COVID-19, people are more often found interacting with their peers via social media and text messages. For instance, my push notifications are up by 37%, and positively enough I have reconnected with my school friends, old friends per se. However, this arose a problem of constantly sticking to my phone and suffering from Nomophobia and Phantom vibration syndrome.</p> 
     <p> æˆ‘è®¤ä¸ºè¿™ä½¿æˆ‘ä»¬é«˜æ•ˆã€‚ ç”±äºä½¿ç”¨äº†COVID-19ï¼Œäººä»¬æ›´å¸¸é€šè¿‡ç¤¾äº¤åª’ä½“å’ŒçŸ­ä¿¡ä¸åŒé¾„äººäº’åŠ¨ã€‚ ä¾‹å¦‚ï¼Œæˆ‘çš„æ¨é€é€šçŸ¥å¢åŠ äº†37ï¼…ï¼Œè€Œä¸”å¾ˆè‚¯å®šçš„æ˜¯ï¼Œæˆ‘ä¸å­¦æ ¡æœ‹å‹ï¼Œæ—§æœ‹å‹æœ¬èº«é‡æ–°å»ºç«‹äº†è”ç³»ã€‚ ä½†æ˜¯ï¼Œè¿™å¼•èµ·äº†ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯ä¸æ–­ç²˜åœ¨æˆ‘çš„æ‰‹æœºä¸Šï¼Œå¹¶æ‚£æœ‰ææƒ§ç—‡å’Œå¹»å½±æŒ¯åŠ¨ç»¼åˆç—‡ã€‚</p> 
     <blockquote> 
      <p>Nomophobia â€” a term describing a growing fear in todayâ€™s world â€” the fear of being without a mobile device, or beyond mobile phone contact. The Post Office commissioned YouGov, a research organization, to look at anxieties suffered by mobile phone users. The study found that about 58 percent of men and 47 percent of women suffer from the phobia, and an additional 9 percent feel stressed when their mobile phones are off. The study sampled 2,163 people. Read more <a href="https://www.psychologytoday.com/us/blog/artificial-maturity/201409/nomophobia-rising-trend-in-students#:~:text=Nomophobia%20is%20a%20term%20describing%20a%20growing%20fear%20in%20today'%20rel=" rel="noopener nofollow">here</a>.</p> 
      <p> ææƒ§ç—‡(Nomophobia)æ˜¯æè¿°å½“ä»Šä¸–ç•Œæ—¥ç›Šå¢é•¿çš„ææƒ§æ„Ÿçš„ä¸€ç§æœ¯è¯­ï¼Œå®ƒè¡¨ç¤ºæ‹…å¿ƒæ²¡æœ‰ç§»åŠ¨è®¾å¤‡æˆ–æ— æ³•ä¸æ‰‹æœºé€šè¯ã€‚ é‚®å±€å§”æ‰˜ç ”ç©¶æœºæ„YouGovè°ƒæŸ¥æ‰‹æœºç”¨æˆ·é­å—çš„ç„¦è™‘ã€‚ ç ”ç©¶å‘ç°ï¼Œå¤§çº¦58ï¼…çš„ç”·æ€§å’Œ47ï¼…çš„å¥³æ€§æ‚£æœ‰ææ€–ç—‡ï¼Œå¦å¤–9ï¼…çš„äººåœ¨å…³é—­æ‰‹æœºåä¼šæ„Ÿåˆ°å‹åŠ›ã€‚ è¯¥ç ”ç©¶å¯¹2,163äººè¿›è¡Œäº†æŠ½æ ·ã€‚ <a href="https://www.psychologytoday.com/us/blog/artificial-maturity/201409/nomophobia-rising-trend-in-students#:~:text=Nomophobia%20is%20a%20term%20describing%20a%20growing%20fear%20in%20today'%20rel=" rel="noopener nofollow">åœ¨è¿™é‡Œ</a>é˜…è¯»æ›´å¤šã€‚</p> 
      <p>Phantom vibration syndrome â€” where you think your phone is vibrating but itâ€™s not â€” has been around only since the mobile age. Nearly 90 percent of college undergrads <a href="http://www.sciencedirect.com/science/article/pii/S0747563212000799" rel="noopener nofollow">in a 2012 study</a> said they felt phantom vibrations. Get more insights <a href="https://www.npr.org/sections/alltechconsidered/2013/09/30/226820044/phantom-phone-vibrations-so-common-they-ve-changed-our-brains" rel="noopener nofollow">here</a>.</p> 
      <p> å¹»å½±æŒ¯åŠ¨ç»¼åˆç—‡(æ‚¨è®¤ä¸ºæ‰‹æœºåœ¨æŒ¯åŠ¨ï¼Œä½†å®é™…ä¸Šå¹¶æ²¡æœ‰)ï¼Œä»…åœ¨ç§»åŠ¨æ—¶ä»£å‡ºç°äº†ã€‚ <a href="http://www.sciencedirect.com/science/article/pii/S0747563212000799" rel="noopener nofollow">åœ¨2012å¹´çš„ä¸€é¡¹ç ”ç©¶ä¸­ï¼Œ</a>å°†è¿‘90ï¼…çš„å¤§å­¦æœ¬ç§‘ç”Ÿè¡¨ç¤ºä»–ä»¬æ„Ÿåˆ°å¹»å½±èˆ¬çš„æŒ¯åŠ¨ã€‚ <a href="https://www.npr.org/sections/alltechconsidered/2013/09/30/226820044/phantom-phone-vibrations-so-common-they-ve-changed-our-brains" rel="noopener nofollow">åœ¨æ­¤å¤„</a>è·å–æ›´å¤šè§è§£ã€‚</p> 
     </blockquote> 
     <p>I was indeed almost always on the phone, and even while sleeping, I used to wake up hastily to check my phone as well, and being an introvert I love to sleep. So, I decided to make AI work for me.</p> 
     <p> å®é™…ä¸Šï¼Œæˆ‘å‡ ä¹ä¸€ç›´åœ¨æ‰“ç”µè¯ï¼Œå³ä½¿åœ¨ç¡è§‰çš„æ—¶å€™ï¼Œæˆ‘ä¹Ÿå¸¸å¸¸åŒ†åŒ†é†’æ¥ï¼Œä¹Ÿè¦æ£€æŸ¥æˆ‘çš„æ‰‹æœºï¼Œè€Œä¸”æˆ‘æ€§æ ¼å†…å‘ï¼Œå–œæ¬¢ç¡è§‰ã€‚ å› æ­¤ï¼Œæˆ‘å†³å®šè®©AIä¸ºæˆ‘å·¥ä½œã€‚</p> 
     <p>With Recurrent Neural Networks (RNN), I decided to train my machine to generate automatic replies, trained based on my personal chats/replies/forwards, etc.</p> 
     <p> å€ŸåŠ©é€’å½’ç¥ç»ç½‘ç»œ(RNN)ï¼Œæˆ‘å†³å®šè®­ç»ƒæˆ‘çš„æœºå™¨ä»¥ç”Ÿæˆè‡ªåŠ¨ç­”å¤ï¼Œå¹¶æ ¹æ®æˆ‘çš„ä¸ªäººèŠå¤©/ç­”å¤/è½¬å‘ç­‰è¿›è¡Œè®­ç»ƒã€‚</p> 
     <p>On the corollary, there are many fledgling chatbots trained on the humongous text. However, they lack the human touch and the word and sentence formations one uses while texting. While sending short messages, for instance â€” fewer people write â€œSee you Laterâ€ and my personal network uses â€œc u l8râ€- both of which convey the same message, but with different semantic and syntactic structuring.</p> 
     <p> ç»“æœæ˜¯ï¼Œæœ‰è®¸å¤šåˆšèµ·æ­¥çš„èŠå¤©æœºå™¨äººå·²ç»æ¥å—äº†åºå¤§çš„æ–‡æœ¬åŸ¹è®­ã€‚ ä½†æ˜¯ï¼Œå®ƒä»¬ç¼ºä¹äººçš„è§¦è§‰ï¼Œå¹¶ä¸”åœ¨å‘çŸ­ä¿¡æ—¶ä¸ä¼šä½¿ç”¨å•è¯å’Œå¥å­çš„å½¢å¼ã€‚ ä¾‹å¦‚ï¼Œåœ¨å‘é€çŸ­æ¶ˆæ¯æ—¶-æ›´å°‘çš„äººå†™â€œç¨åå†è§â€ï¼Œè€Œæˆ‘çš„ä¸ªäººç½‘ç»œä½¿ç”¨â€œ cu8râ€-ä¸¤è€…éƒ½ä¼ è¾¾ç›¸åŒçš„æ¶ˆæ¯ï¼Œä½†è¯­ä¹‰å’Œå¥æ³•ç»“æ„ä¸åŒã€‚</p> 
     <h3> æ•°æ®é›†ï¼š <span style="font-weight: bold;">(</span>Dataset :<span style="font-weight: bold;">)</span></h3> 
     <p>I have 881 text messages which are basically interactions between 11 different participants from India(most of them), Germany, and the USA. Due to this time difference, not all are active at once. Few are more gregarious, few more tacit. So this data is a perfect mix of human interactions â€” sarcastic and sassy â€” replies, which are more prominent in taking.</p> 
     <p> æˆ‘æœ‰881æ¡çŸ­ä¿¡ï¼ŒåŸºæœ¬ä¸Šæ˜¯æ¥è‡ªå°åº¦(å…¶ä¸­å¤§å¤šæ•°)ï¼Œå¾·å›½å’Œç¾å›½çš„11ä¸ªä¸åŒå‚ä¸è€…ä¹‹é—´çš„äº’åŠ¨ã€‚ ç”±äºè¯¥æ—¶é—´å·®ï¼Œå¹¶éæ‰€æœ‰åŠŸèƒ½éƒ½åŒæ—¶å¤„äºæ´»åŠ¨çŠ¶æ€ã€‚ å¾ˆå°‘æœ‰åˆç¾¤çš„ï¼Œå¾ˆå°‘æ˜¯é»˜è®¤çš„ã€‚ å› æ­¤ï¼Œè¿™äº›æ•°æ®å®Œç¾åœ°èåˆäº†äººç±»äº’åŠ¨(å˜²è®½å’Œé‡è›®)çš„å›ç­”ï¼Œåœ¨å›ç­”ä¸­æ›´ä¸ºçªå‡ºã€‚</p> 
     <p>The main reason for training on this data is â€” itâ€™s the most active group in my network and more close to me as I do not want to sound like a bot when I am â€œreplyingâ€.</p> 
     <p> å¯¹æ­¤æ•°æ®è¿›è¡ŒåŸ¹è®­çš„ä¸»è¦åŸå› æ˜¯-å®ƒæ˜¯æˆ‘ç½‘ç»œä¸­æœ€æ´»è·ƒçš„ç»„ï¼Œå¹¶ä¸”ä¸æˆ‘æ›´æ¥è¿‘ï¼Œå› ä¸ºæˆ‘ä¸æƒ³åœ¨â€œå›å¤â€æ—¶å¬èµ·æ¥åƒä¸ªæœºå™¨äººã€‚</p> 
     <h3> èŠå¤© <span style="font-weight: bold;">(</span>LETS TALK<span style="font-weight: bold;">)</span></h3> 
     <pre><code class="has"># importing necessary libraries<br>import numpy as np<br>import pandas as pd<br>import matplotlib.pyplot as plt<br>import nltk<br>import string<br>import unidecode<br>import random<br>import torch</code></pre> 
     <p>After importing we need to have a GPU as RNN or any deep learning neural network requires heavy computing and takes a long time on CPU. additionally, GPUs have additional advantages over CPUs, these include having more computational units and having a higher bandwidth to retrieve from memory.</p> 
     <p> å¯¼å…¥åï¼Œæˆ‘ä»¬éœ€è¦å°†GPUç”¨ä½œRNNæˆ–ä»»ä½•æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œéƒ½éœ€è¦å¤§é‡è®¡ç®—ï¼Œå¹¶ä¸”åœ¨CPUä¸ŠèŠ±è´¹å¾ˆé•¿æ—¶é—´ã€‚ æ­¤å¤–ï¼ŒGPUä¸CPUç›¸æ¯”è¿˜å…·æœ‰å…¶ä»–ä¼˜åŠ¿ï¼ŒåŒ…æ‹¬å…·æœ‰æ›´å¤šçš„è®¡ç®—å•å…ƒå’Œæ›´é«˜çš„å¸¦å®½ä»¥ä»å†…å­˜ä¸­æ£€ç´¢ã€‚</p> 
     <pre><code class="has">train_on_gpu = torch.cuda.is_available()<br>if(train_on_gpu):<br>    print('Training on GPU!')<br>else: <br>    print('No GPU available, training on CPU; consider making n_epochs very small.')</code></pre> 
     <p>This code will tell you if you have a GPU or not. even if you don't have one, it is just going to take a longer, but still gives you results.</p> 
     <p> è¯¥ä»£ç å°†å‘Šè¯‰æ‚¨æ˜¯å¦æœ‰GPUã€‚ å³ä½¿æ‚¨æ²¡æœ‰ï¼Œä¹Ÿå°†èŠ±è´¹æ›´é•¿çš„æ—¶é—´ï¼Œä½†ä»ç„¶å¯ä»¥ä¸ºæ‚¨å¸¦æ¥ç»“æœã€‚</p> 
     <pre><code class="has">train_df = pd.read_csv("WhatsappChat.csv")<br>author = train_df["Content"]</code></pre> 
     <figure style="display:block;text-align:center;"> 
      <div> 
       <div> 
        <div> 
         <div> 
          <div style="text-align: center;"> 
           <img alt="Image for post" src="https://images2.imgbox.com/21/b7/soPG6eNw_o.png" width="747" height="426" style="outline: none;"> 
          </div> 
         </div> 
        </div> 
       </div> 
      </div> 
     </figure> 
     <p>This is how the data frame looks like, I have worked on some data processing and Exploratory Data Analysis to bring it in this formation. The code to change WhatsApp chat into a similar pandas data frame visit <a href="https://github.com/baban9/Personal-Projects/blob/master/Chat_analysis.ipynb" rel="noopener nofollow">here</a>. As I am training it on the content of the chats, we will just be working on that column.</p> 
     <p> è¿™å°±æ˜¯æ•°æ®æ¡†æ¶çš„æ ·å­ï¼Œæˆ‘å·²ç»è¿›è¡Œäº†ä¸€äº›æ•°æ®å¤„ç†å’Œæ¢ç´¢æ€§æ•°æ®åˆ†æï¼Œä»¥ä½¿å…¶å½¢æˆè¿™ç§å½¢å¼ã€‚ å°†WhatsAppèŠå¤©æ›´æ”¹ä¸ºç±»ä¼¼ç†ŠçŒ«æ•°æ®æ¡†æ¶çš„ä»£ç è¯·è®¿é—®<a href="https://github.com/baban9/Personal-Projects/blob/master/Chat_analysis.ipynb" rel="noopener nofollow">è¿™é‡Œ</a>ã€‚ å½“æˆ‘åœ¨èŠå¤©å†…å®¹ä¸Šå¯¹å…¶è¿›è¡ŒåŸ¹è®­æ—¶ï¼Œæˆ‘ä»¬å°†ä»…åœ¨è¯¥åˆ—ä¸Šè¿›è¡Œå·¥ä½œã€‚</p> 
     <pre><code class="has">text = list(author)<br>def joinStrings(text):<br>    return ' '.join(string for string in text)<br>text = joinStrings(text)<br># text = [item for sublist in author[:5].values for item in sublist]<br>len(text.split())test_sentence = text.lower().split()trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])<br>            for i in range(len(test_sentence) - 2)]<br>chunk_len=len(trigrams)<br>print(trigrams[:3])</code></pre> 
     <p>after joining and making the content as a huge text data, I am training the data based on tri-gram as most of the replies â€” at least in my network â€” are sized at 3 words in reply.</p> 
     <p> åŠ å…¥å†…å®¹å¹¶ä½¿ä¹‹æˆä¸ºå·¨å¤§çš„æ–‡æœ¬æ•°æ®ä¹‹åï¼Œæˆ‘å°†æ ¹æ®tri-gramè®­ç»ƒæ•°æ®ï¼Œå› ä¸ºå¤§å¤šæ•°ç­”å¤(è‡³å°‘åœ¨æˆ‘çš„ç½‘ç»œä¸­)çš„ç­”å¤å¤§å°ä¸º3ä¸ªå­—ã€‚</p> 
     <p>Since to Train an RNN, I need a vocabulary size, so that my replies don't go out of bounds.</p> 
     <p> è‡ªä»è®­ç»ƒRNNä»¥æ¥ï¼Œæˆ‘éœ€è¦ä¸€ä¸ªè¯æ±‡é‡ï¼Œä»¥ä¾¿æˆ‘çš„å›ç­”ä¸ä¼šè¶…å‡ºèŒƒå›´ã€‚</p> 
     <pre><code class="has">vocab = set(test_sentence)<br>voc_len=len(vocab)<br>word_to_ix = {word: i for i, word in enumerate(vocab)}# making input and their respective replies <br>inp=[]<br>tar=[]<br>for context, target in trigrams:<br>        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)<br>        inp.append(context_idxs)<br>        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)<br>        tar.append(targ)</code></pre> 
     <h2> RNN <span style="font-weight: bold;">(</span>RNN<span style="font-weight: bold;">)</span></h2> 
     <p>Itâ€™s time we define our neural network class and see what it can do for us.</p> 
     <p> æ˜¯æ—¶å€™å®šä¹‰ç¥ç»ç½‘ç»œç±»äº†ï¼Œçœ‹çœ‹å®ƒèƒ½ä¸ºæˆ‘ä»¬åšä»€ä¹ˆã€‚</p> 
     <pre><code class="has">class RNN(nn.Module):<br>    def __init__(self, input_size, hidden_size, output_size, n_layers=1):<br>        super(RNN, self).__init__()<br>        self.input_size = input_size<br>        self.hidden_size = hidden_size<br>        self.output_size = output_size<br>        self.n_layers = n_layers<br>        <br>        self.encoder = nn.Embedding(input_size, hidden_size)<br>        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers,batch_first=True,<br>                          bidirectional=False)<br>        self.decoder = nn.Linear(hidden_size, output_size)<br>    <br>    def forward(self, input, hidden):<br>        input = self.encoder(input.view(1, -1))<br>        output, hidden = self.gru(input.view(1, 1, -1), hidden)<br>        output = self.decoder(output.view(1, -1))<br>        return output, hiddendef init_hidden(self):<br>        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))</code></pre> 
     <p>Here is a class RNN, a general object-oriented programming approach to instantiate objects and their respective methods or functions for faster execution.</p> 
     <p> è¿™æ˜¯ç±»RNNï¼Œè¿™æ˜¯ä¸€ç§é€šç”¨çš„é¢å‘å¯¹è±¡çš„ç¼–ç¨‹æ–¹æ³•ï¼Œç”¨äºå®ä¾‹åŒ–å¯¹è±¡åŠå…¶å„è‡ªçš„æ–¹æ³•æˆ–å‡½æ•°ï¼Œä»¥ä¾¿æ›´å¿«åœ°æ‰§è¡Œã€‚</p> 
     <p>The def forward() function is our forward pass or feed-forward network and connection of the neural network. And the def init_hidden() is a variable instantiate for hidden layers.</p> 
     <p> def forward()å‡½æ•°æ˜¯æˆ‘ä»¬çš„å‰å‘é€šè¿‡æˆ–å‰é¦ˆç½‘ç»œä»¥åŠç¥ç»ç½‘ç»œçš„è¿æ¥ã€‚ def init_hidden()æ˜¯ç”¨äºéšè—å±‚çš„å˜é‡å®ä¾‹ã€‚</p> 
     <pre><code class="has">def train(inp, target):<br>    hidden = decoder.init_hidden().cuda()<br>    decoder.zero_grad()<br>    loss = 0<br>    <br>    for c in range(chunk_len):<br>        output, hidden = decoder(inp[c].cuda(), hidden)<br>        loss += criterion(output, target[c].cuda())loss.backward()<br>    decoder_optimizer.step()return loss.data.item() / chunk_len</code></pre> 
     <p>Now we need to reduce loss to get the optimized reply and check the accuracy of the model. The above code gives us data loss in whole backpropagation.</p> 
     <p> ç°åœ¨æˆ‘ä»¬éœ€è¦å‡å°‘æŸå¤±ä»¥è·å¾—ä¼˜åŒ–çš„ç­”å¤å¹¶æ£€æŸ¥æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚ ä¸Šé¢çš„ä»£ç ä½¿æˆ‘ä»¬åœ¨æ•´ä¸ªåå‘ä¼ æ’­è¿‡ç¨‹ä¸­éƒ½ä¸¢å¤±äº†æ•°æ®ã€‚</p> 
     <pre><code class="has">import time, mathdef time_since(since):<br>    s = time.time() - since<br>    m = math.floor(s / 60)<br>    s -= m * 60<br>    return '%dm %ds' % (m, s)</code></pre> 
     <p>This is a simple function to check how much time does it take to run the program or time taken to train the model.</p> 
     <p> è¿™æ˜¯ä¸€ä¸ªç®€å•çš„åŠŸèƒ½ï¼Œç”¨äºæ£€æŸ¥è¿è¡Œç¨‹åºéœ€è¦å¤šå°‘æ—¶é—´æˆ–è®­ç»ƒæ¨¡å‹éœ€è¦çš„æ—¶é—´ã€‚</p> 
     <pre><code class="has">n_epochs = 50<br>print_every = 10<br>plot_every = 10<br>hidden_size = 100<br>n_layers = 1<br>lr = 0.015decoder = RNN(voc_len, hidden_size, voc_len, n_layers)<br>decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)<br>criterion = nn.CrossEntropyLoss()start = time.time()<br>all_losses = []<br>loss_avg = 0<br>if(train_on_gpu):<br>    decoder.cuda()<br>for epoch in range(1, n_epochs + 1):<br>    loss = train(inp,tar)       <br>    loss_avg += lossif epoch % print_every == 0:<br>        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 50, loss))<br>#         print(evaluate('ge', 200), '\n')if epoch % plot_every == 0:<br>        all_losses.append(loss_avg / plot_every)<br>        loss_avg = 0</code></pre> 
     <p>This is where the magic happens â€” training the chat and learning what to reply for 50 times I let the machine read the chat and let me know what is the best reply to the message. Also, prints the loss incurred after 10 epochs and time took to execute.</p> 
     <p> è¿™å°±æ˜¯é­”æœ¯å‘ç”Ÿçš„åœ°æ–¹â€“è®­ç»ƒèŠå¤©å¹¶å­¦ä¹ 50æ¬¡ç­”å¤ï¼Œè®©æœºå™¨é˜…è¯»èŠå¤©å¹¶è®©æˆ‘çŸ¥é“å¯¹æ¶ˆæ¯çš„æœ€ä½³ç­”å¤æ˜¯ä»€ä¹ˆã€‚ åŒæ ·ï¼Œæ‰“å°10ä¸ªå†å…ƒå’Œæ‰§è¡Œæ—¶é—´ä¹‹åçš„æŸå¤±ã€‚</p> 
     <pre><code class="has">import matplotlib.pyplot as plt<br>import matplotlib.ticker as ticker<br>%matplotlib inlineplt.figure()<br>plt.plot(all_losses)</code></pre> 
     <p>This plots the losses for those who â€” like me â€” appreciate plots and likes visual representations then numbers.</p> 
     <p> å¯¹äºé‚£äº›åƒæˆ‘ä¸€æ ·æ¬£èµæƒ…èŠ‚ï¼Œå–œæ¬¢è§†è§‰è¡¨ç¤ºå†å–œæ¬¢æ•°å­—çš„äººï¼Œè¿™ä¼šç”»å‡ºæŸå¤±ã€‚</p> 
     <pre><code class="has">def evaluate(prime_str='this process', predict_len=100, temperature=0.8):<br>    hidden = decoder.init_hidden().cuda()for p in range(predict_len):<br>        <br>        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long).cuda()<br>        inp = prime_input[-2:] #last two words as input<br>        output, hidden = decoder(inp, hidden)<br>        <br>        # Sample from the network as a multinomial distribution<br>        output_dist = output.data.view(-1).div(temperature).exp()<br>        top_i = torch.multinomial(output_dist, 1)[0]<br>        <br>        # Add predicted word to string and use as next input<br>        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]<br>        prime_str += " " + predicted_word<br>#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)return prime_str</code></pre> 
     <p>We need to define an evaluation function to check if we are getting any tangible replies generated. It takes the prime string, length of the sentences, and temperature which takes care of the missing words if any new message comes.</p> 
     <p> æˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªè¯„ä¼°å‡½æ•°ï¼Œä»¥æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ä»»ä½•åˆ‡å®çš„ç­”å¤ã€‚ å®ƒé‡‡ç”¨ç´ æ•°å­—ç¬¦ä¸²ï¼Œå¥å­çš„é•¿åº¦å’Œæ¸©åº¦ï¼Œå¦‚æœæœ‰ä»»ä½•æ–°æ¶ˆæ¯å‡ºç°ï¼Œå®ƒå°†å¤„ç†ä¸¢å¤±çš„å•è¯ã€‚</p> 
     <pre><code class="has">print(evaluate('trip pe',11, temperature=1))# output <br>trip pe shuru ? dekh nağŸ˜…. bumble to sanky bhi use kar sakta</code></pre> 
     <p>Voila! There is a message generated and it makes less sense, but tangible words. Interestingly, it learned the smileys as well. And we use a huge amount of emoticons in our chats.</p> 
     <p> ç§ï¼ ç”Ÿæˆäº†ä¸€æ¡æ¶ˆæ¯ï¼Œå®ƒæ„ä¹‰ä¸å¤§ï¼Œä½†å´æ˜¯å®è¯ã€‚ æœ‰è¶£çš„æ˜¯ï¼Œå®ƒä¹Ÿå­¦ä¼šäº†ç¬‘è„¸ã€‚ è€Œä¸”æˆ‘ä»¬åœ¨èŠå¤©ä¸­ä½¿ç”¨äº†å¤§é‡çš„è¡¨æƒ…ç¬¦å·ã€‚</p> 
     <h3> æœªæ¥çš„å·¥ä½œ <span style="font-weight: bold;">(</span>Future work<span style="font-weight: bold;">)</span></h3> 
     <p>Now, all I need is work on APIs to embed this code in the WhatsApp chat, let it train in a span of a month, and generate the messages â€” then I donâ€™t look at my phone. This will cure my sleep cycle and leverage me in interacting with people around me than on my phone. Hopefully with increased epochs, say 100 and more data over time this will give fewer errors and more personalized replies which will trick my friends into wondering whether Iâ€™m a BOT or replying with my conscience.</p> 
     <p>ç°åœ¨ï¼Œæˆ‘éœ€è¦åšçš„å°±æ˜¯å°†è¿™äº›ä»£ç åµŒå…¥åˆ°WhatsAppèŠå¤©ä¸­çš„APIä¸Šï¼Œè®©å®ƒåœ¨ä¸€ä¸ªæœˆçš„æ—¶é—´å†…è¿›è¡Œè®­ç»ƒå¹¶ç”Ÿæˆæ¶ˆæ¯-ç„¶åæˆ‘å°±ä¸ä¼šçœ‹æ‰‹æœºäº†ã€‚ è¿™å¯ä»¥æ”¹å–„æˆ‘çš„ç¡çœ å‘¨æœŸï¼Œå¹¶å¯ä»¥ä½¿æˆ‘ä¸å‘¨å›´çš„äººäº’åŠ¨(è€Œä¸æ˜¯é€šè¿‡æ‰‹æœº)ã€‚ å¸Œæœ›éšç€æ—¶ä»£çš„å¢åŠ ï¼Œä¾‹å¦‚éšç€æ—¶é—´çš„æ¨ç§»å¢åŠ 100ä¸ªæ•°æ®ï¼Œè¿™å°†å‡å°‘é”™è¯¯å¹¶æä¾›æ›´å¤šä¸ªæ€§åŒ–çš„ç­”å¤ï¼Œè¿™å°†ä½¿æˆ‘çš„æœ‹å‹è¿·æƒ‘ä¸è§£ï¼Œæˆ‘æ˜¯BOTè¿˜æ˜¯å‡ºäºè‰¯å¿ƒè€Œå›è¦†ã€‚</p> 
     <p>If you are interested, you can get the code <a href="https://github.com/baban9/Personal-Projects/blob/master/chat%20generator.ipynb" rel="noopener nofollow">here</a>.</p> 
     <p> å¦‚æœæ‚¨æœ‰å…´è¶£ï¼Œå¯ä»¥åœ¨<a href="https://github.com/baban9/Personal-Projects/blob/master/chat%20generator.ipynb" rel="noopener nofollow">æ­¤å¤„</a>è·å–ä»£ç ã€‚</p> 
     <p>Do let me know if you think this method lacks some ideas, or how I can optimize it further to get to being a humanlike BOT and let this AI take over my communication.</p> 
     <p> è¯·è®©æˆ‘çŸ¥é“æ‚¨æ˜¯å¦è®¤ä¸ºè¿™ç§æ–¹æ³•ç¼ºä¹ä¸€äº›æƒ³æ³•ï¼Œæˆ–è€…æˆ‘å¦‚ä½•è¿›ä¸€æ­¥ä¼˜åŒ–å®ƒä»¥æˆä¸ºä¸€ä¸ªåƒäººä¸€æ ·çš„BOTï¼Œå¹¶è®©è¯¥AIæ¥ç®¡æˆ‘çš„äº¤æµã€‚</p> 
    </div> 
   </div> 
  </section> 
 </div> 
 <blockquote> 
  <p>ç¿»è¯‘è‡ª: <a href="https://medium.com/the-innovation/chat-generator-d61cc5a1d1df" rel="nofollow">https://medium.com/the-innovation/chat-generator-d61cc5a1d1df</a></p> 
 </blockquote> 
</article>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/85c57005702babe1629664475661666d/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">é’ˆå¯¹iframeåº•éƒ¨ç•™ç™½é—®é¢˜è§£å†³æ–¹æ¡ˆ</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8001b8cacd3787b4320281998c7b90ba/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">æ·±åº¦å­¦ä¹ é¢†åŸŸä¸“ä¸šè¯æ±‡_æ·±åº¦å­¦ä¹ æ—¶ä»£çš„äººæ–‡é¢†åŸŸä¸“ä¸šçŸ¥è¯†</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 ç¼–ç¨‹éšæƒ³.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>