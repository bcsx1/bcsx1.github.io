<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>对 Canal (增量数据订阅与消费)的理解 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="对 Canal (增量数据订阅与消费)的理解" />
<meta property="og:description" content="概述
canal是阿里巴巴旗下的一款开源项目，纯Java开发。基于数据库增量日志解析，提供增量数据订阅&amp;消费，目前主要支持了MySQL(也支持mariaDB)。
起源：早期，阿里巴巴B2B公司因为存在杭州和美国双机房部署，存在跨机房同步的业务需求。不过早期的数据库同步业务，主要是基于trigger的方式获取增量变更，不过从2010年开始，阿里系公司开始逐步的尝试基于数据库的日志解析，获取增量变更进行同步，由此衍生出了增量订阅&amp;消费的业务，从此开启了一段新纪元。
基于日志增量订阅&amp;消费支持的业务：
数据库镜像 数据库实时备份 多级索引 (卖家和买家各自分库索引) search build 业务cache刷新 价格变化等重要业务消息 工作原理
mysql主备复制实现：
从上层来看，复制分成三步：
master将改变记录到二进制日志(binary log)中(这些记录叫做二进制日志事件，binary log events，可以通过show binlog events进行查看)； slave将master的binary log events拷贝到它的中继日志(relay log)； slave重做中继日志中的事件，将改变反映它自己的数据。 canal的工作原理
原理相对比较简单：
canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议 mysql master收到dump请求，开始推送binary log给slave(也就是canal) canal解析binary log对象(原始为byte流) 架构设计
个人理解，数据增量订阅与消费应当有如下几个点：
1、增量订阅和消费模块应当包括binlog日志抓取，binlog日志解析，事件分发过滤(EventSink)，存储(EventStore)等主要模块。
2、如果需要确保HA可以采用Zookeeper保存各个子模块的状态，让整个增量订阅和消费模块实现无状态化，当然作为consumer(客户端)的状态也可以保存在zk之中。
3、整体上通过一个Manager System进行集中管理，分配资源。
可以参考下图：
canal架构设计
说明：
server代表一个canal运行实例，对应于一个jvm instance对应于一个数据队列 (1个server对应1..n个instance) instance模块：
eventParser (数据源接入，模拟slave协议和master进行交互，协议解析) eventSink (Parser和Store链接器，进行数据过滤，加工，分发的工作) eventStore (数据存储) metaManager (增量订阅&amp;消费信息管理器) EventParser
整个parser过程大致可分为几部：
Connection获取上一次解析成功的位置(如果第一次启动，则获取初始制定的位置或者是当前数据库的binlog位点) Connection建立连接，发生BINLOG_DUMP命令 Mysql开始推送Binary Log 接收到的Binary Log通过Binlog parser进行协议解析，补充一些特定信息 传递给EventSink模块进行数据存储，是一个阻塞操作，直到存储成功 存储成功后，定时记录Binary Log位置 EventSink设计" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/4851afba5d6e4eee28e7763361f79476/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-07-04T16:18:00+08:00" />
<meta property="article:modified_time" content="2017-07-04T16:18:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">对 Canal (增量数据订阅与消费)的理解</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="cnblogs_post_body" class="blogpost-body"> 
 <p><strong>概述</strong></p> 
 <p>canal是阿里巴巴旗下的一款开源项目，纯Java开发。基于数据库增量日志解析，提供增量数据订阅&amp;消费，目前主要支持了MySQL(也支持mariaDB)。</p> 
 <p>起源：早期，阿里巴巴B2B公司因为存在杭州和美国双机房部署，存在跨机房同步的业务需求。不过早期的数据库同步业务，主要是基于trigger的方式获取增量变更，不过从2010年开始，阿里系公司开始逐步的尝试基于数据库的日志解析，获取增量变更进行同步，由此衍生出了增量订阅&amp;消费的业务，从此开启了一段新纪元。</p> 
 <p>基于日志增量订阅&amp;消费支持的业务：</p> 
 <ul><li>数据库镜像</li></ul> 
 <ul><li class="_mce_tagged_br">数据库实时备份</li></ul> 
 <ul><li class="_mce_tagged_br">多级索引 (卖家和买家各自分库索引)</li></ul> 
 <ul><li class="_mce_tagged_br">search build</li></ul> 
 <ul><li class="_mce_tagged_br">业务cache刷新</li></ul> 
 <ul><li class="_mce_tagged_br">价格变化等重要业务消息</li></ul> 
 <p><strong>工作原理</strong></p> 
 <p>mysql主备复制实现：</p> 
 <p><img class="img_loading" title="QQ20170617-190612@2x" src="https://images2.imgbox.com/7c/36/rpSRxsib_o.jpg" alt=""></p> 
 <p>从上层来看，复制分成三步：</p> 
 <ul><li>master将改变记录到二进制日志(binary log)中(这些记录叫做二进制日志事件，binary log events，可以通过show binlog events进行查看)；</li></ul> 
 <ul><li class="_mce_tagged_br">slave将master的binary log events拷贝到它的中继日志(relay log)；</li></ul> 
 <ul><li class="_mce_tagged_br">slave重做中继日志中的事件，将改变反映它自己的数据。</li></ul> 
 <p><strong>canal的工作原理</strong></p> 
 <p><img class="img_loading" title="QQ20170617-190741@2x" src="https://images2.imgbox.com/dc/25/zoFW9SZT_o.jpg" alt=""></p> 
 <p>原理相对比较简单：</p> 
 <ul><li>canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议</li></ul> 
 <ul><li class="_mce_tagged_br">mysql master收到dump请求，开始推送binary log给slave(也就是canal)</li></ul> 
 <ul><li class="_mce_tagged_br">canal解析binary log对象(原始为byte流)</li></ul> 
 <p><strong>架构设计</strong></p> 
 <p>个人理解，数据增量订阅与消费应当有如下几个点：</p> 
 <p>　　1、增量订阅和消费模块应当包括binlog日志抓取，binlog日志解析，事件分发过滤(EventSink)，存储(EventStore)等主要模块。</p> 
 <p class="_mce_tagged_br">　　2、如果需要确保HA可以采用Zookeeper保存各个子模块的状态，让整个增量订阅和消费模块实现无状态化，当然作为consumer(客户端)的状态也可以保存在zk之中。</p> 
 <p class="_mce_tagged_br">　　3、整体上通过一个Manager System进行集中管理，分配资源。</p> 
 <p>可以参考下图：</p> 
 <p><img class="img_loading" title="QQ20170617-190849@2x" src="https://images2.imgbox.com/e4/52/cdZ1iAZH_o.jpg" alt=""></p> 
 <p><strong>canal架构设计</strong></p> 
 <p><img class="img_loading" title="QQ20170617-190921@2x" src="https://images2.imgbox.com/a0/59/6z1jrrde_o.jpg" alt=""></p> 
 <p>说明：</p> 
 <ul><li>server代表一个canal运行实例，对应于一个jvm</li></ul> 
 <ul><li class="_mce_tagged_br">instance对应于一个数据队列 (1个server对应1..n个instance)</li></ul> 
 <p>instance模块：</p> 
 <ul><li>eventParser (数据源接入，模拟slave协议和master进行交互，协议解析)</li></ul> 
 <ul><li class="_mce_tagged_br">eventSink (Parser和Store链接器，进行数据过滤，加工，分发的工作)</li></ul> 
 <ul><li class="_mce_tagged_br">eventStore (数据存储)</li></ul> 
 <ul><li class="_mce_tagged_br">metaManager (增量订阅&amp;消费信息管理器)</li></ul> 
 <p><strong>EventParser</strong></p> 
 <p><img class="img_loading" title="QQ20170617-191012@2x" src="https://images2.imgbox.com/60/e4/lQ1lqnnZ_o.jpg" alt=""></p> 
 <p>整个parser过程大致可分为几部：</p> 
 <ul><li>Connection获取上一次解析成功的位置(如果第一次启动，则获取初始制定的位置或者是当前数据库的binlog位点)</li></ul> 
 <ul><li class="_mce_tagged_br">Connection建立连接，发生BINLOG_DUMP命令</li></ul> 
 <ul><li class="_mce_tagged_br">Mysql开始推送Binary Log</li></ul> 
 <ul><li class="_mce_tagged_br">接收到的Binary Log通过Binlog parser进行协议解析，补充一些特定信息</li></ul> 
 <ul><li class="_mce_tagged_br">传递给EventSink模块进行数据存储，是一个阻塞操作，直到存储成功</li></ul> 
 <ul><li class="_mce_tagged_br">存储成功后，定时记录Binary Log位置</li></ul> 
 <p><strong>EventSink设计</strong></p> 
 <p><img class="img_loading" title="QQ20170617-191110@2x" src="https://images2.imgbox.com/39/f0/WFYeJz1o_o.jpg" alt=""></p> 
 <p>说明：</p> 
 <ul><li>数据过滤：支持通配符的过滤模式，表名，字段内容等</li></ul> 
 <ul><li class="_mce_tagged_br">数据路由/分发：解决1:n (1个parser对应多个store的模式)</li></ul> 
 <ul><li class="_mce_tagged_br">数据归并：解决n:1 (多个parser对应1个store)</li></ul> 
 <ul><li class="_mce_tagged_br">数据加工：在进入store之前进行额外的处理，比如join</li></ul> 
 <p><strong>1 数据1:n业务 ：</strong></p> 
 <p>为了合理的利用数据库资源， 一般常见的业务都是按照schema进行隔离，然后在mysql上层或者dao这一层面上，进行一个数据源路由，屏蔽数据库物理位置对开发的影响，阿里系主要是通过cobar/tddl来解决数据源路由问题。 所以，一般一个数据库实例上，会部署多个schema，每个schema会有由1个或者多个业务方关注。</p> 
 <p><strong>2 数据n:1业务：</strong></p> 
 <p>同样，当一个业务的数据规模达到一定的量级后，必然会涉及到水平拆分和垂直拆分的问题，针对这些拆分的数据需要处理时，就需要链接多个store进行处理，消费的位点就会变成多份，而且数据消费的进度无法得到尽可能有序的保证。 所以，在一定业务场景下，需要将拆分后的增量数据进行归并处理，比如按照时间戳/全局id进行排序归并.</p> 
 <p><strong>EventStore设计</strong></p> 
 <p>目前实现了Memory内存、本地file存储以及持久化到zookeeper以保障数据集群共享。</p> 
 <p>Memory内存的RingBuffer设计：</p> 
 <p><img class="img_loading" title="QQ20170617-191309@2x" src="https://images2.imgbox.com/07/55/438OzBCO_o.jpg" alt=""></p> 
 <p>定义了3个cursor</p> 
 <ul><li>Put : Sink模块进行数据存储的最后一次写入位置</li></ul> 
 <ul><li class="_mce_tagged_br">Get : 数据订阅获取的最后一次提取位置</li></ul> 
 <ul><li class="_mce_tagged_br">Ack : 数据消费成功的最后一次消费位置</li></ul> 
 <p>借鉴Disruptor的RingBuffer的实现，将RingBuffer拉直来看：</p> 
 <p><img class="img_loading" title="QQ20170617-191339@2x" src="https://images2.imgbox.com/57/bc/x9Tu53sg_o.jpg" alt=""></p> 
 <p>实现说明：</p> 
 <ul><li>Put/Get/Ack cursor用于递增，采用long型存储</li></ul> 
 <ul><li class="_mce_tagged_br">buffer的get操作，通过取余或者与操作。(与操作： cusor &amp; (size – 1) , size需要为2的指数，效率比较高)</li></ul> 
 <p><strong>Instance设计</strong></p> 
 <p><img class="img_loading" title="QQ20170617-191417@2x" src="https://images2.imgbox.com/e9/62/01tYHpfc_o.jpg" alt=""></p> 
 <p>instance代表了一个实际运行的数据队列，包括了EventPaser,EventSink,EventStore等组件。</p> 
 <p>抽象了CanalInstanceGenerator，主要是考虑配置的管理方式：</p> 
 <p>1、manager方式： 和你自己的内部web console/manager系统进行对接。(alibaba内部使用方式)</p> 
 <p>2、spring方式：基于spring xml + properties进行定义，构建spring配置.</p> 
 <ul><li>spring/memory-instance.xml 所有的组件(parser , sink , store)都选择了内存版模式，记录位点的都选择了memory模式，重启后又会回到初始位点进行解析。特点：速度最快，依赖最少</li></ul> 
 <ul><li class="_mce_tagged_br">spring/file-instance.xml 所有的组件(parser , sink , store)都选择了基于file持久化模式，注意，不支持HA机制.支持单机持久化</li></ul> 
 <ul><li class="_mce_tagged_br">spring/default-instance.xml 所有的组件(parser , sink , store)都选择了持久化模式，目前持久化的方式主要是写入zookeeper，保证数据集群共享. 支持HA</li></ul> 
 <ul><li class="_mce_tagged_br">spring/group-instance.xml 主要针对需要进行多库合并时，可以将多个物理instance合并为一个逻辑instance，提供客户端访问。场景：分库业务。 比如产品数据拆分了4个库，每个库会有一个instance，如果不用group，业务上要消费数据时，需要启动4个客户端，分别链接4个instance实例。使用group后，可以在canal server上合并为一个逻辑instance，只需要启动1个客户端，链接这个逻辑instance即可.</li></ul> 
 <p><strong>Server设计</strong></p> 
 <p><img class="img_loading" title="QQ20170617-191604@2x" src="https://images2.imgbox.com/8b/66/yqd4RGZT_o.jpg" alt=""></p> 
 <p>server代表了一个canal的运行实例，为了方便组件化使用，特意抽象了Embeded(嵌入式) / Netty(网络访问)的两种实现：</p> 
 <ul><li>Embeded : 对latency和可用性都有比较高的要求，自己又能hold住分布式的相关技术(比如failover)</li></ul> 
 <ul><li class="_mce_tagged_br">Netty : 基于netty封装了一层网络协议，由canal server保证其可用性，采用的pull模型，当然latency会稍微打点折扣，不过这个也视情况而定。</li></ul> 
 <p><strong>增量订阅/消费设计</strong></p> 
 <p><strong><img class="img_loading" title="QQ20170617-191735@2x" src="https://images2.imgbox.com/c5/7d/j128AXD4_o.jpg" alt=""><img class="img_loading" title="QQ20170617-193449@2x" src="https://images2.imgbox.com/39/c2/EXVbOh28_o.jpg" alt=""></strong></p> 
 <p>具体的协议格式，可参见：CanalProtocol.proto</p> 
 <p>get/ack/rollback协议介绍：</p> 
 <ul><li>Message getWithoutAck(int batchSize)，允许指定batchSize，一次可以获取多条，每次返回的对象为Message，包含的内容为：</li></ul> 
 <ul><li style="list-style-type:none;"> 
   <ul><li class="_mce_tagged_br">a. batch id 唯一标识</li></ul></li></ul> 
 <ul><li style="list-style-type:none;"> 
   <ul><li class="_mce_tagged_br">b. entries 具体的数据对象，对应的数据对象格式：EntryProtocol.proto</li></ul></li></ul> 
 <ul><li class="_mce_tagged_br">void rollback(long batchId)，顾命思议，回滚上次的get请求，重新获取数据。基于get获取的batchId进行提交，避免误操作</li></ul> 
 <ul><li class="_mce_tagged_br">void ack(long batchId)，顾命思议，确认已经消费成功，通知server删除数据。基于get获取的batchId进行提交，避免误操作</li></ul> 
 <ul><li class="_mce_tagged_br">canal的get/ack/rollback协议和常规的jms协议有所不同，允许get/ack异步处理，比如可以连续调用get多次，后续异步按顺序提交ack/rollback，项目中称之为流式api.</li></ul> 
 <p class="_mce_tagged_br">流式api设计的好处：</p> 
 <ul><li class="_mce_tagged_br">get/ack异步化，减少因ack带来的网络延迟和操作成本 (99%的状态都是处于正常状态，异常的rollback属于个别情况，没必要为个别的case牺牲整个性能)</li></ul> 
 <ul><li class="_mce_tagged_br">get获取数据后，业务消费存在瓶颈或者需要多进程/多线程消费时，可以不停的轮询get数据，不停的往后发送任务，提高并行化. (作者在实际业务中的一个case：业务数据消费需要跨中美网络，所以一次操作基本在200ms以上，为了减少延迟，所以需要实施并行化)</li></ul> 
 <p>流式api设计：</p> 
 <p><img class="img_loading" title="QQ20170617-191850@2x" src="https://images2.imgbox.com/08/7b/UUqcPGRR_o.jpg" alt=""></p> 
 <ul><li>每次get操作都会在meta中产生一个mark，mark标记会递增，保证运行过程中mark的唯一性</li></ul> 
 <ul><li class="_mce_tagged_br">每次的get操作，都会在上一次的mark操作记录的cursor继续往后取，如果mark不存在，则在last ack cursor继续往后取</li></ul> 
 <ul><li class="_mce_tagged_br">进行ack时，需要按照mark的顺序进行数序ack，不能跳跃ack. ack会删除当前的mark标记，并将对应的mark位置更新为last ack cusor</li></ul> 
 <ul><li class="_mce_tagged_br">一旦出现异常情况，客户端可发起rollback情况，重新置位：删除所有的mark, 清理get请求位置，下次请求会从last ack cursor继续往后取</li></ul> 
 <p><strong>数据格式</strong></p> 
 <p>canal采用protobuff:</p> 
 <blockquote> 
  <p>Entry</p> 
  <p>Header</p> 
  <p>logfileName [binlog文件名]</p> 
  <p>logfileOffset [binlog position]</p> 
  <p>executeTime [发生的变更]</p> 
  <p>schemaName</p> 
  <p>tableName</p> 
  <p>eventType [insert/update/delete类型]</p> 
  <p>entryType [事务头BEGIN/事务尾END/数据ROWDATA]</p> 
  <p>storeValue [byte数据,可展开，对应的类型为RowChange]</p> 
  <p>RowChange</p> 
  <p>isDdl [是否是ddl变更操作，比如create table/drop table]</p> 
  <p>sql [具体的ddl sql]</p> 
  <p>rowDatas [具体insert/update/delete的变更数据，可为多条，1个binlog event事件可对应多条变更，比如批处理]</p> 
  <p>beforeColumns [Column类型的数组]</p> 
  <p>afterColumns [Column类型的数组]</p> 
  <p>Column</p> 
  <p>index</p> 
  <p>sqlType [jdbc type]</p> 
  <p>name [column name]</p> 
  <p>isKey [是否为主键]</p> 
  <p>updated [是否发生过变更]</p> 
  <p>isNull [值是否为null]</p> 
  <p>value [具体的内容，注意为文本]</p> 
 </blockquote> 
 <p>canal-message example:</p> 
 <p>比如数据库中的表：</p> 
 <blockquote> 
  <p>mysql&gt; select * from person;</p> 
  <p>+----+------+------+------+</p> 
  <p>| id | name | age | sex |</p> 
  <p>+----+------+------+------+</p> 
  <p>| 1 | zzh | 10 | m |</p> 
  <p>| 3 | zzh3 | 12 | f |</p> 
  <p>| 4 | zzh4 | 5 | m |</p> 
  <p>+----+------+------+------+</p> 
  <p>3 rows in set (0.00 sec)</p> 
 </blockquote> 
 <p>更新一条数据(update person set age=15 where id=4)：</p> 
 <blockquote> 
  <p>****************************************************</p> 
  <p>* Batch Id: [2] ,count : [3] , memsize : [165] , Time : 2016-09-07 15:54:18</p> 
  <p>* Start : [mysql-bin.000003:6354:1473234846000(2016-09-07 15:54:06)]</p> 
  <p>* End : [mysql-bin.000003:6550:1473234846000(2016-09-07 15:54:06)]</p> 
  <p>****************************************************</p> 
  <p> </p> 
  <p>================&gt; binlog[mysql-bin.000003:6354] , executeTime : 1473234846000 , delay : 12225ms</p> 
  <p>BEGIN ----&gt; Thread id: 67</p> 
  <p>----------------&gt; binlog[mysql-bin.000003:6486] , name[canal_test,person] , eventType : UPDATE , executeTime : 1473234846000 , delay : 12225ms</p> 
  <p>id : 4 type=int(11)</p> 
  <p>name : zzh4 type=varchar(100)</p> 
  <p>age : 15 type=int(11) update=true</p> 
  <p>sex : m type=char(1)</p> 
  <p>----------------</p> 
  <p>END ----&gt; transaction id: 308</p> 
  <p>================&gt; binlog[mysql-bin.000003:6550] , executeTime : 1473234846000 , delay : 12240ms</p> 
 </blockquote> 
 <p><strong>HA机制设计</strong></p> 
 <p>canal的HA分为两部分，canal server和canal client分别有对应的ha实现：</p> 
 <ul><li>canal server: 为了减少对mysql dump的请求，不同server上的instance要求同一时间只能有一个处于running，其他的处于standby状态.</li></ul> 
 <ul><li class="_mce_tagged_br">canal client: 为了保证有序性，一份instance同一时间只能由一个canal client进行get/ack/rollback操作，否则客户端接收无法保证有序。</li></ul> 
 <p>整个HA机制的控制主要是依赖了zookeeper的几个特性，watcher和EPHEMERAL节点(和session生命周期绑定)，可以看下zookeeper的相关文章。</p> 
 <p>Canal Server:</p> 
 <p><img class="img_loading" title="QQ20170617-192323@2x" src="https://images2.imgbox.com/94/0f/vpdos2hf_o.jpg" alt=""></p> 
 <p>大致步骤：</p> 
 <ul><li>canal server要启动某个canal instance时都先向zookeeper进行一次尝试启动判断 (实现：创建EPHEMERAL节点，谁创建成功就允许谁启动)</li></ul> 
 <ul><li class="_mce_tagged_br">创建zookeeper节点成功后，对应的canal server就启动对应的canal instance，没有创建成功的canal instance就会处于standby状态</li></ul> 
 <ul><li class="_mce_tagged_br">一旦zookeeper发现canal server A创建的节点消失后，立即通知其他的canal server再次进行步骤1的操作，重新选出一个canal server启动instance.</li></ul> 
 <ul><li class="_mce_tagged_br">canal client每次进行connect时，会首先向zookeeper询问当前是谁启动了canal instance，然后和其建立链接，一旦链接不可用，会重新尝试connect.</li></ul> 
 <ul><li class="_mce_tagged_br">Canal Client的方式和canal server方式类似，也是利用zokeeper的抢占EPHEMERAL节点的方式进行控制.</li></ul> 
 <p>HA配置架构图(举例)如下所示：</p> 
 <p><img class="img_loading" title="QQ20170617-192414@2x" src="https://images2.imgbox.com/60/65/Un2PbLno_o.jpg" alt=""></p> 
 <p><strong>canal其他链接方式</strong></p> 
 <p>canal还有几种连接方式：</p> 
 <p><strong>1. 单连</strong></p> 
 <p><img class="img_loading" title="QQ20170617-192442@2x" src="https://images2.imgbox.com/2d/53/pA0f4ug7_o.jpg" alt=""></p> 
 <p><strong>2. 两个client+两个instance+1个mysql</strong></p> 
 <p>当mysql变动时，两个client都能获取到变动</p> 
 <p><img class="img_loading" title="QQ20170617-192531@2x" src="https://images2.imgbox.com/61/88/YB3GRX9t_o.jpg" alt=""></p> 
 <p> </p> 
 <p><strong>3. 一个server+两个instance+两个mysql+两个client</strong></p> 
 <p> </p> 
 <p><img class="img_loading" title="QQ20170617-192607@2x" src="https://images2.imgbox.com/b0/43/wzpUlNNN_o.jpg" alt=""></p> 
 <p><strong>4. instance的standby配置</strong></p> 
 <p><img class="img_loading" title="QQ20170617-192647@2x" src="https://images2.imgbox.com/80/34/oqNeBKWH_o.jpg" alt=""></p> 
 <p><strong>整体架构</strong></p> 
 <p>从整体架构上来说canal是这种架构的(canal中没有包含一个运维的console web来对接，但要运用于分布式环境中肯定需要一个Manager来管理)：</p> 
 <p><img class="img_loading" title="QQ20170617-192716@2x" src="https://images2.imgbox.com/39/10/w1wHWDhe_o.jpg" alt=""></p> 
 <p>一个总体的manager system对应于n个Canal Server(物理上来说是一台服务器), 那么一个Canal Server对应于n个Canal Instance(destinations). 大体上是三层结构，第二层也需要Manager统筹运维管理。</p> 
 <p>那么随着Docker技术的兴起，是否可以试一下下面的架构呢？</p> 
 <p><img class="img_loading" title="QQ20170617-192751@2x" src="https://images2.imgbox.com/31/d8/0lvPgyYN_o.jpg" alt=""></p> 
 <ul><li>一个docker中跑一个instance服务，相当于略去server这一层的概念。</li></ul> 
 <ul><li class="_mce_tagged_br">Manager System中配置一个instance,直接调取一个docker发布这个instance,其中包括向这个instance发送配置信息，启动instance服务.</li></ul> 
 <ul><li class="_mce_tagged_br">instance在运行过程中，定时刷新binlog filename+ binlog position的信息至zk。</li></ul> 
 <ul><li class="_mce_tagged_br">如果一个instance出现故障，instance本身报错或者zk感知此node消失，则根据相应的信息，比如上一步保存的binlog filename+binlog position重新开启一个docker服务，当然这里可以适当的加一些重试机制。</li></ul> 
 <ul><li class="_mce_tagged_br">当要更新时，类似AB test, 先关闭一个docker,然后开启新的已更新的替换，循序渐进的进行。</li></ul> 
 <ul><li class="_mce_tagged_br">当涉及到分表分库时，多个物理表对应于一个逻辑表，可以将结果存于一个公共的模块(比如MQ)，或者单独存取也可以，具体情况具体分析</li></ul> 
 <ul><li class="_mce_tagged_br">存储可以参考canal的多样化：内存，文件，zk，或者加入至MQ中</li></ul> 
 <ul><li class="_mce_tagged_br">docker由此之外的工具管理，比如kubernetes</li></ul> 
 <ul><li class="_mce_tagged_br">也可以进一步添加HA的功能，两个docker对应一个mysql，互为主备，类似Canal的HA架构。如果时效性不是贴别强的场景，考虑到成本，此功能可以不采用。</li></ul> 
 <p><strong>总结</strong></p> 
 <p>这里总结了一下Canal的一些点，仅供参考：</p> 
 <p>　　1、原理：模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议；mysql master收到dump请求，开始推送binary log给slave(也就是canal)；解析binary log对象(原始为byte流)</p> 
 <p class="_mce_tagged_br">　　2、重复消费问题：在消费端解决。</p> 
 <p class="_mce_tagged_br">　　3、采用开源的open-replicator来解析binlog</p> 
 <p class="_mce_tagged_br">　　4、canal需要维护EventStore，可以存取在Memory, File, zk</p> 
 <p class="_mce_tagged_br">　　5、canal需要维护客户端的状态，同一时刻一个instance只能有一个消费端消费</p> 
 <p class="_mce_tagged_br">　　6、数据传输格式：protobuff</p> 
 <p class="_mce_tagged_br">　　7、支持binlog format 类型:statement, row, mixed. 多次附加功能只能在row下使用，比如otter</p> 
 <p class="_mce_tagged_br">　　8、binlog position可以支持保存在内存，文件，zk中</p> 
 <p class="_mce_tagged_br">　　9、instance启动方式：rpc/http; 内嵌</p> 
 <p class="_mce_tagged_br">　　10、有ACK机制</p> 
 <p class="_mce_tagged_br">　　11、无告警，无监控，这两个功能都需要对接外部系统</p> 
 <p class="_mce_tagged_br">　　12、方便快速部署。</p> 
 <p><strong>参考资料</strong></p> 
 <p>https://github.com/alibaba/canal</p> 
</div> 
<p>转载于:https://www.cnblogs.com/sky-sql/p/7115927.html</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1417d365d4bebf8a55ed42302dcee181/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">c&#43;&#43;十进制转二进制</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/51a5edd8679f78756b1a60163b7d5bee/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">echarts中series中的数据如何如何循环显示数据</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>