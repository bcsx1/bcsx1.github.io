<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>OpenCV学习笔记 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="OpenCV学习笔记" />
<meta property="og:description" content="文章目录 OpenCV基本操作读取图像显示图像保存图像waitKey()创建窗口销毁窗口 图像处理基础item()itemset()通道拆分通道合并获取图像属性 图像运算加法运算图像加权和按位逻辑运算位平面分解图像加密与解密数字水印 色彩空间类型转换cv2.cvtColor()cv2.inRange(img, min, max)HSV色彩空间BGRA色彩空间 几何变换缩放翻转仿射透视重映射 阈值处理threshold()adaptiveThreshold()Otsu处理 图像平滑处理均值滤波方框滤波高斯滤波中值滤波双边滤波2D卷积 形态学操作腐蚀膨胀通用形态学函数开运算闭运算形态学梯度运算顶帽运算黑帽运算核函数 图像梯度Sobel算子Scharr算子Laplacian算子 图像金字塔向下采样向上采样 图像轮廓Canny边缘检测查找并绘制轮廓矩特征Hu矩轮廓拟合凸包利用形状场景算法比较轮廓轮廓的特征值 直方图处理绘制直方图直方图均衡化 傅里叶变换用Numpy实现傅里叶变换用OpenCV实现傅里叶变换 模板匹配模板匹配基础多模板匹配 霍夫变换霍夫变换原理霍夫直线变换概率霍夫变换霍夫圆变换 图像分割与提取距离变换函数标注图像分水岭算法实现图像分割与提取交互式前景提取 视频处理VideoCapture类VideoWriter类 绘画及交互绘画基础滚动条 OpenCV 本文基于《OpenCV轻松入门：面向Python》，作者李立宗。
在RGB图像中，图像是由R、G、B三个通道构成的，但是在OpenCV中，通道是按照B、G、R的顺序存储的。
基本操作 读取图像 img = cv2.imread(&#39;lena.png&#39;) 显示图像 cv2.imshow(&#39;show&#39;, img) 保存图像 cv2.imwrite(&#39;new_lena.png&#39;, img) waitKey() 若没有按键被按下，则返回-1；如果有按键被按下，则返回该按键的ASCII码。
创建窗口 cv2.namedWindow(&#39;window&#39;) 销毁窗口 销毁指定窗口
cv2.destroyWindow(&#39;window&#39;) # 销毁指定窗口 cv2.destroyAllWindows() # 销毁所有窗口 图像处理基础 item() 用于访问图像的像素点。
对于灰度图
img.item(row, col) 对于RGB图像
img.item(row, col, channel) itemset() 用于修改图像的像素值。
对于灰度图
img.itemset((row, col), value) 对于RGB图像
img.itemset((row, col, channel), value) 通道拆分 b, g, r = cv2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/332f0617dcc3ad444c8565d5d2805a6b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-22T14:22:07+08:00" />
<meta property="article:modified_time" content="2020-11-22T14:22:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">OpenCV学习笔记</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#OpenCV_1" rel="nofollow">OpenCV</a></li><li><ul><li><a href="#_6" rel="nofollow">基本操作</a></li><li><ul><li><a href="#_8" rel="nofollow">读取图像</a></li><li><a href="#_14" rel="nofollow">显示图像</a></li><li><a href="#_20" rel="nofollow">保存图像</a></li><li><a href="#waitKey_26" rel="nofollow">waitKey()</a></li><li><a href="#_30" rel="nofollow">创建窗口</a></li><li><a href="#_36" rel="nofollow">销毁窗口</a></li></ul> 
   </li><li><a href="#_45" rel="nofollow">图像处理基础</a></li><li><ul><li><a href="#item_47" rel="nofollow">item()</a></li><li><a href="#itemset_63" rel="nofollow">itemset()</a></li><li><a href="#_79" rel="nofollow">通道拆分</a></li><li><a href="#_85" rel="nofollow">通道合并</a></li><li><a href="#_91" rel="nofollow">获取图像属性</a></li></ul> 
   </li><li><a href="#_99" rel="nofollow">图像运算</a></li><li><ul><li><a href="#_101" rel="nofollow">加法运算</a></li><li><a href="#_115" rel="nofollow">图像加权和</a></li><li><a href="#_123" rel="nofollow">按位逻辑运算</a></li><li><a href="#_132" rel="nofollow">位平面分解</a></li><li><a href="#_155" rel="nofollow">图像加密与解密</a></li><li><a href="#_168" rel="nofollow">数字水印</a></li></ul> 
   </li><li><a href="#_190" rel="nofollow">色彩空间类型转换</a></li><li><ul><li><a href="#cv2cvtColor_192" rel="nofollow">cv2.cvtColor()</a></li><li><a href="#cv2inRangeimg_min_max_199" rel="nofollow">cv2.inRange(img, min, max)</a></li><li><a href="#HSV_211" rel="nofollow">HSV色彩空间</a></li><li><a href="#BGRA_225" rel="nofollow">BGRA色彩空间</a></li></ul> 
   </li><li><a href="#_241" rel="nofollow">几何变换</a></li><li><ul><li><a href="#_243" rel="nofollow">缩放</a></li><li><a href="#_259" rel="nofollow">翻转</a></li><li><a href="#_271" rel="nofollow">仿射</a></li><li><a href="#_339" rel="nofollow">透视</a></li><li><a href="#_365" rel="nofollow">重映射</a></li></ul> 
   </li><li><a href="#_382" rel="nofollow">阈值处理</a></li><li><ul><li><a href="#threshold_384" rel="nofollow">threshold()</a></li><li><a href="#adaptiveThreshold_413" rel="nofollow">adaptiveThreshold()</a></li><li><a href="#Otsu_444" rel="nofollow">Otsu处理</a></li></ul> 
   </li><li><a href="#_456" rel="nofollow">图像平滑处理</a></li><li><ul><li><a href="#_458" rel="nofollow">均值滤波</a></li><li><a href="#_478" rel="nofollow">方框滤波</a></li><li><a href="#_502" rel="nofollow">高斯滤波</a></li><li><a href="#_525" rel="nofollow">中值滤波</a></li><li><a href="#_540" rel="nofollow">双边滤波</a></li><li><a href="#2D_559" rel="nofollow">2D卷积</a></li></ul> 
   </li><li><a href="#_575" rel="nofollow">形态学操作</a></li><li><ul><li><a href="#_577" rel="nofollow">腐蚀</a></li><li><a href="#_598" rel="nofollow">膨胀</a></li><li><a href="#_613" rel="nofollow">通用形态学函数</a></li><li><a href="#_630" rel="nofollow">开运算</a></li><li><a href="#_648" rel="nofollow">闭运算</a></li><li><a href="#_666" rel="nofollow">形态学梯度运算</a></li><li><a href="#_678" rel="nofollow">顶帽运算</a></li><li><a href="#_696" rel="nofollow">黑帽运算</a></li><li><a href="#_712" rel="nofollow">核函数</a></li></ul> 
   </li><li><a href="#_737" rel="nofollow">图像梯度</a></li><li><ul><li><a href="#Sobel_739" rel="nofollow">Sobel算子</a></li><li><a href="#Scharr_784" rel="nofollow">Scharr算子</a></li><li><a href="#Laplacian_816" rel="nofollow">Laplacian算子</a></li></ul> 
   </li><li><a href="#_832" rel="nofollow">图像金字塔</a></li><li><ul><li><a href="#_836" rel="nofollow">向下采样</a></li><li><a href="#_854" rel="nofollow">向上采样</a></li></ul> 
   </li><li><a href="#_872" rel="nofollow">图像轮廓</a></li><li><ul><li><a href="#Canny_874" rel="nofollow">Canny边缘检测</a></li><li><a href="#_898" rel="nofollow">查找并绘制轮廓</a></li><li><a href="#_954" rel="nofollow">矩特征</a></li><li><a href="#Hu_1046" rel="nofollow">Hu矩</a></li><li><a href="#_1091" rel="nofollow">轮廓拟合</a></li><li><a href="#_1287" rel="nofollow">凸包</a></li><li><a href="#_1393" rel="nofollow">利用形状场景算法比较轮廓</a></li><li><a href="#_1457" rel="nofollow">轮廓的特征值</a></li></ul> 
   </li><li><a href="#_1627" rel="nofollow">直方图处理</a></li><li><ul><li><a href="#_1629" rel="nofollow">绘制直方图</a></li><li><a href="#_1672" rel="nofollow">直方图均衡化</a></li></ul> 
   </li><li><a href="#_1707" rel="nofollow">傅里叶变换</a></li><li><ul><li><a href="#Numpy_1709" rel="nofollow">用Numpy实现傅里叶变换</a></li><li><a href="#OpenCV_1816" rel="nofollow">用OpenCV实现傅里叶变换</a></li></ul> 
   </li><li><a href="#_1922" rel="nofollow">模板匹配</a></li><li><ul><li><a href="#_1924" rel="nofollow">模板匹配基础</a></li><li><a href="#_1981" rel="nofollow">多模板匹配</a></li></ul> 
   </li><li><a href="#_2043" rel="nofollow">霍夫变换</a></li><li><ul><li><a href="#_2045" rel="nofollow">霍夫变换原理</a></li><li><a href="#_2061" rel="nofollow">霍夫直线变换</a></li><li><a href="#_2098" rel="nofollow">概率霍夫变换</a></li><li><a href="#_2136" rel="nofollow">霍夫圆变换</a></li></ul> 
   </li><li><a href="#_2174" rel="nofollow">图像分割与提取</a></li><li><ul><li><a href="#_2176" rel="nofollow">距离变换函数</a></li><li><a href="#_2228" rel="nofollow">标注图像</a></li><li><a href="#_2292" rel="nofollow">分水岭算法实现图像分割与提取</a></li><li><a href="#_2337" rel="nofollow">交互式前景提取</a></li></ul> 
   </li><li><a href="#_2402" rel="nofollow">视频处理</a></li><li><ul><li><a href="#VideoCapture_2404" rel="nofollow">VideoCapture类</a></li><li><a href="#VideoWriter_2484" rel="nofollow">VideoWriter类</a></li></ul> 
   </li><li><a href="#_2534" rel="nofollow">绘画及交互</a></li><li><ul><li><a href="#_2536" rel="nofollow">绘画基础</a></li><li><a href="#_2622" rel="nofollow">滚动条</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="OpenCV_1"></a>OpenCV</h2> 
<p>本文基于《OpenCV轻松入门：面向Python》，作者李立宗。<br> 在RGB图像中，图像是由R、G、B三个通道构成的，但是在OpenCV中，通道是按照B、G、R的顺序存储的。</p> 
<h3><a id="_6"></a>基本操作</h3> 
<h4><a id="_8"></a>读取图像</h4> 
<pre><code>img = cv2.imread('lena.png')
</code></pre> 
<h4><a id="_14"></a>显示图像</h4> 
<pre><code>cv2.imshow('show', img)
</code></pre> 
<h4><a id="_20"></a>保存图像</h4> 
<pre><code>cv2.imwrite('new_lena.png', img)
</code></pre> 
<h4><a id="waitKey_26"></a>waitKey()</h4> 
<p>若没有按键被按下，则返回-1；如果有按键被按下，则返回该按键的ASCII码。</p> 
<h4><a id="_30"></a>创建窗口</h4> 
<pre><code>cv2.namedWindow('window')
</code></pre> 
<h4><a id="_36"></a>销毁窗口</h4> 
<p>销毁指定窗口</p> 
<pre><code>cv2.destroyWindow('window')  # 销毁指定窗口
cv2.destroyAllWindows()  # 销毁所有窗口
</code></pre> 
<h3><a id="_45"></a>图像处理基础</h3> 
<h4><a id="item_47"></a>item()</h4> 
<p>用于访问图像的像素点。</p> 
<p>对于灰度图</p> 
<pre><code>img.item(row, col)
</code></pre> 
<p>对于RGB图像</p> 
<pre><code>img.item(row, col, channel)
</code></pre> 
<h4><a id="itemset_63"></a>itemset()</h4> 
<p>用于修改图像的像素值。</p> 
<p>对于灰度图</p> 
<pre><code>img.itemset((row, col), value)
</code></pre> 
<p>对于RGB图像</p> 
<pre><code>img.itemset((row, col, channel), value)
</code></pre> 
<h4><a id="_79"></a>通道拆分</h4> 
<pre><code>b, g, r = cv2.split(img)
</code></pre> 
<h4><a id="_85"></a>通道合并</h4> 
<pre><code>bgr = cv2.merge([b, g, r])
</code></pre> 
<h4><a id="_91"></a>获取图像属性</h4> 
<pre><code>img.shape  # 获取行数、列数、通道数
img.size  # 行数×列数×通道数
img.dtype  # 图像的数据类型
</code></pre> 
<h3><a id="_99"></a>图像运算</h3> 
<h4><a id="_101"></a>加法运算</h4> 
<ul><li> <p>使用"+"对图像a,b进行求和运算时，若两个图像对应像素值的和小于或等于255时，则直接得到运算结果；若两个图像对应像素值的和大于255，则将运算结果对256取模。</p> </li><li> <p>使用cv2.add()函数进行求和运算时，若两个图像对应像素值的和小于或等于255时，则直接得到运算结果；若两个图像对应像素值的和大于255，则将运算结果为饱和值255。</p> </li></ul> 
<p>cv2.add()参数的三种形式</p> 
<pre><code>cv2.add(img1,img2)
cv2.add(img,value)
cv2.add(value,img)
</code></pre> 
<h4><a id="_115"></a>图像加权和</h4> 
<p>output=img1×alpha+img2×beta+gamma</p> 
<pre><code>output = cv2.addWeighted(img1, alpha, img2, beta, gamma)
</code></pre> 
<h4><a id="_123"></a>按位逻辑运算</h4> 
<pre><code>cv2.bitwise_and(img1, img2)  # 按位与
cv2.bitwise_or(img1, img2)  # 按位或
cv2.bitwise_xor(img1, img2)  # 按位异或
cv2.bitwise_not(img)  # 按位取反
</code></pre> 
<h4><a id="_132"></a>位平面分解</h4> 
<ol><li>图像预处理：读取图像，获取图像的行(row)和列(col)。</li><li>构造提取矩阵：建立一个值均为2<sup>n</sup>的矩阵作为提取矩阵，用来与图像进行按位与运算，以提取第n个位平面。</li><li>提取位平面：将灰度图像与提取矩阵进行按位与运算，得到各个位平面。</li><li>阈值处理：先将大于0的值处理为True，等于0的值处理为False，得到mask矩阵。再将位平面矩阵中对应mask矩阵中相应位置为True的值替换为255。</li><li>显示图像：用for循环显示出图像。</li></ol> 
<pre><code>img = cv2.imread('lena.png', 0)  # 将图像调整为灰度图
cv2.imshow('lena', img)
row, col = img.shape
x = np.zeros((row, col, 8), dtype=np.uint8)  # 用于提取各个位平面
for i in range(8):
    x[:, :, i] = 2 ** i
r = np.zeros((row, col, 8), dtype=np.uint8)
for i in range(8):
    r[:, :, i] = cv2.bitwise_and(img, x[:, :, i])  # 提取位平面
    mask = r[:, :, i] &gt; 0  # 若值大于0则为True，否则为False
    r[mask] = 255  # 若为True则将值替换为255
    cv2.imshow(str(i), r[:, :, i])
</code></pre> 
<h4><a id="_155"></a>图像加密与解密</h4> 
<p>通过对原始图像与密钥图像进行按位异或，可以实现加密；将加密后的图像与密钥图像再进行按位异或，可以实现解密。</p> 
<pre><code>img = cv2.imread('lena.png', 0)  # 将图像调整为灰度图
key = np.random.randint(0, 256, size=[512, 512], dtype=np.uint8)  # 生成密钥图像
encryption = cv2.bitwise_xor(img, key)  # 加密
decryption = cv2.bitwise_xor(encryption, key)  # 解密
cv2.imshow('encryption', encryption)
cv2.imshow('decryption', decryption)
</code></pre> 
<h4><a id="_168"></a>数字水印</h4> 
<p>将图像的最低有效位层替换为需要隐藏的二值图像，可以实现将二值图像隐藏的目的。由于二值图像处于图像的最低有效位上，所以对图像的影响非常不明显。</p> 
<pre><code>img = cv2.imread('image/lena.png', 0)  # 将图像调整为灰度图
waterMark = cv2.imread('image/cmh.png', 0)  # 读取水印图像
w = waterMark[:, :] &gt; 0  # 若值大于0则为True，否则为False
waterMark[w] = 1  # 若为True则将值替换为1
row, col = img.shape
array1 = np.ones([row, col], np.uint8)  # 构造值为1的矩阵
array254 = np.ones([row, col], np.uint8) * 254  # 构造值为254的矩阵
imgHigh7 = cv2.bitwise_and(img, array254)  # 取出图像的高7位

encryption = cv2.bitwise_or(imgHigh7, waterMark)  # 加密
decryption = cv2.bitwise_and(encryption, array1)  # 解密
d = decryption[:, :] &gt; 0  # 若值大于0则为True，否则为False
decryption[d] = 255  # 若为True则将值替换为255
cv2.imshow('encryption', encryption)
cv2.imshow('decryption', decryption)
</code></pre> 
<h3><a id="_190"></a>色彩空间类型转换</h3> 
<h4><a id="cv2cvtColor_192"></a>cv2.cvtColor()</h4> 
<pre><code>gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # 将图像转换为灰度图
HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # 将图像转换为HSV空间
</code></pre> 
<h4><a id="cv2inRangeimg_min_max_199"></a>cv2.inRange(img, min, max)</h4> 
<p>通过函数cv2.inRange()来判断图像内像素点的像素值是否在指定的范围内。如果处于该指定区间内，则对应位置上的值为255，如果不处于该指定区间内，则对应位置上的值为0。</p> 
<pre><code>mask = cv2.inRange(img, 100, 200)  # 单通道图像

minValue = np.array([100, 100, 100])
maxValue = np.array([200, 200, 200])
mask = cv2.inRange(img, minValue, maxValue)  # 多通道图像
</code></pre> 
<h4><a id="HSV_211"></a>HSV色彩空间</h4> 
<p>H：色调（Hue，也成为色相）</p> 
<p>S：饱和度（Saturation）</p> 
<p>V：亮度（Value）</p> 
<ul><li> <p>色调H：取值范围是[0,360]，在OpenCV中，可以直接把色调的值除以2，得到[0,180]之间的值，以适应8位二进制的存储和表示范围。</p> </li><li> <p>饱和度S：取值范围是[0,1]，灰度颜色的饱和度值为0。</p> </li><li> <p>亮度V：取值范围是[0,1]。</p> </li></ul> 
<h4><a id="BGRA_225"></a>BGRA色彩空间</h4> 
<p>A通道，也叫alpha通道，表示透明度，取值范围是[0,255]，表示从透明到不透明。</p> 
<pre><code>bgra255 = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)  # 转换为BGRA色彩空间
b, g, r, a = cv2.split(bgra255)  # 分离b,g,r,a
a[:, :] = 125
bgra125 = cv2.merge([b, g, r, a])
a[:, :] = 0
bgra0 = cv2.merge([b, g, r, a])
cv2.imwrite('image/bgra255.png', bgra255)
cv2.imwrite('image/bgra125.png', bgra125)
cv2.imwrite('image/bgra0.png', bgra0)
</code></pre> 
<h3><a id="_241"></a>几何变换</h3> 
<h4><a id="_243"></a>缩放</h4> 
<p><strong>cv2.resize(img, dsize, fx, fy, interpolation)</strong></p> 
<p>在cv2.resize()函数中，图像的大小可以通过"dsize"或者"fx"、"fy"二者之一来指定。</p> 
<ul><li>通过dsize指定：</li></ul> 
<p>如果指定参数dsize的值，无论是否指定了参数fx和fy的值，都由dsize来决定目标图像的大小。需要注意的是，dsize内的第一个参数对应缩放后图像的宽度（width，即列数col，与参数fx相关），第二个参数对应缩放后图像的高度（height，即行数row，与参数fy相关）。</p> 
<ul><li>通过参数fx和fy指定：</li></ul> 
<p>如果参数dsize的值是None，那么目标图像的大小通过参数fx和fy来决定。</p> 
<p>当缩小图像时，使用区域插值方式（cv2.INTER_AREA）能够得到最好的效果。当放大图像时，使用三次样条插值（cv2.INTER_CUBIC）方式和双线性插值（cv2.INTER_LINEAR）方式都能取得较好的效果。三次样条插值方式速度较慢。双线性插值方式速度相对较快且效果并不逊色，双线性插值方式是默认方式。</p> 
<h4><a id="_259"></a>翻转</h4> 
<p><strong>cv2.flip(img, flipCode)</strong></p> 
<p>flipCode参数的意义：</p> 
<ul><li> <p>0：绕x轴旋转</p> </li><li> <p>正数：绕y轴旋转</p> </li><li> <p>负数：绕x轴，y轴同时旋转</p> </li></ul> 
<h4><a id="_271"></a>仿射</h4> 
<p><strong>cv2.warpAffine(img, M, dsize)</strong></p> 
<ul><li> <p>M代表一个2×3的变换矩阵</p> </li><li> <p>dsize代表输出图像的尺寸大小</p> </li></ul> 
<p><strong>output(x,y)=img(M<sub>11</sub>x+M<sub>12</sub>y+M<sub>13</sub>,M<sub>21</sub>x+M<sub>22</sub>y+M<sub>23</sub>)</strong></p> 
<ol><li> <p><strong>平移：</strong></p> <p>将原始图像img向右移动100个像素，向下移动200个像素，则其对应关系为：</p> <p>output(x,y)=img(x+100,y+200)，得到M=[[1,0,100],[0,1,200]]</p> <pre><code>height, width = img.shape[:2]
M = np.float32([[1, 0, 100], [0, 1, 200]])  # 构造平移矩阵
move = cv2.warpAffine(img, M, (width, height))  # 平移
cv2.imshow('original', img)
cv2.imshow('move', move)
</code></pre> </li><li> <p><strong>旋转：</strong></p> <p>进行旋转之前可以先通过**cv2.getRotationMatrix2D()**函数获取转换矩阵。该函数语法格式为：</p> <p><strong>retval = cv2.getRotationMatrix2D(center, angle, scale)</strong></p> 
  <ul><li> <p>center：旋转的中心点</p> </li><li> <p>angle：旋转的角度，正数代表逆时针旋转，负数代表顺时针旋转</p> </li><li> <p>scale：变换尺度</p> </li></ul> <p>以图像中心为原点，逆时针旋转45°，并缩小为原始图像的0.6倍，代码如下：</p> <pre><code>height, width = img.shape[:2]
M = cv2.getRotationMatrix2D((height / 2, width / 2), 45, 0.6)  # 构造旋转矩阵
rotate = cv2.warpAffine(img, M, (width, height))
cv2.imshow('original', img)
cv2.imshow('rotate', rotate)
</code></pre> </li><li> <p><strong>更复杂的仿射变换：</strong></p> <p>对于更复杂的仿射变换，可以用**cv2.getAffineTransform()**函数生成转换矩阵M。该函数语法格式为：</p> <p><strong>retval = cv2.getAffineTransform(pts1, pts2)</strong></p> 
  <ul><li> <p>pts1代表输入图像的三个点坐标</p> </li><li> <p>pts2代表输出图像的三个点坐标</p> </li></ul> <p>在该函数中，pts1、pts2都是包含三个二维数组(x,y)点的数组。上述参数通过函数定义了两个平行四边形。pts1、pts2的三个点分别对应平行四边形的左上角、右上角、左下角三个点。</p> <pre><code>row, col = img.shape[:2]
pts1 = np.float32([[0, 0], [col - 1, 0], [0, row - 1]])
pts2 = np.float32([[0, row * 0.33], [col * 0.85, row * 0.25], [col * 0.15, row * 0.7]])
M = cv2.getAffineTransform(pts1, pts2)
output = cv2.warpAffine(img, M, (col, row))
cv2.imshow('original', img)
cv2.imshow('result', output)
</code></pre> </li></ol> 
<h4><a id="_339"></a>透视</h4> 
<p>仿射可以将矩形映射为任意平行四边形，透视变换可以将矩形映射为任意四边形。</p> 
<p><strong>cv2.warpPerspective(img, M, dsize)</strong></p> 
<ul><li>M代表一个3×3的变换矩阵</li></ul> 
<p>可以使用**cv2.getPerspectiveTransform()**函数生成转换矩阵M。该函数语法格式为：</p> 
<p><strong>retval = cv2.getPerspectiveTransform(pts1, pts2)</strong></p> 
<ul><li>pts1代表输入图像的四个顶点的坐标</li><li>pts2代表输出图像的四个顶点的坐标</li></ul> 
<pre><code>img = cv2.imread('image/perspective.bmp')
row, col = img.shape[:2]
pts1 = np.float32([[150, 50], [400, 50], [60, 450], [310, 450]])
pts2 = np.float32([[50, 50], [row - 50, 50], [50, col - 50], [row - 50, col - 50]])
M = cv2.getPerspectiveTransform(pts1, pts2)  # 构造透视变换矩阵
output = cv2.warpPerspective(img, M, (col, row))  # 透视
cv2.imshow('original', img)
cv2.imshow('perspective', output)
</code></pre> 
<h4><a id="_365"></a>重映射</h4> 
<p>把一幅图像内的像素点放置到另外一幅图像内的指定位置，这个过程叫做重映射。</p> 
<p><strong>cv2.remap(img, map1, map2, interpolation)</strong></p> 
<ul><li> <p>map1参数有两种可能的值：</p> 
  <ul><li> <p>表示(x,y)点的一个映射</p> </li><li> <p>表示CV_16SC2，CV_32FC1，CV_32FC2类型(x,y)点的x值</p> </li></ul> </li><li> <p>map2参数同样有两种可能的值：</p> 
  <ul><li>当map1表示(x,y)时，该值为空</li><li>当map1表示(x,y)点的x值时，该值是CV_16UC1，CV_32FC1类型(x,y)点的y值</li></ul> </li><li> <p>interpolation表示插值方式</p> </li></ul> 
<h3><a id="_382"></a>阈值处理</h3> 
<h4><a id="threshold_384"></a>threshold()</h4> 
<p><strong>retval, output = cv2.threshold(img, thresh, maxval, type)</strong></p> 
<ul><li>retval代表返回的阈值</li><li>output代表阈值分割结果图像</li><li>img代表要进行阈值分割的图像</li><li>thresh代表要设定的阈值</li><li>maxval代表当type参数为THRESH_BINARY或者THRESH_BINARY_INV类型时，需要设定的最大值</li><li>type代表阈值分割的类型</li></ul> 
<img src="https://images2.imgbox.com/d5/1f/p2brOUMa_o.png" alt="阈值分割类型"> 
<img src="https://images2.imgbox.com/5e/3d/1K1mOOoy_o.png" alt="阈值分割类型可视化表示"> 
<pre><code>img = cv2.imread('image/lena.png', 0)
thresh1, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)  # 二值化阈值处理
thresh2, binary_inv = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)  # 反二值化阈值处理
thresh3, trunc = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)  # 截断阈值化处理
thresh4, toZero_inv = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)  # 超阈值零处理
thresh5, toZero = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)  # 低阈值零处理
cv2.imshow('BINARY', binary)
cv2.imshow('BINARY_INV', binary_inv)
cv2.imshow('TRUNC', trunc)
cv2.imshow('TOZERO_INV', toZero_inv)
cv2.imshow('TOZERO', toZero)
</code></pre> 
<h4><a id="adaptiveThreshold_413"></a>adaptiveThreshold()</h4> 
<p>可以使用**cv2.adaptiveThreshold()**来实现自适应阈值处理，该函数的语法格式为：</p> 
<p><strong>cv2.adaptiveThreshold(img, maxValue, adaptiveMethod, thresholdType, blockSize, C)</strong></p> 
<ul><li> <p>maxValue代表最大值</p> </li><li> <p>adaptiveMethod代表自适应方法</p> </li><li> <p>thresholdType代表阈值处理方式，该值必须是cv2.THRESH_BINARY或者cv2.THRESH_BINARY_INV中的一个</p> </li><li> <p>blockSize代表块大小。表示一个像素在计算其阈值时所使用的邻域尺寸。</p> </li><li> <p>C是常量</p> </li></ul> 
<p>自适应阈值等于每个像素由参数blockSize所指定邻域的加权平均值减去常量C。<strong>adaptiveMethod</strong>参数包含两种不同的方法：</p> 
<ul><li><strong>cv2.ADAPTIVE_THRESH_MEAN_C</strong>：邻域所有像素点的权重值是一样的</li><li><strong>cv2.ADAPTIVE_THRESH_GAUSSIAN_C</strong>：权重值与邻域各个像素点到中心点的距离有关，通过高斯方程得到各个点的权重值</li></ul> 
<pre><code>img = cv2.imread('image/computer.jpg', 0)
thresh1, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)  # 二值化阈值处理
mean = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 3)
gaussian = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5, 3)
cv2.imshow('BINARY', binary)
cv2.imshow('MEAN', mean)
cv2.imshow('GAUSSIAN', gaussian)
</code></pre> 
<h4><a id="Otsu_444"></a>Otsu处理</h4> 
<p>Otsu方法能根据当前图像给出最佳的类间分割阈值。Otsu方法会遍历所有可能阈值，从而找到最佳的阈值。</p> 
<p>通过在函数<strong>cv2.threshold()<strong>中对参数</strong>type</strong>的类型多传递一个参数<strong>cv2.THRESH_OTSU</strong>，即可实现Otsu方法的阈值分割。在使用Otsu方法时，要把阈值设为0</p> 
<pre><code>img = cv2.imread('image/lena.png', 0)
thresh, otsu = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  # Otsu处理
cv2.imshow('OTSU', otsu)
</code></pre> 
<h3><a id="_456"></a>图像平滑处理</h3> 
<h4><a id="_458"></a>均值滤波</h4> 
<p>均值滤波是指用当前像素点周围N×N个像素值的均值来代替当前的像素值。</p> 
<p><strong>cv2.blur(img, ksize, anchor, borderType)</strong></p> 
<ul><li>img是需要处理的图像，它可以有任意数量的通道，并能对各个通道独立处理。</li><li>ksize是滤波核的大小。滤波核大小是指在均值处理中，其邻域图像的高度和宽度。</li><li>anchor是锚点，其默认值为(-1,-1)，表示当前计算均值的点位于核的中心点位置。</li><li>borderType是边界样式，该值决定了以何种方式处理边界。</li></ul> 
<p>函数**cv2.blur()**的一般形式为：<strong>cv2.blur(img, ksize)</strong></p> 
<pre><code>img = cv2.imread('image/lenaNoise.png')
output = cv2.blur(img, (5, 5))  # 均值滤波
cv2.imshow('original', img)
cv2.imshow('blur', output)
</code></pre> 
<h4><a id="_478"></a>方框滤波</h4> 
<p>方框滤波可以自由选择是否对均值滤波的结果进行归一化，即可以自由选择滤波结果是邻域像素值之和的平均值，还是邻域像素值之和。</p> 
<p><strong>cv2.boxFilter(img, ddepth, ksize, anchor, normalize, borderType)</strong></p> 
<ul><li> <p>ddepth是处理结果图像的图像深度，一般使用-1表示与原始图像使用相同的图像深度。</p> </li><li> <p>ksize是滤波核的大小。滤波核大小是指在滤波处理中，其邻域图像的高度和宽度。</p> </li><li> <p>anchor是锚点，其默认值为(-1,-1)，表示当前计算均值的点位于核的中心点位置。</p> </li><li> <p>normalize表示在滤波时是否进行归一化处理,默认值为1</p> 
  <ul><li>normalize=1时，表示要进行归一化处理，要用邻域像素值之和除以面积</li><li>normalize=0时，表示不需要进行归一化处理，直接使用邻域像素值之和</li></ul> </li><li> <p>borderType是边界样式，该值决定了以何种方式处理边界。</p> </li></ul> 
<p>函数**cv2.boxFilter()**的一般形式为：<strong>cv2.boxFilter(img, ddepth, ksize)</strong></p> 
<pre><code>img = cv2.imread('image/lenaNoise.png')
output = cv2.boxFilter(img, -1, (5, 5))  # 方框滤波
cv2.imshow('original', img)
cv2.imshow('boxFilter', output)
</code></pre> 
<h4><a id="_502"></a>高斯滤波</h4> 
<p>在进行均值滤波和方框滤波时，其邻域内每个像素的权值是相等的。在高斯滤波中，会将中心点的权重值加大，远离中心点的权重值减小。</p> 
<p><strong>cv2.GaussianBlur(img, ksize, sigmaX, sigmaY, borderType)</strong></p> 
<ul><li> <p>ksize是滤波核的大小。滤波核大小是指在滤波处理中，其邻域图像的高度和宽度。<strong>ksize的宽度和高度可以不相同，但是它们必须是奇数</strong></p> </li><li> <p>sigmaX是卷积核在X轴方向(水平方向)的标准差</p> </li><li> <p>sigmaY是卷积核在Y轴方向(垂直方向)的标准差。如果将该值设置为0，则只采用sigmaX的值；如果sigmaX和sigmaY都是0，则通过ksize.width和ksize.height计算得到</p> 
  <ul><li>sigmaX=0.3×[(ksize.width-1)×0.5-1]+0.8</li><li>sigmaY=0.3×[(ksize.height-1)×0.5-1]+0.8</li></ul> </li><li> <p>borderType是边界样式，该值决定了以何种方式处理边界</p> </li></ul> 
<p>函数**cv2.GaussianBlur()**的一般形式为：<strong>cv2.GaussianBlur(img, ksize, 0, 0)</strong></p> 
<pre><code>img = cv2.imread('image/lenaNoise.png')
output = cv2.GaussianBlur(img, (5, 5), 0, 0)  # 高斯滤波
cv2.imshow('original', img)
cv2.imshow('GaussianBlur', output)
</code></pre> 
<h4><a id="_525"></a>中值滤波</h4> 
<p>中值滤波用邻域内所有像素值的中间值来代替当前像素点的像素值。</p> 
<p><strong>cv2.medianBlur(img, ksize)</strong></p> 
<ul><li>ksize是滤波核的大小。滤波核大小是指在滤波处理中，其邻域图像的高度和宽度。<strong>核大小必须是比1大的奇数</strong>。</li></ul> 
<pre><code>img = cv2.imread('image/lenaNoise.png')
output = cv2.medianBlur(img, 3)  # 中值滤波
cv2.imshow('original', img)
cv2.imshow('medianBlur', output)
</code></pre> 
<h4><a id="_540"></a>双边滤波</h4> 
<p>前述滤波方式基本只考虑了空间的权重信息，计算起来比较方便，但是在边缘信息的处理上存在较大的问题。双边滤波在计算某一个像素点的新值时，不仅考虑距离信息(距离越远，权重越小)，还考虑色彩信息(色彩差别越大，权重越小)。双边滤波综合考虑距离和色彩的权重结果，既能够有效的去除噪声，又能够较好的保护边缘信息。</p> 
<p><strong>cv2.bilateralFilter(img, d, sigmaColor, sigmaSpace)</strong></p> 
<ul><li>d是在滤波时选取的空间距离参数，这里表示以当前像素点为中心点的直径。如果该值为非正数，则会自动从参数sigmaSpace计算得到。推荐d=5。</li><li>sigmaColor是滤波处理时选取的颜色差值范围，该值决定了周围哪些像素点能够参与到滤波中来。与当前像素点的像素值差值小于sigmaColor的像素点，能够参与到当前的滤波中。</li><li>sigmaSpace是坐标空间中的sigma值。它的值越大，说明有越多的点能够参与到滤波计算中来。当d＞0时，无论sigmaSpace的值如何，d都指定邻域大小；否则，d与sigmaSpace的值成比例。</li></ul> 
<p>为了简单起见，可以将sigmaColor和sigmaSpace的值设置为相同的。一般情况下，10&lt;sigma&lt;150。</p> 
<pre><code>img = cv2.imread('image/lenaNoise.png')
output = cv2.bilateralFilter(img, 25, 100, 100)  # 双边滤波
cv2.imshow('original', img)
cv2.imshow('bilateralFilter', output)
</code></pre> 
<h4><a id="2D_559"></a>2D卷积</h4> 
<p>我们有时希望使用特定的卷积核实现卷积操作，OpenCV允许用户自定义卷积核实现卷积操作，使用OpenCV的自定义卷积核实现卷积操作的函数是<strong>cv2.filter2D()</strong>。</p> 
<p><strong>cv2.filter2D(img, ddepth, kernel)</strong></p> 
<ul><li>ddepth是处理结果图像的图像深度，一般使用-1表示与原始图像使用相同的图像深度。</li><li>kernel是卷积核，是一个单通道的数组。如果想在处理彩色图像时让每个通道使用不同的核，则必须将彩色图像分解后使用不同的核完成操作。</li></ul> 
<pre><code>kernel = np.ones((9, 9), np.float32) / 81
output = cv2.filter2D(img, -1, kernel)
cv2.imshow('original', img)
cv2.imshow('filter2D', output)
</code></pre> 
<h3><a id="_575"></a>形态学操作</h3> 
<h4><a id="_577"></a>腐蚀</h4> 
<p>腐蚀能够将图像的边界点消除，使图像沿着边界向内收缩，也可以将小于指定结构体元素的部分去除。</p> 
<p>在腐蚀过程中，通常使用一个结构元来逐个像素地扫描要被腐蚀的图像，并根据结构元和被腐蚀图像的关系来确定腐蚀结果。</p> 
<ul><li>如果结构元完全处于前景图像中，就将结构元中心点所对应的腐蚀结果图像中的像素点处理为前景色</li><li>如果结构元未完全处于前景图像中，就将结构元中心点所对应的腐蚀结果图像中的像素点处理为背景色</li></ul> 
<p><strong>cv2.erode(img, kernel)</strong></p> 
<ul><li>kernel代表腐蚀操作时所采用的结构类型。它可以自定义生成，也可以通过函数**cv2.getStructuringElement()**生成。</li></ul> 
<pre><code>img = cv2.imread('image/erode.bmp')
kernel = np.ones((10, 10), np.uint8)
output = cv2.erode(img, kernel)  # 腐蚀
cv2.imshow('original', img)
cv2.imshow('erode', output)
</code></pre> 
<h4><a id="_598"></a>膨胀</h4> 
<p>膨胀操作能对图像的边界进行扩张。</p> 
<ul><li>如果结构元中任意一点处于前景图像中，就将膨胀结果图像中对应像素点处理为前景色</li><li>如果结构元完全处于背景图像外，就将膨胀结果图像中对应像素点处理为背景色</li></ul> 
<pre><code>img = cv2.imread('image/dilation.bmp')
kernel = np.ones((10, 10), np.uint8)
output = cv2.dilate(img, kernel)  # 膨胀
cv2.imshow('original', img)
cv2.imshow('dilate', output)
</code></pre> 
<h4><a id="_613"></a>通用形态学函数</h4> 
<p><strong>cv2.morphologyEx(img, op, kernel)</strong></p> 
<ul><li>op代表操作类型</li></ul> 
<table><thead><tr><th>类型</th><th>说明</th><th>含义</th><th>操作</th></tr></thead><tbody><tr><td>cv2.MORPH_ERODE</td><td>腐蚀</td><td>腐蚀</td><td>erode(img)</td></tr><tr><td>cv2.MORPH_DILATE</td><td>膨胀</td><td>膨胀</td><td>dilate(img)</td></tr><tr><td>cv2.MORPH_OPEN</td><td>开运算</td><td>先腐蚀后膨胀</td><td>dilate(erode(img))</td></tr><tr><td>cv2.MORPH_CLOSE</td><td>闭运算</td><td>先膨胀后腐蚀</td><td>erode(dilate(img))</td></tr><tr><td>cv2.MORPH_GRADIENT</td><td>形态学梯度运算</td><td>膨胀图减腐蚀图</td><td>dilate(img)-erode(img)</td></tr><tr><td>cv2.MORPH_TOPHAT</td><td>顶帽运算</td><td>原始图像减开运算所得图像</td><td>img-open(img)</td></tr><tr><td>cv2.MORPH_BLACKHAT</td><td>黑帽运算</td><td>闭运算所得图像减原始图像</td><td>close(img)-img</td></tr><tr><td>cv2.MORPH_HITMISS</td><td>击中击不中</td><td>前景背景腐蚀运算的交集</td><td>intersection(erode(img),erode(img))</td></tr></tbody></table> 
<h4><a id="_630"></a>开运算</h4> 
<p>开运算先将图像腐蚀，再将所得图像膨胀。开运算可以用于去噪、计数等。</p> 
<p><strong>cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)</strong></p> 
<pre><code>img1 = cv2.imread('image/opening1.bmp')
img2 = cv2.imread('image/opening2.bmp')
kernel = np.ones((10, 10), np.uint8)
output1 = cv2.morphologyEx(img1, cv2.MORPH_OPEN, kernel)  # 开运算
output2 = cv2.morphologyEx(img2, cv2.MORPH_OPEN, kernel)  # 开运算
cv2.imshow('img1', img1)
cv2.imshow('OPEN1', output1)
cv2.imshow('img2', img2)
cv2.imshow('OPEN2', output2)
</code></pre> 
<h4><a id="_648"></a>闭运算</h4> 
<p>闭运算是先膨胀、后腐蚀的运算，它有助于关闭前景物体内部的小孔，或去除物体上的小黑点，还可以将不同的前景图像进行连接。</p> 
<p><strong>cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)</strong></p> 
<pre><code>img1 = cv2.imread('image/closing1.bmp')
img2 = cv2.imread('image/closing2.bmp')
kernel = np.ones((10, 10), np.uint8)
output1 = cv2.morphologyEx(img1, cv2.MORPH_CLOSE, kernel)  # 闭运算
output2 = cv2.morphologyEx(img2, cv2.MORPH_CLOSE, kernel, iterations=3)  # 闭运算，迭代3次
cv2.imshow('img1', img1)
cv2.imshow('CLOSE1', output1)
cv2.imshow('img2', img2)
cv2.imshow('CLOSE2', output2)
</code></pre> 
<h4><a id="_666"></a>形态学梯度运算</h4> 
<p>形态学梯度运算是用图像的膨胀图像减腐蚀图像的操作，可以获取原始图像中前景图像的边缘。</p> 
<pre><code>img = cv2.imread('image/gradient.bmp')
kernel = np.ones((5, 5), np.uint8)
output = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)  # 形态学梯度运算
cv2.imshow('img', img)
cv2.imshow('GRADIENT', output)
</code></pre> 
<h4><a id="_678"></a>顶帽运算</h4> 
<p>顶帽运算是用原始图像减去开运算所得图像的操作，能够获取图像的噪声信息，或者得到比原始图像的边缘更亮的边缘信息。</p> 
<p><strong>cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)</strong></p> 
<pre><code>img1 = cv2.imread('image/tophat.bmp')
img2 = cv2.imread('image/lena.png')
kernel = np.ones((5, 5), np.uint8)
output1 = cv2.morphologyEx(img1, cv2.MORPH_TOPHAT, kernel)  # 顶帽运算
output2 = cv2.morphologyEx(img2, cv2.MORPH_TOPHAT, kernel)  # 顶帽运算
cv2.imshow('img1', img1)
cv2.imshow('TOPHAT1', output1)
cv2.imshow('img2', img2)
cv2.imshow('TOPHAT2', output2)
</code></pre> 
<h4><a id="_696"></a>黑帽运算</h4> 
<p>黑帽运算是用闭运算图像减去原始图像的操作，能够获取图像内部的小孔，或者前景色中的小黑点，或者得到比原始图像的边缘更暗的边缘部分。</p> 
<pre><code>img1 = cv2.imread('image/blackhat.bmp')
img2 = cv2.imread('image/lena.png')
kernel = np.ones((5, 5), np.uint8)
output1 = cv2.morphologyEx(img1, cv2.MORPH_BLACKHAT, kernel)  # 黑帽运算
output2 = cv2.morphologyEx(img2, cv2.MORPH_BLACKHAT, kernel)  # 黑帽运算
cv2.imshow('img1', img1)
cv2.imshow('BLACKHAT1', output1)
cv2.imshow('img2', img2)
cv2.imshow('BLACKHAT2', output2)
</code></pre> 
<h4><a id="_712"></a>核函数</h4> 
<p>在进行形态学操作时，必须使用一个特定的核，该核可以自定义生成，也可以通过函数**cv2.getStructuringElement()**生成。该函数的语法格式为：</p> 
<p><strong>cv2.getStructuringElement(shape, ksize)</strong></p> 
<ul><li>shape代表形状类型</li></ul> 
<table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>cv2.MORPH_RECT</td><td>矩形结构元素。所有元素值都是1</td></tr><tr><td>cv2.MORPH_CROSS</td><td>十字形结构元素。对角线元素值为1</td></tr><tr><td>cv2.MORPH_ELLIPSE</td><td>椭圆形结构元素</td></tr></tbody></table> 
<ul><li>ksize代表结构元素的大小</li></ul> 
<pre><code>kernel1 = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
kernel2 = cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5))
kernel3 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
print('kernel1=', kernel1)
print('kernel2=', kernel2)
print('kernel3=', kernel3)
</code></pre> 
<h3><a id="_737"></a>图像梯度</h3> 
<h4><a id="Sobel_739"></a>Sobel算子</h4> 
<p>在OpenCV中，使用函数**cv2.Sobel()**实现Sobel算子运算，该函数的语法格式为：</p> 
<p><strong>cv2.Sobel(img, ddepth, dx, dy, [ksize])</strong></p> 
<ul><li> <p>ddepth代表输出图像的深度，<strong>通常设置为cv2.CV_64F</strong></p> </li><li> <p>dx代表x方向上的求导阶数</p> </li><li> <p>dy代表y方向上的求导阶数</p> </li><li> <p>ksize代表Sobel核的大小，该值为-1时，则会使用Scharr算子进行运算</p> </li></ul> 
<p>在实际操作中，计算梯度值可能会出现负数，如果处理的图像是8位图类型，则在ddepth为-1时，意味着指定运算结果也是8位图类型，那么所有负数会自动截断为0，发生信息丢失。所以，在运算时要先使用更高的数据类型<strong>cv2.CV_64F</strong>，再通过取绝对值将其映射为<strong>cv2.CV_8U</strong>(8位图)类型。所以通常将ddepth设置为cv2.CV_64F。</p> 
<p>在OpenCV中，使用函数**cv2.convertScaleAbs()**对参数取绝对值，该函数的语法格式为：</p> 
<p><strong>cv2.convertScaleAbs(img[, alpha[, beta]])</strong></p> 
<ul><li>alpha代表调节系数，默认为1</li><li>beta代表调节亮度值，默认为0</li></ul> 
<p>参数dx和dy通常的值为0或1，最大值为2。如果是0，表示在该方向上没有求导。dx和dy不能同时为0。</p> 
<ul><li>计算x方向边缘(梯度)：dx=1，dy=0</li><li>计算y方向边缘(梯度)：dx=0，dy=1</li><li>dx和dy的值均为1：dx=1，dy=1</li><li>计算x方向和y方向的边缘叠加：通过组合方式实现</li></ul> 
<pre><code>img = cv2.imread('image/sobel.bmp')
SobelX = cv2.Sobel(img, cv2.CV_64F, 1, 0)  # x方向边缘(梯度)
SobelX = cv2.convertScaleAbs(SobelX)  # x方向边缘(梯度)
SobelY = cv2.Sobel(img, cv2.CV_64F, 0, 1)  # y方向边缘(梯度)
SobelY = cv2.convertScaleAbs(SobelY)  # y方向边缘(梯度)
SobelXY = cv2.Sobel(img, cv2.CV_64F, 1, 1)  # dx和dy的值均为1
SobelXY = cv2.convertScaleAbs(SobelXY)  # dx和dy的值均为1
SobelXYAdd = cv2.addWeighted(SobelX, 0.5, SobelY, 0.5, 0)  # x方向和y方向的边缘叠加
cv2.imshow('original', img)
cv2.imshow('SobelX', SobelX)
cv2.imshow('SobelY', SobelY)
cv2.imshow('SobelXY', SobelXY)
cv2.imshow('SobelXYAdd', SobelXYAdd)
</code></pre> 
<h4><a id="Scharr_784"></a>Scharr算子</h4> 
<p>Scharr算子具有和Sobel算子同样的速度，且精度更高。OpenCV提供了函数**cv2.Scharr()**来计算Scharr算子。其语法格式为：</p> 
<p><strong>cv2.Scharr(img, ddepth, dx, dy)</strong></p> 
<ul><li> <p>ddepth代表输出图像的深度，<strong>应该设置为cv2.CV_64F</strong></p> </li><li> <p>dx代表x方向上的求导阶数</p> </li><li> <p>dy代表y方向上的求导阶数</p> </li></ul> 
<p>**cv2.Scharr(img, ddepth, dx, dy)<strong>和</strong>cv2.Sobel(img, ddepth, dx, dy, -1)**是等价的。</p> 
<p>**cv2.Scharr()**中，要求dx和dy满足：<strong>dx&gt;=0 &amp;&amp; dy&gt;=0 &amp;&amp; dx+dy==1</strong></p> 
<ul><li>计算x方向边缘(梯度)：dx=1，dy=0</li><li>计算y方向边缘(梯度)：dx=0，dy=1</li><li>计算x方向和y方向的边缘叠加：通过组合方式实现</li></ul> 
<pre><code>img = cv2.imread('image/scharr.bmp')
ScharrX = cv2.Scharr(img, cv2.CV_64F, 1, 0)  # x方向边缘(梯度)
ScharrX = cv2.convertScaleAbs(ScharrX)  # x方向边缘(梯度)
ScharrY = cv2.Scharr(img, cv2.CV_64F, 0, 1)  # y方向边缘(梯度)
ScharrY = cv2.convertScaleAbs(ScharrY)  # y方向边缘(梯度)
ScharrXYAdd = cv2.addWeighted(ScharrX, 0.5, ScharrY, 0.5, 0)  # x方向和y方向的边缘叠加
cv2.imshow('original', img)
cv2.imshow('ScharrX', ScharrX)
cv2.imshow('ScharrY', ScharrY)
cv2.imshow('ScharrXYAdd', ScharrXYAdd)
</code></pre> 
<h4><a id="Laplacian_816"></a>Laplacian算子</h4> 
<p>Laplacian算子是一种二阶导数算子，其具有旋转不变性，可以满足不同方向的图像边缘锐化(边缘检测)的要求。通常情况下，其算子的系数之和需要为0。</p> 
<p><strong>cv2.Laplacian(img, ddepth)</strong></p> 
<ul><li>ddepth代表输出图像的深度</li></ul> 
<pre><code>img = cv2.imread('image/laplacian.bmp')
Laplacian = cv2.Laplacian(img, cv2.CV_64F)
Laplacian = cv2.convertScaleAbs(Laplacian)  # Laplacian算子
cv2.imshow('original', img)
cv2.imshow('ScharrX', Laplacian)
</code></pre> 
<h3><a id="_832"></a>图像金字塔</h3> 
<p>图像金字塔是由一幅图像的多个不同分辨率的子图所构成的图像集合。该组图像是由单个图像通过不断地降采样所产生的。图像金字塔的底部是待处理的高分辨率图像(原始图像)，而顶部则是其低分辨率的近似图像。</p> 
<h4><a id="_836"></a>向下采样</h4> 
<p>最简单的图像金字塔可以通过不断地删除图像的偶数行和偶数列得到，也可以先对原始图像滤波，得到原始图像的近似图像，然后将近似图像的偶数行和偶数列删除以获取向下采样的结果，滤波器可以选择邻域滤波器、高斯滤波器。</p> 
<p>OpenCV提供了函数**cv2.pyrDown()**用于实现图像金字塔操作中的向下采样，其语法形式为：</p> 
<p><strong>cv2.pyrDown(img)</strong></p> 
<p>输出图像的大小为Size((img.col+1)/2, (img.row+1)/2)</p> 
<pre><code>img = cv2.imread('image/lena.png', 0)
output = cv2.pyrDown(img)  # 向下采样
cv2.imshow('original', img)
cv2.imshow('pyrDown', output)
print("shape:", output.shape)
</code></pre> 
<h4><a id="_854"></a>向上采样</h4> 
<p>向上采样时，先对像素点以补零的方式完成插值，将图像变为原来的两倍宽、两倍高，再将图像用高斯滤波器进行卷积运算，最后将图像内的每个像素点的值乘以4，以保证得到的像素值的范围依旧在[0,255]内。</p> 
<p>OpenCV提供了函数**cv2.pyrUp()**用于实现图像金字塔操作中的向下采样，其语法形式为：</p> 
<p><strong>cv2.pyrUp(img)</strong></p> 
<p>输出图像的大小为Size(img.col×2, img.row×2)</p> 
<pre><code>img = cv2.imread('image/lena.png', 0)
output = cv2.pyrUp(img)  # 向上采样
cv2.imshow('original', img)
cv2.imshow('pyrUp', output)
print("shape:", output.shape)
</code></pre> 
<h3><a id="_872"></a>图像轮廓</h3> 
<h4><a id="Canny_874"></a>Canny边缘检测</h4> 
<p>Canny边缘检测分为以下几个步骤：</p> 
<ul><li>步骤一：去噪</li><li>步骤二：计算梯度的幅度与方向</li><li>步骤三：非极大值抑制</li><li>步骤四：确定边缘。使用双阈值算法确定最终的边缘信息</li></ul> 
<p>OpenCV提供了函数**cv2.Canny()**来实现Canny边缘检测，其语法形式为：</p> 
<p><strong>cv2.Canny(img, threshold1, threshold2)</strong></p> 
<ul><li>image为8位输入图像</li><li>threshold1表示处理过程中的第一个阈值</li><li>threshold2表示处理过程中的第二个阈值</li></ul> 
<pre><code>img = cv2.imread('image/lena.png', 0)
output = cv2.Canny(img, 128, 200)  # Canny边缘检测
cv2.imshow('original', img)
cv2.imshow('Canny', output)
</code></pre> 
<h4><a id="_898"></a>查找并绘制轮廓</h4> 
<p>在OpenCV中，函数<strong>cv2.findContours()<strong>用于查找图像的轮廓，并能够根据参数返回特定表示方式的轮廓。函数</strong>cv2.drawContours()<strong>能够将查找到的轮廓绘制到图像上，该函数可以根据参数在图像上绘制不同式样的轮廓。在OpenCV中，都是</strong>从黑色背景中查找白色对象</strong>。</p> 
<p>**cv2.findContours()**的语法格式为：</p> 
<p><strong>contours, hierarchy = cv2.findContours(img, mode, method)</strong></p> 
<p>返回值：</p> 
<ul><li>contours：返回的轮廓 
  <ul><li>contours[i]是第i个轮廓，contours[i] [j]是第i个轮廓内的第j个点</li><li>轮廓的个数：len(contours)</li><li>每个轮廓的点数：len(contours[i])</li></ul> </li><li>hierarchy：图像的拓扑信息。其形式是：[Next, Previous, First_Child, Parent] 
  <ul><li>Next：后一个轮廓的索引号</li><li>Previous：前一个轮廓的索引号</li><li>First_Child：第一个子轮廓的索引号</li><li>Parent：父轮廓的索引号</li><li>如果上述各个参数所对应的关系为空时，则该参数为-1</li></ul> </li></ul> 
<p>参数：</p> 
<ul><li>image：原始图像，8位单通道二值图像</li><li>mode：轮廓检索模式 
  <ul><li><strong>cv2.RETR_EXTERNAL</strong>：只检测外轮廓</li><li><strong>cv2.RETR_LIST</strong>：对检测到的轮廓不建立等级关系</li><li><strong>cv2.RETR_CCOMP</strong>：检索所有轮廓并将它们组织成两级层次结构。上面的一层为外边界，下面的一层为内孔的边界。</li><li><strong>cv2.RETR_TREE</strong>：建立一个等级树结构的轮廓</li></ul> </li><li>method：轮廓的近似方法 
  <ul><li><strong>cv2.CHAIN_APPROX_NONE</strong>：存储所有的轮廓点，相邻两个点的像素位置差不超过1</li><li><strong>cv2.CHAIN_APPROX_SIMPLE</strong>：压缩水平方向、垂直方向、对角线方向的元素，只保留该方向的终点坐标</li></ul> </li></ul> 
<p>在OpenCV中，可以使用函数**cv2.drawContours()**绘制图像轮廓。该函数的语法格式为：</p> 
<p><strong>image = cv2.drawContours(image, contours, contourIdx, color[, thickness])</strong></p> 
<ul><li> <p>image：待绘制轮廓的图像。函数会在图像image上直接绘制轮廓，参数image和返回值image在函数运算后的值是相同的，所以，如果图像image还有其他用途的话，则需要预先复制一份。</p> </li><li> <p>contours：需要绘制的轮廓</p> </li><li> <p>contourIdx：需要绘制的边缘索引，告诉函数要绘制某一条轮廓函数全部轮廓。如果该参数是一个正数或者零，则表示绘制对应索引号的轮廓；如果该值是负数，则表示绘制全部轮廓。</p> </li><li> <p>color：绘制的颜色，用BGR格式表示</p> </li><li> <p>thickness：可选参数，表示绘制轮廓时所用画笔的粗细。如果将该值设置为-1，则表示绘制实心轮廓。</p> </li></ul> 
<pre><code>img = cv2.imread('image/contours.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
image = cv2.drawContours(imgCopy, contours, -1, (0, 0, 255), 5)  # 绘制轮廓
cv2.imshow('original', img)
cv2.imshow('drawContours', image)
</code></pre> 
<h4><a id="_954"></a>矩特征</h4> 
<p>OpenCV提供了函数**cv2.moments()**来获取图像的轮廓矩，其语法形式为：</p> 
<p><strong>cv2.moments(array)</strong></p> 
<ul><li>array：可以是点集，也可以是灰度图像或者二值图像。当array是点集时，函数会把点集作为一条轮廓</li></ul> 
<p>该函数的返回值是矩特征，主要包括：</p> 
<ol><li>空间矩：</li></ol> 
<ul><li>零阶矩：m00 <strong>表示一个轮廓的面积</strong></li><li>一阶矩：m10，m01</li><li>二阶矩：m20，m11，m02</li><li>三阶矩：m30，m21，m12，m03</li></ul> 
<ol start="2"><li>中心矩：<strong>具有平移不变性</strong></li></ol> 
<ul><li>二阶中心矩：mu20，mu11，mu02</li><li>三阶中心矩：mu30，mu21，mu12，mu03</li></ul> 
<ol start="3"><li>归一化中心矩：<strong>具有平移不变性和缩放不变性</strong></li></ol> 
<ul><li>二阶Hu矩：nu20，nu11，nu02</li><li>三阶Hu矩：nu30，nu21，nu12，nu03</li></ul> 
<pre><code>img = cv2.imread('image/moments.bmp')
cv2.imshow('original', img)
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
n = len(contours)  # 轮廓的个数
contoursImg = []
for i in range(n):
    temp = np.zeros(img.shape, np.uint8)
    contoursImg.append(temp)
    contoursImg[i] = cv2.drawContours(contoursImg[i], contours, i, (255, 0, 0), 3)
    cv2.imshow("contours[" + str(i) + "]", contoursImg[i])  # 显示轮廓
    print("轮廓" + str(i) + "的矩：\n", cv2.moments(contours[i]))  # 轮廓的矩
    print("轮廓" + str(i) + "的面积：%d" % cv2.moments(contours[i])['m00'])  # 轮廓的面积
</code></pre> 
<p>函数**cv2.contourArea()**用于计算轮廓的面积，该函数的语法格式为：</p> 
<p><strong>cv2.contourArea(contour)</strong></p> 
<ul><li>contour是轮廓</li></ul> 
<pre><code>img = cv2.imread('image/moments.bmp')
cv2.imshow('original', img)
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
n = len(contours)  # 轮廓的个数
contoursImg = []
for i in range(n):
    temp = np.zeros(img.shape, np.uint8)
    contoursImg.append(temp)
    contoursImg[i] = cv2.drawContours(contoursImg[i], contours, i, (255, 0, 0), 3)
    cv2.imshow("contours[" + str(i) + "]", contoursImg[i])  # 显示轮廓
    print("轮廓" + str(i) + "的面积：%d" % cv2.contourArea(contours[i]))  # 轮廓的面积
</code></pre> 
<p>函数**cv2.arcLength()**用于计算轮廓的面积，该函数的语法格式为：</p> 
<p><strong>cv2.arcLength(curve, closed)</strong></p> 
<ul><li>curve是轮廓</li><li>closed是布尔值，用来表示轮廓是否是封闭的</li></ul> 
<pre><code>img = cv2.imread('image/moments.bmp')
cv2.imshow('original', img)
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
n = len(contours)  # 轮廓的个数
contoursImg = []
for i in range(n):
    temp = np.zeros(img.shape, np.uint8)
    contoursImg.append(temp)
    contoursImg[i] = cv2.drawContours(contoursImg[i], contours, i, (255, 0, 0), 3)
    cv2.imshow("contours[" + str(i) + "]", contoursImg[i])  # 显示轮廓
    print("轮廓" + str(i) + "的长度：%d" % cv2.arcLength(contours[i], True))  # 轮廓的长度
</code></pre> 
<h4><a id="Hu_1046"></a>Hu矩</h4> 
<p>Hu矩是归一化中心矩的线性组合。Hu矩在图像旋转、缩放、平移等操作后，仍能保持矩的不变性，所以经常会使用Hu矩来识别图像的特征。</p> 
<p>在OpenCV中，使用函数**cv2.HuMoments()**可以得到Hu矩，该函数的语法格式为：</p> 
<p><strong>cv2.HuMoments(m)</strong></p> 
<ul><li>m是由函数**cv2.moments()**计算得到的矩特征值</li></ul> 
<pre><code>img = cv2.imread('image/cs.bmp', 0)
HuM1 = cv2.HuMoments(cv2.moments(img)).flatten()  # 将数组变为一维
print("HuM1:", HuM1)
</code></pre> 
<p>利用Hu矩判断两个对象的一致性结果比较抽象。为了更直观方便地比较Hu矩值，OpenCV提供了函数**cv2.matchShapes()**对两个对象的Hu矩进行比较，该函数的语法格式为：</p> 
<p><strong>cv2.matchShapes(contour1, contour2, method, parameter)</strong></p> 
<ul><li> <p>contour1：第一个轮廓或灰度图像</p> </li><li> <p>contour2：第二个轮廓或灰度图像</p> </li><li> <p>method：比较两个对象的Hu矩的方法</p> </li><li> <p>parameter：应用于method的特定参数。设置为0。</p> </li></ul> 
<pre><code>img1 = cv2.imread('image/cs1.bmp', 0)
img2 = cv2.imread('image/cs2.bmp', 0)
img3 = cv2.imread('image/cc.bmp', 0)
ret0 = cv2.matchShapes(img1, img1, 1, 0)  # 相同图像
ret1 = cv2.matchShapes(img1, img2, 1, 0)  # 相似图像
ret2 = cv2.matchShapes(img1, img3, 1, 0)  # 不相似图像
print("相同图像的matchShapes=", ret0)
print("相似图像的matchShapes=", ret1)
print("不相似图像的matchShapes=", ret2)
</code></pre> 
<p>相同图像的matchShapes= 0.0<br> 相似图像的matchShapes= 0.0001154058519395873<br> 不相似图像的matchShapes= 0.012935752303635195</p> 
<p>同一幅图的Hu矩是不变的，二者差值为0；相似的图像返回值的差较小；不相似图像返回值的差较大。</p> 
<h4><a id="_1091"></a>轮廓拟合</h4> 
<p>在计算轮廓时，可能并不需要实际的轮廓，而仅需要一个接近于轮廓的近似多边形。OpenCV提供了多种计算轮廓近似多边形的方法。</p> 
<ol><li><strong>矩形包围框</strong></li></ol> 
<p>函数**cv2.boundingRect()**能够绘制轮廓的矩形边界，该函数的语法格式为：</p> 
<p><strong>retval = cv2.boundingRect(points)</strong></p> 
<ul><li>retval表示返回的矩形边界的左上角顶点的坐标值及矩形边界的宽度和高度</li><li>points是灰度图像或轮廓</li></ul> 
<p>该函数还可以是具有4个返回值的形式：<strong>x, y, w, h = cv2.boundingRect(points)</strong></p> 
<ul><li>x：矩形边界左上角顶点的x坐标</li><li>y：矩形边界左上角顶点的y坐标</li><li>w：矩形边界x方向的长度</li><li>h：矩形边界y方向的长度</li></ul> 
<pre><code>img = cv2.imread('image/cc.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
x, y, w, h = cv2.boundingRect(contours[0])  # 矩形包围框
cv2.rectangle(imgCopy, (x, y), (x + w, y + h), (255, 255, 255), 2)  # 绘制矩形框
cv2.imshow('original', img)
cv2.imshow('boundingRect', imgCopy)
</code></pre> 
<ol start="2"><li><strong>最小包围矩形框</strong></li></ol> 
<p>函数**cv2.minAreaRect()**能够绘制轮廓的最小包围矩形框，该函数的语法格式为：</p> 
<p><strong>retval = cv2.minAreaRect(points)</strong></p> 
<ul><li>retval表示返回的矩形特征信息。该值的结构是(最小外接矩形的中心(x, y), (宽度, 高度), 旋转角度)</li><li>points是轮廓</li></ul> 
<p>返回值retval的结构不符合函数cv2.drawContours()的参数结构，所以需要用函数**cv2.boxPoints()**将retval转换成符合要求的结构，该函数的语法格式为：</p> 
<p><strong>points = cv2.boxPoints(box)</strong></p> 
<ul><li>points是能够用于函数cv2.drawContours()的轮廓点</li><li>box是函数cv2.minAreaRect()的返回值</li></ul> 
<pre><code>img = cv2.imread('image/cc.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
rect = cv2.minAreaRect(contours[0])  # 最小包围矩形框
points = cv2.boxPoints(rect)  # 转换格式
points = np.int0(points)  # 取整
cv2.drawContours(imgCopy, [points], 0, (255, 255, 255), 2)
cv2.imshow('original', img)
cv2.imshow('minAreaRect', imgCopy)
</code></pre> 
<ol start="3"><li><strong>最小包围圆形</strong></li></ol> 
<p>函数**cv2.minEnclosingCircle()**通过迭代算法构造一个对象的面积最小包围圆形，该函数的语法格式为：</p> 
<p>**center, radius = cv2.minEnclosingCircle(points) **</p> 
<ul><li>center是最小包围圆形的圆心</li><li>radius是最小包围圆形的半径</li><li>points是轮廓</li></ul> 
<pre><code>img = cv2.imread('image/cc.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
(x, y), radius = cv2.minEnclosingCircle(contours[0])  # 最小包围圆形
center = (int(x), int(y))  # 取整
radius = int(radius)  # 取整
cv2.circle(imgCopy, center, radius, (255, 255, 255), 2)
cv2.imshow('original', img)
cv2.imshow('minEnclosingCircle', imgCopy)
</code></pre> 
<ol start="4"><li><strong>最优拟合椭圆</strong></li></ol> 
<p>函数**cv2.fitEllipse()**可以用来构造最优拟合椭圆，该函数的语法格式为：</p> 
<p><strong>retval = cv2.fitEllipse(points)</strong></p> 
<ul><li>retval是RotatedRect类型的值</li><li>points是轮廓</li></ul> 
<pre><code>img = cv2.imread('image/cc.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
ellipse = cv2.fitEllipse(contours[0])  # 最优拟合椭圆
cv2.ellipse(imgCopy, ellipse, (255, 0, 0), 2)
cv2.imshow('original', img)
cv2.imshow('fitEllipse', imgCopy)
</code></pre> 
<ol start="5"><li><strong>最优拟合直线</strong></li></ol> 
<p>函数**cv2.fitLine()**可以用来构造最优拟合直线，该函数的语法格式为：</p> 
<p><strong>line = cv2.fitLine(points, distType, param, reps, aeps)</strong></p> 
<ul><li> <p>line：对于二维直线，输出为4维，前两维代表拟合出的直线的方向，后两位代表直线上的一点。（即点斜式）</p> </li><li> <p>points：轮廓</p> </li><li> <p>distType：距离类型。拟合直线时，要使输入点到拟合直线的距离之和最小，其类型如下表所示</p> </li><li> <p>param：距离参数，与所选的距离类型有关。当此参数设置为0时，会自动选择最优值</p> </li><li> <p>reps：拟合直线所需要的径向精度，通常设置为0.01</p> </li><li> <p>aeps：拟合直线所需要的角度精度，通常设置为0.01</p> </li></ul> 
<table><thead><tr><th>值</th><th>含义</th></tr></thead><tbody><tr><td>cv2.DIST_USER</td><td>用户定义距离</td></tr><tr><td>cv2.DIST_L1</td><td>distance = |x1-x2|+|y1-y2|</td></tr><tr><td>cv2.DIST_L2</td><td>欧式距离，此时与最小二乘法相同</td></tr><tr><td>cv2.DIST_C</td><td>distance =max(|x1-x2|, |y1-y2|)</td></tr><tr><td>cv2.DIST_L12</td><td>distance = 2(sqrt(1+x*x/2) - 1))</td></tr><tr><td>cv2.DIST_FAIR</td><td>distance = c<sup>2</sup>(|x|/c-log(1+|x|/c)), c = 1.3998</td></tr><tr><td>cv2.DIST_WELSCH</td><td>distance =c<sup>2</sup>/2(1-exp(-(x/c)2)), c = 2.9846</td></tr><tr><td>cv2.DIST_HUBER</td><td>distance =|x|&lt;c ? x<sup>2</sup>/2 : c(|x|-c/2), c=1.345</td></tr></tbody></table> 
<pre><code>img = cv2.imread('image/cc.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
row, col = img.shape[:2]
[vx, vy, x, y] = cv2.fitLine(contours[0], cv2.DIST_L2, 0, 0.01, 0.01)  # 最优拟合直线
left_y = int((-x * vy / vx) + y)
right_y = int(((col - x) * vy / vx) + y)
cv2.line(imgCopy, (col - 1, right_y), (0, left_y), (255, 0, 0), 2)
cv2.imshow('original', img)
cv2.imshow('fitLine', imgCopy)
</code></pre> 
<ol start="6"><li><strong>最小外包三角形</strong></li></ol> 
<p>函数**cv2.minEnclosingTriangle()**可以用来构造最小外包三角形，该函数的语法格式为：</p> 
<p><strong>retval, triangle = cv2.minEnclosingTriangle(points)</strong></p> 
<ul><li>retval：最小外包三角形的面积</li><li>triangle ：最小外包三角形的三个顶点集</li><li>points：轮廓</li></ul> 
<pre><code>img = cv2.imread('image/cc.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
area, triangle = cv2.minEnclosingTriangle(contours[0])  # 最小外包三角形
for i in range(3):
    cv2.line(imgCopy, tuple(triangle[i][0]), tuple(triangle[(i + 1) % 3][0]), (255, 0, 0), 2)
cv2.imshow('original', img)
cv2.imshow('minEnclosingTriangle', imgCopy)
</code></pre> 
<ol start="7"><li><strong>逼近多边形</strong></li></ol> 
<p>函数**cv2.approxPolyDP()**可以用来构造指定精度的逼近多边形曲线，该函数的语法格式为：</p> 
<p><strong>approxCurve = cv2.approxPolyDP(curve, epsilon, closed)</strong></p> 
<ul><li>approxCurve是逼近多边形的点集</li><li>curve是轮廓</li><li>epsilon是精度，原始轮廓的边界点与逼近多边形边界之间的最大距离。通常设置为多边形总长度的百分比形式</li><li>closed是布尔值，表示多边形是否封闭。</li></ul> 
<pre><code>img = cv2.imread('image/cc.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
epsilon = 0.01 * cv2.arcLength(contours[0], True)  # 设置精度
approxCurve = cv2.approxPolyDP(contours[0], epsilon, True)  # 逼近多边形曲线
cv2.drawContours(imgCopy, [approxCurve], 0, (255, 0, 0), 2)
cv2.imshow('original', img)
cv2.imshow('minEnclosingTriangle', imgCopy)
</code></pre> 
<h4><a id="_1287"></a>凸包</h4> 
<ol><li><strong>凸包</strong></li></ol> 
<p>凸包指的是完全包含原有轮廓，并且仅由轮廓上的点所构成的多边形。凸包的每一处都是凸的，即在凸包内连接任意两点的直线都在凸包的内部。</p> 
<p>函数**cv2.convexHull()**可以用来获取轮廓的凸包，该函数的语法格式为：</p> 
<p><strong>hull = cv2.convexHull(points[, clockwise[, returnPoints]])</strong></p> 
<ul><li> <p>points：轮廓</p> </li><li> <p>clockwise：布尔值。该值为True时，凸包角点将按顺时针方向排列；该值为False时，凸包角点将按逆时针方向排列。</p> </li><li> <p>returnPoints：布尔值。默认为True，函数返回凸包角点的x、y轴坐标；当为False时，函数返回轮廓中凸包角点的索引。</p> </li></ul> 
<ol start="2"><li><strong>凸缺陷</strong></li></ol> 
<p>凸包与轮廓之间的部分称为凸缺陷。函数**cv2.convexityDefects()**可以用来获取凸缺陷，该函数的语法格式为：</p> 
<p><strong>convexityDefects = cv2.convexityDefects(contour, convexhull)</strong></p> 
<ul><li> <p>convexityDefects为凸缺陷点集。它是一个数组，每一行包含的值是[起点，终点，轮廓上距离凸包最远的点，最远点到凸包的近似距离]，前三个值是轮廓点的索引，需要到轮廓点中去找它们</p> </li><li> <p>contour是轮廓</p> </li><li> <p>convexhull是凸包</p> </li></ul> 
<p>需要注意的是，用cv2.convexityDefects()计算凸缺陷时，要使用凸包作为参数。在查找凸包时，所使用函数cv2.convexHull()的参数returnPoints的值必须是False。</p> 
<pre><code>img = cv2.imread('image/hand.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
cnt = contours[0]
hull = cv2.convexHull(cnt, returnPoints=False)  # 凸包
defects = cv2.convexityDefects(cnt, hull)  # 凸缺陷
for i in range(defects.shape[0]):
    s, e, f, d = defects[i, 0]
    start = tuple(cnt[s][0])
    end = tuple(cnt[e][0])
    far = tuple(cnt[f][0])
    cv2.line(imgCopy, start, end, (255, 0, 0), 2)
    cv2.circle(imgCopy, far, 5, (255, 0, 0), -1)
cv2.imshow('original', img)
cv2.imshow('convexityDefects', imgCopy)
</code></pre> 
<ol start="3"><li><strong>几何学测试</strong></li></ol> 
<p><strong>判断轮廓是否是凸形的</strong></p> 
<p>函数**cv2.isContourConvex()**可以用来判断轮廓是否是凸形的，该函数的语法格式为：</p> 
<p><strong>retval = cv2.isContourConvex(contour)</strong></p> 
<ul><li>retval是布尔值，该值为True时表示轮廓是凸形的，为False时，不是凸形的</li><li>contour为要判断的轮廓</li></ul> 
<pre><code>img = cv2.imread('image/hand.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
hull = cv2.convexHull(contours[0])  # 凸包
cv2.polylines(imgCopy, [hull], True, (255, 0, 0), 2)
result = cv2.isContourConvex(hull)  # 判断轮廓是否是凸形的
print(result)
cv2.imshow('original', img)
cv2.imshow('isContourConvex', imgCopy)
</code></pre> 
<p><strong>点到轮廓的距离</strong></p> 
<p>函数**cv2.pointPolygonTest()**可以用来计算点到多边形(轮廓)的最短距离，该函数的语法格式为：</p> 
<p><strong>retval = cv2.pointPolygonTest(contour, pt, measureDist)</strong></p> 
<ul><li>contour为轮廓</li><li>pt为待判定的点</li><li>measureDist为布尔值，表示距离的判定方式。 
  <ul><li>值为True时，表示计算点到轮廓的距离。如果点在轮廓的外部，返回值为负数；如果点在轮廓上，返回值为0；如果点在轮廓内部，返回值为正数。</li><li>值为False时，不计算距离，只返回"-1"，“0”，“1"中的一个值，表示点相对于轮廓的位置关系。如果点在轮廓的外部，返回值为”-1"；如果点在轮廓上，返回值为"0"；如果点在轮廓内部，返回值为"1"。</li></ul> </li></ul> 
<pre><code>img = cv2.imread('image/cs1.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
hull = cv2.convexHull(contours[0])  # 凸包
cv2.polylines(imgCopy, [hull], True, (255, 0, 0), 2)
distA = cv2.pointPolygonTest(hull, (300, 150), True)  # 点到轮廓的距离
distB = cv2.pointPolygonTest(hull, (300, 250), True)  # 点到轮廓的距离
distC = cv2.pointPolygonTest(hull, (423, 112), True)  # 点到轮廓的距离
cv2.putText(imgCopy, "A", (300, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)
cv2.putText(imgCopy, "B", (300, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)
cv2.putText(imgCopy, "C", (423, 112), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)
print("distA:", distA)
print("distB:", distB)
print("distC:", distC)
cv2.imshow('original', img)
cv2.imshow('pointPolygonTest', imgCopy)
</code></pre> 
<h4><a id="_1393"></a>利用形状场景算法比较轮廓</h4> 
<ol><li><strong>计算形状场景距离</strong></li></ol> 
<p>函数**cv2.createShapeContextDistanceExtractor()**可以用来计算形状场景距离，该函数的语法格式为：</p> 
<p><strong>retval = cv2.createShapeContextDistanceExtractor()</strong></p> 
<ul><li>retval返回结果</li></ul> 
<p>该结果可以通过函数<strong>cv2.ShapeDistanceExtractor.computeDistance(contour1, contour2)</strong></p> 
<ul><li>contour1和contour2是两个不同的轮廓</li></ul> 
<pre><code>img1 = cv2.imread('image/cs1.bmp', 0)
img2 = cv2.imread('image/cs2.bmp', 0)
img3 = cv2.imread('image/hand.bmp', 0)
ret, binary1 = cv2.threshold(img1, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
ret, binary2 = cv2.threshold(img2, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
ret, binary3 = cv2.threshold(img3, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours1, hierarchy = cv2.findContours(binary1, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
contours2, hierarchy = cv2.findContours(binary2, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
contours3, hierarchy = cv2.findContours(binary3, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
cnt1 = contours1[0]
cnt2 = contours2[0]
cnt3 = contours3[0]
result = cv2.createShapeContextDistanceExtractor()  # 计算形状场景距离
d1 = result.computeDistance(cnt1, cnt1)
d2 = result.computeDistance(cnt1, cnt2)
d3 = result.computeDistance(cnt1, cnt3)
print("相同图像的距离=", d1)
print("相似图像的距离=", d2)
print("不相似图像的距离=", d3)
</code></pre> 
<ol start="2"><li><strong>计算Hausdorff距离</strong></li></ol> 
<p>函数**cv2.createHausdorffDistanceExtractor()**可以用来计算形状场景距离，该函数的语法格式为：</p> 
<p><strong>retval = cv2.createHausdorffDistanceExtractor()</strong></p> 
<pre><code>img1 = cv2.imread('image/cs1.bmp', 0)
img2 = cv2.imread('image/cs3.bmp', 0)
img3 = cv2.imread('image/hand.bmp', 0)
ret, binary1 = cv2.threshold(img1, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
ret, binary2 = cv2.threshold(img2, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
ret, binary3 = cv2.threshold(img3, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours1, hierarchy = cv2.findContours(binary1, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
contours2, hierarchy = cv2.findContours(binary2, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
contours3, hierarchy = cv2.findContours(binary3, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
cnt1 = contours1[0]
cnt2 = contours2[0]
cnt3 = contours3[0]
result = cv2.createHausdorffDistanceExtractor()  # 计算Hausdorff距离
d1 = result.computeDistance(cnt1, cnt1)
d2 = result.computeDistance(cnt1, cnt2)
d3 = result.computeDistance(cnt1, cnt3)
print("相同图像的距离=", d1)
print("相似图像的距离=", d2)
print("不相似图像的距离=", d3)
</code></pre> 
<h4><a id="_1457"></a>轮廓的特征值</h4> 
<ol><li><strong>宽高比</strong></li></ol> 
<p>宽高比 = 宽度(width) / 高度(height)</p> 
<pre><code>img = cv2.imread('image/cc.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
x, y, w, h = cv2.boundingRect(contours[0])
aspectRatio = float(w) / h  # 宽高比
print("宽高比=", aspectRatio)
</code></pre> 
<ol start="2"><li><strong>Extend</strong></li></ol> 
<p>可以使用轮廓面积与矩形边界面积之比Extend来描述图像及其轮廓特征。</p> 
<p>Extend= 轮廓面积(对象面积) / 矩形边界面积</p> 
<pre><code>img = cv2.imread('image/cc.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
x, y, w, h = cv2.boundingRect(contours[0])
rectArea = w * h
cntArea = cv2.contourArea(contours[0])
Extend = float(cntArea) / rectArea  # Extend
print("Extend=", Extend)
</code></pre> 
<ol start="3"><li><strong>Solidity</strong></li></ol> 
<p>可以使用轮廓面积与凸包面积之比Solidity来衡量图像、轮廓及凸包的特征。</p> 
<p>Solidity= 轮廓面积(对象面积) / 凸包面积</p> 
<pre><code>img = cv2.imread('image/hand.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
cntArea = cv2.contourArea(contours[0])
hull = cv2.convexHull(contours[0])
hullArea = cv2.contourArea(hull)
Solidity = float(cntArea) / hullArea  # Solidity
print("Solidity=", Solidity)
</code></pre> 
<ol start="4"><li><strong>等效直径</strong></li></ol> 
<p>该值是与轮廓面积相等的圆形的直径。</p> 
<p>等效直径 = sqrt(4 × 轮廓面积 / π)</p> 
<pre><code>img = cv2.imread('image/cc.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
cntArea = cv2.contourArea(contours[0])
equivalentDiameter = np.sqrt(4 * cntArea / np.pi)  # 等效直径
print("等效直径=", equivalentDiameter)
</code></pre> 
<ol start="5"><li><strong>轮廓像素点</strong></li></ol> 
<p><strong>使用Numpy函数获取轮廓像素点：</strong></p> 
<p>**numpy.nonzero()<strong>函数能够找出数组内非零元素的位置，但是其返回值是将行、列分别显示的。使用</strong>numpy.transpose()**函数处理上述返回值则可以得到这些点的(x,y)形式的坐标。</p> 
<p><strong>使用OpenCV函数获取轮廓像素点：</strong></p> 
<p>**cv2.findNonZero()**函数可以用于查找非零元素的索引。该函数的语法格式为：</p> 
<p><strong>idx = cv2.findNonZero(src)</strong></p> 
<ul><li>idx表示非零元素的索引位置，在返回的索引中，每个元素对应的是(列号，行号)的格式</li><li>src表示要查找非零元素的图像</li></ul> 
<ol start="6"><li><strong>最大值和最小值及它们的位置</strong></li></ol> 
<pre><code>img = cv2.imread('image/boat.jpg')
cv2.imshow("original", img)
plt.hist(img.ravel(), 256)  # 使用Numpy绘制直方图
plt.show()
</code></pre> 
<ul><li>min_val：最小值</li><li>max_val：最大值</li><li>min_loc：最小值的位置</li><li>max_loc：最大值的位置</li><li>img：单通道图像</li></ul> 
<pre><code>img = cv2.imread('image/ct.png')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
cnt = contours[2]
mask = np.zeros(gray.shape, np.uint8)
mask = cv2.drawContours(mask, [cnt], -1, (255, 0, 0), -1)
min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(gray, mask)  # 最大值和最小值及它们的位置
print("min_val:", min_val)
print("max_val:", max_val)
print("min_loc:", min_loc)
print("max_loc:", max_loc)
maskImg = np.zeros(img.shape, np.uint8)
maskImg = cv2.drawContours(maskImg, [cnt], -1, (255, 255, 255), -1)
loc = cv2.bitwise_and(img, maskImg)
cv2.imshow("original", img)
cv2.imshow("mask", loc)
</code></pre> 
<ol start="7"><li><strong>平均颜色及平均灰度</strong></li></ol> 
<p>函数**cv2.mean()**可以用来计算一个对象的平均颜色或平均灰度，该函数的语法格式为：</p> 
<p><strong>mean_val = cv2.mean(img)</strong></p> 
<ul><li>mean_val：返回的平均值。返回值有4个值，分别是RGB和alpha通道的均值。</li></ul> 
<pre><code>img = cv2.imread('image/ct.png')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
cnt = contours[2]
mask = np.zeros(gray.shape, np.uint8)
mask = cv2.drawContours(mask, [cnt], -1, (255, 0, 0), -1)
meanVal = cv2.mean(img, mask)  # 平均颜色及平均灰度
print("meanVal:", meanVal)
</code></pre> 
<ol start="8"><li><strong>极点</strong></li></ol> 
<pre><code>img = cv2.imread('image/cs1.bmp')
imgCopy = img.copy()  # 复制图像
gray = cv2.cvtColor(imgCopy, cv2.COLOR_BGR2GRAY)  # 转换为灰度图
ret, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)  # 将图像二值化
contours, hierarchy = cv2.findContours(binary, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 查找轮廓
mask = np.zeros(gray.shape, np.uint8)
cnt = contours[0]
cv2.drawContours(mask, [cnt], 0, 255, -1)
leftmost = tuple(cnt[cnt[:, :, 0].argmin()][0])  # 最左端
rightmost = tuple(cnt[cnt[:, :, 0].argmax()][0])  # 最右端
topmost = tuple(cnt[cnt[:, :, 1].argmin()][0])  # 最上端
bottommost = tuple(cnt[cnt[:, :, 1].argmax()][0])  # 最下端
print("leftmost=", leftmost)
print("rightmost=", rightmost)
print("topmost=", topmost)
print("bottommost=", bottommost)
cv2.putText(imgCopy, 'A', leftmost, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
cv2.putText(imgCopy, 'B', rightmost, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
cv2.putText(imgCopy, 'C', topmost, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
cv2.putText(imgCopy, 'D', bottommost, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
cv2.imshow("result", imgCopy)
</code></pre> 
<h3><a id="_1627"></a>直方图处理</h3> 
<h4><a id="_1629"></a>绘制直方图</h4> 
<ol><li><strong>使用Numpy绘制直方图</strong></li></ol> 
<p>可以使用**matplotlib.pyplot.hist()**函数绘制直方图。此函数的作用是根据数据源和灰度级分组绘制直方图。其基本语法格式为：</p> 
<p><strong>matplotlib.pyplot.hist(x, bins)</strong></p> 
<ul><li>x：数据源，必须是一维的。图像通常是二维的，需要使用**ravel()**函数将图像处理为一维数据源以后再作为参数使用</li><li>bins：表示灰度级的分组情况</li></ul> 
<pre><code>img = cv2.imread('image/boat.jpg')
cv2.imshow("original", img)
plt.hist(img.ravel(), 256)  # 使用Numpy绘制直方图
plt.show()
</code></pre> 
<ol start="2"><li><strong>使用OpenCV绘制直方图</strong></li></ol> 
<p>函数**cv2.calcHist()**可以用来计算图像的统计直方图，该函数能统计各个灰度级的像素点个数。该函数的语法格式为：</p> 
<p><strong>hist = cv2.calcHist(img, channels, mask, histSize, ranges)</strong></p> 
<ul><li>hist：返回的统计直方图，是一个一维数组</li><li>img：原始图像，该图像需要用"[]"括起来</li><li>channels：指定通道编号，通道编号需要用"[]"括起来，如果是单通道图像，该参数的值就是[0]。</li><li>mask：掩模图像。当统计整幅图像的直方图时，该值为None</li><li>histSize：BINS的值，该值需要用"[]"括起来</li><li>ranges：像素值范围</li></ul> 
<pre><code>img = cv2.imread('image/girl.bmp')
cv2.imshow("original", img)
histB = cv2.calcHist([img], [0], None, [256], [0, 255])  # 得到直方图数据
histG = cv2.calcHist([img], [1], None, [256], [0, 255])  # 得到直方图数据
histR = cv2.calcHist([img], [2], None, [256], [0, 255])  # 得到直方图数据
plt.plot(histB, color='b', label='B')
plt.plot(histG, color='g', label='G')
plt.plot(histR, color='r', label='R')
plt.show()
</code></pre> 
<h4><a id="_1672"></a>直方图均衡化</h4> 
<p>直方图均衡化的算法主要包括两个步骤：</p> 
<ol><li>计算累计直方图</li><li>对累计直方图进行区间转换</li></ol> 
<p>在累计直方图的基础上，对原有灰度级空间进行转换可以在原有范围内对灰度级实现均衡化，也可以在更广泛的灰度空间范围内对灰度级实现均衡化。</p> 
<ol><li><strong>在原有范围内实现均衡化</strong></li></ol> 
<p>在原有范围内实现直方图均衡化时，用当前灰度级的累计概率乘以当前灰度级的最大值，得到新的灰度级，并作为均衡化结果。</p> 
<ol start="2"><li><strong>在更广泛的范围内实现均衡化</strong></li></ol> 
<p>在更广泛的范围内实现直方图均衡化时，用当前灰度级的累计概率乘以更广泛的范围灰度级的最大值，得到新的灰度级，并作为均衡化结果。</p> 
<p>函数**cv2.equalizeHist()**可以用来实现直方图均衡化。该函数的语法格式为：</p> 
<p><strong>output = cv2.equalizeHist(img)</strong></p> 
<ul><li>img是8位单通道原始图像</li></ul> 
<pre><code>img = cv2.imread('image/equ.bmp', 0)
output = cv2.equalizeHist(img)  # 直方图均衡化
cv2.imshow("original", img)
cv2.imshow("equalizeHist", output)
plt.figure("原始图像直方图")
plt.hist(img.ravel(), 256)
plt.figure("均衡化图像直方图")
plt.hist(output.ravel(), 256)
plt.show()
</code></pre> 
<h3><a id="_1707"></a>傅里叶变换</h3> 
<h4><a id="Numpy_1709"></a>用Numpy实现傅里叶变换</h4> 
<ol><li><strong>实现傅里叶变换</strong></li></ol> 
<p>Numpy提供函数**numpy.fft.fft2()**可以用来实现傅里叶变换。该函数的语法格式为：</p> 
<p><strong>fft= numpy.fft.fft2(img)</strong></p> 
<ul><li>img是灰度图像</li><li>fft是一个复数数组</li></ul> 
<p>图像频谱中的零频率分量位于频谱图像的左上角，为了便于观察通常会使用**numpy.fft.fftshift()**函数将零频率成分移动到频率图像的中心位置。该函数的语法格式为：</p> 
<p><strong>fftShift = numpy.fft.fftshift(fft)</strong></p> 
<p>对图像进行傅里叶变换后，得到的是一个复数数组，为了显示为图像，需要将它们的值调整到[0, 255]的灰度空间内，使用公式为：</p> 
<p><strong>output = 20×numpy.log(numpy.abs(fftShift))</strong></p> 
<pre><code>img = cv2.imread('image/lena.png', 0)
fft = np.fft.fft2(img)  # 傅里叶变换
fftShift = np.fft.fftshift(fft)
output = 20 * np.log(np.abs(fftShift))
plt.subplot(121)
plt.imshow(img, cmap='gray')
plt.title('original'), plt.axis('off')
plt.subplot(122)
plt.imshow(output, cmap='gray')
plt.title('result'), plt.axis('off')
plt.show()
</code></pre> 
<ol start="2"><li><strong>实现傅里叶逆变换</strong></li></ol> 
<p>如果在傅里叶变换过程中使用了**numpy.fft.fftshift()<strong>函数移动零频率分量，那么在傅里叶逆变换过程中需要先使用</strong>numpy.fft.ifftshift()**函数将零频率分量移到原来的位置，再进行傅里叶逆变换。该函数的语法格式为：</p> 
<p><strong>ifftShift = numpy.fft.ifftshift(原始频谱)</strong></p> 
<p>函数**numpy.fft.ifft2()**可以用来实现傅里叶逆变换，返回空间域复数数组。该函数的语法格式为：</p> 
<p><strong>ifft = numpy.fft.ifft2(ifftShift)</strong></p> 
<p>傅里叶逆变换得到的空间域信息是一个复数数组需要将该信息调整到[0, 255]的灰度空间内，使用公式为：</p> 
<p><strong>img = numpy.abs(ifft)</strong></p> 
<pre><code>img = cv2.imread('image/lena.png', 0)
fft = np.fft.fft2(img)  # 傅里叶变换
fftShift = np.fft.fftshift(fft)
ifftShift = np.fft.ifftshift(fftShift)
ifft = np.fft.ifft2(ifftShift)  # 傅里叶逆变换
output = np.abs(ifft)
plt.subplot(121)
plt.imshow(img, cmap='gray')
plt.title('original'), plt.axis('off')
plt.subplot(122)
plt.imshow(output, cmap='gray')
plt.title('output'), plt.axis('off')
plt.show()
</code></pre> 
<ol start="3"><li><strong>实现高通滤波</strong></li></ol> 
<pre><code>img = cv2.imread('image/lena.png', 0)
fft = np.fft.fft2(img)  # 傅里叶变换
fftShift = np.fft.fftshift(fft)
row, col = img.shape
r, c = int(row / 2), int(col / 2)  # 图像中心点
fftShift[r - 30:r + 30, c - 30:c + 30] = 0  # 去除低频信息
ifftShift = np.fft.ifftshift(fftShift)
ifft = np.fft.ifft2(ifftShift)  # 傅里叶逆变换
output = np.abs(ifft)
plt.subplot(121)
plt.imshow(img, cmap='gray')
plt.title('original'), plt.axis('off')
plt.subplot(122)
plt.imshow(output, cmap='gray')
plt.title('output'), plt.axis('off')
plt.show()
</code></pre> 
<ol start="4"><li><strong>实现低通滤波</strong></li></ol> 
<pre><code>img = cv2.imread('image/lena.png', 0)
fft = np.fft.fft2(img)  # 傅里叶变换
fftShift = np.fft.fftshift(fft)
row, col = img.shape
r, c = int(row / 2), int(col / 2)  # 图像中心点
mask = np.zeros((row, col), np.uint8)
mask[r - 30:r + 30, c - 30:c + 30] = 1
fftShift = fftShift * mask
ifftShift = np.fft.ifftshift(fftShift)
ifft = np.fft.ifft2(ifftShift)  # 傅里叶逆变换
output = np.abs(ifft)
plt.subplot(121)
plt.imshow(img, cmap='gray')
plt.title('original'), plt.axis('off')
plt.subplot(122)
plt.imshow(output, cmap='gray')
plt.title('output'), plt.axis('off')
plt.show()
</code></pre> 
<h4><a id="OpenCV_1816"></a>用OpenCV实现傅里叶变换</h4> 
<ol><li><strong>实现傅里叶变换</strong></li></ol> 
<p>函数**cv2.dft()**可以用来实现傅里叶变换，返回空间域复数数组。该函数的语法格式为：</p> 
<p><strong>dft= cv2.dft(img, flags)</strong></p> 
<ul><li>img要先使用**np.float32()**函数将图像转换为np.float32格式</li><li>flags的值通常为<strong>cv2.DFT_COMPLEX_OUTPUT</strong>，用来输出一个复数阵列</li></ul> 
<p>此时，零频率分量并不在中心位置，为了处理方便需要将其移到中心位置，可以用**numpy.fft.fftshift()**实现。</p> 
<p><strong>dftShift = numpy.fft.fftshift(dft)</strong></p> 
<p>经过上述处理后，频谱图像还只是一个由实部和虚部构成的值。要将其显示出来，还要用**cv2.magnitude()**函数处理，该函数可以计算频谱信息的幅度，该函数的语法格式为：</p> 
<p><strong>output = cv2.magnitude(x, y)</strong></p> 
<ul><li> <p>output：频谱信息的幅度</p> </li><li> <p>x：实部</p> </li><li> <p>y：虚部</p> </li></ul> 
<p>得到频谱信息的幅度后，还需要将幅度值映射到灰度空间[0, 255]内，使其以灰度图像的形式显示出来。</p> 
<p><strong>output = 20 * np.log(cv2.magnitude(x, y))</strong></p> 
<pre><code>img = cv2.imread('image/lena.png', 0)
dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)  # 傅里叶变换
dftShift = np.fft.fftshift(dft)
output = 20 * np.log(cv2.magnitude(dftShift[:, :, 0], dftShift[:, :, 1]))
plt.subplot(121), plt.imshow(img, cmap='gray')
plt.title('original'), plt.axis('off')
plt.subplot(122), plt.imshow(output, cmap='gray')
plt.title('result'), plt.axis('off')
plt.show()
</code></pre> 
<ol start="2"><li><strong>实现傅里叶逆变换</strong></li></ol> 
<p>如果在傅里叶变换过程中使用了**numpy.fft.fftshift()<strong>函数移动零频率分量，那么在傅里叶逆变换过程中需要先使用</strong>numpy.fft.ifftshift()**函数将零频率分量移到原来的位置，再进行傅里叶逆变换。该函数的语法格式为：</p> 
<p><strong>idftShift = numpy.fft.ifftshift(原始频谱)</strong></p> 
<p>函数**cv2.idft()**可以用来实现傅里叶逆变换。该函数的语法格式为：</p> 
<p><strong>idft= cv2.idft(idftShift)</strong></p> 
<p>进行傅里叶逆变换后得到的仍旧是复数，需要使用函数**cv2.magnitude()**计算其幅度。</p> 
<pre><code>img = cv2.imread('image/lena.png', 0)
dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)  # 傅里叶变换
dftShift = np.fft.fftshift(dft)
idftShift = np.fft.ifftshift(dftShift)
idft = cv2.idft(idftShift)  # 傅里叶逆变换
output = cv2.magnitude(idft[:, :, 0], idft[:, :, 1])
plt.subplot(121), plt.imshow(img, cmap='gray')
plt.title('original'), plt.axis('off')
plt.subplot(122), plt.imshow(output, cmap='gray')
plt.title('result'), plt.axis('off')
plt.show()
</code></pre> 
<ol start="3"><li><strong>实现高通滤波</strong></li></ol> 
<pre><code>img = cv2.imread('image/lena.png', 0)
dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)  # 傅里叶变换
dftShift = np.fft.fftshift(dft)
row, col = img.shape
r, c = int(row / 2), int(col / 2)  # 图像中心点
dftShift[r - 30:r + 30, c - 30:c + 30] = 0  # 去除低频信息
idftShift = np.fft.ifftshift(dftShift)
idft = cv2.idft(idftShift)  # 傅里叶逆变换
output = cv2.magnitude(idft[:, :, 0], idft[:, :, 1])
plt.subplot(121), plt.imshow(img, cmap='gray')
plt.title('original'), plt.axis('off')
plt.subplot(122), plt.imshow(output, cmap='gray')
plt.title('result'), plt.axis('off')
plt.show()
</code></pre> 
<ol start="4"><li><strong>实现低通滤波</strong></li></ol> 
<pre><code>img = cv2.imread('image/lena.png', 0)
dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)  # 傅里叶变换
dftShift = np.fft.fftshift(dft)
row, col = img.shape
r, c = int(row / 2), int(col / 2)  # 图像中心点
mask = np.zeros((row, col, 2), np.uint8)
mask[r - 30:r + 30, c - 30:c + 30] = 1
dftShift = dftShift * mask
idftShift = np.fft.ifftshift(dftShift)
idft = cv2.idft(idftShift)  # 傅里叶逆变换
output = cv2.magnitude(idft[:, :, 0], idft[:, :, 1])
plt.subplot(121), plt.imshow(img, cmap='gray')
plt.title('original'), plt.axis('off')
plt.subplot(122), plt.imshow(output, cmap='gray')
plt.title('result'), plt.axis('off')
plt.show()
</code></pre> 
<h3><a id="_1922"></a>模板匹配</h3> 
<h4><a id="_1924"></a>模板匹配基础</h4> 
<p>模板匹配是指在当前图像A内寻找与图像B最相似的部分。模板匹配的操作方法是将模板图像B在图像A上滑动，遍历所有像素以完成匹配。</p> 
<p>函数**cv2.matchTemplate()**可以用来实现模板匹配。该函数的语法格式为：</p> 
<p><strong>cv2.matchTemplate(img, templ, method)</strong></p> 
<ul><li>img为原始图像，必须是8位或者32位的浮点型图像</li><li>templ为模板图像，它的尺寸必须小于或等于原始图像，并且与原始图像有相同的类型</li><li>method为匹配方法，如下图所示</li></ul> 
<table><thead><tr><th>参数</th><th>对应数值</th><th>说明</th></tr></thead><tbody><tr><td>CV_TM_SQDIFF</td><td>0</td><td>以方差为依据进行匹配；若完全匹配，则结果为0；若不匹配，则会得到一个很大的值</td></tr><tr><td>CV_TM_SQDIFF_NORMED</td><td>1</td><td>归一化平方差匹配</td></tr><tr><td>CV_TM_CCORR</td><td>2</td><td>该方法将模板图像与输入图像相乘；数值越大表明匹配程度越好</td></tr><tr><td>CV_TM_CCORR_NORMED</td><td>3</td><td>归一化相关匹配</td></tr><tr><td>CV_TM_CCOEFF</td><td>4</td><td>1表示完美匹配，-1表示最差匹配，0表示没有任何相关性</td></tr><tr><td>CV_TM_CCOEFF_NORMED</td><td>5</td><td>归一化相关系数匹配</td></tr></tbody></table> 
<p><strong>用cv2.TM_SQDIFF方法进行模板匹配</strong></p> 
<pre><code>img = cv2.imread('image/lena.png', 0)
template = cv2.imread('image/lenaEye.bmp', 0)
templateH, templateW = template.shape  # 模板的高、宽
match = cv2.matchTemplate(img, template, cv2.TM_SQDIFF)  # 模板匹配(cv2.TM_SQDIFF)
min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(match)  # 最大值和最小值及它们的位置
topLeft = min_loc  # 左上角
bottomRight = (topLeft[0] + templateW, topLeft[1] + templateH)  # 右下角
cv2.rectangle(img, topLeft, bottomRight, (255, 0, 0), 2)
plt.subplot(121), plt.imshow(img, cmap='gray')
plt.title('result'), plt.axis('off')
plt.subplot(122), plt.imshow(match, cmap='gray')
plt.title('Match Result'), plt.axis('off')
plt.show()
</code></pre> 
<p><strong>用cv2.TM_CCOEFF方法进行模板匹配</strong></p> 
<pre><code>img = cv2.imread('image/lena.png', 0)
template = cv2.imread('image/lenaEye.bmp', 0)
templateH, templateW = template.shape  # 模板的高、宽
match = cv2.matchTemplate(img, template, cv2.TM_CCOEFF)  # 模板匹配(cv2.TM_CCOEFF)
min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(match)  # 最大值和最小值及它们的位置
topLeft = max_loc  # 左上角
bottomRight = (topLeft[0] + templateW, topLeft[1] + templateH)  # 右下角
cv2.rectangle(img, topLeft, bottomRight, (255, 0, 0), 2)
plt.subplot(121), plt.imshow(img, cmap='gray')
plt.title('result'), plt.axis('off')
plt.subplot(122), plt.imshow(match, cmap='gray')
plt.title('Match Result'), plt.axis('off')
plt.show()
</code></pre> 
<h4><a id="_1981"></a>多模板匹配</h4> 
<p>多模板匹配分为以下5个步骤：</p> 
<ol><li><strong>获取匹配位置的集合</strong></li></ol> 
<p>函数**numpy.where()**能够获取模板匹配位置的集合。对于不同的输入，其返回值是不同的。</p> 
<ul><li>当输入为一位数组时，返回值是一维索引，只有一组索引数组</li><li>当输入为二维数组时，返回值是匹配值的位置索引，因此会有两组索引数组表示返回值的位置</li></ul> 
<p>所以，函数<strong>np.where()<strong>可以找出在函数</strong>cv2.matchTemplate()<strong>的返回值中，哪些位置上的值是大于阈值</strong>threshold</strong>的。可以采用语句：</p> 
<p><strong>loc = np.where(res &gt;= threshold)</strong></p> 
<ul><li> <p>loc是满足"res &gt;= threshold"的像素点的索引集合</p> </li><li> <p>res是函数**cv2.matchTemplate()**进行模板匹配后的返回值</p> </li><li> <p>threshold是阈值</p> </li></ul> 
<ol start="2"><li><strong>循环</strong></li></ol> 
<p>在获取匹配值的索引集合后，可以采用如下语句遍历所有匹配的位置，对这些位置做标记：</p> 
<pre><code>for i in 匹配位置集合:
	标记匹配位置
</code></pre> 
<ol start="3"><li><strong>在循环中使用函数zip()</strong></li></ol> 
<p>函数zip()用可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的元素。因此，如果希望循环遍历由np.where()返回的模板匹配索引集合，可以采用语句：</p> 
<pre><code>for i in zip(*模板匹配索引集合):
	标记处理
</code></pre> 
<ol start="4"><li><strong>调整坐标</strong></li></ol> 
<p>使用**np.where()<strong>得到的形式为"(行号，列号)"的位置索引，但是函数</strong>cv2.rectangle()**中指定顶点的参数的形式为"(列号，行号)"的位置索引。所以要进行行列互换，可以使用语句：<strong>loc[::-1]</strong></p> 
<ol start="5"><li><strong>标记匹配图像的位置</strong></li></ol> 
<p>函数**cv2.rectangle()**可以标记匹配图像的位置。</p> 
<ol start="6"><li><strong>总程序</strong></li></ol> 
<pre><code>img = cv2.imread('image/lena4.bmp', 0)
template = cv2.imread('image/lena4Temp.bmp', 0)
templateH, templateW = template.shape  # 模板的高、宽
res = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED)  # 模板匹配(cv2.TM_CCOEFF_NORMED)
threshold = 0.9  # 阈值
loc = np.where(res &gt;= threshold)
for pt in zip(*loc[::-1]):
    cv2.rectangle(img, pt, (pt[0] + templateW, pt[1] + templateH), (255, 0, 0), 2)
plt.imshow(img, cmap='gray')
plt.xticks([]), plt.yticks([])
plt.show()
</code></pre> 
<h3><a id="_2043"></a>霍夫变换</h3> 
<h4><a id="_2045"></a>霍夫变换原理</h4> 
<p>与笛卡尔坐标系对应，在霍夫坐标系中，横坐标采用笛卡尔坐标系中直线的斜率k，纵坐标使用笛卡尔坐标系中直线的截距b。</p> 
<ul><li> <p>笛卡尔空间内的一条直线确定了霍夫空间内的一个点</p> </li><li> <p>霍夫空间内的一个点确定了笛卡尔空间内的一条直线</p> </li><li> <p>笛卡尔空间内的两个点会映射为霍夫空间内两条相交于(k, b)的直线</p> </li><li> <p>笛卡尔空间内的两个点对应的直线会映射为霍夫空间内的点(k, b)</p> </li></ul> 
<p>在霍夫空间内，经过一个点的直线越多，说明其在笛卡尔空间内映射的直线是由越多的点所穿过的，那么它实际存在的可能性就越大，它的可靠性也越高。</p> 
<p>假如有垂直于x轴的直线，它的斜率k为无穷大，截距b无法取值，可以将笛卡尔坐标系映射到极坐标系上。</p> 
<h4><a id="_2061"></a>霍夫直线变换</h4> 
<p>函数**cv2.HoughLines()**可以用来实现霍夫直线变换。该函数要求所操作的原图像是一个二值图像，所以在进行霍夫变换之前要先将原图像进行二值化或者进行Canny边缘检测。该函数的语法格式为：</p> 
<p><strong>lines = cv2.HoughLines(img, rho, theta, threshold)</strong></p> 
<ul><li>lines中的每个元素都是一对浮点数，表示检测到的直线的参数，即(r, θ)</li><li>img为原图像，必须是8位单通道二值图像</li><li>rho是以像素为单位的距离r的精度，一般情况下设置为1</li><li>theta是角度θ的精度，一般情况下设置为π/180，表示要搜索所有可能的角度</li><li>threshold是阈值。该值越小，判断出的直线就越多</li></ul> 
<pre><code>img = cv2.imread('image/computer.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
edge = cv2.Canny(gray, 50, 150, apertureSize=3)  # Canny边缘检测
rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
rgbCopy = rgbImg.copy()
lines = cv2.HoughLines(edge, 1, np.pi / 180, 140)  # 霍夫直线变换
for line in lines:
    rho, theta = line[0]
    a = np.cos(theta)
    b = np.sin(theta)
    x0 = a * rho
    y0 = b * rho
    x1 = int(x0 + 1000 * (-b))
    y1 = int(y0 + 1000 * a)
    x2 = int(x0 - 1000 * (-b))
    y2 = int(y0 - 1000 * a)
    cv2.line(rgbImg, (x1, y1), (x2, y2), (0, 0, 255), 2)
plt.subplot(121)
plt.imshow(rgbCopy), plt.axis('off')
plt.subplot(122)
plt.imshow(rgbImg), plt.axis('off')
plt.show()
</code></pre> 
<h4><a id="_2098"></a>概率霍夫变换</h4> 
<p>为了更好地判断直线（线段），概率霍夫变换算法还对选取直线的方法作了两点改进：</p> 
<ul><li> <p>接受直线的最小长度。如果有超过阈值个数的像素点构成了一条直线，但是这条直线很短，那么就不会接受该直线作为判断结果，而认为这条直线仅仅是图像中的若干个像素点恰好随机构成了一种算法上的直线关系而已，实际上原图中并不存在这条直线。</p> </li><li> <p>接受直线时允许的最大像素点间距。如果有超过阈值个数的像素点构成了一条直线，但是这组像素点之间的距离都很远，就不会接受该直线作为判断结果，而认为这条直线仅仅是图像中的若干个像素点恰好随机构成了一种算法上的直线关系而已，实际上原图中并不存在这条直线。</p> </li></ul> 
<p>函数**cv2.HoughLinesP()**可以用来实现霍夫直线变换。该函数要求所操作的原图像是一个二值图像，所以在进行霍夫变换之前要先将原图像进行二值化或者进行Canny边缘检测。该函数的语法格式为：</p> 
<p><strong>lines = cv2.HoughLinesP(img, rho, theta, threshold, minLineLength, maxLineGap)</strong></p> 
<ul><li> <p>lines中的每个元素都是一对浮点数，表示检测到的直线的参数，即(r, θ)</p> </li><li> <p>img为原图像，必须是8位单通道二值图像</p> </li><li> <p>rho是以像素为单位的距离r的精度，一般情况下设置为1</p> </li><li> <p>theta是角度θ的精度，一般情况下设置为π/180，表示要搜索所有可能的角度</p> </li><li> <p>threshold是阈值。该值越小，判断出的直线就越多</p> </li><li> <p>minLineLength用来控制"接受直线的最小长度"的值</p> </li><li> <p>maxLineGap用来控制"接受直线时允许的最大像素点间距"</p> </li></ul> 
<pre><code>img = cv2.imread('image/computer.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
edge = cv2.Canny(gray, 50, 150, apertureSize=3)  # Canny边缘检测
rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
rgbCopy = rgbImg.copy()
lines = cv2.HoughLinesP(edge, 1, np.pi / 180, 160, minLineLength=100, maxLineGap=10)  # 概率霍夫变换
for line in lines:
    x1, y1, x2, y2 = line[0]
    cv2.line(rgbImg, (x1, y1), (x2, y2), (255, 255, 255), 2)
plt.subplot(121)
plt.imshow(rgbCopy), plt.axis('off')
plt.subplot(122)
plt.imshow(rgbImg), plt.axis('off')
plt.show()
</code></pre> 
<h4><a id="_2136"></a>霍夫圆变换</h4> 
<p>在霍夫圆变换中需要考虑圆半径和圆心（x坐标、y坐标）共三个参数。在OpenCV中采用的策略是两轮筛选，第一轮筛选找出可能存在的圆的位置（圆心），第二轮再根据第一轮的结果筛选出半径大小。</p> 
<p>函数**cv2.HoughCircles()**可以用来实现霍夫圆变换。该函数要求所操作的原图像是一个二值图像，所以在进行霍夫变换之前要先将原图像进行二值化或者进行Canny边缘检测。该函数的语法格式为：</p> 
<p><strong>circles = cv2.HoughCircles(img, method, dp, minDist, param1, param2, minRadius, maxRadius)</strong></p> 
<ul><li> <p>circles ：由圆心坐标和半径构成</p> </li><li> <p>img：原图像，类型为8位单通道灰度图像</p> </li><li> <p>method：检测方法，设置为cv2.HOUGH_GRADIENT</p> </li><li> <p>dp：累计器分辨率，它是一个分割比率，用来指定图像分辨率与圆心累加器分辨率的比例</p> </li><li> <p>minDist：圆心间的最小间距，该值被当作阈值使用</p> </li><li> <p>param1：它对应的是Canny边缘检测器的高阈值，在缺省时默认值为100</p> </li><li> <p>param2：圆心位置必须收到的投票数。只有在第一轮筛选过程中投票数超过该值的圆才有资格进入第二轮的筛选，在缺省时默认值为100</p> </li><li> <p>minRadius：圆半径的最小值，小于该值的圆不会被检测出来。在缺省时默认值为0，该参数不起作用</p> </li><li> <p>maxRadius：圆半径的最大值，大于该值的圆不会被检测出来。在缺省时默认值为0，该参数不起作用</p> </li></ul> 
<pre><code>img = cv2.imread('image/chess.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
rgbCopy = rgbImg.copy()
gray = cv2.medianBlur(gray, 5)
circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 300, param1=50, param2=30, minRadius=100, maxRadius=200)  # 霍夫圆变换
circles = np.uint16(np.around(circles))
for i in circles[0, :]:
    cv2.circle(rgbImg, (i[0], i[1]), i[2], (255, 0, 0), 12)
    cv2.circle(rgbImg, (i[0], i[1]), 2, (255, 0, 0), 12)
plt.subplot(121)
plt.imshow(rgbCopy), plt.axis('off')
plt.subplot(122)
plt.imshow(rgbImg), plt.axis('off')
plt.show()
</code></pre> 
<h3><a id="_2174"></a>图像分割与提取</h3> 
<h4><a id="_2176"></a>距离变换函数</h4> 
<p>当图像内的各个子图没有连接时，可以直接使用形态学的腐蚀操作确定前景对象，但是如果图像内的子图连接在一起时，就很难确定前景对象了。此时借助距离变换函数**cv2.distanceTransform()**可以方便地将前景对象提取出来。</p> 
<p>距离变换函数**cv2.distanceTransform()**计算二值图像内任意点到最近背景点的距离。一般情况下，该函数计算的是图像内非零值像素点到最近的零值像素点的距离，即计算二值图像中所有像素点距离其最近的值为0的像素点的距离。如果像素点本身的值为0，则这个距离也为0。</p> 
<p>距离变换函数**cv2.distanceTransform()**的计算结果反映了各个像素与背景（值为0的像素点）的距离关系。通常情况下：</p> 
<ul><li> <p>如果前景对象的中心（质心）距离值为0的像素点距离较远，会得到一个较大的值。</p> </li><li> <p>如果前景对象的边缘距离值为0的像素点较近，会得到一个较小的值。</p> </li></ul> 
<p>如果对上述计算结果进行阈值化，就可以得到图像内子图的中心、骨架等信息。距离变换函数可以用于计算对象的中心，还能细化轮廓、获取图像前景等，有多种功能。</p> 
<p>距离变换函数**cv2.distanceTransform()**的语法格式为：</p> 
<p><strong>cv2.distanceTransform(img, distanceType, maskSize)</strong></p> 
<ul><li>img是8位单通道二值图像</li><li>distanceType是距离类型参数，具体值和含义如下图所示</li><li>maskSize是掩模的尺寸，当distanceType = cv2.DIST_L1或cv2.DIST_C时，maskSize强制为3</li></ul> 
<table><thead><tr><th>值</th><th>含义</th></tr></thead><tbody><tr><td>cv2.DIST_USER</td><td>用户定义距离</td></tr><tr><td>cv2.DIST_L1</td><td>distance = |x1-x2|+|y1-y2|</td></tr><tr><td>cv2.DIST_L2</td><td>欧式距离，此时与最小二乘法相同</td></tr><tr><td>cv2.DIST_C</td><td>distance =max(|x1-x2|, |y1-y2|)</td></tr><tr><td>cv2.DIST_L12</td><td>distance = 2(sqrt(1+x*x/2) - 1))</td></tr><tr><td>cv2.DIST_FAIR</td><td>distance = c2(|x|/c-log(1+|x|/c)), c = 1.3998</td></tr><tr><td>cv2.DIST_WELSCH</td><td>distance =c2/2(1-exp(-(x/c)2)), c = 2.9846</td></tr><tr><td>cv2.DIST_HUBER</td><td>distance =|x|&lt;c ? x2/2 : c(|x|-c/2), c=1.345</td></tr></tbody></table> 
<pre><code>img = cv2.imread('image/water_coins.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
imgCopy = img.copy()
ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
kernel = np.ones((3, 3), np.uint8)
opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)  # 开运算
distanceTransform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)  # 距离变换
ret, fore = cv2.threshold(distanceTransform, 0.7 * distanceTransform.max(), 255, 0)
plt.subplot(131)
plt.imshow(imgCopy), plt.axis('off')
plt.subplot(132)
plt.imshow(distanceTransform), plt.axis('off')
plt.subplot(133)
plt.imshow(fore), plt.axis('off')
plt.show()
</code></pre> 
<h4><a id="_2228"></a>标注图像</h4> 
<p>函数**cv2.connectedComponents()**可以用来标注。该函数会将背景标注为0，将其他的对象使用从1开始的正整数标注。该函数的语法格式为：</p> 
<p><strong>retval, labels = cv2.connectedComponents(img)</strong></p> 
<ul><li>retval为返回的标注的数量</li><li>labels为标注的结果图像</li><li>img为8位单通道的待标注图像</li></ul> 
<pre><code>img = cv2.imread('image/water_coins.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
imgCopy = img.copy()
ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
kernel = np.ones((3, 3), np.uint8)
opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)  # 开运算
sure_bg = cv2.dilate(opening, kernel, iterations=3)  # 确定背景
dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
ret, fore = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)
fore = np.uint8(fore)  # 前景图像的中心点图像
ret, markers = cv2.connectedComponents(fore)  # 对中心点图像进行标注
plt.subplot(131)
plt.imshow(imgCopy), plt.axis('off')
plt.subplot(132)
plt.imshow(fore), plt.axis('off')
plt.subplot(133)
plt.imshow(markers), plt.axis('off')
plt.show()
</code></pre> 
<p>函数**cv2.connectedComponents()<strong>在标注图像时，会将背景标注为0，将其他的对象用从1开始的正整数标注。在分水岭算法中，标注值0代表未知区域，所以我们要对函数</strong>cv2.connectedComponents()**标注的结果进行调整：将标注的结果都加上数值1。为了能够使用分水岭算法，还需要对原始图像内的未知区域进行标注，将已经计算出来的未知区域标注为0即可。这里的关键代码为：</p> 
<pre><code>ret, markers = cv2.connectedComponents(fore)
markers = markers + 1
markers[未知区域] = 0
</code></pre> 
<pre><code>img = cv2.imread('image/water_coins.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
kernel = np.ones((3, 3), np.uint8)
opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)  # 开运算
sure_bg = cv2.dilate(opening, kernel, iterations=3)  # 确定背景
dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
ret, fore = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)
fore = np.uint8(fore)
ret, markers1 = cv2.connectedComponents(fore)
foreAdv = fore.copy()
unknown = cv2.subtract(sure_bg, foreAdv)  # 未知区域
ret, markers2 = cv2.connectedComponents(foreAdv)
markers2 = markers2 + 1  # 修正标注结果
markers2[unknown == 255] = 0
plt.subplot(121)
plt.imshow(markers1), plt.axis('off')
plt.subplot(122)
plt.imshow(markers2), plt.axis('off')
plt.show()
</code></pre> 
<h4><a id="_2292"></a>分水岭算法实现图像分割与提取</h4> 
<p>步骤：</p> 
<ol><li>通过开运算对原始图像O去噪</li><li>通过腐蚀操作获取确定背景B</li><li>利用距离变换函数**cv2.distanceTransform()**对原始图像进行运算，并进行阈值处理，得到确定前景F</li><li>计算未知区域UN（UN = O - B - F）</li><li>利用函数**cv2.connectedComponents()**对原始图像O进行标注</li><li>对函数**cv2.connectedComponents()**的标注结果进行修正</li><li>使用分水岭函数完成对图像的分割</li></ol> 
<p>函数**cv2.watershed()**可以用来实现分水岭算法。该函数的语法格式为：</p> 
<p><strong>cv2.watershed(img, markers)</strong></p> 
<ul><li> <p>img是8位三通道的图像。在对图像使用**cv2.watershed()**函数处理之前，必须先用正数大致勾画出图像中的期望分割区域。每一个分割的区域会被标注为1、2、3等。对于尚未确定的区域，需要将它们标注为0，我们可以将标注区域理解为进行分水岭算法分割的"种子"区域。</p> </li><li> <p>markers是32位单通道的标注结果。在markers中，每一个像素要么被设置为初期的种子值，要么被设置为"-1"表示边界。markers可以省略。</p> </li></ul> 
<pre><code>img = cv2.imread('image/water_coins.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
imgCopy = img.copy()
ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
kernel = np.ones((3, 3), np.uint8)
opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)  # 开运算
sure_bg = cv2.dilate(opening, kernel, iterations=3)  # 确定背景
dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)
sure_fg = np.uint8(sure_fg)  # 确定前景
unknown = cv2.subtract(sure_bg, sure_fg)  # 未知区域
ret, markers = cv2.connectedComponents(sure_fg)
markers = markers + 1  # 修正标注结果
markers[unknown == 255] = 0
markers = cv2.watershed(img, markers)  # 分水岭算法
img[markers == -1] = [0, 255, 0]
plt.subplot(121)
plt.imshow(imgCopy), plt.axis('off')
plt.subplot(122)
plt.imshow(img), plt.axis('off')
plt.show()
</code></pre> 
<h4><a id="_2337"></a>交互式前景提取</h4> 
<p>函数**cv2.grabCut()**可以用来实现交互式前景提取。该函数的语法格式为：</p> 
<p><strong>mask, bgdModel, fgdModel = cv2.grabCut(img, mask, rect, bgdModel, fgdModel, iterCount[, mode])</strong></p> 
<ul><li> <p>img是8位3通道的图像</p> </li><li> <p>mask是8位单通道的掩模图像，用于确定前景区域、背景区域和不确定区域，可以设置为4种形式：</p> 
  <ul><li><strong>cv2.GC_BGD</strong>：表示确定背景，也可以用数值0表示</li><li><strong>cv2.GC_FGD</strong>：表示确定前景，也可以用数值1表示</li><li><strong>cv2.GC_PR_BGD</strong>：表示可能的背景，也可以用数值2表示</li><li><strong>cv2.GC_PR_FGD</strong>：表示可能的前景，也可以用数值3表示</li></ul> </li><li> <p>rect是包含前景对象的区域，该区域外的部分被认为是确定背景。只有当参数mode的值设置为矩形模式<strong>cv2.GC_INIT_WITH_RECT</strong>时，参数rect才有意义。使用掩模模式时，将该值设置为None即可。</p> </li><li> <p>bgdModel为算法内部使用的数组，只需要创建大小为(1, 65)的numpy.float64数组</p> </li><li> <p>fgdModel为算法内部使用的数组，只需要创建大小为(1, 65)的numpy.float64数组</p> </li><li> <p>iterCount表示迭代的次数</p> </li><li> <p>mode表示迭代模式</p> </li></ul> 
<p><strong>GrabCut算法提取图像的前景(不使用掩模)</strong></p> 
<pre><code>img = cv2.imread('image/lena.png')
rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
mask = np.zeros(img.shape[:2], np.uint8)  # 将掩模设置为0
bgdModel = np.zeros((1, 65), np.float64)
fgdModel = np.zeros((1, 65), np.float64)
rect = (50, 50, 400, 400)
cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)
mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
ogc = img * mask2[:, :, np.newaxis]
ogc = cv2.cvtColor(ogc, cv2.COLOR_BGR2RGB)
plt.subplot(121)
plt.imshow(rgbImg), plt.axis('off')
plt.subplot(122)
plt.imshow(ogc), plt.axis('off')
plt.show()
</code></pre> 
<p><strong>GrabCut算法提取图像的前景(使用标记的掩模)</strong></p> 
<pre><code>img = cv2.imread('image/lena.png')
rgbImg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
mask = np.zeros(img.shape[:2], np.uint8)
bgd = np.zeros((1, 65), np.float64)
fgd = np.zeros((1, 65), np.float64)
rect = (50, 50, 400, 500)
cv2.grabCut(img, mask, rect, bgd, fgd, 5, cv2.GC_INIT_WITH_RECT)
mask2 = cv2.imread('image/lenaMask.png', 0)
mask2Show = cv2.imread('image/lenaMask.png')
m2rgb = cv2.cvtColor(mask2Show, cv2.COLOR_BGR2RGB)
mask[mask2 == 0] = 0  # 将黑色值映射到掩模上
mask[mask2 == 255] = 1  # 将白色值映射到掩模上
mask, bgd, fgd = cv2.grabCut(img, mask, None, bgd, fgd, 5, cv2.GC_INIT_WITH_MASK)
mask = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
ogc = img * mask[:, :, np.newaxis]
ogc = cv2.cvtColor(ogc, cv2.COLOR_BGR2RGB)
plt.subplot(121)
plt.imshow(m2rgb), plt.axis('off')
plt.subplot(122)
plt.imshow(ogc), plt.axis('off')
plt.show()
</code></pre> 
<h3><a id="_2402"></a>视频处理</h3> 
<h4><a id="VideoCapture_2404"></a>VideoCapture类</h4> 
<ol><li><strong>初始化</strong></li></ol> 
<p>**cv2.VideoCapture()**函数可以用于打开摄像头并初始化。</p> 
<p>初始化当前的摄像头</p> 
<pre><code>cap = cv2.VideoCapture(0)
</code></pre> 
<p>初始化视频文件</p> 
<pre><code>cap = cv2.VideoCapture("test.avi")
</code></pre> 
<ol start="2"><li><strong>检查初始化是否成功</strong></li></ol> 
<p>可以使用函数**cv2.VideoCapture.isOpened()**检查初始化是否成功。</p> 
<pre><code>retval = cv2.VideoCapture.isOpened()
</code></pre> 
<ul><li>若成功，返回值retval为True</li><li>若失败，返回值retval为False</li></ul> 
<p>如果初始化失败，可以使用函数**cv2.VideoCapture.open()**打开摄像头。</p> 
<pre><code>retval = cv2.VideoCapture.open(0)
</code></pre> 
<p>函数**cv2.VideoCapture.isOpened()<strong>和函数</strong>cv2.VideoCapture.open()**也能用于处理视频文件。</p> 
<ol start="3"><li><strong>捕获帧</strong></li></ol> 
<pre><code>retval, image = cv2.VideoCapture.read()
</code></pre> 
<ol start="4"><li><strong>释放</strong></li></ol> 
<p>若当前有一个VideoCapture类的对象cap，要将其释放，可以使用语句</p> 
<pre><code>cap.release()
</code></pre> 
<ol start="5"><li><strong>属性设置</strong></li></ol> 
<p>函数**cv2.VideoCapture.get()**用于获取cv2.VideoCapture类对象的属性。该函数的语法格式为：</p> 
<p><strong>retval = cv2.VideoCapture.get(propId)</strong></p> 
<ul><li>propId对应着cv2.VideoCapture类对象的属性</li></ul> 
<p>函数**cv2.VideoCapture.set()**用于设置cv2.VideoCapture类对象的属性。该函数的语法格式为：</p> 
<p><strong>retval = cv2.VideoCapture.set(propId, value)</strong></p> 
<table><thead><tr><th>值</th><th>propId</th><th>含义</th></tr></thead><tbody><tr><td>cv2.CV_CAP_PROP_FRAME_WIDTH</td><td>3</td><td>帧的宽度</td></tr><tr><td>cv2.CV_CAP_PROP_FRAME_HEIGHT</td><td>4</td><td>帧的高度</td></tr><tr><td>cv2.CV_CAP_PROP_FPS</td><td>5</td><td>帧速</td></tr></tbody></table> 
<ol start="6"><li><strong>捕获摄像头视频</strong></li></ol> 
<pre><code>cap = cv2.VideoCapture(0)
while True:
    success, img = cap.read()
    cv2.imshow("Video", img)
    if cv2.waitKey(1) &amp; 0XFF == 27:
        break
</code></pre> 
<h4><a id="VideoWriter_2484"></a>VideoWriter类</h4> 
<p>OpenCV中的cv2.VideoWriter类可以将图片序列保存为视频文件，也可以修改视频的各种属性，还可以完成对视频类型的转换。</p> 
<ol><li><strong>初始化</strong></li></ol> 
<p><strong>cv2.VideoWriter(filename, fourcc, fps, frameSize)</strong></p> 
<ul><li> <p>filename指定输出目标视频的存放路径和文件名</p> </li><li> <p>fourcc表示视频编解码格式</p> </li><li> <p>fps为帧速率</p> </li><li> <p>frameSize为每一帧的长和宽</p> </li></ul> 
<ol start="2"><li><strong>write函数</strong></li></ol> 
<p>**cv2.VideoWriter.write(img)**用于写入下一帧视频，若当前有一个VideoWriter类的对象out，要将一个视频帧frame写入，可以使用语句</p> 
<pre><code>out.write(frame)
</code></pre> 
<ol start="3"><li><strong>释放</strong></li></ol> 
<p>若当前有一个VideoWriter类的对象out，要将其释放，可以使用语句</p> 
<pre><code>out.release()
</code></pre> 
<ol start="4"><li><strong>保存摄像头视频</strong></li></ol> 
<pre><code>cap = cv2.VideoCapture(0)
fourcc = cv2.VideoWriter_fourcc(*'XVID')  # 保存视频的编码
out = cv2.VideoWriter('output.avi', fourcc, 20, (640, 480))
while cap.isOpened():
    success, img = cap.read()
    if success:
        out.write(img)
        cv2.imshow('frame', img)
        if cv2.waitKey(1) == 27:
            break
    else:
        break
cap.release()
out.release()
cv2.destroyAllWindows()
</code></pre> 
<h3><a id="_2534"></a>绘画及交互</h3> 
<h4><a id="_2536"></a>绘画基础</h4> 
<ol><li><strong>绘制直线</strong></li></ol> 
<p><strong>img = cv2.line(img, pt1, pt2, color, thickness[, lineType])</strong></p> 
<ul><li>pt1表示线段的起点</li><li>pt2表示线段的终点</li><li>color表示绘制的颜色</li><li>thickness表示线条的粗细</li><li>lineType表示线条的类型</li></ul> 
<pre><code>img = cv2.line(img, (50, 50), (300, 300), (255, 0, 0), 2)
</code></pre> 
<ol start="2"><li><strong>绘制矩形</strong></li></ol> 
<p><strong>img = cv2.rectangle(img, pt1, pt2, color, thickness[, lineType])</strong></p> 
<ul><li>pt1表示矩形的顶点</li><li>pt2表示矩形中与pt1对角的顶点</li><li>color表示绘制的颜色，-1代表填充为实心</li><li>thickness表示线条的粗细</li><li>lineType表示线条的类型</li></ul> 
<pre><code>img = cv2.rectangle(img, (50, 50), (300, 300), (255, 0, 0), 2)
</code></pre> 
<ol start="3"><li><strong>绘制圆形</strong></li></ol> 
<p><strong>img = cv2.circle(img, center, radius, color, thickness[, lineType])</strong></p> 
<ul><li>center为圆心坐标</li><li>radius为半径</li><li>color表示绘制的颜色，-1代表填充为实心</li><li>thickness表示线条的粗细</li><li>lineType表示线条的类型</li></ul> 
<pre><code>img = cv2.circle(img, (200, 200), 50, (255, 0, 0), 2)
</code></pre> 
<ol start="4"><li><strong>绘制椭圆</strong></li></ol> 
<p><strong>img = cv2.ellipse(img, center, axes, angle, startAngle, endAngle, color, thickness[, lineType])</strong></p> 
<ul><li>center为椭圆的圆心坐标</li><li>axes为轴的长度</li><li>angle为偏转的角度</li><li>startAngle为圆弧起始角的角度</li><li>endAngle为圆弧终结角的角度</li><li>color表示绘制的颜色，-1代表填充为实心</li></ul> 
<pre><code>img = cv2.ellipse(img, (200, 200), (200, 100), 30, 0, 360, (255, 0, 0), 2)
</code></pre> 
<ol start="5"><li><strong>绘制多边形</strong></li></ol> 
<p><strong>img = cv2.polylines(img, pts, isClosed, color, thickness[, lineType])</strong></p> 
<ul><li>pts为多边形的各个顶点</li><li>isClosed为闭合标记，用来指示多边形是否是封闭的</li></ul> 
<pre><code>pts = np.array([[200, 50], [300, 200], [200, 350], [100, 200]], np.int32)
pts = pts.reshape((-1, 1, 2))
img = cv2.polylines(img, [pts], True, (255, 0, 0), 2)
</code></pre> 
<ol start="6"><li><strong>绘制文字</strong></li></ol> 
<p><strong>img = cv2.putText(img, text, org, fontFace, fontScale, color)</strong></p> 
<ul><li>text为多边形的各个顶点</li><li>org为绘制文字的位置，以文字的左下角为起点</li><li>fontFace表示字体类型</li><li>fontScale表示字体大小</li><li>color表示绘制的颜色</li></ul> 
<pre><code>img = cv2.putText(img, "OpenCV", (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0), 2)
</code></pre> 
<h4><a id="_2622"></a>滚动条</h4> 
<p>函数**cv2.createTrackbar()**用来定义滚动条，其语法格式为：</p> 
<p><strong>cv2.createTrackbar(trackbarName, windowName, value, count, onChange)</strong></p> 
<ul><li>trackbarName为滚动条的名称</li><li>windowName为滚动条所依附窗口的名称</li><li>value为初始值</li><li>count为滚动条的最大值</li><li>onChange为回调函数</li></ul> 
<p>滚动条的值可以通过函数**cv2.getTrackbarPos()**获取，其语法格式为：</p> 
<p><strong>retval = cv2.getTrackbarPos(trackbarname, winname)</strong></p> 
<ul><li>retval为返回值，获取滚动条的值</li><li>trackbarname为滚动条的名称</li><li>winname为滚动条所依附窗口的名称</li></ul> 
<p><strong>用滚动条实现调色板</strong></p> 
<pre><code>def changeColor(x):
    r = cv2.getTrackbarPos('R', 'image')
    g = cv2.getTrackbarPos('G', 'image')
    b = cv2.getTrackbarPos('B', 'image')
    img[:] = [b, g, r]


img = np.zeros((100, 500, 3), np.uint8)
cv2.namedWindow('image')
cv2.createTrackbar('R', 'image', 0, 255, changeColor)
cv2.createTrackbar('G', 'image', 0, 255, changeColor)
cv2.createTrackbar('B', 'image', 0, 255, changeColor)
while True:
    cv2.imshow('image', img)
    if cv2.waitKey(0) &amp; 0XFF == 27:
        cv2.destroyAllWindows()
</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7ebf9087d3f23566680f8fd2c69bda33/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python类型强制转换_python怎么强制转换类型</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/67a78e3c0f3e64225df8222ed319313a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C语言 个位数统计</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>