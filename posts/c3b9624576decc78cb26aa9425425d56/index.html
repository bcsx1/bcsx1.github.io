<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】深度学习概论（二） - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【机器学习】深度学习概论（二）" />
<meta property="og:description" content="五、受限玻尔兹曼机（Restricted Boltzmann Machine，RBM）
5.1 RBM介绍
示例代码：
Python 编写了一个简单的 RBM 实现，并用一些假数据训练了它。然后，他展示了如何用 RBM 来解释用户的电影偏好，以及如何用 RBM 来生成电影推荐：
使用一些假数据训练了RBM。
爱丽丝：（哈利波特 = 1，阿凡达 = 1，LOTR 3 = 1，角斗士 = 0，泰坦尼克号 = 0，闪光 = 0）。SF/奇幻大粉丝。
鲍勃：（哈利波特 = 1，阿凡达 = 0，LOTR 3 = 1，角斗士 = 0，泰坦尼克号 = 0，闪光 = 0）。SF/奇幻迷，但不喜欢《阿凡达》。
卡罗尔：（哈利波特 = 1，阿凡达 = 1，LOTR 3 = 1，角斗士 = 0，泰坦尼克号 = 0，闪光 = 0）。SF/奇幻大粉丝。
大卫：（哈利波特 = 0，阿凡达 = 0，LOTR 3 = 1，角斗士 = 1，泰坦尼克号 = 1，闪光 = 0）。奥斯卡大奖得主的粉丝。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/c3b9624576decc78cb26aa9425425d56/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-28T12:33:39+08:00" />
<meta property="article:modified_time" content="2023-12-28T12:33:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】深度学习概论（二）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p><strong>五、受限玻尔兹曼机（Restricted Boltzmann Machine，RBM）</strong></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/49/fe/Fb2AMV3r_o.jpg" alt="cd92844354fd82de0dda2e407a255bb3.jpeg"></p> 
 <p><strong>5.1 RBM介绍</strong></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/72/50/Mha7vLfZ_o.jpg" alt="ac3c3d62a55ab04d25874f23db8fd57b.jpeg"></p> 
 <p><strong>示例代码：</strong></p> 
 <p>Python 编写了一个简单的 RBM 实现，并用一些假数据训练了它。然后，他展示了如何用 RBM 来解释用户的电影偏好，以及如何用 RBM 来生成电影推荐：</p> 
 <p style="text-align:left;">使用一些假数据训练了RBM。</p> 
 <ul><li><p>爱丽丝：（哈利波特 = 1，阿凡达 = 1，LOTR 3 = 1，角斗士 = 0，泰坦尼克号 = 0，闪光 = 0）。SF/奇幻大粉丝。</p></li><li><p>鲍勃：（哈利波特 = 1，阿凡达 = 0，LOTR 3 = 1，角斗士 = 0，泰坦尼克号 = 0，闪光 = 0）。SF/奇幻迷，但不喜欢《阿凡达》。</p></li><li><p>卡罗尔：（哈利波特 = 1，阿凡达 = 1，LOTR 3 = 1，角斗士 = 0，泰坦尼克号 = 0，闪光 = 0）。SF/奇幻大粉丝。</p></li><li><p>大卫：（哈利波特 = 0，阿凡达 = 0，LOTR 3 = 1，角斗士 = 1，泰坦尼克号 = 1，闪光 = 0）。奥斯卡大奖得主的粉丝。</p></li><li><p>埃里克：（哈利波特 = 0，阿凡达 = 0，LOTR 3 = 1，角斗士 = 1，泰坦尼克号 = 1，闪光 = 0）。奥斯卡奖得主的粉丝，泰坦尼克号除外。</p></li><li><p>弗雷德：（哈利波特 = 0，阿凡达 = 0，LOTR 3 = 1，角斗士 = 1，泰坦尼克号 = 1，闪光 = 0）。奥斯卡大奖得主的粉丝。</p></li></ul> 
 <p>该网络学习了以下权重：</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/44/7c/aMg5ZTXD_o.png" alt="548d3601f2c5346b051d114ea1b184f3.png"></p> 
 <p style="text-align:left;">请注意，第一个隐藏单元似乎对应于奥斯卡奖得主，第二个隐藏单元似乎对应于 SF/奇幻电影，正如我们所希望的那样。</p> 
 <p style="text-align:left;">如果我们给 RBM 一个新用户 George，他将 （Harry Potter = 0， Avatar = 0， LOTR 3 = 0， Gladiator = 1， Titanic = 1， Glitter = 0） 作为他的偏好，会发生什么？它打开了奥斯卡奖得主单元（但不是 SF/奇幻单元），正确地猜测乔治可能喜欢奥斯卡奖得主的电影。</p> 
 <p style="text-align:left;">如果我们只激活 SF/幻想单元，并运行一系列不同的 RBM，会发生什么？在我的试验中，它打开了哈利波特、阿凡达和 LOTR 3 三次;它打开了《阿凡达》和《LOTR 3》，但没有打开《哈利波特》一次;它打开了哈利波特和 LOTR 3，但没有打开阿凡达，两次。请注意，根据我们的训练示例，这些生成的偏好确实符合我们期望真正的 SF/奇幻粉丝想要观看的内容。</p> 
 <pre class="has"><code class="language-ruby"># 导入未来模块，用于兼容不同版本的Python
from __future__ import print_function
# 导入numpy库，用于科学计算
import numpy as np


# 定义一个类，表示受限玻尔兹曼机
class RBM:
    # 定义初始化方法，接受可见层单元数和隐藏层单元数作为参数
    def __init__(self, num_visible, num_hidden):
        # 将隐藏层单元数和可见层单元数赋值给类的属性
        self.num_hidden = num_hidden
        self.num_visible = num_visible
        # 设置一个调试打印的标志，用于控制是否打印训练信息
        self.debug_print = True


        # 创建一个随机数生成器，指定随机种子为1234
        np_rng = np.random.RandomState(1234)


        # 创建一个权重矩阵，用于存储可见层和隐藏层之间的连接权重
        # 权重矩阵的形状为(num_visible, num_hidden)，即每一列对应一个隐藏单元，每一行对应一个可见单元
        # 权重矩阵的初始值为均匀分布在[-0.1 * np.sqrt(6. / (num_hidden + num_visible)),
        # 0.1 * np.sqrt(6. / (num_hidden + num_visible))]之间的随机数，这个范围是根据论文中的建议选择的
        self.weights = np.asarray(np_rng.uniform(
                low=-0.1 * np.sqrt(6. / (num_hidden + num_visible)),
                            high=0.1 * np.sqrt(6. / (num_hidden + num_visible)),
                            size=(num_visible, num_hidden)))




        # 在权重矩阵的第一行和第一列插入零，用于表示偏置单元的权重
        # 偏置单元是一种特殊的单元，它的值始终为1，用于增加模型的灵活性
        # 第一行的权重表示隐藏层的偏置，第一列的权重表示可见层的偏置
        self.weights = np.insert(self.weights, 0, 0, axis = 0)
        self.weights = np.insert(self.weights, 0, 0, axis = 1)


    # 定义一个训练方法，接受数据，最大训练轮数，学习率等参数
    def train(self, data, max_epochs = 1000, learning_rate = 0.1):
        # 获取数据的样本数，即第一个维度的大小
        num_examples = data.shape[0]


        # 在数据的第一列插入1，用于表示偏置单元的值
        data = np.insert(data, 0, 1, axis = 1)


        # 遍历训练轮数
        for epoch in range(max_epochs):      
            # 将数据作为可见层的状态，计算隐藏层的激活值
            # 这是正向传播的过程，也称为正相对比散度阶段，或者现实阶段
            # 激活值等于数据与权重矩阵的点积，形状为(num_examples, num_hidden + 1)
            pos_hidden_activations = np.dot(data, self.weights)      
            # 计算隐藏层的激活概率，即隐藏层的单元以一定的概率被激活（取值为1）
            # 激活概率是通过逻辑斯蒂函数（或称为Sigmoid函数）计算的，它可以将任意值映射到(0,1)之间
            # 形状仍为(num_examples, num_hidden + 1)
            pos_hidden_probs = self._logistic(pos_hidden_activations)
            # 将第一列的激活概率设为1，用于表示偏置单元的值
            pos_hidden_probs[:,0] = 1 # Fix the bias unit.
            # 根据隐藏层的激活概率，生成隐藏层的状态
            # 隐藏层的状态是一个二值的矩阵，形状为(num_examples, num_hidden + 1)
            # 隐藏层的状态等于激活概率是否大于一个随机数，如果大于则为1，否则为0
            pos_hidden_states = pos_hidden_probs &gt; np.random.rand(num_examples, self.num_hidden + 1)
            # 注意，我们在计算关联矩阵时，使用的是隐藏层的激活概率，而不是隐藏层的状态
            # 我们也可以使用状态，具体可以参考Hinton的论文《A Practical Guide to Training Restricted Boltzmann Machines》的第三节
            # 关联矩阵是可见层和隐藏层的状态的外积，形状为(num_visible + 1, num_hidden + 1)
            pos_associations = np.dot(data.T, pos_hidden_probs)


            # 从隐藏层的状态重构可见层的激活值
            # 这是反向传播的过程，也称为负相对比散度阶段，或者梦境阶段
            # 激活值等于隐藏层的状态与权重矩阵的转置的点积，形状为(num_examples, num_visible + 1)
            neg_visible_activations = np.dot(pos_hidden_states, self.weights.T)
            # 计算可见层的激活概率，即可见层的单元以一定的概率被激活（取值为1）
            # 激活概率是通过逻辑斯蒂函数（或称为Sigmoid函数）计算的，它可以将任意值映射到(0,1)之间
            # 形状仍为(num_examples, num_visible + 1)
            neg_visible_probs = self._logistic(neg_visible_activations)
            # 将第一列的激活概率设为1，用于表示偏置单元的值
            neg_visible_probs[:,0] = 1 # Fix the bias unit.
            # 从可见层的激活概率计算隐藏层的激活值
            # 激活值等于可见层的激活概率与权重矩阵的点积，形状为(num_examples, num_hidden + 1)
            neg_hidden_activations = np.dot(neg_visible_probs, self.weights)
            # 计算隐藏层的激活概率，即隐藏层的单元以一定的概率被激活（取值为1）
            # 激活概率是通过逻辑斯蒂函数（或称为Sigmoid函数）计算的，它可以将任意值映射到(0,1)之间
            # 形状仍为(num_examples, num_hidden + 1)
            neg_hidden_probs = self._logistic(neg_hidden_activations)
            # 注意，我们在计算关联矩阵时，使用的是可见层和隐藏层的激活概率，而不是状态
            # 关联矩阵是可见层和隐藏层的激活概率的外积，形状为(num_visible + 1, num_hidden + 1)
            neg_associations = np.dot(neg_visible_probs.T, neg_hidden_probs)


            # 更新权重矩阵
            # 权重矩阵的更新量等于学习率乘以正相关联矩阵减去负相关联矩阵，再除以样本数
            # 这样可以使得正相的概率增大，负相的概率减小，从而最大化数据的似然度
            # 更新权重矩阵，使用学习率、正相联和负相联的差值除以样本数作为增量
            self.weights += learning_rate * ((pos_associations - neg_associations) / num_examples)


            # 计算误差，使用数据和负可见概率的差的平方和
            error = np.sum((data - neg_visible_probs) ** 2)
            # 如果开启了调试打印，打印出每个迭代的误差
            if self.debug_print:
                print("Epoch %s: error is %s" % (epoch, error))




    # 定义一个方法，用于从可见层运行网络，得到隐藏层的状态
    def run_visible(self, data):
        # 获取样本数
        num_examples = data.shape[0]
        
        # 创建一个矩阵，每一行是一个训练样本对应的隐藏单元（加上一个偏置单元）
        hidden_states = np.ones((num_examples, self.num_hidden + 1))
        
        # 在数据的第一列插入偏置单元，值为1
        data = np.insert(data, 0, 1, axis = 1)


        # 计算隐藏单元的激活值
        hidden_activations = np.dot(data, self.weights)
        # 计算隐藏单元被激活的概率
        hidden_probs = self._logistic(hidden_activations)
        # 根据概率随机激活隐藏单元
        hidden_states[:,:] = hidden_probs &gt; np.random.rand(num_examples, self.num_hidden + 1)
        # 始终将偏置单元设置为1
        # hidden_states[:,0] = 1


        # 忽略偏置单元
        hidden_states = hidden_states[:,1:]
        return hidden_states
    
    # 定义一个方法，用于从隐藏层运行网络，得到可见层的状态
    # TODO: 去除这个方法和`run_visible`之间的代码重复？
    def run_hidden(self, data):
        # 获取样本数
        num_examples = data.shape[0]


        # 创建一个矩阵，每一行是一个训练样本对应的可见单元（加上一个偏置单元）
        visible_states = np.ones((num_examples, self.num_visible + 1))


        # 在数据的第一列插入偏置单元，值为1
        data = np.insert(data, 0, 1, axis = 1)


        # 计算可见单元的激活值
        visible_activations = np.dot(data, self.weights.T)
        # 计算可见单元被激活的概率
        visible_probs = self._logistic(visible_activations)
        # 根据概率随机激活可见单元
        visible_states[:,:] = visible_probs &gt; np.random.rand(num_examples, self.num_visible + 1)
        # 始终将偏置单元设置为1
        # visible_states[:,0] = 1


        # 忽略偏置单元
        visible_states = visible_states[:,1:]
        return visible_states
    
    # 定义一个方法，用于生成梦境样本，即从网络中随机抽取可见层的状态
    def daydream(self, num_samples):
        # 创建一个矩阵，每一行是一个可见单元（加上一个偏置单元）的样本
        samples = np.ones((num_samples, self.num_visible + 1))


        # 从均匀分布中取第一个样本
        samples[0,1:] = np.random.rand(self.num_visible)


        # 开始交替的吉布斯采样
        # 注意，我们保持隐藏单元的二进制状态，但是将可见单元作为实数概率
        # 参见 Hinton 的 "A Practical Guide to Training Restricted Boltzmann Machines" 的第三节
        # 了解更多原因
        for i in range(1, num_samples):
            visible = samples[i-1,:]


            # 计算隐藏单元的激活值
            hidden_activations = np.dot(visible, self.weights)      
            # 计算隐藏单元被激活的概率
            hidden_probs = self._logistic(hidden_activations)
            # 根据概率随机激活隐藏单元
            hidden_states = hidden_probs &gt; np.random.rand(self.num_hidden + 1)
            # 始终将偏置单元设置为1
            hidden_states[0] = 1


            # 重新计算可见单元被激活的概率
            visible_activations = np.dot(hidden_states, self.weights.T)
            visible_probs = self._logistic(visible_activations)
            visible_states = visible_probs &gt; np.random.rand(self.num_visible + 1)
            samples[i,:] = visible_states


        # 忽略偏置单元（第一列），因为它们总是被设置为1
        return samples[:,1:]                                         
                                       
# 判断是否是主模块，如果是，则执行以下代码
if __name__ == '__main__':
    # 创建一个受限玻尔兹曼机的实例，指定可见层单元数为6，隐藏层单元数为2
    r = RBM(num_visible = 6, num_hidden = 2)
    # 创建一个训练数据的数组，每一行是一个样本，每一列是一个特征
    # 这里的数据是一个二值的矩阵，表示6个特征的存在或缺失
    training_data = np.array([[1,1,1,0,0,0],[1,0,1,0,0,0],[1,1,1,0,0,0],[0,0,1,1,1,0], [0,0,1,1,0,0],[0,0,1,1,1,0]])
    # 调用训练方法，指定最大训练轮数为5000
    r.train(training_data, max_epochs = 5000)
    # 打印出训练后的权重矩阵
    print(r.weights)
    # 创建一个用户数据的数组，表示一个新的样本
    user = np.array([[0,0,0,1,1,0]])
    # 打印出从可见层运行网络得到的隐藏层的状态
    print(r.run_visible(user))</code></pre> 
 <p><strong>输出结果：</strong></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/66/e7/meVQTWd9_o.png" alt="a02cf3b28e5c85960fe24bd6de98a550.png"></p> 
 <p><strong>5.2 深度玻尔兹曼机</strong><br></p> 
 <p style="text-align:left;">深度玻尔兹曼机（Deep Boltzmann Machine，DBM）是一种基于能量的生成模型，它可以用来学习复杂数据的概率分布。DBM由多层隐变量组成，每层隐变量之间没有连接，但是每层隐变量都与下一层可见变量或上一层隐变量相连。DBM的最底层是可见层，它表示观测到的数据，例如图像、文本或音频。DBM的目标是最大化数据的对数似然，即让模型生成的数据尽可能接近真实数据。DBM的训练过程涉及到两个阶段：预训练和微调。预训练是使用贪婪逐层算法，将每两层隐变量视为一个受限玻尔兹曼机（Restricted Boltzmann Machine，RBM），并用对比散度（Contrastive Divergence，CD）算法进行无监督学习。微调是使用随机最大似然（Stochastic Maximum Likelihood，SML）算法，对整个模型进行联合优化，以提高模型的泛化能力。</p> 
 <p style="text-align:left;">DBM具有以下几个优点：</p> 
 <ul><li><p>DBM可以从高维、非线性、非高斯的数据中学习出抽象的特征表示，从而实现数据的降维和特征提取。</p></li><li><p>DBM可以用于生成新的数据样本，例如生成新的图像或文本，从而实现数据的增强和创造。</p></li><li><p>DBM可以用于多种任务，例如分类、回归、聚类、协同过滤、推荐系统等，只需在模型的顶层添加一个适当的输出层即可。</p></li></ul> 
 <p style="text-align:left;">DBM也有以下几个缺点：</p> 
 <ul><li><p>DBM的训练过程比较复杂和耗时，需要大量的计算资源和数据量。</p></li><li><p>DBM的训练过程涉及到很多超参数的选择，例如学习率、批量大小、采样步数、正则化项等，这些超参数对模型的性能有很大的影响，但是很难确定最优的值。</p></li><li><p>DBM的理论分析比较困难，很多性质和定理还没有得到严格的证明，例如模型的收敛性、稳定性、可解释性等</p></li></ul> 
 <p><strong>5.3 深度置信网</strong></p> 
 <p>深度置信网（Deep Belief Network，DBN）是一种基于图模型的生成模型，它由多层受限玻尔兹曼机（RBM）堆叠而成。DBN的最底层是可见层，它表示观测到的数据，例如图像、文本或音频。DBN的最顶层是一个无向图，它表示数据的高层抽象特征。DBN的中间层是有向图，它表示数据的中间层特征。DBN的目标是最大化数据的对数似然，即让模型生成的数据尽可能接近真实数据。DBN的训练过程涉及到两个阶段：预训练和微调。预训练是使用贪婪逐层算法，将每两层视为一个RBM，并用CD算法进行无监督学习。微调是使用反向传播（Backpropagation，BP）算法，对整个模型进行有监督学习，以提高模型的泛化能力。</p> 
 <p>DBN具有以下几个优点：</p> 
 <ul><li><p>DBN可以从高维、非线性、非高斯的数据中学习出抽象的特征表示，从而实现数据的降维和特征提取。</p></li><li><p>DBN可以用于生成新的数据样本，例如生成新的图像或文本，从而实现数据的增强和创造。</p></li><li><p>DBN可以用于多种任务，例如分类、回归、聚类、协同过滤、推荐系统等，只需在模型的顶层添加一个适当的输出层即可。</p></li></ul> 
 <p>DBN也有以下几个缺点：</p> 
 <ul><li><p>DBN的训练过程比较复杂和耗时，需要大量的计算资源和数据量。</p></li><li><p>DBN的训练过程涉及到很多超参数的选择，例如学习率、批量大小、采样步数、正则化项等，这些超参数对模型的性能有很大的影响，但是很难确定最优的值。</p></li><li><p>DBN的理论分析比较困难，很多性质和定理还没有得到严格的证明，例如模型的收敛性、稳定性、可解释性等</p></li></ul> 
 <p><strong>附录：</strong></p> 
 <p><strong>受限玻尔兹曼机应用场景</strong></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/30/84/z89DobsC_o.png" alt="a5beb9b5b283ab132f8a7c152b5b1ce6.png"></p> 
 <p><strong>各种激活函数的优缺点</strong><br></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/41/a7/A7uBmYWm_o.png" alt="e1100bf2fbb47f081b8343292fe5f731.png"></p> 
 <p>各种激活函数各有优缺点，在深度学习中都有其适用场景。</p> 
 <ul><li><p>Sigmoid和Tanh函数是传统的激活函数，具有输出范围有限、优化稳定等优点，但容易过饱和，梯度弥散。</p></li><li><p>ReLU函数是近年来流行的激活函数，具有计算速度快、容易训练等优点，但容易发生“死神经元”问题。</p></li><li><p>Leaky ReLU、ELU和SELU等函数是ReLU函数的改进版本，解决了“死神经元”问题。</p></li><li><p>softmax函数常用于多分类任务，可以用来输出概率分布</p></li></ul> 
 <p><strong>参考网址</strong></p> 
 <p>https://blog.echen.me/2011/07/18/introduction-to-restricted-boltzmann-machines/</p> 
 <p>https://github.com/python-pillow/Pillow/ Python 图像库 </p> 
 <p>https://blog.echen.me/2011/07/18/introduction-to-restricted-boltzmann-machines/ 受限玻尔兹曼机简介 (echen.me)</p> 
 <p style="text-align:center;">The End</p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d16e6f97440d353bc09a9de3b8c9aa55/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">安徽某高校《R语言与统计建模》期末上机题复习</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f395acb18e329e456e7fb1ddab69c181/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">干了这么多年CRUD，你真的会处理异常吗？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>