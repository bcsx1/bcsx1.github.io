<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark--优化 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Spark--优化" />
<meta property="og:description" content="Spark--优化 总结：优化方向RDD/代码调优1.尽可能复用RDD2.保证对一个RDD执行多次算子操作时，这个RDD本身仅仅被计算一次。3.尽量避免使用shuffle类算子4.使用高性能的算子5.广播变量 参数调优1.num-executors →==executors数量==2.executor-memory→==executors内存==3.executor-cores→==executors核数==4.driver-memory →==driver端的内存==5,spark.default.parallelism →`每个stage的默认task数量`6.spark.storage.memoryFraction→==rdd持久化占内存比例==7.spark.shuffle.memoryFraction→==聚合所占比例== 0.spark程序的执行流程1.关于RDD的相关调优1.避免创建重复的RDD2.尽可能复用同一个RDD3.对多次使用的RDD进行持久化4.尽量避免使用shuffle类算子5.使用map-side预聚合的shuffle操作6.使用高性能的算子使用reduceByKey/aggregateByKey替代groupByKey使用mapPartitions替代普通map使用foreachPartitions替代foreach使用filter之后进行coalesce操作使用repartitionAndSortWithinPartitions替代repartition与sort类操作 7.广播变量 2.资源参数调优1.num-executors →==executors数量==2.executor-memory→==executors内存==3.executor-cores→==executors核数==4.driver-memory →==driver端的内存==5,spark.default.parallelism →`每个stage的默认task数量`6.spark.storage.memoryFraction→==rdd持久化占内存比例==7.spark.shuffle.memoryFraction→==聚合所占比例== 总结：优化方向 RDD/代码调优 1.尽可能复用RDD 避免创建重复的RDD尽可能复用同一个RDD 2.保证对一个RDD执行多次算子操作时，这个RDD本身仅仅被计算一次。 对多次使用的RDD进行持久化。 3.尽量避免使用shuffle类算子 涉及到宽窄依赖的划分涉及到拉取数据能避免则尽可能避免使用reduceByKey、join、distinct、repartition等会进行shuffle的算子，尽量使用map类的非shuffle算子。reduceByKey代替groupByKey，map进行聚合，减少数据传输 4.使用高性能的算子 使用reduceByKey/aggregateByKey替代groupByKey使用mapPartitions替代普通map使用foreachPartitions替代foreach使用filter之后进行coalesce操作 5.广播变量 相当于在每个executor中只驻留一份变量副本，task共享，不需要在去driver端拉取，减少数据传输。 参数调优 1.num-executors →executors数量 2.executor-memory→executors内存 3.executor-cores→executors核数 4.driver-memory →driver端的内存 5,spark.default.parallelism →每个stage的默认task数量 6.spark.storage.memoryFraction→rdd持久化占内存比例 7.spark.shuffle.memoryFraction→聚合所占比例 0.spark程序的执行流程 1.关于RDD的相关调优 1.避免创建重复的RDD 对于同一份数据，只应该创建一个RDD，不能创建多个RDD来代表同一份数据。 // 需要对名为“hello.txt”的HDFS文件进行一次map操作，再进行一次reduce操作。也就是说，需要对一份数据执行两次算子操作。 // 错误的做法：对于同一份数据执行多次算子操作时，创建多个RDD。 // 这里执行了两次textFile方法，针对同一个HDFS文件，创建了两个RDD出来，然后分别对每个RDD都执行了一个算子操作。 // 这种情况下，Spark需要从HDFS上两次加载hello.txt文件的内容，并创建两个单独的RDD；第二次加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。 val rdd1 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd1.map(...) val rdd2 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd2.reduce(...) // 正确的用法：对于一份数据执行多次算子操作时，只使用一个RDD。 // 这种写法很明显比上一种写法要好多了，因为我们对于同一份数据只创建了一个RDD，然后对这一个RDD执行了多次算子操作。 // 但是要注意到这里为止优化还没有结束，由于rdd1被执行了两次算子操作，第二次执行reduce操作的时候，还会再次从源头处重新计算一次rdd1的数据，因此还是会有重复计算的性能开销。 // 要彻底解决这个问题，必须结合“原则三：对多次使用的RDD进行持久化”，才能保证一个RDD被多次使用时只被计算一次。 val rdd1 = sc.textFile(&#34;hdfs://192.168.0.1:9000/hello.txt&#34;) rdd1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/749c3966f54a168e52e4f6e1bba58f31/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-03T19:39:29+08:00" />
<meta property="article:modified_time" content="2023-12-03T19:39:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark--优化</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>Spark--优化</h4> 
 <ul><li><a href="#_1" rel="nofollow">总结：优化方向</a></li><li><ul><li><a href="#RDD_2" rel="nofollow">RDD/代码调优</a></li><li><ul><li><a href="#1RDD_3" rel="nofollow">1.尽可能复用RDD</a></li><li><a href="#2RDDRDD_6" rel="nofollow">2.保证对一个RDD执行多次算子操作时，这个RDD本身仅仅被计算一次。</a></li><li><a href="#3shuffle_8" rel="nofollow">3.尽量避免使用shuffle类算子</a></li><li><a href="#4_13" rel="nofollow">4.使用高性能的算子</a></li><li><a href="#5_18" rel="nofollow">5.广播变量</a></li></ul> 
   </li><li><a href="#_21" rel="nofollow">参数调优</a></li><li><ul><li><a href="#1numexecutors__executors_22" rel="nofollow">1.num-executors →==executors数量==</a></li><li><a href="#2executormemoryexecutors_23" rel="nofollow">2.executor-memory→==executors内存==</a></li><li><a href="#3executorcoresexecutors_24" rel="nofollow">3.executor-cores→==executors核数==</a></li><li><a href="#4drivermemory_driver_25" rel="nofollow">4.driver-memory →==driver端的内存==</a></li><li><a href="#5sparkdefaultparallelism_stagetask_26" rel="nofollow">5,spark.default.parallelism →`每个stage的默认task数量`</a></li><li><a href="#6sparkstoragememoryFractionrdd_27" rel="nofollow">6.spark.storage.memoryFraction→==rdd持久化占内存比例==</a></li><li><a href="#7sparkshufflememoryFraction_28" rel="nofollow">7.spark.shuffle.memoryFraction→==聚合所占比例==</a></li></ul> 
  </li></ul> 
  </li><li><a href="#0spark_29" rel="nofollow">0.spark程序的执行流程</a></li><li><a href="#1RDD_33" rel="nofollow">1.关于RDD的相关调优</a></li><li><ul><li><a href="#1RDD_34" rel="nofollow">1.避免创建重复的RDD</a></li><li><a href="#2RDD_57" rel="nofollow">2.尽可能复用同一个RDD</a></li><li><a href="#3RDD_89" rel="nofollow">3.对多次使用的RDD进行持久化</a></li><li><a href="#4shuffle_115" rel="nofollow">4.尽量避免使用shuffle类算子</a></li><li><a href="#5mapsideshuffle_117" rel="nofollow">5.使用map-side预聚合的shuffle操作</a></li><li><a href="#6_125" rel="nofollow">6.使用高性能的算子</a></li><li><ul><li><a href="#reduceByKeyaggregateByKeygroupByKey_126" rel="nofollow">使用reduceByKey/aggregateByKey替代groupByKey</a></li><li><a href="#mapPartitionsmap_128" rel="nofollow">使用mapPartitions替代普通map</a></li><li><a href="#foreachPartitionsforeach_130" rel="nofollow">使用foreachPartitions替代foreach</a></li><li><a href="#filtercoalesce_133" rel="nofollow">使用filter之后进行coalesce操作</a></li><li><a href="#repartitionAndSortWithinPartitionsrepartitionsort_135" rel="nofollow">使用repartitionAndSortWithinPartitions替代repartition与sort类操作</a></li></ul> 
   </li><li><a href="#7_137" rel="nofollow">7.广播变量</a></li></ul> 
  </li><li><a href="#2_156" rel="nofollow">2.资源参数调优</a></li><li><ul><li><a href="#1numexecutors__executors_157" rel="nofollow">1.num-executors →==executors数量==</a></li><li><a href="#2executormemoryexecutors_160" rel="nofollow">2.executor-memory→==executors内存==</a></li><li><a href="#3executorcoresexecutors_163" rel="nofollow">3.executor-cores→==executors核数==</a></li><li><a href="#4drivermemory_driver_166" rel="nofollow">4.driver-memory →==driver端的内存==</a></li><li><a href="#5sparkdefaultparallelism_stagetask_170" rel="nofollow">5,spark.default.parallelism →`每个stage的默认task数量`</a></li><li><a href="#6sparkstoragememoryFractionrdd_174" rel="nofollow">6.spark.storage.memoryFraction→==rdd持久化占内存比例==</a></li><li><a href="#7sparkshufflememoryFraction_178" rel="nofollow">7.spark.shuffle.memoryFraction→==聚合所占比例==</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>总结：优化方向</h2> 
<h3><a id="RDD_2"></a>RDD/代码调优</h3> 
<h4><a id="1RDD_3"></a>1.尽可能复用RDD</h4> 
<ul><li><code>避免创建重复的RDD</code></li><li><code>尽可能复用同一个RDD</code></li></ul> 
<h4><a id="2RDDRDD_6"></a>2.保证对一个RDD执行多次算子操作时，这个RDD本身仅仅被计算一次。</h4> 
<ul><li>对多次使用的RDD进行<code>持久化</code>。</li></ul> 
<h4><a id="3shuffle_8"></a>3.尽量避免使用shuffle类算子</h4> 
<ul><li><code>涉及到宽窄依赖的划分</code></li><li><code>涉及到拉取数据</code></li><li>能避免则尽可能<code>避免</code>使用<code>reduceByKey、join、distinct、repartition</code>等会进行shuffle的算子，尽量使用map类的非shuffle算子。</li><li><code>reduceByKey代替groupByKey</code>，map进行聚合，减少数据传输</li></ul> 
<h4><a id="4_13"></a>4.使用高性能的算子</h4> 
<ul><li>使用<code>reduceByKey/aggregateByKey</code>替代<code>groupByKey</code></li><li>使用<code>mapPartitions</code>替代<code>普通map</code></li><li>使用<code>foreachPartitions</code>替代<code>foreach</code></li><li>使用<code>filter之后进行coalesce</code>操作</li></ul> 
<h4><a id="5_18"></a>5.广播变量</h4> 
<ul><li>相当于在每个executor中只驻留一份变量副本，task共享，不需要在去driver端拉取，减少数据传输。</li></ul> 
<h3><a id="_21"></a>参数调优</h3> 
<h4><a id="1numexecutors__executors_22"></a>1.num-executors →<mark>executors数量</mark></h4> 
<h4><a id="2executormemoryexecutors_23"></a>2.executor-memory→<mark>executors内存</mark></h4> 
<h4><a id="3executorcoresexecutors_24"></a>3.executor-cores→<mark>executors核数</mark></h4> 
<h4><a id="4drivermemory_driver_25"></a>4.driver-memory →<mark>driver端的内存</mark></h4> 
<h4><a id="5sparkdefaultparallelism_stagetask_26"></a>5,spark.default.parallelism →<code>每个stage的默认task数量</code></h4> 
<h4><a id="6sparkstoragememoryFractionrdd_27"></a>6.spark.storage.memoryFraction→<mark>rdd持久化占内存比例</mark></h4> 
<h4><a id="7sparkshufflememoryFraction_28"></a>7.spark.shuffle.memoryFraction→<mark>聚合所占比例</mark></h4> 
<h2><a id="0spark_29"></a>0.spark程序的执行流程</h2> 
<p><img src="https://images2.imgbox.com/09/b5/4duvyveX_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="1RDD_33"></a>1.关于RDD的相关调优</h2> 
<h3><a id="1RDD_34"></a>1.避免创建重复的RDD</h3> 
<ul><li><code>对于同一份数据，只应该创建一个RDD</code>，不能创建多个RDD来代表同一份数据。</li></ul> 
<pre><code class="prism language-scala"><span class="token comment">// 需要对名为“hello.txt”的HDFS文件进行一次map操作，再进行一次reduce操作。也就是说，需要对一份数据执行两次算子操作。</span>
 
<span class="token comment">// 错误的做法：对于同一份数据执行多次算子操作时，创建多个RDD。</span>
<span class="token comment">// 这里执行了两次textFile方法，针对同一个HDFS文件，创建了两个RDD出来，然后分别对每个RDD都执行了一个算子操作。</span>
<span class="token comment">// 这种情况下，Spark需要从HDFS上两次加载hello.txt文件的内容，并创建两个单独的RDD；第二次加载HDFS文件以及创建RDD的性能开销，很明显是白白浪费掉的。</span>
<span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"hdfs://192.168.0.1:9000/hello.txt"</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"hdfs://192.168.0.1:9000/hello.txt"</span><span class="token punctuation">)</span>
rdd2<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
 
<span class="token comment">// 正确的用法：对于一份数据执行多次算子操作时，只使用一个RDD。</span>
<span class="token comment">// 这种写法很明显比上一种写法要好多了，因为我们对于同一份数据只创建了一个RDD，然后对这一个RDD执行了多次算子操作。</span>
<span class="token comment">// 但是要注意到这里为止优化还没有结束，由于rdd1被执行了两次算子操作，第二次执行reduce操作的时候，还会再次从源头处重新计算一次rdd1的数据，因此还是会有重复计算的性能开销。</span>
<span class="token comment">// 要彻底解决这个问题，必须结合“原则三：对多次使用的RDD进行持久化”，才能保证一个RDD被多次使用时只被计算一次。</span>
<span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"hdfs://192.168.0.1:9000/hello.txt"</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="2RDD_57"></a>2.尽可能复用同一个RDD</h3> 
<ul><li>比如说，<code>有一个RDD的数据格式是key-value类型的，另一个是单value类型的，这两个RDD的value数据是完全一样的</code>。那么此时我们<code>可以只使用key-value类型的那个RDD，因为其中已经包含了另一个的数据</code>。对于类似这种多个RDD的数据有重叠或者包含的情况，我们应该尽量复用一个RDD，这样可以<code>尽可能地减少RDD的数量，从而尽可能减少算子执行的次数</code>。</li></ul> 
<pre><code class="prism language-scala"><span class="token comment">// 错误的做法。</span>
 
<span class="token comment">// 有一个&lt;Long, String&gt;格式的RDD，即rdd1。</span>
<span class="token comment">// 接着由于业务需要，对rdd1执行了一个map操作，创建了一个rdd2，而rdd2中的数据仅仅是rdd1中的value值而已，也就是说，rdd2是rdd1的子集。</span>
JavaPairRDD<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> rdd1 <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
JavaRDD<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> rdd2 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
 
<span class="token comment">// 分别对rdd1和rdd2执行了不同的算子操作。</span>
rdd1<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
rdd2<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
 
<span class="token comment">// 正确的做法。</span>
 
<span class="token comment">// 上面这个case中，其实rdd1和rdd2的区别无非就是数据格式不同而已，rdd2的数据完全就是rdd1的子集而已，却创建了两个rdd，并对两个rdd都执行了一次算子操作。</span>
<span class="token comment">// 此时会因为对rdd1执行map算子来创建rdd2，而多执行一次算子操作，进而增加性能开销。</span>
 
<span class="token comment">// 其实在这种情况下完全可以复用同一个RDD。</span>
<span class="token comment">// 我们可以使用rdd1，既做reduceByKey操作，也做map操作。</span>
<span class="token comment">// 在进行第二个map操作时，只使用每个数据的tuple._2，也就是rdd1中的value值，即可。</span>
JavaPairRDD<span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> rdd1 <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
rdd1<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>tuple<span class="token punctuation">.</span>_2<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
 
<span class="token comment">// 第二种方式相较于第一种方式而言，很明显减少了一次rdd2的计算开销。</span>
<span class="token comment">// 但是到这里为止，优化还没有结束，对rdd1我们还是执行了两次算子操作，rdd1实际上还是会被计算两次。</span>
<span class="token comment">// 因此还需要配合“原则三：对多次使用的RDD进行持久化”进行使用，才能保证一个RDD被多次使用时只被计算一次。</span>
</code></pre> 
<h3><a id="3RDD_89"></a>3.对多次使用的RDD进行持久化</h3> 
<pre><code class="prism language-scala"><span class="token comment">// 如果要对一个RDD进行持久化，只要对这个RDD调用cache()和persist()即可。</span>
 
<span class="token comment">// 正确的做法。</span>
<span class="token comment">// cache()方法表示：使用非序列化的方式将RDD中的数据全部尝试持久化到内存中。</span>
<span class="token comment">// 此时再对rdd1执行两次算子操作时，只有在第一次执行map算子时，才会将这个rdd1从源头处计算一次。</span>
<span class="token comment">// 第二次执行reduce算子时，就会直接从内存中提取数据进行计算，不会重复计算一个rdd。</span>
<span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"hdfs://192.168.0.1:9000/hello.txt"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
 
<span class="token comment">// persist()方法表示：手动选择持久化级别，并使用指定的方式进行持久化。</span>
<span class="token comment">// 比如说，StorageLevel.MEMORY_AND_DISK_SER表示，内存充足时优先持久化到内存中，内存不充足时持久化到磁盘文件中。</span>
<span class="token comment">// 而且其中的_SER后缀表示，使用序列化的方式来保存RDD数据，此时RDD中的每个partition都会序列化成一个大的字节数组，然后再持久化到内存或磁盘中。</span>
<span class="token comment">// 序列化的方式可以减少持久化的数据对内存/磁盘的占用量，进而避免内存被持久化数据占用过多，从而发生频繁GC。</span>
<span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"hdfs://192.168.0.1:9000/hello.txt"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>persist<span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_AND_DISK_SER<span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
 
</code></pre> 
<p><img src="https://images2.imgbox.com/ac/44/iBG3dwed_o.png" alt="在这里插入图片描述"></p> 
<ul><li>对于persist()方法而言，我们可以根据不同的业务场景选择不同的持久化级别。</li><li>如果纯内存的级别都无法使用，那么建议使用<code>MEMORY_AND_DISK_SER</code>策略，而不是MEMORY_AND_DISK策略。因为既然到了这一步，就说明RDD的数据量很大，内存无法完全放下。序列化后的数据比较少，可以节省内存和磁盘的空间开销。同时该策略会优先尽量尝试将数据缓存在内存中，内存缓存不下才会写入磁盘。</li></ul> 
<h3><a id="4shuffle_115"></a>4.尽量避免使用shuffle类算子</h3> 
<ul><li>能避免则尽可能避免使用<code>reduceByKey、join、distinct、repartition</code>等会进行shuffle的算子，尽量使用map类的非shuffle算子</li></ul> 
<h3><a id="5mapsideshuffle_117"></a>5.使用map-side预聚合的shuffle操作</h3> 
<ul><li><code>类似于MapReduce中的本地combiner</code>。map-side预聚合之后，<code>每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销</code>。</li><li>reduceByKey和groupByKey进行单词计数。其中第一张图是<code>groupByKey</code>的原理图，可以看到，<code>没有进行任何本地聚合时，所有数据都会在集群节点之间传输</code>；第二张图是<code>reduceByKey</code>的原理图，可以看到，<code>每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。</code></li><li>groupByKey<br> <img src="https://images2.imgbox.com/96/2d/oqwzuiuU_o.png" alt="在这里插入图片描述"></li><li>reduceByKey<br> <img src="https://images2.imgbox.com/18/40/vu60Bz1E_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="6_125"></a>6.使用高性能的算子</h3> 
<h4><a id="reduceByKeyaggregateByKeygroupByKey_126"></a>使用reduceByKey/aggregateByKey替代groupByKey</h4> 
<ul><li>相当于提前聚合，减少数据的传输</li></ul> 
<h4><a id="mapPartitionsmap_128"></a>使用mapPartitions替代普通map</h4> 
<ul><li>mapPartitions类的算子，<code>一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些</code>。但是有的时候，使用mapPartitions会出现<code>OOM</code>（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时<code>要慎重</code>！</li></ul> 
<h4><a id="foreachPartitionsforeach_130"></a>使用foreachPartitions替代foreach</h4> 
<ul><li>原理类似于“使用mapPartitions替代map”，也是<code>一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据</code>。在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。</li><li>比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地<code>创建和销毁数据库连接</code>，性能是非常低下；但是如果用foreachPartitions算子一次性处理一个partition的数据，那么<code>对于每个partition，只要创建一个数据库连接即可</code>，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。</li></ul> 
<h4><a id="filtercoalesce_133"></a>使用filter之后进行coalesce操作</h4> 
<ul><li>通常<code>对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去</code>。因为filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。因此用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。</li></ul> 
<h4><a id="repartitionAndSortWithinPartitionsrepartitionsort_135"></a>使用repartitionAndSortWithinPartitions替代repartition与sort类操作</h4> 
<ul><li>repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。</li></ul> 
<h3><a id="7_137"></a>7.广播变量</h3> 
<ul><li>有时在开发过程中，会遇到需要<code>在算子函数中使用外部变量的场景</code>（尤其是大变量，比如100M以上的大集合），那么此时就应该使用Spark的广播（Broadcast）功能来提升性能。</li><li>在算子函数中使用到外部变量时，默认情况下，Spark会将该变量复制多个副本，通过网络传输到task中，此时每个task都有一个变量副本。如果变量本身比较大的话（比如100M，甚至1G），那么大量的变量副本在网络中传输的性能开销，以及在各个节点的Executor中占用过多内存导致的频繁GC，都会极大地影响性能。</li><li>因此对于上述情况，如果使用的外部变量比较大，建议使用Spark的广播功能，对该变量进行广播。<code>广播后的变量，会保证每个Executor的内存中，只驻留一份变量副本，而Executor中的task执行时共享该Executor中的那份变量副本</code>。这样的话，可以大大减少变量副本的数量，从而减少网络传输的性能开销，并减少对Executor内存的占用开销，降低GC的频率。</li></ul> 
<pre><code class="prism language-scala"><span class="token comment">// 以下代码在算子函数中，使用了外部的变量。</span>
<span class="token comment">// 此时没有做任何特殊操作，每个task都会有一份list1的副本。</span>
<span class="token keyword">val</span> list1 <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>list1<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
 
<span class="token comment">// 以下代码将list1封装成了Broadcast类型的广播变量。</span>
<span class="token comment">// 在算子函数中，使用广播变量时，首先会判断当前task所在Executor内存中，是否有变量副本。</span>
<span class="token comment">// 如果有则直接使用；如果没有则从Driver或者其他Executor节点上远程拉取一份放到本地Executor内存中。</span>
<span class="token comment">// 每个Executor内存中，就只会驻留一份广播变量副本。</span>
<span class="token keyword">val</span> list1 <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">val</span> list1Broadcast <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>list1<span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>list1Broadcast<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="2_156"></a>2.资源参数调优</h2> 
<h3><a id="1numexecutors__executors_157"></a>1.num-executors →<mark>executors数量</mark></h3> 
<ul><li>参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。</li><li>参数调优建议：每个Spark作业的运行一般设置<code>50~100个</code>左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。<code>设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。</code></li></ul> 
<h3><a id="2executormemoryexecutors_160"></a>2.executor-memory→<mark>executors内存</mark></h3> 
<ul><li>参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。</li><li>参数调优建议：每个Executor进程的内存设置<code>4G~8G</code>较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，<code>num-executors乘以executor-memory，是不能超过队列的最大内存量的</code>。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。</li></ul> 
<h3><a id="3executorcoresexecutors_163"></a>3.executor-cores→<mark>executors核数</mark></h3> 
<ul><li>参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。</li><li>参数调优建议：Executor的CPU core数量设置为<code>2~4个</code>较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。</li></ul> 
<h3><a id="4drivermemory_driver_166"></a>4.driver-memory →<mark>driver端的内存</mark></h3> 
<ul><li>参数说明：该参数用于设置Driver进程的内存。</li><li>参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用<code>collect</code>算子将RDD的数据全部拉取到Driver上进行处理，那么<code>必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。</code></li></ul> 
<h3><a id="5sparkdefaultparallelism_stagetask_170"></a>5,spark.default.parallelism →<code>每个stage的默认task数量</code></h3> 
<ul><li>参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。</li><li>参数调优建议：Spark作业的默认task数量为<code>500~1000个</code>较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致<code>Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃</code>。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。</li></ul> 
<h3><a id="6sparkstoragememoryFractionrdd_174"></a>6.spark.storage.memoryFraction→<mark>rdd持久化占内存比例</mark></h3> 
<ul><li>参数说明：该参数用于<code>设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。</code>也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。</li><li>参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</li></ul> 
<h3><a id="7sparkshufflememoryFraction_178"></a>7.spark.shuffle.memoryFraction→<mark>聚合所占比例</mark></h3> 
<ul><li> <p>参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</p> </li><li> <p>参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。资源参数的调优，没有一个固定的值，需要同学们根据自己的实际情况（包括Spark作业中的shuffle操作数量、RDD持久化操作数量以及spark web ui中显示的作业gc情况），同时参考本篇文章中给出的原理以及调优建议，合理地设置上述参数。</p> </li><li> <p>参考自 <a href="https://blog.csdn.net/rlnLo2pNEfx9c/article/details/113874399?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161430876316780255226600%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=161430876316780255226600&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-4-113874399.pc_search_result_cache&amp;utm_term=spark%E4%BC%98%E5%8C%96&amp;spm=1018.2226.3001.4187">https://blog.csdn.net/rlnLo2pNEfx9c/article/details/113874399?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161430876316780255226600%2522%252C%2522scm%2522%253A%252220140713.130102334…%2522%257D&amp;request_id=161430876316780255226600&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2<sub>all</sub>sobaiduend~default-4-113874399.pc_search_result_cache&amp;utm_term=spark%E4%BC%98%E5%8C%96&amp;spm=1018.2226.3001.4187</a></p> </li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/eb45b1817ca558f909c84d1a18f7f2c6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Hbase相关</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b9b3fe636081d96b021b61481ce52411/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">线上学习51单片机最全教程（只需要一台电脑）！！！第一关：点亮第一个led灯</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>