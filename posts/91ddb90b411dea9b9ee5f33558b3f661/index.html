<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>YOLOV5 C&#43;&#43;部署的人员检测项目【学习笔记（十一）】 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="YOLOV5 C&#43;&#43;部署的人员检测项目【学习笔记（十一）】" />
<meta property="og:description" content="文章目录 一、安装Pytorch 及 YOLO v51.1 安装GPU版 pytorch1.2 安装YOLO v5所需依赖 二、YOLO v5训练自定义数据2.1 标注数据2.1.1 安装labelImg2.1.2 标注 2.2 准备数据集2.2.1 组织目录结构2.2.2 创建 dataset.yaml 2.3 选择合适的预训练模型2.4 训练2.5 可视化2.5.1 wandb2.5.2 Tensorboard 2.6 测试评估模型2.6.1 测试2.6.2 评估 三、yolov5模型导出ONNX3.1 工作机制3.2 修改yolov5 代码，输出ONNX3.3 具体修改细节 四、TensorRT部署4.1 模型构建4.2 模型的推理4.3 INT8、FP16量化对比4.3.1 简介4.3.2 TensorRT中实现 4.4 预处理和后处理4.4.1 预处理（Preprocess）4.4.1.1 使用CPU做letterbox、归一化、BGR2RGB、NHWC to NCHW4.4.1.2 使用CPU做letterbox，GPU做归一化、BGR2RGB、NHWC to NCHW4.4.1.3 使用GPU预处理所有步骤 4.4.2 后处理（Postprocess） 4.5人员闯入、聚众的应用开发4.5.1 RTMP推流4.5.2 人员闯入应用开发4.5.3 人员聚众应用开发4.5.4 多线程流水线 4.6 jetson nano 和 jetson xavier NX部署4.6.1 jetson nx4.6.2 jetson nano 五、附录：5.1 CUDA quickstart5." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/91ddb90b411dea9b9ee5f33558b3f661/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-12T12:02:40+08:00" />
<meta property="article:modified_time" content="2023-12-12T12:02:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">YOLOV5 C&#43;&#43;部署的人员检测项目【学习笔记（十一）】</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#Pytorch__YOLO_v5_2" rel="nofollow">一、安装Pytorch 及 YOLO v5</a></li><li><ul><li><a href="#11_GPU_pytorch_4" rel="nofollow">1.1 安装GPU版 pytorch</a></li><li><a href="#12_YOLO_v5_89" rel="nofollow">1.2 安装YOLO v5所需依赖</a></li></ul> 
   </li><li><a href="#YOLO_v5_122" rel="nofollow">二、YOLO v5训练自定义数据</a></li><li><ul><li><a href="#21__124" rel="nofollow">2.1 标注数据</a></li><li><ul><li><a href="#211_labelImg_126" rel="nofollow">2.1.1 安装labelImg</a></li><li><a href="#212__138" rel="nofollow">2.1.2 标注</a></li></ul> 
    </li><li><a href="#22__154" rel="nofollow">2.2 准备数据集</a></li><li><ul><li><a href="#221__156" rel="nofollow">2.2.1 组织目录结构</a></li><li><a href="#222__datasetyaml_183" rel="nofollow">2.2.2 创建 dataset.yaml</a></li></ul> 
    </li><li><a href="#23__199" rel="nofollow">2.3 选择合适的预训练模型</a></li><li><a href="#24__218" rel="nofollow">2.4 训练</a></li><li><a href="#25__233" rel="nofollow">2.5 可视化</a></li><li><ul><li><a href="#251_wandb_235" rel="nofollow">2.5.1 wandb</a></li><li><a href="#252_Tensorboard_247" rel="nofollow">2.5.2 Tensorboard</a></li></ul> 
    </li><li><a href="#26__255" rel="nofollow">2.6 测试评估模型</a></li><li><ul><li><a href="#261__257" rel="nofollow">2.6.1 测试</a></li><li><a href="#262__276" rel="nofollow">2.6.2 评估</a></li></ul> 
   </li></ul> 
   </li><li><a href="#yolov5ONNX_296" rel="nofollow">三、yolov5模型导出ONNX</a></li><li><ul><li><a href="#31__298" rel="nofollow">3.1 工作机制</a></li><li><a href="#32_yolov5_ONNX_310" rel="nofollow">3.2 修改yolov5 代码，输出ONNX</a></li><li><a href="#33__346" rel="nofollow">3.3 具体修改细节</a></li></ul> 
   </li><li><a href="#TensorRT_515" rel="nofollow">四、TensorRT部署</a></li><li><ul><li><a href="#41__523" rel="nofollow">4.1 模型构建</a></li><li><a href="#42__625" rel="nofollow">4.2 模型的推理</a></li><li><a href="#43_INT8FP16_730" rel="nofollow">4.3 INT8、FP16量化对比</a></li><li><ul><li><a href="#431__734" rel="nofollow">4.3.1 简介</a></li><li><a href="#432_TensorRT_754" rel="nofollow">4.3.2 TensorRT中实现</a></li></ul> 
    </li><li><a href="#44__898" rel="nofollow">4.4 预处理和后处理</a></li><li><ul><li><a href="#441_Preprocess_900" rel="nofollow">4.4.1 预处理（Preprocess）</a></li><li><ul><li><a href="#4411_CPUletterboxBGR2RGBNHWC_to_NCHW_966" rel="nofollow">4.4.1.1 使用CPU做letterbox、归一化、BGR2RGB、NHWC to NCHW</a></li><li><a href="#4412_CPUletterboxGPUBGR2RGBNHWC_to_NCHW_997" rel="nofollow">4.4.1.2 使用CPU做letterbox，GPU做归一化、BGR2RGB、NHWC to NCHW</a></li><li><a href="#4413_GPU_1024" rel="nofollow">4.4.1.3 使用GPU预处理所有步骤</a></li></ul> 
     </li><li><a href="#442_Postprocess_1034" rel="nofollow">4.4.2 后处理（Postprocess）</a></li></ul> 
    </li><li><a href="#45_1052" rel="nofollow">4.5人员闯入、聚众的应用开发</a></li><li><ul><li><a href="#451__RTMP_1054" rel="nofollow">4.5.1 RTMP推流</a></li><li><a href="#452___1104" rel="nofollow">4.5.2 人员闯入应用开发</a></li><li><a href="#453___1161" rel="nofollow">4.5.3 人员聚众应用开发</a></li><li><a href="#454___1181" rel="nofollow">4.5.4 多线程流水线</a></li></ul> 
    </li><li><a href="#46_jetson_nano__jetson_xavier_NX_1291" rel="nofollow">4.6 jetson nano 和 jetson xavier NX部署</a></li><li><ul><li><a href="#461_jetson_nx_1293" rel="nofollow">4.6.1 jetson nx</a></li><li><a href="#462_jetson_nano_1410" rel="nofollow">4.6.2 jetson nano</a></li></ul> 
   </li></ul> 
   </li><li><a href="#_1518" rel="nofollow">五、附录：</a></li><li><ul><li><a href="#51_CUDA__quickstart_1520" rel="nofollow">5.1 CUDA quickstart</a></li><li><ul><li><a href="#511__1522" rel="nofollow">5.1.1 简介</a></li><li><a href="#512__blockthread_1540" rel="nofollow">5.1.2 线程块 block、线程thread</a></li><li><a href="#513_kernel__1574" rel="nofollow">5.1.3 kernel 函数</a></li><li><a href="#514__1599" rel="nofollow">5.1.4 代码解释</a></li></ul> 
    </li><li><a href="#52_TensorRT_plugin_1605" rel="nofollow">5.2 TensorRT plugin</a></li><li><ul><li><a href="#521_Yolov5_decode_1613" rel="nofollow">5.2.1 Yolov5 decode流程</a></li><li><a href="#522_plugin_1663" rel="nofollow">5.2.2 plugin基本流程介绍</a></li><li><a href="#523_Plugin_1748" rel="nofollow">5.2.3 Plugin中需要实现的方法介绍</a></li></ul> 
    </li><li><a href="#53_pipeline_Demo_1850" rel="nofollow">5.3 多线程pipeline Demo</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="Pytorch__YOLO_v5_2"></a>一、安装Pytorch 及 YOLO v5</h3> 
<h4><a id="11_GPU_pytorch_4"></a>1.1 安装GPU版 pytorch</h4> 
<ul><li> <p>方法一：conda虚拟环境</p> <p>首先，请参考上一节课将<code>GPU driver, cuda, cudnn</code>先安装完毕。</p> </li></ul> 
<pre><code class="prism language-bash"><span class="token comment"># 使用conda虚拟环境（安装文档：https://docs.conda.io/en/latest/miniconda.html）</span>

<span class="token comment"># 创建conda虚拟环境，参考你选择的版本安装即可</span>

<span class="token comment"># 最新版：https://pytorch.org/get-started/locally/</span>
<span class="token comment"># 历史版本：https://pytorch.org/get-started/previous-versions/</span>
</code></pre> 
<ul><li> <p>方法二：docker 方式（推荐）</p> 
  <blockquote> 
   <p>使用docker主要是因为与主机性能区别不大，且配置简单，只需要安装GPU驱动，不用考虑安装Pytorch指定的CUDA,cuDNN等（容器内部已有）；</p> 
   <p>注意：如果你已经在虚拟机、云GPU、Jetson等平台，则没有必要使用docker。</p> 
  </blockquote> </li></ul> 
<pre><code class="prism language-shell"><span class="token comment"># 安装docker</span>

<span class="token function">sudo</span> <span class="token function">apt-get</span> remove <span class="token function">docker</span> docker-engine docker.io containerd runc

<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token punctuation">\</span>
    ca-certificates <span class="token punctuation">\</span>
    <span class="token function">curl</span> <span class="token punctuation">\</span>
    gnupg <span class="token punctuation">\</span>
    lsb-release

<span class="token function">sudo</span> <span class="token function">mkdir</span> <span class="token parameter variable">-m</span> 0755 <span class="token parameter variable">-p</span> /etc/apt/keyrings
<span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="token operator">|</span> <span class="token function">sudo</span> gpg <span class="token parameter variable">--dearmor</span> <span class="token parameter variable">-o</span> /etc/apt/keyrings/docker.gpg

<span class="token builtin class-name">echo</span> <span class="token punctuation">\</span>
  <span class="token string">"deb [arch=<span class="token variable"><span class="token variable">$(</span>dpkg --print-architecture<span class="token variable">)</span></span> signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  <span class="token variable"><span class="token variable">$(</span>lsb_release <span class="token parameter variable">-cs</span><span class="token variable">)</span></span> stable"</span> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/docker.list <span class="token operator">&gt;</span> /dev/null

<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> nvidia-container2

<span class="token function">sudo</span> systemctl restart <span class="token function">docker</span>

</code></pre> 
<p>具体安装细节可以参考docker文档：https://docs.docker.com/engine/install/ubuntu/。 然后安装<code>nvidia-container-toolkit</code>, 依次运行以下命令</p> 
<pre><code class="prism language-shell"><span class="token assign-left variable">distribution</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">.</span> /etc/os-release<span class="token punctuation">;</span><span class="token builtin class-name">echo</span> $ID$VERSION_ID<span class="token variable">)</span></span> <span class="token punctuation">\</span>
      <span class="token operator">&amp;&amp;</span> <span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://nvidia.github.io/libnvidia-container/gpgkey <span class="token operator">|</span> <span class="token function">sudo</span> gpg <span class="token parameter variable">--dearmor</span> <span class="token parameter variable">-o</span> /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg <span class="token punctuation">\</span>
      <span class="token operator">&amp;&amp;</span> <span class="token function">curl</span> <span class="token parameter variable">-s</span> <span class="token parameter variable">-L</span> https://nvidia.github.io/libnvidia-container/<span class="token variable">$distribution</span>/libnvidia-container.list <span class="token operator">|</span> <span class="token punctuation">\</span>
            <span class="token function">sed</span> <span class="token string">'s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g'</span> <span class="token operator">|</span> <span class="token punctuation">\</span>
            <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/nvidia-container-toolkit.list

<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> nvidia-container-toolkit
</code></pre> 
<p>安装完成后，拉取pytorch镜像以进行测试（这里我们使用pytorch版本为<code>1.12.0a0+2c916ef</code>）：</p> 
<pre><code class="prism language-shell"><span class="token comment"># $(pwd):/app 表示把当前host工作路径挂载到容器的/app目录下</span>
<span class="token comment"># --name env_pyt_1.12 表示容器的名称是env_pyt_1</span>
<span class="token function">docker</span> run <span class="token parameter variable">--gpus</span> all <span class="token parameter variable">-it</span> <span class="token parameter variable">--name</span> env_pyt_1.12 <span class="token parameter variable">-v</span> <span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">pwd</span><span class="token variable">)</span></span>:/app nvcr.io/nvidia/pytorch:22.03-py3 

<span class="token comment"># 容器内部检查pytorch可用性</span>
$ python
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token function">import</span> torch
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> torch.__version__
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> print<span class="token punctuation">(</span>torch.cuda.is_available<span class="token punctuation">(</span><span class="token punctuation">))</span>
True
</code></pre> 
<p>经过漫长的拉取后，我们便可以进入docker的命令行中进行操作。</p> 
<blockquote> 
 <p>在nvidia的NGC container地址中https://catalog.ngc.nvidia.com/containers，我们可以找到很多好用的nvidia container。</p> 
 <p>Vs code 提供的插件可以让我们访问容器内部：<code>ms-vscode-remote.remote-containers</code></p> 
</blockquote> 
<h4><a id="12_YOLO_v5_89"></a>1.2 安装YOLO v5所需依赖</h4> 
<ul><li>安装</li></ul> 
<pre><code class="prism language-shell"><span class="token comment"># 克隆地址</span>
<span class="token function">git</span> clone https://github.com/ultralytics/yolov5.git
<span class="token comment"># 进入目录</span>
<span class="token builtin class-name">cd</span> yolov5	
<span class="token comment"># 选择分支，这里使用了特定版本的yolov5，主要是避免出现兼容问题</span>
<span class="token function">git</span> checkout a80dd66efe0bc7fe3772f259260d5b7278aab42f

<span class="token comment"># 安装依赖（如果是docker环境，要进入容器环境后再安装）</span>
pip3 <span class="token function">install</span> <span class="token parameter variable">-r</span> requirements.txt		
</code></pre> 
<ul><li>下载预训练权重文件</li></ul> 
<p>下载地址：https://github.com/ultralytics/yolov5，附件位置：<code>3.预训练模型/</code>，将权重文件放到<code>weights</code>目录下：</p> 
<ul><li>测试是否安装成功</li></ul> 
<pre><code class="prism language-shell">python detect.py <span class="token parameter variable">--source</span> ./data/images/ <span class="token parameter variable">--weights</span> weights/yolov5s.pt --conf-thres <span class="token number">0.4</span>
</code></pre> 
<blockquote> 
 <p>docker容器内部可能报错：AttributeError: partially initialized module ‘cv2’ has no attribute ‘_registerMatType’ (most likely due to a circular import)，使用<code>pip3 install "opencv-python-headless&lt;4.3"</code></p> 
</blockquote> 
<p>如果一切配置成功，则可以看到以下检测结果</p> 
<img src="https://images2.imgbox.com/83/cf/Iu0HWnVN_o.jpg"> 
<h3><a id="YOLO_v5_122"></a>二、YOLO v5训练自定义数据</h3> 
<h4><a id="21__124"></a>2.1 标注数据</h4> 
<h5><a id="211_labelImg_126"></a>2.1.1 安装labelImg</h5> 
<p>需要在有界面的主机上安装，远程ssh无法使用窗口</p> 
<pre><code class="prism language-shell"><span class="token comment"># 建议使用conda虚拟环境</span>
<span class="token comment"># 安装</span>
pip <span class="token function">install</span> labelImg
<span class="token comment"># 启动</span>
labelImg
</code></pre> 
<h5><a id="212__138"></a>2.1.2 标注</h5> 
<img src="https://images2.imgbox.com/5e/80/tdA5oyrZ_o.jpg"> 
<p>按照视频示例教程进行标注，保存路径下会生成<code>txt</code> YOLO格式标注文件。</p> 
<img src="https://images2.imgbox.com/c0/09/zMF9aLJ1_o.jpg"> 
<img src="https://images2.imgbox.com/67/8c/N5XSJUhs_o.jpg"> 
<ul><li>一张图片对应一个txt标注文件（如果图中无所要物体，则无需txt文件）；</li><li>txt每行一个物体（一张图中可以有多个标注）；</li><li>每行数据格式：<code>类别id、x_center y_center width height</code>；</li><li><strong>xywh</strong>必须归一化（0-1），其中<code>x_center、width</code>除以图片宽度，<code>y_center、height</code>除以画面高度；</li><li>类别id必须从0开始计数。</li></ul> 
<h4><a id="22__154"></a>2.2 准备数据集</h4> 
<h5><a id="221__156"></a>2.2.1 组织目录结构</h5> 
<pre><code class="prism language-bash"><span class="token builtin class-name">.</span> 工作路径
├── datasets
│   └── person_data
│       ├── images
│       │   ├── train
│       │   │   └── demo_001.jpg
│       │   └── val
│       │       └── demo_002.jpg
│       └── labels
│           ├── train
│           │   └── demo_001.txt
│           └── val
│               └── demo_002.txt
└── yolov5
</code></pre> 
<p><strong>要点：</strong></p> 
<ul><li><code>datasets</code>与<code>yolov5</code>同级目录；</li><li>图片 <code>datasets/person_data/images/train/{文件名}.jpg</code>对应的标注文件在 <code>datasets/person_data/labels/train/{文件名}.txt</code>，YOLO会根据这个映射关系自动寻找（<code>images</code>换成<code>labels</code>）；</li><li>训练集和验证集 
  <ul><li><code>images</code>文件夹下有<code>train</code>和<code>val</code>文件夹，分别放置训练集和验证集图片;</li><li><code>labels</code>文件夹有<code>train</code>和<code>val</code>文件夹，分别放置训练集和验证集标签(yolo格式）;</li></ul> </li></ul> 
<h5><a id="222__datasetyaml_183"></a>2.2.2 创建 dataset.yaml</h5> 
<p>复制<code>yolov5/data/coco128.yaml</code>一份，比如为<code>coco_person.yaml</code></p> 
<pre><code class="prism language-yaml"><span class="token comment"># Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]</span>
<span class="token key atrule">path</span><span class="token punctuation">:</span> ../datasets/person_data  <span class="token comment"># 数据所在目录</span>
<span class="token key atrule">train</span><span class="token punctuation">:</span> images/train  <span class="token comment"># 训练集图片所在位置（相对于path）</span>
<span class="token key atrule">val</span><span class="token punctuation">:</span>  images/val <span class="token comment"># 验证集图片所在位置（相对于path）</span>
<span class="token key atrule">test</span><span class="token punctuation">:</span>  <span class="token comment"># 测试集图片所在位置（相对于path）（可选）</span>

<span class="token comment"># 类别</span>
<span class="token key atrule">nc</span><span class="token punctuation">:</span> <span class="token number">5</span>  <span class="token comment"># 类别数量</span>
<span class="token key atrule">names</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'pedestrians'</span><span class="token punctuation">,</span><span class="token string">'riders'</span><span class="token punctuation">,</span><span class="token string">'partially-visible-person'</span><span class="token punctuation">,</span><span class="token string">'ignore-regions'</span><span class="token punctuation">,</span><span class="token string">'crowd'</span><span class="token punctuation">]</span> <span class="token comment"># 类别标签名</span>
</code></pre> 
<h4><a id="23__199"></a>2.3 选择合适的预训练模型</h4> 
<blockquote> 
 <p>官方权重下载地址：https://github.com/ultralytics/yolov5</p> 
</blockquote> 
<img src="https://images2.imgbox.com/10/84/eMQYP2zX_o.jpg"> 
<p>根据你的设备，选择合适的预训练模型，具体模型比对如下：</p> 
<img src="https://images2.imgbox.com/3b/d4/RgEJr2g5_o.jpg"> 
<p>复制<code>models</code>下对应模型的<code>yaml</code>文件，重命名，比如课程另存为<code>yolov5s_person.yaml</code>，并修改其中：</p> 
<pre><code class="prism language-shell"><span class="token comment"># nc: 80  # 类别数量</span>
nc: <span class="token number">5</span>  <span class="token comment"># number of classes</span>
</code></pre> 
<h4><a id="24__218"></a>2.4 训练</h4> 
<p>下载对应的预训练模型权重文件，可以放到<code>weights</code>目录下，设置本机最好性能的各个参数，即可开始训练，课程中训练了以下参数：</p> 
<pre><code class="prism language-shell"><span class="token comment"># yolov5s </span>
python ./train.py <span class="token parameter variable">--data</span> ./data/coco_person.yaml <span class="token parameter variable">--cfg</span> ./models/yolov5s_person.yaml <span class="token parameter variable">--weights</span> ./weights/yolov5s.pt --batch-size <span class="token number">32</span> <span class="token parameter variable">--epochs</span> <span class="token number">120</span> <span class="token parameter variable">--workers</span> <span class="token number">0</span> <span class="token parameter variable">--name</span> s_120 <span class="token parameter variable">--project</span> yolo_person_s
</code></pre> 
<blockquote> 
 <p>更多参数见<code>train.py</code>；</p> 
 <p>训练结果在<code>yolo_person_s/</code>中可见，一般训练时间在几个小时以上。</p> 
</blockquote> 
<h4><a id="25__233"></a>2.5 可视化</h4> 
<h5><a id="251_wandb_235"></a>2.5.1 wandb</h5> 
<p>YOLO官网推荐使用https://wandb.ai/。</p> 
<ul><li>去官网注册账号；</li><li>获取<code>key</code>秘钥，地址：https://wandb.ai/authorize</li><li>使用<code>pip install wandb</code>安装包；</li><li>使用<code>wandb login</code>粘贴秘钥后登录；</li><li>打开网站即可查看训练进展。</li></ul> 
<img src="https://images2.imgbox.com/1f/b0/iNRTaPlL_o.jpg"> 
<h5><a id="252_Tensorboard_247"></a>2.5.2 Tensorboard</h5> 
<p><code>tensorboard --logdir=./yolo_person_s</code></p> 
<img src="https://images2.imgbox.com/bc/b3/cL8XLGgw_o.jpg"> 
<h4><a id="26__255"></a>2.6 测试评估模型</h4> 
<h5><a id="261__257"></a>2.6.1 测试</h5> 
<blockquote> 
 <p>测试媒体位置：<code>4.老师训练结果/</code></p> 
</blockquote> 
<pre><code class="prism language-shell"><span class="token comment"># 如                                                             </span>
python detect.py <span class="token parameter variable">--source</span> ./000057.jpg <span class="token parameter variable">--weights</span> ./yolo_person_s/s_120/weights/best.pt --conf-thres <span class="token number">0.3</span>
<span class="token comment"># 或</span>
python detect.py <span class="token parameter variable">--source</span> ./c3.mp4 <span class="token parameter variable">--weights</span> ./yolo_person_s/s_120/weights/best.pt --conf-thres <span class="token number">0.3</span>
</code></pre> 
<p>检测前后结果：</p> 
<p><img src="https://images2.imgbox.com/0b/a9/Fw4VelKt_o.jpg" alt=""></p> 
<img src="https://images2.imgbox.com/e6/0f/VyxyeEUq_o.jpg"> 
<h5><a id="262__276"></a>2.6.2 评估</h5> 
<pre><code class="prism language-shell"><span class="token comment"># s 模型</span>

<span class="token comment"># python val.py --data  ./data/coco_person.yaml  --weights ./yolo_person_s/s_120/weights/best.pt --batch-size 12</span>
<span class="token comment"># 15.8 GFLOPs</span>
                   Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 
                     all       <span class="token number">1000</span>      <span class="token number">28027</span>      <span class="token number">0.451</span>      <span class="token number">0.372</span>      <span class="token number">0.375</span>      <span class="token number">0.209</span>
             pedestrians       <span class="token number">1000</span>      <span class="token number">17600</span>      <span class="token number">0.738</span>      <span class="token number">0.854</span>      <span class="token number">0.879</span>      <span class="token number">0.608</span>
                  riders       <span class="token number">1000</span>        <span class="token number">185</span>      <span class="token number">0.546</span>      <span class="token number">0.492</span>      <span class="token number">0.522</span>      <span class="token number">0.256</span>
 artially-visible-person       <span class="token number">1000</span>       <span class="token number">9198</span>      <span class="token number">0.461</span>      <span class="token number">0.334</span>      <span class="token number">0.336</span>      <span class="token number">0.125</span>
          ignore-regions       <span class="token number">1000</span>        <span class="token number">391</span>       <span class="token number">0.36</span>      <span class="token number">0.132</span>      <span class="token number">0.116</span>     <span class="token number">0.0463</span>
                   crowd       <span class="token number">1000</span>        <span class="token number">653</span>      <span class="token number">0.152</span>     <span class="token number">0.0468</span>     <span class="token number">0.0244</span>    <span class="token number">0.00841</span>
</code></pre> 
<h3><a id="yolov5ONNX_296"></a>三、yolov5模型导出ONNX</h3> 
<h4><a id="31__298"></a>3.1 工作机制</h4> 
<p>在本项目中，我们将使用<code>tensort decode plugin</code>来代替原来yolov5代码中的decode操作，如果不替换，这部分运算将影响整体性能。</p> 
<p>为了让<code>tensorrt</code>能够识别并加载我们额外添加的<code>plugin operator</code>，我们需要修改Yolov5代码中导出onnx模型的部分。</p> 
<blockquote> 
 <p>onnx是一种开放的模型格式，可以用来表示深度学习模型，它是由微软开发的，目前已经成为了深度学习模型的标准格式。可以简单理解为各种框架模型转换的一种桥梁。</p> 
</blockquote> 
<p>流程如图所示： <img src="https://images2.imgbox.com/a6/30/Su2JGJTx_o.jpg"></p> 
<h4><a id="32_yolov5_ONNX_310"></a>3.2 修改yolov5 代码，输出ONNX</h4> 
<blockquote> 
 <p>修改之前，建议先使用<code>python export.py --weights weights/yolov5s.pt --include onnx --simplify --dynamic</code>导出一份原始操作的onnx模型，以便和修改后的模型进行对比。</p> 
</blockquote> 
<p>使用课程附件提供的<code>git patch</code>批量修改代码，代码位置：<code>1.代码/export.patch</code></p> 
<pre><code class="prism language-shell"><span class="token comment"># 将patch复制到yolov5文件夹</span>
<span class="token function">cp</span> export.patch yolov5/
<span class="token comment"># 进入yolov5文件夹</span>
<span class="token builtin class-name">cd</span> yolov5/
<span class="token comment"># 应用patch</span>
<span class="token function">git</span> am export.patch
</code></pre> 
<blockquote> 
 <p>在理解代码逻辑后，也可以根据自己的需要在最新版本上的yolov5上进行修改。</p> 
</blockquote> 
<p>首先根据上文自行根据yolov5的要求安装相关依赖，然后再执行下面命令安装导出onnx需要的依赖：</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> seaborn
pip <span class="token function">install</span> onnx-graphsurgeon
pip <span class="token function">install</span> onnx-simplifier<span class="token operator">==</span><span class="token number">0.3</span>.10

<span class="token function">apt</span> update
<span class="token function">apt</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> libgl1-mesa-glx
</code></pre> 
<p>安装完成后，准备好训练好的模型文件，这里默认为<code>yolov5s.pt</code>，然后执行：</p> 
<pre><code class="prism language-shell">python export.py <span class="token parameter variable">--weights</span> weights/yolov5s.pt <span class="token parameter variable">--include</span> onnx <span class="token parameter variable">--simplify</span> <span class="token parameter variable">--dynamic</span>
</code></pre> 
<p>以生成对应的onnx文件。</p> 
<h4><a id="33__346"></a>3.3 具体修改细节</h4> 
<p>在<code>models/yolo.py</code>文件中54行，我们需要修改<code>class Detect</code>的forward方法，以删除其box decode运算，以直接输出网络结果。在后面的tensorrt部署中，我们将利用decode plugin来进行decode操作，并用gpu加速。修改内容如下：</p> 
<pre><code class="prism language-python"><span class="token operator">-</span>            bs<span class="token punctuation">,</span> _<span class="token punctuation">,</span> ny<span class="token punctuation">,</span> nx <span class="token operator">=</span> x<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>shape  <span class="token comment"># x(bs,255,20,20) to x(bs,3,20,20,85)</span>
<span class="token operator">-</span>            x<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> self<span class="token punctuation">.</span>na<span class="token punctuation">,</span> self<span class="token punctuation">.</span>no<span class="token punctuation">,</span> ny<span class="token punctuation">,</span> nx<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">-</span>
<span class="token operator">-</span>            <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>  <span class="token comment"># inference</span>
<span class="token operator">-</span>                <span class="token keyword">if</span> self<span class="token punctuation">.</span>onnx_dynamic <span class="token keyword">or</span> self<span class="token punctuation">.</span>grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">!=</span> x<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
<span class="token operator">-</span>                    self<span class="token punctuation">.</span>grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>anchor_grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_grid<span class="token punctuation">(</span>nx<span class="token punctuation">,</span> ny<span class="token punctuation">,</span> i<span class="token punctuation">)</span>
<span class="token operator">-</span>
<span class="token operator">-</span>                y <span class="token operator">=</span> x<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">-</span>                <span class="token keyword">if</span> self<span class="token punctuation">.</span>inplace<span class="token punctuation">:</span>
<span class="token operator">-</span>                    y<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>y<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">[</span>i<span class="token punctuation">]</span>  <span class="token comment"># xy</span>
<span class="token operator">-</span>                    y<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>y<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>anchor_grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span>  <span class="token comment"># wh</span>
<span class="token operator">-</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>  <span class="token comment"># for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953</span>
<span class="token operator">-</span>                    xy<span class="token punctuation">,</span> wh<span class="token punctuation">,</span> conf <span class="token operator">=</span> y<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>nc <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>  <span class="token comment"># y.tensor_split((2, 4, 5), 4)  # torch 1.8.0</span>
<span class="token operator">-</span>                    xy <span class="token operator">=</span> <span class="token punctuation">(</span>xy <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">[</span>i<span class="token punctuation">]</span>  <span class="token comment"># xy</span>
<span class="token operator">-</span>                    wh <span class="token operator">=</span> <span class="token punctuation">(</span>wh <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>anchor_grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span>  <span class="token comment"># wh</span>
<span class="token operator">-</span>                    y <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>xy<span class="token punctuation">,</span> wh<span class="token punctuation">,</span> conf<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token operator">-</span>                z<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">.</span>view<span class="token punctuation">(</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>no<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token operator">-</span>
<span class="token operator">-</span>        <span class="token keyword">return</span> x <span class="token keyword">if</span> self<span class="token punctuation">.</span>training <span class="token keyword">else</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>z<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>export <span class="token keyword">else</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>z<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
<span class="token operator">+</span>            y <span class="token operator">=</span> x<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">+</span>            z<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
<span class="token operator">+</span>        <span class="token keyword">return</span> z
</code></pre> 
<p>可以看到这里删除了主要的运算部分，将模型输出直接作为list返回。修改后，onnx的输出将被修改为三个原始网络输出，我们需要在输出后添加decode plugin的算子。首先我们先导出onnx，再利用nvidia的graph surgeon来修改onnx。首先我们修改onnx export部分代码：</p> 
<blockquote> 
 <p>GraphSurgeon 是nvidia提供的工具，可以方便的用于修改、添加或者删除onnx网络图中的节点，并生成新的onnx。参考链接：https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeon。</p> 
</blockquote> 
<pre><code class="prism language-python">    torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>export<span class="token punctuation">(</span>
        model<span class="token punctuation">,</span>
        im<span class="token punctuation">,</span>
        f<span class="token punctuation">,</span>
        verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        opset_version<span class="token operator">=</span>opset<span class="token punctuation">,</span>
        training<span class="token operator">=</span>torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>TrainingMode<span class="token punctuation">.</span>TRAINING <span class="token keyword">if</span> train <span class="token keyword">else</span> torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>TrainingMode<span class="token punctuation">.</span>EVAL<span class="token punctuation">,</span>
        do_constant_folding<span class="token operator">=</span><span class="token keyword">not</span> train<span class="token punctuation">,</span>
        input_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'images'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        output_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'p3'</span><span class="token punctuation">,</span> <span class="token string">'p4'</span><span class="token punctuation">,</span> <span class="token string">'p5'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        dynamic_axes<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
            <span class="token string">'images'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
                <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">'batch'</span><span class="token punctuation">,</span>
                <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">'height'</span><span class="token punctuation">,</span>
                <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">'width'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  <span class="token comment"># shape(1,3,640,640)</span>
            <span class="token string">'p3'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
                <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">'batch'</span><span class="token punctuation">,</span>
                <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">'height'</span><span class="token punctuation">,</span>
                <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">'width'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  <span class="token comment"># shape(1,25200,4)</span>
            <span class="token string">'p4'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
                <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">'batch'</span><span class="token punctuation">,</span>
                <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">'height'</span><span class="token punctuation">,</span>
                <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">'width'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token string">'p5'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
                <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">'batch'</span><span class="token punctuation">,</span>
                <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">'height'</span><span class="token punctuation">,</span>
                <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">'width'</span><span class="token punctuation">}</span>
        <span class="token punctuation">}</span> <span class="token keyword">if</span> dynamic <span class="token keyword">else</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
</code></pre> 
<p>将onnx的输出改为3个原始网络输出。输出完成后，我们再加载onnx，并simplify：</p> 
<pre><code class="prism language-python">model_onnx <span class="token operator">=</span> onnx<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
model_onnx <span class="token operator">=</span> onnx<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>  <span class="token comment"># load onnx model</span>
onnx<span class="token punctuation">.</span>checker<span class="token punctuation">.</span>check_model<span class="token punctuation">(</span>model_onnx<span class="token punctuation">)</span>  <span class="token comment"># check onnx model</span>

<span class="token comment"># Simplify</span>
<span class="token keyword">if</span> simplify<span class="token punctuation">:</span>
    <span class="token comment"># try:</span>
    check_requirements<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'onnx-simplifier'</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">import</span> onnxsim

    LOGGER<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>prefix<span class="token punctuation">}</span></span><span class="token string"> simplifying with onnx-simplifier </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>onnxsim<span class="token punctuation">.</span>__version__<span class="token punctuation">}</span></span><span class="token string">...'</span></span><span class="token punctuation">)</span>
    model_onnx<span class="token punctuation">,</span> check <span class="token operator">=</span> onnxsim<span class="token punctuation">.</span>simplify<span class="token punctuation">(</span>model_onnx<span class="token punctuation">,</span>
        dynamic_input_shape<span class="token operator">=</span>dynamic<span class="token punctuation">,</span>
        input_shapes<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'images'</span><span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">(</span>im<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">}</span> <span class="token keyword">if</span> dynamic <span class="token keyword">else</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
    <span class="token keyword">assert</span> check<span class="token punctuation">,</span> <span class="token string">'assert check failed'</span>
    onnx<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model_onnx<span class="token punctuation">,</span> f<span class="token punctuation">)</span>
</code></pre> 
<p>然后我们再将onnx加载回来，用nvidia surgeon进行修改:</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> onnx_graphsurgeon <span class="token keyword">as</span> onnx_gs
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
yolo_graph <span class="token operator">=</span> onnx_gs<span class="token punctuation">.</span>import_onnx<span class="token punctuation">(</span>model_onnx<span class="token punctuation">)</span>
</code></pre> 
<p>首先我们获取原始的onnx输出p3,p4,p5：</p> 
<pre><code class="prism language-python">p3 <span class="token operator">=</span> yolo_graph<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
p4 <span class="token operator">=</span> yolo_graph<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
p5 <span class="token operator">=</span> yolo_graph<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
</code></pre> 
<p>然后我们定义新的onnx输出，由于decode plugin中，有4个输出，所以我们将定义4个新的输出。其名字需要和下面的代码保持一致，这是decode_plugin中预先定义好的。</p> 
<pre><code class="prism language-python">decode_out_0 <span class="token operator">=</span> onnx_gs<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>
  <span class="token string">"DecodeNumDetection"</span><span class="token punctuation">,</span>
  dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32
<span class="token punctuation">)</span>
decode_out_1 <span class="token operator">=</span> onnx_gs<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>
  <span class="token string">"DecodeDetectionBoxes"</span><span class="token punctuation">,</span>
  dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32
<span class="token punctuation">)</span>
decode_out_2 <span class="token operator">=</span> onnx_gs<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>
  <span class="token string">"DecodeDetectionScores"</span><span class="token punctuation">,</span>
  dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32
<span class="token punctuation">)</span>
decode_out_3 <span class="token operator">=</span> onnx_gs<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>
  <span class="token string">"DecodeDetectionClasses"</span><span class="token punctuation">,</span>
  dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32
<span class="token punctuation">)</span>
</code></pre> 
<p>然后我们需要再添加一些decode参数，定义如下：</p> 
<pre><code class="prism language-python">decode_attrs <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

decode_attrs<span class="token punctuation">[</span><span class="token string">"max_stride"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>stride<span class="token punctuation">)</span><span class="token punctuation">)</span>
decode_attrs<span class="token punctuation">[</span><span class="token string">"num_classes"</span><span class="token punctuation">]</span> <span class="token operator">=</span> model<span class="token punctuation">.</span>model<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>nc
decode_attrs<span class="token punctuation">[</span><span class="token string">"anchors"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> v <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span><span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span><span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span><span class="token number">119</span><span class="token punctuation">,</span> <span class="token number">116</span><span class="token punctuation">,</span><span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">156</span><span class="token punctuation">,</span><span class="token number">198</span><span class="token punctuation">,</span> <span class="token number">373</span><span class="token punctuation">,</span><span class="token number">326</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
decode_attrs<span class="token punctuation">[</span><span class="token string">"prenms_score_threshold"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.25</span>
</code></pre> 
<p>在定义好了相关参数后，我们创建一个onnx node，用作decode plugin。由于我们的tensorrt plugin的名称为<code>YoloLayer_TRT</code>,因此这里我们需要保持op的名字与我们的plugin名称一致。通过如下代码，我们创建了一个node：</p> 
<pre><code class="prism language-python">    decode_plugin <span class="token operator">=</span> onnx_gs<span class="token punctuation">.</span>Node<span class="token punctuation">(</span>
        op<span class="token operator">=</span><span class="token string">"YoloLayer_TRT"</span><span class="token punctuation">,</span>
        name<span class="token operator">=</span><span class="token string">"YoloLayer"</span><span class="token punctuation">,</span>
        inputs<span class="token operator">=</span><span class="token punctuation">[</span>p3<span class="token punctuation">,</span> p4<span class="token punctuation">,</span> p5<span class="token punctuation">]</span><span class="token punctuation">,</span>
        outputs<span class="token operator">=</span><span class="token punctuation">[</span>decode_out_0<span class="token punctuation">,</span> decode_out_1<span class="token punctuation">,</span> decode_out_2<span class="token punctuation">,</span> decode_out_3<span class="token punctuation">]</span><span class="token punctuation">,</span>
        attrs<span class="token operator">=</span>decode_attrs
    <span class="token punctuation">)</span>
</code></pre> 
<p>然后我们将这个node添加了网络中：</p> 
<pre><code class="prism language-python">    yolo_graph<span class="token punctuation">.</span>nodes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>decode_plugin<span class="token punctuation">)</span>
    yolo_graph<span class="token punctuation">.</span>outputs <span class="token operator">=</span> decode_plugin<span class="token punctuation">.</span>outputs
    yolo_graph<span class="token punctuation">.</span>cleanup<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toposort<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model_onnx <span class="token operator">=</span> onnx_gs<span class="token punctuation">.</span>export_onnx<span class="token punctuation">(</span>yolo_graph<span class="token punctuation">)</span>
</code></pre> 
<p>最后添加一些meta信息后，我们导出最终的onnx文件，这个文件可以用于后续的tensorrt部署和推理。</p> 
<pre><code class="prism language-python">    d <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'stride'</span><span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>stride<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'names'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>names<span class="token punctuation">}</span>
    <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> d<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        meta <span class="token operator">=</span> model_onnx<span class="token punctuation">.</span>metadata_props<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token punctuation">)</span>
        meta<span class="token punctuation">.</span>key<span class="token punctuation">,</span> meta<span class="token punctuation">.</span>value <span class="token operator">=</span> k<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">(</span>v<span class="token punctuation">)</span>

    onnx<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model_onnx<span class="token punctuation">,</span> f<span class="token punctuation">)</span>
    LOGGER<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>prefix<span class="token punctuation">}</span></span><span class="token string"> export success, saved as </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>f<span class="token punctuation">}</span></span><span class="token string"> (</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>file_size<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.1f</span><span class="token punctuation">}</span></span><span class="token string"> MB)'</span></span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> f
</code></pre> 
<h3><a id="TensorRT_515"></a>四、TensorRT部署</h3> 
<p>使用<code>TensorRT</code> docker容器：</p> 
<pre><code class="prism language-shell"><span class="token function">docker</span> run <span class="token parameter variable">--gpus</span> all <span class="token parameter variable">-it</span> <span class="token parameter variable">--name</span> env_trt <span class="token parameter variable">-v</span> <span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">pwd</span><span class="token variable">)</span></span>:/app nvcr.io/nvidia/tensorrt:22.08-py3
</code></pre> 
<h4><a id="41__523"></a>4.1 模型构建</h4> 
<blockquote> 
 <p>代码位置：<code>1.代码/tensorrt_cpp/build.cu</code></p> 
</blockquote> 
<p>和我们之前课程中的TensorRT构建流程一样，yolov5转到onnx后，也是通过相同的流程进行模型构建，并保存序列化后的模型为文件。</p> 
<ol><li><strong>创建builder</strong>。这里我们使用了<code>std::unique_ptr</code>只能指针包装我们的builder，实现自动管理指针生命周期。</li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// =========== 1. 创建builder ===========</span>
<span class="token keyword">auto</span> builder <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">unique_ptr</span><span class="token generic class-name"><span class="token operator">&lt;</span>nvinfer1<span class="token double-colon punctuation">::</span>IBuilder<span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>nvinfer1<span class="token double-colon punctuation">::</span><span class="token function">createInferBuilder</span><span class="token punctuation">(</span>sample<span class="token double-colon punctuation">::</span>gLogger<span class="token punctuation">.</span><span class="token function">getTRTLogger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>builder<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
  std<span class="token double-colon punctuation">::</span>cerr <span class="token operator">&lt;&lt;</span> <span class="token string">"Failed to create builder"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<ol start="2"><li>**创建网络。**这里指定了explicitBatch</li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// ========== 2. 创建network：builder---&gt;network ==========</span>
<span class="token comment">// 显性batch</span>
<span class="token keyword">const</span> <span class="token keyword">auto</span> explicitBatch <span class="token operator">=</span> <span class="token number">1U</span> <span class="token operator">&lt;&lt;</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">uint32_t</span><span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>nvinfer1<span class="token double-colon punctuation">::</span>NetworkDefinitionCreationFlag<span class="token double-colon punctuation">::</span>kEXPLICIT_BATCH<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 调用builder的createNetworkV2方法创建network</span>
<span class="token keyword">auto</span> network <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">unique_ptr</span><span class="token generic class-name"><span class="token operator">&lt;</span>nvinfer1<span class="token double-colon punctuation">::</span>INetworkDefinition<span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>builder<span class="token operator">-&gt;</span><span class="token function">createNetworkV2</span><span class="token punctuation">(</span>explicitBatch<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>network<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
  std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Failed to create network"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<ol start="3"><li>**创建config。**用于模型构建的参数配置</li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// ========== 3. 创建config配置：builder---&gt;config ==========</span>
<span class="token keyword">auto</span> config <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">unique_ptr</span><span class="token generic class-name"><span class="token operator">&lt;</span>nvinfer1<span class="token double-colon punctuation">::</span>IBuilderConfig<span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>builder<span class="token operator">-&gt;</span><span class="token function">createBuilderConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>config<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
  std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Failed to create config"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<ol start="4"><li>**创建onnx 解析器，**并进行解析</li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// 创建onnxparser，用于解析onnx文件</span>
<span class="token keyword">auto</span> parser <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">unique_ptr</span><span class="token generic class-name"><span class="token operator">&lt;</span>nvonnxparser<span class="token double-colon punctuation">::</span>IParser<span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>nvonnxparser<span class="token double-colon punctuation">::</span><span class="token function">createParser</span><span class="token punctuation">(</span><span class="token operator">*</span>network<span class="token punctuation">,</span> sample<span class="token double-colon punctuation">::</span>gLogger<span class="token punctuation">.</span><span class="token function">getTRTLogger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 调用onnxparser的parseFromFile方法解析onnx文件</span>
<span class="token keyword">auto</span> parsed <span class="token operator">=</span> parser<span class="token operator">-&gt;</span><span class="token function">parseFromFile</span><span class="token punctuation">(</span>onnx_file_path<span class="token punctuation">,</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>sample<span class="token double-colon punctuation">::</span>gLogger<span class="token punctuation">.</span><span class="token function">getReportableSeverity</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>parsed<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
  std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Failed to parse onnx file"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<ol start="5"><li>**配置网络构建参数。**这里由于我们导出onnx时并没有指定输入图像的batch，height，width。因此在构建时，我们需要告诉tensorrt我们最终运行时，输入图像的范围，batch size的范围。这样tensorrt才能对应为我们进行模型构建与优化。这里我们将输入指定到了1,3,640,640，这样tensorrt就会为这个尺寸的输入搜索最优算子并构建网络。其中设置pofile参数，即是我们用来指定输入大小搜索范围的。</li></ol> 
<pre><code class="prism language-cpp"><span class="token keyword">auto</span> input <span class="token operator">=</span> network<span class="token operator">-&gt;</span><span class="token function">getInput</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">auto</span> profile <span class="token operator">=</span> builder<span class="token operator">-&gt;</span><span class="token function">createOptimizationProfile</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
profile<span class="token operator">-&gt;</span><span class="token function">setDimensions</span><span class="token punctuation">(</span>input<span class="token operator">-&gt;</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>OptProfileSelector<span class="token double-colon punctuation">::</span>kMIN<span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>Dims4<span class="token punctuation">{<!-- --></span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
profile<span class="token operator">-&gt;</span><span class="token function">setDimensions</span><span class="token punctuation">(</span>input<span class="token operator">-&gt;</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>OptProfileSelector<span class="token double-colon punctuation">::</span>kOPT<span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>Dims4<span class="token punctuation">{<!-- --></span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
profile<span class="token operator">-&gt;</span><span class="token function">setDimensions</span><span class="token punctuation">(</span>input<span class="token operator">-&gt;</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>OptProfileSelector<span class="token double-colon punctuation">::</span>kMAX<span class="token punctuation">,</span> nvinfer1<span class="token double-colon punctuation">::</span>Dims4<span class="token punctuation">{<!-- --></span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 使用addOptimizationProfile方法添加profile，用于设置输入的动态尺寸</span>
config<span class="token operator">-&gt;</span><span class="token function">addOptimizationProfile</span><span class="token punctuation">(</span>profile<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 设置精度，不设置是FP32，设置为FP16，设置为INT8需要额外设置calibrator</span>
config<span class="token operator">-&gt;</span><span class="token function">setFlag</span><span class="token punctuation">(</span>nvinfer1<span class="token double-colon punctuation">::</span>BuilderFlag<span class="token double-colon punctuation">::</span>kFP16<span class="token punctuation">)</span><span class="token punctuation">;</span>

builder<span class="token operator">-&gt;</span><span class="token function">setMaxBatchSize</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 设置最大工作空间（最新版本的TensorRT已经废弃了setWorkspaceSize）</span>
config<span class="token operator">-&gt;</span><span class="token function">setMemoryPoolLimit</span><span class="token punctuation">(</span>nvinfer1<span class="token double-colon punctuation">::</span>MemoryPoolType<span class="token double-colon punctuation">::</span>kWORKSPACE<span class="token punctuation">,</span> <span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 7. 创建流，用于设置profile</span>
<span class="token keyword">auto</span> profileStream <span class="token operator">=</span> samplesCommon<span class="token double-colon punctuation">::</span><span class="token function">makeCudaStream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>profileStream<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span> <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span> <span class="token punctuation">}</span>
config<span class="token operator">-&gt;</span><span class="token function">setProfileStream</span><span class="token punctuation">(</span><span class="token operator">*</span>profileStream<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<ol start="6"><li><strong>将模型序列化</strong>，并进行保存</li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// ========== 4. 创建engine：builder---&gt;engine(*nework, *config) ==========</span>
<span class="token comment">// 使用buildSerializedNetwork方法创建engine，可直接返回序列化的engine（原来的buildEngineWithConfig方法已经废弃，需要先创建engine，再序列化）</span>
<span class="token keyword">auto</span> plan <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">unique_ptr</span><span class="token generic class-name"><span class="token operator">&lt;</span>nvinfer1<span class="token double-colon punctuation">::</span>IHostMemory<span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>builder<span class="token operator">-&gt;</span><span class="token function">buildSerializedNetwork</span><span class="token punctuation">(</span><span class="token operator">*</span>network<span class="token punctuation">,</span> <span class="token operator">*</span>config<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>plan<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
  std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Failed to create engine"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token comment">// ========== 5. 序列化保存engine ==========</span>
std<span class="token double-colon punctuation">::</span>ofstream <span class="token function">engine_file</span><span class="token punctuation">(</span><span class="token string">"./model/yolov5.engine"</span><span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>ios<span class="token double-colon punctuation">::</span>binary<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">assert</span><span class="token punctuation">(</span>engine_file<span class="token punctuation">.</span><span class="token function">is_open</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token string">"Failed to open engine file"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
engine_file<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">char</span> <span class="token operator">*</span><span class="token punctuation">)</span>plan<span class="token operator">-&gt;</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> plan<span class="token operator">-&gt;</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
engine_file<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="42__625"></a>4.2 模型的推理</h4> 
<blockquote> 
 <p>代码位置：<code>1.代码/tensorrt_cpp/build.cu</code></p> 
</blockquote> 
<p>如同之前的TensorRT课程介绍一样，推理过程将读取模型文件，并对输入进行预处理，然后读取模型输出后，再进行后处理。</p> 
<ol><li><strong>创建运行时</strong></li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// ========= 1. 创建推理运行时runtime =========</span>
<span class="token keyword">auto</span> runtime <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">unique_ptr</span><span class="token generic class-name"><span class="token operator">&lt;</span>nvinfer1<span class="token double-colon punctuation">::</span>IRuntime<span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>nvinfer1<span class="token double-colon punctuation">::</span><span class="token function">createInferRuntime</span><span class="token punctuation">(</span>sample<span class="token double-colon punctuation">::</span>gLogger<span class="token punctuation">.</span><span class="token function">getTRTLogger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>runtime<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
  std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"runtime create failed"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
  <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<ol start="2"><li><strong>反序列化</strong>模型得到推理<strong>Engine</strong></li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// ======== 2. 反序列化生成engine =========</span>
<span class="token comment">// 加载模型文件</span>
<span class="token keyword">auto</span> plan <span class="token operator">=</span> <span class="token function">load_engine_file</span><span class="token punctuation">(</span>engine_file<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 反序列化生成engine</span>
<span class="token keyword">auto</span> mEngine <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">shared_ptr</span><span class="token generic class-name"><span class="token operator">&lt;</span>nvinfer1<span class="token double-colon punctuation">::</span>ICudaEngine<span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>runtime<span class="token operator">-&gt;</span><span class="token function">deserializeCudaEngine</span><span class="token punctuation">(</span>plan<span class="token punctuation">.</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> plan<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<ol start="3"><li><strong>创建执行上下文</strong></li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// ======== 3. 创建执行上下文context =========</span>
<span class="token keyword">auto</span> context <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">unique_ptr</span><span class="token generic class-name"><span class="token operator">&lt;</span>nvinfer1<span class="token double-colon punctuation">::</span>IExecutionContext<span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>mEngine<span class="token operator">-&gt;</span><span class="token function">createExecutionContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<ol start="4"><li><strong>创建输入输出缓冲区管理器</strong>，这里我们使用的是tensorrt sample code中的buffer管理器，以方便我们进行内存的分配和cpu gpu之间的内存拷贝。</li></ol> 
<pre><code class="prism language-cpp">samplesCommon<span class="token double-colon punctuation">::</span>BufferManager <span class="token function">buffers</span><span class="token punctuation">(</span>mEngine<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<ol start="5"><li>我们读取视频文件，并逐帧读取图像，送入模型中，进行推理</li></ol> 
<pre><code class="prism language-cpp"><span class="token keyword">auto</span> cap <span class="token operator">=</span> cv<span class="token double-colon punctuation">::</span><span class="token function">VideoCapture</span><span class="token punctuation">(</span>input_video_path<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">while</span><span class="token punctuation">(</span>cap<span class="token punctuation">.</span><span class="token function">isOpened</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
  cv<span class="token double-colon punctuation">::</span>Mat frame<span class="token punctuation">;</span>
  cap <span class="token operator">&gt;&gt;</span> frame<span class="token punctuation">;</span>
  <span class="token keyword">if</span> <span class="token punctuation">(</span>frame<span class="token punctuation">.</span><span class="token function">empty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">break</span><span class="token punctuation">;</span>
  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> 
<ol start="6"><li>首先对输入图像进行预处理，这里我们使用<code>preprocess.cu</code>中的代码，其中实现了对输入图像处理的gpu 加速（后续再进行讲解）。</li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// 输入预处理</span>
<span class="token function">process_input</span><span class="token punctuation">(</span>frame<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span>buffers<span class="token punctuation">.</span><span class="token function">getDeviceBuffer</span><span class="token punctuation">(</span>kInputTensorName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<ol start="7"><li>预处理完成后，我们调用推理api <code>executeV2</code>，进行模型推理，并将模型输出拷贝到cpu</li></ol> 
<pre><code class="prism language-cpp">context<span class="token operator">-&gt;</span><span class="token function">executeV2</span><span class="token punctuation">(</span>buffers<span class="token punctuation">.</span><span class="token function">getDeviceBindings</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
buffers<span class="token punctuation">.</span><span class="token function">copyOutputToHost</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<ol start="8"><li>最后我们从buffer manager中获取模型输出，并执行nms，得到最后的检测框</li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// 获取模型输出</span>
<span class="token keyword">int32_t</span> <span class="token operator">*</span>num_det <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">int32_t</span> <span class="token operator">*</span><span class="token punctuation">)</span>buffers<span class="token punctuation">.</span><span class="token function">getHostBuffer</span><span class="token punctuation">(</span>kOutNumDet<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 检测到的目标个数</span>
<span class="token keyword">int32_t</span> <span class="token operator">*</span>cls <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">int32_t</span> <span class="token operator">*</span><span class="token punctuation">)</span>buffers<span class="token punctuation">.</span><span class="token function">getHostBuffer</span><span class="token punctuation">(</span>kOutDetCls<span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment">// 检测到的目标类别</span>
<span class="token keyword">float</span> <span class="token operator">*</span>conf <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span>buffers<span class="token punctuation">.</span><span class="token function">getHostBuffer</span><span class="token punctuation">(</span>kOutDetScores<span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment">// 检测到的目标置信度</span>
<span class="token keyword">float</span> <span class="token operator">*</span>bbox <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span>buffers<span class="token punctuation">.</span><span class="token function">getHostBuffer</span><span class="token punctuation">(</span>kOutDetBBoxes<span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment">// 检测到的目标框</span>
<span class="token comment">// 后处理</span>
std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span>Detection<span class="token operator">&gt;</span> bboxs<span class="token punctuation">;</span>
<span class="token function">yolo_nms</span><span class="token punctuation">(</span>bboxs<span class="token punctuation">,</span> num_det<span class="token punctuation">,</span> cls<span class="token punctuation">,</span> conf<span class="token punctuation">,</span> bbox<span class="token punctuation">,</span> kConfThresh<span class="token punctuation">,</span> kNmsThresh<span class="token punctuation">)</span><span class="token punctuation">;</span>

</code></pre> 
<ol start="9"><li>我们依次将检测框画到图像上，再打印对应的fps和推理时间。并显示图像</li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// 结束时间</span>
<span class="token keyword">auto</span> end <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span>chrono<span class="token double-colon punctuation">::</span>high_resolution_clock<span class="token double-colon punctuation">::</span><span class="token function">now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">auto</span> elapsed <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span>chrono<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">duration_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>chrono<span class="token double-colon punctuation">::</span>milliseconds<span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>end <span class="token operator">-</span> start<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">auto</span> time_str <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token function">to_string</span><span class="token punctuation">(</span>elapsed<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"ms"</span><span class="token punctuation">;</span>
<span class="token keyword">auto</span> fps_str <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token function">to_string</span><span class="token punctuation">(</span><span class="token number">1000</span> <span class="token operator">/</span> elapsed<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"fps"</span><span class="token punctuation">;</span>

<span class="token comment">// 遍历检测结果</span>
<span class="token keyword">for</span> <span class="token punctuation">(</span>size_t j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> bboxs<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> j<span class="token operator">++</span><span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
  cv<span class="token double-colon punctuation">::</span>Rect r <span class="token operator">=</span> <span class="token function">get_rect</span><span class="token punctuation">(</span>frame<span class="token punctuation">,</span> bboxs<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>bbox<span class="token punctuation">)</span><span class="token punctuation">;</span>
  cv<span class="token double-colon punctuation">::</span><span class="token function">rectangle</span><span class="token punctuation">(</span>frame<span class="token punctuation">,</span> r<span class="token punctuation">,</span> cv<span class="token double-colon punctuation">::</span><span class="token function">Scalar</span><span class="token punctuation">(</span><span class="token number">0x27</span><span class="token punctuation">,</span> <span class="token number">0xC1</span><span class="token punctuation">,</span> <span class="token number">0x36</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  cv<span class="token double-colon punctuation">::</span><span class="token function">putText</span><span class="token punctuation">(</span>frame<span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span><span class="token function">to_string</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span>bboxs<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>class_id<span class="token punctuation">)</span><span class="token punctuation">,</span> cv<span class="token double-colon punctuation">::</span><span class="token function">Point</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>x<span class="token punctuation">,</span> r<span class="token punctuation">.</span>y <span class="token operator">-</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cv<span class="token double-colon punctuation">::</span>FONT_HERSHEY_PLAIN<span class="token punctuation">,</span> <span class="token number">1.2</span><span class="token punctuation">,</span> cv<span class="token double-colon punctuation">::</span><span class="token function">Scalar</span><span class="token punctuation">(</span><span class="token number">0x27</span><span class="token punctuation">,</span> <span class="token number">0xC1</span><span class="token punctuation">,</span> <span class="token number">0x36</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
cv<span class="token double-colon punctuation">::</span><span class="token function">putText</span><span class="token punctuation">(</span>frame<span class="token punctuation">,</span> time_str<span class="token punctuation">,</span> cv<span class="token double-colon punctuation">::</span><span class="token function">Point</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cv<span class="token double-colon punctuation">::</span>FONT_HERSHEY_PLAIN<span class="token punctuation">,</span> <span class="token number">1.2</span><span class="token punctuation">,</span> cv<span class="token double-colon punctuation">::</span><span class="token function">Scalar</span><span class="token punctuation">(</span><span class="token number">0xFF</span><span class="token punctuation">,</span> <span class="token number">0xFF</span><span class="token punctuation">,</span> <span class="token number">0xFF</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
cv<span class="token double-colon punctuation">::</span><span class="token function">putText</span><span class="token punctuation">(</span>frame<span class="token punctuation">,</span> fps_str<span class="token punctuation">,</span> cv<span class="token double-colon punctuation">::</span><span class="token function">Point</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cv<span class="token double-colon punctuation">::</span>FONT_HERSHEY_PLAIN<span class="token punctuation">,</span> <span class="token number">1.2</span><span class="token punctuation">,</span> cv<span class="token double-colon punctuation">::</span><span class="token function">Scalar</span><span class="token punctuation">(</span><span class="token number">0xFF</span><span class="token punctuation">,</span> <span class="token number">0xFF</span><span class="token punctuation">,</span> <span class="token number">0xFF</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

cv<span class="token double-colon punctuation">::</span><span class="token function">imshow</span><span class="token punctuation">(</span><span class="token string">"frame"</span><span class="token punctuation">,</span> frame<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="43_INT8FP16_730"></a>4.3 INT8、FP16量化对比</h4> 
<blockquote> 
 <p>首先需要确保你的GPU支持INT8计算（如jetson nano不支持INT8）</p> 
</blockquote> 
<h5><a id="431__734"></a>4.3.1 简介</h5> 
<p>深度学习量化就是将深度学习模型中的参数（例如权重和偏置）从浮点数转换成整数或者定点数的过程。这样做可以减少模型的存储和计算成本，从而达到模型压缩和运算加速的目的。如int8量化，让原来模型中32bit存储的数字映射到8bit再计算（范围是[-128,127]）。</p> 
<ul><li>加快推理速度：访问一次32位浮点型可以访问4次int8整型数据；</li><li>减少存储空间和内存占用：在边缘设备（如嵌入式）上部署更实用。</li></ul> 
<p>当然，提升速度的同时，量化也会带来精度的损失，为了能尽可能减少量化过程中精度的损失，需要使用各种校准方法来降低信息的损失。TensorRT 中支持两种 INT8 校准算法：</p> 
<ul><li>熵校准 (Entropy Calibration)</li><li>最小最大值校准 (Min-Max Calibration)</li></ul> 
<blockquote> 
 <ul><li> <p>熵校准是一种动态校准算法，它使用 KL 散度 (KL Divergence) 来度量推理数据和校准数据之间的分布差异。在熵校准中，校准数据是从实时推理数据中采集的，它将 INT8 精度量化参数看作概率分布，根据推理数据和校准数据的 KL 散度来更新量化参数。这种方法的优点是可以更好地反映实际推理数据的分布。</p> </li><li> <p>最小最大值校准使用最小最大值算法来计算量化参数。在最小最大值校准中，需要使用一组代表性的校准数据来生成量化参数，首先将推理中的数据进行统计，计算数据的最小值和最大值，然后根据这些值来计算量化参数。</p> </li></ul> 
</blockquote> 
<p>这两种校准方法都需要准备一些数据用于在校准时执行推理，以统计数据的分布情况。<strong>一般数据需要有代表性，即需要符合最终实际落地场景的数据</strong>，实际应用中一般准备500-1000个数据用于量化。</p> 
<h5><a id="432_TensorRT_754"></a>4.3.2 TensorRT中实现</h5> 
<p>在 TensorRT 中，可以通过实现 <code>IInt8EntropyCalibrator2</code> 接口或 <code>IInt8MinMaxCalibrator</code> 接口来执行熵校准或最小最大值校准，并且需要实现几个虚函数方法：</p> 
<ul><li><code>getBatch() </code>方法：用于提供一批校准数据；</li><li><code>readCalibrationCache()</code> 和 <code>writeCalibrationCache()</code> 方法：实现缓存机制，以避免在每次启动时重新加载校准数据。</li></ul> 
<p>课程附件中<code>build.cu</code>代码实现了 <code>IInt8MinMaxCalibrator</code> 接口，用于对 INT8 模型进行离线静态校准（你可以替换<code>IInt8EntropyCalibrator2</code>换成熵校准进行结果对比）。</p> 
<pre><code class="prism language-C++">// 定义校准数据读取器
// 如果要用entropy的话改为：IInt8EntropyCalibrator2
class CalibrationDataReader : public IInt8MinMaxCalibrator
{
  ....
}
</code></pre> 
<ul><li>在构造函数中，需要传递数据目录、数据列表和BatchSize等参数。数据目录是指包含校准数据的文件夹路径，数据列表是指校准数据文件的名称列表。构造函数还会初始化输入张量的维度和大小，以及在设备上分配内存。</li></ul> 
<pre><code class="prism language-cpp"><span class="token function">CalibrationDataReader</span><span class="token punctuation">(</span><span class="token keyword">const</span> std<span class="token double-colon punctuation">::</span>string <span class="token operator">&amp;</span>dataDir<span class="token punctuation">,</span> <span class="token keyword">const</span> std<span class="token double-colon punctuation">::</span>string <span class="token operator">&amp;</span>list<span class="token punctuation">,</span> <span class="token keyword">int</span> batchSize <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token operator">:</span> <span class="token function">mDataDir</span><span class="token punctuation">(</span>dataDir<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">mCacheFileName</span><span class="token punctuation">(</span><span class="token string">"weights/calibration.cache"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">mBatchSize</span><span class="token punctuation">(</span>batchSize<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">mImgSize</span><span class="token punctuation">(</span>kInputH <span class="token operator">*</span> kInputW<span class="token punctuation">)</span>
    <span class="token punctuation">{<!-- --></span>
        mInputDims <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> kInputH<span class="token punctuation">,</span> kInputW<span class="token punctuation">}</span><span class="token punctuation">;</span> <span class="token comment">// 设置网络输入尺寸</span>
        mInputCount <span class="token operator">=</span> mBatchSize <span class="token operator">*</span> samplesCommon<span class="token double-colon punctuation">::</span><span class="token function">volume</span><span class="token punctuation">(</span>mInputDims<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">cuda_preprocess_init</span><span class="token punctuation">(</span>mImgSize<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>mDeviceBatchData<span class="token punctuation">,</span> kInputH <span class="token operator">*</span> kInputW <span class="token operator">*</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 加载校准数据集文件列表</span>
        std<span class="token double-colon punctuation">::</span>ifstream <span class="token function">infile</span><span class="token punctuation">(</span>list<span class="token punctuation">)</span><span class="token punctuation">;</span>
        std<span class="token double-colon punctuation">::</span>string line<span class="token punctuation">;</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span>std<span class="token double-colon punctuation">::</span><span class="token function">getline</span><span class="token punctuation">(</span>infile<span class="token punctuation">,</span> line<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">{<!-- --></span>
            sample<span class="token double-colon punctuation">::</span>gLogInfo <span class="token operator">&lt;&lt;</span> line <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
            mFileNames<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        mBatchCount <span class="token operator">=</span> mFileNames<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> mBatchSize<span class="token punctuation">;</span>
        std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"CalibrationDataReader: "</span> <span class="token operator">&lt;&lt;</span> mFileNames<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> <span class="token string">" images, "</span> <span class="token operator">&lt;&lt;</span> mBatchCount <span class="token operator">&lt;&lt;</span> <span class="token string">" batches."</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
</code></pre> 
<ul><li><code>getBatch()</code> 方法用于提供一批校准数据。在该方法中，需要将当前批次的校准数据读取到内存中，并将其复制到设备内存中。然后，将数据指针传递给 TensorRT 引擎，以供后续的校准计算使用。</li></ul> 
<pre><code class="prism language-cpp"><span class="token keyword">bool</span> <span class="token function">getBatch</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span>bindings<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">char</span> <span class="token operator">*</span>names<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> nbBindings<span class="token punctuation">)</span> <span class="token keyword">noexcept</span> <span class="token keyword">override</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>mCurBatch <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">&gt;</span> mBatchCount<span class="token punctuation">)</span>
        <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token keyword">int</span> offset <span class="token operator">=</span> kInputW <span class="token operator">*</span> kInputH <span class="token operator">*</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> mBatchSize<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span>
        <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">int</span> idx <span class="token operator">=</span> mCurBatch <span class="token operator">*</span> mBatchSize <span class="token operator">+</span> i<span class="token punctuation">;</span>
            std<span class="token double-colon punctuation">::</span>string fileName <span class="token operator">=</span> mDataDir <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> mFileNames<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
            cv<span class="token double-colon punctuation">::</span>Mat img <span class="token operator">=</span> cv<span class="token double-colon punctuation">::</span><span class="token function">imread</span><span class="token punctuation">(</span>fileName<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">int</span> new_img_size <span class="token operator">=</span> img<span class="token punctuation">.</span>cols <span class="token operator">*</span> img<span class="token punctuation">.</span>rows<span class="token punctuation">;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>new_img_size <span class="token operator">&gt;</span> mImgSize<span class="token punctuation">)</span>
            <span class="token punctuation">{<!-- --></span>
                mImgSize <span class="token operator">=</span> new_img_size<span class="token punctuation">;</span>
                <span class="token function">cuda_preprocess_destroy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token comment">// 释放之前的内存</span>
                <span class="token function">cuda_preprocess_init</span><span class="token punctuation">(</span>mImgSize<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 重新分配内存</span>
            <span class="token punctuation">}</span>
            <span class="token function">process_input_gpu</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span> mDeviceBatchData <span class="token operator">+</span> i <span class="token operator">*</span> offset<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> nbBindings<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span>
        <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">strcmp</span><span class="token punctuation">(</span>names<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> kInputTensorName<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token punctuation">{<!-- --></span>
                bindings<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> mDeviceBatchData <span class="token operator">+</span> i <span class="token operator">*</span> offset<span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>

        mCurBatch<span class="token operator">++</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
</code></pre> 
<ul><li><code>readCalibrationCache()</code> 方法用于从缓存文件中读取校准缓存，返回一个指向缓存数据的指针，以及缓存数据的大小。如果没有缓存数据，则返回<code>nullptr</code>。</li></ul> 
<pre><code class="prism language-cpp"><span class="token keyword">const</span> <span class="token keyword">void</span><span class="token operator">*</span> <span class="token function">readCalibrationCache</span><span class="token punctuation">(</span>std<span class="token double-colon punctuation">::</span>size_t<span class="token operator">&amp;</span> length<span class="token punctuation">)</span> <span class="token keyword">noexcept</span> <span class="token keyword">override</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// read from file</span>
    mCalibrationCache<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    std<span class="token double-colon punctuation">::</span>ifstream <span class="token function">input</span><span class="token punctuation">(</span>mCacheFileName<span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>ios<span class="token double-colon punctuation">::</span>binary<span class="token punctuation">)</span><span class="token punctuation">;</span>
    input <span class="token operator">&gt;&gt;</span> std<span class="token double-colon punctuation">::</span>noskipws<span class="token punctuation">;</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span>input<span class="token punctuation">.</span><span class="token function">good</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">{<!-- --></span>
        std<span class="token double-colon punctuation">::</span><span class="token function">copy</span><span class="token punctuation">(</span>std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">istream_iterator</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">char</span><span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">istream_iterator</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">char</span><span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  std<span class="token double-colon punctuation">::</span><span class="token function">back_inserter</span><span class="token punctuation">(</span>mCalibrationCache<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    length <span class="token operator">=</span> mCalibrationCache<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">return</span> length <span class="token operator">?</span> mCalibrationCache<span class="token punctuation">.</span><span class="token function">data</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<ul><li><code>writeCalibrationCache()</code> 方法用于将校准缓存写入到缓存文件中。在该方法中，需要将缓存数据指针和缓存数据的大小传递给文件输出流，并将其写入到缓存文件中。</li></ul> 
<pre><code class="prism language-cpp"><span class="token keyword">void</span> <span class="token function">writeCalibrationCache</span><span class="token punctuation">(</span><span class="token keyword">const</span> <span class="token keyword">void</span><span class="token operator">*</span> cache<span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>size_t length<span class="token punctuation">)</span> <span class="token keyword">noexcept</span> <span class="token keyword">override</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// write tensorrt calibration cache to file</span>
    std<span class="token double-colon punctuation">::</span>ofstream <span class="token function">output</span><span class="token punctuation">(</span>mCacheFileName<span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>ios<span class="token double-colon punctuation">::</span>binary<span class="token punctuation">)</span><span class="token punctuation">;</span>
    output<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token generic-function"><span class="token function">reinterpret_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">const</span> <span class="token keyword">char</span><span class="token operator">*</span><span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>cache<span class="token punctuation">)</span><span class="token punctuation">,</span> length<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>在业务代码中，首先会检查当前平台是否支持 INT8 推理，如果不支持，则打印一条警告信息，并设置引擎为 <code>FP16</code> 模式。否则，创建一个 <code>CalibrationDataReader</code> 类型的对象 <code>calibrator</code>，并将其设置为 INT8 校准器，然后将 INT8 模式标志设置到配置对象 config 中。</p> 
<pre><code class="prism language-cpp"><span class="token comment">// 设置精度，不设置是FP32，设置为FP16，设置为INT8需要额外设置calibrator</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>builder<span class="token operator">-&gt;</span><span class="token function">platformHasFastInt8</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
  sample<span class="token double-colon punctuation">::</span>gLogInfo <span class="token operator">&lt;&lt;</span> <span class="token string">"设备不支持int8."</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span>
  config<span class="token operator">-&gt;</span><span class="token function">setFlag</span><span class="token punctuation">(</span>nvinfer1<span class="token double-colon punctuation">::</span>BuilderFlag<span class="token double-colon punctuation">::</span>kFP16<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token keyword">else</span>
<span class="token punctuation">{<!-- --></span>
  <span class="token comment">// 设置calibrator量化校准器</span>
  <span class="token keyword">auto</span> calibrator <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">CalibrationDataReader</span><span class="token punctuation">(</span>calib_dir<span class="token punctuation">,</span> calib_list_file<span class="token punctuation">)</span><span class="token punctuation">;</span>
  config<span class="token operator">-&gt;</span><span class="token function">setFlag</span><span class="token punctuation">(</span>nvinfer1<span class="token double-colon punctuation">::</span>BuilderFlag<span class="token double-colon punctuation">::</span>kINT8<span class="token punctuation">)</span><span class="token punctuation">;</span>
  config<span class="token operator">-&gt;</span><span class="token function">setInt8Calibrator</span><span class="token punctuation">(</span>calibrator<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>运行</p> 
<pre><code class="prism language-bash"><span class="token comment"># 进入media目录，在视频中随机挑选200帧画面作为校准图片</span>
ffmpeg <span class="token parameter variable">-i</span> c3.mp4 sample%04d.png
<span class="token function">ls</span> *.png <span class="token operator">|</span> <span class="token function">shuf</span> <span class="token parameter variable">-n</span> <span class="token number">200</span> <span class="token operator">&gt;</span> filelist.txt

<span class="token comment"># build后的参数分别是onnx未知、校准集目录（用于拼接完整图片路径）、文件列表路径</span>
./build/build weights/yolov5s_person.onnx ./media/ ./media/filelist.txt 
</code></pre> 
<h4><a id="44__898"></a>4.4 预处理和后处理</h4> 
<h5><a id="441_Preprocess_900"></a>4.4.1 预处理（Preprocess）</h5> 
<p>Yolov5图像预处理步骤主要如下：</p> 
<ol><li><strong>lettorbox</strong>：即保持原图比例（图像直接resize到输入大小效果不好），将图片放在一个正方形的画布中，多余的部分用黑色填充。</li><li><strong>Normalization（归一化）</strong>：将像素值缩放至<code>[0,1]</code>间；</li><li><strong>颜色通道顺序调整</strong>：BGR2RGB</li><li><strong>NHWC 转为 NCHW</strong></li></ol> 
<p><strong>Letterbox</strong> 示例：原图为：<code>960 x 540 </code>的图片，处理后变成<code>640 x 640</code>的正方形图片：</p> 
<table><thead><tr><th>原图</th><th>Resize后</th><th>letterbox处理后</th></tr></thead><tbody><tr><td><img src="https://images2.imgbox.com/2a/21/UtEOYgq3_o.png" alt=""></td><td><img src="https://images2.imgbox.com/5b/16/U8m4Zzjh_o.jpg" alt=""></td><td><img src="https://images2.imgbox.com/ba/1f/5rSDmSMr_o.jpg" alt=""></td></tr></tbody></table> 
<p>我们可以使用<code>opencv</code>的<code>cv::warpAffine</code>函数，对图片进行仿射变换，来实现<code>letterbox</code>（在CPU上操作）：</p> 
<blockquote> 
 <p>参考代码<code>demo_test/letterbox.cpp</code></p> 
</blockquote> 
<pre><code class="prism language-c++">// 对输入图片进行letterbox处理，即保持原图比例，将图片放在一个正方形的画布中，多余的部分用黑色填充
// 使用cv::warpAffine，将图片进行仿射变换，将图片放在画布中
// 这里使用inline关键字，表示该函数在编译时会被直接替换到调用处，不会生成函数调用，提高效率
inline cv::Mat letterbox(cv::Mat &amp;src)
{
  float scale = std::min(kInputH / (float)src.rows, kInputW / (float)src.cols);

  int offsetx = (kInputW - src.cols * scale) / 2;
  int offsety = (kInputH - src.rows * scale) / 2;

  cv::Point2f srcTri[3]; // 计算原图的三个点：左上角、右上角、左下角
  srcTri[0] = cv::Point2f(0.f, 0.f);
  srcTri[1] = cv::Point2f(src.cols - 1.f, 0.f);
  srcTri[2] = cv::Point2f(0.f, src.rows - 1.f);
  cv::Point2f dstTri[3]; // 计算目标图的三个点：左上角、右上角、左下角
  dstTri[0] = cv::Point2f(offsetx, offsety);
  dstTri[1] = cv::Point2f(src.cols * scale - 1.f + offsetx, offsety);
  dstTri[2] = cv::Point2f(offsetx, src.rows * scale - 1.f + offsety);
  cv::Mat warp_mat = cv::getAffineTransform(srcTri, dstTri);       // 计算仿射变换矩阵
  cv::Mat warp_dst = cv::Mat::zeros(kInputH, kInputW, src.type()); // 创建目标图
  cv::warpAffine(src, warp_dst, warp_mat, warp_dst.size());        // 进行仿射变换
  return warp_dst;
}
</code></pre> 
<p>为了对比<code>CUDA</code>加速效果，在<code>runtime.cu</code>中，使用参数<code>mode</code>可以选择不同的处理模式：</p> 
<pre><code class="prism language-c++">// 选择预处理方式
if (mode == 0)
{
  // 使用CPU做letterbox、归一化、BGR2RGB、NHWC to NCHW
  process_input_cpu(frame, (float *)buffers.getDeviceBuffer(kInputTensorName));
}
else if (mode == 1)
{
  // 使用CPU做letterbox，GPU做归一化、BGR2RGB、NHWC to NCHW
  process_input_cv_affine(frame, (float *)buffers.getDeviceBuffer(kInputTensorName));
}
else if (mode == 2)
{
  // 使用cuda预处理所有步骤
  process_input_gpu(frame, (float *)buffers.getDeviceBuffer(kInputTensorName));
}
</code></pre> 
<h6><a id="4411_CPUletterboxBGR2RGBNHWC_to_NCHW_966"></a>4.4.1.1 使用CPU做letterbox、归一化、BGR2RGB、NHWC to NCHW</h6> 
<pre><code class="prism language-C++">// 使用CPU做letterbox、归一化、BGR2RGB、NHWC to NCHW
void process_input_cpu(cv::Mat &amp;src, float *input_device_buffer)
{

  auto warp_dst = letterbox(src);                      // letterbox
  warp_dst.convertTo(warp_dst, CV_32FC3, 1.0 / 255.0); // normalization
  cv::cvtColor(warp_dst, warp_dst, cv::COLOR_BGR2RGB); // BGR2RGB
  // NHWC to NCHW：rgbrgbrgb to rrrgggbbb：
  std::vector&lt;cv::Mat&gt; warp_dst_nchw_channels;
  cv::split(warp_dst, warp_dst_nchw_channels); // 将输入图像分解成三个单通道图像：rrrrr、ggggg、bbbbb

  // 将每个单通道图像进行reshape操作，变为1x1xHxW的四维矩阵
  for (auto &amp;img : warp_dst_nchw_channels)
  {
    // reshape参数分别是cn：通道数，rows：行数
    // 类似[[r,r,r,r,r]]或[[g,g,g,g,g]]或[[b,b,b,b,b]]，每个有width * height个元素
    img = img.reshape(1, 1);
  }
  // 将三个单通道图像拼接成一个三通道图像，即rrrrr、ggggg、bbbbb拼接成rrrgggbbb
  cv::Mat warp_dst_nchw;
  cv::hconcat(warp_dst_nchw_channels, warp_dst_nchw);
  // 将处理后的图片数据拷贝到GPU
  CUDA_CHECK(cudaMemcpy(input_device_buffer, warp_dst_nchw.ptr(), kInputH * kInputW * 3 * sizeof(float), cudaMemcpyHostToDevice));
}
</code></pre> 
<h6><a id="4412_CPUletterboxGPUBGR2RGBNHWC_to_NCHW_997"></a>4.4.1.2 使用CPU做letterbox，GPU做归一化、BGR2RGB、NHWC to NCHW</h6> 
<pre><code class="prism language-C++">// 使用CPU做letterbox，GPU做归一化、BGR2RGB、NHWC to NCHW
void process_input_cv_affine(cv::Mat &amp;src, float *input_device_buffer)
{
  auto warp_dst = letterbox(src);
  cuda_pure_preprocess(warp_dst.ptr(), input_device_buffer, kInputW, kInputH);
}

// GPU做归一化、BGR2RGB、NHWC to NCHW
void cuda_pure_preprocess(
    uint8_t *src, float *dst, int dst_width, int dst_height)
{

  int img_size = dst_width * dst_height * 3;
  CUDA_CHECK(cudaMemcpy(img_buffer_device, src, img_size, cudaMemcpyHostToDevice));

  int jobs = dst_height * dst_width;
  int threads = 256;
  int blocks = ceil(jobs / (float)threads);

  preprocess_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(
      img_buffer_device, dst, dst_width, dst_height, jobs);
}
</code></pre> 
<h6><a id="4413_GPU_1024"></a>4.4.1.3 使用GPU预处理所有步骤</h6> 
<pre><code class="prism language-c++">// 使用cuda预处理所有步骤
void process_input_gpu(cv::Mat &amp;src, float *input_device_buffer)
{
  cuda_preprocess(src.ptr(), src.cols, src.rows, input_device_buffer, kInputW, kInputH);
}
</code></pre> 
<h5><a id="442_Postprocess_1034"></a>4.4.2 后处理（Postprocess）</h5> 
<pre><code class="prism language-C++">// 执行nms（非极大值抑制），得到最后的检测框
std::vector&lt;Detection&gt; bboxs;
yolo_nms(bboxs, num_det, cls, conf, bbox, kConfThresh, kNmsThresh);

// 遍历检测结果
for (size_t j = 0; j &lt; bboxs.size(); j++)
{
  cv::Rect r = get_rect(frame, bboxs[j].bbox);
  cv::rectangle(frame, r, cv::Scalar(0x27, 0xC1, 0x36), 2);
  cv::putText(frame, std::to_string((int)bboxs[j].class_id), cv::Point(r.x, r.y - 10), cv::FONT_HERSHEY_PLAIN, 1.2, cv::Scalar(0x27, 0xC1, 0x36), 2);
}
</code></pre> 
<h4><a id="45_1052"></a>4.5人员闯入、聚众的应用开发</h4> 
<h5><a id="451__RTMP_1054"></a>4.5.1 RTMP推流</h5> 
<blockquote> 
 <p>代码位置：1.opencv_rtmp</p> 
</blockquote> 
<p>为了将渲染后的画面传输出去，可以结合推流工具，步骤如下：</p> 
<ol><li>启动<code>rtsp-simple-server</code>, 开启<code>RTMP服务器</code></li><li>使用<code>ffmpeg</code>将视频流推送到<code>RTMP服务器</code>中</li><li>通过<code>vlc</code>等客户端读取<code>rtmp://127.0.0.1:1935/live/mystream</code> 即可获取显示视频流</li></ol> 
<blockquote> 
 <p>RTMP服务器：<a href="https://github.com/aler9/rtsp-simple-server">rtsp-simple-server / MediaMTX</a> 是一个现成的、零依赖的服务器和代理，允许用户发布、读取和代理实时视频和音频流；</p> 
 <p><code>ffmpeg</code>推流工具：<a href="https://github.com/andreanobile/opencv_ffmpeg_streaming">opencv_ffmpeg_streaming</a>。</p> 
</blockquote> 
<p>如果在docker内运行，需要将端口映射出去：</p> 
<pre><code class="prism language-bash"><span class="token comment"># 映射端口并启动（注意主机端口不一样）</span>
<span class="token comment"># 1935 是RTMP端口</span>
<span class="token comment"># 8554 是RTSP端口</span>
<span class="token function">docker</span> run <span class="token parameter variable">--gpus</span> all <span class="token parameter variable">-it</span> <span class="token parameter variable">--name</span> env_trt <span class="token parameter variable">-p</span> <span class="token number">1936</span>:1935 <span class="token parameter variable">-p</span> <span class="token number">8556</span>:8554 <span class="token parameter variable">-v</span> <span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">pwd</span><span class="token variable">)</span></span>:/app env_trt_img
</code></pre> 
<pre><code class="prism language-bash"><span class="token comment"># 为了能利用之前的容器（容器内部可能已经安装好了很多组件）</span>

<span class="token comment"># 之前的启动命令（未映射端口）</span>
<span class="token function">docker</span> run <span class="token parameter variable">--gpus</span> all <span class="token parameter variable">-it</span> <span class="token parameter variable">--name</span> env_trt <span class="token parameter variable">-v</span> <span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">pwd</span><span class="token variable">)</span></span>:/app nvcr.io/nvidia/tensorrt:22.08-py3
<span class="token comment"># 停止容器</span>
<span class="token function">docker</span> stop env_trt
<span class="token comment"># 创建自定义镜像</span>
<span class="token function">docker</span> commit env_trt env_trt_img
<span class="token comment"># 重新启动</span>
</code></pre> 
<p>可以将上节课代码做一些改动（<code>代码位置：2.yolo_trt_rtmp</code>），将<code>docker</code>容器内的数据推出来查看，为了演示真实IPC读取场景，我们让<code>rtsp-simple-server</code>也模拟了一个永不结束的<code>RTSP</code>视频流。</p> 
<pre><code class="prism language-bash"><span class="token comment"># 进入rtmp_server目录</span>
<span class="token builtin class-name">cd</span> rtmp_server
<span class="token comment"># 开启RTSP模拟IPC以及RTMP服务器</span>
./start_server.sh
</code></pre> 
<blockquote> 
 <p>如果你使用的是AUTO DL等云服务，请确保对应端口开启或者使用VS Code的端口映射功能查看。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/cf/29/0ZFD4LCO_o.png" alt=""></p> 
<h5><a id="452___1104"></a>4.5.2 人员闯入应用开发</h5> 
<blockquote> 
 <p>代码位置：<code>3.yolo_trt_app/task/border_cross.cpp</code></p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/73/d2/GFOr0Wr6_o.png" alt=""></p> 
<p>人员闯入的应用是利用判断一个点是否在多边形内来实现的，多边形和点的定义如下：</p> 
<pre><code class="prism language-cpp"><span class="token comment">// Point Struct Definitiono</span>
<span class="token keyword">struct</span> <span class="token class-name">Point</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">int</span> x<span class="token punctuation">;</span>
    <span class="token keyword">int</span> y<span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>

<span class="token comment">// Polygon Struct Definition</span>
<span class="token keyword">struct</span> <span class="token class-name">Polygon</span> <span class="token punctuation">{<!-- --></span>
    std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span>Point<span class="token operator">&gt;</span> points<span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre> 
<p>在代码中实现了<strong>射线法</strong>（Ray Casting）算法，用于判断一个点是否在一个多边形内部。该算法的基本思路是从给定的点出发沿任意方向画一条射线，然后计算这条射线与多边形相交的次数。如果交点个数是奇数，则该点在多边形内部；否则，它在多边形外部。</p> 
<p>函数 isInside 接受一个 Polygon 和一个 Point 作为输入，并返回一个布尔值，指示该点是否在多边形内部。函数首先检查多边形是否至少有三个顶点，因为不到三个顶点的图形不能被视为多边形。</p> 
<p>然后，函数创建一个 extreme 点，它的 x 坐标非常大，y 坐标与给定点相同。这个点用于从给定点向右绘制一条水平射线。</p> 
<p>然后，函数循环遍历多边形的所有边，检查每个边是否与射线相交。这是使用 doIntersect 函数完成的，该函数检查两条线段是否相交。如果找到一个交点，则函数使用 orientation 函数检查交点相对于边的方向。如果方向为零，则表示交点在边上。该函数然后使用 onSegment 函数检查交点是否在边上。如果交点在边上，则函数返回 true。</p> 
<p>如果交点不在边上，则函数增加 count 变量的值。最后，如果 count 是奇数，则函数返回 true，表示该点在多边形内部；否则，它返回 false，表示该点在多边形外部。</p> 
<p><strong>总之，给定的代码通过从给定点向右绘制一条水平射线，并计算它与多边形边的交点数来判断点是否在多边形内部。如果交点数是奇数，则该点在多边形内部；如果是偶数，它在多边形外部。</strong></p> 
<pre><code class="prism language-cpp"><span class="token keyword">bool</span> <span class="token function">isInside</span><span class="token punctuation">(</span>Polygon polygon<span class="token punctuation">,</span> Point p<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">int</span> n <span class="token operator">=</span> polygon<span class="token punctuation">.</span>points<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>n <span class="token operator">&lt;</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    Point extreme <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token number">10000</span><span class="token punctuation">,</span> p<span class="token punctuation">.</span>y<span class="token punctuation">}</span><span class="token punctuation">;</span>
    <span class="token keyword">int</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token keyword">do</span> <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">int</span> next <span class="token operator">=</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> n<span class="token punctuation">;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">doIntersect</span><span class="token punctuation">(</span>polygon<span class="token punctuation">.</span>points<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> polygon<span class="token punctuation">.</span>points<span class="token punctuation">[</span>next<span class="token punctuation">]</span><span class="token punctuation">,</span> p<span class="token punctuation">,</span> extreme<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">orientation</span><span class="token punctuation">(</span>polygon<span class="token punctuation">.</span>points<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> p<span class="token punctuation">,</span> polygon<span class="token punctuation">.</span>points<span class="token punctuation">[</span>next<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                <span class="token keyword">return</span> <span class="token function">onSegment</span><span class="token punctuation">(</span>polygon<span class="token punctuation">.</span>points<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> p<span class="token punctuation">,</span> polygon<span class="token punctuation">.</span>points<span class="token punctuation">[</span>next<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
            count<span class="token operator">++</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        i <span class="token operator">=</span> next<span class="token punctuation">;</span>
    <span class="token punctuation">}</span> <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">return</span> count <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>通过<code>isInside</code>函数我们可以判断一个点是否在多边形内，从而判断是否有人员闯入。</p> 
<h5><a id="453___1161"></a>4.5.3 人员聚众应用开发</h5> 
<blockquote> 
 <p>代码位置：<code>3.yolo_trt_app/task/gather.cpp</code></p> 
</blockquote> 
<p><code>gather.cpp</code> 中<code>gather</code>函数实现了<strong>K-means聚类算法</strong>，可以将一组点分为多个聚类。通过计算每个聚类中点的标准差，可以确定每个聚类中点之间是否聚集在一起。以下是函数如何使用来确定是否有人员聚集的步骤：</p> 
<ol><li>首先，我们需要获取一组点的数据，这些点代表人员的位置。</li><li>将这些点作为参数传递给 kMeans 函数，该函数需要指定聚类数 k 和最大迭代次数。</li><li>kMeans 函数将返回一组聚类，每个聚类都是一组点。</li><li>将这些聚类作为参数传递给 isGather 函数，该函数需要指定一个阈值，该阈值表示允许的最大标准差。</li><li>isGather 函数将返回一组聚类，其中每个聚类都被认为是人员聚集的聚类。</li></ol> 
<p>调用 isGather 函数，将聚类数据和阈值作为参数传递。如果 gatherPoints 向量非空，则表示存在人员聚集。如果 gatherPoints 向量为空，则表示不存在人员聚集。</p> 
<p><code>gather_rule</code>功能是将给定的点集points按照一定的<strong>距离阈值</strong>threshold进行聚类，即将距离小于threshold的点归为一类。具体解释如下：</p> 
<p>首先定义了一个阈值threshold和一个二维的vector容器gatherPoints，用于存储聚类后的点集。 然后对于points中的每个点进行遍历。 在遍历gatherPoints之前，需要先定义一个函数averagePoint，该函数用于计算一个点集的平均点。接下来对于gatherPoints中的每个点集pts，计算该点集的平均点与当前点的距离dist。 如果dist小于阈值threshold，则将当前点加入到该点集中。 如果dist大于等于阈值threshold，则将当前点作为一个新的点集加入到gatherPoints中。 最后返回聚类后的点集gatherPoints。 总体来说，这段代码通过遍历点集并计算点之间的距离，将距离小于阈值的点归为一类，得到了聚类后的点集。最后再通过点集的大小来判断是否属于人员聚集。目前有3人及以上聚集则当作人员聚集。</p> 
<h5><a id="454___1181"></a>4.5.4 多线程流水线</h5> 
<p>多线程知识参考附录：<code>5.3 多线程pipeline Demo</code></p> 
<p>当前我们程序的大致步骤可以分为：</p> 
<ol><li>从文件或RTSP视频流读取画面帧</li><li>输入数据的预处理</li><li>推理inference</li><li>NMS后处理</li><li>绘制画面，及人员闯入及聚众应用</li><li>推流</li></ol> 
<p>其实<code>runtime.cu</code>中画面显示的FPS是根据<code>输入数据的预处理 --&gt;推理--&gt;NMS后处理 </code>（2、3、4）这三步的耗时，老师机器参考耗时输出如下：</p> 
<pre><code class="prism language-bash"><span class="token comment"># 参数：&lt;engine_file&gt; &lt;input_path_path&gt; &lt;preprocess_mode&gt; &lt;dist_threshold&gt; &lt;stream&gt; &lt;bitrate&gt;</span>

<span class="token comment"># 720P 文件，开启推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5.engine rtmp_server/c3_720.mp4  2 100 1 8000000</span>
each step time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1.316</span>,0.349,3.939,0.404,0.798,9.293
each step fps: <span class="token number">759.878</span>,2865.33,253.872,2475.25,1253.13,107.608
method <span class="token number">1</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">16.102</span>, fps: <span class="token number">62.1041</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1003.58</span>, fps: <span class="token number">60.7826</span>,frame count: <span class="token number">61</span>

<span class="token comment"># 720P 文件，关闭推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5.engine rtmp_server/c3_720.mp4  2 100 0 8000000</span>
each step time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1.376</span>,0.283,3.365,0.336,0.604,0
each step fps: <span class="token number">726.744</span>,3533.57,297.177,2976.19,1655.63,inf
method <span class="token number">1</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">5.967</span>, fps: <span class="token number">167.588</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1004.79</span>, fps: <span class="token number">157.247</span>,frame count: <span class="token number">158</span>

<span class="token comment"># 1080P 文件，开启推流</span>
<span class="token comment">#  ./build/runtime ./weights/yolov5.engine rtmp_server/c3_1080.mp4  2 100 1 8000000</span>
each step time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">2.976</span>,0.667,3.945,0.413,0.916,15.577
each step fps: <span class="token number">336.021</span>,1499.25,253.485,2421.31,1091.7,64.1972
method <span class="token number">1</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">24.497</span>, fps: <span class="token number">40.8213</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1014.25</span>, fps: <span class="token number">40.4239</span>,frame count: <span class="token number">41</span>

<span class="token comment"># 1080P 文件，关闭推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5.engine rtmp_server/c3_1080.mp4  2 100 0 8000000</span>
each step time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">2.921</span>,0.614,3.366,0.396,0.891,0
each step fps: <span class="token number">342.349</span>,1628.66,297.089,2525.25,1122.33,inf
method <span class="token number">1</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">8.191</span>, fps: <span class="token number">122.085</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1004.57</span>, fps: <span class="token number">119.454</span>,frame count: <span class="token number">120</span>

<span class="token comment"># 1080p rstp视频流，开启推流</span>
<span class="token comment">#  ./build/runtime ./weights/yolov5.engine rtsp  2 100 1 8000000</span>
each step time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">23.183</span>,0.732,3.961,0.446,0.494,10.165
each step fps: <span class="token number">43.1351</span>,1366.12,252.462,2242.15,2024.29,98.3768
method <span class="token number">1</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">38.985</span>, fps: <span class="token number">25.6509</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1002.46</span>, fps: <span class="token number">24.9388</span>,frame count: <span class="token number">25</span>

<span class="token comment"># 1080p rstp视频流，关闭推流</span>
<span class="token comment">#  ./build/runtime ./weights/yolov5.engine rtsp  2 100 0 8000000</span>
each step time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">30.315</span>,1.508,4.181,1.561,2.567,0
each step fps: <span class="token number">32.987</span>,663.13,239.177,640.615,389.56,inf
method <span class="token number">1</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">40.138</span>, fps: <span class="token number">24.914</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1013.76</span>, fps: <span class="token number">24.6607</span>,frame count: <span class="token number">25</span>
</code></pre> 
<blockquote> 
 <p>method 1 ：计算单张图片的总耗时</p> 
 <p>method 2 : 计算超过 1s 一共处理了多少张图片 (计算平均帧率)</p> 
</blockquote> 
<p>你可以调整各种参数，可以看到：</p> 
<ul><li>耗时最高的部分是： 
  <ul><li>从文件或RTSP视频流读取画面帧（1）</li><li>推理inference（3）</li><li>推流（6）</li></ul> </li><li>分辨率越高耗时越高</li><li>RTSP视频流的读流速度低于读取文件的方式（设备帧率限制），所以RTSP整体帧率基本上无法超过相机帧率</li><li>推流比特率也会影响整体速度</li><li>另外，如果画面目标较多，耗时也会增加</li></ul> 
<p>在<code>runtime_thread.cu</code>中，我们使用多线程流水线的方式来进行优化，一共分为四个线程：</p> 
<ol><li><code>readFrame</code>：从文件或RTSP视频流读取画面帧（1）</li><li><code>inference</code>：输入数据的预处理、推理inference、NMS后处理（2、3、4）</li><li><code>postprocess</code>： 和 绘制画面，及人员闯入及聚众应用（5）</li><li><code>streamer</code>：推流（6）</li></ol> 
<p>老师机器参考耗时输出如下：</p> 
<pre><code class="prism language-bash"><span class="token comment"># 1080P 文件，开启推流</span>
<span class="token comment">#  ./build/runtime_thread ./weights/yolov5.engine rtmp_server/c3_1080.mp4  2 100 1 8000000</span>
step1: <span class="token number">3</span>.099ms, fps: <span class="token number">322.685</span>
step2: <span class="token number">5</span>.077ms, fps: <span class="token number">196.967</span>
step3 time: <span class="token number">0</span>.925ms, fps: <span class="token number">1081.08</span>
step4 time: <span class="token number">14</span>.309ms, fps: <span class="token number">69.8861</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1004.54</span>, fps: <span class="token number">57.738</span>,frame count: <span class="token number">58</span>

<span class="token comment"># 1080p rstp视频流，开启推流</span>
<span class="token comment">#  ./build/runtime_thread ./weights/yolov5.engine rtsp  2 100 1 8000000</span>
step1: <span class="token number">39</span>.843ms, fps: <span class="token number">25.0985</span>
step2: <span class="token number">5</span>.342ms, fps: <span class="token number">187.196</span>
step3 time: <span class="token number">1</span>.137ms, fps: <span class="token number">879.508</span>
step4 time: <span class="token number">12</span>.741ms, fps: <span class="token number">78.4868</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1038.47</span>, fps: <span class="token number">25.0367</span>,frame count: <span class="token number">26</span>
</code></pre> 
<p>可以看到：</p> 
<ul><li>读取文件方式，所有步骤的帧率由单线程的40多提高到57；</li><li>读取rtsp方式，所有步骤的帧率无明显变化（仍然受限于相机帧率）。</li></ul> 
<h4><a id="46_jetson_nano__jetson_xavier_NX_1291"></a>4.6 jetson nano 和 jetson xavier NX部署</h4> 
<h5><a id="461_jetson_nx_1293"></a>4.6.1 jetson nx</h5> 
<blockquote> 
 <p>附件代码位置：<code>jetson代码/nx.zip</code></p> 
 <p>! 代码相对于PC有微小改动</p> 
</blockquote> 
<p>老师硬件环境参考信息（使用<code>jtop</code>得到）：</p> 
<blockquote> 
 <p>如要刷机，镜像归档参考：https://developer.nvidia.com/embedded/jetpack-archive</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/8c/bd/qOtc1uOO_o.png" alt=""></p> 
<p>编译项目准备：</p> 
<pre><code class="prism language-bash"><span class="token comment"># 如果出现No CMAKE_CUDA_COMPILER could be found，修改一下环境变量：</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span>:/usr/local/cuda/bin
<span class="token comment"># 安装依赖包</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libavutil-dev libavfilter-dev libavformat-dev libsdl2-dev libavcodec-dev libx264-dev libxvidcore-dev libvdpau-dev libva-dev libxcb-shm0-dev libwavpack-dev libvpx-dev libvorbis-dev libogg-dev libvidstab-dev libspeex-dev libopus-dev libopencore-amrnb-dev libopencore-amrwb-dev libmp3lame-dev libfreetype6-dev libfdk-aac-dev libass-dev libbz2-dev libsoxr-dev
</code></pre> 
<p><strong>YOLOv5 S 模型</strong></p> 
<ul><li>单线程</li></ul> 
<pre><code class="prism language-bash"><span class="token comment"># 参数：&lt;engine_file&gt; &lt;input_path_path&gt; &lt;preprocess_mode&gt; &lt;dist_threshold&gt; &lt;stream&gt; &lt;bitrate&gt;</span>

<span class="token comment"># 720P 文件，开启推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5s.engine rtmp_server/c3_720.mp4  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1027.08</span>, fps: <span class="token number">15.5781</span>,frame count: <span class="token number">16</span>

<span class="token comment"># 720P 文件，关闭推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5s.engine rtmp_server/c3_720.mp4  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1003.74</span>, fps: <span class="token number">59.7762</span>,frame count: <span class="token number">60</span>

<span class="token comment"># 720P RTSP，开启推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5s.engine rtsp  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1032.3</span>, fps: <span class="token number">14.5307</span>,frame count: <span class="token number">15</span>

<span class="token comment"># 720P RTSP，关闭推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5s.engine rtsp  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1034.82</span>, fps: <span class="token number">25.1251</span>,frame count: <span class="token number">26</span>
</code></pre> 
<ul><li>多线程</li></ul> 
<pre><code class="prism language-bash"><span class="token comment"># 参数：&lt;engine_file&gt; &lt;input_path_path&gt; &lt;preprocess_mode&gt; &lt;dist_threshold&gt; &lt;stream&gt; &lt;bitrate&gt;</span>

<span class="token comment"># 720P 文件，开启推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5s.engine rtmp_server/c3_720.mp4  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1046.31</span>, fps: <span class="token number">20.0705</span>,frame count: <span class="token number">21</span>

<span class="token comment"># 720P 文件，关闭推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5s.engine rtmp_server/c3_720.mp4  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1003.24</span>, fps: <span class="token number">76.7516</span>,frame count: <span class="token number">77</span>

<span class="token comment"># 720P RTSP，开启推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5s.engine rtsp  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1005.82</span>, fps: <span class="token number">19.8843</span>,frame count: <span class="token number">20</span>

<span class="token comment"># 720P RTSP，关闭推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5s.engine rtsp  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1005.57</span>, fps: <span class="token number">24.8616</span>,frame count: <span class="token number">25</span>
</code></pre> 
<p><strong>YOLOV5 N 模型</strong></p> 
<ul><li>单线程</li></ul> 
<pre><code class="prism language-bash"><span class="token comment"># 参数：&lt;engine_file&gt; &lt;input_path_path&gt; &lt;preprocess_mode&gt; &lt;dist_threshold&gt; &lt;stream&gt; &lt;bitrate&gt;</span>

<span class="token comment"># 720P 文件，开启推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5n.engine rtmp_server/c3_720.mp4  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1029.93</span>, fps: <span class="token number">16.5059</span>,frame count: <span class="token number">17</span>

<span class="token comment"># 720P 文件，关闭推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5n.engine rtmp_server/c3_720.mp4  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1007.66</span>, fps: <span class="token number">74.4296</span>,frame count: <span class="token number">75</span>

<span class="token comment"># 720P RTSP，开启推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5n.engine rtsp  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1013.58</span>, fps: <span class="token number">14.799</span>,frame count: <span class="token number">15</span>

<span class="token comment"># 720P RTSP，关闭推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5n.engine rtsp  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1003.79</span>, fps: <span class="token number">24.9057</span>,frame count: <span class="token number">25</span>
</code></pre> 
<ul><li>多线程</li></ul> 
<pre><code class="prism language-bash"><span class="token comment"># 参数：&lt;engine_file&gt; &lt;input_path_path&gt; &lt;preprocess_mode&gt; &lt;dist_threshold&gt; &lt;stream&gt; &lt;bitrate&gt;</span>

<span class="token comment"># 720P 文件，开启推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5n.engine rtmp_server/c3_720.mp4  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1046.23</span>, fps: <span class="token number">19.1162</span>,frame count: <span class="token number">20</span>

<span class="token comment"># 720P 文件，关闭推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5n.engine rtmp_server/c3_720.mp4  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1003.65</span>, fps: <span class="token number">94.655</span>,frame count: <span class="token number">95</span>

<span class="token comment"># 720P RTSP，开启推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5n.engine rtsp  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1029.55</span>, fps: <span class="token number">18.4546</span>,frame count: <span class="token number">19</span>

<span class="token comment"># 720P RTSP，关闭推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5n.engine rtsp  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1005.57</span>, fps: <span class="token number">24.8616</span>,frame count: <span class="token number">25</span>
</code></pre> 
<h5><a id="462_jetson_nano_1410"></a>4.6.2 jetson nano</h5> 
<blockquote> 
 <p>附件代码位置：附件代码位置：<code>jetson代码/nano.zip</code></p> 
 <p>! 代码相对于PC有改动</p> 
 <p>主要修改点：NANO GPU 是Maxwell 架构（<a href="https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/" rel="nofollow">参考这里</a> ），修改了<code>CMakeLists.txt</code>；</p> 
</blockquote> 
<p>老师硬件环境参考信息（使用<code>jtop</code>得到）：</p> 
<p><img src="https://images2.imgbox.com/7d/fd/vFlpermK_o.png" alt=""></p> 
<p><strong>YOLOv5 S 模型</strong></p> 
<ul><li>单线程</li></ul> 
<pre><code class="prism language-bash"><span class="token comment"># 参数：&lt;engine_file&gt; &lt;input_path_path&gt; &lt;preprocess_mode&gt; &lt;dist_threshold&gt; &lt;stream&gt; &lt;bitrate&gt;</span>

<span class="token comment"># 720P 文件，开启推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5s.engine rtmp_server/c3_720.mp4  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1115.41</span>, fps: <span class="token number">7.17228</span>,frame count: <span class="token number">8</span>

<span class="token comment"># 720P 文件，关闭推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5s.engine rtmp_server/c3_720.mp4  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1012.27</span>, fps: <span class="token number">12.8424</span>,frame count: <span class="token number">13</span>

<span class="token comment"># 720P RTSP，开启推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5s.engine rtsp  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1038.04</span>, fps: <span class="token number">8.67019</span>,frame count: <span class="token number">9</span>

<span class="token comment"># 720P RTSP，关闭推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5s.engine rtsp  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1061.26</span>, fps: <span class="token number">13.1919</span>,frame count: <span class="token number">14</span>
</code></pre> 
<ul><li>多线程</li></ul> 
<pre><code class="prism language-bash"><span class="token comment"># 参数：&lt;engine_file&gt; &lt;input_path_path&gt; &lt;preprocess_mode&gt; &lt;dist_threshold&gt; &lt;stream&gt; &lt;bitrate&gt;</span>

<span class="token comment"># 720P 文件，开启推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5s.engine rtmp_server/c3_720.mp4  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1065.54</span>, fps: <span class="token number">13.1389</span>,frame count: <span class="token number">14</span>

<span class="token comment"># 720P 文件，关闭推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5s.engine rtmp_server/c3_720.mp4  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1045.08</span>, fps: <span class="token number">13.3961</span>,frame count: <span class="token number">14</span>

<span class="token comment"># 720P RTSP，开启推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5s.engine rtsp  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1007.5</span>, fps: <span class="token number">13.8958</span>,frame count: <span class="token number">14</span>

<span class="token comment"># 720P RTSP，关闭推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5s.engine rtsp  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1011.88</span>, fps: <span class="token number">13.8356</span>,frame count: <span class="token number">14</span>
</code></pre> 
<p><strong>YOLOV5 N 模型</strong></p> 
<ul><li>单线程</li></ul> 
<pre><code class="prism language-bash"><span class="token comment"># 参数：&lt;engine_file&gt; &lt;input_path_path&gt; &lt;preprocess_mode&gt; &lt;dist_threshold&gt; &lt;stream&gt; &lt;bitrate&gt;</span>

<span class="token comment"># 720P 文件，开启推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5n.engine rtmp_server/c3_720.mp4  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1059.62</span>, fps: <span class="token number">9.43736</span>,frame count: <span class="token number">10</span>

<span class="token comment"># 720P 文件，关闭推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5n.engine rtmp_server/c3_720.mp4  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1025.55</span>, fps: <span class="token number">23.402</span>,frame count: <span class="token number">24</span>

<span class="token comment"># 720P RTSP，开启推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5n.engine rtsp  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1044</span>, fps: <span class="token number">11.4942</span>,frame count: <span class="token number">12</span>

<span class="token comment"># 720P RTSP，关闭推流</span>
<span class="token comment"># ./build/runtime ./weights/yolov5n.engine rtsp  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1039.09</span>, fps: <span class="token number">25.0219</span>,frame count: <span class="token number">26</span>
</code></pre> 
<ul><li>多线程</li></ul> 
<pre><code class="prism language-bash"><span class="token comment"># 参数：&lt;engine_file&gt; &lt;input_path_path&gt; &lt;preprocess_mode&gt; &lt;dist_threshold&gt; &lt;stream&gt; &lt;bitrate&gt;</span>

<span class="token comment"># 720P 文件，开启推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5n.engine rtmp_server/c3_720.mp4  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1038.55</span>, fps: <span class="token number">14.4432</span>,frame count: <span class="token number">15</span>

<span class="token comment"># 720P 文件，关闭推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5n.engine rtmp_server/c3_720.mp4  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1023.37</span>, fps: <span class="token number">26.3835</span>,frame count: <span class="token number">27</span>

<span class="token comment"># 720P RTSP，开启推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5n.engine rtsp  2 100 1 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1032.58</span>, fps: <span class="token number">19.3689</span>,frame count: <span class="token number">20</span>

<span class="token comment"># 720P RTSP，关闭推流</span>
<span class="token comment"># ./build/runtime_thread ./weights/yolov5n.engine rtsp  2 100 0 2000000</span>
method <span class="token number">2</span> all steps time<span class="token punctuation">(</span>ms<span class="token punctuation">)</span>: <span class="token number">1026.91</span>, fps: <span class="token number">27.2662</span>,frame count: <span class="token number">28</span>
</code></pre> 
<h3><a id="_1518"></a>五、附录：</h3> 
<h4><a id="51_CUDA__quickstart_1520"></a>5.1 CUDA quickstart</h4> 
<h5><a id="511__1522"></a>5.1.1 简介</h5> 
<p>CUDA是一种并行计算平台和编程模型，由NVIDIA推出，它可以利用GPU（图形处理器）进行高效的并行计算。使用CUDA编程可以提高计算密集型应用程序的性能，例如图像处理、科学计算、机器学习、深度学习等。相比于使用CPU进行串行计算，使用GPU并行计算可以大大提高计算速度和效率（如图像数据归一化，需要对每个像素值进行操作）。</p> 
<p>CUDA编程的基本步骤可以概括为以下几个部分：</p> 
<ol><li> <p><strong>定义kernel核函数</strong>：首先需要定义一个kernel函数，用于在GPU上执行并行计算任务。使用<code>__global__</code>关键字来标记kernel函数，表示它将在GPU上执行。</p> </li><li> <p><strong>分配内存并初始化数据</strong>：接下来需要在主机端分配内存，并初始化数据。然后，使用<code>cudaMalloc()</code>函数在GPU上分配相同大小的内存，并使用<code>cudaMemcpy()</code>函数将数据从主机端复制到GPU上。</p> </li><li> <p><strong>启动kernel函数</strong>：使用<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>语法启动kernel函数，将线程块的数量和大小作为参数传递给kernel函数。线程块的数量和大小通常需要根据计算任务的特点进行调整，以最大化利用GPU的计算能力。</p> </li><li> <p><strong>将结果从GPU上复制回主机端</strong>：执行kernel函数后，需要使用<code>cudaMemcpy()</code>函数将结果从GPU上复制回主机端。这样我们就可以在主机端访问并处理这些数据了。</p> </li><li> <p><strong>释放内存</strong>：最后需要使用<code>cudaFree()</code>函数释放在GPU上分配的内存，并使用标准的C或C++语言函数释放在主机端分配的内存。</p> </li></ol> 
<h5><a id="512__blockthread_1540"></a>5.1.2 线程块 block、线程thread</h5> 
<p>在CUDA编程中，一个CUDA Kernel 是由众多的线程（threads）组成的，这些线程可以被组织成一个或多个block（块），而这些block又可以被组织成一个或多个grid（网格），如下图：</p> 
<p><img src="https://images2.imgbox.com/b2/cb/uxWIacrq_o.png" alt=""></p> 
<ul><li><strong>Thread</strong>：线程是CUDA中最基本的执行单元，每个线程都执行相同的操作，但操作的数据不同。</li><li><strong>BLock</strong>：线程块是线程的集合，所有线程共享同一线程块的共享内存，并且可以通过线程块内同步方式进行通信。</li><li><strong>Grid</strong>：网格是线程块的集合，网格中的所有线程块可以同时执行，每个线程块的线程都相互独立，块之间不能直接通信。</li></ul> 
<p>一个grid可以包含多个block，block可以是一维、二维或三维的，block中的thread也可以是一维、二维或三维的。每个线程都有一个唯一的线程ID，可以用来访问不同的数据和内存位置。在同一个线程块中，线程ID是从0开始连续编号的，可以通过内置变量 <code>threadIdx</code> 来获取：</p> 
<pre><code class="prism language-C++">// 获取本线程的索引，blockIdx 指的是线程块的索引，blockDim 指的是线程块的大小，threadIdx 指的是本线程块中的线程索引
int tid = blockIdx.x * blockDim.x + threadIdx.x;    
</code></pre> 
<p>在CUDA编程中，block和thread的数量和大小通常需要根据计算任务的特点进行调整，以最大化利用GPU的计算能力。例如，对于大规模的并行计算任务，可以使用更多的线程和线程块来充分利用GPU的并行处理能力。而对于计算量较小的任务，使用更少的线程和线程块可能会更高效。</p> 
<pre><code class="prism language-C++">// 计算需要的线程总量（高度 x 宽度）:640*640=409600
int jobs = dst_height * dst_width;
// 一个线程块包含256个线程
int threads = 256;
// 计算线程块的数量
int blocks = ceil(jobs / (float)threads);

// 调用kernel函数
preprocess_kernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(
  img_buffer_device, dst, dst_width, dst_height, jobs); // 函数的参数
</code></pre> 
<h5><a id="513_kernel__1574"></a>5.1.3 kernel 函数</h5> 
<p>在CUDA编程中，kernel函数是在GPU上执行的函数，用于实现并行计算任务。当启动kernel函数时，GPU上的每个线程都会执行相同的程序代码，从而实现高效的并行计算。</p> 
<p>在CUDA中，我们可以使用<code>__global__</code>关键字来标记一个函数，使之成为kernel函数。<code>__global__</code>关键字告诉编译器这个函数将在GPU上执行，而不是在CPU上执行。除此之外，kernel函数和普通的函数并没有太大区别，可以有输入参数和输出参数，可以有本地变量和控制流程语句，甚至可以调用其他函数。</p> 
<p>在kernel函数中，我们可以使用一些内置的变量和函数来获取当前线程的信息，例如<code>threadIdx、blockIdx、blockDim</code>等。这些变量和函数可以帮助我们确定当前线程的位置和执行流程，从而更好地调度并行计算任务的执行。</p> 
<p>启动kernel函数需要使用<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>语法。<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>中第一个参数一般是一个整数，用于指定线程块的数量。第二个参数是一个整数或一个<code>dim3</code>类型，用于指定每个线程块中的线程数量。<code>dim3</code>类型是一个三维向量，可以分别指定每个线程块中<code>x、y、z</code>方向的线程数量。如果只指定了一个整数，那么默认使用这个整数作为x方向的线程数量，而y和z方向的线程数量默认为1。</p> 
<pre><code class="prism language-C++">// 向量加法
__global__ void add(int *a, int *b, int *c, int N)
{   
    // 获取本线程块的索引，blockIdx 指的是线程块的索引，blockDim 指的是线程块的大小，threadIdx 指的是线程的索引
    int tid = blockIdx.x * blockDim.x + threadIdx.x;    
    if (tid &lt; N)
        c[tid] = a[tid] + b[tid];
}
// 调用kernel函数
add&lt;&lt;&lt;n_blocks, n_threads&gt;&gt;&gt;(dev_a, dev_b, dev_c, N); 
</code></pre> 
<h5><a id="514__1599"></a>5.1.4 代码解释</h5> 
<p><code>simple.cu</code>演示了如何使用CUDA在GPU上进行向量加法，并比较使用CPU和GPU的时间。</p> 
<h4><a id="52_TensorRT_plugin_1605"></a>5.2 TensorRT plugin</h4> 
<blockquote> 
 <p>TensorRT插件的编写涉及CUDA、网络操作细节知识较多，本节是YOLOV5 decode的样例，仅作参考。</p> 
 <p>在实现插件时，需要根据插件的具体功能来设计相应的计算逻辑，更多介绍请参考：https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#extending</p> 
</blockquote> 
<h5><a id="521_Yolov5_decode_1613"></a>5.2.1 Yolov5 decode流程</h5> 
<p>将YOLOv5 COCO预训练模型（80个类别）导出ONNX，可查看到3个head（shape分别是<code>[255,80,80], [255,40,40], [255,20,20]</code>），经过decode后变成最终的输出output （<code>[25200,85]</code>），再经过NMS就可以得到最终的检测框。</p> 
<p><img src="https://images2.imgbox.com/a0/e9/7e08225F_o.png" alt=""></p> 
<p><strong>decode、后处理的大致流程：</strong></p> 
<ul><li> <p>输入图片推理得到3个head的特征图</p> <img src="https://images2.imgbox.com/13/b4/fwNCiu0b_o.jpg"> </li><li> <p>将每个head 变形，下图是其中<code>[255,80,80]</code> 这个head的变形</p> 
  <ul><li>因为有3种anchor，<code>[255,80,80]</code>可以转换为3个<code>[85,80,80]</code>的Tensor，即<code>[3,85,80,80]</code></li><li>取出其中一个Tensor的一个cell，即一个网格的预测结果，大小为<code>[85,1,1]</code> 
    <ul><li>其中1,1表示网格的横纵坐标位置</li><li>85表示：<code>(tx,ty,tw,th,score, [0,0,1,...,0,0,0] )</code>即检测框的<code>xywh</code>和<code>score</code>，80个类别独热编码的<code>classes</code></li><li>decode的核心流程就是根据<code>tx,ty,tw,th</code>计算<code>bx,by,bw,bh</code></li></ul> </li></ul> <p><img src="https://images2.imgbox.com/0c/62/KHHWPShW_o.png" alt=""></p> </li><li> <p>计算<code>bx,by,bw,bh</code></p> <img src="https://images2.imgbox.com/6f/8d/inXtBZBm_o.jpg"> 
  <ul><li>蓝色为预测框，黑色虚线为anchor</li></ul> <p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             b 
            
           
             x 
            
           
          
            = 
           
          
            2 
           
          
            σ 
           
          
            ( 
           
           
           
             t 
            
           
             x 
            
           
          
            ) 
           
          
            − 
           
          
            0.5 
           
          
            + 
           
           
           
             c 
            
           
             x 
            
           
           
           
           
             b 
            
           
             y 
            
           
          
            = 
           
          
            2 
           
          
            σ 
           
          
            ( 
           
           
           
             t 
            
           
             y 
            
           
          
            ) 
           
          
            − 
           
          
            0.5 
           
          
            + 
           
           
           
             c 
            
           
             y 
            
           
           
           
           
             b 
            
           
             w 
            
           
          
            = 
           
           
           
             p 
            
           
             w 
            
           
          
            ( 
           
          
            2 
           
          
            σ 
           
          
            ( 
           
           
           
             t 
            
           
             w 
            
           
          
            ) 
           
           
           
             ) 
            
           
             2 
            
           
           
           
           
             b 
            
           
             h 
            
           
          
            = 
           
           
           
             p 
            
           
             h 
            
           
          
            ( 
           
          
            2 
           
          
            σ 
           
          
            ( 
           
           
           
             t 
            
           
             h 
            
           
          
            ) 
           
           
           
             ) 
            
           
             2 
            
           
          
         
           b_x = 2\sigma(t_x)-0.5+c_x \\ b_y = 2\sigma(t_y)-0.5+c_y \\ b_w = p_w(2\sigma(t_w))^2 \\ b_h = p_h(2\sigma(t_h))^2 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">0.5</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 0.9805em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">0.5</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.1141em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.1141em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></p> 
  <blockquote> 
   <p>bx, by取值范围 (-0.5,1.5) 负责一个网格一定范围内中心点的预测</p> 
   <p>bw,bh取值范围(0,4) ，即是anchor宽度高度调节范围的0~4倍</p> 
  </blockquote> </li><li> <p>最后三个特征图，每个特征图3种anchor，转换下来：</p> 
  <ul><li><code>[255,80,80]</code> --&gt; <code>[3,80,80,85]</code> --&gt; <code>[19200,85]</code></li><li><code>[255,40,40]</code> --&gt; <code>[3,40,40,85]</code> --&gt; <code>[4800,85]</code></li><li><code>[255,20,20]</code> --&gt; <code>[3,20,20,85]</code> --&gt; <code>[1200,85]</code></li><li>最终组合到一起，最终的输出为<code>[25200,85]</code> ，85中80是类别数量</li></ul> </li><li> <p>NMS筛选最终的检测框</p> </li></ul> 
<h5><a id="522_plugin_1663"></a>5.2.2 plugin基本流程介绍</h5> 
<p>在我们之前的介绍中提到，我们使用了<code>YoloLayer_TRT</code>插件，其功能是<code>decode onnx</code>模型的输出，这里的<code>decode</code>算子用GPU实现并加速了，以提高模型吞吐量。</p> 
<blockquote> 
 <p>参考：3.3 具体修改细节</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/0e/9b/RTmZGo95_o.png" alt=""></p> 
<p>实现TensorRT Plugin需要实现插件类，和插件工厂类，并对插件进行注册。步骤如下：</p> 
<ol><li> <p>定义插件版本和插件名:</p> 
  <blockquote> 
   <p>位置：<code>yoloPlugins.h</code> 第51行</p> 
  </blockquote> </li></ol> 
<pre><code class="prism language-cpp"><span class="token comment">// 定义插件版本和插件名</span>
<span class="token keyword">namespace</span>
<span class="token punctuation">{<!-- --></span>
    <span class="token keyword">const</span> <span class="token keyword">char</span> <span class="token operator">*</span>YOLOLAYER_PLUGIN_VERSION<span class="token punctuation">{<!-- --></span><span class="token string">"1"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>
    <span class="token keyword">const</span> <span class="token keyword">char</span> <span class="token operator">*</span>YOLOLAYER_PLUGIN_NAME<span class="token punctuation">{<!-- --></span><span class="token string">"YoloLayer_TRT"</span><span class="token punctuation">}</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> <span class="token comment">// namespace</span>
</code></pre> 
<ol start="2"><li> <p>实现插件类</p> 
  <blockquote> 
   <p>位置：<code>yoloPlugins.h</code> 第58行</p> 
  </blockquote> <p>插件类需要继承<code>IPluginV2DynamicExt</code>类。这份代码中定义的插件类名是<code>YoloLayer</code>，其中实现了<code>IPluginV2DynamicExt</code>中的虚函数和一些成员变量和函数。</p> </li></ol> 
<pre><code class="prism language-cpp"><span class="token keyword">class</span> <span class="token class-name">YoloLayer</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> nvinfer1<span class="token double-colon punctuation">::</span><span class="token class-name">IPluginV2DynamicExt</span></span>
<span class="token punctuation">{<!-- --></span>
<span class="token keyword">public</span><span class="token operator">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">private</span><span class="token operator">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre> 
<ol start="3"><li> <p>实现插件创建类</p> 
  <blockquote> 
   <p>位置：<code>yoloPlugins.h</code> 第112行</p> 
  </blockquote> <p>插件创建类需要继承<code>IPluginCreator</code>类，并实现其中的虚函数。这份代码中定义的插件创建类名是<code>YoloLayerPluginCreator</code>，其中实现了<code>IPluginCreator</code>中的虚函数和一些成员变量和函数。</p> </li></ol> 
<pre><code class="prism language-cpp"><span class="token keyword">class</span> <span class="token class-name">YoloLayerPluginCreator</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> nvinfer1<span class="token double-colon punctuation">::</span><span class="token class-name">IPluginCreator</span></span>
<span class="token punctuation">{<!-- --></span>
<span class="token keyword">public</span><span class="token operator">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

<span class="token keyword">private</span><span class="token operator">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre> 
<p>上述代码定义在头文件<code>yoloPlugins.h</code>中，具体的函数实现放在了<code>yoloPlugins.cpp</code>文件中，同时核心的计算部分由cuda进行实现，放在了<code>yoloForward_nc.cu</code>中。</p> 
<ol start="4"><li> <p>注册插件</p> 
  <blockquote> 
   <p>位置：<code>yoloPlugins.cpp</code> 第341行</p> 
  </blockquote> <p>在实现了各个类方法后，需要调用宏对plugin进行注册。以方便TensorRT识别并找到对应的Plugin。</p> </li></ol> 
<pre><code class="prism language-cpp"><span class="token function">REGISTER_TENSORRT_PLUGIN</span><span class="token punctuation">(</span>YoloLayerPluginCreator<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<ol start="5"><li>编译插件库并使用</li></ol> 
<pre><code class="prism language-cmake">add_library(yolo_plugin SHARED
    plugins/yoloPlugins.cpp
    plugins/yoloForward_nc.cu
)
add_executable(build
    build.cu
    ${TensorRT_SAMPLE_DIR}/common/logger.cpp
    ${TensorRT_SAMPLE_DIR}/common/sampleUtils.cpp
)
# 这里需要注意加上-Wl,--no-as-needed，否则可能连接失败
target_link_libraries(build PRIVATE -Wl,--no-as-needed yolo_plugin) # -Wl,--no-as-needed is needed to avoid linking errors
</code></pre> 
<h5><a id="523_Plugin_1748"></a>5.2.3 Plugin中需要实现的方法介绍</h5> 
<p>核心需要实现的方法有<code>configurePlugin</code>, <code>enqueue</code>, 还有用于序列化和反序列的方法。</p> 
<ol><li><code>configurePugin</code>用于配置相关参数的信息：</li></ol> 
<pre><code class="prism language-cpp"><span class="token keyword">void</span> <span class="token class-name">YoloLayer</span><span class="token double-colon punctuation">::</span><span class="token function">configurePlugin</span><span class="token punctuation">(</span>
    <span class="token keyword">const</span> nvinfer1<span class="token double-colon punctuation">::</span>DynamicPluginTensorDesc <span class="token operator">*</span>in<span class="token punctuation">,</span> <span class="token keyword">int</span> nbInputs<span class="token punctuation">,</span> <span class="token keyword">const</span> nvinfer1<span class="token double-colon punctuation">::</span>DynamicPluginTensorDesc <span class="token operator">*</span>out<span class="token punctuation">,</span> <span class="token keyword">int</span> nbOutputs<span class="token punctuation">)</span> <span class="token keyword">noexcept</span>
<span class="token punctuation">{<!-- --></span>
  <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre> 
<ol start="2"><li><code>enqueue</code>方法则是进行模型推理，需要调用对应的推理代码。</li></ol> 
<pre><code class="prism language-C++">int YoloLayer::enqueue(const nvinfer1::PluginTensorDesc *inputDesc, const nvinfer1::PluginTensorDesc *outputDesc, const void *const *inputs,
                       void *const *outputs, void *workspace, cudaStream_t stream) noexcept
{
	  .......
    return 0;
}    
</code></pre> 
<ol start="3"><li>另外一个比较重要的是序列化，序列化需要把plugin的参数存入序列化数据中，如下代码所示：</li></ol> 
<pre><code class="prism language-cpp"><span class="token keyword">void</span> <span class="token class-name">YoloLayer</span><span class="token double-colon punctuation">::</span><span class="token function">serialize</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span> buffer<span class="token punctuation">)</span> <span class="token keyword">const</span> <span class="token keyword">noexcept</span>
<span class="token punctuation">{<!-- --></span>
    <span class="token keyword">char</span> <span class="token operator">*</span>d <span class="token operator">=</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">char</span><span class="token operator">*</span><span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>buffer<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">write</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_NetWidth<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">write</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_NetHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">write</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_MaxStride<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">write</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_NumClasses<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">write</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_ScoreThreshold<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">write</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_OutputSize<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// write anchors:</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> m_Anchors<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token function">write</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_Anchors<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">// write feature size:</span>
    uint yoloTensorsSize <span class="token operator">=</span> m_FeatureSpatialSize<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>uint i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> yoloTensorsSize<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token function">write</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_FeatureSpatialSize<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">h</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">write</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_FeatureSpatialSize<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">w</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>其中write函数把plugin的参数写到对应的内存位置，在后续将模型序列化存入磁盘时，这些数据也会被存入模型文件中。在反序列化的过程中，模型序列化数据又会被解析出来用于创建plugin。如下：</p> 
<pre><code class="prism language-cpp"><span class="token class-name">YoloLayer</span><span class="token double-colon punctuation">::</span><span class="token function">YoloLayer</span> <span class="token punctuation">(</span><span class="token keyword">const</span> <span class="token keyword">void</span><span class="token operator">*</span> data<span class="token punctuation">,</span> size_t length<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
    <span class="token keyword">const</span> <span class="token keyword">char</span> <span class="token operator">*</span>d <span class="token operator">=</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">const</span> <span class="token keyword">char</span><span class="token operator">*</span><span class="token operator">&gt;</span></span></span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">read</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_NetWidth<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">read</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_NetHeight<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">read</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_MaxStride<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">read</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_NumClasses<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">read</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_ScoreThreshold<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">read</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_OutputSize<span class="token punctuation">)</span><span class="token punctuation">;</span>

    m_Anchors<span class="token punctuation">.</span><span class="token function">resize</span><span class="token punctuation">(</span>NFEATURES <span class="token operator">*</span> NANCHORS <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span>uint i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> m_Anchors<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token function">read</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> m_Anchors<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">for</span><span class="token punctuation">(</span>uint i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> NFEATURES<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token keyword">int</span> height<span class="token punctuation">;</span>
        <span class="token keyword">int</span> width<span class="token punctuation">;</span>
        <span class="token function">read</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> height<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">read</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> width<span class="token punctuation">)</span><span class="token punctuation">;</span>
        m_FeatureSpatialSize<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>nvinfer1<span class="token double-colon punctuation">::</span><span class="token function">DimsHW</span><span class="token punctuation">(</span>height<span class="token punctuation">,</span> width<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre> 
<p>在上面的构造函数中实现了从序列化数据中读取参数的功能，以构造plugin。Plugin需要实现的核心函数包括：</p> 
<ul><li><code>getOutputDimensions()</code>：计算并返回插件的输出张量的尺寸。</li><li><code>enqueue()</code>：执行插件的前向传播计算。</li><li><code>configurePlugin()</code>：设置插件的参数和输入/输出张量的数据类型等信息。</li><li><code>getSerializationSize()</code>和<code>serialize()</code>：用于插件的序列化。</li><li><code> deserialize()</code>：用于插件的反序列化。</li></ul> 
<p>在实现插件时，需要根据插件的具体功能来设计相应的计算逻辑，并在<code>enqueue()</code>函数中实现。同时，还需要根据插件的输入/输出张量的数据类型等信息来设置插件的参数，在<code>configurePlugin()</code>函数中实现。最后,通过宏注册<code>plugin</code>，并和主程序一起编译即可。</p> 
<pre><code class="prism language-C++">// 注册插件。 在实现了各个类方法后，需要调用宏对plugin进行注册。以方便TensorRT识别并找到对应的Plugin。
REGISTER_TENSORRT_PLUGIN(YoloLayerPluginCreator);
</code></pre> 
<h4><a id="53_pipeline_Demo_1850"></a>5.3 多线程pipeline Demo</h4> 
<blockquote> 
 <p>附件位置：<code>4.thread_pipeline </code></p> 
</blockquote> 
<p>示例代码实现了一个生产者-消费者模型，使用队列作为共享资源来存储生产者生产的数据，消费者从队列中取出数据进行消费。在这个模型中，生产者和消费者是两个不同的线程，共享同一个队列。</p> 
<ul><li> <p>定义了一个全局变量 buffer 代表队列，大小为 <code>buffer_size</code>，设置为 10。</p> </li><li> <p>使用互斥锁 <code>buffer_mutex</code> 来保护对队列的访问，以确保生产者和消费者不能同时访问队列。</p> </li><li> <p><code>not_full</code> 和 <code>not_empty</code> 是条件变量，用于在队列满时阻塞生产者线程，在队列为空时阻塞消费者线程。</p> </li><li> <p>生产者线程的函数是 <code>produce()</code>，它将数字 1 到 20 添加到队列中。生产者线程首先尝试获取互斥锁，然后在条件变量 <code>not_full</code> 上等待，直到队列不再满。一旦队列未满，生产者线程将数字添加到队列中，并发送信号给条件变量 <code>not_empty</code>，通知消费者线程队列中已有数据可以消费。</p> </li><li> <p>消费者线程的函数是 <code>consume()</code>，它从队列中取出数字并进行消费。消费者线程也首先尝试获取互斥锁，然后在条件变量 <code>not_empty</code> 上等待，直到队列中有数据可供消费。一旦有数据可供消费，消费者线程将数字从队列中删除，并发送信号给条件变量 <code>not_full</code>，通知生产者线程队列中已有空间可以继续生产数据。</p> </li><li> <p>在主函数 main() 中，我们创建了两个线程，一个用于生产者函数 <code>producer()</code>，另一个用于消费者函数 <code>consumer()</code>。然后我们等待两个线程执行完毕，使用 <code>join()</code> 函数来等待线程完成执行。</p> </li></ul> 
<p>这段代码演示了如何使用互斥锁和条件变量实现生产者-消费者模型，实现了线程之间的同步，以确保生产者和消费者在访问共享资源时不会发生竞争条件问题。</p> 
<p>使用<code>g++ main.cpp -std=c++14 -pthread</code>编译代码，并执行<code>./a.out</code>执行代码查看运行结果。</p> 
<p><strong><font color="red">备注：本文为修改后的转载，没有转载链接，所以文章类型暂为原创</font></strong></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/167cf2da7bed0de350fb9b1970a19a06/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">undefined reference to symbol ‘pthread_create‘解决方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9aad27fc99732c70bab3b91e262fede4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">史上最全的Linux常用命令汇总（超全面！超详细！）收藏这一篇就够了！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>