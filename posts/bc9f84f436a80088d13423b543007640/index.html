<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【复盘与分享】第十一届泰迪杯B题：产品订单的数据分析与需求预测 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【复盘与分享】第十一届泰迪杯B题：产品订单的数据分析与需求预测" />
<meta property="og:description" content="文章目录 题目第一问第二问2.1 数据预处理2.2 数据集分析2.2.1 训练集2.2.2 预测集 2.3 特征工程2.4 模型建立2.4.1 模型框架和评价指标2.4.2 模型建立2.4.3 误差分析和特征筛选2.4.4 新品模型 2.5 模型融合2.6 预测方法2.7 总结 结尾 距离比赛结束已经过去两个多月了。
整个过程还是非常辛苦的，在前期整个团队都在进行学习铺垫，精力主要集中在全部数据给出后的建模
收到了答辩的通知，可惜评委问的问题太过离谱，没能展现出我们的创新点，最终没能获得特等奖，是个国一
因为感觉对我们的工作进行一个总结，对很多准备相关比赛的同学还是挺有帮助的，所以还是复盘一下
所有的代码和数据已经上传至github
链接：ProductDemandForecast-TeddyCup11B
大家不用在评论区问我要了，明年会将论文和答辩ppt也开源供大家学习，请自觉点赞收藏，给github点点star（论文已更新）
用Prophet一个个商品预测肯定是错误的，训练时间太长。先整合成结构化数据，再上机器学习才是合理的做法
题目 任务1：数据分析
针对提供的历史销售数据(order_train1.csv)，需要进行深入的数据分析。分析主题包括但不限于：
1.1 产品的不同价格对需求量的影响
1.2 产品所在区域对需求量的影响，以及不同区域的产品需求量有何特性
1.3 不同销售方式（线上和线下）的产品需求量的特性
1.4 不同品类之间的产品需求量有何不同点和共同点
1.5 不同时间段（例如月头、月中、月末等）产品需求量有何特性
1.6 节假日对产品需求量的影响
1.7 促销（如618、双十一等）对产品需求量的影响
1.8 季节因素对产品需求量的影响
任务2：需求预测
基于上述分析，需要建立数学模型，对给出的产品(predict_sku1.csv)进行未来3个月（即2019年1月、2月、3月）的月需求量预测。预测结果需要按照给定格式保存为文件result1.xlsx。
请分别按照天、周、月的时间粒度进行预测，并尝试分析不同的预测粒度对预测精度可能产生的影响。
第一问 第一问就是数据探索性分析，没啥好说的，现在会调chatgpt并且进行简单的修改就能做出不错的图了。
虽然题目的意思可能是通过第一问的分析，对第二问的建模起到什么帮助，可能会在论文里看起来不错，但说实话屁用没有。第二问预测靠的还是特征工程等经验。所以第一问不是重点，展示几个图吧，不细讲了。
价格与需求量散点图 线下/线上订单需求量随时间变化趋势图 各大类/细类产品需求量占比双环图 各大类产品月需求量气泡图 不同时段（月初、月中、月末）的产品需求量折线图 线下/上销售趋势 “6.18”和“双十一”期间Top50促销产品所属细类双向柱状图 第二问 第二问要预测的精准，还是比较考验学习、代码能力的，当时是看了好几个销量预测的比赛代码，主要是kaggle上的，并且一步步自己改。搭出Baseline后，能先有一个预测的结果，再一步步的加上自己的想法。
以下内容都是先有Baseline后一步步试出来的，所以会有些跳跃性
一些链接（很多我找不到了）：
详细的EDA和随机森林
1st place solution - Part 1 - “Hands on Data”" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/bc9f84f436a80088d13423b543007640/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-11T18:36:11+08:00" />
<meta property="article:modified_time" content="2023-12-11T18:36:11+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【复盘与分享】第十一届泰迪杯B题：产品订单的数据分析与需求预测</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_17" rel="nofollow">题目</a></li><li><a href="#_38" rel="nofollow">第一问</a></li><li><a href="#_87" rel="nofollow">第二问</a></li><li><ul><li><a href="#21__101" rel="nofollow">2.1 数据预处理</a></li><li><a href="#22__129" rel="nofollow">2.2 数据集分析</a></li><li><ul><li><a href="#221__131" rel="nofollow">2.2.1 训练集</a></li><li><a href="#222__157" rel="nofollow">2.2.2 预测集</a></li></ul> 
   </li><li><a href="#23__165" rel="nofollow">2.3 特征工程</a></li><li><a href="#24__173" rel="nofollow">2.4 模型建立</a></li><li><ul><li><a href="#241__175" rel="nofollow">2.4.1 模型框架和评价指标</a></li><li><a href="#242__185" rel="nofollow">2.4.2 模型建立</a></li><li><a href="#243__193" rel="nofollow">2.4.3 误差分析和特征筛选</a></li><li><a href="#244__203" rel="nofollow">2.4.4 新品模型</a></li></ul> 
   </li><li><a href="#25__210" rel="nofollow">2.5 模型融合</a></li><li><a href="#26__218" rel="nofollow">2.6 预测方法</a></li><li><a href="#27__228" rel="nofollow">2.7 总结</a></li></ul> 
  </li><li><a href="#_234" rel="nofollow">结尾</a></li></ul> 
</div> 
<p></p> 
<blockquote> 
 <p>距离比赛结束已经过去两个多月了。</p> 
 <p>整个过程还是非常辛苦的，在前期整个团队都在进行学习铺垫，精力主要集中在全部数据给出后的建模</p> 
 <p>收到了答辩的通知，可惜评委问的问题太过离谱，没能展现出我们的创新点，最终没能获得特等奖，是个国一</p> 
 <p>因为感觉对我们的工作进行一个总结，对很多准备相关比赛的同学还是挺有帮助的，所以还是复盘一下</p> 
</blockquote> 
<p>所有的代码和数据已经上传至github</p> 
<blockquote> 
 <p>链接：<a href="https://github.com/wanziw/ProductDemandForecast-TeddyCup11B/">ProductDemandForecast-TeddyCup11B</a><br> 大家不用在评论区问我要了，明年会将论文和答辩ppt也开源供大家学习，请自觉点赞收藏，给github点点star（论文已更新）</p> 
</blockquote> 
<p>用Prophet一个个商品预测肯定是错误的，训练时间太长。先整合成结构化数据，再上机器学习才是合理的做法</p> 
<h2><a id="_17"></a>题目</h2> 
<p><strong>任务1：数据分析</strong></p> 
<p>针对提供的历史销售数据(order_train1.csv)，需要进行深入的数据分析。分析主题包括但不限于：</p> 
<p>1.1 产品的不同价格对需求量的影响<br> 1.2 产品所在区域对需求量的影响，以及不同区域的产品需求量有何特性<br> 1.3 不同销售方式（线上和线下）的产品需求量的特性<br> 1.4 不同品类之间的产品需求量有何不同点和共同点<br> 1.5 不同时间段（例如月头、月中、月末等）产品需求量有何特性<br> 1.6 节假日对产品需求量的影响<br> 1.7 促销（如618、双十一等）对产品需求量的影响<br> 1.8 季节因素对产品需求量的影响</p> 
<p><strong>任务2：需求预测</strong></p> 
<p>基于上述分析，需要建立数学模型，对给出的产品(predict_sku1.csv)进行未来3个月（即2019年1月、2月、3月）的月需求量预测。预测结果需要按照给定格式保存为文件result1.xlsx。</p> 
<p>请分别按照天、周、月的时间粒度进行预测，并尝试分析不同的预测粒度对预测精度可能产生的影响。</p> 
<h2><a id="_38"></a>第一问</h2> 
<p>第一问就是数据探索性分析，没啥好说的，现在会调chatgpt并且进行简单的修改就能做出不错的图了。</p> 
<p>虽然题目的意思可能是通过第一问的分析，对第二问的建模起到什么帮助，可能会在论文里看起来不错，但说实话屁用没有。第二问预测靠的还是特征工程等经验。所以第一问不是重点，展示几个图吧，不细讲了。</p> 
<ul><li>价格与需求量散点图</li></ul> 
<p><img src="https://images2.imgbox.com/47/ac/xFArjn6K_o.jpg" alt=""></p> 
<ul><li>线下/线上订单需求量随时间变化趋势图</li></ul> 
<p><img src="https://images2.imgbox.com/9f/61/GtFWy5A3_o.jpg" alt=""></p> 
<ul><li>各大类/细类产品需求量占比双环图</li></ul> 
<p><img src="https://images2.imgbox.com/e6/e9/pRbddX8n_o.jpg" alt=""></p> 
<ul><li>各大类产品月需求量气泡图</li></ul> 
<p><img src="https://images2.imgbox.com/7f/44/IOkN5BaV_o.jpg" alt=""></p> 
<ul><li>不同时段（月初、月中、月末）的产品需求量折线图</li></ul> 
<p><img src="https://images2.imgbox.com/61/d8/gNotLWwl_o.jpg" alt=""></p> 
<ul><li>线下/上销售趋势</li></ul> 
<p><img src="https://images2.imgbox.com/ff/08/uEIBkIal_o.jpg" alt=""></p> 
<p><img src="https://images2.imgbox.com/57/51/9Ng7AhCF_o.jpg" alt=""></p> 
<ul><li>“6.18”和“双十一”期间Top50促销产品所属细类双向柱状图</li></ul> 
<p><img src="https://images2.imgbox.com/ad/89/UBtWjcgg_o.jpg" alt=""></p> 
<h2><a id="_87"></a>第二问</h2> 
<p>第二问要预测的精准，还是比较考验学习、代码能力的，当时是看了好几个销量预测的比赛代码，主要是kaggle上的，并且一步步自己改。搭出Baseline后，能先有一个预测的结果，再一步步的加上自己的想法。</p> 
<p><code>以下内容都是先有Baseline后一步步试出来的，所以会有些跳跃性</code></p> 
<blockquote> 
 <p>一些链接（很多我找不到了）：</p> 
 <p><a href="https://www.jianshu.com/p/1f6eef8a86fd" rel="nofollow">详细的EDA和随机森林</a></p> 
 <p><a href="https://www.kaggle.com/code/kyakovlev/1st-place-solution-part-1-hands-on-data/notebook" rel="nofollow">1st place solution - Part 1 - “Hands on Data”</a></p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/2b/f7/AS2q1VCJ_o.jpg" alt=""></p> 
<h3><a id="21__101"></a>2.1 数据预处理</h3> 
<ul><li> <p>缺失值处理</p> </li><li> <p>异常值检测</p> 
  <ul><li>对于检测出来有异常值的商品</li><li>在预测集中的商品单独建模（手动预测）</li><li>不再预测集中的商品直接删除</li></ul> </li><li> <p>分类型数据转换成数值型</p> 
  <ul><li>销售渠道</li><li>产品编号/产品类别/销售区域</li></ul> </li><li> <p>对于波动很大的销量数据，我们有两种指标。</p> 
  <ul><li>标签平滑处理：取对数，用RMSE指标</li><li>不对数处理：使用Tweedie偏差（Tweedie deviance）</li></ul> </li><li> 
  <blockquote> 
   <p>如果你不处理，就用RMSE评价销量预测的精确度肯定有问题。</p> 
   <p>比如一只5块钱的笔（一个月销量大约5000个），预测偏差100个。跟一块2000块钱的手表（一个月销量大约500个），预测偏差100个。用RMSE评价是一样的，但实际上肯定是手表预测的偏差带来的问题更大。Tweedie偏差就能解决这种问题</p> 
   <p>当然如果先对数处理，倒也可以用RMSE</p> 
   <p>二选一即可，最后我还是使用了后者</p> 
  </blockquote> </li></ul> 
<h3><a id="22__129"></a>2.2 数据集分析</h3> 
<h4><a id="221__131"></a>2.2.1 训练集</h4> 
<p>这里我们对数据进行了很详细的分析，我自己单独去看每一类别中的每个商品的趋势，就能发现很多特征。尽管大部分因为时间原因没有用上，但这在现实业务的预测中是很重要的一步。我们要对这个数据集有详细的了解，才能针对性处理。</p> 
<p>稍微列举几点：</p> 
<ol><li>403/404/405：最初线上，2017年起增加线下</li><li>406：线下，小规模订单；2018.3从105区域迁到其他区域</li><li>407：销售趋势呈多个小高峰，具有季节性趋势</li><li>411：于2017年11月上市</li><li>自2017年起，地区104停止销售，104地区大部分产品转移到105地区，编写函数实现数据迁移</li><li><strong>有些商品</strong>有线上引领线下的销售特征，如果某个商品线上涨了，那个这个商品下个月大概率线下也会涨</li></ol> 
<ul><li>数据按月整合，才能做特征工程和机器学习 
  <ul><li>对每个产品的需求量按区域和月份进行整合</li><li>建立一个包含销售区域、销售月份和产品等组合信息的结构化数据集</li></ul> </li></ul> 
<p><img src="https://images2.imgbox.com/ae/d5/QhRccvrg_o.jpg" alt=""></p> 
<ul><li>然后我们提出了一个比较有用的策略-<strong>商品分层</strong>。思路来源于营销课广告，因为不同性质定位的产品，其销售规律肯定有所不同，所以分类 
  <ul><li><strong>新品</strong>：直至第36个月（date_block_num）才开始出现在市场上的产品。</li><li><strong>流星品</strong>：突然出现的商品；但销售时长不超过5个月，销量会急剧下降。</li><li><strong>睡眠品</strong>：一直保持客观的销量，却在某个时间点之后销售量骤减，但究其原因并非季节性因素的产品。</li><li><strong>常规品</strong>：总有销量的产品；销售时长达39周以上或至少存在于市场中一年以上。</li></ul> </li><li>其实应该还有<strong>季节性商品</strong>的，但是大部分商品其存在时间都没到两年，所以算法不太能判断的出来，遂放弃</li></ul> 
<h4><a id="222__157"></a>2.2.2 预测集</h4> 
<ul><li>然后我们编写了分类函数，对预测集中的商品进行分类，来看看要预测的都是哪些商品</li></ul> 
<p><img src="https://images2.imgbox.com/16/86/7NLmd2Uy_o.jpg" alt=""></p> 
<p>发现大部分是常规品，新品占比也不小。在搭出Baseline后我们进行了<strong>误差分析</strong>（后面会提，就是分析预测误差来源于哪里）。我们就发现很多的新品和一些波动大的商品，预测偏差很大，所以单独建立了<strong>新品模型</strong>。</p> 
<h3><a id="23__165"></a>2.3 特征工程</h3> 
<p>特征工程是最重要的，也是决定模型最终预测精度的关键。常规的就是滞后特征、趋势特征等等。不断添加新特征，不断训练模型验证效果，最后没用的特征我们删除就好</p> 
<ul><li>切记不要数据泄漏，不要在做特征的时候引入未来的数据。比如趋势应该是上上个月-&gt;上个月的趋势，别是上个月-&gt;这个月的。这个月数据是要预测的</li></ul> 
<p><img src="https://images2.imgbox.com/07/29/JxssjA6P_o.jpg" alt=""></p> 
<h3><a id="24__173"></a>2.4 模型建立</h3> 
<h4><a id="241__175"></a>2.4.1 模型框架和评价指标</h4> 
<ul><li> <p>题目非常离谱的要按日/周/月分别建模预测。实际上能做好月的就不错了，因为不然你要做三组特征，这是不可能的。</p> 
  <ul><li> <p>我们的解法就是按照月预测，不断的优化。日/周的就prophet随便预测一下就行。但在这个过程中，我们发现prophet不仅可以预测，还可以提取一些季节性特征。</p> </li><li> <p>因为我们做的特征实际上是缺少季节性的，所以就融入了这部分来自prophet提取的特征，也发现效果确实不错。</p> </li></ul> </li></ul> 
<p><img src="https://images2.imgbox.com/7f/58/YyudFTxq_o.jpg" alt=""></p> 
<h4><a id="242__185"></a>2.4.2 模型建立</h4> 
<ul><li>模型选择的话，我们Baseline使用LightGBM做的，因为其训练时间最快，方便我们不断优化 
  <ul><li>最后使用了三种梯度提升树算法（LightGBM、CatBoost、XGBoost）进行模型融合</li><li>该怎么说呢，效果肯定是很好的，但是这样也会带来过拟合。实际上，其实不用那么复杂，用一个模型也许效果最好</li></ul> </li></ul> 
<p><img src="https://images2.imgbox.com/34/8a/tEm1XK9V_o.jpg" alt=""></p> 
<h4><a id="243__193"></a>2.4.3 误差分析和特征筛选</h4> 
<ul><li>误差分析 
  <ul><li>在训练前期的帮助很大</li><li>重新预测误差大的商品，并将预测值覆盖提交到原先的模型中</li></ul> </li><li>特征筛选 
  <ul><li>剔除没啥用的特征</li></ul> </li></ul> 
<p><img src="https://images2.imgbox.com/09/1b/90rC4nUs_o.jpg" alt=""></p> 
<h4><a id="244__203"></a>2.4.4 新品模型</h4> 
<ul><li>对于新品，我们使用滑动窗口提取出每个月的新品，来组成新品模型的训练集和预测集</li><li>并且重新进行特征工程，因为新品没啥历史数据，预测只能靠同类商品的一些信息，所以我们做的特征往这个方向靠</li></ul> 
<p><img src="https://images2.imgbox.com/4b/37/jIYMalZF_o.jpg" alt=""></p> 
<h3><a id="25__210"></a>2.5 模型融合</h3> 
<p>比较了一下，选定了进行模型融合的方法</p> 
<p>还是那句话，模型太复杂并不代表真正的预测效果越好。但是这些工作在论文的展现中是需要的。</p> 
<p><img src="https://images2.imgbox.com/cb/8d/EQVSXBYD_o.jpg" alt=""></p> 
<h3><a id="26__218"></a>2.6 预测方法</h3> 
<p>我们还测试了三种预测方法。因为题目要求预测往后三个月的数据。</p> 
<p>直接预测、滚动预测应该比较好理解。</p> 
<p>滞后预测需要重新做特征，比如预测M+2月的销售量。我们是不能用M+1月的数据做特征的</p> 
<p><img src="https://images2.imgbox.com/f3/f2/Lr3JQHeA_o.jpg" alt=""></p> 
<h3><a id="27__228"></a>2.7 总结</h3> 
<p><img src="https://images2.imgbox.com/2c/e0/2wgBYInA_o.jpg" alt=""></p> 
<h2><a id="_234"></a>结尾</h2> 
<p>先吐槽一下本次比赛的题目，题目的数据感觉质量不是太好，前期做起来很头疼，也许是销量数据的通病。第二问的按日/周/月精度分别预测让人很难理解。再吐槽一下评委，私以为能进入答辩的队伍应该都是用机器学习/深度学习对整个数据集一起训练的，评委应该focus我们工作的创新点。但是评委貌似无法理解，认为我们怎么能用到了Prophet但又不用一个个训练，好像很难理解用机器学习怎么对每个商品进行预测。我们达到的是全局最优而不是每个商品最优，这跟用不用Prophet无关（我们只是用了Prophet来一个个提取特征，总体的工作是用LGBM不断优化的）。</p> 
<p>还有就是这个比赛需要先提交论文和预测数据（2019年1、2、3月的数据），提交的后一天又会给出1、2、3月的数据，要求在预测一遍4、5、6月的数据。当时都五一放假了喂，那天早上发现1月份的真实销售数据销量很高，总体大概是预测的2～3倍。然后我就发现5月的数据也有可能很高，就重新改代码，总结了每一类商品的每月销售特征，又预测了一天。最终相信效果应该是不错的。合理的运用Trick来提升预测精度也是获奖必不可少的部分！</p> 
<p>最后致谢一下吧。感谢我的两位队友的努力，感谢npy的作图和比赛期间的理解、感谢学姐学长的帮助和答辩指导、感谢我的指导老师。希望这篇总结能帮助到别人。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9c76034688dcd3a90a43a1c2fc0d86d7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">STM32超声波——HC_SR04</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9447b878e20ded8788e1a9e7a9098a82/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【Regulatory Genomics】Part3 GENOMICS AT NVIDIA、ATACWORKS</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>