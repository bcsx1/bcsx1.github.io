<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>EpilepsyGAN:具有隐私保护的合成癫痫脑活动-2021(同26) - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="EpilepsyGAN:具有隐私保护的合成癫痫脑活动-2021(同26)" />
<meta property="og:description" content="EpilepsyGAN: Synthetic Epileptic Brain Activities with Privacy Preservation Abstract 癫痫是一种慢性神经系统疾病，影响全世界6500多万人，表现为反复发作的无端癫痫发作。癫痫发作的不可预测性不仅会降低患者的生活质量，而且还可能危及生命。目前正在开发监测脑电图(EEG)信号的现代系统，以检测癫痫发作，以提醒护理人员并减少癫痫发作对患者生活质量的影响。这种癫痫检测系统采用最先进的机器学习算法，需要大量标记的个人数据进行训练。然而，对于医学专家和患者来说，在癫痫发作期间获取脑电图信号是一个昂贵且耗时的过程。此外，这些数据通常包含敏感的个人信息，引起隐私问题。在这项工作中，我们生成了合成的类似癫痫发作的脑电活动，即EEG信号，可用于训练癫痫发作检测算法，减轻了对敏感记录数据的需求。我们的实验表明，用我们的GAN模型生成的合成癫痫发作数据成功地保护了患者的隐私，而不会在癫痫发作监测期间产生任何性能下降。
I. INTRODUCTION 癫痫是全球第四大最常见的慢性神经系统疾病，影响超过6500万人。癫痫表现为由于大脑异常活动引起的反复无端癫痫发作。三分之一的癫痫患者患有耐药性无法控制的癫痫发作，发作时间通常无法预测。癫痫发作的时间从几秒到几分钟不等，症状多种多样，包括感觉先兆、意识丧失、行为停止、自动运动和全身抽搐。癫痫不仅会降低患者的生活质量，而且复发性癫痫患者的死亡率比普通人群相应组高5倍[3]，[4]。在癫痫学术语中，发作期样本是从癫痫发作段提取的，而发作间期样本是从非癫痫发作段提取的。
使用可穿戴设备[5]-[10]进行持续实时监测是降低死亡率、提高癫痫患者生活水平和独立性的一个有前景的解决方案。可穿戴设备可以在较长时间内持续实时采集和处理患者的脑电图信号，以检测发作期。通过这种方式，当癫痫发作发生时，警报可以自动发送给护理人员或家庭成员。
然而，开发可靠的癫痫发作检测系统的一个根本障碍是缺乏足够的训练数据量。事实上，现代检测系统是由基于机器学习的算法[11]和[12]驱动的，这些算法需要大量记录发作期的样本，以便可靠地检测未来的癫痫发作。收集和标记癫痫患者的脑电图数据是一个昂贵的过程，目前需要患者在癫痫发作时被记录在监测单元中。在临床实践中，这种记录在少数患者中进行，并且在短时间内(通常为一周)进行，因此只能记录每位患者的几次癫痫发作[13]。围绕共享医疗数据存在的隐私担忧加剧了这一问题。
特别是，从匿名数据集[14]中重新识别患者的可能性和数据泄漏的风险阻碍了医疗数据的共享。
在这项工作中，为了解决上述问题，我们提出了EpilepsyGAN，一种生成对抗网络(GAN)[15]，它可以产生高质量的合成癫痫发作信号，我们证明了所提出的框架的有效性。据我们所知，这是第一次生成癫痫发作脑电图样本，并用于训练癫痫检测算法。然后，我们利用模型的生产力来解决癫痫监测案例中的隐私问题。为此，首先，我们证明，与基于真实数据的训练相比，使用合成数据训练癫痫监测系统不会降低癫痫发作检测性能。此外，我们强调了生物医学应用中潜在的隐私问题，特别是癫痫，并证明使用合成数据阻碍了对患者的重新识别。这构成了GANs的现实应用，对医疗保健和医疗数据隐私有直接影响。因此，我们工作的主要贡献总结如下:
1)生成模型能够产生真实的合成癫痫发作信号，可以训练癫痫监测系统，在癫痫发作检测方面具有与真实癫痫发作信号相似的性能。
2)应用合成数据保护隐私和一项关于真实和合成的发作期数据对患者再识别的脆弱性的比较研究表明，与真实数据相比，合成数据的脆弱性降低了7.2倍。
2相关工作 由于GANs的出现，合成数据生成领域取得了非凡的进展。近年来，GANs在计算机视觉[16]，[17]，音频[18]，[19]或自然语言处理[20]，[21]等各种具有挑战性的领域取得了出色的成绩。然而，它们在医疗领域的成功却较为有限。
在过去的几年里，为医疗应用生成可靠的合成数据在文献中得到了广泛的研究。一些研究使用医学成像[22]-[24]和重症监护病房(ICU)监测[25]-[27]等领域的合成数据来增强现有的训练集，以提高检测精度。尽管这种数据增强方法已被证明是有效的，但之前仅使用合成数据进行训练的尝试已经报告了[23]，[25]性能的严重退化，到目前为止还不可能不使用真实的训练数据。因此，无法访问真正的训练数据，只能获得纯合成训练集的情况仍然没有解决。然而，考虑到与收集和共享医疗数据[28]相关的困难和隐私问题，这在包括癫痫在内的一些医疗应用程序中是一个常见的场景。
在大脑信号的具体情况下，GANs应用于生成真实的合成信号，迄今为止取得的成功非常有限:[29]生成了类似脑电图的信号，没有在任何特定的任务或病理检测中证明合成数据的质量。[30]生成合成脑电图数据来增强脑机接口现有的真实训练集，但他们没有在完全合成的训练集上进行评估。[31]使用GAN对脑电图信号的空间分辨率进行上采样，尽管视觉质量有所改善，但与原始训练集相比，得到的训练集在心理图像分类任务中的准确度下降了4-9%。然而，尽管针对合成脑电图的生成，但目前的文献尚未涉及癫痫，特别是发作期样本的生成。
此外，在过去的几年里，GAN模型因为能够在隐私敏感的应用程序中生成真实的合成数据而引起了人们的关注。在具有敏感数据的医疗应用程序的背景下，DPGAN[32]和patgan[33]提出了差分私有GAN模型，其中通过在模型的梯度中添加噪声来获得隐私。他们的评估表明，pite - gan和DPGAN在高维数据集(如UCI癫痫发作识别数据集[34])中质量都大幅下降。差分隐私技术引入了众所周知的隐私级别(即附加噪声的大小)和性能之间的权衡。也就是说，当我们增加噪声量级时，合成数据以逐渐丧失效用为代价变得更加私密。
第二类隐私保护技术，如MedGAN[36]，通过自动编码器和GAN的组合生成高维合成离散变量。他们的结果表明，生成的数据和相应的训练记录之间的1对1映射很弱，这意味着合成数据保护了患者的隐私。MedGAN在电子健康记录(EHR)数据上取得了令人印象深刻的结果，然而，该数据本质上是离散的，因此这种类型的模型不能用于生成连续的生物医学信号，如脑电图。
在本文中，我们提出使用GANs来生成癫痫发作的合成数据，这是脑电图记录中罕见的事件，我们评估了生成的样本在癫痫检测任务中的质量和效用。此外，我们展示了患者重新识别的可能性，并证明使用我们的EpilepsyGAN模型产生的合成信号缓解了在癫痫发作检测问题中与共享敏感医疗数据相关的隐私问题。
3生成模型 GANs是一类深度生成模型，其中两个神经网络同时训练，同时在二个极小极大博弈中竞争。一个网络是一个鉴别器，用来估计样本是真实的还是合成的。另一个网络是生成器，其任务是生成真实的合成样本，最大限度地提高鉴别器出错的概率。在训练过程中，鉴别器提高了识别合成样本的能力，而生成器学习生成越来越逼真的样本来欺骗鉴别器。在这种对抗性设置中，当生成器产生真实的样本，使得鉴别器无法区分它们是真实的还是合成的时，就达到了平衡。
EpilepsyGAN是一种有条件的GAN[37]，在输入时给定发作间期脑电图样本，它会生成癫痫发作期的脑电图样本。我们设计的基本原理是，由于癫痫发作的不可预测性和发生频率低，记录癫痫发作的成本非常高，但发作间信号可以在任何时刻轻松记录。因此，我们根据目标患者发作间样本对网络进行调节，以便向生成器提供额外的信息，可以利用这些信息生成更真实的发作样本。通过这种方式，我们可以使用已经存在的数据库来训练GAN，然后使用GAN为新患者生成癫痫发作样本。
我们的GAN的架构是仿照[38]，[39]的SEGAN。如图1所示，我们的生成器是一个带有加权跳过连接的Unet[40]卷积自编码器网络。通常，自动编码器由两个对称部分组成，编码器处理输入样本并生成潜在代码，解码器通过解码潜在代码恢复原始样本。然而，在我们的例子中，解码器不恢复原始的inter-ictal样本，而是将潜在代码转换为一个ictal样本。为了获得样本多样性，通过将均值为0、标准差为1的高斯噪声级联到潜码中，将随机性引入模型。跳过连接将编码器的每一层的特征映射与训练期间学到的权重相乘，然后将该操作的结果添加到解码器的相应特征映射中。因此，跳过连接的权重调节从编码器馈送到解码器的信息量。GAN的鉴别器具有与生成器的编码器相同的结构，但它在输出端包含一个额外的全连接层。这样，鉴别器输出一个介于0和1之间的值，其中1表示实类，0表示合成类。
为了获得模型的网络参数，在训练阶段迭代求解优化问题，在此过程中，发生器和鉴别器的损失函数交替最小化。在我们的模型中，这些损失是基于最小二乘GAN (LSGAN)[41]。
因此，判别器的最小化目标为
在这个目标中，函数D对应于鉴别器，G对应于生成器，如前所述，鉴别器的输出介于0和1之间。θD为鉴别器的网络参数。输入数据x是从真实数据分布pdata(x)中采样的真实发作期信号。在第二项中，G(x)是由周期间输入x生成的合成周期样本。当输入是真实的周期样本x时，损失函数的第一项将鉴别器推到输出1，而当鉴别器在给定合成样本的情况下输出0时，第二项最小化。
另一方面，生成器的网络参数为θG的损失函数为:
其中y表示参考发作信号与发作间样本x配对。为了使训练更稳定，生成器的损失包括一个加权L1正则化项。这一项确保生成的信号与参考信号y相似。我们观察到，如果没有这个正则化项，网络的参数在训练过程中迅速饱和，产生无意义的输出。在方程2中，λ是一个超参数，我们使用验证集将其调优为100，以便将损失函数的两项缩放到可比的量级，防止正则化项主导优化问题。此外，生成器损失的第一项鼓励生成器产生被鉴别器分类为1的合成样本，即，真实的，这与鉴别器的损失函数是对立的。因此，在训练过程中，生成器和鉴别器的利益竞争驱使生成器产生越来越多的真实样本。
A. Architecture Details架构详图 生成器的输入是长度为2048点的样本。编码器由8个块组成，这些块交替使用一个卷积层和一个大小为2和步幅为2的最大池化层。卷积中使用的1D滤波器大小为31，步幅为1。如图1所示，编码器中滤波器的数量逐渐增加。编码器的输入形状为2048x1，而输出形状为8x1024。连接到潜在代码的高斯噪声Z具有相同的形状，即8x1024。在解码器中，膨胀和反卷积的滤波器大小与编码器中的池化和卷积相同。这样，生成器的u型编码器-解码器结构是对称的，输出形状为2048x1。
使用的激活是leakyReLu函数[42]，除了解码器的最后一个块，其中我们使用双曲正切函数。所有的卷积和反卷积都是无偏的，频谱归一化[43]应用在生成器和鉴别器的每个块之前。在此基础上，在鉴别器中应用虚拟批归一化[44]。
为了训练模型，我们使用Adam[45]优化器，β1和β2的值分别为0和0.9，生成器的学习率为0.0001，鉴别器的学习率为0.0004。我们通过超参数搜索发现这些值，它们与[38]中的相同，在我们的应用程序中也表现最好。训练期间使用的小批量数据的大小为100个样本。
B.现实场景 在需要监测新患者且没有可用的癫痫发作数据来训练监测系统的情况下，合成癫痫发作的产生特别重要。医院可以使用一个生成模型来训练来自其他患者的数据，为新患者生成合成数据，而不是将患者带入医院的记录单元，直到她遭受足够的癫痫发作来训练系统。这是本工作中考虑的场景，分为两部分:训练生成模型(第III-C节);以及使用生成的样本进行训练生成合成发作数据和实时发作监测(第五节)。
图2描述了该设置的高级图片。
假设有N名患者，我们考虑在现实场景中，我们有N - 1名患者的发作数据，而这N - 1名患者中未包含的第i名患者是需要监测的新患者，其发作数据不可用。然而，考虑到发作间期数据易于记录，并且可以在任何时候有效地完成，我们假设我们也有第i位患者的发作间期数据。然后，
(1)我们使用来自N - 1名患者的数据训练我们的生成模型，
(2)我们从新患者i的发作间期数据中生成发作期数据。注意，不需要为每个新患者重新训练模型;在训练它一次之后，可以生成任意数量的新患者的合成数据。一旦我们训练了EpilepsyGAN并为目标患者i生成了合成的发作数据，我们就使用这些合成数据来训练分类器(例如，随机森林)来执行发作检测任务。具体来说，任务是在患者i的真实ictal和合成ictal样本上检测出患者i训练的真实ictal样本。该分类器的性能让我们了解了合成数据的质量，即它是否适合训练监测算法。
C.生成模型训练 为了训练EpilepsyGAN，我们使用了来自EPILEPSIAE项目数据库[46]的数据，该数据库是世界上最大的癫痫检测公共数据库之一。该数据集包含30名不同癫痫患者的记录，共277次癫痫发作，总持续时间为21001秒。脑电图数据以256hz的采样频率采集，并将其分为1小时的记录，每个记录对应一个记录会话。每个患者的一小时录音数量在96到281次之间变化。
在这项工作中，我们的目标是建立现实世界和无耻辱的可穿戴监测设备[47]，因此我们只考虑标准10-20系统[48]中的电极F7T3和F8T4，它们可以很容易地隐藏在眼镜[7]中。这些电极最有可能捕捉到颞叶癫痫。在EPILEPSIAE数据库中，30名患者中有25名患者经历了至少一次位于脑内颞叶的癫痫发作。我们使用持续时间为4秒的样本，因为这个长度对检测癫痫发作是有效的。假设数据是在256hz的频率下记录的，这导致样本长度为2048，即每个电极1024。四秒长的发作样本的收集有三秒的重叠，以增加训练发作样本的数量，而发作间样本的收集没有重叠，因为没有发作发生。此外，我们没有对数据进行任何滤波或预处理，而是直接处理原始EEG信号。
为了构建训练集，我们将每个发作期样本与从同一患者随机挑选的发作间期样本配对。这意味着在生成器的输入处给出的每个ictal间期样本都与一个ictal样本相关联，该样本被用作指导训练的参考。通过这种方式，生成器学会将发作间期样本映射到相应患者的发作样本。由于发作期样本重叠一秒，而发作间期样本不重叠一秒，相似的发作期样本(重叠)被配对到不相似的发作间期样本(不重叠)，因此，为了学习转换，模型需要理解发作期和发作间期分布之间的关系，而不是任意配对的信号部分之间的关系;这有效地起到正则化的作用。
如第III-B节所述，为了训练模型，遵循了省略策略:对于每个目标患者i, EpilepsyGAN使用来自所有其他患者(N - 1)的发作期和发作间数据进行训练，因此，它可以用于为未见过的患者生成合成的发作期样本。
训练样本的确切数量取决于数据库中除了被遗漏的患者i之外的所有患者的癫痫发作记录的秒数，尽管略有不同，但大约是20,000个样本。按照这个方案，GAN是独立训练的，每次都剔除一个病人，因此，我们得到每个病人一个模型，即30个模型。
四、隐私保护 癫痫发作信号被认为是隐私方面的敏感数据，因为它们可以透露患者的健康状况。这包括癫痫发作的严重程度，癫痫的类型，以及使用者患有癫痫的事实。这些敏感信息可能会被复杂的第三方利用，因此，共享和存储癫痫发作信号可能会危及患者的隐私。为了解决这一隐私问题并保护患者的隐私，我们建议使用合成的发作信号而不是真正的发作信号。合成数据由第三节中介绍的EpilepsyGAN生成。
在本节中，我们将介绍一个评估程序，以评估使用合成脑电图样本时是否保护了隐私。为了在隐私环境下比较真实的ictal信号和合成的ictal信号，我们假设这些信号是匿名的，即没有身份信息。我们使用发作信号的可识别性作为度量来显示癫痫信号中隐私问题的存在。
A.患者识别 我们将患者识别定义为在数据集中识别输入信号所属的人的问题。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/244e4ea54c6592f8247f3bd08c53a0ac/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-07T15:41:36+08:00" />
<meta property="article:modified_time" content="2023-01-07T15:41:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">EpilepsyGAN:具有隐私保护的合成癫痫脑活动-2021(同26)</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>EpilepsyGAN: Synthetic Epileptic Brain Activities with Privacy Preservation</h2> 
<h2 style="text-align:center;">Abstract</h2> 
<p>癫痫是一种慢性神经系统疾病，影响全世界6500多万人，表现为反复发作的无端癫痫发作。癫痫发作的不可预测性不仅会降低患者的生活质量，而且还可能危及生命。目前正在开发监测脑电图(EEG)信号的现代系统，以检测癫痫发作，以提醒护理人员并减少癫痫发作对患者生活质量的影响。这种癫痫检测系统采用最先进的机器学习算法，需要大量标记的个人数据进行训练。然而，对于医学专家和患者来说，在癫痫发作期间获取脑电图信号是一个昂贵且耗时的过程。此外，这些数据通常包含敏感的个人信息，引起隐私问题。<span style="color:#956fe7;"><strong>在这项工作中，我们生成了合成的类似癫痫发作的脑电活动，即EEG信号，可用于训练癫痫发作检测算法，减轻了对敏感记录数据的需求</strong></span>。我们的实验表明，用我们的GAN模型生成的合成癫痫发作数据成功地保护了患者的隐私，而不会在癫痫发作监测期间产生任何性能下降。</p> 
<h3 style="text-align:center;">I. INTRODUCTION</h3> 
<p>癫痫是全球第四大最常见的慢性神经系统疾病，影响超过6500万人。癫痫表现为由于大脑异常活动引起的反复无端癫痫发作。三分之一的癫痫患者患有耐药性无法控制的癫痫发作，发作时间通常无法预测。癫痫发作的时间从几秒到几分钟不等，症状多种多样，包括感觉先兆、意识丧失、行为停止、自动运动和全身抽搐。癫痫不仅会降低患者的生活质量，而且复发性癫痫患者的死亡率比普通人群相应组高5倍[3]，[4]。在癫痫学术语中，<span style="color:#956fe7;"><strong>发作期样本是从癫痫发作段提取的，而发作间期样本是从非癫痫发作段提取的。</strong></span></p> 
<p><span style="color:#0d0016;">使用可穿戴设备[5]-[10]进行持续实时监测是降低死亡率、提高癫痫患者生活水平和独立性的一个有前景的解决方案。可穿戴设备可以在较长时间内持续实时采集和处理患者的脑电图信号，以检测发作期。通过这种方式，当癫痫发作发生时，警报可以自动发送给护理人员或家庭成员。</span></p> 
<p><span style="color:#0d0016;">然而，开发可靠的癫痫发作检测系统的一个根本障碍是</span><span style="color:#956fe7;"><strong>缺乏足够的训练数据量</strong></span><span style="color:#0d0016;">。事实上，现代检测系统是由基于机器学习的算法[11]和[12]驱动的，这些算法需要大量记录发作期的样本，以便可靠地检测未来的癫痫发作。收集和标记癫痫患者的脑电图数据是一个昂贵的过程，目前需要患者在癫痫发作时被记录在监测单元中。在临床实践中，这种记录在少数患者中进行，并且在短时间内(通常为一周)进行，因此只能记录每位患者的几次癫痫发作[13]。围绕共享医疗数据存在的隐私担忧加剧了这一问题。</span></p> 
<p><span style="color:#0d0016;">特别是，从匿名数据集[14]中重新识别患者的可能性和数据泄漏的风险阻碍了医疗数据的共享。</span></p> 
<p><span style="color:#0d0016;">在这项工作中，为了解决上述问题，我们提出了</span><span style="color:#956fe7;"><strong>EpilepsyGAN，一种生成对抗网络(GAN)[15]，它可以产生高质量的合成癫痫发作信号，我们证明了所提出的框架的有效性</strong></span><span style="color:#0d0016;">。据我们所知，这是第一次生成癫痫发作脑电图样本，并用于训练癫痫检测算法。然后，我们利用模型的生产力来解决癫痫监测案例中的隐私问题。为此，首先，我们证明，与基于真实数据的训练相比，使用合成数据训练癫痫监测系统<strong>不会降低癫痫发作检测性能</strong>。此外，我们强调了生物医学应用中潜在的隐私问题，特别是癫痫，并证明使用合成数据阻碍了对患者的重新识别。这构成了GANs的现实应用，对医疗保健和医疗数据隐私有直接影响。因此，我们工作的主要贡献总结如下:</span></p> 
<p><span style="color:#956fe7;"><strong>1)生成模型能够产生真实的合成癫痫发作信号，可以训练癫痫监测系统，在癫痫发作检测方面具有与真实癫痫发作信号相似的性能。</strong></span></p> 
<p><span style="color:#956fe7;"><strong>2)应用合成数据保护隐私和一项关于真实和合成的发作期数据对患者再识别的脆弱性的比较研究表明，与真实数据相比，合成数据的脆弱性降低了7.2倍。</strong></span></p> 
<h3 style="text-align:center;"><span style="color:#0d0016;"><strong>2相关工作</strong></span></h3> 
<p><span style="color:#0d0016;">由于GANs的出现，合成数据生成领域取得了非凡的进展。近年来，GANs在计算机视觉[16]，[17]，音频[18]，[19]或自然语言处理[20]，[21]等各种具有挑战性的领域取得了出色的成绩。然而，它们在医疗领域的成功却较为有限。</span></p> 
<p><span style="color:#0d0016;">在过去的几年里，为医疗应用生成可靠的合成数据在文献中得到了广泛的研究。一些研究使用医学成像[22]-[24]和重症监护病房(ICU)监测[25]-[27]等领域的合成数据来增强现有的训练集，以提高检测精度。尽管这种数据增强方法已被证明是有效的，但之前仅使用合成数据进行训练的尝试已经报告了[23]，[25]性能的严重退化，到目前为止还不可能不使用真实的训练数据。因此，无法访问真正的训练数据，只能获得纯合成训练集的情况仍然没有解决。然而，考虑到与收集和共享医疗数据[28]相关的困难和隐私问题，这在包括癫痫在内的一些医疗应用程序中是一个常见的场景。</span></p> 
<p><span style="color:#0d0016;">在大脑信号的具体情况下，<strong>GANs应用于生成真实的合成信号，迄今为止取得的成功非常有限:</strong>[29]生成了类似脑电图的信号，没有在任何特定的任务或病理检测中证明合成数据的质量。[30]生成合成脑电图数据来增强脑机接口现有的真实训练集，但他们没有在完全合成的训练集上进行评估。[31]使用GAN对脑电图信号的空间分辨率进行上采样，尽管视觉质量有所改善，但与原始训练集相比，得到的训练集在心理图像分类任务中的准确度下降了4-9%。然而，尽管针对合成脑电图的生成，但目前的文献尚未涉及癫痫，特别是发作期样本的生成。</span></p> 
<p><span style="color:#0d0016;">此外，在过去的几年里，GAN模型因为能够在隐私敏感的应用程序中生成真实的合成数据而引起了人们的关注。在具有敏感数据的医疗应用程序的背景下，DPGAN[32]和patgan[33]提出了<strong>差分私有GAN模型，其中通过在模型的梯度中添加噪声来获得隐私</strong>。他们的评估表明，pite - gan和DPGAN在高维数据集(如UCI癫痫发作识别数据集[34])中质量都大幅下降。<strong>差分隐私技术引入了众所周知的隐私级别(即附加噪声的大小)和性能之间的权衡。</strong>也就是说，当我们增加噪声量级时，合成数据以逐渐丧失效用为代价变得更加私密。</span></p> 
<p><span style="color:#0d0016;">第二类隐私保护技术，如MedGAN[36]，通过<strong>自动编码器和GAN的组合生成高维合成离散变量</strong>。他们的结果表明，生成的数据和相应的训练记录之间的1对1映射很弱，这意味着合成数据保护了患者的隐私。MedGAN在电子健康记录(EHR)数据上取得了令人印象深刻的结果，<strong>然而，该数据本质上是离散的，因此这种类型的模型不能用于生成连续的生物医学信号，如脑电图</strong>。</span></p> 
<p><span style="color:#0d0016;">在本文中，我们</span><span style="color:#956fe7;"><strong>提出使用GANs来生成癫痫发作的合成数据</strong></span><span style="color:#0d0016;">，这是脑电图记录中罕见的事件，我们</span><span style="color:#956fe7;"><strong>评估了生成的样本在癫痫检测任务中的质量和效用</strong></span><span style="color:#0d0016;">。此外，我们展示了患者重新识别的可能性，并证明使用我们的EpilepsyGAN模型产生的合成信号缓解了在癫痫发作检测问题中与共享敏感医疗数据相关的隐私问题。</span></p> 
<h3 style="text-align:center;"><span style="color:#0d0016;">3生成模型</span></h3> 
<p><span style="color:#0d0016;">GANs是一类深度生成模型，其中两个神经网络同时训练，同时在二个极小极大博弈中竞争。一个网络是一个</span><strong><span style="color:#956fe7;">鉴别器</span></strong><span style="color:#0d0016;">，用来估计样本是真实的还是合成的。另一个网络是</span><span style="color:#956fe7;"><strong>生成器</strong></span><span style="color:#0d0016;">，其任务是生成真实的合成样本，最大限度地提高鉴别器出错的概率。在训练过程中，鉴别器提高了识别合成样本的能力，而生成器学习生成越来越逼真的样本来欺骗鉴别器。在这种对抗性设置中，当生成器产生真实的样本，使得鉴别器无法区分它们是真实的还是合成的时，就达到了平衡。</span></p> 
<p><span style="color:#0d0016;">EpilepsyGAN是一种有条件的GAN[37]，</span><strong><span style="color:#956fe7;">在输入时给定发作间期脑电图样本，它会生成癫痫发作期的脑电图样本。</span></strong><span style="color:#0d0016;">我们设计的基本原理是，由于癫痫发作的不可预测性和发生频率低，记录癫痫发作的成本非常高，但发作间信号可以在任何时刻轻松记录。因此，</span><span style="color:#956fe7;"><strong>我们根据目标患者发作间样本对网络进行调节，以便向生成器提供额外的信息，可以利用这些信息生成更真实的发作样本</strong></span><span style="color:#0d0016;">。通过这种方式，我们可以使用已经存在的数据库来训练GAN，然后使用GAN为新患者生成癫痫发作样本。</span></p> 
<p><span style="color:#0d0016;">我们的GAN的架构是仿照[38]，[39]的SEGAN。如图1所示，我们的</span><span style="color:#956fe7;"><strong>生成器是一个带有加权跳过连接的Unet[40]卷积自编码器网络。</strong></span><span style="color:#0d0016;">通常，自动编码器由两个对称部分组成，</span><span style="color:#956fe7;"><strong>编码器处理输入样本并生成潜在代码，解码器通过解码潜在代码恢复原始样本。</strong></span><span style="color:#0d0016;">然而，在我们的例子中，解码器不恢复原始的inter-ictal样本，<strong>而是将潜在代码转换为一个ictal样本</strong>。为了获得样本多样性，</span><span style="color:#956fe7;"><strong>通过将均值为0、标准差为1的高斯噪声级联到潜码中，将随机性引入模型</strong></span><span style="color:#0d0016;">。跳过连接将编码器的每一层的特征映射与训练期间学到的权重相乘，然后将该操作的结果添加到解码器的相应特征映射中。因此，跳过连接的权重调节从编码器馈送到解码器的信息量。GAN的</span><span style="color:#956fe7;"><strong>鉴别器</strong></span><span style="color:#0d0016;">具有与生成器的编码器相同的结构，但它在输出端包含一个额外的全连接层。这样，鉴别器输出一个介于0和1之间的值，其中1表示实类，0表示合成类。</span></p> 
<p><img alt="" height="931" src="https://images2.imgbox.com/f4/f8/w8q6YYRl_o.png" width="802"></p> 
<p></p> 
<p><span style="color:#0d0016;">为了获得模型的网络参数，在训练阶段迭代求解优化问题，在此过程中，发生器和鉴别器的损失函数交替最小化。在我们的模型中，这些损失是基于最小二乘GAN (LSGAN)[41]。</span></p> 
<p><span style="color:#0d0016;">因此，判别器的最小化目标为</span></p> 
<p><img alt="" height="148" src="https://images2.imgbox.com/cf/5c/DwFXTd0y_o.png" width="762"></p> 
<p>在这个目标中，函数D对应于鉴别器，G对应于生成器，如前所述，<strong>鉴别器的输出介于0和1之间</strong>。<strong>θD为鉴别器的网络参数</strong>。输入数据x是从真实数据分布pdata(x)中采样的真实发作期信号。在第二项中，G(x)是由周期间输入x生成的合成周期样本。当输入是真实的周期样本x时，损失函数的第一项将鉴别器推到输出1，而当鉴别器在给定合成样本的情况下输出0时，第二项最小化。</p> 
<p>另一方面，生成器的网络参数为θG的损失函数为:</p> 
<p><img alt="" height="163" src="https://images2.imgbox.com/13/22/lyF1FYt5_o.png" width="880"></p> 
<p>其中y表示参考发作信号与发作间样本x配对。为了使训练更稳定，生成器的损失包括一个加权L1正则化项。这一项确保生成的信号与参考信号y相似。我们观察到，如果没有这个正则化项，网络的参数在训练过程中迅速饱和，产生无意义的输出。在方程2中，λ是一个超参数，我们使用验证集将其调优为100，以便将损失函数的两项缩放到可比的量级，防止正则化项主导优化问题。此外，生成器损失的第一项鼓励生成器产生被鉴别器分类为1的合成样本，即，真实的，这与鉴别器的损失函数是对立的。因此，在训练过程中，生成器和鉴别器的利益竞争驱使生成器产生越来越多的真实样本。</p> 
<h3>A. Architecture Details架构详图</h3> 
<p>生成器的<span style="color:#956fe7;"><strong>输入</strong></span>是长度为2048点的样本。<strong><span style="color:#956fe7;">编码器</span></strong>由8个块组成，这些块交替使用一个卷积层和一个大小为2和步幅为2的最大池化层。卷积中使用的1D滤波器大小为31，步幅为1。如图1所示，编码器中滤波器的数量逐渐增加。编码器的输入形状为2048x1，而输出形状为8x1024。连接到潜在代码的高斯噪声Z具有相同的形状，即8x1024。在<strong><span style="color:#956fe7;">解码器</span></strong>中，膨胀和反卷积的滤波器大小与编码器中的池化和卷积相同。这样，生成器的u型编码器-解码器结构是对称的，输出形状为2048x1。</p> 
<p><img alt="" height="672" src="https://images2.imgbox.com/43/29/nGCNzTBt_o.png" width="515"></p> 
<p></p> 
<p>使用的激活是leakyReLu函数[42]，除了解码器的最后一个块，其中我们使用双曲正切函数。所有的卷积和反卷积都是无偏的，频谱归一化[43]应用在生成器和鉴别器的每个块之前。在此基础上，在鉴别器中应用虚拟批归一化[44]。</p> 
<p>为了训练模型，我们使用Adam[45]优化器，β1和β2的值分别为0和0.9，生成器的学习率为0.0001，鉴别器的学习率为0.0004。我们通过超参数搜索发现这些值，它们与[38]中的相同，在我们的应用程序中也表现最好。训练期间使用的小批量数据的大小为100个样本。</p> 
<h3 style="text-align:center;">B.现实场景</h3> 
<p>在需要监测新患者且没有可用的癫痫发作数据来训练监测系统的情况下，合成癫痫发作的产生特别重要。医院可以使用一个生成模型来训练来自其他患者的数据，为新患者生成合成数据，而不是将患者带入医院的记录单元，直到她遭受足够的癫痫发作来训练系统。这是本工作中考虑的场景，分为两部分:<span style="color:#956fe7;"><strong>训练生成模型(第III-C节);以及使用生成的样本进行训练生成合成发作数据和实时发作监测(第五节)。</strong></span></p> 
<p>图2描述了该设置的高级图片。</p> 
<p><img alt="" height="760" src="https://images2.imgbox.com/c2/59/Yzr5TWiQ_o.png" width="1200"></p> 
<p> 假设有N名患者，我们考虑在现实场景中，我们有N - 1名患者的发作数据，而这N - 1名患者中未包含的第i名患者是需要监测的新患者，其<span style="color:#956fe7;"><strong>发作数据不可用</strong></span>。然而，考虑到发作间期数据易于记录，并且可以在任何时候有效地完成，我们<span style="color:#956fe7;"><strong>假设我们也有第i位患者的发作间期数据</strong></span>。然后，</p> 
<p>(1)我们使用来自N - 1名患者的数据训练我们的生成模型，</p> 
<p>(2)我们从新患者i的发作间期数据中生成发作期数据。注意，不需要为每个新患者重新训练模型;在训练它一次之后，可以生成任意数量的新患者的合成数据。一旦我们训练了EpilepsyGAN并为目标患者i生成了合成的发作数据，<strong>我们就使用这些合成数据来训练分类器(例如，随机森林)来执行发作检测任务。</strong>具体来说，<span style="color:#956fe7;"><strong>任务是在患者i的真实ictal和合成ictal样本上检测出患者i训练的真实ictal样本。</strong></span>该分类器的性能让我们了解了合成数据的质量，即它是否适合训练监测算法。</p> 
<h3 style="text-align:center;">C.生成模型训练</h3> 
<p>为了训练EpilepsyGAN，我们使用了来自EPILEPSIAE项目数据库[46]的数据，该数据库是世界上最大的癫痫检测公共数据库之一。该数据集包含30名不同癫痫患者的记录，共277次癫痫发作，总持续时间为21001秒。脑电图数据以256hz的采样频率采集，并将其分为1小时的记录，每个记录对应一个记录会话。每个患者的一小时录音数量在96到281次之间变化。</p> 
<p>在这项工作中，我们的目标是建立现实世界和无耻辱的可穿戴监测设备[47]，因此我们只考虑标准10-20系统[48]中的电极<span style="color:#956fe7;"><strong>F7T3和F8T4</strong></span>，它们可以很容易地隐藏在眼镜[7]中。这些电极最有可能捕捉到颞叶癫痫。在EPILEPSIAE数据库中，30名患者中有25名患者经历了至少一次位于脑内颞叶的癫痫发作。我们使用<span style="color:#956fe7;"><strong>持续时间为4秒的样本</strong></span>，因为这个长度对检测癫痫发作是有效的。假设数据是在256hz的频率下记录的，这导致样本长度为2048，即每个电极1024。四秒长的发作样本的收集有三秒的重叠，以增加训练发作样本的数量，而发作间样本的收集没有重叠，因为没有发作发生。此外，我们没有对数据进行任何滤波或预处理，而是直接处理原始EEG信号。</p> 
<p>为了构建训练集，我们<span style="color:#956fe7;"><strong>将每个发作期样本与从同一患者随机挑选的发作间期样本配对</strong></span>。这意味着在生成器的输入处给出的每个ictal间期样本都与一个ictal样本相关联，该样本被用作指导训练的参考。通过这种方式，生成器学会将发作间期样本映射到相应患者的发作样本。由于发作期样本重叠一秒，而发作间期样本不重叠一秒，相似的发作期样本(重叠)被配对到不相似的发作间期样本(不重叠)，因此，为了学习转换，<strong>模型需要理解发作期和发作间期分布之间的关系，而不是任意配对的信号部分之间的关系;这有效地起到正则化的作用。</strong></p> 
<p>如第III-B节所述，为了训练模型，遵循了<span style="color:#956fe7;"><strong>省略策略</strong></span>:对于每个目标患者i, EpilepsyGAN使用来自所有其他患者(N - 1)的发作期和发作间数据进行训练，因此，它可以用于为未见过的患者生成合成的发作期样本。</p> 
<p>训练样本的确切数量取决于数据库中除了被遗漏的患者i之外的所有患者的癫痫发作记录的秒数，尽管略有不同，但大约是20,000个样本。按照这个方案，GAN是独立训练的，每次都剔除一个病人，因此，我们得到每个病人一个模型，即30个模型。</p> 
<h3 style="text-align:center;">四、隐私保护</h3> 
<p>癫痫发作信号被认为是隐私方面的敏感数据，因为它们可以透露患者的健康状况。这包括癫痫发作的严重程度，癫痫的类型，以及使用者患有癫痫的事实。这些敏感信息可能会被复杂的第三方利用，因此，共享和存储癫痫发作信号可能会危及患者的隐私。为了解决这一隐私问题并保护患者的隐私，我们建议使用合成的发作信号而不是真正的发作信号。合成数据由第三节中介绍的EpilepsyGAN生成。</p> 
<p>在本节中，我们将介绍一个<span style="color:#956fe7;"><strong>评估程序，以评估使用合成脑电图样本时是否保护了隐私</strong></span>。为了在隐私环境下比较真实的ictal信号和合成的ictal信号，我们假设这些信号是匿名的，即没有身份信息。我们使用<strong>发作信号的可识别性</strong>作为度量来显示癫痫信号中隐私问题的存在。</p> 
<h4>A.患者识别</h4> 
<p>我们将患者识别定义为在数据集中识别输入信号所属的人的问题。</p> 
<p>在这个任务中，分类模型学习将每个输入信号映射到相应的患者。例如，随机患者识别的准确性为1/N，其中N是实验中考虑的患者总数。<span style="color:#956fe7;"><strong>我们认为这种随机的患者识别，表示为expand，作为参考基线。</strong></span></p> 
<p>现在让我们集中讨论基于原始发作信号与合成发作信号识别患者的可能性。为此，我们提出了两个实验:exporig和Expsynt。在这两个实验的第一步，<strong>训练卷积神经网络(CNN)仅基于间期信号进行患者识别。</strong>然后在Exporig中，<strong>对模型进行原始发作信号的测试</strong>，即将每个输入的发作信号映射到该发作信号所属的患者。我们在Expsynt中遵循了相同的程序，但在合成的ictal信号上对模型进行了测试。</p> 
<h4>B.分类模型体系结构</h4> 
<p>为患者识别任务提出的CNN模型受到ResNet[49]的启发，如图3所示。</p> 
<p>该模型<strong>以归一化脑电图信号样本作为输入，并生成输出，</strong>以识别输入信号属于哪个患者。总输入长度为4136，由四部分组成:</p> 
<p>•来自电极F7T3的4秒EEG信号</p> 
<p>•来自电极F8T4的4秒EEG信号</p> 
<p>•第一部分的离散小波变换(DWT)</p> 
<p>•第二部分的DWT</p> 
<p>第一部分和第二部分共2048分。在第三和第四部分中使用的DWT是daubecies -4，并执行了三个级别。我们从经验上发现，在输入信息中加入DWT对模型的识别任务有显著的帮助。因此，提供输入信号的DWT可以简化分类器的任务。</p> 
<p><img alt="" height="712" src="https://images2.imgbox.com/8f/54/Hdk9D5ca_o.png" width="481"></p> 
<p>用于患者识别的模型架构。模型中B1、B2、B3、B4为有剩余跳过连接的块。每个块有两个卷积层和一个跳过连接。每个卷积层之后是批处理归一化和ReLU激活，这在图中没有显示。过滤器的数量在每一层中都表示出来。</p> 
<p>如图3所示，模型的<span style="color:#956fe7;"><strong>第一层是带有32个滤波器的卷积层。每个过滤器的长度为5，步幅为2。该模型包括四个剩余块:B1到B4</strong></span>。所有块都有两个卷积层和一个快捷路径(残差连接)。此外，在每个块的卷积之前应用批量归一化[50]和整流线性单元(ReLU)[51]。因此，区块的整体结构遵循[52]中的预激活区块设计。在每个块中，第一和第二卷积层的步长分别为2和1。因此，与输入相比，每个块的输出被下采样2倍。为了确保卷积块的输出与剩余连接的输出兼容，即具有相同的大小，我们交替使用两种下采样策略。在区块B2和B4中，最大池化操作符应用于剩余连接，而在区块B1和B3中，使用过滤器大小为1和步幅为2的卷积层。通过这种方式，我们提供了合理数量的附加参数，这些参数决定了模型的表达能力。</p> 
<p>滤波器的数量从第一个卷积层的32个逐渐增加到B4卷积层的128个。通过这种方式，更深的层可以检测到更复杂的模式组合。在剩余块之后，模型有两个全连接(FC)层和一个软最大激活层。最后一个完全连接层的神经元数量与训练集中n的患者数量相同。最后，softmax层返回患者的概率分布。</p> 
<h3 style="text-align:center;">五、评估程序</h3> 
<p>对于某些类型的数据，例如图像或音频，人们可以自然地感知合成样本的质量。因此，与人类感知密切相关的指标可以用于这些领域来评估综合生成的数据。从人类的感知中衍生出来的是没有信息量的。另一种方法是让医学专家评估生成样本的质量。除了接触医学专家带来的后勤困难之外，这种方法还使结果的再现和与新技术的比较变得困难。</p> 
<p>在这项工作中，我们的<span style="color:#956fe7;"><strong>目标是生成用于癫痫发作检测的合成发作样本</strong></span>。因此，我们建议在癫痫检测问题中<span style="color:#956fe7;"><strong>直接量化合成脑电图样本的质量</strong></span>。基于此任务，我们设计了一个评估程序，使我们能够系统地评估合成的ictal样本，并遵循与[25]中的“训练合成，测试真实”方法类似的理念。这个过程对应于第三- b节中描述的现实世界场景的第二部分。</p> 
<p>我们的评估基于最先进的分类器，该分类器使用<span style="color:#956fe7;"><strong>随机森林算法[53]来确定传入的4秒样本是一个ictal样本还是一个inter-ictal样本。</strong></span>该分类器使用500棵树，并遵循[7]的分类器，[7]是为癫痫监测的无污名可穿戴设备量身定制的。<strong>因此，使用相同的分类器，不仅可以评估在医疗环境中使用我们的合成样本的可行性，还可以评估在使用可穿戴技术的持续监测的更严格的设置中使用的可行性。</strong></p> 
<p>每个病人i都是独立的。我们将目标患者i的<strong>真实发作间样本分为三个不重叠的集合</strong>，我们分别表示为SiGan, SiTrain, SiTest。我们的程序考虑了这样一个场景，<strong>即唯一可用来训练癫痫发作检测算法的数据是真实的发作间样本STraini和由SGANi生成的目标患者i的合成发作样本i</strong>。作为比较的基线，我们考虑所有其他N - 1患者的真实发作样本和目标患者的发作间样本STraini可用的情况。评估程序可分为四个步骤:</p> 
<p>1)构建目标训练集Ti、基线训练集Bi、测试集Ei。</p> 
<p>2)相关领域特征的识别与提取。</p> 
<p>3)使用目标训练集Ti训练癫痫发作检测分类器，并在测试集Ei上进行评估。</p> 
<p>4)使用基线训练集Bi和测试集Ei上的评价训练癫痫发作检测分类器。</p> 
<p>因此，我们<span style="color:#956fe7;"><strong>首先建立目标训练集Ti、基线训练集Bi和测试集Ei，</strong></span>方法如下:</p> 
<p><strong>•目标训练集Ti</strong>:由2000个合成的发作期样本(使用来自目标患者S Gani的真实发作间期样本生成)和来自目标患者i的2000个真实发作间期样本(S Traini)组成。</p> 
<p><strong>•基线训练集Bi</strong>:包括从数据库中除目标患者i外的所有N−1例患者中随机选择的2000例真实癫痫发作样本，以及目标患者(ST raini)的2000例发作间期样本。</p> 
<p><strong>•测试集Ei:</strong>由目标患者i的所有不重叠的发作样本和来自同一患者的两倍多的发作间样本组成，即ST esti。</p> 
<p>请注意，合成的ictal样本是目标训练集Ti和基线训练集Bi之间唯一不同的方面。这确保了两个训练集之间的<span style="color:#956fe7;"><strong>性能差异</strong></span>完全是<strong>由于发作样本的质量，而不是真正的发作间样本ST raini</strong>。另一方面，我们建立了一个不平衡的测试集Ei，其中发作间期样本数量为发作期样本的两倍;尽管如此，我们用来衡量系统性能的指标(灵敏度和特异性)与数据集中的inter-ictal和ictal的比率是不变的。考虑到每个患者记录的癫痫发作次数不同，测试集的大小在患者之间略有变化。</p> 
<p>一旦数据在训练集和测试集中被分割，在我们的程序中执行的<span style="color:#956fe7;"><strong>第二步是识别和提取相关特征</strong></span>。在这一阶段，<span style="color:#956fe7;"><strong>我们再次遵循[7]，每个电极提取54个功率和非线性的特征，由于我们考虑两个电极，所以特征总数为108个。</strong></span>这些特征随后被提取为所有样本在训练和测试集。</p> 
<p>计算非线性特征后，利用<span style="color:#956fe7;"><strong>离散小波变换将信号分解至7级</strong></span>。提取的<span style="color:#956fe7;"><strong>非线性特征</strong></span>为:k = 0.2和k = 0.35时的第六和第七级样本熵[54];n = 3, n = 5, n = 7时，第三，第四，第五，第六和第七能级排列熵[55];第三，第四，第五，第六和第七层，以及原始信号，香农，Renyi和Tsallis熵。<strong><span style="color:#956fe7;">功率特征</span>为:δ [0.5,4] Hz， θ [4,8] Hz， α [8,12] Hz， β [13,30] Hz， γ [30,45] Hz以及[0,0.1]Hz， [0.1,0.5] Hz， [12,13] Hz中的<span style="color:#956fe7;">总功率，总频带功率和相对频段功率</span>。</strong></p> 
<p>特征提取后，使用目标训练集训练<span style="color:#956fe7;"><strong>随机森林分类器</strong></span>，并将得到的分类器与测试集进行评估。然后对基线训练集重复相同的过程，其结果用作参考。我们为每个患者重复这些实验15次，每次对数据进行洗牌，以使我们的结果对不同的数据分割以及随机森林的不同学习配置具有鲁棒性。</p> 
<p>所提出的过程提供了一个框架，通过简单地在目标训练集中使用给定模型生成的合成ictal样本，就可以轻松地比较不同的生成模型。此外，使用可穿戴设备中癫痫发作检测的下游任务作为信号质量的代理，使我们可以直接得出关于一组合成发作样本的效用的结论。因此，后续工作可以依靠这一程序来比较综合生成的ictal数据的质量和效用。</p> 
<h3 style="text-align:center;">VI. RESULTS</h3> 
<h4>A.模型收敛</h4> 
<p>为了<span style="color:#956fe7;"><strong>确定EpilepsyGAN的收敛点</strong></span>，我们随机选取5名患者(患者2、8、9、17和30)作为验证集，评估模型在不同训练时期产生的数据;我们也使用这个验证集来确定模型的其他超参数，在第三节中描述。患者8患有额叶癫痫，而验证组中的其他患者患有颞叶癫痫。<strong>我们计算每个模型的性能评分为敏感性和特异性的几何平均值，其中敏感性和特异性分别为真阳性率和真阴性率</strong>。我们报告几何平均值，因为它是规范化值[56]的<strong>唯一正确平均值</strong>。表一显示了五名患者在不同时期的平均表现。我们观察到超过100个epoch的训练是如何影响性能的，因此，我们训练了100个epoch的EpilepsyGAN。</p> 
<p><img alt="" height="268" src="https://images2.imgbox.com/3f/bb/6T1gtTZY_o.png" width="506"></p> 
<h3> B.真实样本与合成样本的相似性</h3> 
<p>在对GAN模型生成的样本的质量和效用进行定量评估之前，我们视觉地检查了合成的ictal样本，并将其与真实的ictal样本进行了比较。通过这种方式，我们验证了模型生成的样本不仅可以训练检测系统，而且是真实的，并遵循与癫痫发作相关的模式。如图4所示，我们将感兴趣的两个电极的4秒真实发作期脑电图信号与为同一患者生成的4秒合成发作期脑电图进行比较，我们观察到众所周知的δ - θ节律的存在，即有节奏的缓慢活动，振荡频率在0.5-4或4-7赫兹。<span style="color:#956fe7;"><strong>这种模式清楚地表明，在合成生成的脑电图信号[57]中，发作放电和癫痫发作段是正确产生的。</strong></span></p> 
<p>接下来，我们<span style="color:#956fe7;"><strong>定量研究我们的合成发作数据与真实发作数据的相似程度</strong></span>。为了了解合成样本与真实样本之间的相似度，我们还计算了真实样本之间的相似度，并以此作为参考。</p> 
<p>这样，对于每个患者，我们得到两个值:<strong>真实到真实的相似性和真实到合成的相似性</strong>。为了计算每个相似值，我们做以下工作:</p> 
<p>1)我们从同一个病人中随机选择2000对信号。在实变合成的情况下，每对信号中一个是实信号，另一个是合成信号;在实对实的情况下，两个信号都是实的且不同。</p> 
<p>2)对于每一对信号，我们分别计算每个电极的FFT;这样每个信号产生两个fft，即每对4个fft。</p> 
<p>3)计算每对电极对应fft之间的余弦相似度;然后对两个电极求平均值。</p> 
<p>4)最后，我们对2000对进行平均，得到每个患者一个数字。</p> 
<p>测量FFTs之间的相似性而不是原始信号之间的相似性的理由是<span style="color:#956fe7;"><strong>癫痫发作表现为某些频段的变化</strong></span>;因此，FFT更好地代表了我们感兴趣的信息。<span style="color:#956fe7;"><strong>余弦相似度的选择是合理的</strong></span>，因为这个度量对数据的移位很敏感。这样，<strong>如果两个信号在不同的频带上呈现较高的值，相似值就会较小</strong>。相似性研究结果如图5所示。请注意，垂直轴的范围很窄，在0.54和0.68之间。</p> 
<p><img alt="" height="406" src="https://images2.imgbox.com/85/94/sWK7JbLf_o.png" width="539"></p> 
<p>结果表明，在实-实和实-合成两种情况下，信号相似度都在相同的范围内。此外，从图中可以清楚地看出，在这两种情况下，<strong>患者之间的相似值遵循相同的模式，</strong>即真实与真实相似度高的患者往往具有较高的真实与合成相似度，反之亦然。这个实验首次证明了我们的生成方法的有效性。</p> 
<h4>C.合成信号性能</h4> 
<p>在视觉检查和相似性分析之后，我们根据我们的评估程序对epilepsiae数据集中剩余的25名患者进行实验。我们在这里强调，<strong>每次评估的患者对应于GAN训练期间遗漏的患者，因此GAN和测试集之间不存在信息泄漏。</strong>我们对每位患者的实验详细结果见表二。同样，报告的值是敏感性和特异性的几何平均值。</p> 
<p><img alt="" height="559" src="https://images2.imgbox.com/46/a7/HIQsngAN_o.png" width="517"></p> 
<p>直观地，我们会期望用合成的发作样本训练癫痫发作检测算法会导致性能下降。然而，我们的实验表明，与仅使用来自通用数据库的真实样本的训练相比，使用合成样本的训练总体上提高了1.3%。使用合成数据时性能改善的一种解释是，<span style="color:#956fe7;"><strong>由于我们的GAN生成发作期数据来自同一患者的发作间样本，因此模型生成的合成癫痫保留了许多个人特征。</strong></span>这一总表现差异的计算方法是综合病例中所有患者得分的几何平均值与基线病例中所有患者得分的几何平均值之间的差值。这些结果通过了Wilcoxon统计显著性检验，p值为0.011，22号病人已排除1，这表明基线和合成训练集获得的结果之间的差异具有统计学意义。除此之外，如图6所示，24例患者中有16例(67%)改善超过1%，而24例患者中只有3例表现下降超过1%。</p> 
<p><img alt="" height="387" src="https://images2.imgbox.com/ec/b9/3GV3lcX0_o.png" width="494"></p> 
<p>对于表现下降最明显的患者，患者21的癫痫发作发生在枕叶，以重复尖刺为主。这种模式相对罕见，在数据集中没有很好地表现出来(仅占癫痫发作的10.5%)。因此，我们的GAN不能像捕捉其他模式那样精确地模拟这种行为。此外，患者20在该数据集中只有4次癫痫发作，这是数据集中癫痫发作次数最少的，阻碍了我们对该患者合成数据的可靠评估。</p> 
<p>这些结果证明了<strong>我们生成的合成发作数据的高质量</strong>，以及它对癫痫发作检测的现实世界任务的实用性。在我们的实验中，我们试图以可比的方式评估数据的性能，因此我们在评估中不引入任何先验知识。然而，在需要监测患者的现实环境中，可以使用关于目标患者癫痫发作模式的先验知识来适应GAN的训练。通过这种方式，EpilepsyGAN可以仅使用与目标患者遵循相同模式的发作样本进行训练，这可能会提高检测算法的性能。我们把这个实验的扩展留到以后的工作去做。</p> 
<h4>D.模式崩溃评估</h4> 
<p>GANs的对抗性训练可能会失败，导致模式崩溃，即生成器崩溃为几个模式或样本类型，系统地欺骗鉴别器[58]。</p> 
<p>我们观察到患者22在基线和合成训练集上的表现都非常差，因此，它不是样本质量的相关指标。这个病人患有顶叶癫痫，上面提到的电极几乎感觉不到这个顶叶。因此，该患者已从性能总差异的计算中删除。</p> 
<p>因此，如果模型遭受这种不希望的失败，所生成的数据的多样性是有限的，输入条件被忽略。如果我们的模型发生模态塌缩，不同患者产生的数据将收敛到相同的合成样本。<span style="color:#956fe7;"><strong>在这里，我们研究了我们的GAN模型在训练过程中是否会发生模式塌缩，</strong></span>如果发生，会发生到什么程度。在本实验中，我们仅使用来自所有患者的合成ictal信号，并将这些信号随机分为<strong>训练集(70%)和测试集(30%)。</strong>我们考虑我们的CNN架构，并训练模型将每个合成的ictal信号映射到相应的患者，即该信号为其产生的患者。</p> 
<p>该分类任务的结果经过归一化处理，如图7所示为混淆矩阵，30例患者中有28例被分类，准确率超过93.5%。只有2例准确率较低，分别为75.9%和23.3%，而平均准确率高达95.4%。结果清楚地表明，为每个患者生成的合成ictal样本是不同的和可区分的，这反过来表明模式崩溃不会在患者之间发生。</p> 
<p><img alt="" height="389" src="https://images2.imgbox.com/ee/10/l9Yfht1M_o.png" width="489"></p> 
<h4> E.患者识别</h4> 
<p>为了评估患者识别任务，我们使用与上述相同的5名患者进行验证(患者2、8、9、17和30)。其余25例患者符合测试集，我们在实验中从中选择不同的子集。特别地，我们选择N = 2,4,8,16和25个患者的子集，从测试集中的25个患者中随机选择。<span style="color:#956fe7;"><strong>在这些子集上，我们使用数据集中的所有发作间信号、真实发作期信号和合成发作期信号执行第四节中描述的识别任务</strong></span>。结果如图8所示。在该图中，五组显示了测试集中N = 2、4、8、16和25例患者的实验结果。每一组包括三个条，分别表示用于exporig、Expsynt和expand的识别精度。</p> 
<p><img alt="" height="422" src="https://images2.imgbox.com/29/7e/BuJDppnJ_o.png" width="502"></p> 
<p></p> 
<p>我们注意到本实验的设置，<strong>特别是Expsynt的设置与前一节的模式崩溃实验有本质的不同:</strong>在模式崩溃实验中，训练集和测试集都由纯合成的ictal样本组成，而在这里，训练集由真实的ictal数据和真实的ictal (exports)和合成的ictal (Expsynt)数据组成。因此，<strong>本患者识别实验研究了是否有可能在给定患者的发作间和发作间样本(真实或合成)之间建立关联，无论是否存在模式坍塌。</strong></p> 
<p>通过比较exporig和expand的结果，很明显，<span style="color:#956fe7;"><strong>当我们考虑原始的(真实的)发作信号时，与随机基线相比，患者明显更容易被重新识别</strong></span>。当N = 2、4、8、16和25时，exporig(蓝柱)和Exprand(黄柱)的可识别性比，即可识别的患者多多少倍，分别为1.5倍、2.8倍、4.4倍、7.1倍和9.6倍。</p> 
<p>另一方面，Expsynt的结果表明，<span style="color:#956fe7;"><strong>使用合成数据进行患者识别要比使用真实数据困难得多</strong></span>。比较Expsynt(红色柱状图)和expand(黄色柱状图)的结果，我们看到当N = 2、4、8、16和25时，识别率分别低至1.1x、1.1x、1.4x、1.3x和1.3x。最后，<strong>当N = 25时，Expsynt和exporig的比值为7.2倍，这表明从合成数据中重新识别患者比使用真实数据困难7.2倍。这些结果证明了我们的生成方法在隐私方面的收益。</strong></p> 
<h4>F 针对病人的结果</h4> 
<p>接下来，我们对识别结果进行深入研究，并调查每个患者的可识别性。现在，对于每个实验，exporig和Expsynt，来自25名患者的所有发作信号都被输入到训练过的模型中，以进行识别。<span style="color:#956fe7;"><strong>对于每个患者i，第i个患者被正确识别的信号数用TPi表示。第i个患者与其他患者错误关联的信号数用FNi表示</strong></span>。基于这两个关键值，我们计算召回(敏感性)指标，以产生患者特定的结果。</p> 
<p>召回率指标定义如下:</p> 
<p><img alt="" height="118" src="https://images2.imgbox.com/2f/09/2jGK5Ul8_o.png" width="705"></p> 
<p>对于每个实验中的每个测试患者，我们计算回忆值。图9显示了使用真实和合成的ictal信号时的患者特异性回忆值。</p> 
<p><img alt="" height="346" src="https://images2.imgbox.com/fa/fb/TSGh4KF1_o.png" width="477"></p> 
<p>在图9中，每个小提琴形状代表了测试集中所有患者回忆值的分布。左手边的小提琴，对应真实ictal数据的实验回忆值。我们看到，对于真实的ictal数据，召回率上四分位数为58.6%。这表明，<span style="color:#956fe7;"><strong>仅根据患者的真实发作数据，就可以识别出四分之一的患者，概率超过58.6%</strong></span>。请注意，如果我们为每个输入信号随机选择一个患者，召回指标将为4.0%。另外，8例患者的再识别概率超过50.0%。该召回分布的最大值为74.2%。另一方面，<strong>合成数据的召回值分布如图</strong>9中右手边的小提琴所示。中位数仅为3.2%，<span style="color:#956fe7;"><strong>这意味着使用合成数据，识别出一半以上患者的概率与随机数据相同</strong></span>。这表明，与真实数据相比，由EpilepsyGAN生成的合成数据不太容易受到隐私漏洞和重新识别的影响。</p> 
<h4>g .讨论</h4> 
<p>本节的实验表明:</p> 
<p><span style="color:#956fe7;"><strong>1)合成癫痫可以用来训练癫痫检测算法，即区分真实发作间期和真实发作信号。</strong></span></p> 
<p><span style="color:#956fe7;"><strong> 2)生成模型不会坍缩为单一模式，即针对不同的患者产生不同的信号。</strong></span></p> 
<p><span style="color:#956fe7;"><strong>3)对于真实的发作间信号，从真实的发作样本中识别患者比从合成的发作样本中识别患者更容易。</strong></span></p> 
<p>这些实验是互补的，因为1)在给定合成发作样本的情况下，确定真实发作样本和发作间样本之间的可辨别性；2)区分患者之间的合成发作样本；以及3)研究给定患者的发作间样本和发作样本之间的关系。。结果表明，虽然合成的发作信号在患者之间是不同的(这是所期望的)，但从合成的发作信号中识别患者比从真实的发作信号中识别患者要困难得多，而且在癫痫发作检测任务中没有退化。</p> 
<h3>7结论</h3> 
<p>在这项工作中，我们提出了一种生成模型<span style="color:#956fe7;"><strong>EpilepsyGAN，它成功地生成了癫痫发作的合成脑电图信号</strong></span>。这构成了深度生成模型在医疗保健领域的直接应用，并在癫痫治疗方面向前迈出了一步。此外，我们还提出了一个<span style="color:#956fe7;"><strong>评估程序</strong></span>，使我们能够系统地和定量地评估生成的合成ictal样本的质量和效用。我们的结果强调，专门使用合成癫痫发作的训练可以获得与使用通用真实样本的训练相当的表现。</p> 
<p>据我们所知，在医疗领域，我们第一次生成了可以训练检测算法的合成数据集，并基于真实数据达到(甚至改进)最先进的结果，这证明了我们合成数据的质量。<strong>这种解决方案既避免了与扣押记录和标记相关的成本，也避免了共享个人和敏感数据所带来的隐私问题。</strong>虽然我们已经证明了我们的GAN模型可以生成真实的癫痫发作信号，但<strong><span style="color:#956fe7;">进一步提高信号质量</span></strong>可能需要修改模型和训练策略。特别是，使用<span style="color:#956fe7;"><strong>未配对数据的模型的变分版本</strong></span>是一个很有前途的候选，因为它应该能够学习分布之间(inter-ictal和ictal)的匹配，而不是样本之间的匹配。我们相信，对未配对和条件深度生成模型的进一步研究可能会推动该领域朝着基于合成数据的个性化医疗方向发展。</p> 
<p>最后，我们已经证明了从发作数据中重新识别患者是可能的，并证明了使用我们提出的GAN模型产生的合成信号缓解了与共享癫痫发作检测数据相关的隐私问题，而不会损失检测性能。</p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5fb2828a0acdd19e88ac1b1036f49200/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">map2object</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ea4757e1f83a80409de559f7aa01a07b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">动态表格Vue版</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>