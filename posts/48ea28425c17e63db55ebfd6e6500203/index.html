<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>（2021，StyleGAN3）无失真（Alias-Free）生成对抗网络 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="（2021，StyleGAN3）无失真（Alias-Free）生成对抗网络" />
<meta property="og:description" content="Alias-Free Generative Adversarial Networks
公众号：EDPJ
目录
0. 摘要
1. 简介
2. 通过连续信号解释的等变性（equivariance）
2.1 等变网络层
3. 在生成网络中的实际应用 3.1 傅里叶特征和基线简化（配置 B–D）
3.2 由连续解释驱动的逐步重新设计
4. 结果
5. 局限性、讨论和未来工作
参考
S. 总结
S.1 核心思想
S.2 网络结构
0. 摘要 我们观察到，尽管具有层次卷积性质，典型的生成对抗网络的合成过程以不健康的方式依赖于绝对像素坐标。 这表现为，例如，细节似乎粘在图像坐标上，而不是所描绘物体的表面。 我们将根本原因追溯到导致生成器网络失真的粗心信号处理。 将网络中的所有信号解释为连续信号，我们得出普遍适用的小架构更改，以确保不需要的信息不会泄漏到分层合成过程中。 生成的网络与 StyleGAN2 的 FID 相匹配，但它们的内部表示存在显着差异，并且即使在亚像素尺度上，它们也完全等同于平移和旋转。 我们的结果为更适合视频和动画的生成模型铺平了道路。
1. 简介 在现实世界中，不同尺度的细节倾向于分层变换。 例如，移动头部会导致鼻子移动，进而移动其上的皮肤毛孔。 典型的 GAN 生成器的结构是类似的：粗糙的、低分辨率的特征通过上采样层分层细化，通过卷积局部混合，并通过非线性引入新的细节。 我们观察到，尽管有这种表面上的相似性，但当前的 GAN 架构并没有以自然的分层方式合成图像：粗特征主要控制更精细特征的存在，而不是它们的精确位置。 相反，许多细节似乎都固定在像素坐标中。 这种令人不安的“纹理粘附”在隐空间插值中清晰可见（参见图 1 和我们在项目页面上的随附视频），打破了在空间中移动的固体和连贯物体的错觉。我们的目标是展示更自然的转换层次结构 ，其中每个特征的确切子像素位置完全继承自底层粗糙特征。
事实证明，当前网络可以通过图像边界、每像素噪声输入和位置编码以及混叠（或失真），利用中间层可获得的非故意位置参考，部分绕过理想的分层结构。失真尽管是一个微妙而关键的问题，但在 GAN 文献中却很少受到关注。 我们确定了它的两个来源：1）由非理想的上采样滤波器（例如最近邻、双线性的或跨步的卷积）产生的像素网格的微弱残像（faint after-images），以及 2）非线性的逐点应用，例如 ReLU 或 swish。 我们发现网络有办法和动机来放大哪怕是最轻微的失真，并将其组合到多个尺度上，使其能够为屏幕坐标中固定的纹理图案奠定基础。 这适用于深度学习中常用的所有滤波器，甚至是图像处理中使用的高质量滤波器。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/48ea28425c17e63db55ebfd6e6500203/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-26T17:28:02+08:00" />
<meta property="article:modified_time" content="2023-05-26T17:28:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">（2021，StyleGAN3）无失真（Alias-Free）生成对抗网络</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:center;"><strong>Alias-Free Generative Adversarial Networks</strong></p> 
<p style="text-align:center;"><strong>公众号：EDPJ</strong></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="-toc" style="margin-left:0px;"><a href="#0.%20%E6%91%98%E8%A6%81" rel="nofollow">0. 摘要</a></p> 
<p id="1.%20%E7%AE%80%E4%BB%8B-toc" style="margin-left:0px;"><a href="#1.%20%E7%AE%80%E4%BB%8B" rel="nofollow">1. 简介</a></p> 
<p id="2.%20%E9%80%9A%E8%BF%87%E8%BF%9E%E7%BB%AD%E4%BF%A1%E5%8F%B7%E8%A7%A3%E9%87%8A%E7%9A%84%E7%AD%89%E5%8F%98%E6%80%A7%EF%BC%88equivariance%EF%BC%89-toc" style="margin-left:0px;"><a href="#2.%20%E9%80%9A%E8%BF%87%E8%BF%9E%E7%BB%AD%E4%BF%A1%E5%8F%B7%E8%A7%A3%E9%87%8A%E7%9A%84%E7%AD%89%E5%8F%98%E6%80%A7%EF%BC%88equivariance%EF%BC%89" rel="nofollow">2. 通过连续信号解释的等变性（equivariance）</a></p> 
<p id="2.1%20%E7%AD%89%E5%8F%98%E7%BD%91%E7%BB%9C%E5%B1%82-toc" style="margin-left:40px;"><a href="#2.1%20%E7%AD%89%E5%8F%98%E7%BD%91%E7%BB%9C%E5%B1%82" rel="nofollow">2.1 等变网络层</a></p> 
<p id="3.%20%E5%9C%A8%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%C2%A0-toc" style="margin-left:0px;"><a href="#3.%20%E5%9C%A8%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%C2%A0" rel="nofollow">3. 在生成网络中的实际应用 </a></p> 
<p id="3.1%20%E5%82%85%E9%87%8C%E5%8F%B6%E7%89%B9%E5%BE%81%E5%92%8C%E5%9F%BA%E7%BA%BF%E7%AE%80%E5%8C%96%EF%BC%88%E9%85%8D%E7%BD%AE%20B%E2%80%93D%EF%BC%89-toc" style="margin-left:40px;"><a href="#3.1%20%E5%82%85%E9%87%8C%E5%8F%B6%E7%89%B9%E5%BE%81%E5%92%8C%E5%9F%BA%E7%BA%BF%E7%AE%80%E5%8C%96%EF%BC%88%E9%85%8D%E7%BD%AE%20B%E2%80%93D%EF%BC%89" rel="nofollow">3.1 傅里叶特征和基线简化（配置 B–D）</a></p> 
<p id="3.2%20%E7%94%B1%E8%BF%9E%E7%BB%AD%E8%A7%A3%E9%87%8A%E9%A9%B1%E5%8A%A8%E7%9A%84%E9%80%90%E6%AD%A5%E9%87%8D%E6%96%B0%E8%AE%BE%E8%AE%A1-toc" style="margin-left:40px;"><a href="#3.2%20%E7%94%B1%E8%BF%9E%E7%BB%AD%E8%A7%A3%E9%87%8A%E9%A9%B1%E5%8A%A8%E7%9A%84%E9%80%90%E6%AD%A5%E9%87%8D%E6%96%B0%E8%AE%BE%E8%AE%A1" rel="nofollow">3.2 由连续解释驱动的逐步重新设计</a></p> 
<p id="4.%20%E7%BB%93%E6%9E%9C-toc" style="margin-left:0px;"><a href="#4.%20%E7%BB%93%E6%9E%9C" rel="nofollow">4. 结果</a></p> 
<p id="5.%20%E5%B1%80%E9%99%90%E6%80%A7%E3%80%81%E8%AE%A8%E8%AE%BA%E5%92%8C%E6%9C%AA%E6%9D%A5%E5%B7%A5%E4%BD%9C-toc" style="margin-left:0px;"><a href="#5.%20%E5%B1%80%E9%99%90%E6%80%A7%E3%80%81%E8%AE%A8%E8%AE%BA%E5%92%8C%E6%9C%AA%E6%9D%A5%E5%B7%A5%E4%BD%9C" rel="nofollow">5. 局限性、讨论和未来工作</a></p> 
<p id="%E5%8F%82%E8%80%83-toc" style="margin-left:0px;"><a href="#%E5%8F%82%E8%80%83" rel="nofollow">参考</a></p> 
<p id="S.%20%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#S.%20%E6%80%BB%E7%BB%93" rel="nofollow">S. 总结</a></p> 
<p id="S.1%20%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3-toc" style="margin-left:40px;"><a href="#S.1%20%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3" rel="nofollow">S.1 核心思想</a></p> 
<p id="S.2%20%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-toc" style="margin-left:40px;"><a href="#S.2%20%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84" rel="nofollow">S.2 网络结构</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="0.%20%E6%91%98%E8%A6%81">0. 摘要</h2> 
<p>我们观察到，尽管具有层次卷积性质，典型的生成对抗网络的合成过程以不健康的方式依赖于绝对像素坐标。 这表现为，例如，细节似乎粘在图像坐标上，而不是所描绘物体的表面。 我们将根本原因追溯到导致生成器网络失真的粗心信号处理。 将网络中的所有信号解释为连续信号，我们得出普遍适用的小架构更改，以确保不需要的信息不会泄漏到分层合成过程中。 生成的网络与 StyleGAN2 的 FID 相匹配，但它们的内部表示存在显着差异，并且即使在亚像素尺度上，它们也完全等同于平移和旋转。 我们的结果为更适合视频和动画的生成模型铺平了道路。</p> 
<h2 id="1.%20%E7%AE%80%E4%BB%8B">1. 简介</h2> 
<p><img alt="" height="359" src="https://images2.imgbox.com/3c/6f/j7JKP2GT_o.png" width="759"></p> 
<p>在现实世界中，不同尺度的细节倾向于分层变换。 例如，移动头部会导致鼻子移动，进而移动其上的皮肤毛孔。 典型的 GAN 生成器的结构是类似的：粗糙的、低分辨率的特征通过上采样层分层细化，通过卷积局部混合，并通过非线性引入新的细节。 我们观察到，尽管有这种表面上的相似性，但当前的 GAN 架构并没有以自然的分层方式合成图像：粗特征主要控制更精细特征的存在，而不是它们的精确位置。 相反，许多细节似乎都固定在像素坐标中。 这种令人不安的“纹理粘附”在隐空间插值中清晰可见（参见图 1 和我们在项目页面上的随附视频），打破了在空间中移动的固体和连贯物体的错觉。我们的目标是展示更自然的转换层次结构 ，其中每个特征的确切子像素位置完全继承自底层粗糙特征。</p> 
<p>事实证明，当前网络可以通过图像边界、每像素噪声输入和位置编码以及混叠（或失真），利用中间层可获得的非故意位置参考，部分绕过理想的分层结构。失真尽管是一个微妙而关键的问题，但在 GAN 文献中却很少受到关注。 我们确定了它的两个来源：1）由非理想的上采样滤波器（例如最近邻、双线性的或跨步的卷积）产生的像素网格的微弱残像（faint after-images），以及 2）非线性的逐点应用，例如 ReLU 或 swish。 我们发现网络有办法和动机来放大哪怕是最轻微的失真，并将其组合到多个尺度上，使其能够为屏幕坐标中固定的纹理图案奠定基础。 这适用于深度学习中常用的所有滤波器，甚至是图像处理中使用的高质量滤波器。</p> 
<p>那么，我们如何消除不需要的辅助信息，从而阻止网络使用它呢？ 虽然可以通过简单地对稍大的图像进行操作来解决边界问题，但失真要困难得多。我们首先注意到失真在经典的 Shannon-Nyquist 信号处理框架中得到最自然的处理，然后将焦点切换到仅由离散样本网格表示的连续域上的带限函数。现在，成功消除所有位置参考源意味无论像素坐标如何，都可以同样好地生成细节，这反过来相当于在所有层中对亚像素平移（可选的旋转）实施连续等变（equivariance）。 为实现这一目标，我们描述了对 StyleGAN2 生成器的所有信号处理方面的全面改革。 我们的贡献包括令人惊讶的发现，即当前的上采样滤波器在抑制失真方面根本不够积极，并且需要衰减超过 100dB 的极高品质滤波器。 此外，我们通过考虑逐点非线性在连续域中的影响并对结果进行适当的低通滤波，提出了一种解决由逐点非线性引起的失真的原则性解决方案。 我们还表明，在大修之后，基于 1x1 卷积的模型产生了一个强大的旋转等变变换生成器。</p> 
<p>一旦失真被充分抑制以迫使模型实现更自然的层次细化，其操作模式就会发生巨大变化：出现的内部 representation 现在包括允许细节正确附加到底层表面的坐标系。 这有望显着改进生成视频和动画的模型。 新的 StyleGAN3 生成器在 FID 方面与 StyleGAN2 相匹配，但计算量稍大。</p> 
<p>最近的几项工作研究了 CNN 中缺乏的 translation equivariance，主要是在分类的背景下。 我们显着扩展了该文献中的抗失真措施，并表明这样做会导致根本改变的图像生成行为。Group-equivariant CNN 旨在将平移权重共享的效率优势推广到例如旋转和缩放。 我们的 1x1 卷积可以看作是一个连续 E2-equivariant 模型的实例，它与例如通道方式的 ReLU 非线性和调制保持兼容。 Dey 等人将 90° 旋转和翻转 equivariant CNN 应用于 GAN 并显示出改进的数据效率。 我们的工作是互补的，而不是为了效率。 最近基于隐式网络的 GAN通过类似的 1x1 卷积独立生成每个像素。 虽然是等变的（equivariant,），但这些模型对纹理粘附没有帮助，因为它们不使用上采样层次结构或实现浅层非抗锯齿层次结构。</p> 
<h2 id="2.%20%E9%80%9A%E8%BF%87%E8%BF%9E%E7%BB%AD%E4%BF%A1%E5%8F%B7%E8%A7%A3%E9%87%8A%E7%9A%84%E7%AD%89%E5%8F%98%E6%80%A7%EF%BC%88equivariance%EF%BC%89">2. 通过连续信号解释的等变性（equivariance）</h2> 
<p>要开始分析 CNN 中的等变性，我们首先要重新思考我们对流经网络的信号究竟是什么的看法。 即使数据可以作为值存储在像素网格中，我们也不能天真地用这些值来直接表示信号。 这样做会阻止我们将 operations 视为将特征图的内容平移半个像素这样微不足道的操作。</p> 
<p>根据 Nyquist–Shannon 采样定理，定期采样的信号可以表示任何包含介于零和采样率一半之间的频率的连续信号。 让我们考虑一个二维、离散采样的特征映射 Z[x]，它由不同幅度的 Dirac 脉冲的规则网格组成，间隔 1/s 个单位，其中 s 是采样率。 这类似于无限的二维值网格。</p> 
<p>给定 Z[x] 和 s，Whittaker–Shannon 插值公式指出相应的连续 representation z(x) 是通过将离散采样的 Dirac 网格 Z[x] 与理想插值滤波器 Φ_s 进行卷积而获得的，即，z(x) =(Φ_s * Z)(x)，其中 * 表示连续卷积，Φ_s(x) = sinc(sx_0) · sinc(sx_1)，sinc(x) = sin(πx) / (πx)。Φ_s 在水平和垂直维度上的带宽限制为 s/2，确保生成的连续信号捕获可以用采样率 s 表示的所有频率。</p> 
<p><img alt="" height="314" src="https://images2.imgbox.com/58/76/ySyV8MSY_o.png" width="911"></p> 
<p>从连续域到离散域的转换对应于在 Z[x] 的采样点对连续信号 z(x) 进行采样，我们将其定义为偏移一半的样本间距，从而位于“像素中心”，参见图 2 left。 这可以表示为与二维 Dirac comb 的点乘</p> 
<p class="img-center"><img alt="" height="28" src="https://images2.imgbox.com/71/5f/0AGOiCG1_o.png" width="354"></p> 
<p>我们指定在 z(x) 中的单位正方形 x ∈ [0,1]^2 作为我们感兴趣的信号的画布。 在 Z[x] 中，该区域有 s^2 个离散样本，但上面与 Φ_s 的卷积意味着单位正方形外的 Z[x] 的值也会影响单位正方形内的 z(x)。 因此，存储 s 个像素特征图是不够的； 理论上，我们需要存储整个无限 Z[x]。 作为一个实用的解决方案，我们将 Z[x] 存储为一个二维数组，该数组覆盖的区域略大于单位正方形（第 3.2 节）。 </p> 
<p>在带宽有限、连续的特征图 z(x) 和离散采样的特征图 Z[x] 之间建立对应关系后，我们可以将注意力从通常的以像素为中心的信号视图上移开。 在本文的其余部分，我们将把 z(x) 解释为正在操作的实际信号，而离散采样的特征图 Z[x] 只是一种方便的编码。</p> 
<p><strong>网络层的离散和连续的 representation</strong>。实际的神经网络在离散采样的特征图上运行。 考虑在离散特征图上运行的操作 F（卷积、非线性等）：Z' = F(Z)。 特征图有相应的连续对应物，因此我们在连续域中也有相应的映射：z' = f(z)。 现在，可以看到在一个域中指定的操作在另一个域中执行相应的操作： </p> 
<p><img alt="" height="30" src="https://images2.imgbox.com/87/7e/aFW5P85x_o.png" width="773"></p> 
<p>其中，⊙ 表示点乘，s 和 s' 是输入和输出采样率。 请注意，在后一种情况下，f 不得引入超出输出带宽限制 s'/2 的频率内容。</p> 
<h3 id="2.1%20%E7%AD%89%E5%8F%98%E7%BD%91%E7%BB%9C%E5%B1%82">2.1 等变网络层</h3> 
<p>如果操作 f 在连续域中与 2D 平面的空间变换 t 可互换：tΟf = fΟt，则操作 f 与 2D 平面的空间变换 t 是等变的。 我们注意到，当输入带宽限制为 s/2 时，等变操作不得生成高于 s'/2 的输出带宽限制的频率内容，否则不存在保真的离散输出 representation。</p> 
<p>我们在本文中关注两种类型的等变：平移和旋转。 在旋转的情况下，谱约束稍微严格一些——旋转图像对应于旋转谱，为了保证水平和垂直方向的带宽限制，谱必须限制在半径 s/2 的圆盘上。 这适用于初始网络输入以及用于下采样的带宽限制滤波器，稍后将进行描述。</p> 
<p>我们现在考虑典型生成器网络中的原始操作：卷积、上采样、下采样和非线性。 不失一般性，我们讨论作用于单个特征图的操作：特征的逐点线性组合对分析没有影响。</p> 
<p><strong>卷积。</strong>考虑具有离散内核 K 的标准卷积。我们可以将 K 解释为与输入特征图位于同一网格中，采样率为 s。 离散域运算就是 F_conv(Z) = K*Z，我们从等式 1 中得到相应的连续运算: </p> 
<p><img alt="" height="26" src="https://images2.imgbox.com/ca/5e/lD0uBf0I_o.png" width="762"></p> 
<p>由于卷积的可交换性以及离散化之后与理想低通滤波器卷积的事实，两者都具有相同的采样率 s，是恒等操作，即，</p> 
<p class="img-center"><img alt="" height="22" src="https://images2.imgbox.com/3f/14/dLlODZ0N_o.png" width="178"></p> 
<p>换句话说，卷积通过在特征图的连续 representation 上连续滑动离散化内核来运行。 这个卷积没有引入新的频率，所以平移和旋转等变的带宽限制要求很容易满足。 </p> 
<p>卷积也在连续域中与平移交换，因此该操作与平移等变。对于旋转等方差，离散核 K 需要径向对称。 我们稍后在第 3.2 节中展示了平凡对称的 1x1 卷积核，尽管它们很简单，但对于旋转等变生成网络来说是一个可行的选择。</p> 
<p><strong>上采样和下采样。</strong>理想的上采样不会修改连续 representation。 它的唯一目的是增加输出采样率 (s' &gt; s) 以在后续层可能引入额外内容的频谱中增加净空（headroom）。 平移和旋转等变来自作为连续域中恒等操作的上采样。 当 f_up (z) = z 时，根据等式 1 进行离散运算表示为</p> 
<p class="img-center"><img alt="" height="28" src="https://images2.imgbox.com/e1/00/pSgpMsbf_o.png" width="240"></p> 
<p>如果我们选择 s' = ns 且 n 为整数，则可以通过首先将 Z 与零交织以提高其采样率，然后将其与如下离散滤波器进行卷积来实现操作。</p> 
<p class="img-center"><img alt="" height="26" src="https://images2.imgbox.com/4f/78/VdRpDL8l_o.png" width="97"></p> 
<p>在下采样中，我们必须对 z 进行低通滤波以去除高于输出带宽限制的频率，以便信号可以在较粗糙的离散化中得到忠实的表示。 连续域中的操作是</p> 
<p class="img-center"><img alt="" height="23" src="https://images2.imgbox.com/e9/ec/UcM3Znbx_o.png" width="174"></p> 
<p>其中一个理想的低通滤波器</p> 
<p class="img-center"><img alt="" height="27" src="https://images2.imgbox.com/07/c0/5E8Kerbk_o.png" width="129"></p> 
<p>只是归一化为单位质量的相应插值滤波器。 离散的对应物是 F_down (Z) =</p> 
<p><img alt="" height="27" src="https://images2.imgbox.com/58/51/8d73z2rU_o.png" width="734"></p> 
<p>后一个相等来自</p> 
<p class="img-center"><img alt="" height="31" src="https://images2.imgbox.com/71/63/NPZn8jMI_o.png" width="259"></p> 
<p>与上采样类似，整数分数的下采样可以通过离散卷积然后丢弃采样点来实现。 平移等变性自动遵循 f_down (z) 与平移的交换性，但对于旋转等变性，我们必须用具有圆盘形频率响应的径向对称滤波器替换 Φ_s'。 这种理想的滤波器由下式给出</p> 
<p class="img-center"><img alt="" height="29" src="https://images2.imgbox.com/bc/0b/6QMahUaQ_o.png" width="430"></p> 
<p>其中 J_1 是第一类一阶贝塞尔（Bessel）函数。 </p> 
<p><strong>非线性。</strong>在离散域中应用逐点非线性不能与分部平移或旋转交换。 然而，在连续域中，任何逐点函数都可以与几何变换进行交换，因此与平移和旋转等变。 满足带宽限制是另一个问题——例如，在连续域中应用 ReLU 可能会引入无法在输出中表示的任意高频。 </p> 
<p>一个自然的解决方案是通过将连续结果与理想的低通滤波器 Ψ_s 进行卷积来消除有害的高频成分。 然后，非线性的连续 representation 变为</p> 
<p class="img-center"><img alt="" height="27" src="https://images2.imgbox.com/ad/87/aEZBVLIG_o.png" width="341"></p> 
<p>而离散的对应物是（见图 2，right）</p> 
<p class="img-center"><img alt="" height="26" src="https://images2.imgbox.com/40/ef/rFXFnFtF_o.png" width="195"></p> 
<p class="img-center"><img alt="" height="23" src="https://images2.imgbox.com/bd/cf/rXL7UoQd_o.png" width="160"></p> 
<p>如果不临时进入连续 representation，则无法实现这种离散操作。 我们通过对信号进行上采样，在更高分辨率下应用非线性，然后再对其进行下采样来对此进行近似。 即使非线性仍然在离散域中执行，我们发现对于高质量的等变，仅临时增加 2 倍的分辨率就足够了。 对于旋转等变，我们必须在下采样步骤中使用径向对称插值滤波器 Φ°_s，如上所述。</p> 
<p>请注意，非线性是唯一能够在我们的公式中生成新频率的操作，并且我们可以通过在最终离散化操作之前应用截止频率低于 s/2 的重建滤波器来限制这些新频率的范围。 这使我们能够精确控制生成器网络的每一层引入了多少新信息（第 3.2 节）。</p> 
<h2 id="3.%20%E5%9C%A8%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%C2%A0">3. 在生成网络中的实际应用 </h2> 
<p><img alt="" height="349" src="https://images2.imgbox.com/1e/41/SgyyaRfx_o.png" width="913"></p> 
<p>我们现在将把上一节的理论思想应用到实践中，将成熟的 StyleGAN2 生成器转换为与平移和旋转完全等变。 我们将逐步介绍必要的更改，评估它们在图 3 中的影响。鉴别器在我们的实验中保持不变。</p> 
<p>StyleGAN2 生成器由两部分组成。</p> 
<ul><li>首先，一个映射网络将一个初始的、正态分布的隐编码转换为一个中间隐编码 w~W。</li><li>然后，一个合成网络 G 从一个学习到的 4x4x512 常数 Z_0 开始，并应用一个 N 层序列——由卷积、非线性、上采样和逐像素噪声组成——生成输出图像 Z_N = G(Z_0 ; w)。隐编码 w 控制 G 中卷积核的调制。这些层遵循严格的 2 倍上采样规划，其中在每个分辨率下执行两个层，并且在每次上采样后特征图的数量减半。 此外，StyleGAN2 采用跳跃连接（skip connections）、混合正则化（mixing regularization）和路径长度正则化（path length regularization）。</li></ul> 
<p>我们的目标是让 G 的每一层都对应于连续信号等变，以便所有更精细的细节与局部邻域的更粗糙特征一起变换。 如果成功，整个网络将变得类似等变。 换句话说，我们的目标是使合成网络的连续操作 g 等变，对应于应用在连续输入 z_0 的变换 t（平移和旋转）：g(t[z_0];w) = t[g(z_0;w)]。 为了评估各种架构变化和实际近似的影响，我们需要一种方法来衡量网络实现等变的程度。 对于平移等变，我们报告了两组图像之间以分贝 (dB) 为单位的峰值信噪比 (PSNR)，这是通过将合成网络的输入和输出平移一个随机量而获得的</p> 
<p><img alt="" height="45" src="https://images2.imgbox.com/c5/82/vadaNFUe_o.png" width="862"></p> 
<p>每对图像对应于 w 的不同随机选择，在它们相互有效的区域 V 内的整数像素位置 p 处被采样。颜色通道 c 被独立处理，并且生成图像的预期动态范围  -1 ... +1 给出 I_max = 2。操作 t_x 使用 2D 偏移量 x 实现空间转换，这里从整数偏移量的分布 X^2 中得出。 我们为旋转定义了一个类似的度量 EQ-R，旋转角度从 U(0° ，360°) 绘制。 附录 E 提供了实施细节，我们的随附视频强调了不同 dB 值的实际相关性。 </p> 
<h3 id="3.1%20%E5%82%85%E9%87%8C%E5%8F%B6%E7%89%B9%E5%BE%81%E5%92%8C%E5%9F%BA%E7%BA%BF%E7%AE%80%E5%8C%96%EF%BC%88%E9%85%8D%E7%BD%AE%20B%E2%80%93D%EF%BC%89">3.1 傅里叶特征和基线简化（配置 B–D）</h3> 
<p>为了促进输入 z_0 的精确连续平移和旋转，我们将 StyleGAN2 中学习的输入常数替换为傅立叶特征，这也具有自然定义空间无限的特征图的优势。 我们在环形频带 f_c = 2 内均匀采样频率，匹配原始 4x4 输入分辨率，并在训练过程中保持它们固定。 这种变化（图 3 左侧的配置 A 和 B）略微改进了 FID，而且至关重要的是，它允许我们计算等变度量，而无需近似算子 t。 这种基线架构远非等变的； 我们随附的视频显示，当输入特征从其原始位置平移或旋转时，输出图像会急剧恶化。</p> 
<p>接下来，我们删除了每像素噪声输入，因为它们与我们的自然变换层次结构的目标非常不一致，即每个特征的确切子像素位置完全继承自底层粗糙特征。 虽然此更改（配置 C）大约是 FID 中性的，但在单独考虑时它无法改进等变指标。 </p> 
<p>为了进一步简化设置，我们减少了 Karras 等人推荐的映射网络深度，并禁用混合正则化和路径长度正则化。 最后，我们还消除了输出跳过连接。 我们假设它们的好处主要与训练期间的梯度幅度动态有关，并在每次卷积之前使用简单的归一化更直接地解决潜在问题。 我们在训练期间跟踪所有像素和特征图的指数移动平均值 σ^2 = E[x^2]，并将特征图除以 (σ^2)^(1/2)。 在实践中，我们将卷积权重除以 (σ^2)^(1/2) 以提高效率。 这些更改（配置 D）将 FID 带回到原始 StyleGAN2 的水平，同时导致平移等变略有改善。</p> 
<h3 id="3.2%20%E7%94%B1%E8%BF%9E%E7%BB%AD%E8%A7%A3%E9%87%8A%E9%A9%B1%E5%8A%A8%E7%9A%84%E9%80%90%E6%AD%A5%E9%87%8D%E6%96%B0%E8%AE%BE%E8%AE%A1">3.2 由连续解释驱动的逐步重新设计</h3> 
<p><strong>边界和上采样（配置 E）。</strong>我们的理论假设特征图的空间范围是无限的，我们通过在目标画布周围保持固定大小的边距来近似，在每一层之后裁剪到这个扩展的画布。 这种显式扩展是必要的，因为已知边界填充会将绝对图像坐标泄漏到内部 representations 中。 实际上，我们发现 10 像素的边距就足够了，进一步增加对结果没有明显影响。</p> 
<p><img alt="" height="608" src="https://images2.imgbox.com/43/fb/hgR3SzC7_o.png" width="913"></p> 
<p>受我们理论模型的启发，我们用更接近理想低通滤波器的双线性 2 倍上采样滤波器代替。 我们使用具有相对较大的大小为 n = 6 的 Kaiser 窗的加窗 sinc 滤波器，这意味着每个输出像素在上采样中受到 6 个输入像素的影响，而每个输入像素在下采样中影响 6 个输出像素。 Kaiser 窗对于我们的目的来说是一个特别好的选择，因为它提供了对过渡带和衰减的明确控制（图 4a）。 在本节的其余部分，我们明确指定过渡带并使用 Kaiser 的原始公式（附录 C）计算剩余参数。 现在，我们选择采用临界采样并设置滤波器截止 fc = s/2，即恰好在带限处，过渡带半宽 f_h = (2^(1/2)-1)(s/2)。 回想一下，根据我们在第 2 节中的定义，采样率 s 等于画布的宽度（以像素为单位）。</p> 
<p>改进的边界处理和上采样（配置 E）导致更好的平移等变。 然而，FID 降低了 16%，可能是因为我们开始限制特征图可以包含的内容。 在进一步的消融中（图 3，右），较小的重采样滤波器 (n = 4) 会损害平移等变，而较大的滤波器 (n = 8) 主要会增加训练时间。</p> 
<p><strong>过滤非线性（配置 F）。</strong>对于某个放大因子 m，我们对非线性的理论处理要求在 m 倍上采样和 m 倍下采样之间包裹每个泄漏的 ReLU（或任何其他常用的非线性）。 我们进一步注意到，上采样和卷积的顺序可以通过信号的带宽限制来切换，从而允许我们将常规的 2 倍上采样和随后的与非线性相关的 m 倍上采样融合为单个 2m 倍上采样。 在实践中，我们发现 m = 2 就足够了（图 3，右），再次改进了 EQ-T（配置 F）。 使用当前深度学习框架的基本配置实现上采样-LReLU-下采样序列效率不高，因此我们实现了一个结合这些操作的自定义 CUDA 内核（附录 D）（图 4b），从而得出 10 倍更快的训练和可观的内存节省。</p> 
<p><strong>非临界采样（配置 G）。</strong>临界采样方案（其中滤波器截止恰好设置在带宽限制）是许多图像处理应用的理想选择，因为它在抗锯齿和保留高频细节之间取得了良好的平衡。 然而，我们的目标明显不同，因为混叠对生成器的等变非常不利。 虽然高频细节在输出图像中很重要，因此在最高分辨率层中也很重要，但在较早的层中就不那么重要了，因为它们的确切分辨率一开始有些随意。</p> 
<p>为了抑制混叠，我们可以简单地将截止频率降低到 f_c = s/2 - f_h，这样可以确保所有混叠频率（高于 s/2）都在阻带内。例如，降低图 4a 中蓝色滤波器的截止频率，将其频率响应向左移动，以便最坏情况下的混叠频率衰减从 6 dB 提高到 40 dB。 这种过采样可以看作是更好的抗锯齿的计算成本，因为我们现在使用相同数量的样本来表达比以前更慢变化的信号。 在实践中，我们选择降低除最高分辨率层之外的所有层的 f_c，因为最终生成器必须能够生成清晰的图像以匹配训练数据。由于信号现在包含较少的空间信息，我们将用于确定特征图数量的启发式修改为与 f_c 而不是采样率 s 成反比。 这些更改（配置 G）进一步改善了平移等变，并将 FID 推至低于原始 StyleGAN2 的水平。</p> 
<p><strong>变换后的傅立叶特征（配置 H）</strong>。等变生成器层非常适合对未对齐和任意方向的数据集进行建模，因为引入中间特征 z_i 的任何几何变换都将直接转移到最终图像 z_N。 然而，由于层本身引入全局变换的能力有限，输入特征 z_0 在定义 z_N 的全局方向方面起着至关重要的作用。 为了让每个图像的方向都不同，生成器应该能够根据 w 变换 z0。 这促使我们引入学习仿射层，为输入傅立叶特征输出全局平移和旋转参数（图 4b 和附录 F）。 该层被初始化以执行身份转换，但随着时间的推移学会在有益时使用该机制；在配置 H 中，这略微提高了 FID。</p> 
<p><strong>灵活的层规范（配置 T）。</strong>我们的更改大大提高了等变质量，但一些可见的伪影仍然存在，如我们随附的视频所展示的那样。 仔细检查后发现，我们过滤器的衰减（如配置 G 所定义）对于最低分辨率层仍然不足。 这些层往往在其带限附近具有丰富的频率内容，这需要极强的衰减才能完全消除混叠。</p> 
<p>到目前为止，我们已经使用了 StyleGAN2 的严格采样率级数（progression），以及滤波器截止 fc 和半宽 fh 的简单选择，但事实并非如此； 我们可以在每一层的基础上自由地专门化这些参数。 特别是，我们希望 fh 在最低分辨率层中较高，以最大化阻带中的衰减，但在最高分辨率层中较低，以允许匹配训练数据的高频细节。</p> 
<p>图 4c 说明了 14 层生成器中滤波器参数的示例进展，最后有两个临界采样的全分辨率层。 截止频率从第一层中的 fc = 2 几何增长到第一个临界采样层中的 fc = s_N / 2。 我们选择可接受的最小阻带频率开始于</p> 
<p class="img-center"><img alt="" height="30" src="https://images2.imgbox.com/b4/ba/VIu7y60D_o.png" width="105"></p> 
<p>它呈几何增长，但比截止频率慢。 在我们的测试中，最后一层的阻带目标是 f_t = f_c·2^(0.3)，但进展在第一个关键采样层停止。 接下来，我们为每一层设置采样率 s，使其适应高达 f_t 的频率，在不超过输出分辨率的情况下四舍五入到下一个 2 的幂。 最后，为了最大化混叠频率的衰减，我们将过渡带半宽设置为</p> 
<p class="img-center"><img alt="" height="28" src="https://images2.imgbox.com/0e/18/ZFTvVMgM_o.png" width="231"></p> 
<p>即，让其在采样率的限制内尽可能宽，但至少宽度足以达到 ft。由此产生的改进取决于 f_t 和 s / 2 之间留下多少松弛； 作为一个极端的例子，第一层阻带衰减使用该方案从 42 dB 提高到 480 dB。</p> 
<p>新的层规范再次改进了平移等变性（配置 T），消除了剩余的伪影。 进一步的消融（图 3，右）表明 f_t,0 提供了一种用训练速度换取等变质量的有效方法。 请注意，层数现在是一个自由参数，不直接取决于输出分辨率。 事实上，我们发现 N 的固定选择在多个输出分辨率下始终有效，并使其他超参数（如学习率）的行为更具可预测性。 在本文的其余部分，我们使用 N = 14。</p> 
<p><strong>旋转等变（配置 R）</strong>。我们获得了具有两个变化的网络的旋转等变版本。 首先，我们在所有层上用 1x1 替换 3x3 卷积，并通过加倍特征图的数量来补偿减少的容量。 在此配置中，只有上采样和下采样操作在像素之间传播信息。 其次，我们将基于 sinc 的下采样滤波器替换为我们使用相同的 Kaiser 方案构建的基于径向对称 jinc 的下采样滤波器（附录 C）。 我们对除两个关键采样层之外的所有层都这样做，在这些层中匹配训练数据的潜在非径向谱很重要。 这些更改（配置 R）在不损害 FID 的情况下改进了 EQ-R，即使每一层的可训练参数减少了 56%。</p> 
<p>我们还在此配置中采用了额外的稳定技巧。 在训练的早期，我们使用高斯滤波器模糊鉴别器看到的所有图像。 我们从 σ= 10 的像素开始，在前 200k 个图像中将其逐渐变为零。 这可以防止鉴别器在早期过分关注高频。如果没有这个技巧，配置 R 很容易出现早期崩溃，因为生成器有时会学习以较小的延迟产生高频，从而使鉴别器的任务变得微不足道。</p> 
<h2 id="4.%20%E7%BB%93%E6%9E%9C">4. 结果</h2> 
<p><img alt="" height="441" src="https://images2.imgbox.com/8a/34/ECC5SNhm_o.png" width="912"></p> 
<p>图 5 给出了使用 StyleGAN2 以及我们的无失真 StyleGAN3-T 和 StyleGAN3-R 生成器的六个数据集的结果。 除了标准的 FFHQ 和 METFACES 之外，我们还创建了它们的未对齐版本。 我们还创建了一个经过适当重采样的 AFHQ 版本，并收集了一个新的 BEACHES 数据集。 附录 B 详细描述了数据集。 结果表明，我们的 FID 与 StyleGAN2 相比仍然具有竞争力。 StyleGAN3-T 和 StyleGAN3-R 在 FID 方面的表现同样出色，并且都表现出非常高水平的平移等变性。 正如预期的那样，只有后者提供旋转等变。 在 FFHQ (1024x1024) 中，三个生成器的参数分别为 30.0M、22.3M 和 15.8M，而训练时间分别为 1106、1576 (+42%) 和 2248 (+103%) GPU 小时。 我们随附的视频显示了与 StyleGAN2 的并排比较，直观地证明纹理粘连问题已得到解决。 由此产生的运动更加自然，更好地维持了正在成像的连贯 3D 场景的错觉。</p> 
<p><strong>消融和比较。</strong>在 3.1 节中，我们禁用了许多 StyleGAN2 功能。 现在，我们可以将它们一个接一个地打开，以衡量它们对生成器的影响（图 5，右）。</p> 
<ul><li>虽然可以重新启用混合正则化（mixing regularization）而不会产生任何不良影响，但我们还发现即使没有这种显式正则化（附录 A）也可以非常可靠地混合样式。</li><li>重新启用噪声输入或依赖 StyleGAN2 的原始层规范会显着损害等变性，使用固定傅立叶特征或重新启用路径长度正则化（path length regularization）会损害 FID。</li><li>路径长度正则化原则上与平移等变不一致，因为它会惩罚隐空间移动时的图像变化，从而鼓励纹理粘附。我们怀疑等变的违反直觉的改进可能来自稍微模糊的生成图像，代价是 FID 较差。</li></ul> 
<p>在缩放测试中，我们尝试改变特征图的数量，观察到等变保持在较高水平，但当容量减半时 FID 会受到很大影响。 容量加倍可提高 FID 方面的结果质量，但代价是将近 4 倍的训练时间。 最后，我们考虑加窗的 Kaiser 过滤器的替代方案。 Lanczos 在 FID 方面具有竞争力，但作为可分离的过滤器，它特别损害了旋转等变。 高斯（Gaussian）导致明显更差的 FID。</p> 
<p>我们将 StyleGAN3-R 与替代方案进行比较，其中旋转部分是在我们的 StyleGAN3-T 之上使用 p4 对称的 G-CNN 实现的。 这种方法仅提供适度的旋转等变，同时训练速度较慢。 可控滤波器理论上可以提供有竞争力的 EQ-R，但内存和训练时间要求证明对于这种规模的生成器网络是不可行的。 </p> 
<p>附录 A 展示了生成图像的光谱特性与训练数据非常匹配，与几个早期的架构相比具有优势。</p> 
<p><img alt="" height="547" src="https://images2.imgbox.com/82/98/RMtMpBYL_o.png" width="1193"></p> 
<p><strong>内部 representations。</strong>图 6 可视化了网络的典型内部 representations。 虽然在 StyleGAN2 中，所有特征图似乎都对信号幅度进行编码，但在我们的网络中，一些特征图扮演着不同的角色，而是对相位信息进行编码。 显然，当网络在表面上合成细节时，这是需要的； 它需要发明一个坐标系。 在 StyleGAN3-R 中，出现的位置编码模式似乎更加明确。 我们相信，允许在物体表面精确定位的坐标系的存在将在各种应用中证明是有用的，包括高级图像和视频编辑。</p> 
<h2 id="5.%20%E5%B1%80%E9%99%90%E6%80%A7%E3%80%81%E8%AE%A8%E8%AE%BA%E5%92%8C%E6%9C%AA%E6%9D%A5%E5%B7%A5%E4%BD%9C">5. 局限性、讨论和未来工作</h2> 
<p>在这项工作中，我们只修改了生成器，但似乎也可以通过使鉴别器等变来获得更多好处。 例如，在我们的 FFHQ 结果中，当头部转动时牙齿没有正确移动，我们怀疑这是由于鉴别器意外地更喜欢在某些像素位置看到门牙造成的。 并行工作已经确定别名对这种泛化是有害的。</p> 
<p>我们的无失真生成器架构包含关于训练数据性质的隐含假设，违反这些假设可能会导致训练困难。 让我们考虑一个例子。假设我们有黑白卡通作为训练数据，我们（错误地）使用点采样进行预处理，导致训练图像几乎所有像素都是黑色或白色，并且边缘呈锯齿状。 这种严重失真训练数据通常对 GAN 来说很难，但它尤其与等变不一致：一方面，我们要求生成器能够按子像素数量平滑地转换输出，但另一方面 ，边缘仍然必须保持锯齿状并且像素只有黑色/白色，以保持对训练数据的忠实。 同样的问题也可能出现在训练图像、低质量 JPEG 或复古像素图形的信箱中，其中锯齿状的阶梯边缘是美学的定义特征。 在这种情况下，生成器了解像素网格可能是有益的。</p> 
<p>将来，以与分层合成一致的方式重新引入噪声输入（随机变化）可能会很有趣。 更好的路径长度正则化会鼓励相邻特征一起移动，而不是阻止它们移动。 尝试将我们的方法扩展到对应于等变的缩放，各向异性缩放，甚至任意同胚可能是有益的。 最后，众所周知，抗失真应该在色调映射之前完成。 到目前为止，所有的 GAN——包括我们的——都在 sRGB 色彩空间中运行（在色调映射之后）。</p> 
<p>生成器中间的 attention 层可能会通过暂时切换到更高分辨率来类似于非线性处理，尽管 attention 层的时间复杂性可能使这在实践中有些挑战。 最近以标记化转换器（例如 VQGAN）开始的基于attention 的 GAN 可能与等变不一致。 是否有可能使它们等变是一个重要的悬而未决的问题。</p> 
<p>（图像生成）GAN 的潜在负面社会影响包括多种形式的虚假信息，从社交媒体中的假肖像到世界领导人的宣传视频。我们的贡献消除了视频中的某些特征伪影，可能使它们更具说服力或更具欺骗性，具体取决于应用程序。 可行的解决方案包括模型水印以及主要社交媒体网站中的大规模真实性评估。 整个项目在内部的 NVIDIA V100 集群上消耗了 92 个 GPU 年和 225 兆瓦时的电力。 新的 StyleGAN3 生成器的训练或使用成本仅略高于 StyleGAN2。</p> 
<p></p> 
<h2 id="%E5%8F%82%E8%80%83">参考</h2> 
<p>Karras T, Aittala M, Laine S, et al. Alias-free generative adversarial networks[J]. Advances in Neural Information Processing Systems, 2021, 34: 852-863.</p> 
<h2 id="S.%20%E6%80%BB%E7%BB%93">S. 总结</h2> 
<h3 id="S.1%20%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3">S.1 核心思想</h3> 
<p>在现实世界中，不同尺度的细节倾向于分层变换。 例如，移动头部会导致鼻子移动，进而移动其上的皮肤毛孔。 对于典型的 GAN 生成器：粗特征主要控制更精细特征的存在，而不是它们的精确位置。 相反，许多细节似乎都固定在像素坐标中。从而造成像素混叠 / 图像失真。</p> 
<p>像素混叠 / 图像失真的两个来源：</p> 
<ul><li>由非理想的上采样滤波器（例如最近邻、双线性的或跨步的卷积）带有的拖尾导致的像素混叠</li><li>非线性的逐点应用，例如 ReLU 或 swish。连续域中应用 ReLU 可能会引入无法在输出中表示的任意高频。</li></ul> 
<p><img alt="" height="314" src="https://images2.imgbox.com/97/81/fyVJiTfW_o.png" width="911"></p> 
<p>解决办法将：参考 Nyquist–Shannon 采样定理消除失真的办法，把对图像（连续域）的操作（生成图像相对于原始图像的平移或旋转）转移到频域（离散域）中操作，消除所有位置参考源，使得精细特征能随着粗特征的变换而改变（等变）。</p> 
<h3 id="S.2%20%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84">S.2 网络结构</h3> 
<p class="img-center"><img alt="" height="510" src="https://images2.imgbox.com/db/a8/p1wIhPvW_o.png" width="559"></p> 
<p>StyleGAN3 的结构如上图所示，生成网络的输入是傅里叶特征。</p> 
<p>上采样，把离散采样与 0 交织，然后与离散滤波器卷积。</p> 
<p>下采样，对连续  representation 进行低通滤波以去除高于输出带宽限制的频率，以便信号可以忠实的重建。</p> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8606b1fdbe8b3796873998bcb7011d4b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Ubuntu虚拟机安装常用软件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4d85e494419a365bcbe5b87b9c2d5692/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Screencasting/Mirroring an Android Device Screen onto your Desktop under Ubuntu/Linux Mint</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>