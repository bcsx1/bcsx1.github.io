<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习基础学习-1x1卷积核的作用（CNN中） - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习基础学习-1x1卷积核的作用（CNN中）" />
<meta property="og:description" content="前言 这里就不赘述卷积神经网络相关内容了，直接通过博主看的一些资料，自己进行了一些整合，大佬绕道。
对于1x1卷积核的作用主要可以归纳为以下几点
增加网络深度（增加非线性映射次数）升维/降维跨通道的信息交互减少卷积核参数（简化模型） 1、普通卷积 这里首先展示了一个我们最常见的卷积方式（通道数为1），一个5x5的图怕，通过一个3x3的卷积核提取特征得到一个3x3的结果。如果这里的卷积核是1x1的，那么效果如下
2、1x1卷积核作用 2.1 增加网络深度（增加非线性映射次数） 首先直接从网络深度来理解，1x1 的卷积核虽小，但也是卷积核，加 1 层卷积，网络深度自然会增加。
1x1卷积核，可以在保持feature map尺度不变的（即不损失分辨率）的前提下大幅增加非线性特性（利用后接的非线性激活函数），把网络做的很深。并且1x1卷积核的卷积过程相当于全连接的计算过程，通过加入非线性激活函数，可以增加网络的非线性，使得网络可以表达更复杂的特征。
具体来说，引用一下「frank909」博客的内容：
其实问题往下挖掘，应该是增加网络深度有什么好处？为什么非要用 1x1 来增加深度呢？其它的不可以吗？
其实，这涉及到感受野的问题，我们知道卷积核越大，它生成的 featuremap 上单个节点的感受野就越大，随着网络深度的增加，越靠后的 featuremap 上的节点感受野也越大。因此特征也越来越抽象。
但有的时候，我们想在不增加感受野的情况下，让网络加深，为的就是引入更多的非线性。
而 1x1 卷积核，恰巧可以办到。
我们知道，卷积后生成图片的尺寸受卷积核的大小和跨度影响，但如果卷积核是 1x1 ，跨度也是 1，那么生成后的图像大小就并没有变化。
但通常一个卷积过程包括一个激活函数，比如 Sigmoid 和 Relu。
所以，在输入不发生尺寸的变化下，却引入了更多的非线性，这将增强神经网络的表达能力
2.2、升维/降维 其实这里的升维、降维具体指的是通道数的变化，当我们确定了卷积核尺寸后，我们的height、width都不变，那么这里的维度具体指的就是channels。我们通过改变卷积核的数量来改变卷积后特征图的通道channels来实现升维、降维的效果。这样可以将原本的数据量进行增加或者减少
下面分别举两个例子就能明显看到效果
2.2.1 升维 2.2.2 降维 其实很明显的能看出来，无论是升维还是降维，我们都是通过改变卷积核的数量实现的，卷积后的特征图的通道数channels同卷积核的数量保持一致，这里其实不仅仅是1x1卷积核能实现这个功能，其他尺寸的卷积核也可以，那么我们为什么要选用1x1卷积核呢
2.2.3 使用1x1卷积核升维/降维的原因 当我们仅仅只是想要改变通道数的情况下，1x1卷积核是最小的选择，因为大于1x1的卷积核无疑会增加计算的参数量，内存也会随之增大，所以只想单纯的去提升或者降低特征图的通道，选用1x1卷积核最为合适， 1x1卷积核会使用更少的权重参数数量。
2.3 跨通道的信息交互 1x1卷积核只有一个参数，当它作用在多通道的feature map上时，相当于不同通道上的一个线性组合，实际上就是加起来再乘以一个系数，但是这样输出的feature map就是多个通道的整合信息了，能够使网络提取的特征更加丰富。
使用1x1卷积核，实现降维和升维的操作其实就是 channel 间信息的线性组合变化。
比如：在尺寸 3x3，64通道个数的卷积核后面添加一个尺寸1x1，28通道个数的卷积核，就变成了尺寸3x3，28尺寸的卷积核。 原来的64个通道就可以理解为跨通道线性组合变成了28通道，这就是通道间的信息交互。
注意：只是在通道维度上做线性组合，W和H上是共享权值的滑动窗口。
2.4 减少卷积核参数（简化模型） 下面仅以计算权重数为例子进行计算（不添加bias）
2.4.1 一层卷积添加1x1卷积核，分别计算权重数 （1）不使用1x1卷积核
（2）使用1x1卷积核
可以看到不使用1x1的卷积核是使用卷积核的10倍左右" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/91b7e4cf4c6b0b959baa226cd04e24ac/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-23T11:28:20+08:00" />
<meta property="article:modified_time" content="2022-11-23T11:28:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习基础学习-1x1卷积核的作用（CNN中）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>前言</h2> 
<p>这里就不赘述卷积神经网络相关内容了，直接通过博主看的一些资料，自己进行了一些整合，大佬绕道。<br> 对于1x1卷积核的作用主要可以归纳为以下几点</p> 
<ol><li>增加网络深度（增加非线性映射次数）</li><li>升维/降维</li><li>跨通道的信息交互</li><li>减少卷积核参数（简化模型）</li></ol> 
<p><img src="https://images2.imgbox.com/de/08/rX446YMP_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="1_11"></a>1、普通卷积</h2> 
<p><img src="https://images2.imgbox.com/80/67/3wil1QBa_o.png" alt="在这里插入图片描述"></p> 
<p>这里首先展示了一个我们最常见的卷积方式（通道数为1），一个5x5的图怕，通过一个3x3的卷积核提取特征得到一个3x3的结果。如果这里的卷积核是1x1的，那么效果如下<br> <img src="https://images2.imgbox.com/22/0b/uTrYqtai_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="21x1_16"></a>2、1x1卷积核作用</h2> 
<h3><a id="21__17"></a>2.1 增加网络深度（增加非线性映射次数）</h3> 
<p>首先直接从网络深度来理解，1x1 的卷积核虽小，但也是卷积核，加 1 层卷积，网络深度自然会增加。<br> 1x1卷积核，可以在保持feature map尺度不变的（即不损失分辨率）的前提下大幅增加非线性特性（利用后接的非线性激活函数），把网络做的很深。并且1x1卷积核的卷积过程相当于全连接的计算过程，通过加入非线性激活函数，可以增加网络的非线性，使得网络可以表达更复杂的特征。<br> 具体来说，引用一下「frank909」博客的内容：<br> 其实问题往下挖掘，应该是增加网络深度有什么好处？为什么非要用 1x1 来增加深度呢？其它的不可以吗？</p> 
<p>其实，这涉及到感受野的问题，我们知道卷积核越大，它生成的 featuremap 上单个节点的感受野就越大，随着网络深度的增加，越靠后的 featuremap 上的节点感受野也越大。因此特征也越来越抽象。</p> 
<p>但有的时候，我们想在不增加感受野的情况下，让网络加深，为的就是引入更多的非线性。</p> 
<p>而 1x1 卷积核，恰巧可以办到。</p> 
<p>我们知道，卷积后生成图片的尺寸受卷积核的大小和跨度影响，但如果卷积核是 1x1 ，跨度也是 1，那么生成后的图像大小就并没有变化。</p> 
<p>但通常一个卷积过程包括一个激活函数，比如 Sigmoid 和 Relu。</p> 
<p>所以，在输入不发生尺寸的变化下，却引入了更多的非线性，这将增强神经网络的表达能力</p> 
<h3><a id="22_34"></a>2.2、升维/降维</h3> 
<p>其实这里的升维、降维具体指的是通道数的变化，当我们确定了卷积核尺寸后，我们的height、width都不变，那么这里的维度具体指的就是channels。我们通过改变卷积核的数量来改变卷积后特征图的通道channels来实现升维、降维的效果。这样可以将原本的数据量进行增加或者减少<br> 下面分别举两个例子就能明显看到效果<br> <img src="https://images2.imgbox.com/cb/dc/5R8dAwWd_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="221__39"></a>2.2.1 升维</h4> 
<p><img src="https://images2.imgbox.com/81/74/xuyoQHHD_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="222__41"></a>2.2.2 降维</h4> 
<p><img src="https://images2.imgbox.com/39/4f/j458W7iO_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/3e/60/pIsNrkbV_o.png" alt="在这里插入图片描述"></p> 
<p>其实很明显的能看出来，无论是升维还是降维，我们都是通过改变卷积核的数量实现的，卷积后的特征图的通道数channels同卷积核的数量保持一致，这里其实不仅仅是1x1卷积核能实现这个功能，其他尺寸的卷积核也可以，那么我们为什么要选用1x1卷积核呢</p> 
<h4><a id="223_1x1_47"></a>2.2.3 使用1x1卷积核升维/降维的原因</h4> 
<p>当我们仅仅只是想要改变通道数的情况下，1x1卷积核是最小的选择，因为大于1x1的卷积核无疑会<strong>增加计算的参数量</strong>，内存也会随之增大，所以只想单纯的去提升或者降低特征图的通道，选用1x1卷积核最为合适， <strong>1x1卷积核会使用更少的权重参数数量</strong>。</p> 
<h3><a id="23__49"></a>2.3 跨通道的信息交互</h3> 
<p>1x1卷积核只有一个参数，当它作用在多通道的feature map上时，相当于不同通道上的一个线性组合，实际上就是加起来再乘以一个系数，但是这样输出的feature map就是多个通道的整合信息了，能够使网络提取的特征更加丰富。</p> 
<p>使用1x1卷积核，实现降维和升维的操作其实就是 channel 间信息的线性组合变化。</p> 
<p>比如：在尺寸 3x3，64通道个数的卷积核后面添加一个尺寸1x1，28通道个数的卷积核，就变成了尺寸3x3，28尺寸的卷积核。 原来的64个通道就可以理解为跨通道线性组合变成了28通道，这就是通道间的信息交互。</p> 
<p>注意：只是在通道维度上做线性组合，W和H上是共享权值的滑动窗口。</p> 
<h3><a id="24__58"></a>2.4 减少卷积核参数（简化模型）</h3> 
<p>下面仅以计算权重数为例子进行计算（不添加bias）</p> 
<h4><a id="241_1x1_60"></a>2.4.1 一层卷积添加1x1卷积核，分别计算权重数</h4> 
<p>（1）不使用1x1卷积核<br> <img src="https://images2.imgbox.com/21/47/YzsPaE2U_o.png" alt="在这里插入图片描述"><br> （2）使用1x1卷积核<br> <img src="https://images2.imgbox.com/ae/a0/MazmimbF_o.png" alt="在这里插入图片描述"><br> 可以看到不使用1x1的卷积核是使用卷积核的10倍左右</p> 
<h4><a id="242_GoogLeNet3a_66"></a>2.4.2 GoogLeNet的3a模块</h4> 
<p>（1）不使用1x1卷积核<br> <img src="https://images2.imgbox.com/19/63/mmMxbCw8_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/91/0f/lXXZ2qgc_o.png" alt="在这里插入图片描述"></p> 
<p>权重数：192 × (1×1×64) +192 × (3×3×128) + 192 × (5×5×32) = 387072<br> 这个网络的说明如下<br> （1）采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合；<br> （2）之所以卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了；<br> （3）文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了。<br> （4）网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。<br> （2）使用1x1卷积核</p> 
<p><img src="https://images2.imgbox.com/2f/72/6vGZnEUW_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b9/0b/HHvtHi8m_o.png" alt="在这里插入图片描述"></p> 
<p>权重数：192 × (1×1×64) +（192×1×1×96+ 96 × 3×3×128）+（192×1×1×16+16×5×5×32）= 157184</p> 
<p>不使用1x1的卷积核是使用1x1卷积核的权重数2倍</p> 
<h4><a id="243_ResNet_88"></a>2.4.3 ResNet</h4> 
<p>ResNet同样也利用了1×1卷积，并且是在3×3卷积层的前后都使用了，不仅进行了降维，还进行了升维，参数数量进一步减少<br> <img src="https://images2.imgbox.com/3e/22/G81v0Cep_o.png" alt="在这里插入图片描述"><br> 其中右图又称为”bottleneck design”，目的一目了然，就是为了降低参数的数目，第一个1x1的卷积把256维channel降到64维，然后在最后通过1x1卷积恢复，<br> 当我们的特征图通道数为256时，变得很大，出现的问题是计算复杂度会很高，这里做法是通过1×1卷积投影映射回64维，再做一个3×3通道数不变的卷积，然后再通过1×1卷积投影回去256维，因为输入是256维，输出要匹配上，这样设计之后复杂度就跟左图差不多了。<br> 左图参数量：64 x ( 3 x 3 x 64)+64 x ( 3 x 3 x 64 ) = 73728<br> 当通道数增加到 256时：256 x ( 3 x 3 x 256 ) + 256 x ( 3 x 3 x 256 ) = 1179648<br> 右图参数量：256 x ( 1 x 1 x 64) + 64 x ( 3 x 3 x 64 ) + 256 x ( 1 x 1 x 64) = 69632</p> 
<p>当通道数增加为256时，可以发现添加两层1x1的卷积的参数量和64为原有残差块参数量差不多。</p> 
<p>对于常规ResNet，可以用于34层或者更少的网络中，对于Bottleneck Design的ResNet通常用于更深的网络中，目的是减少计算和参数量（实用目的）</p> 
<h2><a id="_101"></a>参考资料</h2> 
<p><a href="https://zhuanlan.zhihu.com/p/40050371?ivk_sa=1024320u" rel="nofollow">一文读懂卷积神经网络中的1x1卷积核</a><br> <a href="https://blog.csdn.net/nefetaria/article/details/107977597">1x1卷积核的作用</a><br> <a href="https://blog.csdn.net/briblue/article/details/83151475">【深度学习】CNN 中 1x1 卷积核的作用</a><br> <a href="https://blog.csdn.net/qq_27278957">深度学习 1x1卷积核的作用</a><br> <a href="https://blog.csdn.net/Keep_Trying_Go/article/details/123027344">1x1卷积的作用</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7b79130eddc3fa3c6b6f0a6098e9389a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【mybatis】第二篇：@Select注解中加入字段判断</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3f8e9e9b42127fb06cead78a85f23c22/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">PyAutoGUI——让所有GUI都自动化</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>