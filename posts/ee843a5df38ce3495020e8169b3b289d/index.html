<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[论文阅读RGBD-SOD][2022_TCSVT_MoADNet][轻量化] - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[论文阅读RGBD-SOD][2022_TCSVT_MoADNet][轻量化]" />
<meta property="og:description" content="MoADNet: Mobile Asymmetric Dual-Stream Networks for Real-Time and Lightweight RGB-D Salient Object Detection paper：https://ieeexplore.ieee.org/abstract/document/9789193
动机 尽管已有许多优秀的RGB-D SOD技术被提出，但它们大多关注性能增强，而缺乏对移动设备上实际部署的关注。
解决方案 在本文中，我们提出了移动非对称双流网络(MoADNet)，用于实时和轻量级RGB-D SOD。
1.首先，受到RGB和深度模式之间固有差异的启发，我们观察到深度图可以用比RGB图像更少的通道表示。因此，我们设计了基于MobileNetV3的非对称双流编码器。
补充：这句话的意思是，深度图像可以使用比RGB图像更少的通道来表示。这是因为深度图像与RGB图像不同，不需要表示颜色信息，而只需表示距离信息。RGB图像包含红色、绿色和蓝色三个通道，每个通道都包含一个像素点的颜色信息。而在深度图像中，每个像素点代表的是距离摄像头的距离值，因此只需要一个通道就可以表示。这也就意味着，相对于RGB图像，深度图像可以用更少的数据来表示，从而减少计算和存储开销。
疑问？？这种不对称是怎么设计的？动机是什么？
在后文提到：前人使用对称双流网络从RGB图像和深度图中提取特征。然而，这两种模式传达了不同的信息。RGB图像包含丰富的颜色和纹理特征，深度图提供空间位置和粗略形状。这两种模式之间的内在差异启发了我们开发非对称双流网络来进行特征提取。
RGB：MobileNetV3-Large，Depth：MobileNetV3-Small
2.其次，我们开发了一种倒置瓶颈跨模态融合(IBCMF)模块来融合多模态特征，该模块采用倒置瓶颈结构来补偿轻量化主干中的信息丢失。
3.第三，我们提出了自适应atrous空间金字塔(A2SP)模块来加速推理，并通过适当选择解码器中的多尺度特征来保持推理的性能。（这个模块可以理解为上下文提取模块，用于更好的表达特征的表示）
IBCMF 1.为什么设计这个模块？
轻量级主干提取代表性特征的能力低。
2.怎么设计的？
受[47]的启发，采用channel expansion 来补偿轻量级骨干中的信息损失。我们首先在低级阶段扩大融合前的channel数量。随后，减少这些channel，以促进逐元素操作。由于该过程与反向瓶颈结构[47]具有相同的精髓，我们将此组件命名为反向瓶颈跨模态融合（ IBCMF)模块。
1）Channel Alignment: 由于我们的目标是设计非对称双流编码器，不同支路的输出可能有不一致的形状。我们使用Pointwise Convolution Conv1×1(·)使RGB和深度流的输出具有相同的通道尺寸，
补充：Pointwise Convolution也被称为 1×1 卷积，是指卷积核大小为 1×1 的卷积操作。Pointwise Convolution 是一种非常轻量级的卷积操作，其本质上就是一种线性变换，可以有效地将通道之间的信息进行整合和变换。
与传统卷积不同，Pointwise Convolution 在空间上不进行滑动窗口卷积，而是在通道维度上进行乘加运算。因此，它可以非常高效地实现通道数的变换和压缩。同时，由于 Pointwise Convolution 的计算量较小，其计算速度也比较快，因此常常被用于轻量化网络设计中。
Pointwise Convolution 主要应用在两个方面：特征融合和特征变换。
具体来说：
特征融合：在深度学习中，我们经常需要将不同尺度的特征进行融合，这时可以使用 Pointwise Convolution 实现通道数的增加或者减少，从而实现特征融合。
特征变换：有时候我们需要对特征进行维度变换，例如将一个高-dimensional 的特征张量映射到 low-dimensional 的嵌入空间中。此时可以使用 Pointwise Convolution 实现通道数的变换，然后将变换得到的特征进行池化或者全局平均池化，从而得到 low-dimensional 的嵌入特征。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/ee843a5df38ce3495020e8169b3b289d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-11T16:36:04+08:00" />
<meta property="article:modified_time" content="2023-04-11T16:36:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[论文阅读RGBD-SOD][2022_TCSVT_MoADNet][轻量化]</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>MoADNet: Mobile Asymmetric Dual-Stream Networks for Real-Time and Lightweight RGB-D Salient Object Detection </h2> 
<p>paper：<a href="https://ieeexplore.ieee.org/abstract/document/9789193" rel="nofollow" title="https://ieeexplore.ieee.org/abstract/document/9789193">https://ieeexplore.ieee.org/abstract/document/9789193</a></p> 
<h2><strong>动机</strong></h2> 
<p>尽管已有许多优秀的RGB-D SOD技术被提出，但它们大多关注性能增强，而缺乏对移动设备上实际部署的关注。</p> 
<h2>解决方案</h2> 
<p>在本文中，我们提出了移动非对称双流网络(MoADNet)，用于实时和轻量级RGB-D SOD。</p> 
<p>1.首先，受到RGB和深度模式之间固有差异的启发，<span style="color:#fe2c24;">我们观察到深度图可以用比RGB图像更少的通道表示</span>。因此，我们设计了基于<span style="background-color:#ffd900;">MobileNetV3</span>的<span style="background-color:#a2e043;">非对称双流编码器</span>。</p> 
<blockquote> 
 <p><span style="background-color:#a2e043;">补充</span>：这句话的意思是，深度图像可以使用比RGB图像更少的通道来表示。这是因为深度图像与RGB图像不同，不需要表示颜色信息，而只需表示距离信息。RGB图像包含红色、绿色和蓝色三个通道，每个通道都包含一个像素点的颜色信息。而在深度图像中，每个像素点代表的是距离摄像头的距离值，因此只需要一个通道就可以表示。这也就意味着，相对于RGB图像，深度图像可以用更少的数据来表示，从而减少计算和存储开销。</p> 
</blockquote> 
<blockquote> 
 <p><span style="background-color:#a2e043;">疑问？？这种不对称是怎么设计的？动机是什么？</span></p> 
 <p>在后文提到：前人使用对称双流网络从RGB图像和深度图中提取特征。然而，这两种模式传达了不同的信息。RGB图像包含丰富的颜色和纹理特征，深度图提供空间位置和粗略形状。这两种模式之间的内在差异启发了我们开发非对称双流网络来进行特征提取。</p> 
 <p>RGB：MobileNetV3-Large，Depth：MobileNetV3-Small</p> 
</blockquote> 
<p>2.其次，我们开发了一种<span style="background-color:#ffd900;">倒置瓶颈跨模态融合(IBCMF)模块</span>来融合多模态特征，该模块采用倒置瓶颈结构来<span style="background-color:#ffd900;">补偿轻量化主干中的信息丢失</span>。</p> 
<p>3.第三，我们提出了<span style="background-color:#ffd900;">自适应atrous空间金字塔(A2SP)模块</span>来加速推理，并通过适当选择解码器中的多尺度特征来保持推理的性能。（这个模块可以理解为上下文提取模块，用于更好的表达特征的表示）</p> 
<p><img alt="" height="544" src="https://images2.imgbox.com/f5/01/ECD1kzkz_o.png" width="930"></p> 
<h3> IBCMF<img alt="" height="407" src="https://images2.imgbox.com/18/45/xhpfsAl1_o.png" width="1176"></h3> 
<blockquote> 
 <p>1.为什么设计这个模块？</p> 
 <p>        轻量级主干提取代表性特征的能力低。</p> 
 <p>2.怎么设计的？</p> 
 <p>        受[47]的启发，采用channel expansion 来补偿轻量级骨干中的信息损失。我们首先在低级阶段扩大融合前的channel数量。随后，减少这些channel，以促进逐元素操作。由于该过程与反向瓶颈结构[47]具有相同的精髓，我们将此组件命名为<strong>反向瓶颈跨模态融合（ IBCMF)</strong>模块。</p> 
</blockquote> 
<p><strong>1）Channel Alignment:</strong> 由于我们的目标是设计非对称双流编码器，不同支路的输出可能有不一致的形状。我们使用Pointwise Convolution Conv1×1(·)使RGB和深度流的输出具有相同的通道尺寸，</p> 
<p class="img-center"><img alt="" height="63" src="https://images2.imgbox.com/ff/35/W8iQw9fu_o.png" width="387"></p> 
<p></p> 
<blockquote> 
 <p><span style="background-color:#a2e043;">补充</span>：Pointwise Convolution也被称为 1×1 卷积，是指卷积核大小为 1×1 的卷积操作。Pointwise Convolution 是一种非常轻量级的卷积操作，其本质上就是一种线性变换，可以有效地将通道之间的信息进行整合和变换。</p> 
 <p>与传统卷积不同，Pointwise Convolution 在空间上不进行滑动窗口卷积，而是在通道维度上进行乘加运算。因此，它可以非常高效地实现通道数的变换和压缩。同时，由于 Pointwise Convolution 的计算量较小，其计算速度也比较快，因此常常被用于轻量化网络设计中。</p> 
 <p>Pointwise Convolution 主要应用在两个方面：特征融合和特征变换。</p> 
 <p>具体来说：</p> 
 <ol><li> <p>特征融合：在深度学习中，我们经常需要将不同尺度的特征进行融合，这时可以使用 Pointwise Convolution 实现通道数的增加或者减少，从而实现特征融合。</p> </li><li> <p>特征变换：有时候我们需要对特征进行维度变换，例如将一个高-dimensional 的特征张量映射到 low-dimensional 的嵌入空间中。此时可以使用 Pointwise Convolution 实现通道数的变换，然后将变换得到的特征进行池化或者全局平均池化，从而得到 low-dimensional 的嵌入特征。</p> </li></ol> 
 <p>总之，Pointwise Convolution 具有计算量小、速度快、通道信息整合等优势，在轻量化网络设计中常常被用于提高网络的性能和效率。</p> 
</blockquote> 
<p><strong>Channel Alignment这样设计有什么好处？在文中作者这样描述的：(</strong>1)可以将不同形状的特征图对齐到同一维度。(2)在主干网的底层阶段，特征由少量的通道表示。通道对齐操作可以增加融合前的通道数量。这样，会有更多的频道特性参与融合，进一步提升性能。(3)在主干的高级阶段，特征通常包含大量的通道。在将这些特性输入解码器之前，通道缩减是不可避免的。通道对准操作使信道变化更加普遍，避免了一次急剧减小所造成的信息损失。</p> 
<hr> 
<p><strong>2)Feature Fusion:</strong>将这些特征串联起来进行跨模态交互，</p> 
<p class="img-center"><img alt="" height="42" src="https://images2.imgbox.com/1e/31/682myC8O_o.png" width="408"></p> 
<p> 在此之后，我们可以得到两个连接的权重</p> 
<p class="img-center"><img alt="" height="40" src="https://images2.imgbox.com/4c/93/MUt3cEZ5_o.png" width="506"></p> 
<p> CSP表示通道分离操作。</p> 
<p>        在对齐通道数量后，我们利用注意机制来选择代表性特征。增强的特性可以表示为:</p> 
<p class="img-center"><img alt="" height="73" src="https://images2.imgbox.com/d1/6a/FU8j3Tnh_o.png" width="432"></p> 
<p> SA表示shuffle attention (SA) module</p> 
<blockquote> 
 <p><span style="background-color:#a2e043;">补充：</span>Shuffle Attention (SA) 模块是一种用于图像分类和目标检测任务的注意力机制模块，它可以有效地提取图像中<span style="color:#fe2c24;">不同区域</span>之间的重要性信息，并帮助模型更好地进行物体辨识。</p> 
 <p>SA 模块的核心思想是将空间上相邻的特征图位置打乱，然后再对每个特征点进行全局池化，这样可以使得特征图中的每个输出点都能够看到相互独立的内容。具体来说，SA 模块的操作步骤如下：</p> 
 <ol><li>输入特征 x 的尺寸为B×C×H×W，其中 B 为 batch size，C 为通道数，H 和 W 分别为特征图的高度和宽度。</li><li>将输入特征 x 分成若干个小块，每个小块的大小为 k×k，并打乱每个小块内的元素顺序。</li><li>对每个小块内的元素进行全局平均池化，得到该小块内的特征表示。</li><li>将所有的小块内的特征表示拼接起来，并通过一个 1x1 卷积层进行非线性变换，得到最终的特征表示。</li></ol> 
 <p>与其他注意力机制不同的是，SA 模块并没有计算 query 和 key 之间的相似度，而是直接从局部特征块中提取信息。</p> 
 <p>总之，SA 模块通过打乱输入特征图的位置、全局池化和特征拼接等操作，可以帮助模型更好地利用图像中不同区域之间的重要性信息，从而提高图像分类和目标检测任务的性能表现。</p> 
 <p></p> 
 <p><strong>Shuffle Attention (SA) 模块和空间注意力（Spatial Attention）在注意力机制的实现方式上有着一定的区别</strong>。</p> 
 <p>空间注意力是一种经典的注意力机制，其<strong>思想是通过对输入图像的不同位置进行加权，让模型更关注重要的信息</strong>。具体来说，空间注意力通常会引入两个关键变量：query 和 key，计算它们之间的相似度，并利用 softmax 函数将相似度转换成权重，最终将这些加权后的特征图进行池化或者卷积。</p> 
 <p>相比于空间注意力，Shuffle Attention 模块则<strong>更加关注特征图中不同区域之间的关联性</strong>，其核心思想是将空间上相邻的特征图位置打乱，然后对每个小块内的元素进行全局平均池化，从而得到该小块内的特征表示。这样可以使得特征图中的每个输出点都能够看到相互独立的内容，进而提取出更全面、更准确的特征。</p> 
 <p>因此，Shuffle Attention 模块与传统的空间注意力模块有着明显的区别。SA 模块通过对特征图中的位置重新排列并进行全局池化等操作，强调了特征图中不同区域之间的相互独立性，能够更好地挖掘不同区域之间的关联性。而空间注意力则更加注重不同位置之间的权重计算，能够更好地提取重要的信息。</p> 
 <p>总之，在实际应用中，选择何种注意力机制取决于具体任务的需求以及特征图中不同区域之间的关联程度。</p> 
 <p></p> 
 <p>更多参考：<a href="https://blog.csdn.net/DD_PP_JJ/article/details/113822143?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=Shuffle%20Attention%20%28SA%29%20%E6%A8%A1%E5%9D%97&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-113822143.142%5Ev82%5Einsert_down38,201%5Ev4%5Eadd_ask,239%5Ev2%5Einsert_chatgpt&amp;spm=1018.2226.3001.4187" title="【CV中的Attention机制】ShuffleAttention_sa注意力机制_*pprp*的博客-CSDN博客">【CV中的Attention机制】ShuffleAttention_sa注意力机制_*pprp*的博客-CSDN博客</a></p> 
</blockquote> 
<p>        特征融合过程可以表示为:</p> 
<p class="img-center"><img alt="" height="82" src="https://images2.imgbox.com/c2/55/mCFn4pLJ_o.png" width="567"></p> 
<p> <strong>3)Channel Projection:</strong> 通过3次ReLU激活的3×3卷积来减少通道的数量。因此，IBCMF模块的最终输出为:</p> 
<p class="img-center"><img alt="" height="49" src="https://images2.imgbox.com/b1/c4/C4D8QfAS_o.png" width="517"></p> 
<p><strong>三个连续的3×3卷积</strong>，为简便起见省略ReLU激活。这种尝试带来了<strong>两个好处</strong>。首先，<strong>减少特征通道的数量有利于内存的使用和计算的消耗</strong>。第二，相同数量的通道<strong>简化了元素操作</strong>。在此之后，我们最终可以得到融合后的feature map。</p> 
<hr> 
<h3></h3> 
<h3>自适应Atrous空间金字塔(A2SP)模块</h3> 
<blockquote> 
 <p>1.为什么设计这个模块？</p> 
 <p>        ASPP由于并行卷积层[16]，它们也降低了GPU推理速度，增加了参数数量。</p> 
 <p>2.怎么设计的？</p> 
 <p>        由于来自不同编码器阶段的特征映射具有不同的分辨率，在解码器中使用相同的扩展速率和内核大小来处理特征映射是不合理的。一些高级阶段的特征映射可以用更少的扩张卷积和更小的内核尺寸来表示。为了加快推理速度和减少参数，我们开发了一个自适应Atrous空间金字塔(A2SP)模块，如图5所示。</p> 
</blockquote> 
<p class="img-center"><img alt="" height="385" src="https://images2.imgbox.com/d3/a7/3Rh0zaLI_o.png" width="624"></p> 
<p></p> 
<p class="img-center"><img alt="" height="380" src="https://images2.imgbox.com/f4/8a/grLpX5yv_o.png" width="548"></p> 
<p></p> 
<p>为了有效地利用多尺度特征，我们首先<strong>自适应</strong>地将通过扩张卷积提取的多尺度信息串联起来。假设这些丰富特征在第i阶段表示为<img alt="F^{Cat}_i" class="mathcode" src="https://images2.imgbox.com/92/d2/RjjAVb2G_o.png">，则可计算为:</p> 
<p class="img-center"><img alt="" height="255" src="https://images2.imgbox.com/f2/74/DpE9RGeP_o.png" width="512"></p> 
<p><img alt="" height="61" src="https://images2.imgbox.com/14/f2/Fcf2yrBP_o.png" width="569"></p> 
<p>最后，我们通过<strong>1*1卷积</strong>将输出特征的<strong>维数恢复</strong>到与输入相同的维数。则在第i阶段，A2SP模块的最终输出为:</p> 
<p></p> 
<p class="img-center"><img alt="" height="52" src="https://images2.imgbox.com/c1/0a/meT9Vfn0_o.png" width="455"></p> 
<p></p> 
<hr> 
<h3>解码器</h3> 
<p>密集连接。在每个连接中，feature map被适当2,4,8上采样，以保持相同的分辨率。</p> 
<p class="img-center"><img alt="" height="199" src="https://images2.imgbox.com/dc/94/OVbNtm63_o.png" width="542"></p> 
<p><strong> 显著性头</strong></p> 
<p class="img-center"><img alt="" height="70" src="https://images2.imgbox.com/2b/0d/xTTfuuXv_o.png" width="494"></p> 
<p>其中Si是第i阶段的预测显著性映射，Upraw(·)表示将特征映射上采样到输入数据的原始大小。请注意，该单元仅在训练阶段使用，而在测试时省略。因此，在不增加任何额外推理成本的情况下，可以提高性能，这与本文设计实时轻量级模型的目标一致。</p> 
<hr> 
<p><img alt="" height="565" src="https://images2.imgbox.com/76/24/82wsgoNh_o.png" width="1200"></p> 
<p> <img alt="" height="470" src="https://images2.imgbox.com/e1/58/PPtxgc1F_o.png" width="1200"></p> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/35e60bacde07cbdf9f6f90b0761ab00c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">element el-table多列多字段同时排序后端返回数据（支持多个字段同时进行排序）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5f541442129200fdb9fc858deabc8d8c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python || 计算1到100之间的奇数之和及偶数之和。</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>