<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>TOF传感器、摄像头传感器、超声波传感器、激光雷达、毫米波雷达 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="TOF传感器、摄像头传感器、超声波传感器、激光雷达、毫米波雷达" />
<meta property="og:description" content="目录
一、智能网联汽车关键技术
二、传感器总结
三、TOF传感器
四、摄像头传感器
五、超声波传感器
六、激光雷达
七、毫米波雷达
八、参考文献
该文是应用于自动驾驶的传感器的学习总结
————————————————————————————
一、智能网联汽车关键技术 环境感知、智能决策、控制执行是智能网联汽车的关键技术：
其中环境感知是通过各种传感器对车辆行驶环境进行动态感知，为决策模块提供输入，实现自动驾驶的基础。
不同的传感器来源就分成了2种感知形式：自主式环境感知、协同式环境感知。
环境感知：包括车辆的行驶路径、车辆周围的参与者、 驾驶状态和驾驶环境等：
行驶路径 结构化道路：检测车辆行驶路径的两侧车道线和各种车道标线；
非结构化道路：车辆的可行使区域
交通参与者 车辆周围的其他车辆、行人
地面可能影响车辆通过和安全的其他移动或静止物体
各种交通标志和交通信号灯等
驾驶状态 驾驶员自身状态
车辆自身行驶状态
车辆周围其他车辆行驶状态
驾驶环境 路面状况
道路交通拥堵情况
天气状况
对于动态对象，除识别外还需要进行轨迹跟踪 二、传感器总结 传感器选型主要有以下条件:
(1）扫描范围，决定了传感器对被感知的目标做出反应的时间;
(2）分辨率，传感器可以为车辆提供的环境细节;
(3）视场角分辨率，决定智能网联汽车需要多少传感器来覆盖感知的区域；
(4）感知目标数量，能够区分3D环境中的静态目标和动态目标的数量，并且确定需要跟踪的目标数量；
(5）刷新率，决定传感器信息更新的频率;
(6）可靠性和准确性，传感器在不同环境条件下的总体可靠性和准确性；
(7〉成本、尺寸和软件兼容性，这是环境感知传感器量产的技术条件之一；
(8）生成的数据量，它决定了车载计算单元的计算量，现在传感器偏向智能传感器，不仅仅是感知，还会分辨信息，把对车辆行驶影像最重要的数据传输给车载计算单元，从而减少其计算负荷。
三、TOF传感器 1、ToF是飞行时间（Time of Flight）的缩写，ToF传感器采用的是红外光，当光从物体上反射回传感器后，根据光的发射与反射的时间差，就可以计算出传感器与测量物体之间的距离；
2、ToF传感器也被称为“深度相机”（depth camera）或者ToF相机；
3、ToF传感器本身由两部分组成：第一部分是发射红外光的二极管，第二部分是特殊的光敏矩阵。传感器测量从物体反射回来的时间可以精确到纳秒级，ToF传感器还有一个重要特性使其成为一个3D传感器。那是因为ToF传感器不仅可以准确计算单个物体与传感器的距离，利用激光返回时间和波长的差异，还能对目标进行精确的数字三维（3D）表征，并直观地绘制出目标的各个特征，为我们提供一个三3D图像。
4、优势和不足：低功耗（3W）、小尺寸、精确快速的测量（纳秒级测量）、深度精度比2D摄像头高、远距离测量、安全性高、成本效益高、能接收动态信息更适合动态场景、可以在恶劣的光照条件下捕捉深度和红外图像；散射光带来的伪影（如果被测物体表面特别明亮且非常靠近ToF传感器，它们会将太多的光散射到接收器中，并产生伪影和不必要的反射）、多次反射带来测量的不确定性（当在拐角和凹面上使用ToF传感器时，光线可能会被多次反射，这些不必要的反射将给测量带来很大的不确定性）、环境光对测量带来不利影响（当在阳光明媚的户外使用ToF传感器时，高强度的阳光会导致传感器像素的快速饱和，从而无法检测到物体反射的实际光）；
5、ToF与LiDar的对比：
①激光雷达（LiDar）是激光探测和测距的缩写，这项技术使用一个激光器作为光源；LiDar使用光脉冲来测量飞行时间，LiDar激光雷达比ToF的测量速度更快且更加精确
②ToF传感器则利用连续波从反射和相移得到飞行时间（即远距离都不会大量衰减），ToF需要较少的专用设备，因此可以与更小、更便宜的设备一起使用
6、3D ToF相机在下一代汽车中具有巨大的应用潜力。该技术有助于车辆实时获得良好的环境感知，实现快速机动和避障，这也是自主驾驶不可或缺的能力。3D ToF还可以用来监控驾驶员和乘客的状态（眼球、动作、姿势、视线、安全带、物体遗留检测、物体分类和识别、移动支付，并在紧急情况下接管车辆的控制。3D ToF相机的手势检测可用于设置室内气候控制或切换到来电。ADI公司开发的ToF模块结合影像传感器和VGA ToF传感器模块与内建图像处理器方案，比传统音波检测具备更佳的检测角度，也更能准确测量物体跟汽车的距离。因此可为汽车倒车系统、开门防护系统、停车辅助系统及盲点侦测等应用提供更大范围的碰撞侦测预防。
7、3D ToF相机能提供实际场景中物体的高分辨率3D深度映射。与传统的2D成像相比，这是一个显著的优势，因为它提供了高度的可信度，可以根据精确的位置对人和物体进行分类。
四、摄像头传感器 1、摄像头传感器，顾名思义就是通过摄像头拍摄车辆周边场景，并以此来识别车辆、行人、行车线等的传感器。从拍摄到的影像可以检测出车辆及车灯、行车道的白线及标识、行人及自行车等。
2、摄像头传感器分为单镜头摄像头和多镜头立体摄像头两种。单镜头摄像头识别的是平面影像，而多镜头立体摄像头内置2个摄像头，除了可以识别立体物体，还可以测算到目标物体的距离。
3、摄像头传感器通过获取摄像头拍摄的车辆周边的实景画面，从实景画面中抽取场景特征信息、调整显像浓度，对画面进行预处理。根据预处理结果，更容易辨别对象的特征及形状、颜色等信息，从而提高检测速度。
4、目标物体处理流程：图像传感器通过图像处理识别对象物体，根据驾驶辅助ECU检测到的信息进行内容识别、判断、控制车辆。
5、检测车道：从经过处理的图像上抽取边缘画面（亮度变化大的区域），从边缘画面中找出行车线标记（车道两侧的实线及虚线，直道显示为直线），通过行车线标记测定车道。基于行车线信息获取车道中央位置、车辆行进方向及测算距离，从而识别、判断、控制车辆。
6、检测道路标识：从经过处理的图像上抽取对应的候补点，寻找由各点分布构成的直线、曲线、平面等任意图形，按照特定的模板推定标识。通过标识信息进行判断并控制车辆。
7、检测行人：人物图像由于体型、姿势、衣着等因素影响较难识别。因此，从图像中区分出静止的背景和运动的人物，需要根据模型化部位（手脚等较大部位的图形）以及统计性特征（全身图像等）进行识别，符合特征的则被判定为行人。根据车辆与行人间的位置关系及测算的距离，识别、判断、控制车辆。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/d612cd298d599447b00aa58827175f4a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-21T15:16:01+08:00" />
<meta property="article:modified_time" content="2023-03-21T15:16:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">TOF传感器、摄像头传感器、超声波传感器、激光雷达、毫米波雷达</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E6%99%BA%E8%83%BD%E7%BD%91%E8%81%94%E6%B1%BD%E8%BD%A6%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E6%99%BA%E8%83%BD%E7%BD%91%E8%81%94%E6%B1%BD%E8%BD%A6%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF" rel="nofollow">一、智能网联汽车关键技术</a></p> 
<p id="%E4%B8%80%E3%80%81%E4%BC%A0%E6%84%9F%E5%99%A8%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E4%BC%A0%E6%84%9F%E5%99%A8%E6%80%BB%E7%BB%93" rel="nofollow">二、传感器总结</a></p> 
<p id="%E4%B8%89%E3%80%81TOF%E4%BC%A0%E6%84%9F%E5%99%A8-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81TOF%E4%BC%A0%E6%84%9F%E5%99%A8" rel="nofollow">三、TOF传感器</a></p> 
<p id="%E4%BA%8C%E3%80%81%E6%91%84%E5%83%8F%E5%A4%B4%E4%BC%A0%E6%84%9F%E5%99%A8-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E6%91%84%E5%83%8F%E5%A4%B4%E4%BC%A0%E6%84%9F%E5%99%A8" rel="nofollow">四、摄像头传感器</a></p> 
<p id="%C2%A0%E4%B8%89%E3%80%81%E8%B6%85%E5%A3%B0%E6%B3%A2%E4%BC%A0%E6%84%9F%E5%99%A8-toc" style="margin-left:0px;"><a href="#%C2%A0%E4%B8%89%E3%80%81%E8%B6%85%E5%A3%B0%E6%B3%A2%E4%BC%A0%E6%84%9F%E5%99%A8" rel="nofollow">五、超声波传感器</a></p> 
<p id="%E5%9B%9B%E3%80%81%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE" rel="nofollow">六、激光雷达</a></p> 
<p id="%C2%A0%E4%BA%94%E3%80%81%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE-toc" style="margin-left:0px;"><a href="#%C2%A0%E4%BA%94%E3%80%81%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE" rel="nofollow">七、毫米波雷达</a></p> 
<p id="%C2%A0%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE-toc" style="margin-left:0px;"><a href="#%C2%A0%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE" rel="nofollow">八、参考文献</a></p> 
<hr id="hr-toc"> 
<p>该文是应用于自动驾驶的传感器的学习总结</p> 
<p>————————————————————————————</p> 
<h2 id="%E4%B8%80%E3%80%81%E6%99%BA%E8%83%BD%E7%BD%91%E8%81%94%E6%B1%BD%E8%BD%A6%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF">一、智能网联汽车关键技术</h2> 
<p>环境感知、智能决策、控制执行是智能网联汽车的关键技术：</p> 
<p><img alt="" height="497" src="https://images2.imgbox.com/33/f4/d35mMlUa_o.png" width="843"></p> 
<p> 其中环境感知是通过各种传感器对车辆行驶环境进行动态感知，为决策模块提供输入，实现自动驾驶的基础。</p> 
<p><img alt="" height="430" src="https://images2.imgbox.com/e9/3f/d4CGGx2i_o.png" width="850"></p> 
<p>不同的传感器来源就分成了2种感知形式：自主式环境感知、协同式环境感知。</p> 
<p>环境感知：包括车辆的行驶路径、车辆周围的参与者、 驾驶状态和驾驶环境等：</p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td style="width:69px;">行驶路径</td><td style="width:429px;"> <p>结构化道路：检测车辆行驶路径的两侧车道线和各种车道标线；</p> <p>非结构化道路：车辆的可行使区域</p> </td></tr><tr><td style="width:69px;">交通参与者</td><td style="width:429px;"> <p>车辆周围的其他车辆、行人</p> <p>地面可能影响车辆通过和安全的其他移动或静止物体</p> <p>各种交通标志和交通信号灯等</p> </td></tr><tr><td style="width:69px;">驾驶状态</td><td style="width:429px;"> <p>驾驶员自身状态</p> <p>车辆自身行驶状态</p> <p>车辆周围其他车辆行驶状态</p> </td></tr><tr><td style="width:69px;">驾驶环境</td><td style="width:429px;"> <p>路面状况</p> <p>道路交通拥堵情况</p> <p>天气状况</p> </td></tr><tr><td colspan="2">对于动态对象，除识别外还需要进行轨迹跟踪</td></tr></tbody></table> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81%E4%BC%A0%E6%84%9F%E5%99%A8%E6%80%BB%E7%BB%93">二、传感器总结</h2> 
<p><img alt="" height="620" src="https://images2.imgbox.com/31/82/Fxi8adJZ_o.png" width="1169"></p> 
<h2 id="%E2%80%8B%E7%BC%96%E8%BE%91"><img alt="" height="622" src="https://images2.imgbox.com/d8/6f/YRuakbIr_o.png" width="1080"></h2> 
<p></p> 
<p>传感器选型主要有以下条件:</p> 
<p>(1）扫描范围，决定了传感器对被感知的目标做出反应的时间;</p> 
<p>(2）分辨率，传感器可以为车辆提供的环境细节;</p> 
<p>(3）视场角分辨率，决定智能网联汽车需要多少传感器来覆盖感知的区域；</p> 
<p>(4）感知目标数量，能够区分3D环境中的静态目标和动态目标的数量，并且确定需要跟踪的目标数量；</p> 
<p>(5）刷新率，决定传感器信息更新的频率;</p> 
<p>(6）可靠性和准确性，传感器在不同环境条件下的总体可靠性和准确性；</p> 
<p>(7〉成本、尺寸和软件兼容性，这是环境感知传感器量产的技术条件之一；</p> 
<p>(8）生成的数据量，它决定了车载计算单元的计算量，现在传感器偏向智能传感器，不仅仅是感知，还会分辨信息，把对车辆行驶影像最重要的数据传输给车载计算单元，从而减少其计算负荷。</p> 
<h2 id="%E4%B8%89%E3%80%81TOF%E4%BC%A0%E6%84%9F%E5%99%A8">三、TOF传感器</h2> 
<p>1、ToF是飞行时间（Time of Flight）的缩写，ToF传感器采用的是红外光，当光从物体上反射回传感器后，根据光的发射与反射的时间差，就可以计算出传感器与测量物体之间的距离；</p> 
<p>2、ToF传感器也被称为“深度相机”（depth camera）或者ToF相机；</p> 
<p>3、ToF传感器本身由两部分组成：第一部分是发射红外光的二极管，第二部分是特殊的光敏矩阵。传感器测量从物体反射回来的时间可以精确到纳秒级，ToF传感器还有一个重要特性使其成为一个3D传感器。那是因为ToF传感器不仅可以准确计算单个物体与传感器的距离，利用激光返回时间和波长的差异，还能对目标进行精确的数字三维（3D）表征，并直观地绘制出目标的各个特征，为我们提供一个三3D图像。</p> 
<p>4、优势和不足：低功耗（3W）、小尺寸、精确快速的测量（纳秒级测量）、深度精度比2D摄像头高、远距离测量、安全性高、成本效益高、能接收动态信息更适合动态场景、可以在恶劣的光照条件下捕捉深度和红外图像；散射光带来的伪影（如果被测物体表面特别明亮且非常靠近ToF传感器，它们会将太多的光散射到接收器中，并产生伪影和不必要的反射）、多次反射带来测量的不确定性（当在拐角和凹面上使用ToF传感器时，光线可能会被多次反射，这些不必要的反射将给测量带来很大的不确定性）、环境光对测量带来不利影响（当在阳光明媚的户外使用ToF传感器时，高强度的阳光会导致传感器像素的快速饱和，从而无法检测到物体反射的实际光）；</p> 
<p>5、ToF与LiDar的对比：<br> ①激光雷达（LiDar）是激光探测和测距的缩写，这项技术使用一个激光器作为光源；LiDar使用光脉冲来测量飞行时间，LiDar激光雷达比ToF的测量速度更快且更加精确<br> ②ToF传感器则利用连续波从反射和相移得到飞行时间（即远距离都不会大量衰减），ToF需要较少的专用设备，因此可以与更小、更便宜的设备一起使用</p> 
<p>6、3D ToF相机在下一代汽车中具有巨大的应用潜力。该技术有助于车辆实时获得良好的环境感知，实现快速机动和避障，这也是自主驾驶不可或缺的能力。3D ToF还可以用来监控驾驶员和乘客的状态（眼球、动作、姿势、视线、安全带、物体遗留检测、物体分类和识别、移动支付，并在紧急情况下接管车辆的控制。3D ToF相机的手势检测可用于设置室内气候控制或切换到来电。ADI公司开发的ToF模块结合影像传感器和VGA ToF传感器模块与内建图像处理器方案，比传统音波检测具备更佳的检测角度，也更能准确测量物体跟汽车的距离。因此可为汽车倒车系统、开门防护系统、停车辅助系统及盲点侦测等应用提供更大范围的碰撞侦测预防。</p> 
<p>7、3D ToF相机能提供实际场景中物体的高分辨率3D深度映射。与传统的2D成像相比，这是一个显著的优势，因为它提供了高度的可信度，可以根据精确的位置对人和物体进行分类。</p> 
<h2 id="%E4%BA%8C%E3%80%81%E6%91%84%E5%83%8F%E5%A4%B4%E4%BC%A0%E6%84%9F%E5%99%A8">四、摄像头传感器</h2> 
<p>1、摄像头传感器，顾名思义就是通过摄像头拍摄车辆周边场景，并以此来识别车辆、行人、行车线等的传感器。从拍摄到的影像可以检测出车辆及车灯、行车道的白线及标识、行人及自行车等。</p> 
<p>2、摄像头传感器分为单镜头摄像头和多镜头立体摄像头两种。单镜头摄像头识别的是平面影像，而多镜头立体摄像头内置2个摄像头，除了可以识别立体物体，还可以测算到目标物体的距离。</p> 
<p>3、摄像头传感器通过获取摄像头拍摄的车辆周边的实景画面，从实景画面中抽取场景特征信息、调整显像浓度，对画面进行预处理。根据预处理结果，更容易辨别对象的特征及形状、颜色等信息，从而提高检测速度。</p> 
<p>4、目标物体处理流程：图像传感器通过图像处理识别对象物体，根据驾驶辅助ECU检测到的信息进行内容识别、判断、控制车辆。</p> 
<p>5、检测车道：从经过处理的图像上抽取边缘画面（亮度变化大的区域），从边缘画面中找出行车线标记（车道两侧的实线及虚线，直道显示为直线），通过行车线标记测定车道。基于行车线信息获取车道中央位置、车辆行进方向及测算距离，从而识别、判断、控制车辆。</p> 
<p>6、检测道路标识：从经过处理的图像上抽取对应的候补点，寻找由各点分布构成的直线、曲线、平面等任意图形，按照特定的模板推定标识。通过标识信息进行判断并控制车辆。</p> 
<p>7、检测行人：人物图像由于体型、姿势、衣着等因素影响较难识别。因此，从图像中区分出静止的背景和运动的人物，需要根据模型化部位（手脚等较大部位的图形）以及统计性特征（全身图像等）进行识别，符合特征的则被判定为行人。根据车辆与行人间的位置关系及测算的距离，识别、判断、控制车辆。</p> 
<p>8、多镜头立体摄像头：单镜头摄像头拍摄到的某一个图像，在转化成二次元画面时，由于缺少目标物体纵深数据导致无法进行立体识别。而多镜头立体摄像头融合了2个摄像头拍摄的图像从而获得视觉差，并利用视觉差使用三件测量的方式计算出纵深数据。因此，立体地识别目标物体的大小及形状</p> 
<p>9、摄像头感知算法：</p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td colspan="2">2D感知算法：</td></tr><tr><td style="width:114px;"> <p>物体检测</p> </td><td style="width:384px;"> <p>R-CNN系列</p> <p>YOLO系列</p> <p>CenterNet系列</p> </td></tr><tr><td style="width:114px;"> <p>物体跟踪</p> </td><td style="width:384px;"> <p>DeepSORT</p> <p>CenterTrack</p> </td></tr><tr><td style="width:114px;"> <p>语义分割</p> </td><td style="width:384px;"> <p>FCN,</p> <p>U-Net</p> <p>DeepLab</p> <p>Mask-RCNN</p> </td></tr><tr><td colspan="2"> <p>3D感知算法（单目和双目算法）：</p> <p>物体检测和深度估计</p> </td></tr></tbody></table> 
<p>注意：图像传感器不能过热或模糊<br><br><br><img alt="" height="238" src="https://images2.imgbox.com/be/65/Vd5v2r8E_o.png" width="713"></p> 
<p> <img alt="" height="324" src="https://images2.imgbox.com/6b/ac/b8dNSGhf_o.png" width="691"></p> 
<p></p> 
<p><img alt="" height="221" src="https://images2.imgbox.com/28/41/sSNP91sR_o.png" width="731"></p> 
<p></p> 
<p><img alt="" height="339" src="https://images2.imgbox.com/09/c6/SOt6ICwR_o.png" width="723"></p> 
<p> <img alt="" height="339" src="https://images2.imgbox.com/f0/80/h3LAlHcZ_o.png" width="716"></p> 
<p> <img alt="" height="401" src="https://images2.imgbox.com/b4/fa/RuuEm2HM_o.png" width="726"></p> 
<p> <img alt="" height="326" src="https://images2.imgbox.com/8e/e8/QOaphoFj_o.png" width="714"></p> 
<p> <img alt="" height="374" src="https://images2.imgbox.com/b5/dc/PnFaZnvx_o.png" width="727"></p> 
<p> <img alt="" height="393" src="https://images2.imgbox.com/2f/36/0zFS1eKg_o.png" width="720"></p> 
<h2 id="%C2%A0%E4%B8%89%E3%80%81%E8%B6%85%E5%A3%B0%E6%B3%A2%E4%BC%A0%E6%84%9F%E5%99%A8">五、超声波传感器</h2> 
<p>1、超声波传感器能被任何材质的障碍物所反射，并接收和放大障碍物反射的超声波脉冲，将超声波脉冲转换成数字信号。</p> 
<p>2、超声波发射器发出超声波，超声波遇到障碍物会返回，超声波传感器正是根据发射波和回波之间的时间差来测定发射点到障碍物的实际距离。</p> 
<p>3、但是强大如超声波传感器可是很怕脏污的，应始终保持表面干净。因为当其被异物附着时，超声波喇叭的震动(残响时间*1)会发生异常。例如超声波喇叭上附着霜（冰）、雪、泥等异物时，会影响超声波喇叭的正常功能。<br><img alt="" height="532" src="https://images2.imgbox.com/54/c7/6bcw8gv4_o.png" width="672"></p> 
<p> <img alt="" height="504" src="https://images2.imgbox.com/ae/84/C1CkEHHU_o.png" width="716"></p> 
<p> <img alt="" height="304" src="https://images2.imgbox.com/16/6a/zsOzVZrh_o.png" width="679"></p> 
<h2 id="%E5%9B%9B%E3%80%81%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE">六、激光雷达</h2> 
<p>1、是以发射激光束探测目标的位置、速度等特征量的雷达。通过向目标发射探测信号(激光)，然后将接收到的从目标反射回来的信号(目标回波)与发射信号进行比较，从而获得目标的距离、方位、速度等相关信息。</p> 
<p>2、摄像头传感器通过获取摄像头拍摄的车辆周边的实景画面，从实景画面中抽取场景特征信息、调整显像浓度，对画面进行预处理。根据预处理结果，更容易辨别对象的特征及形状、颜色等信息，从而提高检测速度。</p> 
<p>3、FLSAH激光雷达：在短时间内向前方发射大面积的激光，依靠高灵敏度的探测器对回波信号进行收集并绘制成像。</p> 
<p>4、扫描式激光雷达：被称为自动驾驶领域中必不可少的传感器。它可对车辆自身位置和目标物体之间的距离以及目标物体的形状进行分析，也可对包括行车道白线在内的道路形状等进行识别。</p> 
<p>5、MEMS激光雷达：MEMS（Micro Electromechanical System）即微机电系统，是指尺寸在几毫米乃至更小的高科技装置，其内部结构一般在微米甚至纳米量级，是一个独立的智能系统。MEMS微光反射镜是指采用光学MEMS技术制造的，把微光反射镜与MEMS驱动器继集成在一起的光学MEMS器件。MEMS微光反射镜的运动方式包括平动和扭转两种机械运动。通过可旋转MEMS微光反射镜改变发射光束的方向，对特定范围进行扫描。目标物体会反射扫描光束，接收部件会识别反射光。通过发射激光和接收到反射光的时间，可以测定与目标物体间的距离以及目标物体的大小。<br><br><img alt="" height="284" src="https://images2.imgbox.com/fe/5c/uo27TyKc_o.png" width="711"></p> 
<p> <img alt="" height="448" src="https://images2.imgbox.com/b2/d9/CUp02D37_o.png" width="790"></p> 
<p> <img alt="" height="534" src="https://images2.imgbox.com/51/28/QCEFy9aG_o.png" width="791"></p> 
<p> <img alt="" height="473" src="https://images2.imgbox.com/16/ae/kaWjzH7y_o.png" width="716"></p> 
<p> <img alt="" height="700" src="https://images2.imgbox.com/99/f6/8eAb057D_o.png" width="714"></p> 
<p>6、激光雷达感知算法：</p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td colspan="2">点云物体检测</td></tr><tr><td style="width:146px;"> <p>Point视图</p> </td><td style="width:352px;"> <p>PointNet++</p> <p>Point-RCNN</p> <p>3D SSD</p> </td></tr><tr><td style="width:146px;">BEV视图</td><td style="width:352px;"> <p>VoxelNet</p> <p>SECOND</p> <p>PIXOR</p> <p>AFDet</p> </td></tr><tr><td style="width:146px;">Range视图</td><td style="width:352px;"> <p>LaserNet</p> <p>RangeDet</p> </td></tr><tr><td style="width:146px;">多视图融合</td><td style="width:352px;"> <p>PointPillar</p> <p>SIENet</p> <p>PV-CNN</p> <p>MV3D</p> <p>RSN</p> </td></tr><tr><td colspan="2" style="width:146px;">点云语义分割</td></tr><tr><td style="width:146px;"> <p>语义分割</p> </td><td style="width:352px;"> <p>RangeNet++</p> <p>SqueezeSeg</p> <p>RandLA-Net</p> </td></tr><tr><td style="width:146px;">实例分割</td><td style="width:352px;"> <p>LiDARSeg</p> <p>SGPN</p> </td></tr><tr><td style="width:146px;">全景分割</td><td style="width:352px;"> <p>Panoptic-PolarNet</p> <p>Panoptic RangeNet</p> <p>4D Panoptic Seg</p> </td></tr></tbody></table> 
<h2 id="%C2%A0%E4%BA%94%E3%80%81%E6%AF%AB%E7%B1%B3%E6%B3%A2%E9%9B%B7%E8%BE%BE">七、毫米波雷达</h2> 
<p>1、是通过毫米波段的电波测量距离、相对距离、方向等的雷达传感器。在驾驶过程中向前方发射毫米波段的电波，若前方有车辆，则可收到反射回来的回波。通过分析检测到的反射波频率变化等，检测前方及对面是否有车辆、与前方及对面车辆间的距离、相对速度和方向等。</p> 
<p>2、车辆上搭载的毫米波雷达通常使用两个波段。毫米波雷达使用的是76GHz波段的电波(毫米波*1)。BSM使用的是24GHz波段的电波(准毫米波)。</p> 
<p><img alt="" height="378" src="https://images2.imgbox.com/e5/e2/DfHTMBd6_o.png" width="748"></p> 
<p> <img alt="" height="290" src="https://images2.imgbox.com/b5/60/XdAbzFa4_o.png" width="730"></p> 
<p> <img alt="" height="254" src="https://images2.imgbox.com/48/79/uCrJNiCt_o.png" width="786"></p> 
<h2 id="%C2%A0%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE">八、参考文献</h2> 
<p><a href="https://mp.weixin.qq.com/s/RfG8GjypVdqVv0E2gKfS2g" rel="nofollow" title="ToF传感器究竟有多神奇？本文告诉你！ (qq.com)">ToF传感器究竟有多神奇？本文告诉你！ (qq.com)</a></p> 
<p><a href="https://www.sohu.com/a/429134001_427184" rel="nofollow" title="读懂ToF传感器，看这一篇就够了！_飞行时间">读懂ToF传感器，看这一篇就够了！_飞行时间</a></p> 
<p><a href="https://mp.weixin.qq.com/s/jgSwd6_8YCvsvhLWYgzDUQ" rel="nofollow" title="自动驾驶背后的传感器 (qq.com)">自动驾驶背后的传感器 (qq.com)</a></p> 
<p><a href="https://mp.weixin.qq.com/s/XAOhoo34-2xk99KXXexXuA" rel="nofollow" title="自动驾驶感知——环境感知的基本概念 (qq.com)">自动驾驶感知——环境感知的基本概念 (qq.com)</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0647ac22597bdc43887cb234dd8a23f8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">List＜Long＞转为String[]</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1700df94459c2a6a559df05fb07bde87/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【转】Typora 安装包2021年11月最后一次免费版本的安装包下载V13.6.1</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>