<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[052]TensorFlow Layers指南：基于CNN的手写数字识别 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[052]TensorFlow Layers指南：基于CNN的手写数字识别" />
<meta property="og:description" content="TensorFlow Layers module 为容易的创建一个神经网络提供了高水平的API接口。它提供了很多方法帮助创建dense（全连接）层和卷积层，增加激活函数和应用dropout做归一化。在这个教程中，你会学到如何用layers构建一个卷积神经网络用于识别手写体数字，基于MNIST数据集。
MNIST 数据集包括手写体数字0~9的6万个训练数据和1万个测试数据，并格式化为28*28像素单色图片。
开端 让我们先创建一个TensorFlow程序 的主框架。创建一个文件命名为：cnn_mnist.py，并书写如下代码：
from __future__ import absolute_import from __future__ import division from __future__ import print_function # Imports import numpy as np import tensorflow as tf from tensorflow.contrib import learn from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib tf.logging.set_verbosity(tf.logging.INFO) # Our application logic will be added here if __name__ == &#34;__main__&#34;: tf.app.run() 阅读完这段教程，学习相应代码就能完成构建，训练和验证一个卷积神经网络，完成代码可以从这里获取
卷积神经网络介绍 卷积神经网络（CNNs）介绍是现在图片分类任务的一个理想模型。CNN通过一系列的过滤器从图片的原始像素数据上抽取和学习更高层次的特征，这些特征用于模型进行分类。CNN包含三部分：
卷积层（Convolutional layers）：这层会应用一定数量的卷积器到图片上。对于每个子区域，该层用一套数学运算产生一个单独的值在输出特征映射中。卷积层特别的应用了一个ReLU activation function 到输出数据上用于引用非线性到模型中。池化层（Pooling layers）：这层下采样图片数据抽取操作，来减少特征维度以减少处理时间。池算法中最大池算法通常被使用，最大池算法抽取特征图的子区域（例如：2*2像素块）全连接层（Dense (fully connected) layers）：Fully Connected 也叫 Dense，因为全连接权重密度很大。其实就是个卷积核宽高等于输入数据宽高的特殊卷积层。卷积层和全连接层可以等效转换。该层用于前面卷积层和池化层的下采样进行 的特征抽取后的分类任务。这层的每个节点都被前一层的每个节点连接。 通常，一个CNN由一系列的卷积模块组成，这些模块完成每步的特征抽取。每个模块由一个卷积层和紧跟的一个池化层组成，最后一个卷积模块由一个或多个全连接层组成，完成分类任务。在CNN的最后一个全连接层对模型的的每个目标类别（模型预测的所有可能类别）都包含着一个单独的节点，这个全连接层有一个softmax激活函数用于为每个节点产生一个0-1之间的值（所有这些softmax值的总和等于1）。我们能够把softmax值对应到一个给定的图片，而这些图片都是对应每个目标类别。CNN网络示例如下：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/e42b8afec047a52c084a709de292500b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-07-25T18:50:27+08:00" />
<meta property="article:modified_time" content="2017-07-25T18:50:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[052]TensorFlow Layers指南：基于CNN的手写数字识别</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>TensorFlow Layers module 为容易的创建一个神经网络提供了高水平的API接口。它提供了很多方法帮助创建dense（全连接）层和卷积层，增加激活函数和应用dropout做归一化。在这个教程中，你会学到如何用<code>layers</code>构建一个卷积神经网络用于识别手写体数字，基于MNIST数据集。</p> 
<p><img src="https://images2.imgbox.com/31/43/DFgqKqN0_o.png" alt="handwrite" title=""></p> 
<p><a href="http://yann.lecun.com/exdb/mnist/" rel="nofollow">MNIST 数据集</a>包括手写体数字0~9的6万个训练数据和1万个测试数据，并格式化为28*28像素单色图片。</p> 
<h4 id="开端">开端</h4> 
<hr> 
<p>让我们先创建一个TensorFlow程序 的主框架。创建一个文件命名为：cnn_mnist.py，并书写如下代码：</p> 
<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> absolute_import
<span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> division
<span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function

<span class="hljs-comment"># Imports</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-keyword">from</span> tensorflow.contrib <span class="hljs-keyword">import</span> learn
<span class="hljs-keyword">from</span> tensorflow.contrib.learn.python.learn.estimators <span class="hljs-keyword">import</span> model_fn <span class="hljs-keyword">as</span> model_fn_lib

tf.logging.set_verbosity(tf.logging.INFO)

<span class="hljs-comment"># Our application logic will be added here</span>

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
  tf.app.run()</code></pre> 
<p>阅读完这段教程，学习相应代码就能完成构建，训练和验证一个卷积神经网络，完成代码可以从<a href="https://www.github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/tutorials/layers/cnn_mnist.py" rel="nofollow">这里</a>获取</p> 
<h4 id="卷积神经网络介绍">卷积神经网络介绍</h4> 
<hr> 
<p>卷积神经网络（CNNs）介绍是现在图片分类任务的一个理想模型。CNN通过一系列的过滤器从图片的原始像素数据上抽取和学习更高层次的特征，这些特征用于模型进行分类。CNN包含三部分：</p> 
<ol><li>卷积层（Convolutional layers）：这层会应用一定数量的卷积器到图片上。对于每个子区域，该层用一套数学运算产生一个单独的值在输出特征映射中。卷积层特别的应用了一个<a href="https://en.wikipedia.org/wiki/Rectifier_%28neural_networks%29" rel="nofollow">ReLU activation function</a> 到输出数据上用于引用非线性到模型中。</li><li>池化层（Pooling layers）：这层<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer" rel="nofollow">下采样图片数据</a>抽取操作，来减少特征维度以减少处理时间。池算法中最大池算法通常被使用，最大池算法抽取特征图的子区域（例如：2*2像素块）</li><li>全连接层（Dense (fully connected) layers）：Fully Connected 也叫 Dense，因为全连接权重密度很大。其实就是个卷积核宽高等于输入数据宽高的特殊卷积层。卷积层和全连接层可以等效转换。该层用于前面卷积层和池化层的下采样进行 的特征抽取后的分类任务。这层的每个节点都被前一层的每个节点连接。</li></ol> 
<p>通常，一个CNN由一系列的卷积模块组成，这些模块完成每步的特征抽取。每个模块由一个卷积层和紧跟的一个池化层组成，最后一个卷积模块由一个或多个全连接层组成，完成分类任务。在CNN的最后一个全连接层对模型的的每个目标类别（模型预测的所有可能类别）都包含着一个单独的节点，这个全连接层有一个<a href="https://en.wikipedia.org/wiki/Softmax_function" rel="nofollow">softmax</a>激活函数用于为每个节点产生一个0-1之间的值（所有这些softmax值的总和等于1）。我们能够把softmax值对应到一个给定的图片，而这些图片都是对应每个目标类别。CNN网络示例如下：</p> 
<p><img src="https://images2.imgbox.com/65/45/FHo4Gn4y_o.png" alt="这里写图片描述" title=""> </p> 
<ul><li>想更全面的了解CNN的架构，可以看斯坦福的<a href="http://cs231n.github.io/convolutional-networks/" rel="nofollow">CNN用于视觉识别课程材料</a></li></ul> 
<h4 id="构建cnn的mnist分类器">构建CNN的MNIST分类器</h4> 
<hr> 
<p>让我们用下面的CNN架构构建一个模型用于对MNIST数据集图片进行分类。 <br> 1. 卷积层1：用32个 的5*5的卷积核（抽取5*5像素的子区域），使用ReLu激活函数。 <br> 2. 池化层1：用一个2*2的过滤器进行最大池化，步长为2（保证池化区域不重叠）。 <br> 3. 卷积层2：用于64个 的5*5的卷积核，使用ReLu激活函数。 <br> 4. 池化层2：再次用一个2*2的过滤器进行最大池化，步长为2 <br> 5. 全连接层1：1024个神经元节点，每个节点有0.4的的概率会正则化丢弃（每个给定的元素点在训练时有0.4的概率被丢弃，防止过拟合）。 <br> 6. 全连接层2:10个神经元节点，每一个对应一个数字目标类（0-9）</p> 
<p><code>tf.layers</code>模块包含了创建上面三种层的方法： <br> - conv2d()：构建一个二维的卷积层。参数有：卷积核数（filters）、卷积和尺寸、填充（padding）、激活函数。 <br> - max_pooling2d()：构建一个二维的池化层，使用最大池算法。参数有：池化核尺寸，步长。 <br> - dense()：构建一个全连接层。参数有：神经元节点数、激活函数。</p> 
<p>上面的每一个函数都接收一个张量（tensor）作为输入，并且返回一个变换过的张量作为输出。这样能够容易的连接一层到另一层：某一层的输出作为下一层的输入。</p> 
<p>将下面的<code>cnn_model_fn</code>函数添加到<code>cnn_mnist.py</code>中，这符合TensorFlow’s Estimator API期待的接口。<code>cnn_mnist.py</code>将MNIST特征数据，标签集合模型模式（TRAIN, EVAL, INFER）作为参数。配置CNN网络，并且返回预测值，损失值和训练操作。</p> 
<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cnn_model_fn</span><span class="hljs-params">(features, labels, mode)</span>:</span>
  <span class="hljs-string">"""Model function for CNN."""</span>
  <span class="hljs-comment"># Input Layer</span>
  input_layer = tf.reshape(features, [-<span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>])

  <span class="hljs-comment"># Convolutional Layer #1</span>
  conv1 = tf.layers.conv2d(
      inputs=input_layer,
      filters=<span class="hljs-number">32</span>,
      kernel_size=[<span class="hljs-number">5</span>, <span class="hljs-number">5</span>],
      padding=<span class="hljs-string">"same"</span>,
      activation=tf.nn.relu)

  <span class="hljs-comment"># Pooling Layer #1</span>
  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=<span class="hljs-number">2</span>)

  <span class="hljs-comment"># Convolutional Layer #2 and Pooling Layer #2</span>
  conv2 = tf.layers.conv2d(
      inputs=pool1,
      filters=<span class="hljs-number">64</span>,
      kernel_size=[<span class="hljs-number">5</span>, <span class="hljs-number">5</span>],
      padding=<span class="hljs-string">"same"</span>,
      activation=tf.nn.relu)
  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=<span class="hljs-number">2</span>)

  <span class="hljs-comment"># Dense Layer</span>
  pool2_flat = tf.reshape(pool2, [-<span class="hljs-number">1</span>, <span class="hljs-number">7</span> * <span class="hljs-number">7</span> * <span class="hljs-number">64</span>])
  dense = tf.layers.dense(inputs=pool2_flat, units=<span class="hljs-number">1024</span>, activation=tf.nn.relu)
  dropout = tf.layers.dropout(
      inputs=dense, rate=<span class="hljs-number">0.4</span>, training=mode == learn.ModeKeys.TRAIN)

  <span class="hljs-comment"># Logits Layer</span>
  logits = tf.layers.dense(inputs=dropout, units=<span class="hljs-number">10</span>)

  loss = <span class="hljs-keyword">None</span>
  train_op = <span class="hljs-keyword">None</span>

  <span class="hljs-comment"># Calculate Loss (for both TRAIN and EVAL modes)</span>
  <span class="hljs-keyword">if</span> mode != learn.ModeKeys.INFER:
    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=<span class="hljs-number">10</span>)
    loss = tf.losses.softmax_cross_entropy(
        onehot_labels=onehot_labels, logits=logits)

  <span class="hljs-comment"># Configure the Training Op (for TRAIN mode)</span>
  <span class="hljs-keyword">if</span> mode == learn.ModeKeys.TRAIN:
    train_op = tf.contrib.layers.optimize_loss(
        loss=loss,
        global_step=tf.contrib.framework.get_global_step(),
        learning_rate=<span class="hljs-number">0.001</span>,
        optimizer=<span class="hljs-string">"SGD"</span>)

  <span class="hljs-comment"># Generate Predictions</span>
  predictions = {
      <span class="hljs-string">"classes"</span>: tf.argmax(
          input=logits, axis=<span class="hljs-number">1</span>),
      <span class="hljs-string">"probabilities"</span>: tf.nn.softmax(
          logits, name=<span class="hljs-string">"softmax_tensor"</span>)
  }

  <span class="hljs-comment"># Return a ModelFnOps object</span>
  <span class="hljs-keyword">return</span> model_fn_lib.ModelFnOps(
      mode=mode, predictions=predictions, loss=loss, train_op=train_op)</code></pre> 
<p>下面的部分（对应上面每块代码块的头部）深入到<code>tf.layers</code>代码中，了解如何创建每层网络结构、如何计算损失（loss）、配置训练操作过程和进行预测。如果你已经对CNNs和<a href="https://www.tensorflow.org/extend/estimators" rel="nofollow">TensorFlow Estimators</a>非常熟悉了，能够直观的明白上述代码，你可以跳过这一部分或直接跳到<code>"Training and Evaluating the CNN MNIST Classifier"</code> </p> 
<h5 id="输入层input-layer"><strong>输入层（Input Layer）</strong></h5> 
<p>在<code>layers</code>模块中用于创建用于二维图片数据的卷积层和池化层的方法期待的张量（tensors）有一个结构（shape）：<code>[batch_size, image_width, image_height, channels]</code>，定义如下： <br> - <code>batch_size</code>：子集的个数，例如在训练时，当执行梯度下降（gradient descent）时被用到。 <br> - <code>image_width</code>：样例图片的宽度。 <br> - <code>image_height</code>：样例图片的高度。 <br> - <code>channels</code>：用例图片的颜色通道数。对于彩色图片，通道数为3（红，绿，蓝），对于单色图片，仅有一个通道（黑）</p> 
<p>这里，我们的MNIST数据集由单色28*28像素的图片组成，因此对于我们的输入层理想的结构是<code>[batch_size, 28, 28, 1]</code>。</p> 
<p>为了修正我们的输入特征映射到这个结构，我们可以执行下面的<code>reshape</code>运算： <br> <code>input_layer = tf.reshape(features, [-1, 28, 28, 1])</code> </p> 
<p>注意到这里我们指定batch size为-1，这是个特殊值，指这个维度应该基于在特征集<code>features</code>中输入值的数量，保持所有其它维度尺寸固定。</p> 
<h5 id="卷积层1convolutional-layer1"><strong>卷积层1（Convolutional Layer1）</strong>：</h5> 
<p>在我们第一个卷积层，我们应用32个5*5像素的过滤器到输入层，用ReLU激活函数，我们用layers中的conv2d()方法创建这个层，如下：</p> 
<pre class="prettyprint"><code class=" hljs avrasm">conv1 = tf<span class="hljs-preprocessor">.layers</span><span class="hljs-preprocessor">.conv</span>2d(
    inputs=input_layer,
    filters=<span class="hljs-number">32</span>,
    kernel_size=[<span class="hljs-number">5</span>, <span class="hljs-number">5</span>],
    padding=<span class="hljs-string">"same"</span>,
    activation=tf<span class="hljs-preprocessor">.nn</span><span class="hljs-preprocessor">.relu</span>)</code></pre> 
<ul><li><code>inputs</code>参数必须是我们的输入张量，必须是<code>[batch_size, image_width, image_height, channels]</code>结构。 </li><li><code>filters</code>参数指定是应用的过滤器个数（这里是32），<code>kernel_size</code>只每个过滤器的维度<code>[width, height]</code>（这里<code>[5, 5]</code>）。 <br> 说明：如果过滤器的宽度和高度有相同的值，可以指定一个单独的整数,如：<code>kernel_size=5</code> </li><li><code>padding</code>参数为两个枚举类型中的一个：<code>valid</code>（默认值）或者<code>same</code>。如果我们想输出张量的宽度和高度跟输入一致，我们可以设<code>padding=same</code>，这会指示TensorFlow在输出张量的边界加0值，来满足28的宽和高度（如果没有padding，一个5*5的卷积作用在28*28的张量上将会产生一个24*24的张量，有24*24个位置去提取5*5的区域从28*28的格子上）。 </li><li><code>activation</code>参数指定应用到卷积输出的的激活函数，这里指定ReLU激活函数<code>tf.nn.relu</code>。</li></ul> 
<p>这里通过<code>conv2d()</code>产生的输出张量有一个结构<code>[batch_size, 28, 28, 32]</code>:与输入有相同的宽度和高度维度，但是每一个过滤器输出有32个通道。</p> 
<h5 id="池化层1pooling-layer1"><strong>池化层1（Pooling Layer1）</strong>：</h5> 
<p>下面，我们连接第一个池化层到我们刚刚创建的卷积层。我们能够用layers里的<code>max_pooling2d()</code>方法构建一个层，这个层用2*2的过滤器和步长2来进行最大池化: <br> <code>pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)</code></p> 
<ul><li><code>inputs</code>参数指定结构是<code>[batch_size, image_width, image_height, channels]</code>的输入张量。这里我们的输入张量是<code>conv1</code>，第一个卷积层的输出，输出张量有结构<code>[batch_size, 28, 28, 32]</code>。</li><li><code>pool_size</code>参数指定最大池化过滤器的尺寸<code>[width, height]</code>(这里是，[2,2])，如果两个维度有相同的值，可以用一个单独的整数值代替（<code>pool_size=2</code>）。</li><li><code>strides</code>参数指定步长的值，这里为2，如果想在两个维度指定不同 的步长值，可以设如：<code>stride=[3, 6]</code> <br> <code>max_pooling2d()</code>函数产生的输出张量<code>(pool1)</code>结构为：<code>[batch_size, 14, 14, 32]</code>：2*2的过滤器会减少宽和高的50%。</li></ul> 
<h5 id="卷积层2和池化层2"><strong>卷积层2和池化层2</strong></h5> 
<p>我们能够像前面一样，用<code>conv2d()</code>和<code>max_pooling2d()</code>函数连接第二个卷积和池化层到CNN网络，对于卷积层2，我们配置64个5*5的过滤器和ReLu激活函数，并且对于池化层2，我们使用相同的空间，如池化层1（一个2*2的最大池化过滤器和步长2）：</p> 
<pre class="prettyprint"><code class=" hljs avrasm">conv2 = tf<span class="hljs-preprocessor">.layers</span><span class="hljs-preprocessor">.conv</span>2d(
    inputs=pool1,
    filters=<span class="hljs-number">64</span>,
    kernel_size=[<span class="hljs-number">5</span>, <span class="hljs-number">5</span>],
    padding=<span class="hljs-string">"same"</span>,
    activation=tf<span class="hljs-preprocessor">.nn</span><span class="hljs-preprocessor">.relu</span>)

pool2 = tf<span class="hljs-preprocessor">.layers</span><span class="hljs-preprocessor">.max</span>_pooling2d(inputs=conv2, pool_size=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], strides=<span class="hljs-number">2</span>)</code></pre> 
<p>注释：卷积层2把第一个池化层的输出（pool1）作为输入，并且产生输出张量<code>conv2</code>，架构为：<code>[batch_size, 14, 14, 64]</code>，与pool1有相同的宽度和高度，并且64个通道对应应用的64个过滤器。 <br> 池化层2把<code>conv2</code>作为输入，产生<code>pool2</code>作为输出，pool2结构为<code>[batch_size, 7, 7, 64]</code> </p> 
<h5 id="全连接层dense-layer"><strong>全连接层（Dense Layer）</strong>：</h5> 
<p>下面，我们增加一个全连接层（1024个神经单元和Relu激活函数）到CNN网络上，来通过卷积层和池化层抽取的特征执行分类任务。然而，在连接到网络上前，我们需要格式化我们的特征映射到结构<code>[batch_size, features]</code>，如此，我们的张量就只有二维了： </p> 
<p><code>pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])</code> </p> 
<p>在上面的<code>reshape()</code>运算，-1指<code>batch_size</code>维度将被动态计算，根据我们输入数据样例的数量。每个样例都有7(pool2宽)*7(pool2高)*64(pool2通道)个特征，因此特征维度为：7*7*64(3136总共)。输出张量<code>pool2_flat</code>有结构<code>[batch_size, 3136]</code>.</p> 
<p>现在我们可以用<code>layers</code>中的<code>dense()</code>方法连接我们的全连接层，如下： </p> 
<p><code>dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)</code> <br> - <code>inputs</code>参数指定输入张量：我们格式化的特征映射<code>pool2_flat</code>. <br> - <code>units</code>参数为全连接层神经元节点的个数(1024)。 <br> - <code>activation</code>,我们依然使用ReLU激活函数。</p> 
<p>为了提高模型的结果，我们应用dropout把我们的全连接层归一化： <br> <code>dropout = tf.layers.dropout( <br> inputs=dense, rate=0.4, training=mode == learn.ModeKeys.TRAIN)</code> </p> 
<ul><li><code>inputs</code>参数，输入张量，为我们全连接层的输出张量。</li><li><code>rate</code>参数指定丢弃率，我们指定0.4，意思为在训练期间，将会随机丢弃40%的元素。</li><li><code>training</code>参数是一个布尔值，指模型现在是否在训练模式。dropout将只有<code>training</code>是<code>True</code>时才执行。 </li></ul> 
<p>我们的输出张量<code>dropout</code>结构为：<code>[batch_size, 1024]</code>。 </p> 
<h5 id="逻辑层logits-layer"><strong>逻辑层（Logits Layer）</strong></h5> 
<p>我们神经网络的最后一层是逻辑层，这层会返回我们的预测原始结果值。我们创建一个10个神经元（每一个对应0-9的每个目标类）的全连接层，使用线性激活函数（默认）： </p> 
<p><code>logits = tf.layers.dense(inputs=dropout, units=10)</code></p> 
<p>CNN的最后的输出张量，logits结构为：<code>[batch_size, 10]</code> </p> 
<h5 id="计算损失率loss"><strong>计算损失率（Loss）</strong></h5> 
<p>对于训练和验证，我们都需要定义一个<a href="https://en.wikipedia.org/wiki/Loss_function" rel="nofollow">损失函数</a>来测量预测结果与目标类的匹配度。对于像MNIST这样的多分类问题，交叉熵（<a href="https://en.wikipedia.org/wiki/Cross_entropy" rel="nofollow">cross entropy</a>）通常被用在损失测量中。下面代码计算当运行模式为<code>TRAIN</code>或<code>EVAL</code>时的交叉熵。 </p> 
<pre class="prettyprint"><code class=" hljs avrasm">loss = None
train_op = None

<span class="hljs-preprocessor"># Calculate loss for both TRAIN and EVAL modes</span>
if mode != learn<span class="hljs-preprocessor">.ModeKeys</span><span class="hljs-preprocessor">.INFER</span>:
  onehot_labels = tf<span class="hljs-preprocessor">.one</span>_hot(indices=tf<span class="hljs-preprocessor">.cast</span>(labels, tf<span class="hljs-preprocessor">.int</span>32), depth=<span class="hljs-number">10</span>)
  loss = tf<span class="hljs-preprocessor">.losses</span><span class="hljs-preprocessor">.softmax</span>_cross_entropy(
      onehot_labels=onehot_labels, logits=logits)</code></pre> 
<p>我们的<code>labels</code>张量包含了我们样例的预测列表，例如：<code>[1, 9, ...]</code>,为了计算交叉熵，首先，我们需要转换<code>labels</code>为相应的<a href="https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science" rel="nofollow"><code>one-hot</code></a>编码。</p> 
<pre class="prettyprint"><code class=" hljs json">[[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],
 ...]</code></pre> 
<p>我们使用<a href="https://www.tensorflow.org/api_docs/python/tf/one_hot" rel="nofollow"><code>tf.one_hot</code></a>函数执行转换操作，有两个必须的参数： <br> - <code>indices</code>：在one-hot张量中有值的位置。–例如上述1值的位置。 <br> - <code>depth</code>：one-hot张量的深度。–例如目标类的数量，这里我们是10。 <br> 下面的代码创建一个one-hot张量为我们的labels</p> 
<p><code>onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)</code> </p> 
<p><code>tf.losses.softmax_cross_entropy()</code>把<code>onehot_labels</code>和<code>logits</code>作为参数，在<code>logits</code>上执行softmax激活，计算交叉熵，并且返回我们的损失，为一个scalar张量： </p> 
<p><code>loss = tf.losses.softmax_cross_entropy( <br> onehot_labels=onehot_labels, logits=logits)</code> </p> 
<h5 id="配置训练参数"><strong>配置训练参数</strong></h5> 
<p>在上面部分，我们定义CNN的损失为logits层和标签（Labels）的softmax交叉熵。让我们配置我们的模型在训练期间让损失值可选，使用<code>tf.contrib.layers</code>中的<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/optimize_loss" rel="nofollow"><code>tf.contrib.layers.optimize_loss</code></a>函数，我们将用一个0.001的学习率和随机梯度下降（<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" rel="nofollow">stochastic gradient descent</a> ） 作为选择算法： </p> 
<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># Configure the Training Op (for TRAIN mode)</span>
if mode == learn<span class="hljs-preprocessor">.ModeKeys</span><span class="hljs-preprocessor">.TRAIN</span>:
    train_op = tf<span class="hljs-preprocessor">.contrib</span><span class="hljs-preprocessor">.layers</span><span class="hljs-preprocessor">.optimize</span>_loss(
        loss=loss,
        global_step=tf<span class="hljs-preprocessor">.contrib</span><span class="hljs-preprocessor">.framework</span><span class="hljs-preprocessor">.get</span>_global_step(),
        learning_rate=<span class="hljs-number">0.001</span>,
        optimizer=<span class="hljs-string">"SGD"</span>)</code></pre> 
<h5 id="产生预测结果"><strong>产生预测结果</strong></h5> 
<p>我们模型的逻辑层( logits layer)返回预测结果原始值张量，结构为：<code>[batch_size, 10]</code>。让我们转换这些原始结果为两种我们的模型函数能够返回的不同的格式： <br> - 每个样例的预测类别：0-9间的一个数字 <br> - 每个样例的每个可能的目标类的概率。</p> 
<p>对于每一个给定的样例，我们的预测类别是在logits张量相应行的最高原始值的元素。我们能够知道这个元素的索引，用如下的函数： <br> <code>tf.argmax(input=logits, axis=1)</code> </p> 
<ul><li><code>input</code>参数指从张量中抽取的最大值，这里是<code>logits</code>。</li><li><code>axis</code>参数指沿着<code>input</code>张量找到的最大值的轴，这里我们最大值的维度是1，这对应于我们的预测</li></ul> 
<p>我们能够从我们的逻辑层导出概率值，通过应用softmax 激活<a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax" rel="nofollow"> tf.nn.softmax</a>：</p> 
<p><code>tf.nn.softmax(logits, name="softmax_tensor")</code> </p> 
<p>我们在字典中编译我们的预测，如下：</p> 
<pre class="prettyprint"><code class=" hljs avrasm">predictions = {
    <span class="hljs-string">"classes"</span>: tf<span class="hljs-preprocessor">.argmax</span>(
        input=logits, axis=<span class="hljs-number">1</span>),
    <span class="hljs-string">"probabilities"</span>: tf<span class="hljs-preprocessor">.nn</span><span class="hljs-preprocessor">.softmax</span>(
        logits, name=<span class="hljs-string">"softmax_tensor"</span>)
}</code></pre> 
<p>最后，我们可以返回我们的预测值、损失、和训练执行，mode参数在<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/ModelFnOps" rel="nofollow">tf.contrib.learn.ModelFnOps</a>对象：</p> 
<p><code># Return a ModelFnOps object <br> return model_fn_lib.ModelFnOps( <br> mode=mode, predictions=predictions, loss=loss, train_op=train_op)</code></p> 
<h4 id="训练和验证cnn-mnist-分类器"><strong>训练和验证CNN MNIST 分类器</strong></h4> 
<hr> 
<p>我们已经编写好我们的MNIST CNN模型函数，现在我们可以训练并验证它。</p> 
<h5 id="加载训练和测试数据"><strong>加载训练和测试数据</strong></h5> 
<p>首先我们加载训练和测试数据，增加<code>main()</code>函数到<code>cnn_mnist.py</code>:</p> 
<pre class="prettyprint"><code class=" hljs avrasm">def main(unused_argv):
  <span class="hljs-preprocessor"># Load training and eval data</span>
  mnist = learn<span class="hljs-preprocessor">.datasets</span><span class="hljs-preprocessor">.load</span>_dataset(<span class="hljs-string">"mnist"</span>)
  train_data = mnist<span class="hljs-preprocessor">.train</span><span class="hljs-preprocessor">.images</span> <span class="hljs-preprocessor"># Returns np.array</span>
  train_labels = np<span class="hljs-preprocessor">.asarray</span>(mnist<span class="hljs-preprocessor">.train</span><span class="hljs-preprocessor">.labels</span>, dtype=np<span class="hljs-preprocessor">.int</span>32)
  eval_data = mnist<span class="hljs-preprocessor">.test</span><span class="hljs-preprocessor">.images</span> <span class="hljs-preprocessor"># Returns np.array</span>
  eval_labels = np<span class="hljs-preprocessor">.asarray</span>(mnist<span class="hljs-preprocessor">.test</span><span class="hljs-preprocessor">.labels</span>, dtype=np<span class="hljs-preprocessor">.int</span>32)</code></pre> 
<p>我们存储训练特征数据（55000张图片的手写数字的原像素值）和训练标签（每张图片对应0-9中的一个值）作为<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html" rel="nofollow">numpy arrays</a>在<code>train_data</code>和<code>train_labels</code>中。同样，我们存储验证特征数据（1000张图片）和验证标签in<code>eval_data</code>和<code>eval_labels</code>。</p> 
<h5 id="创建estimator"><strong>创建Estimator</strong></h5> 
<p>让我们创建一个Estimator（一个TensorFlow的类，用于执行高维模型训练，验证，和接口），对于我们的模型，增加如下代码到main()：</p> 
<pre class="prettyprint"><code class=" hljs vala"><span class="hljs-preprocessor"># Create the Estimator</span>
mnist_classifier = learn.Estimator(
      model_fn=cnn_model_fn, model_dir=<span class="hljs-string">"/tmp/mnist_convnet_model"</span>)</code></pre> 
<ul><li><code>model_fn</code>参数指用于训练、验证、接口的模型函数，我们传递在”Building the CNN MNIST Classifier”中创建的<code>cnn_model_fn</code>给它。</li><li><code>model_dir</code>参数指定模型数据（checkpoints）将被保存的目录（根据需要更换自己的目录）</li></ul> 
<h5 id="设置日志"><strong>设置日志</strong></h5> 
<p>CNNs需要花费一段时间来训练，在训练时我们可以设置一些日志用于我们跟踪程序运行。我们可以用<code>tf.train.SessionRunHook</code>来创建一个<code>tf.train.LoggingTensorHook</code>,它能够记录我们CNN的softmax层的可能值。增加如下代码到main():</p> 
<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># Set up logging for predictions</span>
  tensors_to_log = {<!-- --><span class="hljs-string">"probabilities"</span>: <span class="hljs-string">"softmax_tensor"</span>}
  logging_hook = tf<span class="hljs-preprocessor">.train</span><span class="hljs-preprocessor">.LoggingTensorHook</span>(
      tensors=tensors_to_log, every_n_iter=<span class="hljs-number">50</span>)</code></pre> 
<p>我们创建了一个记录张量的字典在<code>tensors_to_log</code>。每一个key都是我们选择的标签，这些标签将被打印在log输出里。并且相应的标签是TensorFlow图中一个张量的名字。这里，我们的<code>probabilities</code>能够被找到在<code>softmax_tensor</code>中，我们给softmax运算的名字要在我们生成概率之前。</p> 
<p>接着，我们创建<code>LoggingTensorHook</code>,传递<code>tensors_to_log</code>给<code>tensors</code>参数。我们设置<code>every_n_iter=50</code>，这个值指训练每50步记录一下概率值。</p> 
<h5 id="训练模型"><strong>训练模型</strong></h5> 
<p>下面调用fit函数来训练我们的模型，添加如下代码到main：</p> 
<pre class="prettyprint"><code class=" hljs vala"><span class="hljs-preprocessor"># Train the model</span>
mnist_classifier.fit(
    x=train_data,
    y=train_labels,
    batch_size=<span class="hljs-number">100</span>,
    steps=<span class="hljs-number">20000</span>,
    monitors=[logging_hook])</code></pre> 
<p>在fit调用中，我们传递训练特征数据给标签x和y。 <br> - <code>batch_size=100</code>:指模型每步将会在100个样例的小集合上训练 <br> - <code>steps=20000</code>：模型总共训练20000步。 <br> - <code>monitors</code>：我们传递<code>logging_hook</code>给它，以便在训练时能够触发。</p> 
<h5 id="验证模型"><strong>验证模型</strong></h5> 
<p>训练完成，我们想验证我们模型在测试集上的准确率，我们需要创建一个指标词典，用<code>tf.contrib.learn.MetricSpec</code>,它能计算准确率，增加下面代码到main：</p> 
<pre class="prettyprint"><code class=" hljs avrasm"><span class="hljs-preprocessor"># Configure the accuracy metric for evaluation</span>
metrics = {
    <span class="hljs-string">"accuracy"</span>:
        learn<span class="hljs-preprocessor">.MetricSpec</span>(
            metric_fn=tf<span class="hljs-preprocessor">.metrics</span><span class="hljs-preprocessor">.accuracy</span>, prediction_key=<span class="hljs-string">"classes"</span>),
}</code></pre> 
<ul><li><code>metric_fn</code>参数，计算并返回指标的函数。这里我们用在<a href="https://www.tensorflow.org/api_docs/python/tf/metrics" rel="nofollow"><code>tf.metrics</code></a>模块中的<code>accuracy</code>函数。</li><li><code>prediction_key</code>参数，张量的key，这个张量是模型函数返回的预测值，这里，我们用前面创建的分类模型的预测key<code>classes</code>。</li></ul> 
<p>下面我们可以验证我们的模型了，增加如下代码，会验证并打印结果：</p> 
<pre class="prettyprint"><code class=" hljs bash"><span class="hljs-comment"># Evaluate the model and print results</span>
<span class="hljs-built_in">eval</span>_results = mnist_classifier.evaluate(
    x=<span class="hljs-built_in">eval</span>_data, y=<span class="hljs-built_in">eval</span>_labels, metrics=metrics)
print(<span class="hljs-built_in">eval</span>_results)</code></pre> 
<h5 id="运行模型"><strong>运行模型</strong></h5> 
<p>我们已经编写完CNN的模型函数、Estimator和训练验证逻辑，让我们看结果，运行<code>cnn_mnist.py</code> <br> 模型训练后，我们将会看到到日志输出如下所示：</p> 
<pre class="prettyprint"><code class=" hljs r">INFO:tensorflow:loss = <span class="hljs-number">2.36026</span>, step = <span class="hljs-number">1</span>
INFO:tensorflow:probabilities = [[ <span class="hljs-number">0.07722801</span>  <span class="hljs-number">0.08618255</span>  <span class="hljs-number">0.09256398</span>, <span class="hljs-keyword">...</span>]]
<span class="hljs-keyword">...</span>
INFO:tensorflow:loss = <span class="hljs-number">2.13119</span>, step = <span class="hljs-number">101</span>
INFO:tensorflow:global_step/sec: <span class="hljs-number">5.44132</span>
<span class="hljs-keyword">...</span>
INFO:tensorflow:Loss <span class="hljs-keyword">for</span> final step: <span class="hljs-number">0.553216</span>.

INFO:tensorflow:Restored model from /tmp/mnist_convnet_model
INFO:tensorflow:Eval steps [<span class="hljs-number">0</span>,inf) <span class="hljs-keyword">for</span> training step <span class="hljs-number">20000.</span>
INFO:tensorflow:Input iterator is exhausted.
INFO:tensorflow:Saving evaluation summary <span class="hljs-keyword">for</span> step <span class="hljs-number">20000</span>: accuracy = <span class="hljs-number">0.9733</span>, loss = <span class="hljs-number">0.0902271</span>
{<!-- --><span class="hljs-string">'loss'</span>: <span class="hljs-number">0.090227105</span>, <span class="hljs-string">'global_step'</span>: <span class="hljs-number">20000</span>, <span class="hljs-string">'accuracy'</span>: <span class="hljs-number">0.97329998</span>}</code></pre> 
<p>这里我们在测试集上达到了97.3%的准确率。</p> 
<h4 id="额外资料"><strong>额外资料</strong></h4> 
<p>想学习更多的<code>TensorFlow Estimators and CNNs</code>，可以看如下链接： <br> - <a href="https://www.tensorflow.org/extend/estimators" rel="nofollow"><code>Creating Estimators in tf.contrib.learn.</code></a>: TensorFlow Estimator API的引言，我们会学习到如何配置一个Estimator，写一个模型函数，计算loss，定义一个训练过程。 <br> - <a href="https://www.tensorflow.org/get_started/mnist/pros#build_a_multilayer_convolutional_network" rel="nofollow">Deep MNIST for Experts: Building a Multilayer CNN.</a>：学习如何构建一个MNIST CNN分类模型，没有layers ，使用低水平的TensorFlow 运算。</p> 
<p>参考链接：<a href="https://www.tensorflow.org/tutorials/layers" rel="nofollow">https://www.tensorflow.org/tutorials/layers</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8f430ea50eee6b0f857e1e7b85b703db/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">鼠标事件mouseout和mouseleave的区别</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dedbd5ac4d47e97815eb93daf97175b4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python-10 字符串-各种奇葩的内置方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>