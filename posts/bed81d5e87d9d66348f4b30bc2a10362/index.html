<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于darknet框架&#43;yolov3训练自己的数据集 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于darknet框架&#43;yolov3训练自己的数据集" />
<meta property="og:description" content="目录
1.准备标注工具
2.数据集准备
（1）下载数据集
（2）处理数据集
3.修改相应的配置文件
（1）修改voc.data和voc.names
（2）修改yolov3.cfg配置文件
4.下载权重文件
5.训练数据集
（1）训练开始
（2）训练结果
（3）测试结果
DarkNet的编译及安装的过程（无GPU的情况详解）
两款IP Camera&#43;YOLOV3进行目标检测（手机摄像头作为电脑摄像头使用）
windows平台使用CMake工具对darknet的编译以及安装过程&#43;yolov3&#43;图像检测&#43;摄像头检测&#43;视频检测&#43;手机作为摄像头进行检测（详解）
提示：
若读者还没有使用CMake工具对darknet源码进行编译，那么请看上面的文章《windows平台使用CMake工具对darknet的编译以及安装过程&#43;yolov3&#43;图像检测&#43;摄像头检测&#43;视频检测&#43;手机作为摄像头进行检测（详解）》；
若已经在windows平台上对其darknet进行了编译，则可以直接进行下面的操作。
训练自己数据集的官方教程
以下整个过程结构图： 1.准备标注工具 （1）图像标注工具：pip install labelimg
（2）打开标注工具：labelimg（在windows的命令窗口激活相应的虚拟环境之后）
（3）选择要标注的图像文件夹；
2.数据集准备 （1）下载数据集 链接：https://pan.baidu.com/s/18R30A4NtFJ2vpLEIk8I1-w 提取码：b61k
提示：以上下载的数据集是已经处理好的，但是如果读者想要标注自己的数据集的话，那么建议在标注数据集的同时，文件的存放结构按照如下所示：
VOCdevkit VOC2007 Annotations（存放标注图像之后得到的XML文件）ImageSets（包含了存放图像的路径的.txt文件） ​​​​​​​Main ​​​​​​​train.txttest.txtval.txtJPEGImages（存放相应标注图像的位置.jpg）​​​​​​​​​​​​​​labels（运次那个处理数据集的程序之后产生的文件，里面包含了每一张图像对应的txt文件，.txt文件中包含了：[class,cx,cy,w,h]）2007_test.txt（包含了用于测试集的图像绝对路径）2007_train.txt（包含了用于训练集的图像绝对路径）2007_val.txt（包含了用验证集的图像绝对路径）train.all.txt（包含了所有图像绝对路径）train.txt（包含了用于训练集和验证集的图像绝对路径） 提示：为什么建议读者按照上方的结构来放置数据集呢，主要是因为在处理数据集的程序中给定的路径就如上方样式所示，而且上面这样的格式也比较清晰。
（2）处理数据集 提示：该代码看起来有一点长，但是读者不要害怕，关键的地方都做了说明，并且很容易理解。下面的一部分代码是原本就已经给出的，路径为：
import os import pickle import random import numpy as np from PIL import Image from os.path import join from os import listdir, getcwd import xml.etree.ElementTree as ET import cv2 # sets=[(&#39;2012&#39;, &#39;train&#39;), (&#39;2012&#39;, &#39;val&#39;), (&#39;2007&#39;, &#39;train&#39;), (&#39;2007&#39;, &#39;val&#39;), (&#39;2007&#39;, &#39;test&#39;)] # classes = [&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/bed81d5e87d9d66348f4b30bc2a10362/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-24T13:33:41+08:00" />
<meta property="article:modified_time" content="2023-05-24T13:33:41+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于darknet框架&#43;yolov3训练自己的数据集</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="1.%E5%87%86%E5%A4%87%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7-toc" style="margin-left:0px;"><a href="#1.%E5%87%86%E5%A4%87%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7" rel="nofollow">1.准备标注工具</a></p> 
<p id="2.%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87-toc" style="margin-left:0px;"><a href="#2.%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87" rel="nofollow">2.数据集准备</a></p> 
<p id="%EF%BC%881%EF%BC%89%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:40px;"><a href="#%EF%BC%881%EF%BC%89%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow">（1）下载数据集</a></p> 
<p id="%EF%BC%882%EF%BC%89%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:40px;"><a href="#%EF%BC%882%EF%BC%89%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow">（2）处理数据集</a></p> 
<p id="3.%E4%BF%AE%E6%94%B9%E7%9B%B8%E5%BA%94%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-toc" style="margin-left:0px;"><a href="#3.%E4%BF%AE%E6%94%B9%E7%9B%B8%E5%BA%94%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6" rel="nofollow">3.修改相应的配置文件</a></p> 
<p id="%EF%BC%881%EF%BC%89%E4%BF%AE%E6%94%B9voc.data%E5%92%8Cvoc.names-toc" style="margin-left:40px;"><a href="#%EF%BC%881%EF%BC%89%E4%BF%AE%E6%94%B9voc.data%E5%92%8Cvoc.names" rel="nofollow">（1）修改voc.data和voc.names</a></p> 
<p id="%EF%BC%882%EF%BC%89%E4%BF%AE%E6%94%B9yolov3.cfg%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-toc" style="margin-left:40px;"><a href="#%EF%BC%882%EF%BC%89%E4%BF%AE%E6%94%B9yolov3.cfg%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6" rel="nofollow">（2）修改yolov3.cfg配置文件</a></p> 
<p id="4.%E4%B8%8B%E8%BD%BD%E6%9D%83%E9%87%8D%E6%96%87%E4%BB%B6-toc" style="margin-left:0px;"><a href="#4.%E4%B8%8B%E8%BD%BD%E6%9D%83%E9%87%8D%E6%96%87%E4%BB%B6" rel="nofollow">4.下载权重文件</a></p> 
<p id="5.%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:0px;"><a href="#5.%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow">5.训练数据集</a></p> 
<p id="%EF%BC%881%EF%BC%89%E8%AE%AD%E7%BB%83%E5%BC%80%E5%A7%8B-toc" style="margin-left:40px;"><a href="#%EF%BC%881%EF%BC%89%E8%AE%AD%E7%BB%83%E5%BC%80%E5%A7%8B" rel="nofollow">（1）训练开始</a></p> 
<p id="%EF%BC%882%EF%BC%89%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C-toc" style="margin-left:40px;"><a href="#%EF%BC%882%EF%BC%89%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C" rel="nofollow">（2）训练结果</a></p> 
<p id="%C2%A0%EF%BC%883%EF%BC%89%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C-toc" style="margin-left:40px;"><a href="#%C2%A0%EF%BC%883%EF%BC%89%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C" rel="nofollow">（3）测试结果</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p></p> 
<p><a class="link-info" href="https://mydreamambitious.blog.csdn.net/article/details/130773791" rel="nofollow" title="DarkNet的编译及安装的过程（无GPU的情况详解）">DarkNet的编译及安装的过程（无GPU的情况详解）</a></p> 
<p><a class="link-info" href="https://mydreamambitious.blog.csdn.net/article/details/130791133" rel="nofollow" title="两款IP Camera+YOLOV3进行目标检测（手机摄像头作为电脑摄像头使用）">两款IP Camera+YOLOV3进行目标检测（手机摄像头作为电脑摄像头使用）</a></p> 
<p><a class="link-info" href="https://mydreamambitious.blog.csdn.net/article/details/130804424" rel="nofollow" title="windows平台使用CMake工具对darknet的编译以及安装过程+yolov3+图像检测+摄像头检测+视频检测+手机作为摄像头进行检测（详解）">windows平台使用CMake工具对darknet的编译以及安装过程+yolov3+图像检测+摄像头检测+视频检测+手机作为摄像头进行检测（详解）</a></p> 
<p></p> 
<blockquote> 
 <p><strong>提示：</strong></p> 
 <p><span style="color:#4da8ee;">若读者还没有使用CMake工具对darknet源码进行编译，那么请看上面的文章《<a class="link-info" href="https://mydreamambitious.blog.csdn.net/article/details/130804424" rel="nofollow" title="windows平台使用CMake工具对darknet的编译以及安装过程+yolov3+图像检测+摄像头检测+视频检测+手机作为摄像头进行检测（详解）">windows平台使用CMake工具对darknet的编译以及安装过程+yolov3+图像检测+摄像头检测+视频检测+手机作为摄像头进行检测（详解）</a>》；</span></p> 
 <p><span style="color:#4da8ee;">若已经在windows平台上对其darknet进行了编译，则可以直接进行下面的操作。</span></p> 
 <p><span style="color:#4da8ee;"><a class="link-info" href="https://github.com/AlexeyAB/darknet#for-using-network-video-camera-mjpeg-stream-with-any-android-smartphone" title="训练自己数据集的官方教程">训练自己数据集的官方教程</a></span></p> 
</blockquote> 
<blockquote> 
 <p>以下整个过程结构图： </p> 
</blockquote> 
<p><img alt="" height="507" src="https://images2.imgbox.com/54/33/na2nSZcr_o.png" width="960"> </p> 
<p></p> 
<h2 id="1.%E5%87%86%E5%A4%87%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7">1.准备标注工具</h2> 
<blockquote> 
 <p>（1）图像标注工具：pip install labelimg</p> 
 <p><img alt="" height="343" src="https://images2.imgbox.com/c3/b0/z8QjrLYw_o.png" width="1087"></p> 
 <p> </p> 
 <p>（2）打开标注工具：labelimg（在windows的命令窗口激活相应的虚拟环境之后）</p> 
 <p>（3）选择要标注的图像文件夹；</p> 
 <p><img alt="" height="608" src="https://images2.imgbox.com/14/a4/dsiyveRm_o.png" width="1200"></p> 
</blockquote> 
<p></p> 
<h2 id="2.%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87">2.数据集准备</h2> 
<h3 id="%EF%BC%881%EF%BC%89%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86">（1）下载数据集</h3> 
<blockquote> 
 <p><strong>链接：<a class="link-info" href="https://pan.baidu.com/s/18R30A4NtFJ2vpLEIk8I1-w%C2%A0" rel="nofollow" title="https://pan.baidu.com/s/18R30A4NtFJ2vpLEIk8I1-w ">https://pan.baidu.com/s/18R30A4NtFJ2vpLEIk8I1-w </a><br> 提取码：b61k</strong></p> 
 <p><strong>提示：以上下载的数据集是已经处理好的，但是如果读者想要标注自己的数据集的话，那么建议在标注数据集的同时，文件的存放结构按照如下所示：</strong></p> 
 <ul><li><strong>VOCdevkit</strong> 
   <ul><li><strong>VOC2007</strong> 
     <ul><li><strong>Annotations（存放标注图像之后得到的XML文件）</strong></li><li><strong>ImageSets（包含了存放图像的路径的.txt文件）</strong> 
       <ul><li><strong>​​​​​​​Main</strong> 
         <ul><li><strong>​​​​​​​train.txt</strong></li><li><strong>test.txt</strong></li><li><strong>val.txt</strong></li></ul></li></ul></li><li><strong>JPEGImages（存放相应标注图像的位置.jpg）</strong></li><li><strong>​​​​​​​​​​​​​​labels（运次那个处理数据集的程序之后产生的文件，里面包含了每一张图像对应的txt文件，.txt文件中包含了：[class,cx,cy,w,h]）</strong></li><li><strong>2007_test.txt（包含了用于测试集的图像绝对路径）</strong></li><li><strong>2007_train.txt（包含了用于训练集的图像绝对路径）</strong></li><li><strong>2007_val.txt</strong><strong>（包含了用验证集的图像绝对路径）</strong></li><li><strong>train.all.txt</strong><strong>（包含了所有图像绝对路径）</strong></li><li><strong>train.txt</strong><strong>（包含了用于训练集和验证集的图像绝对路径）</strong></li></ul></li></ul></li></ul> 
 <p><img alt="" height="400" src="https://images2.imgbox.com/4e/7b/8vABNx3E_o.png" width="1160"></p> 
 <p><strong>提示：为什么建议读者按照上方的结构来放置数据集呢，主要是因为在处理数据集的程序中给定的路径就如上方样式所示，而且上面这样的格式也比较清晰。</strong></p> 
</blockquote> 
<h3 id="%EF%BC%882%EF%BC%89%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E9%9B%86">（2）处理数据集</h3> 
<blockquote> 
 <p><strong>提示：该代码看起来有一点长，但是读者不要害怕，关键的地方都做了说明，并且很容易理解。下面的一部分代码是原本就已经给出的，路径为：</strong></p> 
 <p><img alt="" height="283" src="https://images2.imgbox.com/bc/5e/igz8u6OE_o.png" width="883"></p> 
</blockquote> 
<pre><code class="hljs">import os
import pickle
import random
import numpy as np
from PIL import Image
from os.path import join
from os import listdir, getcwd
import xml.etree.ElementTree as ET

import cv2

# sets=[('2012', 'train'), ('2012', 'val'), ('2007', 'train'), ('2007', 'val'), ('2007', 'test')]

# classes = ["aeroplane", "bicycle", "bird", "boat", "bottle", "bus", "car", "cat", "chair", "cow", "diningtable", "dog", "horse", "motorbike", "person", "pottedplant", "sheep", "sofa", "train", "tvmonitor"]
sets =('2007', 'train'), ('2007', 'val'), ('2007', 'test')
classes = ['face']

#将数据的格式转换为中心坐标以及图像的高宽[cx,cy,w,h]
def convert(size, box):
    dw = 1./(size[0])
    dh = 1./(size[1])
    x = (box[0] + box[1])/2.0 - 1
    y = (box[2] + box[3])/2.0 - 1
    w = box[1] - box[0]
    h = box[3] - box[2]
    x = x*dw
    w = w*dw
    y = y*dh
    h = h*dh
    return (x,y,w,h)

"""
读者XML文件下的相关信息，比如标注的图像中物体的高宽以及图像的尺寸等信息
注意：XML中的得到的框[xmin,ymin,xmax,ymax]表示图像中物体的左上角坐标(xmin,ymin)
和右下角坐标(xmax,ymax)；但是需要将数据的格式转换为中心坐标以及图像的高宽[cx,cy,w,h]
"""
def convert_annotation(year, image_id):
    in_file = open('VOCdevkit/VOC%s/Annotations/%s.xml'%(year, image_id))
    out_file = open('VOCdevkit/VOC%s/labels/%s.txt'%(year, image_id), 'w')
    tree=ET.parse(in_file)
    root = tree.getroot()
    size = root.find('size')
    w = int(size.find('width').text)
    h = int(size.find('height').text)

    for obj in root.iter('object'):
        difficult = obj.find('difficult').text
        cls = obj.find('name').text
        if cls not in classes or int(difficult)==1:
            continue
        cls_id = classes.index(cls)
        xmlbox = obj.find('bndbox')
        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))
        bb = convert((w,h), b)
        out_file.write(str(cls_id) + " " + " ".join([str(a) for a in bb]) + '\n')


"""
读取文件ImageSets/Main/train.txt，ImageSets/Main/val.txt，ImageSets/Main/test.txt
中的图像的名称，以此来图像的路径+图像名称构成图像的完整路径，读取图像。
"""
def VOC2007():
    wd = getcwd()

    for year, image_set in sets:
        if not os.path.exists('VOCdevkit/VOC%s/labels/'%(year)):
            os.makedirs('VOCdevkit/VOC%s/labels/'%(year))
        image_ids = open('VOCdevkit/VOC%s/ImageSets/Main/%s.txt'%(year, image_set)).read().strip().split()
        list_file = open('%s_%s.txt'%(year, image_set), 'w')
        for image_id in image_ids:
            list_file.write('%s/VOCdevkit/VOC%s/JPEGImages/%s.jpg\n'%(wd, year, image_id))
            convert_annotation(year, image_id)
        list_file.close()

    os.system("cat 2007_train.txt 2007_val.txt 2012_train.txt 2012_val.txt &gt; train.txt")
    os.system("cat 2007_train.txt 2007_val.txt 2007_test.txt 2012_train.txt 2012_val.txt &gt; train.all.txt")

"""
缩放图像的大小到指定图像大小
"""
def resizeImage():
    """
    :return:
    """
    imgPath = r"E:\tempImage"
    imgs_list = os.listdir(imgPath)
    for img_name in imgs_list[:200]:
        img_path = os.path.join(imgPath,img_name)
        img = cv2.imread(img_path)
        newimg = cv2.resize(src = img,dsize=(416,416))
        cv2.imwrite(filename='../myDataset/VOC2007/JPEGImages/'+str(img_name),img = newimg)
    cv2.destroyAllWindows()

"""
由于ImageSets/Main下面并没有存在一下文件
ImageSets/Main/train.txt，ImageSets/Main/val.txt，ImageSets/Main/test.txt
所以需要根据图像，将图像数据集划分为训练集，验证集，测试集，并且将这些数据集的名称存放入
train.txt,val.txt,test.txt文件中
"""
def ImageSets():
    train_val_ratio = 0.8
    val_ratio = 0.1
    test_ratio = 0.1
    xmlfilepath = 'VOCdevkit/VOC2007/Annotations'
    mainPath = 'VOCdevkit/VOC2007/ImageSets/Main'
    if not os.path.exists(mainPath):
        os.makedirs(mainPath)

    xml_list = os.listdir(xmlfilepath)
    total_num = len(xml_list)
    #按其文件名的顺序进行读取
    xml_list.sort(key=lambda x:int(x.split('.')[0]))
    total_range = range(total_num)
    n_train = int(total_num * train_val_ratio)
    n_val = int(total_num * val_ratio)
    n_test = int(total_num * test_ratio)

    # trainPath = os.path.join('VOCdevkit/VOC2007/ImageSets/Main','train')
    # valPath = os.path.join('VOCdevkit/VOC2007/ImageSets/Main','val')
    # testPath = os.path.join('VOCdevkit/VOC2007/ImageSets/Main','test')
    # if not os.path.exists(trainPath):
    #     os.mkdir(trainPath)
    # if not os.path.exists(valPath):
    #     os.mkdir(valPath)
    # if not os.path.exists(testPath):
    #     os.mkdir(testPath)

    train = open('VOCdevkit/VOC2007/ImageSets/Main/train.txt', 'w')
    test = open('VOCdevkit/VOC2007/ImageSets/Main/test.txt', 'w')
    val = open('VOCdevkit/VOC2007/ImageSets/Main/val.txt', 'w')

    for xml_idx in total_range[:n_train]:
        xml_name = xml_list[xml_idx]
        file = xml_name.split('.')[0]+'\n'
        train.write(file)
    for xml_idx in total_range[n_train:n_train + n_val]:
        xml_name = xml_list[xml_idx]
        file= xml_name.split('.')[0]+'\n'
        val.write(file)
    for xml_idx in total_range[n_train+ n_val:total_num]:
        xml_name = xml_list[xml_idx]
        file = xml_name.split('.')[0]+'\n'
        test.write(file)

    train.close()
    test.close()
    val.close()

"""
由于在训练的过程遇到过一个错误，导致不需要8位深的图像转换为24位深的图像
"""
def changeDepthBit():
    path8 = r'VOCdevkit/VOC2007/JPEGImages'
    newpath24 = r'VOCdevkit/VOC2007/ImageDepth24'

    files8 = os.listdir(path8)
    files8.sort(key=lambda x:int(x.split('.')[0]))
    for img_name in files8:
        imgpath = os.path.join(path8,img_name)
        img = Image.open(imgpath).convert('RGB')
        file_name, file_extend = os.path.splitext(img_name)
        dst = os.path.join(newpath24, file_name + '.jpg')
        img.save(dst)


if __name__ == '__main__':
    # resizeImage()
    # ImageSets()
    # VOC2007()
    changeDepthBit()
    pass
</code></pre> 
<p></p> 
<h2 id="3.%E4%BF%AE%E6%94%B9%E7%9B%B8%E5%BA%94%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">3.修改相应的配置文件</h2> 
<h3 id="%EF%BC%881%EF%BC%89%E4%BF%AE%E6%94%B9voc.data%E5%92%8Cvoc.names">（1）修改voc.data和voc.names</h3> 
<blockquote> 
 <p>提示：<strong>将darknet-master-yolov4\darknet-master\build\darknet\x64\data路径下的<span style="color:#fe2c24;">voc.data</span>和<span style="color:#fe2c24;">voc.names</span>拷贝到自己项目的文件目录下。</strong></p> 
</blockquote> 
<blockquote> 
 <p>修改voc.data:</p> 
 <p><img alt="" height="190" src="https://images2.imgbox.com/43/41/aY1ZUxui_o.png" width="908"></p> 
</blockquote> 
<blockquote> 
 <p>修改voc.names：</p> 
 <p><img alt="" height="135" src="https://images2.imgbox.com/ab/4f/BRyPbJo7_o.png" width="539"> </p> 
</blockquote> 
<h3 id="%EF%BC%882%EF%BC%89%E4%BF%AE%E6%94%B9yolov3.cfg%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">（2）修改yolov3.cfg配置文件</h3> 
<blockquote> 
 <p><a class="link-info" href="https://blog.csdn.net/qq_44824148/article/details/120920727" title="详解 yolo配置文件各参数的含义">详解 yolo配置文件各参数的含义</a></p> 
</blockquote> 
<p><img alt="" height="352" src="https://images2.imgbox.com/ff/0f/JtGe7Vo6_o.png" width="939"></p> 
<blockquote> 
 <p><img alt="" height="139" src="https://images2.imgbox.com/e7/de/36uf9VlQ_o.png" width="788"><strong>max_batches修改原则：将行max_batches更改为（classes*2000，但不少于训练图像的数量，且不少于6000），如果您训练了3个类，则f.e.max_batches=6000。 </strong></p> 
</blockquote> 
<blockquote> 
 <p><img alt="" height="348" src="https://images2.imgbox.com/28/92/G8NTG2lt_o.png" width="1104"> <strong>提示：像上面这样的修改有三处需要进行修改，上面给出的只是第一处。需要修改的地方都在是yolo之后和convolutional之后。</strong></p> 
</blockquote> 
<p> </p> 
<h2 id="4.%E4%B8%8B%E8%BD%BD%E6%9D%83%E9%87%8D%E6%96%87%E4%BB%B6">4.下载权重文件</h2> 
<blockquote> 
 <p><a class="link-info" href="https://pjreddie.com/darknet/yolo/" rel="nofollow" title="darknet的官方主页"><strong>darknet的官方主页</strong></a></p> 
 <p><a class="link-info" href="https://pjreddie.com/media/files/darknet53.conv.74" rel="nofollow" title="权重文件下载链接"><strong>权重文件下载链接</strong></a></p> 
</blockquote> 
<p></p> 
<h2 id="5.%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86">5.训练数据集</h2> 
<h3 id="%EF%BC%881%EF%BC%89%E8%AE%AD%E7%BB%83%E5%BC%80%E5%A7%8B">（1）训练开始</h3> 
<blockquote> 
 <p><strong>darknet.exe detector train data/voc.data cfg/yolov3.cfg preTrain/darknet53.conv.74</strong></p> 
 <ul><li><strong>data/voc.data</strong></li><li><strong>cfg/yolov3.cfg</strong></li><li><strong>preTrain/darknet53.conv.74</strong></li></ul> 
</blockquote> 
<p><img alt="" height="446" src="https://images2.imgbox.com/9a/f7/FFRE5Woy_o.png" width="1200"></p> 
<p> </p> 
<h3 id="%EF%BC%882%EF%BC%89%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C">（2）训练结果</h3> 
<p class="img-center"><img alt="" height="338" src="https://images2.imgbox.com/f3/9a/ZYRtoH3N_o.png" width="345"></p> 
<h3 id="%C2%A0%EF%BC%883%EF%BC%89%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C"> （3）测试结果</h3> 
<blockquote> 
 <p><strong>提示：读者可以使用如下链接的代码进行测试：</strong></p> 
 <p><a class="link-info" href="https://mydreamambitious.blog.csdn.net/article/details/125520487" rel="nofollow" title="https://mydreamambitious.blog.csdn.net/article/details/125520487">https://mydreamambitious.blog.csdn.net/article/details/125520487</a></p> 
 <p><strong>或者就使用在介绍关于darknet编译的时候使用的命令进行测试。</strong></p> 
</blockquote> 
<pre><code class="hljs">"""
@Author : Keep_Trying_Go
@Major  : Computer Science and Technology
@Hobby  : Computer Vision
@Time   : 2023/5/24 8:40
"""

import os
import cv2
import numpy as np

#创建窗口
# cv2.namedWindow(winname='detect',flags=cv2.WINDOW_AUTOSIZE)
# cv2.resizeWindow(winname='detect',width=750,height=600)

#读取YOLO-V3权重文件和网络配置文件
net=cv2.dnn.readNet(model='backup/yolov3_final.weights',config='cfg/yolov3.cfg')

#设置置信度阈值和非极大值抑制的阈值
Confidence_thresh=0.2
Nms_thresh=0.35
#读取coco.names文件中的类别
with open('data/voc.names','r') as fp:
    classes=fp.read().splitlines()

#yolo-v3检测
def detect(frame):
    #获取网络模型
    model=cv2.dnn_DetectionModel(net)
    #设置网络的输入参数
    model.setInputParams(scale=1/255,size=(416,416))
    #进行预测
    class_id,scores,boxes=model.detect(frame,confThreshold=Confidence_thresh,
                 nmsThreshold=Nms_thresh)
    #返回预测的类别和坐标
    return class_id,scores,boxes


#实时的检测
def detect_time():
    #开启摄像头 'video/los_angeles.mp4' or 'video/soccer.mp4'
    cap=cv2.VideoCapture(0)

    while cap.isOpened():
        OK,frame=cap.read()
        if not OK:
            break

        frame=cv2.flip(src=frame,flipCode=2)
        # frame=cv2.resize(src=frame,dsize=(416,416))
        #进行预测
        class_ids,scores,boxes=detect(frame)
        #绘制矩形框
        for (class_id,box) in enumerate(boxes):
            (x,y,w,h)=box
            class_name = classes[class_ids[class_id]]
            confidence = scores[class_id]
            confidence=str(round(confidence,2))
            cv2.rectangle(img=frame,pt1=(x,y),pt2=(x+w,y+h),
                          color=(0,255,0),thickness=2)
            text=class_name+' '+confidence
            cv2.putText(img=frame,text=text,
                        org=(x,y-10),fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                        fontScale=1.0,color=(0,255,0),thickness=2)

        cv2.imshow('detect',frame)
        key=cv2.waitKey(1)
        if key==27:
            break

    cap.release()
#单张图片的检测
def signal_detect(image_path='data/2141.png'):
    frame=cv2.imread(image_path)
    frame = cv2.resize(src=frame, dsize=(416, 416))
    # 进行预测
    class_ids, scores, boxes = detect(frame)
    # 绘制矩形框
    for (class_id, box) in enumerate(boxes):
        (x, y, w, h) = box
        class_name = classes[class_ids[class_id]]
        confidence = scores[class_ids[class_id]]
        confidence = str(round(confidence, 2))
        cv2.rectangle(img=frame, pt1=(x, y), pt2=(x + w, y + h),
                      color=(0, 255, 0), thickness=2)
        text = class_name + ' ' + confidence
        cv2.putText(img=frame, text=text,
                    org=(x, y - 10), fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                    fontScale=1.0, color=(0, 255, 0), thickness=2)

    cv2.imshow('detect', frame)
    cv2.waitKey(0)

cv2.destroyAllWindows()


if __name__ == '__main__':
    print('Pycharm')
    # signal_detect()
    detect_time()
</code></pre> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8d010578a22541715ec35f1cfdd1c542/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">通过Maven下载依赖Jar包流程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/96e563b8a9080780f7883839e6742ae3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【4】面试常问：你知道为什么HashMap是线程不安全的吗？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>