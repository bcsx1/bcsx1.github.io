<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>文献速递：生成对抗网络医学影像中的应用——基于CycleGAN的图像到图像转换，用于逼真的外科手术训练模型 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="文献速递：生成对抗网络医学影像中的应用——基于CycleGAN的图像到图像转换，用于逼真的外科手术训练模型" />
<meta property="og:description" content="文献速递：生成对抗网络医学影像中的应用——基于CycleGAN的图像到图像转换，用于逼真的外科手术训练模型 本周给大家分享文献的主题是生成对抗网络（Generative adversarial networks, GANs）在医学影像中的应用。文献的研究内容包括同模态影像生成、跨模态影像生成、GAN在分类和分割方面的应用等。生成对抗网络与其他方法相比展示出了优越的数据生成能力，使它们在医学图像应用中广受欢迎。这些特性引起了医学成像领域研究人员的浓厚兴趣，导致这些技术在各种传统和新颖应用中迅速实施，如图像重建、分割、检测、分类和跨模态合成。
01
文献速递介绍
外科手术训练对于发展技能和灵巧性至关重要。为了获得必要的经验，外科医生需要数千小时的实践。在内窥镜微创手术中，任务更加具有挑战性。为了避免仅与真实病人进行训练，外科医生通常在离体器官、虚拟模拟器或物理训练幻影上发展他们的技能。物理训练幻影为缝合和使用真实仪器操作提供了出色的触觉反馈和组织特性，并且易于获得。此外，它们可以为特定病人解剖定制，并为期望的程序进行优化 。在不同的范围内，外科训练幻影甚至可以用于开发额外的外科应用，如自动外科阶段识别。然而，它们缺乏生命力和不现实的外观，并不反映外科场景的复杂环境 。正如 Engelhardt 等人 所提出的，超现实主义是一种新的增强现实范式，旨在通过将手术过程中的域内模式映射到在这些外科模拟器训练期间捕获的视频流上，解决物理幻影中缺乏现实感的问题。通过生成模型，可以实现从一幅图像到另一幅图像的特征映射。这些生成模型存在不同的方法和概念，即应用变分自编码器（VAE）或生成对抗网络（GANs）。近年来，GANs 在图像合成和图像到图像转换 (I2I) 方面表现出了巨大的潜力 。
最近，已经开发了具有不同架构的几种 GAN 模型，这些架构高度依赖于用作输入的信息类型。对于这种每个域的图像都是未配对的特定域适应任务，CycleGAN 模型已显示出有希望的结果。 本工作的目标是从未配对的合成训练幻影图像生成逼真的二尖瓣术中图像。我们旨在使用 CycleGAN 生成模型实现成功的 I2I 转换，并进行以下实验：
研究最合适的训练损失函数；建立训练和图像质量度量标准，以实现客观和定量的结果评估；评估输入变异性对模型性能的影响。 Title
题目
CycleGAN-Based Image to Image Translation for Realistic SurgicalTraining Phantoms
基于CycleGAN的图像到图像转换，用于逼真的外科手术训练模型
Abstract
摘要
Training in surgery is essential for surgeons to develop skill and dexterity. Physical training phantoms provide excellent haptic feedback and tissue properties for stitching and operating with authentic instruments and are easily available." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/e0c664b2c8f7eb7e51ea179b8f9abbc0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-22T17:00:47+08:00" />
<meta property="article:modified_time" content="2023-12-22T17:00:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">文献速递：生成对抗网络医学影像中的应用——基于CycleGAN的图像到图像转换，用于逼真的外科手术训练模型</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="CycleGAN_0"></a>文献速递：生成对抗网络医学影像中的应用——基于CycleGAN的图像到图像转换，用于逼真的外科手术训练模型</h2> 
<p>本周给大家分享文献的主题是生成对抗网络（Generative adversarial networks, GANs）在医学影像中的应用。文献的研究内容包括同模态影像生成、跨模态影像生成、GAN在分类和分割方面的应用等。生成对抗网络与其他方法相比展示出了优越的数据生成能力，使它们在医学图像应用中广受欢迎。这些特性引起了医学成像领域研究人员的浓厚兴趣，导致这些技术在各种传统和新颖应用中迅速实施，如图像重建、分割、检测、分类和跨模态合成。</p> 
<p><strong>01</strong></p> 
<p><strong>文献速递介绍</strong></p> 
<p>外科手术训练对于发展技能和灵巧性至关重要。为了获得必要的经验，外科医生需要数千小时的实践。在内窥镜微创手术中，任务更加具有挑战性。为了避免仅与真实病人进行训练，外科医生通常在离体器官、虚拟模拟器或物理训练幻影上发展他们的技能。物理训练幻影为缝合和使用真实仪器操作提供了出色的触觉反馈和组织特性，并且易于获得。此外，它们可以为特定病人解剖定制，并为期望的程序进行优化 。在不同的范围内，外科训练幻影甚至可以用于开发额外的外科应用，如自动外科阶段识别。然而，它们缺乏生命力和不现实的外观，并不反映外科场景的复杂环境 。正如 Engelhardt 等人 所提出的，超现实主义是一种新的增强现实范式，旨在通过将手术过程中的域内模式映射到在这些外科模拟器训练期间捕获的视频流上，解决物理幻影中缺乏现实感的问题。通过生成模型，可以实现从一幅图像到另一幅图像的特征映射。这些生成模型存在不同的方法和概念，即应用变分自编码器（VAE）或生成对抗网络（GANs）。近年来，GANs 在图像合成和图像到图像转换 (I2I) 方面表现出了巨大的潜力 。</p> 
<p>最近，已经开发了具有不同架构的几种 GAN 模型，这些架构高度依赖于用作输入的信息类型。对于这种每个域的图像都是未配对的特定域适应任务，CycleGAN 模型已显示出有希望的结果。 本工作的目标是从未配对的合成训练幻影图像生成逼真的二尖瓣术中图像。我们旨在使用 CycleGAN 生成模型实现成功的 I2I 转换，并进行以下实验：</p> 
<ol><li>研究最合适的训练损失函数；</li><li>建立训练和图像质量度量标准，以实现客观和定量的结果评估；</li><li>评估输入变异性对模型性能的影响。</li></ol> 
<p><strong>Title</strong></p> 
<p><strong>题目</strong></p> 
<p><em>CycleGAN-Based Image to Image Translation for Realistic SurgicalTraining Phantoms</em></p> 
<p>基于CycleGAN的图像到图像转换，用于逼真的外科手术训练模型</p> 
<p><strong>Abstract</strong></p> 
<p><strong>摘要</strong></p> 
<p><em>Training in surgery is essential for surgeons to</em> <em>develop skill and dexterity. Physical training phantoms provide excellent haptic feedback and tissue properties for stitching and operating with authentic instruments and are easily available.</em> <em>However, they lack realistic traits and fail to reflect the complex environment of a surgical scene. Generative Adversarial Networks can be used for image-to-image translation,addressing the lack of realism in physical phantoms, by mapping</em> <em>patterns from the intraoperative domain onto the video stream captured during training with these surgical simulators. This work aims to achieve a successful I2I translation, from intra</em></p> 
<p><em>operatory mitral valve surgery images onto a surgical simulator,using the CycleGAN model. Different experiments are performed - comparing the Mean Square Error Loss with the Binary Cross Entropy Loss; validating the Fréchet Inception</em> <em>Distance as a training and image quality metric; and studying the impact of input variability on the model performance.Differences between .</em></p> 
<p><em>MSE and BCE are modest, with MSE being marginally more robust. The FID score proves to be very useful</em> <em>in identifying the best training epochs for the CycleGAN I2I translation architecture. Carefully selecting the input images**can have a great impact in the end results. Using less style variability and input images with good feature details and clearly defined characteristics enables the network to achieve better results.</em></p> 
<p><em>Clinical Relevance— This work further contributes for the</em> <em>domain of realistic surgical training, successfully generating fake intra operatory images from a surgical simulator of thecardiac mitral valve.</em></p> 
<p>外科手术训练对于外科医生培养技能和灵巧性至关重要。物理训练模型提供了极佳的触感反馈和缝合以及使用真实器械操作的组织特性，并且容易获得。然而，它们缺乏逼真的特质，无法反映外科手术现场的复杂环境。生成对抗网络可用于图像到图像的转换，通过将术中领域的模式映射到在这些外科模拟器训练期间捕获的视频流中，解决物理模型缺乏现实感的问题。这项工作旨在使用CycleGAN模型实现从术中二尖瓣手术图像到外科模拟器的成功I2I（Image-to-Image）转换。进行了不同的实验 - 比较均方误差损失与二元交叉熵损失；验证Fréchet Inception Distance作为训练和图像质量指标；以及研究输入变异性对模型性能的影响。</p> 
<p>MSE和BCE之间的差异较小，MSE略微更加稳健。FID得分在确定CycleGAN I2I转换架构的最佳训练时期方面非常有用。仔细选择输入图像可以对最终结果产生很大影响。使用风格变异性较小且输入图像具有良好特征细节和清晰定义的特征可以使网络取得更好的结果。</p> 
<p>临床相关性 - 这项工作为逼真的外科手术训练领域做出了进一步的贡献，成功地从心脏二尖瓣的外科模拟器生成了虚假的术中图像。</p> 
<p><strong>Methods</strong></p> 
<p><strong>方法</strong></p> 
<p><em>A. Image to Image translation using CycleGAN</em> <em>The goal of I2I is to convert an input image from a source domain A to a target domain B. Ideally the extrinsic target style (domain specific features) should be transferred withoutaltering the inherent physical content of the source domain.</em></p> 
<p>A. 使用 CycleGAN 进行图像到图像的转换 图像到图像转换的目标是将输入图像从源域 A 转换到目标域 B。理想情况下，应该转换外在的目标风格（特定于域的特征），而不改变源域的固有物理内容。</p> 
<p><strong>Results</strong></p> 
<p><strong>结果</strong></p> 
<p><em>Figure 3 displays some of the results obtained with the previously described experiments. Three frames from the validation data set were selected based on the presence of specific attributes, such as surgical instruments in a large area of the image, suture wires with different colors and clear contact points with the phantom and, finally, a frame in which</em> <em>the surgical wires overlap with the surgical instrument. The image shows the best and worst FID results for both MSE and BCE losses, from all training epochs.</em></p> 
<p><em>The final experiment results, comparing the performance of the GAN with one single surgical style input, are shown in Figure 4. The same frames were used in order to enable a better</em></p> 
<p><em>comparison with the experiments with 3 surgical styles. Again, the best and worst FID results for both MSE and BCE losses, from all training epochs, are displayed.</em></p> 
<p>图3展示了之前描述实验中获得的一些结果。根据特定属性的存在，从验证数据集中选择了三个帧，例如手术工具占据大面积的图像、不同颜色的缝合线和与幻影明显接触的点，以及手术线与手术工具重叠的一个帧。该图像显示了MSE和BCE损失下的所有训练周期中最佳和最差的FID结果。</p> 
<p>最终实验结果，比较了仅使用单一手术风格输入的GAN的性能，在图4中展示。为了更好地与使用3种手术风格的实验进行比较，使用了相同的帧。同样，展示了MSE和BCE损失下的所有训练周期中最佳和最差的FID结果。</p> 
<p><strong>Conclusions</strong></p> 
<p><strong>结论</strong></p> 
<p><em>MSE Loss is more stable than BCE Loss as, usually, better results are achieved, in a fewer number of epochs. The FID score proves be very useful in identifying the best training epochs for the CycleGAN I2I translation architecture. Carefully selecting the input images can cause a big impact on the end results. Images can be from multiple domains, however using images, with good feature details and clearly defined characteristics, enables the network to achieve better results. Not using sets of images that feature specific instruments, that do not appear in the simulator domain, further potentiates the network performance.</em></p> 
<p>与BCE损失相比，MSE损失更稳定，通常在较少的训练周期内就能达到更好的结果。FID得分在识别CycleGAN图像到图像（I2I）翻译架构的最佳训练周期方面证明非常有用。仔细选择输入图像可以对最终结果产生重大影响。图像可以来自多个领域，但使用具有良好特征细节和清晰定义特性的图像，可以使网络获得更好的结果。不使用特定仪器的图像集，这些仪器在模拟器领域中不出现，进一步增强了网络性能。</p> 
<p><strong>Figure</strong></p> 
<p><strong>图</strong></p> 
<p><img src="https://images2.imgbox.com/14/1a/fDAI7PuQ_o.png" alt="图片"></p> 
<p><em>Figure 1 - CycleGAN architecture. The Generator network path is represented in blue and the Discriminator in yellow. Cycle loss is schematized in orange, with a backward flow. The identity loss input is shown in green.</em></p> 
<p>图1 - CycleGAN架构。生成器网络路径用蓝色表示，判别器用黄色表示。循环损失用橙色示意，带有反向流动。身份损失输入用绿色显示。</p> 
<p><img src="https://images2.imgbox.com/6b/ba/5vKPA5bs_o.png" alt="图片"></p> 
<p><em>Figure 2 - Samples of the training dataset. 3 surgical styles are used,numbered 1 to 3 from top to bottom.</em></p> 
<p>图2 - 训练数据集的样本。使用了3种手术风格，从上到下编号为1至3。</p> 
<p><img src="https://images2.imgbox.com/b9/eb/38oOGv0C_o.png" alt="图片"></p> 
<p><em>Figure 3 - Selection of images to show the obtained results for both losses.<strong>Top row: original phantom image. 2nd and 3rd rows: best and worst FID</strong>scores for MSE, respectively. 4th and 5th rows: best and worst FID scores for BCE, respectively.</em></p> 
<p>图3 - 选择图像以显示两种损失所获得的结果。</p> 
<p>顶部行：原始幻影图像。第2和第3行：分别为MSE的最佳和最差FID得分。第4和第5行：分别为BCE的最佳和最差FID得分。</p> 
<p><img src="https://images2.imgbox.com/05/d4/w5BlpXM6_o.png" alt="图片"></p> 
<p><em>Figure 4 - Selection of images to show the obtained results using only surgical style 3 as input. Top row: original phantom image. 2nd and 3rd</em><br> rows: best and worst FID scores for MSE, respectively. 4th and 5th rows: best and worst FID scores for BCE, respectively.*</p> 
<p>图4 - 选择图像以显示仅使用手术风格3作为输入获得的结果。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8f43c7adbb9d3b97650fb2318577d322/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">STM32 基础知识（探索者开发板）--93讲 PWM</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/27f3845fd66586348ed11510d761a2b9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">大象机器人发布万元级水星Mercury人形机器人产品系列，联结未来，一触即达！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>