<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【paddleGAN学习笔记】PaddlePaddle框架 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【paddleGAN学习笔记】PaddlePaddle框架" />
<meta property="og:description" content="文章目录 PaddlePaddle简介PaddlePaddle GPU版本安装使用PaddlePaddle做线性回归使用paddlepaddle解决MNIST问题Step1:准备数据Step2:配置网络Step3:模型训练Step4:模型评估Step5:模型预测 参考 PaddlePaddle简介 PaddlePaddle（飞浆）是百度开发的国产深度学习框架。用PaddlePaddle的好处是可以用AI Studio平台提供的GPU算力进行模型训练，不仅节约时间而且还是免费的。PaddlePaddle也提供了像PaddleSeg等一些套件，对于新手上手深度学习模型的项目很友好。 PaddlePaddle GPU版本安装 Step1：创建虚拟环境
conda create -n paddle_gpu python=3.7 Step2：进入创建的环境。
activate paddle_gpu
Step3：安装paddlepaddle（GPU版本），CUDA10.1以及与之配套的cuDNN。
conda install paddlepaddle-gpu==2.2.2 cudatoolkit=10.1 --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle/
出现“done”，说明安装完成。
（CPU版）“conda install paddlepaddle==2.2.2 --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle/”
Step4：测试是否安装成功。
依次输入python，import paddle，paddle.utils.run_check()
使用PaddlePaddle做线性回归 ① 引入库
import paddle import numpy as np paddle.__version__ ‘2.2.2’
② 定义训练和测试数据
# 定义训练和测试数据 x_data = np.array([[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.0, 0.0, 0.0, 0.0, 0.0, 0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/97bd7de4ae5fe0bcdabdcdb9c681d191/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-19T20:13:50+08:00" />
<meta property="article:modified_time" content="2022-05-19T20:13:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【paddleGAN学习笔记】PaddlePaddle框架</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#PaddlePaddle_4" rel="nofollow">PaddlePaddle简介</a></li><li><a href="#PaddlePaddle_GPU_10" rel="nofollow">PaddlePaddle GPU版本安装</a></li><li><a href="#PaddlePaddle_28" rel="nofollow">使用PaddlePaddle做线性回归</a></li><li><a href="#paddlepaddleMNIST_129" rel="nofollow">使用paddlepaddle解决MNIST问题</a></li><li><ul><li><a href="#Step1_131" rel="nofollow">Step1:准备数据</a></li><li><a href="#Step2_165" rel="nofollow">Step2:配置网络</a></li><li><a href="#Step3_208" rel="nofollow">Step3:模型训练</a></li><li><a href="#Step4_218" rel="nofollow">Step4:模型评估</a></li><li><a href="#Step5_225" rel="nofollow">Step5:模型预测</a></li></ul> 
  </li><li><a href="#_239" rel="nofollow">参考</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="PaddlePaddle_4"></a>PaddlePaddle简介</h2> 
<ul><li>PaddlePaddle（飞浆）是百度开发的国产深度学习框架。</li><li>用PaddlePaddle的好处是可以用AI Studio平台提供的GPU算力进行模型训练，不仅节约时间而且还是免费的。</li><li>PaddlePaddle也提供了像PaddleSeg等一些套件，对于新手上手深度学习模型的项目很友好。</li></ul> 
<hr> 
<h2><a id="PaddlePaddle_GPU_10"></a>PaddlePaddle GPU版本安装</h2> 
<p>Step1：创建虚拟环境<br> <code>conda create -n paddle_gpu python=3.7 </code></p> 
<p>Step2：进入创建的环境。<br> <code>activate paddle_gpu</code></p> 
<p>Step3：安装paddlepaddle（GPU版本），CUDA10.1以及与之配套的cuDNN。<br> <code>conda install paddlepaddle-gpu==2.2.2 cudatoolkit=10.1 --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle/</code><br> 出现“done”，说明安装完成。</p> 
<blockquote> 
 <p>（CPU版）“conda install paddlepaddle==2.2.2 --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/Paddle/”</p> 
</blockquote> 
<p>Step4：测试是否安装成功。<br> 依次输入<code>python</code>，<code>import paddle</code>，<code>paddle.utils.run_check()</code></p> 
<p><img src="https://images2.imgbox.com/f1/a8/3zH6nSDt_o.png" alt="安装成功"></p> 
<hr> 
<h2><a id="PaddlePaddle_28"></a>使用PaddlePaddle做线性回归</h2> 
<p><strong>① 引入库</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> paddle
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

paddle<span class="token punctuation">.</span>__version__
</code></pre> 
<blockquote> 
 <p>‘2.2.2’</p> 
</blockquote> 
<p><strong>② 定义训练和测试数据</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># 定义训练和测试数据</span>
x_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                   <span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                   <span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                   <span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                   <span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
y_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">7.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">11.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
test_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">6.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>定义一个简单的线性网络，这个网络非常简单，结构是：</li></ul> 
<center>
  [输入层] --&gt; [隐层] --&gt; [激活函数] --&gt; [输出层] 
</center> 
<p></p> 
<ul><li> <p>更具体的就是一个输出大小为100的全连接层、之后接激活函数ReLU和一个输出大小为1的全连接层，就这样构建了一个非常简单的网络。</p> </li><li> <p>这里定义输入层的形状为13，这是因为波士顿房价数据集的每条数据有13个属性，我们之后自定义的数据集也是为了符合这一个维度。</p> </li></ul> 
<p><strong>③ 定义一个简单的线性网络</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># 定义一个简单的线性网络</span>
net <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre> 
<ul><li>接着是定义训练使用的优化方法，这里使用的是<code>随机梯度下降</code>优化方法。</li><li>PaddlePaddle提供了大量的优化函数接口，除了本项目使用的随机梯度下降法（SGD），还有Momentum、Adagrad等等。</li></ul> 
<p><strong>④ 定义优化方法</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># 定义优化方法</span>
optimizer <span class="token operator">=</span> paddle<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> parameters<span class="token operator">=</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>这次训练了10个pass，可根据情况设置更多的训练轮数，通常来说训练的次数和模型收敛有一定的关系。</li><li>因为本项目是一个线性回归任务，所以我们在训练的时候使用的是平方差损失函数。</li><li>因为<code>paddle.nn.functional.square_error_cost</code>求的是一个Batch的损失值，所以我们还要对他求一个平均值。</li><li>PaddlePaddle提供了很多的损失函数的接口，比如交叉熵损失函数<code>paddle.nn.CrossEntropyLoss</code>。</li><li>在训练过程中，我们可以看到输出的损失值在不断减小，证明我们的模型在不断收敛。</li></ul> 
<p><strong>⑤ 开始训练</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># 将numpy类型数据转换成tensor之后才能用于模型训练</span>
inputs <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>x_data<span class="token punctuation">)</span>
labels <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>y_data<span class="token punctuation">)</span>

<span class="token comment"># 开始训练100个pass</span>
<span class="token keyword">for</span> pass_id <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    out <span class="token operator">=</span> net<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> paddle<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>square_error_cost<span class="token punctuation">(</span>out<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">)</span>

    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>clear_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Pass:%d, Cost:%0.5f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>pass_id<span class="token punctuation">,</span> loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>Pass:0, Cost:0.02406<br> Pass:1, Cost:0.02354<br> Pass:2, Cost:0.02302<br> Pass:3, Cost:0.02252<br> Pass:4, Cost:0.02202<br> Pass:5, Cost:0.02154<br> Pass:6, Cost:0.02107<br> Pass:7, Cost:0.02061<br> Pass:8, Cost:0.02016<br> Pass:9, Cost:0.01972</p> 
</blockquote> 
<p>loss.backward()是将损失loss 向输入侧进行反向传播。<br> optimizer.step()是优化器对x的值进行更新。<br> optimizer.zero_grad()清除了优化器中所有x的x.grad。</p> 
<p>训练完成之后，我们使用上面克隆主程序得到的预测程序了预测我们刚才定义的预测数据。根据我们上面定义数据时，满足规律y = 2 * x + 1，所以当x为6时，y应该时13，最后输出的结果也是应该接近13的。</p> 
<p><strong>⑥ 开始预测</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># 开始预测</span>
predict_inputs <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>test_data<span class="token punctuation">)</span>
result <span class="token operator">=</span> net<span class="token punctuation">(</span>predict_inputs<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"当x为6.0时，y为：%0.5f"</span> <span class="token operator">%</span> result<span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>当x为6.0时，y为：13.21323</p> 
</blockquote> 
<hr> 
<h2><a id="paddlepaddleMNIST_129"></a>使用paddlepaddle解决MNIST问题</h2> 
<h3><a id="Step1_131"></a>Step1:准备数据</h3> 
<p>1.MINIST数据集包含60000个训练集和10000测试数据集。分为图片和标签，图片是28*28的像素矩阵，标签为0~9共10个数字。</p> 
<p>2.使用飞桨内置数据集 <code>paddle.vision,datasets.MNIST</code> 定义MNIST数据集的 <code>train_dataset</code> 和 t<code>est_dataset</code>。</p> 
<p>3.使用 <code>Normalize</code> 接口对图片进行归一化。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> paddle
<span class="token keyword">from</span> paddle<span class="token punctuation">.</span>vision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> Normalize

transform <span class="token operator">=</span> Normalize<span class="token punctuation">(</span>mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">127.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                               std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">127.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                               data_format<span class="token operator">=</span><span class="token string">'CHW'</span><span class="token punctuation">)</span>
<span class="token comment"># 使用transform对数据集做归一化</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'download training data and load training data'</span><span class="token punctuation">)</span>
train_dataset <span class="token operator">=</span> paddle<span class="token punctuation">.</span>vision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>mode<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> paddle<span class="token punctuation">.</span>vision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>mode<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'load finished'</span><span class="token punctuation">)</span>
</code></pre> 
<p>取一条数据，观察一下mnist数据集</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

train_data0<span class="token punctuation">,</span> train_label_0 <span class="token operator">=</span> train_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>train_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
train_data0 <span class="token operator">=</span> train_data0<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>train_data0<span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>binary<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train_data0 label is: '</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>train_label_0<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="Step2_165"></a>Step2:配置网络</h3> 
<p>以下的代码判断就是定义一个简单的多层感知器，一共有三层，两个大小为100的隐层和一个大小为10的输出层，因为MNIST数据集是手写0到9的灰度图像，类别有10个，所以最后的输出大小是10。最后输出层的激活函数是<code>softmax</code>，所以最后的输出层相当于一个分类器。加上一个输入层的话，多层感知器的结构是：输入层–&gt;&gt;隐层–&gt;&gt;隐层–&gt;&gt;输出层。</p> 
<pre><code class="prism language-python"><span class="token comment"># 定义多层感知机</span>
<span class="token keyword">class</span> <span class="token class-name">MultilayerPerceptron</span><span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MultilayerPerceptron<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 形状变换，将数据形状从 [] 变为 []</span>
        self<span class="token punctuation">.</span>flatten <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 第一个全连接层</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>in_features<span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
        <span class="token comment"># 使用ReLU激活函数</span>
        self<span class="token punctuation">.</span>act1 <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 第二个全连接层</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
        <span class="token comment"># 使用ReLU激活函数</span>
        self<span class="token punctuation">.</span>act2 <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 第三个全连接层</span>
        self<span class="token punctuation">.</span>linear3 <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># x = x.reshape((-1, 1, 28, 28))</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>act1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>act2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
<span class="token comment"># 使用 paddle.Model 封装 MultilayerPerceptron</span>
model <span class="token operator">=</span> paddle<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>MultilayerPerceptron<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 使用 summary 打印模型结构</span>
model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>配置模型，指定模型训练时所使用的优化算法与损失函数，这里也可以定义计算精度相关的API。</p> 
<pre><code class="prism language-python"><span class="token comment"># 配置模型</span>
model<span class="token punctuation">.</span>prepare<span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>parameters<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 使用Adam算法进行优化</span>
              paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># 使用CrossEntropyLoss 计算损失</span>
              paddle<span class="token punctuation">.</span>metric<span class="token punctuation">.</span>Accuracy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 使用Accuracy 计算精度</span>
</code></pre> 
<h3><a id="Step3_208"></a>Step3:模型训练</h3> 
<p>在<code>prepare</code> 配置好模型训练的相关算法后，调用<code>fit</code>接口，指定训练的数据集，训练的轮数以及数据的<code>batch_size</code>，可以完成模型的训练。</p> 
<pre><code class="prism language-python"><span class="token comment"># 开始模型训练</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> <span class="token comment"># 设置训练数据集</span>
          epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>      <span class="token comment"># 设置训练轮数</span>
          batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token comment"># 设置 batch_size</span>
          verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>     <span class="token comment"># 设置日志打印格式</span>
</code></pre> 
<h3><a id="Step4_218"></a>Step4:模型评估</h3> 
<p>调用<code>evaluate</code>接口并传入验证集。这里我们使用测试集作为验证集。</p> 
<pre><code class="prism language-python">model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="Step5_225"></a>Step5:模型预测</h3> 
<p>调用 <code>predict</code> 接口并传入测试集。</p> 
<pre><code class="prism language-python">results <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_dataset<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 获取概率最大的label</span>
lab <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>results<span class="token punctuation">)</span>                               <span class="token comment">#argsort函数返回的是result数组值从小到大的索引值</span>
<span class="token comment"># print(lab)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"该图片的预测结果的label为: %d"</span> <span class="token operator">%</span> lab<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment">#-1代表读取数组中倒数第一列  </span>
</code></pre> 
<h2><a id="_239"></a>参考</h2> 
<p><a href="https://aistudio.baidu.com/aistudio/projectdetail/4047710" rel="nofollow">【飞桨 AI studio】PaddlePaddle快速入门</a><br> <a href="https://aistudio.baidu.com/aistudio/projectdetail/4048215" rel="nofollow">【飞桨 AI studio】什么是深度学习</a><br> <a href="https://blog.csdn.net/weixin_42855758/article/details/122915076">【CSDN 社区】「基QI学习」的原创文章-深度学习框架安装(Tensorflow&amp;PyTorch&amp;PaddlePaddle）</a></p> 
<hr>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b607f904ce8b12ac3511f5cee09ed93f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">输入学生学号、成绩，并排序</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ec03b403ccae3a35b7752fb451a0a030/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">排序算法——希尔排序</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>