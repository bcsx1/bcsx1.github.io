<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【时间序列】使用 Auto-TS 自动化时间序列预测 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【时间序列】使用 Auto-TS 自动化时间序列预测" />
<meta property="og:description" content="Auto-TS 是 AutoML 的一部分，它将自动化机器学习管道的一些组件。这自动化库有助于非专家训练基本的机器学习模型，而无需在该领域有太多知识。在本文中，小编和你一起学习如何使用 Auto-TS 库自动执行时间序列预测模型。
什么是自动 TS？ 它是一个开源 Python 库，主要用于自动化时间序列预测。它将使用一行代码自动训练多个时间序列模型，这将帮助我们为我们的问题陈述选择最好的模型。
在 python 开源库 Auto-TS 中，auto-ts.Auto_TimeSeries() 使用训练数据调用的主要函数。然后我们可以选择想要的模型类型，例如 stats、ml 或FB prophet-based models （基于 FB 先知的模型）。我们还可以调整参数，这些参数将根据我们希望它基于的评分参数自动选择最佳模型。它将返回最佳模型和一个字典，其中包含提到的预测周期数的预测（默认值 = 2）。
Auto_timeseries 是用于时间序列数据的复杂模型构建实用程序。由于它自动化了复杂工作中涉及的许多任务，因此它假定了许多智能默认值。5.但是我们可以改变它们。Auto_Timeseries 将基于 Statsmodels ARIMA、Seasonal ARIMA 和 Scikit-Learn ML 快速构建预测模型。它将自动选择给出指定最佳分数的最佳模型。
Auto_TimeSeries 能够帮助我们使用 ARIMA、SARIMAX、VAR、可分解（趋势&#43;季节性&#43;残差）模型和集成机器学习模型等技术构建和选择多个时间序列模型。
Auto-TS 库的特点 它使用遗传规划优化找到最佳时间序列预测模型。
它训练普通模型、统计模型、机器学习模型和深度学习模型，具有所有可能的超参数配置和交叉验证。
它通过学习最佳 NaN 插补和异常值去除来执行数据转换以处理杂乱的数据。
选择用于模型选择的指标组合。
安装 pip install auto-ts # 或 pip install git&#43;git://github.com/AutoViML/Auto_TS 依赖包，如下依赖包需要提前安装 dask scikit-learn FB Prophet statsmodels pmdarima XGBoost 导入库 from auto_ts import auto_timeseries 巨坑警告 根据上述安装步骤安装成功后，很大概率会出现这样的错误：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/949f69001fc73939801f0c9a69965408/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-05T12:00:00+08:00" />
<meta property="article:modified_time" content="2022-03-05T12:00:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【时间序列】使用 Auto-TS 自动化时间序列预测</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p>Auto-TS 是 AutoML 的一部分，它将自动化机器学习管道的一些组件。这自动化库有助于非专家训练基本的机器学习模型，而无需在该领域有太多知识。在本文中，小编和你一起学习如何使用 Auto-TS 库自动执行时间序列预测模型。<br></p> 
 <h3>什么是自动 TS？</h3> 
 <p>它是一个开源 Python 库，主要用于自动化时间序列预测。它将使用一行代码自动训练多个时间序列模型，这将帮助我们为我们的问题陈述选择最好的模型。</p> 
 <p>在 python 开源库 Auto-TS 中，<code>auto-ts.Auto_TimeSeries() </code> 使用训练数据调用的主要函数。然后我们可以选择想要的模型类型，例如 stats、ml 或FB prophet-based models （基于 FB 先知的模型）。我们还可以调整参数，这些参数将根据我们希望它基于的评分参数自动选择最佳模型。它将返回最佳模型和一个字典，其中包含提到的预测周期数的预测（默认值 = 2）。</p> 
 <p>Auto_timeseries 是用于时间序列数据的复杂模型构建实用程序。由于它自动化了复杂工作中涉及的许多任务，因此它假定了许多智能默认值。5.但是我们可以改变它们。Auto_Timeseries 将基于 Statsmodels ARIMA、Seasonal ARIMA 和 Scikit-Learn ML 快速构建预测模型。它将自动选择给出指定最佳分数的最佳模型。</p> 
 <p>Auto_TimeSeries 能够帮助我们使用 ARIMA、SARIMAX、VAR、可分解（趋势+季节性+残差）模型和集成机器学习模型等技术构建和选择多个时间序列模型。</p> 
 <h3>Auto-TS 库的特点</h3> 
 <ul><li><p style="text-align:left;">它使用遗传规划优化找到最佳时间序列预测模型。</p></li><li><p style="text-align:left;">它训练普通模型、统计模型、机器学习模型和深度学习模型，具有所有可能的超参数配置和交叉验证。</p></li><li><p style="text-align:left;">它通过学习最佳 NaN 插补和异常值去除来执行数据转换以处理杂乱的数据。</p></li><li><p style="text-align:left;">选择用于模型选择的指标组合。</p></li></ul> 
 <h4>安装</h4> 
 <pre class="has"><code class="language-go">pip install auto-ts  # 或
pip install git+git://github.com/AutoViML/Auto_TS</code></pre> 
 <h5>依赖包，如下依赖包需要提前安装</h5> 
 <pre class="has"><code class="language-go">dask
scikit-learn
FB Prophet
statsmodels
pmdarima
XGBoost</code></pre> 
 <h4>导入库</h4> 
 <pre class="has"><code class="language-go">from auto_ts import auto_timeseries</code></pre> 
 <h4>巨坑警告</h4> 
 <p>根据上述安装步骤安装成功后，很大概率会出现这样的错误：</p> 
 <pre class="has"><code class="language-go">Running setup.py clean for fbprophet
Failed to build fbprophet
Installing collected packages: fbprophet
  Running setup.py install for fbprophet ... error
 ......
  from pystan import StanModel
ModuleNotFoundError: No module named 'pystan'</code></pre> 
 <p>这个时候你会装pystan:<code>pip install pystan </code>。安装完成后，还是会出现上述报错。如果你也出现了如上情况，不要慌，云朵君已经帮你踩过坑了。</p> 
 <p>参考解决方案：(Mac/anaconda)</p> 
 <h5>1. 安装 Ephem：</h5> 
 <pre class="has"><code class="language-go">conda install -c anaconda ephem</code></pre> 
 <img src="https://images2.imgbox.com/a7/e2/hUvG3Crj_o.png" alt="db479bd9c89caaa02edae87dd0b4c53d.png"> 
 <h5>2. 安装 Pystan：</h5> 
 <pre class="has"><code class="language-go">conda install -c conda-forge pystan</code></pre> 
 <img src="https://images2.imgbox.com/55/33/PuuLcAk9_o.png" alt="f1dd78bae24f338a9c7475610ca4f41f.png"> 
 <h5>3. 安装 Fbprophet：</h5> 
 <p>（这个会花费4小时+）</p> 
 <pre class="has"><code class="language-go">conda install -c conda-forge fbprophet</code></pre> 
 <h5>4. 最后安装：</h5> 
 <pre class="has"><code class="language-go">pip install prophet
pip install fbprophet</code></pre> 
 <h5>5. 最后直到出现：</h5> 
 <pre class="has"><code class="language-go">Successfully installed cmdstanpy-0.9.5 fbprophet-0.7.1 holidays-0.13</code></pre> 
 <p>如果上述还不行，你先尝试重启anaconda，如果还不行，则需要先安装：</p> 
 <pre class="has"><code class="language-go">conda install gcc</code></pre> 
 <p>再上述步骤走一遍。</p> 
 <p><strong>上述过程可能要花费1天时间！！</strong></p> 
 <p>最后尝试导入，成功！</p> 
 <pre class="has"><code class="language-go">from auto_ts import auto_timeseries</code></pre> 
 <pre class="has"><code class="language-go">Imported auto_timeseries version:0.0.65. Call by using:
model = auto_timeseries(score_type='rmse', 
time_interval='M', 
non_seasonal_pdq=None, 
seasonality=False,        
seasonal_period=12, 
model_type=['best'], 
verbose=2, 
dask_xgboost_flag=0)
model.fit(traindata, 
ts_column,target)
model.predict(testdata, model='best')</code></pre> 
 <h4><strong>auto_timeseries 中可用的参数</strong></h4> 
 <pre class="has"><code class="language-go">model = auto_timeseries(
score_type='rmse', 
time_interval='Month',
non_seasonal_pdq=None,
seasonity=False,
season_period=12,  
model_type=['Prophet'],verbose=2)</code></pre> 
 <p>可以调整参数并分析模型性能的变化。有关参数的更多详细信息参考auto-ts文档<sup>[1]</sup>。</p> 
 <h4>使用的数据集</h4> 
 <p>本文使用了从 Kaggle 下载的 2006 年 1 月至 2018 年 1 月的亚马逊股票价格<sup>[2]</sup>数据集。该库仅提供训练时间序列预测模型。数据集应该有一个时间或日期格式列。</p> 
 <p><strong>最初，使用时间/日期列加载时间序列数据集：</strong></p> 
 <pre class="has"><code class="language-go">df = pd.read_csv(
    "Amazon_Stock_Price.csv", 
    usecols=['Date', 'Close'])
df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date')</code></pre> 
 <p><strong>现在，将整个数据拆分为训练数据和测试数据：</strong></p> 
 <pre class="has"><code class="language-go">train_df = df.iloc[:2800]
test_df = df.iloc[2800:]</code></pre> 
 <p><strong>现在，我们将可视化拆分训练测试：</strong></p> 
 <pre class="has"><code class="language-go">train_df.Close.plot(
      figsize=(15,8), 
      title= 'AMZN Stock Price', fontsize=14, 
      label='Train')
test_df.Close.plot(
      figsize=(15,8), 
      title= 'AMZN Stock Price', fontsize=14, 
      label='Test')</code></pre> 
 <img src="https://images2.imgbox.com/74/15/2vVs6KgM_o.png" alt="33b635b502ec226e1d58071961fb2caa.png"> 
 <p><strong>现在，让我们初始化 Auto-TS 模型对象，并拟合训练数据：</strong></p> 
 <pre class="has"><code class="language-go">model = auto_timeseries(
  forecast_period=219, 
  score_type='rmse', 
  time_interval='D', 
  model_type='best')
model.fit(traindata= train_df,
    ts_column="Date",
    target="Close")</code></pre> 
 <p><strong>现在让我们比较不同模型的准确率：</strong></p> 
 <pre class="has"><code class="language-go">model.get_leaderboard()
model.plot_cv_scores()</code></pre> 
 <p>得到如下结果：</p> 
 <p>Start of Fit.....</p> 
 <p>    Target variable given as = Close</p> 
 <p>Start of loading of data.....</p> 
 <p>    Inputs: ts_column = Date, sep = ,, target = ['Close']</p> 
 <p>    Using given input: pandas dataframe...</p> 
 <p>    Date column exists in given train data...</p> 
 <p>    train data shape = (2800, 1)</p> 
 <p>Alert: Could not detect strf_time_format of Date. Provide strf_time format during "setup" for better results.</p> 
 <p>Running Augmented Dickey-Fuller test with paramters:</p> 
 <p>    maxlag: 31 regression: c autolag: BIC</p> 
 <p>Data is stationary after one differencing</p> 
 <p>There is 1 differencing needed in this datasets for VAR model</p> 
 <p>No time series plot since verbose = 0. Continuing</p> 
 <p>Time Interval is given as D</p> 
 <p>    Correct Time interval given as a valid Pandas date-range frequency...</p> 
 <p>WARNING: Running best models will take time... Be Patient...</p> 
 <p>==================================================</p> 
 <p>Building Prophet Model</p> 
 <p>==================================================</p> 
 <p>Running Facebook Prophet Model...</p> 
 <p>  Starting Prophet Fit</p> 
 <p>      No seasonality assumed since seasonality flag is set to False</p> 
 <p>  Starting Prophet Cross Validation</p> 
 <p>Max. iterations using expanding window cross validation = 5</p> 
 <p>Fold Number: 1 --&gt; Train Shape: 1705 Test Shape: 219</p> 
 <p>    RMSE = 30.01</p> 
 <p>    Std Deviation of actuals = 19.52</p> 
 <p>    Normalized RMSE (as pct of std dev) = 154%</p> 
 <p>Cross Validation window: 1 completed</p> 
 <p>Fold Number: 2 --&gt; Train Shape: 1924 Test Shape: 219</p> 
 <p>    RMSE = 45.33</p> 
 <p>    Std Deviation of actuals = 34.21</p> 
 <p>    Normalized RMSE (as pct of std dev) = 132%</p> 
 <p>Cross Validation window: 2 completed</p> 
 <p>Fold Number: 3 --&gt; Train Shape: 2143 Test Shape: 219</p> 
 <p>    RMSE = 65.61</p> 
 <p>    Std Deviation of actuals = 39.85</p> 
 <p>    Normalized RMSE (as pct of std dev) = 165%</p> 
 <p>Cross Validation window: 3 completed</p> 
 <p>Fold Number: 4 --&gt; Train Shape: 2362 Test Shape: 219</p> 
 <p>    RMSE = 178.53</p> 
 <p>    Std Deviation of actuals = 75.28</p> 
 <p>    Normalized RMSE (as pct of std dev) = 237%</p> 
 <p>Cross Validation window: 4 completed</p> 
 <p>Fold Number: 5 --&gt; Train Shape: 2581 Test Shape: 219</p> 
 <p>    RMSE = 148.18</p> 
 <p>    Std Deviation of actuals = 57.62</p> 
 <p>    Normalized RMSE (as pct of std dev) = 257%</p> 
 <p>Cross Validation window: 5 completed</p> 
 <p>-------------------------------------------</p> 
 <p>Model Cross Validation Results:</p> 
 <p>-------------------------------------------</p> 
 <p>    MAE (Mean Absolute Error = 85.20</p> 
 <p>    MSE (Mean Squared Error = 12218.34</p> 
 <p>    MAPE (Mean Absolute Percent Error) = 17%</p> 
 <p>    RMSE (Root Mean Squared Error) = 110.5366</p> 
 <p>    Normalized RMSE (MinMax) = 18%</p> 
 <p>    Normalized RMSE (as Std Dev of Actuals)= 60%</p> 
 <p>Time Taken = 13 seconds</p> 
 <p>  End of Prophet Fit</p> 
 <p>==================================================</p> 
 <p>Building Auto SARIMAX Model</p> 
 <p>==================================================</p> 
 <p>Running Auto SARIMAX Model...</p> 
 <p>    Using smaller parameters for larger dataset with greater than 1000 samples</p> 
 <p>    Using smaller parameters for larger dataset with greater than 1000 samples</p> 
 <p>    Using smaller parameters for larger dataset with greater than 1000 samples</p> 
 <p>    Using smaller parameters for larger dataset with greater than 1000 samples</p> 
 <p>    Using smaller parameters for larger dataset with greater than 1000 samples</p> 
 <p>SARIMAX RMSE (all folds): 73.9230</p> 
 <p>SARIMAX Norm RMSE (all folds): 35%</p> 
 <p>-------------------------------------------</p> 
 <p>Model Cross Validation Results:</p> 
 <p>-------------------------------------------</p> 
 <p>    MAE (Mean Absolute Error = 64.24</p> 
 <p>    MSE (Mean Squared Error = 7962.95</p> 
 <p>    MAPE (Mean Absolute Percent Error) = 12%</p> 
 <p>    RMSE (Root Mean Squared Error) = 89.2354</p> 
 <p>    Normalized RMSE (MinMax) = 14%</p> 
 <p>    Normalized RMSE (as Std Dev of Actuals)= 48%</p> 
 <p>    Using smaller parameters for larger dataset with greater than 1000 samples</p> 
 <p>Refitting data with previously found best parameters</p> 
 <p>    Best aic metric = 18805.2</p> 
 <p>                               SARIMAX Results                                </p> 
 <p>==============================================================================</p> 
 <p>Dep. Variable:                  Close   No. Observations:                 2800</p> 
 <p>Model:               SARIMAX(2, 2, 0)   Log Likelihood               -9397.587</p> 
 <p>Date:                Mon, 28 Feb 2022   AIC                          18805.174</p> 
 <p>Time:                        19:45:31   BIC                          18834.854</p> 
 <p>Sample:                             0   HQIC                         18815.888</p> 
 <p>                               - 2800                                         </p> 
 <p>Covariance Type:                  opg                                         </p> 
 <p>==============================================================================</p> 
 <p>                 coef    std err          z      P&gt;|z|      [0.025      0.975]</p> 
 <p>------------------------------------------------------------------------------</p> 
 <p>intercept     -0.0033      0.557     -0.006      0.995      -1.094       1.088</p> 
 <p>drift       3.618e-06      0.000      0.015      0.988      -0.000       0.000</p> 
 <p>ar.L1         -0.6405      0.008    -79.601      0.000      -0.656      -0.625</p> 
 <p>ar.L2         -0.2996      0.009    -32.618      0.000      -0.318      -0.282</p> 
 <p>sigma2        48.6323      0.456    106.589      0.000      47.738      49.527</p> 
 <p>===================================================================================</p> 
 <p>Ljung-Box (L1) (Q):                  14.84   Jarque-Bera (JB):             28231.48</p> 
 <p>Prob(Q):                              0.00   Prob(JB):                         0.00</p> 
 <p>Heteroskedasticity (H):              19.43   Skew:                             0.56</p> 
 <p>Prob(H) (two-sided):                  0.00   Kurtosis:                        18.53</p> 
 <p>===================================================================================</p> 
 <p>Warnings:</p> 
 <p>[1] Covariance matrix calculated using the outer product of gradients (complex-step).</p> 
 <p>===============================================</p> 
 <p>Skipping VAR Model since dataset is &gt; 1000 rows and it will take too long</p> 
 <p>===============================================</p> 
 <p>==================================================</p> 
 <p>Building ML Model</p> 
 <p>==================================================</p> 
 <p>Creating 2 lagged variables for Machine Learning model...</p> 
 <p>    You have set lag = 3 in auto_timeseries setup to feed prior targets. You cannot set lags &gt; 10 ...</p> 
 <p>### Be careful setting dask_xgboost_flag to True since dask is unstable and doesn't work sometime's ###</p> 
 <p>########### Single-Label Regression Model Tuning and Training Started ####</p> 
 <p>Fitting ML model</p> 
 <p>    11 variables used in training ML model = ['Close(t-1)', 'Date_hour', 'Date_minute', 'Date_dayofweek', 'Date_quarter', 'Date_month', 'Date_year', 'Date_dayofyear', 'Date_dayofmonth', 'Date_weekofyear', 'Date_weekend']</p> 
 <p>Running Cross Validation using XGBoost model..</p> 
 <p>    Max. iterations using expanding window cross validation = 2</p> 
 <p>train fold shape (2519, 11), test fold shape = (280, 11)</p> 
 <p>### Number of booster rounds = 250 for XGBoost which can be set during setup ####</p> 
 <p>    Hyper Param Tuning XGBoost with CPU parameters. This will take time. Please be patient...</p> 
 <p>Cross-validated Score = 31.896 in num rounds = 249</p> 
 <p>Time taken for Hyper Param tuning of XGBoost (in minutes) = 0.0</p> 
 <p>Top 10 features:</p> 
 <p>['Date_year', 'Close(t-1)', 'Date_quarter', 'Date_month', 'Date_weekofyear', 'Date_dayofyear', 'Date_dayofmonth', 'Date_dayofweek']</p> 
 <p>    Time taken for training XGBoost on entire train data (in minutes) = 0.0</p> 
 <p>Returning the following:</p> 
 <p>    Model = &lt;xgboost.core.Booster object at 0x7feb8dd30070&gt;</p> 
 <p>    Scaler = Pipeline(steps=[('columntransformer',</p> 
 <p>                 ColumnTransformer(transformers=[('simpleimputer',</p> 
 <p>                                                  SimpleImputer(),</p> 
 <p>                                                  ['Close(t-1)', 'Date_hour',</p> 
 <p>                                                   'Date_minute',</p> 
 <p>                                                   'Date_dayofweek',</p> 
 <p>                                                   'Date_quarter', 'Date_month',</p> 
 <p>                                                   'Date_year',</p> 
 <p>                                                   'Date_dayofyear',</p> 
 <p>                                                   'Date_dayofmonth',</p> 
 <p>                                                   'Date_weekofyear',</p> 
 <p>                                                   'Date_weekend'])])),</p> 
 <p>                ('maxabsscaler', MaxAbsScaler())])</p> 
 <p>    (3) sample predictions:[359.8374  356.59747 355.447  ]</p> 
 <p>XGBoost model tuning completed</p> 
 <p>Target = Close...CV results:</p> 
 <p>    RMSE = 246.63</p> 
 <p>    Std Deviation of actuals = 94.60</p> 
 <p>    Normalized RMSE (as pct of std dev) = 261%</p> 
 <p>Fitting model on entire train set. Please be patient...</p> 
 <p>    Time taken to train model (in seconds) = 0</p> 
 <p>Best Model is: auto_SARIMAX</p> 
 <p>    Best Model (Mean CV) Score: 73.92</p> 
 <p>--------------------------------------------------</p> 
 <p>Total time taken: 52 seconds.</p> 
 <p>--------------------------------------------------</p> 
 <p>Leaderboard with best model on top of list:</p> 
 <p>            name        rmse</p> 
 <p>1  auto_SARIMAX   73.922971</p> 
 <p>0       Prophet   93.532440</p> 
 <p>2            ML  246.630613</p> 
 <img src="https://images2.imgbox.com/cb/9f/9GlyW4ue_o.png" alt="92d378f572124a77b378491d6187bff6.png"> 
 <img src="https://images2.imgbox.com/14/1c/LBuvyva6_o.png" alt="0aae864b7a3b6e04a4b188cb89fbcf6d.png"> 
 <img src="https://images2.imgbox.com/7d/ab/R7sC4xq1_o.png" alt="d541ae4d7d3b44705bb763c6a71b492f.png"> 
 <img src="https://images2.imgbox.com/07/ba/ecIb0rKW_o.png" alt="df298af5f490ef5aa1c50291c5729f44.png"> 
 <img src="https://images2.imgbox.com/1d/da/akLTieKl_o.png" alt="524ee176a98b4f7d5e34c15220569578.png"> 
 <img src="https://images2.imgbox.com/38/bb/4BpKAlVv_o.png" alt="f2653278ae2bef5d81b18a94a0bc656c.png"> 
 <p><strong>现在我们在测试数据上测试我们的模型：</strong></p> 
 <pre class="has"><code class="language-go">future_predictions = model.predict(testdata=219)
# 或 
model.predict(
    testdata=test_df.Close)</code></pre> 
 <p><strong>使用预测周期=219作为auto_SARIMAX模型的输入进行预测：</strong></p> 
 <pre class="has"><code class="language-go">future_predictions</code></pre> 
 <img src="https://images2.imgbox.com/b6/be/8j5hWqmO_o.png" alt="5d55e49a93b3a0ff6b3cfcc1ae70ae59.png"> 
 <p>可视化看下<code>future_predictions</code>是什么样子：</p> 
 <img src="https://images2.imgbox.com/a1/90/1Pg9QExv_o.png" alt="13c07ad4cc75e08a341683221c8dd731.png"> 
 <p><strong>最后，可视化测试数据值和预测：</strong></p> 
 <pre class="has"><code class="language-go">pred_df = pd.concat(
    [test_df,future_predictions],
    axis=1)
ax.plot('Date','Close','b',
         data=pred_df,
         label='Test')
ax.plot('Date','yhat','r',
         data=pred_df,
         label='Predicitions')</code></pre> 
 <img src="https://images2.imgbox.com/01/dc/tM82MTvd_o.png" alt="f4351022cbba345486b8abef67df157b.png"> 
 <p><strong>auto_timeseries 中可用的参数：</strong></p> 
 <pre class="has"><code class="language-go">model = auto_timeseries( 
    score_type='rmse',
    time_interval='Month',
    non_seasonal_pdq=None, 
    seasonity=False,  
    season_period=12,
    model_type=['Prophet'],
    verbose=2)</code></pre> 
 <p><strong>model.fit() 中可用的参数：</strong></p> 
 <pre class="has"><code class="language-go">model.fit(traindata=train_data,
    ts_column=ts_column,
    target=target,
    cv=5, sep="," )</code></pre> 
 <p><strong>model.predict() 中可用的参数：</strong></p> 
 <pre class="has"><code class="language-go">model = model.predict(testdata = '可以是数据框或代表预测周期的整数';  
                      model = 'best', '或代表训练模型的任何其他字符串')</code></pre> 
 <p>可以使用所有这些参数并分析我们模型的性能，然后可以为我们的问题陈述选择最合适的模型。可以查看auto-ts文档<sup>[3]</sup>详细检查所有这些参数。</p> 
 <h3>写在最后</h3> 
 <p>在本文中，讨论了如何在一行 Python 代码中自动化时间序列模型。Auto-TS 对数据进行预处理，因为它从数据中删除异常值并通过学习最佳 NaN 插补来处理混乱的数据。</p> 
 <p>通过初始化 Auto-TS 对象并拟合训练数据，它将自动训练多个时间序列模型，例如 ARIMA、SARIMAX、FB Prophet、VAR，并得出性能最佳的模型。模型的结果跟数据集的大小有一定的关系。如果我们尝试增加数据集的大小，结果应该会有所改善。</p> 
 <h4>参考资料</h4> 
 <p>[1]</p> 
 <p>auto-ts文档: <em>https://pypi.org/project/auto-ts/</em></p> 
 [2] 
 <p>亚马逊股票价格: <em>https://www.kaggle.com/szrlee/stock-time-series-20050101-to-20171231?select=AMZN_2006-01-01_to_2018-01-01.csv</em></p> 
 [3] 
 <p>auto-ts文档: <em>https://pypi.org/project/auto-ts/</em></p> 
 <pre></pre> 
 <pre></pre> 
 <pre></pre> 
 <pre></pre> 
 <pre></pre> 
 <pre class="has"><code class="language-go">往期精彩回顾




适合初学者入门人工智能的路线及资料下载(图文+视频)机器学习入门系列下载中国大学慕课《机器学习》（黄海广主讲）机器学习及深度学习笔记等资料打印《统计学习方法》的代码复现专辑
AI基础下载机器学习交流qq群955171419，加入微信群请扫码：</code></pre> 
 <p><img src="https://images2.imgbox.com/a1/29/E5xQBvcg_o.png" alt="f58afd9eacc56b0b596dfa3db41d6ddd.png"></p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3be6d2732a1998e9691665bfab07b961/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">全网最全的 MySQL 索引优化方案</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/881b8d018ccb9b4e2e40afc4cfc19bb5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">cadence数模混合仿真反标sdf</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>