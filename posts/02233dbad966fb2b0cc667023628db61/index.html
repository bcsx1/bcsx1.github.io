<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【人工智能】机器学习体系 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【人工智能】机器学习体系" />
<meta property="og:description" content="机器学习基础 一、机器学习的概念 1. 机器怎么学习 处理某个特定的任务，以大量的“经验”为基础对任务完成的好坏，给予一定的评判标准通过分析经验数据，任务完成得更好了 2. 机器学习的定义 主要研究计算机系统对于特定任务的性能，逐步进行改善的算法和统计模型。通过输入海量训练数据对模型进行训练，使模型掌握数据所蕴含的潜在规律，进而对新输入的数据进行准确的分类或预测。 3. 机器学习的过程 海量数据 -&gt; 提炼规律 -&gt; 预测未来 二、机器学习的分类 1. 主要分类 有监督学习：提供数据并提供数据对应结果的机器学习过程。无监督学习：提供数据并且不提供数据对应结果的机器学习过程。强化学习：通过与环境交互并获取延迟返回进而改进行为的学习过程。 2. 无监督学习 采用一组仅包含输入的数据，通过寻找数据中的内在结构来进行样本点的分组或聚类。不是响应反馈，而是要识别数据中的共性特征；对于一个新数据，可以通过判断其中是否存在这种特征，来做出响应的反馈。核心应用：统计学中的密度估计和聚类分析。应用例子：谷歌新闻 搜索新闻事件，自动地把它们聚类到一起；这些新闻事件全是同一主题的。 3. 监督学习 构建了包含输入和所需输出的一组数据的数学模型。这些数据称为训练数据，由一组训练样本组成。主要包括分类和回归。分类算法 当输出被限制为有限的一组值（离散数值）时使用 回归算法 当输出可以具有范围内的任何数值（连续数值）时使用 应用例子：预测房价或房屋出售情况
三、监督学习深入介绍 1. 监督学习三要素 模型（model）：总结数据的内在规律，用数学函数描述的系统策略（strategy）：选取最优模型的评价准则算法（algorithm）：选取最优模型的具体方法 2. 监督学习实现步骤 得到一个有限的训练数据集确定包含所有学习模型的集合确定模型选择的准则，也就是学习策略实现求解最优模型的算法，也就是学习算法通过学习算法选择最优模型利用得到的最优模型，对新数据进行预测或分析 3. 监督学习过程示例 4. 模型评估策略 训练集：输入到模型中对模型进行训练的数据集合。测试集：模型训练完成后测试训练效果的数据集合。损失函数（loss function） 用来衡量模型预测误差的大小。定义：选取模型f为决策函数，对于给定的输入参数X，f(X)为预测结果，Y为真实结果；f(X)和Y之间可能会有偏差，我们就用一个损失函数来度量预测偏差的程度，记作L(Y,f(X))损失函数是系数的函数损失函数值越小，模型就越好
5. 经验风险（empirical risk） 6. 训练误差和测试误差 训练误差（training error） 关于训练集的平均损失大小可以用来判断给定问题是否容易学习，但本质上并不重要 测试误差（testing error） 真正反映了模型对未知数据的预测能力，这种能力一般被称为泛化能力 7. 过拟合和欠拟合 欠拟合（under-fitting） 模型没有很好地捕捉到数据特征，特征集过小，导致模型不能很好地拟合数据本质：对数据的特征“学习”得不够 过拟合（over-fitting） 把训练数据学习的太彻底，以至于把噪声数据的特征也学习到了，特征集过大，导致在后期测试的时候不能够很好地识别数据，即不能正确的分类，模型泛化能力太差 8. 模型的选择 当模型复杂度增大时，训练误差会逐渐减小并趋向于0；而测试误差会先减小，达到最小值之后再增大当模型复杂度过大时，就会发生过拟合；所以模型复杂度应适当 9. 正则化（regularization） 正则化的思想是：在所有可能选择的模型中，我们应该选择能够很好地解释已知数据并且十分简单的模型 10. 交叉验证（cross validation） 数据集划分 如果样本数据充足，一种简单方法是随机将数据集切成三部分：训练集（training set），验证集（validation set）和测试集（test set） 训练集：训练模型验证集：模型选择测试集：学习方法评估 数据不充足时，可以重复地利用数据 – 交叉验证 简单交叉验证 数据随机分为两部分，如70%作为训练集，剩下30%作为测试集训练集在不同的条件下（比如参数个数）训练模型，得到不同的模型在测试集上评价各个模型的测试误差，选出最优模型 S折交叉验证（K重交叉验证） 将数据随机一切分为S个互不相交、相同大小的子集；S-1个做训练集，剩下一个做测试集重复进行训练集、测试集的选取，有S种可能的选择 留一交叉验证 11." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/02233dbad966fb2b0cc667023628db61/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-18T07:48:42+08:00" />
<meta property="article:modified_time" content="2021-11-18T07:48:42+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【人工智能】机器学习体系</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>机器学习基础</h2> 
<h3><a id="_1"></a>一、机器学习的概念</h3> 
<h4><a id="1__2"></a>1. 机器怎么学习</h4> 
<ul><li>处理某个特定的任务，以大量的“经验”为基础</li><li>对任务完成的好坏，给予一定的评判标准</li><li>通过分析经验数据，任务完成得更好了</li></ul> 
<h4><a id="2__7"></a>2. 机器学习的定义</h4> 
<ul><li>主要研究计算机系统对于特定任务的性能，逐步进行改善的算法和统计模型。</li><li>通过输入海量训练数据对模型进行训练，使模型掌握数据所蕴含的潜在规律，进而对新输入的数据进行准确的分类或预测。</li></ul> 
<h4><a id="3__10"></a>3. 机器学习的过程</h4> 
<ul><li>海量数据 -&gt; 提炼规律 -&gt; 预测未来</li></ul> 
<h3><a id="_12"></a>二、机器学习的分类</h3> 
<h4><a id="1__13"></a>1. 主要分类</h4> 
<ul><li>有监督学习：提供数据并提供数据对应结果的机器学习过程。</li><li>无监督学习：提供数据并且不提供数据对应结果的机器学习过程。</li><li>强化学习：通过与环境交互并获取延迟返回进而改进行为的学习过程。</li></ul> 
<h4><a id="2__17"></a>2. 无监督学习</h4> 
<ul><li>采用一组仅包含输入的数据，通过寻找数据中的内在结构来进行样本点的分组或聚类。</li><li>不是响应反馈，而是要<strong>识别数据中的共性特征</strong>；对于一个新数据，可以通过判断其中是否存在这种特征，来做出响应的反馈。</li><li>核心应用：统计学中的密度估计和聚类分析。</li><li>应用例子：谷歌新闻 
  <ul><li>搜索新闻事件，自动地把它们聚类到一起；这些新闻事件全是同一主题的。</li></ul> </li></ul> 
<h4><a id="3__23"></a>3. 监督学习</h4> 
<ul><li>构建了包含输入和所需输出的一组数据的数学模型。这些数据称为训练数据，由一组训练样本组成。</li><li>主要包括<strong>分类</strong>和<strong>回归</strong>。</li><li>分类算法 
  <ul><li>当输出被限制为有限的一组值（离散数值）时使用</li></ul> </li><li>回归算法 
  <ul><li>当输出可以具有范围内的任何数值（连续数值）时使用</li></ul> </li><li>应用例子：预测房价或房屋出售情况<br> <img src="https://images2.imgbox.com/1a/dc/Xoe6l6ob_o.png" alt="请添加图片描述"></li></ul> 
<h3><a id="_32"></a>三、监督学习深入介绍</h3> 
<h4><a id="1__33"></a>1. 监督学习三要素</h4> 
<ul><li>模型（model）：总结数据的内在规律，用数学函数描述的系统</li><li>策略（strategy）：选取最优模型的评价准则</li><li>算法（algorithm）：选取最优模型的具体方法</li></ul> 
<h4><a id="2__37"></a>2. 监督学习实现步骤</h4> 
<ul><li>得到一个有限的训练数据集</li><li>确定包含所有学习模型的集合</li><li>确定模型选择的准则，也就是<strong>学习策略</strong></li><li>实现求解最优模型的算法，也就是<strong>学习算法</strong></li><li>通过学习算法选择最优模型</li><li>利用得到的最优模型，对新数据进行预测或分析</li></ul> 
<h4><a id="3__44"></a>3. 监督学习过程示例</h4> 
<p><img src="https://images2.imgbox.com/d7/80/8em0aXFr_o.png" alt="请添加图片描述"></p> 
<h4><a id="4__46"></a>4. 模型评估策略</h4> 
<ul><li>训练集：输入到模型中对模型进行训练的数据集合。</li><li>测试集：模型训练完成后测试训练效果的数据集合。</li><li>损失函数（loss function） 
  <ul><li>用来衡量模型预测误差的大小。</li><li>定义：选取模型f为决策函数，对于给定的输入参数X，f(X)为预测结果，Y为真实结果；f(X)和Y之间可能会有偏差，我们就用一个损失函数来度量预测偏差的程度，记作L(Y,f(X))</li><li>损失函数是系数的函数</li><li>损失函数值越小，模型就越好<br> <img src="https://images2.imgbox.com/cd/c1/3UTU16lq_o.png" alt="请添加图片描述"></li></ul> </li></ul> 
<h4><a id="5_empirical_risk_55"></a>5. 经验风险（empirical risk）</h4> 
<p><img src="https://images2.imgbox.com/d3/c3/KiTJUyVK_o.png" alt="请添加图片描述"></p> 
<h4><a id="6__57"></a>6. 训练误差和测试误差</h4> 
<ul><li>训练误差（training error） 
  <ul><li>关于训练集的平均损失</li><li>大小可以用来判断给定问题是否容易学习，但<strong>本质上并不重要</strong></li></ul> </li><li>测试误差（testing error） 
  <ul><li>真正反映了模型对未知数据的预测能力，这种能力一般被称为<strong>泛化能力</strong></li></ul> </li></ul> 
<h4><a id="7__63"></a>7. 过拟合和欠拟合</h4> 
<p><img src="https://images2.imgbox.com/c6/68/St3X5m7e_o.png" alt="请添加图片描述"></p> 
<ul><li>欠拟合（under-fitting） 
  <ul><li>模型没有很好地捕捉到数据特征，特征集过小，导致模型不能很好地拟合数据</li><li>本质：对数据的特征“学习”得不够</li></ul> </li><li>过拟合（over-fitting） 
  <ul><li>把训练数据学习的太彻底，以至于把噪声数据的特征也学习到了，特征集过大，导致在后期测试的时候不能够很好地识别数据，即不能正确的分类，模型泛化能力太差</li></ul> </li></ul> 
<h4><a id="8__70"></a>8. 模型的选择</h4> 
<ul><li>当模型复杂度增大时，训练误差会逐渐减小并趋向于0；而测试误差会先减小，达到最小值之后再增大</li><li>当模型复杂度过大时，就会发生过拟合；所以模型复杂度应适当</li></ul> 
<h4><a id="9_regularization_73"></a>9. 正则化（regularization）</h4> 
<p><img src="https://images2.imgbox.com/ea/91/C9StYOcS_o.png" alt="请添加图片描述"></p> 
<ul><li>正则化的思想是：在所有可能选择的模型中，我们应该选择能够<strong>很好地解释已知数据</strong>并且<strong>十分简单</strong>的模型</li></ul> 
<h4><a id="10_cross_validation_76"></a>10. 交叉验证（cross validation）</h4> 
<ul><li>数据集划分 
  <ul><li>如果样本数据充足，一种简单方法是随机将数据集切成三部分：训练集（training set），验证集（validation set）和测试集（test set） 
    <ul><li>训练集：训练模型</li><li>验证集：模型选择</li><li>测试集：学习方法评估</li></ul> </li><li>数据不充足时，可以重复地利用数据 – 交叉验证 
    <ul><li>简单交叉验证 
      <ul><li>数据随机分为两部分，如70%作为训练集，剩下30%作为测试集</li><li>训练集在不同的条件下（比如参数个数）训练模型，得到不同的模型</li><li>在测试集上评价各个模型的测试误差，选出最优模型</li></ul> </li><li>S折交叉验证（K重交叉验证） 
      <ul><li>将数据随机一切分为S个互不相交、相同大小的子集；S-1个做训练集，剩下一个做测试集</li><li>重复进行训练集、测试集的选取，有S种可能的选择</li></ul> </li><li>留一交叉验证</li></ul> </li></ul> </li></ul> 
<h4><a id="11__91"></a>11. 分类和回归</h4> 
<ul><li>分类问题 
  <ul><li>预测数据属于哪一类别。 – 离散</li><li>通过大量数据训练模型，预测某个给定房屋能不能出售出去，属于能够出售类型还是不能出售类型</li></ul> </li><li>回归问题 
  <ul><li>根据数据预测一个数值。 – 连续</li><li>给出房屋一些特征，预测房价 / 预测房屋出售的概率</li></ul> </li></ul> 
<h4><a id="12_classification_98"></a>12. 分类（classification）问题</h4> 
<ul><li>在监督学习中，当输出变量Y取有限个离散值时，预测问题就成了分类问题</li><li>监督学习从数据中学习一个分类模型或分类决策函数，称为分类器（classifier）；分类器对新的输入进行预测，称为分类</li><li>分类问题包括<strong>学习</strong>和<strong>分类</strong>两个过程。</li><li>学习过程中，根据已知的训练数据集利用学习方法学习一个分类器。</li><li>分类过程中，利用已习得的分类器对新的输入实例进行分类。</li><li>分类问题方法解决：k近邻、决策树、感知机、逻辑斯谛回归等。</li></ul> 
<h4><a id="13_precisionrecall_105"></a>13. 精确率（precision）和召回率（recall）</h4> 
<ul><li>评价分类器性能的指标一般是分类准确率（accuracy），它定义为分类器对测试集正确分类的样本数与总样本数之比。</li><li>对于二类分类问题，常用的评价指标是精确率与召回率</li><li>通常以关注的类为正类，其它为负类，按照分类器在测试集上预测的正确与否，会有四种情况出现，它们的总数分别记作： 
  <ul><li>TP（True positive）：将正类预测为正类的数目 
    <ul><li>本来应该推荐，把它推荐出来了</li></ul> </li><li>FN（False negative）：将正类预测为负类的数目 
    <ul><li>本来应该推荐，但是最后没把它推荐出来</li></ul> </li><li>FP（False positive）：将负类预测为正类的数目 
    <ul><li>推荐出来了，但是推荐错了</li></ul> </li><li>TN（True negative）：将负类预测为负类的数目 
    <ul><li>本来不应该推荐，没把它推荐出来 <img src="https://images2.imgbox.com/8b/35/ebwIZhhU_o.png" alt="请添加图片描述"></li></ul> </li></ul> </li><li>准确率 
  <ul><li>TP + TN / (TP+FN+FP+TN)</li><li>分类正确的 / 所有加起来的</li></ul> </li><li>精确率 
  <ul><li>TP + FP：所有推荐出来的数据</li><li>TP： 该推荐的，也真正把它推荐出来了</li><li>所有推荐出来的列表里，真正应该推荐出来的比例</li></ul> </li><li>召回率 
  <ul><li>TP + FN：所有应该推荐出来的数据</li><li>TP： 该推荐的，也真正把它推荐出来了</li><li>所有应该推荐出来的列表里，真正推荐出来的比例</li></ul> </li></ul> 
<h4><a id="14_regression_129"></a>14. 回归（regression）问题</h4> 
<ul><li>回归问题用于预测输入变量和输出变量之间的关系</li><li>回归模型就是表示从输入变量到输出变量之间映射的函数</li><li>回归问题的学习等价于函数拟合：选择一条函数曲线，使其很好地拟合已知数据，并且能够很好地预测未知数据</li><li>分类 
  <ul><li>按照输入变量的个数：一元回归和多元回归</li><li>按照模型类型：线性回归和非线性回归</li></ul> </li><li>回归学习的损失函数 – 平方损失函数（抛物线，有最小值）</li><li>如果选取平方损失函数作为损失函数，回归问题可以用著名的<strong>最小二乘法</strong>（least squares）来求解</li></ul> 
<h4><a id="15__138"></a>15. 模型求解算法（学习算法）</h4> 
<ul><li>梯度下降（gradient descent）算法 
  <ul><li>常用的一阶优化方法，是求解无约束优化问题最简单、最经典的方法之一</li><li>梯度方向：函数变化增长最快的方向（变量沿此方向变化时函数增长最快）</li><li>负梯度方向：函数变化减少最快的方向（变量沿此方向变化时函数减少最快）</li><li>损失函数是系数的函数，那么如果系数沿着损失函数的负梯度方向变化，此时损失函数减少最快，能够以最快速度下降到极小值<br> <img src="https://images2.imgbox.com/45/d9/QHwIF3zy_o.png" alt="请添加图片描述"></li><li>比如我们在一座大山上的某处位置，由于我们不知道怎么下山，于是决定走一步算一步，也就是在每走到一个位置的时候，求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。这样一步步的走下去，一直走到觉得我们已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山谷处。</li><li>梯度下降不一定能够找到<strong>全局的最优解</strong>，有可能是一个<strong>局部最优解</strong></li><li>如果损失函数是<strong>凸函数</strong>，梯度下降法得到的解就一定是全局最优解</li></ul> </li><li>牛顿法（Newton method）和拟牛顿法（quasi Newton method） 
  <ul><li>梯度下降法只考虑了一阶导数，而牛顿法考虑了二阶导数，因此收敛速度更快</li></ul> </li></ul> 
<h3><a id="_150"></a>四、机器学习模型介绍</h3> 
<h4><a id="1____151"></a>1. 监督学习 – 回归模型</h4> 
<ul><li>线性回归模型 
  <ul><li>一元线性回归</li><li>多元线性回归</li></ul> </li><li>非线性回归模型</li><li>最小二乘法</li></ul> 
<h4><a id="2__157"></a>2. 线性回归模型</h4> 
<ul><li>线性回归（linear regression）是一种线性模型，它假设输入变量x和单个输出变量y之间存在线性关系</li><li>具体来说，利用线性回归模型，可以从一组输入变量x的线性组合中，计算输出变量y<br> <img src="https://images2.imgbox.com/fc/c1/S89QNSfa_o.png" alt="请添加图片描述"></li><li>给定有d个属性（特征）描述的示例 x = （x1; x2; … ; xd），其中 xi是x在第i个属性（特征）上的取值，线性模型（linear model）试图学得一个通过属性（特征）的线性组合来进行预测的函数，即：<br> <img src="https://images2.imgbox.com/81/45/XIJY1D1Q_o.png" alt="请添加图片描述"></li><li>假设特征和结果都满足线性，即不大于一次方。</li><li>w和b学得之后，模型就得以确定。</li><li>许多功能更为强大的非线性模型可在线性模型的基础上通过引入层级结构 或高维映射而得。</li></ul> 
<h4><a id="3__166"></a>3. 最小二乘法</h4> 
<ul><li>基于均方误差最小化来进行模型求解的方法称为“最小二乘法” (least square method)</li><li>它的主要思想就是选择未知参数，使得理论值与观测值之差的平方和达到最小。<br> <img src="https://images2.imgbox.com/e7/ce/k19TLmvP_o.png" alt="请添加图片描述"></li><li>我们假设输入属性（特征）的数目只有一个：<br> <img src="https://images2.imgbox.com/ab/2f/3VcBBcnz_o.png" alt="请添加图片描述"></li><li>在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧式距离之和最小。<img src="https://images2.imgbox.com/15/bc/bTGIesFp_o.png" alt="请添加图片描述"> 
  <ul><li>arg的意思是后面的公式求得最小值时的参数（w和b）</li></ul> </li></ul> 
<h4><a id="4__174"></a>4. 求解线性回归</h4> 
<ul><li>求解w和b,使得 <img src="https://images2.imgbox.com/4f/ff/6FgjPTWs_o.png" alt="List item">最小化的过程，称为线性回归模型的“最小二乘参数估计”<br> <img src="https://images2.imgbox.com/e0/49/TYrt69DH_o.png" alt="请添加图片描述"></li></ul> 
<h4><a id="5__177"></a>5. 线性回归（最小二乘法）代码实现</h4> 
<pre><code class="prism language-python"><span class="token comment"># 1.引入依赖</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 2.导入数据（data.csv）</span>
points <span class="token operator">=</span> np<span class="token punctuation">.</span>genfromtxt<span class="token punctuation">(</span><span class="token string">'data.csv'</span><span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span>

<span class="token comment"># 提取points中的两列数据，分别作为x和y</span>
x <span class="token operator">=</span> points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token comment"># 用plt画出散点图</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 3.定义损失函数</span>
<span class="token comment"># 损失函数是系数的函数，另外还要传入数据的x，y</span>
<span class="token keyword">def</span> <span class="token function">compute_cost</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> points<span class="token punctuation">)</span><span class="token punctuation">:</span>
    total_cost <span class="token operator">=</span> <span class="token number">0</span>
    m <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>points<span class="token punctuation">)</span>
    
    <span class="token comment"># 逐点计算平方损失误差，然后求平均数</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
        y <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
        total_cost <span class="token operator">+=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> w <span class="token operator">*</span> x <span class="token operator">-</span> b<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
        
    <span class="token keyword">return</span> total_cost <span class="token operator">/</span> m

<span class="token comment"># 4.定义算法拟合函数</span>
<span class="token comment"># 先定义一个求均值的函数</span>
<span class="token keyword">def</span> <span class="token function">average</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">sum</span> <span class="token operator">=</span> <span class="token number">0</span>
    num <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">sum</span> <span class="token operator">+=</span> data<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token builtin">sum</span> <span class="token operator">/</span> num

<span class="token comment"># 定义核心拟合函数</span>
<span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>points<span class="token punctuation">)</span><span class="token punctuation">:</span>
    m <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>points<span class="token punctuation">)</span>
    x_bar <span class="token operator">=</span> average<span class="token punctuation">(</span>points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    sum_yx <span class="token operator">=</span> <span class="token number">0</span>
    sum_x2 <span class="token operator">=</span> <span class="token number">0</span>
    sum_delta <span class="token operator">=</span> <span class="token number">0</span>
    
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
        y <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
        sum_yx <span class="token operator">+=</span> y <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> x_bar<span class="token punctuation">)</span>
        sum_x2 <span class="token operator">+=</span> x <span class="token operator">**</span> <span class="token number">2</span>
        
    <span class="token comment">## 根据公式计算w</span>
    w <span class="token operator">=</span> sum_yx <span class="token operator">/</span> <span class="token punctuation">(</span>sum_x2 <span class="token operator">-</span> m <span class="token operator">*</span> <span class="token punctuation">(</span>x_bar<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
        y <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
        sum_delta <span class="token operator">+=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> w <span class="token operator">*</span> x<span class="token punctuation">)</span>
    
    b <span class="token operator">=</span> sum_delta <span class="token operator">/</span> m
    <span class="token keyword">return</span> w<span class="token punctuation">,</span> b

<span class="token comment"># 5.测试</span>
w<span class="token punctuation">,</span> b <span class="token operator">=</span> fit<span class="token punctuation">(</span>points<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"w is:"</span><span class="token punctuation">,</span> w<span class="token punctuation">)</span>    <span class="token comment"># 系数</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"b is:"</span><span class="token punctuation">,</span> b<span class="token punctuation">)</span>    <span class="token comment"># 截距</span>

cost <span class="token operator">=</span> compute_cost<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> points<span class="token punctuation">)</span>    <span class="token comment"># 损失函数</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"cost is:"</span><span class="token punctuation">,</span> cost<span class="token punctuation">)</span>

<span class="token comment"># 结果</span>
<span class="token comment"># w is: 1.3224310227553846</span>
<span class="token comment"># b is: 7.991020982269173</span>
<span class="token comment"># cost is: 110.25738346621313</span>

<span class="token comment"># 6.画出拟合曲线</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token comment"># 针对每一个x，计算出预测的y值</span>
pred_y <span class="token operator">=</span> w <span class="token operator">*</span> x <span class="token operator">+</span> b

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> pred_y<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/a1/ec/AiefXg7t_o.png" alt="请添加图片描述"></p> 
<h4><a id="6__268"></a>6. 多元线性回归</h4> 
<ul><li>如果有两个或两个以上的自变量，这样的线性回归分析就称为多元线性回归</li><li>实际问题中，一个现象往往是受多个因素影响的，所以多元线性回归比一元线性回归的实际应用更广<br> <img src="https://images2.imgbox.com/83/41/JpIg3Wxj_o.png" alt="请添加图片描述"></li></ul> 
<h4><a id="7__273"></a>7. 梯度下降法求解线性回归</h4> 
<p><img src="https://images2.imgbox.com/0c/b4/7l6xQiJg_o.png" alt="请添加图片描述"></p> 
<p><img src="https://images2.imgbox.com/2e/b2/FlXCsQSu_o.png" alt="请添加图片描述"></p> 
<ul><li>a在梯度下降算法中被称作为<strong>学习率</strong>或者<strong>步长</strong></li><li>这意味着我们可以通过a来控制每一步走的距离，以保证不要走太快，错过了最低点；同时也要保证收敛速度不要太慢</li><li>所以a的选择在梯度下降法中往往是很重要的，不能太大也不能太小</li></ul> 
<h4><a id="8__281"></a>8. 梯度下降法和最小二乘法</h4> 
<ul><li>相同点 
  <ul><li>本质和目标相同：两种方法都是经典的学习算法，在给定已知数据的前提下利用求导算出一个模型（函数），使得损失函数最小，然后对给定的新数据进行估算预测</li></ul> </li><li>不同点 
  <ul><li>损失函数：梯度下降可以选取其它损失函数，而最小二乘一定是平方损失函数</li><li>实现方法：最小二乘法是直接求导找出全局最小；而梯度下降是一种迭代法</li><li>效果：最小二乘找到的<strong>一定是全局最小</strong>，但计算繁琐，且复杂情况下未必有解；梯度下降迭代计算简单，但找到的<strong>一般是局部最小</strong>，只有在目标函数是凸函数时才是全局最小；到最小点附近时收敛速度会变慢，且对初始点的选择极为敏感</li></ul> </li></ul> 
<h4><a id="9__288"></a>9. 线性回归（梯度下降法）代码实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 1.导入数据（data.csv）</span>
points <span class="token operator">=</span> np<span class="token punctuation">.</span>genfromtxt<span class="token punctuation">(</span><span class="token string">'data.csv'</span><span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span>

<span class="token comment"># 提取points中的两列数据，分别作为x和y</span>
x <span class="token operator">=</span> points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token comment"># 用plt画出散点图</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 2.定义损失函数</span>
<span class="token comment"># 损失函数是系数的函数，另外还要传入数据的x，y</span>
<span class="token keyword">def</span> <span class="token function">compute_cost</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> points<span class="token punctuation">)</span><span class="token punctuation">:</span>
    total_cost <span class="token operator">=</span> <span class="token number">0</span>
    m <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>points<span class="token punctuation">)</span>
    
    <span class="token comment"># 逐点计算平方损失误差，然后求平均数</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
        y <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
        total_cost <span class="token operator">+=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> w <span class="token operator">*</span> x <span class="token operator">-</span> b<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
        
    <span class="token keyword">return</span> total_cost <span class="token operator">/</span> m

<span class="token comment"># 3.定义模型的超参数</span>
alpha <span class="token operator">=</span> <span class="token number">0.0001</span>
initial_w <span class="token operator">=</span> <span class="token number">0</span>
initial_b <span class="token operator">=</span> <span class="token number">0</span>
num_iter <span class="token operator">=</span> <span class="token number">10</span>

<span class="token comment"># 4.定义核心梯度下降算法函数</span>
<span class="token keyword">def</span> <span class="token function">grad_desc</span><span class="token punctuation">(</span>points<span class="token punctuation">,</span> initial_w<span class="token punctuation">,</span> initial_b<span class="token punctuation">,</span> alpha<span class="token punctuation">,</span> num_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
    w <span class="token operator">=</span> initial_w
    b <span class="token operator">=</span> initial_b
    <span class="token comment"># 定义一个list保存所有的损失函数值，用来显示下降的过程</span>
    cost_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
        cost_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>compute_cost<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> points<span class="token punctuation">)</span><span class="token punctuation">)</span>
        w<span class="token punctuation">,</span> b <span class="token operator">=</span> step_grad_desc<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> alpha<span class="token punctuation">,</span> points<span class="token punctuation">)</span>
        
    <span class="token keyword">return</span> <span class="token punctuation">[</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> cost_list<span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">step_grad_desc</span><span class="token punctuation">(</span>current_w<span class="token punctuation">,</span> current_b<span class="token punctuation">,</span> alpha<span class="token punctuation">,</span> points<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sum_grad_w <span class="token operator">=</span> <span class="token number">0</span>
    sum_grad_b <span class="token operator">=</span> <span class="token number">0</span>
    m <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>points<span class="token punctuation">)</span>
    
    <span class="token comment"># 对每个点，代入公式求和</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
        y <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
        sum_grad_w <span class="token operator">+=</span> <span class="token punctuation">(</span>current_w <span class="token operator">*</span> x <span class="token operator">+</span> current_b <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">*</span> x
        sum_grad_b <span class="token operator">+=</span> current_w <span class="token operator">*</span> x <span class="token operator">+</span> current_b <span class="token operator">-</span> y
    
    <span class="token comment"># 用公式求当前梯度</span>
    grad_w <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">/</span> m <span class="token operator">*</span> sum_grad_w
    grad_b <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">/</span> m <span class="token operator">*</span> sum_grad_b
    
    <span class="token comment"># 梯度下降，更新当前的w和b</span>
    updated_w <span class="token operator">=</span> current_w <span class="token operator">-</span> alpha <span class="token operator">*</span> grad_w
    updated_b <span class="token operator">=</span> current_b <span class="token operator">-</span> alpha <span class="token operator">*</span> grad_b
    
    <span class="token keyword">return</span> updated_w<span class="token punctuation">,</span> updated_b

<span class="token comment"># 5.测试：运行梯度下降算法计算最优的w和b</span>
w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> cost_list <span class="token operator">=</span> grad_desc<span class="token punctuation">(</span>points<span class="token punctuation">,</span> initial_w<span class="token punctuation">,</span> initial_b<span class="token punctuation">,</span> alpha<span class="token punctuation">,</span> num_iter<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"w is:"</span><span class="token punctuation">,</span> w<span class="token punctuation">)</span>    <span class="token comment"># 系数	w is: 1.4774173755483797</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"b is:"</span><span class="token punctuation">,</span> b<span class="token punctuation">)</span>    <span class="token comment"># 截距	b is: 0.02963934787473238</span>

cost <span class="token operator">=</span> compute_cost<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> points<span class="token punctuation">)</span>    <span class="token comment"># 损失函数</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"cost is:"</span><span class="token punctuation">,</span> cost<span class="token punctuation">)</span>	<span class="token comment"># cost is: 112.65585181499748</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>cost_list<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 6.画出拟合曲线</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token comment"># 针对每一个x，计算出预测的y值</span>
pred_y <span class="token operator">=</span> w <span class="token operator">*</span> x <span class="token operator">+</span> b

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> pred_y<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/7d/24/xD8uFmqZ_o.png" alt="请添加图片描述"></p> 
<h4><a id="10_sklearn_382"></a>10. 线性回归调用sklearn库代码实现</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 1.导入数据（data.csv）</span>
points <span class="token operator">=</span> np<span class="token punctuation">.</span>genfromtxt<span class="token punctuation">(</span><span class="token string">'data.csv'</span><span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span>

<span class="token comment"># 提取points中的两列数据，分别作为x和y</span>
x <span class="token operator">=</span> points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>

<span class="token comment"># 用plt画出散点图</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 2.定义损失函数</span>
<span class="token comment"># 损失函数是系数的函数，另外还要传入数据的x，y</span>
<span class="token keyword">def</span> <span class="token function">compute_cost</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> points<span class="token punctuation">)</span><span class="token punctuation">:</span>
    total_cost <span class="token operator">=</span> <span class="token number">0</span>
    m <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>points<span class="token punctuation">)</span>
    
    <span class="token comment"># 逐点计算平方损失误差，然后求平均数</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
        y <span class="token operator">=</span> points<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
        total_cost <span class="token operator">+=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> w <span class="token operator">*</span> x <span class="token operator">-</span> b<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
        
    <span class="token keyword">return</span> total_cost <span class="token operator">/</span> m

<span class="token comment"># 调用机器学习库</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression
lr <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>

x_new <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
y_new <span class="token operator">=</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_new<span class="token punctuation">,</span> y_new<span class="token punctuation">)</span>

<span class="token comment"># 从训练好的模型中提取系数和截距</span>
w <span class="token operator">=</span> lr<span class="token punctuation">.</span>coef_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
b <span class="token operator">=</span> lr<span class="token punctuation">.</span>intercept_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"w is:"</span><span class="token punctuation">,</span> w<span class="token punctuation">)</span>    <span class="token comment"># 系数 w is: 1.3224310227553597</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"b is:"</span><span class="token punctuation">,</span> b<span class="token punctuation">)</span>    <span class="token comment"># 截距 b is: 7.991020982270399</span>

cost <span class="token operator">=</span> compute_cost<span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> points<span class="token punctuation">)</span>    <span class="token comment"># 损失函数 cost is: 110.25738346621318</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"cost is:"</span><span class="token punctuation">,</span> cost<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token comment"># 针对每一个x，计算出预测的y值</span>
pred_y <span class="token operator">=</span> w <span class="token operator">*</span> x <span class="token operator">+</span> b

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> pred_y<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/1a/39/jmVzQ93u_o.png" alt="请添加图片描述"></p> 
<h4><a id="11__440"></a>11. 分类模型</h4> 
<ul><li>K近邻</li><li>逻辑斯谛回归</li><li>决策树</li></ul> 
<h4><a id="12_KKNN_444"></a>12. K近邻（KNN）</h4> 
<ul><li>最简单最初级的分类器，就是将全部的训练数据所对应的类别都记录下来，当测试对象的属性和某个训练对象的属性完全匹配时，便可以对其进行分类</li><li>K近邻（k-nearest neighbour, KNN）是一种基本分类方法，通过测量不同特征值之间的距离进行分类。它的思路是：如果一个样本在特征空间中的k个最相似（即特征空间中最邻近）的样本中的大多数属于某一个类 另L则该样本也属于这个类别，其中K通常是不大于20的整数</li><li>KNN算法中，所选择的邻居都是已经正确分类的对象</li><li>KNN示例 
  <ul><li>绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？</li><li>如果K=3,由于红色三角形所占比例为2/3,绿色圆将被赋予红色三角形那个类, 如果K=5,由于蓝色四方形比例为3/5, 因此绿色圆被赋予蓝色四方形类</li><li>KNN算法的结果很大程度取决于K的选择<br> <img src="https://images2.imgbox.com/79/04/MMwoJ3WR_o.png" alt="请添加图片描述"></li></ul> </li><li>KNN距离 
  <ul><li>KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配冋题，在这里距囲一般使用欧氏距离或曼哈顿距离<br> <img src="https://images2.imgbox.com/d5/53/d4IjYBpg_o.png" alt="请添加图片描述"></li></ul> </li><li>KNN算法 
  <ul><li>在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据, 则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为：<br> a） 计算测试数据与各个训练数据之间的距离；<br> b） 按照距离的递增关系进行排序；<br> c） 选取距离最小的K个点；<br> d） 确定前K个点所在类别的出现频率；<br> e） 返回前K个点中出现频率最高的类别作为测试数据的预测分类。</li></ul> </li></ul> 
<pre><code class="prism language-python"><span class="token comment"># K近邻算法</span>
<span class="token comment"># 1.引入依赖</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment"># 这里直接引入sklearn里的数据集，iris鸢尾花</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token comment"># 切分数据集为训练集和测试集</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token comment"># 计算分类预测的准确率</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score

<span class="token comment"># 2.数据的加载和预处理</span>
iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># iris</span>
<span class="token comment"># data相当于x，target相当于y</span>
<span class="token comment"># feature_names 对应data里的四个特征</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data <span class="token operator">=</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> columns <span class="token operator">=</span> iris<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span>
<span class="token comment"># 在表后面增加一列</span>
df<span class="token punctuation">[</span><span class="token string">'class'</span><span class="token punctuation">]</span> <span class="token operator">=</span> iris<span class="token punctuation">.</span>target
<span class="token comment"># 改成具体名字</span>
df<span class="token punctuation">[</span><span class="token string">'class'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'class'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token number">0</span><span class="token punctuation">:</span>iris<span class="token punctuation">.</span>target_names<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span>iris<span class="token punctuation">.</span>target_names<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">:</span>iris<span class="token punctuation">.</span>target_names<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token comment"># 整个数据的统计方法</span>
df<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> iris<span class="token punctuation">.</span>data
<span class="token comment"># 把一维转成二维，不管多少行全部排成一列</span>
y <span class="token operator">=</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># (150, 4)(150, 1)</span>

<span class="token comment"># 划分训练集和测试集</span>
<span class="token comment"># random_state 随机种子</span>
<span class="token comment"># stratify 按照y进行等比例分层</span>
x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">35</span><span class="token punctuation">,</span> stratify<span class="token operator">=</span>y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_train<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># (105, 4)(105, 1) 105行4列</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_test<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># (45, 4)(45, 1)</span>

<span class="token comment"># 取x_test的一行，一维转成二维数组</span>
<span class="token comment"># x_test[0].reshape(1,-1).shape # (1, 4)</span>
<span class="token comment"># print(x_train)</span>
<span class="token comment"># print(x_test[0].reshape(1, -1)) # 取出来test的第一行 [[5.8 2.7.5.1.1.9]]</span>
<span class="token comment"># x_train里的每一个元素减去x_test的第一行，再求和sum得到一个数</span>
<span class="token comment"># 想要按照每一行加起来，最后生成一列，需要加参数axis=1</span>
<span class="token comment"># np.sum(np.abs(x_train-x_test[0].reshape(1, -1)), axis=1)</span>

<span class="token comment"># dist=np.array([3,2,532,3243,432,3242,332,121,2343,323244])</span>
<span class="token comment"># nn_index = np.argsort(dist)</span>
<span class="token comment"># nn_y = y_train[nn_index[:6]].ravel()</span>
<span class="token comment"># # 统计每一个出现的次数</span>
<span class="token comment"># np.bincount(nn_y)</span>
<span class="token comment"># print(nn_y) # [2 1 0 1 1 2]</span>
<span class="token comment"># print(np.bincount(nn_y)) # [1 3 2]</span>
<span class="token comment"># print(np.argmax(np.bincount(nn_y))) # [1]</span>

<span class="token comment"># 3.核心算法实现</span>
<span class="token comment"># 距离函数定义</span>
<span class="token keyword">def</span> <span class="token function">l1_distance</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># a可以是一个矩阵，b是一个行向量</span>
    <span class="token comment"># a如果传入的是(105,4)，b只能传入1行4列(1，4)</span>
    <span class="token comment"># a里面的每一行都减去b，得到的还是一个矩阵</span>
    <span class="token comment"># 最后再做sum，一行有4个维度，把4个维度加起来</span>
    <span class="token comment"># axis=1，把每行都加起来，最后保存成一列</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>a<span class="token operator">-</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">l2_distance</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token operator">-</span>b<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 分类器实现</span>
<span class="token keyword">class</span> <span class="token class-name">kNN</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 定义一个初始化方法，__init__ 是类的构造方法</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_neighbors <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> dist_func <span class="token operator">=</span> l1_distance<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>n_neighbors <span class="token operator">=</span> n_neighbors
        self<span class="token punctuation">.</span>dist_func <span class="token operator">=</span> dist_func
    
    <span class="token comment"># 训练模型方法</span>
    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>x_train <span class="token operator">=</span> x
        self<span class="token punctuation">.</span>y_train <span class="token operator">=</span> y
    
    <span class="token comment"># 模型预测方法</span>
    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 初始化预测分类数组</span>
        <span class="token comment"># 长度是x.shape[0]，归成一列</span>
        y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>self<span class="token punctuation">.</span>y_train<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        
        <span class="token comment"># 遍历输入的x数据点，取出每一个数据点的序号i和数据x_test</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> x_test <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># x_test跟所有训练数据计算距离</span>
            distances <span class="token operator">=</span> self<span class="token punctuation">.</span>dist_func<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">)</span>
            
            <span class="token comment"># 得到的距离按照由近到远排序，取出索引值</span>
            nn_index <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>distances<span class="token punctuation">)</span> <span class="token comment"># 取得排序之后的参数</span>
            
            <span class="token comment"># 选取最近的k个点，保存它们对应的分类类别</span>
            <span class="token comment"># 做一个切片，把前k个取出来</span>
            <span class="token comment"># ravel把矩阵展开成一个一维数组</span>
            nn_y <span class="token operator">=</span> self<span class="token punctuation">.</span>y_train<span class="token punctuation">[</span>nn_index<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>n_neighbors<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
            <span class="token comment"># 统计类别中出现频率最高的那个，赋给y_pred[i]</span>
            <span class="token comment"># 统计每一个出现的次数，取出最大得到它的参数，就是我们要的那个值</span>
            y_pred<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>np<span class="token punctuation">.</span>bincount<span class="token punctuation">(</span>nn_y<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> y_pred

<span class="token comment"># 4.测试</span>
<span class="token comment"># 定义一个knn实例</span>
knn <span class="token operator">=</span> kNN<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token comment"># 训练模型</span>
knn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
<span class="token comment"># 传入测试数据，做预测</span>
y_pred <span class="token operator">=</span> knn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>

<span class="token comment"># 求出预测准确率</span>
accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测准确率："</span><span class="token punctuation">,</span> accuracy<span class="token punctuation">)</span> <span class="token comment"># 预测准确率：0.9333333333333333</span>

<span class="token comment"># 定义一个knn实例</span>
knn <span class="token operator">=</span> kNN<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 训练模型</span>
knn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token comment"># 保存结果list</span>
result_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment"># 针对不同的参数选取，做预测</span>
<span class="token keyword">for</span> p <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    knn<span class="token punctuation">.</span>dist_func <span class="token operator">=</span> l1_distance <span class="token keyword">if</span> p <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> l2_distance

    <span class="token comment"># 考虑不同的k取值，步长为2</span>
    <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        knn<span class="token punctuation">.</span>n_neighbors <span class="token operator">=</span> k
        <span class="token comment"># 传入测试数据，做预测</span>
        y_pred <span class="token operator">=</span> knn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
        <span class="token comment"># 求出预测准确率</span>
        accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
        result_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>k<span class="token punctuation">,</span> <span class="token string">'l1_distance'</span> <span class="token keyword">if</span> p <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">'l2_distance'</span><span class="token punctuation">,</span> accuracy<span class="token punctuation">]</span><span class="token punctuation">)</span>
        
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>result_list<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'k'</span><span class="token punctuation">,</span> <span class="token string">'距离函数'</span><span class="token punctuation">,</span> <span class="token string">'预测准确率'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df
</code></pre> 
<p><img src="https://images2.imgbox.com/fb/fe/mkQTZwZr_o.png" alt="请添加图片描述"></p> 
<h4><a id="13__604"></a>13. 逻辑斯蒂回归</h4> 
<ul><li>线性回归的问题 – 怎样判断肿瘤是否恶性？<br> <img src="https://images2.imgbox.com/ef/3e/OendQjug_o.png" alt="请添加图片描述"></li><li>线性回归健壮性不够，一旦有噪声，立刻"投降"<br> <img src="https://images2.imgbox.com/63/f1/69ZrJfEn_o.png" alt="请添加图片描述"></li><li>Sigmoid函数（压缩函数）<br> <img src="https://images2.imgbox.com/13/ae/JlXr5fUG_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/25/da/NBocPWKJ_o.png" alt="请添加图片描述"></li></ul> 
<p><img src="https://images2.imgbox.com/4d/d5/TkWyu1TK_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/9f/e2/1Bo2SlU8_o.png" alt="请添加图片描述"></p> 
<ul><li>平方损失函数的问题<br> <img src="https://images2.imgbox.com/cb/86/0QUreVro_o.png" alt="请添加图片描述"></li><li>值如果贴近分类边界（Sigmoid函数） 
  <ul><li>预测值如果是0.51，按照模型应该分到1那一类，分类正确误差是0.49，分类正确了但是误差还是很大，分类错误了误差是0.51，分类正确与否误差差不多</li><li>如果使用平方损失函数的话，没有体现出来分类正确还是分类错误</li></ul> </li></ul> 
<p><img src="https://images2.imgbox.com/28/cd/GcTHPUtS_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/2d/4f/pQ0wKqgK_o.png" alt="请添加图片描述"></p> 
<ul><li>如果接近0的时候，值会减小的特别快，比1大的时候，过程变化得比较缓慢</li><li>预测错的话就快速增大，预测对的话误差就越来越小，变化比较缓慢</li><li>损失函数<br> <img src="https://images2.imgbox.com/a1/7a/b3dz9Nzy_o.png" alt="请添加图片描述"></li><li>预测值当y=1时，实际分类为1，损失值为0，越接近1损失就越小，衰减的也会越来越慢，越接近0损失就越大，误差值小于0.5会急速上升</li><li>预测值当y=0时，实际分类为0，小于0.5代表分类正确，误差就很小，如果大于0.5分类错误，误差急速上升<br> <img src="https://images2.imgbox.com/6c/9f/CwKX6wkd_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/fa/b3/0Hju1cf7_o.png" alt="请添加图片描述"></li><li>梯度下降法求解</li></ul> 
<p><img src="https://images2.imgbox.com/58/fb/TpmtC9QN_o.png" alt="请添加图片描述"></p> 
<h4><a id="14__637"></a>14. 决策树</h4> 
<ul><li>决策树是一种简单高效并且具有强解释性的模型，广泛应用于数据分析领域。 其本质是一颗自上而下的由多个判断节点组成的树<br> <img src="https://images2.imgbox.com/ce/95/xeLzhvRm_o.png" alt="请添加图片描述"></li><li>预测小明今天是否会出门打球<br> <img src="https://images2.imgbox.com/af/28/Tc5NV4j9_o.png" alt="请添加图片描述"></li></ul> 
<p><img src="https://images2.imgbox.com/11/87/Hu2Rj63b_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/36/f8/zfamB3X8_o.png" alt="请添加图片描述"></p> 
<ul><li> <p>决策树与if-then规则</p> 
  <ul><li>决策树可以看作一个if-then规则的集合</li><li>由决策树的根节点到叶节点的每一条路径，构建一条规则：路径上内部节点的特征对应着规则的条件(condition)，叶节点对应规则的结论</li><li>决策树的if-then规则集合有一个重要性质：互斥并且完备。这就是说，每个实例都被一条规则(一条路径)所覆盖，并且只被这一条规则覆盖<br> <img src="https://images2.imgbox.com/43/84/3dYiEc0h_o.png" alt="请添加图片描述"></li></ul> </li><li> <p>决策树的目标</p> 
  <ul><li>决策树学习的本质，是从训练数据集中归纳出一组 if-then 分类规则</li><li>与训练集不相矛盾的决策树，可能有很多个，也可能一个也没有；所以我们需要选择一个与训练数据集矛盾较小的决策树</li><li>另一角度，我们可以把决策树看成一个条件概率模型，我们的目标是将实例分配到条件概率更大的那一类中去</li><li>从所有可能的情况中选择最优决策树，是一个NP<strong>完全问题</strong>，所以我们通常采用启发式算法求解决策树，得到一个<strong>次最优解</strong></li><li>采用的算法通常是递归地进行以下过程：选择<strong>最优特征</strong>，并根据该特征对训练数据进行分割，使得各个子数据集都有一个最好的分类</li></ul> </li><li> <p>特征选择</p> 
  <ul><li>特征选择就是决定用哪个特征来划分特征空间<br> <img src="https://images2.imgbox.com/93/0b/01SkRup9_o.png" alt="请添加图片描述"></li></ul> </li><li> <p>随机变量</p> 
  <ul><li>随机变量(random variable)的本质是一个函数，是从样本空间的子集到实 数的映射，将事件转换成一个数值</li><li>根据样本空间中的元素不同(即不同的实验结果)，随机变量的值也将随机产生。 可以说，随机变量是“数值化”的实验结果</li><li>在现实生活中，实验结果是描述性的词汇，比如“硬币的正面”、“反面”。 在数学家眼里，这些文字化的叙述太过繁琐，所以拿数字来代表它们<br> <img src="https://images2.imgbox.com/1f/3b/qIADT6Na_o.png" alt="请添加图片描述"></li></ul> </li><li> <p>熵<br> <img src="https://images2.imgbox.com/05/d5/165zIDSq_o.png" alt="请添加图片描述"><img src="https://images2.imgbox.com/49/46/eckTwgvj_o.png" alt="请添加图片描述"></p> </li><li> <p>熵的示例<br> <img src="https://images2.imgbox.com/c1/0f/9Xdy7Vle_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/a4/d3/aum07iBr_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/cb/10/d48OobtT_o.png" alt="请添加图片描述"></p> </li><li> <p>决策树的目标</p> 
  <ul><li>我们使用决策树模型的最终目的是利用决策树模型进行分类预测，预测我们给出的一组数据最终属于哪一种类别，这是一个由不确定到确定的过程</li><li>最终理想的分类是，每一组数据，都能确定性地按照决策树分支找到对应的类别</li><li>所以我们就选择使数据信息炳下降最快的特征作为分类节点，使得决策树尽快地趋于确定</li></ul> </li><li> <p>条件熵<br> <img src="https://images2.imgbox.com/8a/65/HNGqjJ80_o.png" alt="请添加图片描述"></p> </li><li> <p>信息增益<br> <img src="https://images2.imgbox.com/31/47/jOCXjuFC_o.png" alt="请添加图片描述"></p> </li><li> <p>决策树的生成算法</p> </li><li> <p>ID3</p> 
  <ul><li>决策树（ID3）的训练过程就是找到信息增益最大的特征，然后按照此特征进行分类，然后再找到各类型子集中信息增益最大的特征，然后按照此特征进行分类，最终得到符合要求的模型。</li></ul> </li><li> <p>C4.5</p> 
  <ul><li>C4.5算法在ID3基础上做了改进，用信息增益比来选择特征</li></ul> </li><li> <p>分类与回归树（CART）</p> 
  <ul><li>由特征选择、树的生成和剪枝三部分组成，既可以用于分类也可以用于回归</li></ul> </li></ul> 
<h4><a id="15_K_686"></a>15. K均值聚类</h4> 
<ul><li>回归和分类问题都得知道x对应的y，回归问题y本身的数值得知道，分类问题鸢尾花预测的分类本身得知道，这是典型的监督学习问题，知道它的答案，知道它的结果</li><li>无监督学习的特点：只有x没有y，给一组数据找它的规律</li><li>聚类：本身不知道该分到哪一类，得到的数据就是一堆点，找出规律让它们自动的聚在一起</li><li>降维：数据太庞大了，整个维度太多了，希望把它的维度降低，提取最重要的信息，提取更能表现的特征</li><li>无监督学习 
  <ul><li>聚类 
    <ul><li>k均值</li><li>基于密度的聚类</li><li>最大期望聚类</li></ul> </li><li>降维 
    <ul><li>潜语义分析（LSA）</li><li>主成分分析（PCA）</li><li>奇异值分解（SVD）</li></ul> </li></ul> </li><li>聚类 – k均值<br> <img src="https://images2.imgbox.com/75/7c/LMWzqloH_o.png" alt="请添加图片描述"></li><li>k均值(k-means)是聚类算法中最为简单、高效的，属于无监督学习算法</li><li>核心思想：由用户指定k个初始质心(initial centroids)，以作为聚类的类别(cluster)，重复迭代直至算法收敛</li><li>基本算法流程： 
  <ul><li>选取k个初始质心(作为初始cluster);</li><li>repeat: 
    <ul><li>对每个样本点，计算得到距其最近的质心，将其类别标为该质心所对应的cluster;</li><li>重新计算k个cluser对应的质心；</li></ul> </li><li>until质心不再发生变化或迭代达到上限</li></ul> </li></ul> 
<h4><a id="16_K_710"></a>16. K均值聚类代码实现</h4> 
<pre><code class="prism language-python"><span class="token comment"># 1.引入依赖</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 从sklearn中直接生成聚类数据</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>samples_generator <span class="token keyword">import</span> make_blobs

<span class="token comment"># 2.数据加载</span>
<span class="token comment"># 100个点，分成6类</span>
x<span class="token punctuation">,</span> y <span class="token operator">=</span> make_blobs<span class="token punctuation">(</span> n_samples<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> centers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1234</span><span class="token punctuation">,</span> cluster_std<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>
<span class="token comment"># x # 100个样本点的坐标</span>
<span class="token comment"># y # 6个类别</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">)</span> <span class="token comment"># x[:,0]表示第一列 c表示颜色</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/9f/83/vH5bAYuo_o.png" alt="请添加图片描述"></p> 
<pre><code class="prism language-python"><span class="token comment"># 3.算法实现</span>
<span class="token comment"># 引入scipy中的距离函数，默认欧式距离</span>
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>spatial<span class="token punctuation">.</span>distance <span class="token keyword">import</span> cdist

<span class="token keyword">class</span> <span class="token class-name">K_Means</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 初始化，参数 n_clusters(K)、迭代次数 max_iter、初始质心 centroids</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_clusters<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> centroids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>n_clusters <span class="token operator">=</span> n_clusters
        self<span class="token punctuation">.</span>max_iter <span class="token operator">=</span> max_iter
        self<span class="token punctuation">.</span>centroids <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>centroids<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
        
    <span class="token comment"># 训练模型方法，k-means聚类过程，传入原始数据</span>
    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 假如没有指定初始质心，就随机选取data中的点作为初始质心</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>centroids<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 从data中随机生成0到data行数的6个整数，作为索引值</span>
            self<span class="token punctuation">.</span>centroids <span class="token operator">=</span> data<span class="token punctuation">[</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_clusters<span class="token punctuation">)</span> <span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        <span class="token comment"># 开始迭代</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 1.计算距离矩阵，得到的是一个100*6的矩阵</span>
            <span class="token comment"># 只要传入同维度矩阵即可</span>
            distances <span class="token operator">=</span> cdist<span class="token punctuation">(</span>data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>centroids<span class="token punctuation">)</span>
            
            <span class="token comment"># 2.对距离按由近到远排序，选取最近的质心点的类别，作为当前点的分类</span>
            <span class="token comment"># 取最小值，最后取出（100，1）的数据保存成一列</span>
            c_ind <span class="token operator">=</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>distances<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            
            <span class="token comment"># 3.对每一类数据进行均值计算，更新质心点坐标</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_clusters<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment"># 排除掉没有出现在c_ind里的类别</span>
                <span class="token keyword">if</span> i <span class="token keyword">in</span> c_ind<span class="token punctuation">:</span>
                    <span class="token comment"># 选出所有类别是i的点，取data里面坐标的均值，更新第i个质心</span>
                    <span class="token comment"># 取出data里面true的值 2列，每一列做均值计算 axis=0 得到一行数据</span>
                    self<span class="token punctuation">.</span>centroids<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>data<span class="token punctuation">[</span>c_ind<span class="token operator">==</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 实现预测方法</span>
    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 跟上面一样，先计算距离矩阵，然后选取距离最近的那个质心的类别</span>
        distances <span class="token operator">=</span> cdist<span class="token punctuation">(</span>samples<span class="token punctuation">,</span> self<span class="token punctuation">.</span>centroids<span class="token punctuation">)</span>
        c_ind <span class="token operator">=</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>distances<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> c_ind

    
<span class="token comment"># 示例</span>
<span class="token comment"># 行数就是有5个点，列数就是和每一个质心的距离，第一行代表第一个数据和每一个质心的距离</span>
dist <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">121</span><span class="token punctuation">,</span><span class="token number">221</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
               <span class="token punctuation">[</span><span class="token number">121</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
               <span class="token punctuation">[</span><span class="token number">65</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
               <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">221</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
               <span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
c_ind <span class="token operator">=</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>dist<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>c_ind<span class="token punctuation">)</span>  <span class="token comment"># [2 1 2 0 3] 每一个元素和哪一类最近</span>
x_new<span class="token operator">=</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span> 
<span class="token comment"># [[-0.02708305  5.0215929 ]</span>
<span class="token comment"># [-5.49252256  6.27366991]</span>
<span class="token comment"># [-5.37691608  1.51403209]</span>
<span class="token comment"># [-5.37872006  2.16059225]</span>
<span class="token comment"># [ 9.58333171  8.10916554]]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_new<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>c_ind <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># [ True False  True False False]</span>
x_new<span class="token punctuation">[</span>c_ind <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token comment"># 选出类别为2的所有点</span>
<span class="token comment"># array([[-0.02708305,  5.0215929 ], [-5.37691608,  1.51403209]])</span>
<span class="token comment"># 把每一列加起来求平均值</span>
np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x_new<span class="token punctuation">[</span>c_ind <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># array([-2.70199956,  3.26781249])</span>

<span class="token comment"># 4.测试</span>
<span class="token comment"># 定义一个绘制子图函数</span>
<span class="token keyword">def</span> <span class="token function">plotKMeans</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> centroids<span class="token punctuation">,</span> subplot<span class="token punctuation">,</span> title<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 分配子图，121表示1行2列的子图中的第一个</span>
    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span>subplot<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>
    <span class="token comment"># 画出质心点</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>centroids<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> centroids<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>title<span class="token punctuation">)</span>

kmeans <span class="token operator">=</span> K_Means<span class="token punctuation">(</span>max_iter<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> centroids<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plotKMeans<span class="token punctuation">(</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> kmeans<span class="token punctuation">.</span>centroids<span class="token punctuation">,</span> <span class="token number">121</span><span class="token punctuation">,</span> <span class="token string">'Initial State'</span> <span class="token punctuation">)</span>

<span class="token comment"># 开始聚类</span>
kmeans<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

plotKMeans<span class="token punctuation">(</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> kmeans<span class="token punctuation">.</span>centroids<span class="token punctuation">,</span> <span class="token number">122</span><span class="token punctuation">,</span> <span class="token string">'Final State'</span> <span class="token punctuation">)</span>

<span class="token comment"># 预测新数据点的类别</span>
x_new <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_pred <span class="token operator">=</span> kmeans<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_new<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>kmeans<span class="token punctuation">.</span>centroids<span class="token punctuation">)</span>
<span class="token comment"># [[ 5.76444812 -4.67941789]</span>
<span class="token comment"># [-2.89174024 -0.22808556]</span>
<span class="token comment"># [-5.89115978  2.33887408]</span>
<span class="token comment"># [-4.53406813  6.11523454]</span>
<span class="token comment"># [-1.15698106  5.63230377]</span>
<span class="token comment"># [ 9.20551979  7.56124841]]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span>
<span class="token comment"># [1 5]</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x_new<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x_new<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/13/8b/tT0roDeS_o.png" alt="请添加图片描述"></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ab7ef9edff34ebbaa29a6ddb24b8b0f4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">openeuler 欧拉操作系统的几个图形界面安装方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e2a064baaaad38850971ab43220eecbb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">git强制覆盖本地代码（与git远程仓库保持一致）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>