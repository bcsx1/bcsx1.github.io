<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习相关 解答 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="机器学习相关 解答" />
<meta property="og:description" content="解答 一、机器学习相关 1、基本概念 1-1 简述解决一个机器学习问题时，你的流程是怎样的？ 确定问题：有监督问题还是无监督问题？回归问题还是分类问题？
数据收集与处理
特征工程：包括特征构建、特征选择、特征组合等
模型训练、调参、评估：包括模型的选择，选择最优的参数
模型部署：模型在线上运行的效果直接决定模型的成败
1-2 损失函数是什么，如何定义合理的损失函数？ 机器 学习模型关于单个样本的预测值与真实值的差称为损失。用于计算损失的函数称为损失函数。损失函数是​和​的非负实值函数函数。1-3 回归模型和分类模型常用损失函数有哪些？各有什么优缺点 回归模型常用的损失函数有： 0-1损失函数：
绝对损失函数：异常点多的情况下鲁棒性好；但不方便求导
平方损失函数：求导方便，能够用梯度下降法优化；对异常值敏感
对数损失函数/对数似然损失函数：
Huber 损失函数：结合了绝对损失函数和平方损失函数的优点；缺点是需要调整超参数 ​
Log-Cosh 损失函数：具有Huber的所有优点，同时二阶处处可微（牛顿法要求二阶可微）
1-4 什么是结构误差和经验误差？训练模型的时候如何判断已经达到最优？ 经验风险（经验损失）：模型 ​关于训练数据集的平均损失
结构风险：是在经验风险上加上表示模型复杂度的正则化项
经验风险最小化的策略认为，经验风险最小的模型是最优的模型。
结构风险最小化是为了防止过拟合而提出的，结构风险最小化等价于正则化。结构风险最小化的策略认为结构风险最小的模型是最优的模型。
1-5 模型的“泛化”能力是指？如何提升模型泛化能力？ 通常将模型对未知数据的预测能力称为泛化能力（generalization ability）。现实中采用最多的方法是通过测试误差来评价学习方法的泛化能力。
1-6 如何选择合适的模型评估指标？AUC、精准度、召回率、F1值都是什么？如何计算？有什么优缺点？ TP：将正类预测为正类数
FN：将正类预测为负类数
FP：将负类预测为正类数
TN：将负类预测为负类数
分类任务指标​
Accuracy（准确率）：分类正确的样本占总样本个数的比例
缺点：不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。比如，当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。
解决：可以使用每个类别下的样本准确率的算术平均（平均准确率）作为模型评估的指标。
Precision（精确率）：分类正确的正样本个数占分类器判定为正样本的样本个数的比例
Recall（召回率）：分类正确的正样本数占真正的正样本个数的比例
F1-score：precision和recall的调和平均值；当精确率和召回率都高时，F1值也会高
在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用Top N返回结果的Precision和Recall值来衡量排序模型的性能。即认为模型返回的Top N结果就是模型判定的正样本，计算前N个位置的Precision@N和Recall@N。为了综合评估一个排序模型的好坏，不仅要看模型在不同Top N下的Precision@N和Recall@N，而且最好画出模型的P-R曲线。P-R曲线的横轴是Recall，纵轴是Precision。
ROC：横坐标为假阳性率（False Positive Rate，FPR）；纵坐标为真阳性率（True Positive Rate，TPR）
其中P是真实的正样本的数量，N是真实的负样本的数量，TP是P个正样本中被分类器预测为正样本的个数，FP是N个负样本中被预测为正样本的个数。
【如何绘制ROC曲线】通过不断移动分类器的“截断点”来生成曲线上的一组关键点。在二分类问题中，模型输出一般是预测样本为正例的概率，在输出最终的正例负例之前，我们需要制定一个阈值。大于该阈值的样本判定为正例，小于该阈值的样本判定为负例。通过动态调整截断点，绘制每个截断点对应位置，再连接所有点得到最终的ROC曲线。
AUC：ROC曲线下的面积大小。计算AUC值只要沿着ROC横轴做积分就可以。AUC取值一般在0.5~1之间。AUC越大，分类性能越好。AUC表示预测的正例排在负例前面的概率。
指标想表达的含义，简单来说其实就是随机抽出一对样本（一个正样本，一个负样本），然后用训练得到的分类器来对这两个样本进行预测，预测得到正样本的概率大于负样本概率的概率
AUC为0.5表明对正例和负例没有区分能力，对于不论真实类别是1还是0，分类器预测为1的概率是相等的。
我们希望分类器达到的效果：对于真实类别为1的样本，分类器预测为1的概率（TPR）要大于真实类别为0而预测类别为1的概率（FPR），即y&gt;x
AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。
思路：1.首先对预测值进行排序，排序的方式用了python自带的函数sorted，详见注释。
2.对所有样本按照预测值从小到大标记rank，rank其实就是index&#43;1，index是排序后的sorted_pred数组中的索引
3.将所有正样本的rank相加，遇到预测值相等的情况，不管样本的正负性，对rank要取平均值再相加
4.将rank相加的和减去正样本排在正样本之后的情况，再除以总的组合数，得到auc" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/bcb5abef63555f197e2f3bcb85ce37aa/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-12-15T16:02:44+08:00" />
<meta property="article:modified_time" content="2021-12-15T16:02:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习相关 解答</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>解答</h2> 
<h3><strong>一、机器学习相关</strong></h3> 
<h3><strong>1、基本概念</strong></h3> 
<ul><li>1-1 简述解决一个机器学习问题时，你的流程是怎样的？ 
  <ol><li> <p>确定问题：有监督问题还是无监督问题？回归问题还是分类问题？</p> </li><li> <p>数据收集与处理</p> </li><li> <p>特征工程：包括特征构建、特征选择、特征组合等</p> </li><li> <p>模型训练、调参、评估：包括模型的选择，选择最优的参数</p> </li><li> <p>模型部署：模型在线上运行的效果直接决定模型的成败</p> </li></ol></li><li><a href="#1-2" rel="nofollow" title="1-2 损失函数是什么，如何定义合理的损失函数？">1-2 损失函数是什么，如何定义合理的损失函数？</a> 机器 学习模型关于单个样本的预测值与真实值的差称为<strong>损失</strong>。用于计算损失的函数称为<strong>损失函数</strong>。损失函数是​和​的非负实值函数函数。</li><li><a href="#1-3" rel="nofollow" title="1-3 回归模型和分类模型常用损失函数有哪些？各有什么优缺点">1-3 回归模型和分类模型常用损失函数有哪些？各有什么优缺点</a> 回归模型常用的损失函数有： 
  <ol><li> <p>0-1损失函数：</p> </li><li> <p>绝对损失函数：异常点多的情况下鲁棒性好；但不方便求导</p> </li></ol></li></ul> 
<ol><li> <p>平方损失函数：求导方便，能够用梯度下降法优化；对异常值敏感</p> </li><li> <p>对数损失函数/对数似然损失函数：</p> </li><li> <p>Huber 损失函数：结合了绝对损失函数和平方损失函数的优点；缺点是需要调整超参数 ​</p> </li><li> <p>Log-Cosh 损失函数：具有Huber的所有优点，同时二阶处处可微（牛顿法要求二阶可微）</p> </li></ol> 
<p></p> 
<ul><li><a href="#1-4" rel="nofollow" title="1-4 什么是结构误差和经验误差？训练模型的时候如何判断已经达到最优？">1-4 什么是结构误差和经验误差？训练模型的时候如何判断已经达到最优？</a></li></ul> 
<p>经验风险（经验损失）：模型 ​关于训练数据集的平均损失</p> 
<p>结构风险：是在经验风险上加上表示模型复杂度的正则化项</p> 
<p>经验风险最小化的策略认为，经验风险最小的模型是最优的模型。</p> 
<p>结构风险最小化是为了防止过拟合而提出的，结构风险最小化等价于正则化。结构风险最小化的策略认为结构风险最小的模型是最优的模型。</p> 
<p></p> 
<ul><li><a href="#1-5" rel="nofollow" title="1-5 模型的“泛化”能力是指？如何提升模型泛化能力？">1-5 模型的“泛化”能力是指？如何提升模型泛化能力？</a></li></ul> 
<p>通常将模型对未知数据的预测能力称为泛化能力（generalization ability）。现实中采用最多的方法是通过测试误差来评价学习方法的泛化能力。</p> 
<ul><li><a href="#1-6" rel="nofollow" title="1-6 如何选择合适的模型评估指标？AUC、精准度、召回率、F1值都是什么？如何计算？有什么优缺点？">1-6 如何选择合适的模型评估指标？AUC、精准度、召回率、F1值都是什么？如何计算？有什么优缺点？</a></li></ul> 
<p><strong>TP</strong>：将正类预测为正类数</p> 
<p><strong>FN</strong>：将正类预测为负类数</p> 
<p><strong>FP</strong>：将负类预测为正类数</p> 
<p><strong>TN</strong>：将负类预测为负类数</p> 
<p>分类任务指标​</p> 
<p><strong>Accuracy</strong>（准确率）：分类正确的样本占总样本个数的比例</p> 
<ul><li> <p>缺点：不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。比如，当负样本占99%时，分类器把所有样本都预测为负样本也可以获得99%的准确率。</p> </li><li> <p>解决：可以使用每个类别下的样本准确率的算术平均（平均准确率）作为模型评估的指标。</p> </li></ul> 
<p><strong>Precision</strong>（精确率）：分类正确的正样本个数占分类器判定为正样本的样本个数的比例</p> 
<p><strong>Recall</strong>（召回率）：分类正确的正样本数占真正的正样本个数的比例</p> 
<p><strong>F1-score</strong>：precision和recall的调和平均值；当精确率和召回率都高时，F1值也会高</p> 
<p>在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用Top N返回结果的Precision和Recall值来衡量排序模型的性能。即认为模型返回的Top N结果就是模型判定的正样本，计算前N个位置的Precision@N和Recall@N。为了综合评估一个排序模型的好坏，不仅要看模型在不同Top N下的Precision@N和Recall@N，而且最好画出模型的P-R曲线。P-R曲线的横轴是Recall，纵轴是Precision。</p> 
<p><strong>ROC</strong>：横坐标为假阳性率（False Positive Rate，FPR）；纵坐标为真阳性率（True Positive Rate，TPR）</p> 
<p>其中P是真实的正样本的数量，N是真实的负样本的数量，TP是P个正样本中被分类器预测为正样本的个数，FP是N个负样本中被预测为正样本的个数。</p> 
<p>【如何绘制ROC曲线】通过不断移动分类器的“截断点”来生成曲线上的一组关键点。在二分类问题中，模型输出一般是预测样本为正例的概率，在输出最终的正例负例之前，我们需要制定一个阈值。大于该阈值的样本判定为正例，小于该阈值的样本判定为负例。通过动态调整截断点，绘制每个截断点对应位置，再连接所有点得到最终的ROC曲线。</p> 
<p><strong>AUC</strong>：ROC曲线下的面积大小。计算AUC值只要沿着ROC横轴做积分就可以。AUC取值一般在0.5~1之间。AUC越大，分类性能越好。AUC表示预测的正例排在负例前面的概率。</p> 
<p>指标想表达的含义，简单来说其实就是随机抽出一对样本（一个正样本，一个负样本），然后用训练得到的分类器来对这两个样本进行预测，预测得到正样本的概率大于负样本概率的概率</p> 
<p><img alt="img" src="https://images2.imgbox.com/7f/06/kzpGYieV_o.jpg"></p> 
<p>AUC为0.5表明对正例和负例没有区分能力，对于不论真实类别是1还是0，分类器预测为1的概率是相等的。</p> 
<p>我们希望分类器达到的效果：对于真实类别为1的样本，分类器预测为1的概率（TPR）要大于真实类别为0而预测类别为1的概率（FPR），即y&gt;x</p> 
<p>AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。</p> 
<p></p> 
<p>思路：1.首先对预测值进行排序，排序的方式用了python自带的函数sorted，详见注释。</p> 
<p>　　　2.对所有样本按照预测值从小到大标记rank，rank其实就是index+1，index是排序后的sorted_pred数组中的索引</p> 
<p>　　　3.将所有正样本的rank相加，遇到预测值相等的情况，不管样本的正负性，对rank要取平均值再相加</p> 
<p>4.将rank相加的和减去正样本排在正样本之后的情况，再除以总的组合数，得到auc</p> 
<p>回归任务指标​</p> 
<p><strong>RMSE</strong>：计算预测值和实际值的平均误差</p> 
<p></p> 
<ul><li><a href="#1-7" rel="nofollow" title="1-7 什么是混淆矩阵？">1-7 什么是混淆矩阵？</a> 混淆矩阵，又称误差矩阵，就是分别统计分类模型归错类，归对类的观测值个数，然后把结果放在一个表里展示出来。这个表就是混淆矩阵。 混淆矩阵是ROC曲线绘制的基础，同时它也是衡量分类型模型准确度中最基本，最直观，计算最简单的方法。 
  <table><thead><tr><th>混淆矩阵</th><th>预测结果</th><th>预测结果</th></tr></thead><tbody><tr><td>真实情况</td><td>反例</td><td>正例</td></tr><tr><td>反例</td><td>TN（真反例）</td><td>FP（假正例）</td></tr><tr><td>正例</td><td>FN（假反例）</td><td>TP（真正例）</td></tr></tbody></table></li></ul> 
<ul><li> <p>TN：True Negative，被判定为负样本，事实上也是负样本</p> </li><li> <p>FP：False Positive，被判定为正样本，但事实上是负样本</p> </li><li> <p>FN：False Negative，被判定为负样本，但事实上是正样本</p> </li><li> <p>TP：True Positive，被判定为正样本，事实上也是正样本</p> </li><li><a href="#1-8" rel="nofollow" title="1-8 ROC曲线如何绘制？相比P-R曲线有什么特点？">1-8 ROC曲线如何绘制？相比P-R曲线有什么特点？</a> ROC曲线的纵轴为TPR，横轴为FPR，曲线上每个点对应一个TPR和FPR。通过调整模型阈值可以得到一个个点，从而将各个点连起来即可得到ROC曲线。 一般情况下，PR曲线易受样本数量的影响，样本数量不均衡情况下PR曲线会有明显变化，故一般使用ROC曲线。</li><li><a href="#1-9" rel="nofollow" title="1-9 如何评判模型是过拟合还是欠拟合？遇到过拟合或欠拟合时，你是如何解决？">1-9 如何评判模型是过拟合还是欠拟合？遇到过拟合或欠拟合时，你是如何解决？</a></li></ul> 
<p>过拟合是指学习时选择的模型所包含的参数过多，以至出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。</p> 
<p>当训练集效果差，欠拟合（如accuracy&lt;0.8）；训练集效果好，测试集效果差，过拟合</p> 
<p><strong>欠拟合解决方法：</strong></p> 
<ol><li> <p>增加特征</p> </li><li> <p>提高模型复杂度：神经网络提高神经元数、增加层数；SVM使用核函数；</p> </li><li> <p>减小正则项的系数</p> </li></ol> 
<p><strong>过拟合解决方法：</strong></p> 
<ol><li> <p>提高样本数量 ：</p> 
  <ul><li> <p>神经网络：Data Augmentation（数据增强）</p> </li></ul></li><li> <p>简化模型：</p> 
  <ul><li> <p>神经网络使用 Dropout、Early Stopping</p> </li><li> <p>决策树剪枝、限制树的深度</p> </li></ul></li><li> <p>加入正则化项（L1或L2）或提高惩罚系数</p> </li><li> <p>使用集成学习</p> </li><li> <p>神经网络中使用dropout机制</p> </li><li> <p>early stopping</p> </li><li> <p>标签平滑</p> </li></ol> 
<p></p> 
<ul><li><a href="#1-10" rel="nofollow" title="1-10 你是如何针对应用场景选择合适的模型？">1-10 你是如何针对应用场景选择合适的模型？</a></li><li><a href="#1-11" rel="nofollow" title="1-11 如何选择模型中的超参数？有什么方法，并说说其优劣点">1-11 如何选择模型中的超参数？有什么方法，并说说其优劣点</a></li></ul> 
<p>超参搜索算法一般包括的要素（1）目标函数（2）搜索范围，上限和下限缺点（3）其他参数，如搜索步长。</p> 
<ol><li> <p><strong>网格搜索</strong></p> </li></ol> 
<p>查找搜索范围内所有的点来确定最优值；实际应用中先用较大搜索范围和较大步长，寻找全局最优值可能位置；然后逐步缩小搜索范围和搜索步长，寻找更精确位置。</p> 
<ul><li> <p>优点</p> 
  <ul><li> <p>简单</p> </li><li> <p>如果采用较大的搜索范围和较小步长，有很大概率找到全局最优值</p> </li></ul></li><li> <p>缺点</p> 
  <ul><li> <p>耗时</p> </li><li> <p>目标函数非凸时，可能错过全局最优解</p> </li></ul></li></ul> 
<ol><li> <p><strong>随机搜索</strong></p> </li></ol> 
<p>不再测试上界和下界之间的所有值，而是在搜索范围中随机选取样本点。如果样本点集足够大，通过随机搜索也能大概率找到全局最优解或其近似。</p> 
<ul><li> <p>优点</p> 
  <ul><li> <p>更快</p> </li></ul></li><li> <p>缺点</p> 
  <ul><li> <p>可能错过全局最优解</p> </li></ul></li></ul> 
<ol><li> <p><strong>贝叶斯优化算法</strong></p> </li></ol> 
<p>对目标函数形状进行学习，找到使目标函数向全局最优值提升的参数。</p> 
<ul><li> <p>优点</p> 
  <ul><li> <p>不同于前两种方法测试一个新点时会忽略前一个点的信息；贝叶斯优化算法充分利用之前的信息</p> </li></ul></li><li> <p>缺点</p> 
  <ul><li> <p>容易陷入局部最优值</p> </li></ul></li></ul> 
<p></p> 
<ul><li><a href="#1-12" rel="nofollow" title="1-12 误差分析是什么？你是如何进行误差分析？">1-12 误差分析是什么？你是如何进行误差分析？</a> 误差诊断：通过训练误差和测试误差来分析模型是否存在高方差、高偏差。 
  <ul><li> <p>如果训练误差较高：说明模型的偏差较大，模型出现了欠拟合。</p> </li><li> <p>如果训练误差较低，而测试误差较高：说明模型的方差较大，出现了过拟合。</p> </li><li> <p>如果训练误差较低，测试误差也较低：说明模型的方差和偏差都适中，是一个比较理想的模型。</p> </li><li> <p>如果训练误差较高，且测试误差更高：说明模型的方差和偏差都较大。</p> </li></ul> 上述分析的前提是：训练集、测试集的数据来自于同一个分布，且最优误差较小。否则讨论更复杂。</li><li><a href="#1-13" rel="nofollow" title="1-13 你是如何理解模型的偏差和方差？什么样的情况是高偏差，什么情况是高方差？">1-13 你是如何理解模型的偏差和方差？什么样的情况是高偏差，什么情况是高方差？</a> 
  <ul><li> <p>高偏差对应于模型的欠拟合：模型过于简单，以至于未能很好的学习训练集，从而使得训练误差过高。</p> <p>此时模型预测的方差较小，表示预测较稳定。但是模型预测的偏差会较大，表示预测不准确。</p> </li><li> <p>高方差对应于模型的过拟合：模型过于复杂，以至于将训练集的细节都学到，将训练集的一些细节当做普遍的规律，从而使得测试集误差与训练集误差相距甚远。</p> </li></ul></li><li><a href="#1-14" rel="nofollow" title="1-14 出现高偏差或者高方差的时候你有什么优化策略？">1-14 出现高偏差或者高方差的时候你有什么优化策略？</a></li><li><a href="#1-15" rel="nofollow" title="1-15 奥卡姆剃刀定律是什么？对机器学习模型优化有何启发？举例说明">1-15 奥卡姆剃刀定律是什么？对机器学习模型优化有何启发？举例说明</a></li></ul> 
<p>奥卡姆剃刀定律：若有多个假设与观察一致，则选最简单的那个</p> 
<p>奥卡姆剃刀原理应用于模型选择时变为以下想法：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的，也就是应该选择的模型。</p> 
<p>从贝叶斯估计的角度来看，正则化项对应于模型的先验概率。可以假设复杂的模型有较小的先验概率，简单的模型有较大的先验概率。</p> 
<p></p> 
<ul><li><a href="#1-16" rel="nofollow" title="1-16 线性模型和非线性模型的区别？哪些模型是线性模型，哪些模型是非线性模型？">1-16 线性模型和非线性模型的区别？哪些模型是线性模型，哪些模型是非线性模型？</a></li></ul> 
<p>非概率模型可以分为线性模型和非线性模型。如果函数 ​ 或 ​ 是线性函数，则称模型是线性模型，否则成模型为非线性模型。</p> 
<p><strong>线性模型</strong>：感知机、线性支持向量机、k近邻、k均值、潜在语义分析</p> 
<p><strong>非线性模型</strong>：核函数支持向量机、AdaBoost，神经网络</p> 
<p></p> 
<ul><li><a href="#1-17" rel="nofollow" title="1-17 生成式模型和判别式模型的区别？哪些模型是生成式模型，哪些模型是判别式模型？">1-17 生成式模型和判别式模型的区别？哪些模型是生成式模型，哪些模型是判别式模型？</a></li></ul> 
<p>监督学习方法分为生成方法（generative approach）和判别方法（discriminative approach）。所学习到的模型分别称为生成模型和判别模型。监督学习的模型一般形式为决策函数：​ 或者条件概率分布 ​。</p> 
<p><strong>生成方法</strong>由数据学习联合概率分布 ​，然后求出条件概率分布 ​作为预测模型：</p> 
<p>之所以成为生成方法，是因为模型表示了给定输入 ​ 产生输出 ​的生成关系。</p> 
<p>典型的生成模型：朴素贝叶斯法、隐马尔可夫模型。</p> 
<p><strong>判别方法</strong>由数据直接学习决策函数 ​ 或者条件概率分布 ​作为预测的模型，关心的是对给定的输入 ​，应该预测什么样的输出 ​。</p> 
<p>典型的判别模型：k近邻、感知机、决策树、逻辑斯蒂回归、最大熵模型、支持向量机、提升方法、条件随机场。</p> 
<p></p> 
<ul><li><a href="#1-18" rel="nofollow" title="1-18 概率模型和非概率模型的区别？哪些模型是概率模型，哪些模型是非概率模型？">1-18 概率模型和非概率模型的区别？哪些模型是概率模型，哪些模型是非概率模型？</a></li></ul> 
<p>概率模型与非概率模型的区别在于模型的内在结构。<strong>概率模型一定可以表示为联合概率分布的形式</strong>，其中的变量表示输入、输出、因变量甚至参数。而针对非概率模型则不一定存在这样的联合概率分布。</p> 
<p>统计学习的模型可以分为概率模型（probabilistic model）和非概率模型（non-probabilistic model）或者确定性模型（deterministic model）。在监督学习中，概率模型取条件概率分布形式 ​，非概率模型取函数形式 ​，其中​是输入，​是输出。在无监督学习中，概率模型取条件概率分布形式 ​或 ​，其中​是输入，​是输出。在监督学习中，概率模型是生成模型，非概率模型是判别模型。</p> 
<p><strong>概率模型</strong>：决策树、朴素贝叶斯、隐马尔可夫模型、条件随机场、概率潜在语义分析、潜在狄利克雷分布、高斯混合模型</p> 
<p><strong>非概率模型</strong>：感知机、支持向量机、k近邻、AdaBoost、k均值、潜在语义分析、神经网络</p> 
<p>逻辑斯蒂回归即可看做概率模型，又可看做非概率模型。</p> 
<p></p> 
<ul><li><a href="#1-18" rel="nofollow" title="1-19 参数化模型和非参数化模型的区别？哪些模型是参数化模型，哪些模型是非参数化模型？">1-19 参数化模型和非参数化模型的区别？哪些模型是参数化模型，哪些模型是非参数化模型？</a></li></ul> 
<p>统计学习模型又可以分为参数化模型（parametric model）和非参数化模型（non-parametric model）。参数化模型假设模型参数的维度固定，模型可以由有限维参数完全刻画；非参数模型假设模型参数的维度不固定或者说无穷大，随着训练数据量的增加而不断增大。</p> 
<p><strong>参数化模型</strong>：感知机、朴素贝叶斯、逻辑斯蒂回归、k均值、高斯混合模型</p> 
<p><strong>非参数化模型</strong>：决策树、支持向量机、AdaBoost、k近邻、潜在语义分析、概率潜在语义分析、潜在狄利克雷分配</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9cbf9f66bc0a7963fc12b92ceaebd35c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C语言练习，利用求阶乘函数Fact()，编程计算并输出从1到n之间所有数的阶乘值。</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/42666e4ddcd94798f904845de2959fac/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">数据结构 实验二 单链表的基本操作 ① 逆序建立单链表② 遍历单链表(输出单链表每个元素的值)③ 在单链表第5个元素前插入一个值为999的元素.④ 删除单链表第5个元素.</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>