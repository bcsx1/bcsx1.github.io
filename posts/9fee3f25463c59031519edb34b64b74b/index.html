<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大语言模型之四-LlaMA-2从模型到应用 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="大语言模型之四-LlaMA-2从模型到应用" />
<meta property="og:description" content="最近开源大语言模型LlaMA-2火出圈，从huggingface的Open LLM Leaderboard开源大语言模型排行榜可以看到LlaMA-2还是非常有潜力的开源商用大语言模型之一，相比InstructGPT，LlaMA-2在数据质量、培训技术、能力评估、安全评估和责任发布方面进行了大量的技术更新，此外在商业许可、huggingface等社区支持等方面也做的比较好，本篇文章以7B模型为例介绍LlaMA-2的推理、训练以及应用。
相对来说LlaMA-2模型结构比Transformer简单一些，关于Transformer可以参见博客《大语言模型之一 Attention is all you need —Transformer》本篇文章重点参考了LlaMA（Meta）的官方Paper。
LlaMA-2是基于Transformer的Decoder部分，其训练数据45TB、2万亿个token，预训练上下文长度为4096，采用了GQA（分组查询注意力机制）提高推理速度，使用了超过100万个人类注释训练对SFT模型模型，伯克利大学的人工智能专业博士Nathan Lambert 则在自己的博客表示，经过一些列基准测试，除了编程能力，LlaMA-2达到了ChatGPT水平，Meta提出了一种提高多轮一致性的新方法GAtt，灵感来源于上下文蒸馏法，论文中还有一些对于奖励模型、RLHF流程、安全评估和许可申明的观点。
奖励模型是强化学习的关键，为了得到一个好的奖励模型，Meta收集了大量偏好数据，量级远远超过了开源社区目前使用的数据量，Meta采用二分类得分模型评价指标，没有使用更加复杂的反馈模型，数据收集的重点在有用性和安全性，对每个数据源使用了不同的指导原则，添加了安全元数据，迭代式数据收集方式，每周分配收集人工注释，随着收集到更多偏好数据，奖励模型也得到改进，数据这一项LlaMA-2大概得花费大约是2000万美元，奖励模型部分Meta训练了两个独立的奖励模型，一个是针对有用性进行了优化，另一个是针对安全性进行了优化；
在训练硬件方面，Meta 在其研究超级集群（Research Super Cluster, RSC）以及内部生产集群上对模型进行了预训练。两个集群均使用了 NVIDIA A100。在 Meta 的评估中，多项测评结果显示，Llama 2 在包括推理、编码、精通性和知识测试等许多外部基准测试中都优于其他开源语言模型。
当然，对于今天的大模型来说，「安全」是一个重要性不亚于「性能」的指标。在 Llama 2 的研发过程中，Meta 使用了三个常用基准评估其安全性：
真实性，指语言模型是否会产生错误信息，采用 TruthfulQA 基准；毒性，指语言模型是否会产生「有毒」、粗鲁、有害的内容，采用 ToxiGen 基准；偏见，指语言模型是否会产生存在偏见的内容，采用 BOLD 基准。 huggingface构建了一个脚本，其中使用了 QLoRA 和 trl 中的 SFTTrainer 来对 Llama 2 进行指令微调。，现在可以用短短几行代码中对所有 Llama-2 模型使用自己的数据进行训练！通过使用 4-bit 和 PEFT，即使在单个 A100 GPU 上，这个脚本也可以用于 70B 模型的训练。你可以在 T4 GPU 上进行 7B 的训练（即在 Colab 上可以免费获取的资源），或者在 A100 GPU 上进行 70B 的训练。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/9fee3f25463c59031519edb34b64b74b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-27T23:15:20+08:00" />
<meta property="article:modified_time" content="2023-09-27T23:15:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大语言模型之四-LlaMA-2从模型到应用</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>最近开源大语言模型LlaMA-2火出圈，从huggingface的<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" rel="nofollow">Open LLM Leaderboard</a>开源大语言模型排行榜可以看到LlaMA-2还是非常有潜力的开源商用大语言模型之一，相比InstructGPT，LlaMA-2在数据质量、培训技术、能力评估、安全评估和责任发布方面进行了大量的技术更新，此外在商业许可、huggingface等社区支持等方面也做的比较好，本篇文章以7B模型为例介绍LlaMA-2的推理、训练以及应用。</p> 
<p>相对来说LlaMA-2模型结构比Transformer简单一些，关于Transformer可以参见博客《<a href="https://blog.csdn.net/shichaog/article/details/132156049?spm=1001.2014.3001.5501">大语言模型之一 Attention is all you need —Transformer</a>》本篇文章重点参考了LlaMA（Meta）的官方Paper。</p> 
<p>LlaMA-2是基于Transformer的Decoder部分，其训练数据45TB、2万亿个token，预训练上下文长度为4096，采用了GQA（分组查询注意力机制）提高推理速度，使用了超过100万个人类注释训练对SFT模型模型，伯克利大学的人工智能专业博士Nathan Lambert 则在自己的博客表示，经过一些列基准测试，除了编程能力，LlaMA-2达到了ChatGPT水平，Meta提出了一种提高多轮一致性的新方法GAtt，灵感来源于上下文蒸馏法，论文中还有一些对于奖励模型、RLHF流程、安全评估和许可申明的观点。</p> 
<p>奖励模型是强化学习的关键，为了得到一个好的奖励模型，Meta收集了大量偏好数据，量级远远超过了开源社区目前使用的数据量，Meta采用二分类得分模型评价指标，没有使用更加复杂的反馈模型，数据收集的重点在有用性和安全性，对每个数据源使用了不同的指导原则，添加了安全元数据，迭代式数据收集方式，每周分配收集人工注释，随着收集到更多偏好数据，奖励模型也得到改进，数据这一项LlaMA-2大概得花费大约是2000万美元，奖励模型部分Meta训练了两个独立的奖励模型，一个是针对有用性进行了优化，另一个是针对安全性进行了优化；</p> 
<p>在训练硬件方面，Meta 在其研究超级集群（Research Super Cluster, RSC）以及内部生产集群上对模型进行了预训练。两个集群均使用了 NVIDIA A100。在 Meta 的评估中，多项测评结果显示，Llama 2 在包括推理、编码、精通性和知识测试等许多外部基准测试中都优于其他开源语言模型。</p> 
<p>当然，对于今天的大模型来说，「安全」是一个重要性不亚于「性能」的指标。在 Llama 2 的研发过程中，Meta 使用了三个常用基准评估其安全性：</p> 
<ul><li>真实性，指语言模型是否会产生错误信息，采用 TruthfulQA 基准；</li><li>毒性，指语言模型是否会产生「有毒」、粗鲁、有害的内容，采用 ToxiGen 基准；</li><li>偏见，指语言模型是否会产生存在偏见的内容，采用 BOLD 基准。</li></ul> 
<p>huggingface构建了一个<a href="https://github.com/huggingface/trl/blob/main/examples/scripts/sft_trainer.py">脚本</a>，其中使用了 QLoRA 和 <a href="https://github.com/huggingface/trl">trl</a> 中的 SFTTrainer 来对 Llama 2 进行指令微调。，现在可以用短短几行代码中对所有 Llama-2 模型使用自己的数据进行训练！通过使用 4-bit 和 PEFT，即使在单个 A100 GPU 上，这个脚本也可以用于 70B 模型的训练。你可以在 T4 GPU 上进行 7B 的训练（即在 Colab 上可以免费获取的资源），或者在 A100 GPU 上进行 70B 的训练。</p> 
<p><a href="https://github.com/huggingface/trl">TRL</a>——Transformer Reinforcement Learning。这是huggingface一个超全面的全栈库，包含了一整套工具用于使用强化学习 (Reinforcement Learning) 训练 transformer 语言模型。从监督调优 (Supervised Fine-tuning step, SFT)，到训练奖励模型 (Reward Modeling)，再到近端策略优化 (Proximal Policy Optimization)，实现了全面覆盖！并且 TRL 库已经与 transformers 集成，方便直接使用！</p> 
<p><img src="https://images2.imgbox.com/66/73/ZmIza9aR_o.png" alt="在这里插入图片描述"></p> 
<p>PEFT（Parameter Efficient Fine-Tuning）是一种用于微调神经网络模型的技术，旨在在保持模型性能的同时，显著减少微调所需的计算资源和时间。这对于在资源有限的环境下进行模型微调非常有用。PEFT 的主要思想是通过使用较小的学习率来微调模型的一部分参数，而不是对整个模型的所有参数进行微调。具体来说，PEFT 将模型的参数分为不同的组，然后在每个组上应用不同的学习率。这样可以将微调的计算开销分布到多个小批次中，从而减少了每个小批次的计算负担，使得模型可以在较小的设备上进行高效微调。<br> 在推理阶段，针对不同的模型，huggingface的建议如下：</p> 
<ul><li>要推理 7B 模型，建议选择 “GPU [medium] - 1x Nvidia A10G”。</li><li>要推理 13B 模型，建议选择 “GPU [xlarge] - 1x Nvidia A100”。</li><li>要推理 70B 模型，建议选择 “GPU [xxxlarge] - 8x Nvidia A100”。</li></ul> 
<p>不过这并不是唯一的选择，但是模型结果的并行性质决定了，GPU的效率会比CPU高出很多。</p> 
<h3><a id="LlaMA2__31"></a>LlaMA-2 模型推理和结构</h3> 
<p>这里参考了<a href="https://github.com/karpathy/llama2.c">karpathy/llama2.c</a>，以Prompt输入，“你好！”为例说明推理这一过程，这里是7B模型，</p> 
<ol><li>首先从训练得到的token_embedding_table表（embedding矩阵）中找到“你”这个token的对应的向量表示，即4096个浮点数组成的向量（因为表示的是词，所以常称为词向量，后文用词向量统一表示），获得词向量之后，进行RMSNorm。，如下图中的圈1示意，每一个token（LlaMA-2共32000个token）的向量长度是4096，即token_embedding_table表的大小是[32000, 4096]。</li></ol> 
<pre><code>float* content_row = &amp;(w-&gt;token_embedding_table[token * dim]);
</code></pre> 
<ol start="2"><li>在获得该词向量之后，进行了RMSNorm运算，圈二位置所示。这里没用使用LayerNorm，说是在梯度下降时RMSNorm可以使损失更加平滑。RMSNorm论文中对LayerNorm的公式做了改造。在原有LayerNorm中借助了每个layer统计的mean和variance对参数进行了调整，但RMSNorm认为re-centering invariance property是不必要的，只用保留re-scaling invariance property。</li></ol> 
<pre><code>        // attention rmsnorm
        rmsnorm(s-&gt;xb, x, w-&gt;rms_att_weight + l*dim, dim);
</code></pre> 
<ol start="3"><li> <p>RMS之后的进入linear层，获得QKV，图中圈3，圈4，圈5分别是[4096,4096]大小的矩阵，经过Linear之后得到了，Q、K、V，这里需要注意的是，K，V是需要保留历史值得，比如图中在输入“好”这个token时，KV的你是保留在这的。关于QKV这里可以做个简单的解释。<br> Transformer的原文中一个很重要的词是Attention，比如问你 “鸣人是哪部动漫里的人物？”，你会将注意力（Attention）放在“鸣人”并从你的记忆中搜索，然后给出答案鸣人，由此可见一个语句中每个token的重要性并不是均等的，有些token需要给以更多的注意力（Attention）。<br> QKV的作用如名字所示，因为google是做搜索引擎的，所以这里的Qurey，Key和Value的意义可以参考如下的搜索引擎结果对标图。<br> 从这里可以看到Query和Key是有相似性的，根据Query和Key的相似性展示Value的内容。所以Attention中的核心公式是。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
        
         
          
          
            s 
           
          
            o 
           
          
            f 
           
          
            t 
           
          
            m 
           
          
            a 
           
          
            x 
           
          
            ( 
           
          
            Q 
           
           
           
             K 
            
           
             T 
            
           
          
            ) 
           
          
            ∗ 
           
          
            V 
           
          
         
           softmax(\mathbf Q \mathbf K^T)* \mathbf V 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.1413em; vertical-align: -0.25em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathbf">Q</span><span class="mord"><span class="mord mathbf">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8913em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6861em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span></span></span></span></span></span><br> 其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           s 
          
         
           o 
          
         
           f 
          
         
           t 
          
         
           m 
          
         
           a 
          
         
           x 
          
         
           ( 
          
         
           Q 
          
          
          
            K 
           
          
            T 
           
          
         
           ) 
          
         
           ∗ 
          
         
        
          softmax(\mathbf Q \mathbf K^T)* 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0913em; vertical-align: -0.25em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathbf">Q</span><span class="mord"><span class="mord mathbf">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8413em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">∗</span></span></span></span></span>是根据Query和Key的相似性，获取<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           V 
          
         
        
          \mathbf V 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6861em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span></span></span></span></span>中应该注意的掩码（Query中不是每个token都有相同的重要性， Value中的每个token的重要性也是不同的）这一不同性，可以通过softmax（按和等与一归一化）给Value的每个token分配权重。<br> <img src="https://images2.imgbox.com/cb/98/lIaxJe1W_o.png" alt="在这里插入图片描述"></p> </li><li> <p>有了上面的QKV的初步理解之后，接下来看看LlaMA-2的Multi-Head，LlaMA-2 7B模型（Meta官方）的参数内容如下：</p> </li></ol> 
<pre><code>(venv) ➜  localGPT git:(main) ✗ cat ~/llama/llama-2-7b/params.json
{"dim": 4096, "multiple_of": 256, "n_heads": 32, "n_layers": 32, "norm_eps": 1e-05, "vocab_size": -1}
</code></pre> 
<p>这里的n_heads:32就是对应于Attention score里面的32，将步骤3中的QKV（长度为4096）都分为32个head，每个head的长度为128（128*32=4096），圈6和圈7，圈8和圈9是因为时序上是有依赖关系的，比如“好”这个token和“你”这个token是存在时序上的关系。圈6和圈8是计算“你”的Attention score，圈7和圈8是计算“好”的Attention score，然后将“好”当前以及之前历史所有的token Attention score的影响叠加到当前的“好”这个token，得到圈10计算的累积Attention score。</p> 
<p>LLama2的注意力机制使用了GQA<br> MHA（Multi-head Attention）是标准的多头注意力机制，h个Query、Key 和 Value 矩阵。<br> MQA（Multi-Query Attention，Fast Transformer Decoding: One Write-Head is All You Need）是多查询注意力的一种变体，也是用于自回归解码的一种注意力机制。与MHA不同的是，MQA 让所有的头之间共享同一份 Key 和 Value 矩阵，每个头只单独保留了一份 Query 参数，从而大大减少 Key 和 Value 矩阵的参数量。<br> GQA（Grouped-Query Attention，GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints）是分组查询注意力，GQA将查询头分成G组，每个组共享一个Key 和 Value 矩阵。GQA-G是指具有G组的grouped-query attention。GQA-1具有单个组，因此具有单个Key 和 Value，等效于MQA。而GQA-H具有与头数相等的组，等效于MHA。</p> 
<ol start="5"><li>计算Attention out，就是将累积Attention score和Wo做Linear运算，然后将Attention out和步骤圈2的RMSNorm和其相加（resnet结构），然后再计算RMSNorm得到Attention Norm结果，即圈13。</li><li>FFN运算，将圈13的结果，分别通过W1，W3以及W2计算后得到前向网络的输出，然后再进行类似步骤5的resnet步骤得到一个Transformer block的输出，</li><li>Transformer block重复32次，然后再经过RMSNorm输出，再经过logits运算后得到输出。</li></ol> 
<p><img src="https://images2.imgbox.com/10/3c/x09juYVm_o.png" alt="请添加图片描述"><br> 图3 LLama-2 图例过程<br> 至此，模型的推理部分完成了。</p> 
<p>因为<a href="https://github.com/karpathy/llama2.c">llama2.c</a>是基于c代码的，因而其效率和速度理论上可以更快（SIMD），此外，该库的作者还给了tinystories的一个参数量少很多简化版的LlaMA模型预训练例子。tinystories的数据集是从Hugging face下载的<a href="https://huggingface.co/datasets/roneneldan/TinyStories" rel="nofollow">地址</a>。</p> 
<h3><a id="_73"></a>大模型训练相关</h3> 
<p>预训练模型从上面的tinystories可以看出来，这到不是什么难事，接下里就是指令微调以及基于人类反馈的强化学习。指令微调（SFT）和预训练模型最大的差异在于数据集，当然为了SFT算力需求更少，也会采用诸如LoRA等方法，当然Hugging face已经将这些都做成了先从的API供调用使用了。Huggingface上有很多数据集，除了这里大语言模型，还有多模态数据集，详见<a href="https://huggingface.co/datasets?task_categories=task_categories:text-generation&amp;language=language:ml&amp;sort=trending" rel="nofollow">Huggingface官网</a>。</p> 
<h4><a id="_75"></a>指令微调数据集</h4> 
<p>开源的大语言模型训练数据集基本在Huggingface上都可以找到。</p> 
<ul><li>斯坦福开源数据集，<a href="https://huggingface.co/datasets/QingyiSi/Alpaca-CoT/blob/1d971b5591d198b810ccca6feaed420df9f39d28/alpaca/alpaca_data.json" rel="nofollow">alpaca_data.json</a>，包含了微调Alpaca模型的52k条指令跟随数据，json文件是一个字典列表，每个字典包含instruction:str，描述模型应执行的任务。</li><li><a href="https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M" rel="nofollow">Generated_Chat_0.4M,</a>包含约40万条由BELLE项目生成的个性化角色对话数据，包含角色介绍。<br> 注意：此数据集是由ChatGPT产生的，未经过严格校验，题目或解题过程可能包含错误。使用过程中请注意这一点。</li><li>S<a href="https://huggingface.co/datasets/BelleGroup/school_math_0.25M" rel="nofollow">chool Math 0.25M</a>,包含约25万条由BELLE项目生成的中文数学题数据，包含解题过程。<br> 注意：此数据集是由ChatGPT产生的，未经过严格校验，题目或解题过程可能包含错误。使用过程中请注意这一点。</li><li><a href="https://huggingface.co/datasets/JosephusCheung/GuanacoDataset" rel="nofollow">JosephusCheung/GuanacoDataset</a>,该数据集共534,530条，花费了6k美金，是一个多语言数据集，包括英文、中文、日语。<br> 此外还有Fifefly数据集，alpaca_chinese_datase等。</li></ul> 
<p>Huggingface的<a href="https://huggingface.co/docs/trl/index" rel="nofollow">trl</a>库提供的API如下：</p> 
<ul><li>Model Classes: A brief overview of what each public model class does.</li><li>SFTTrainer: Supervise Fine-tune your model easily with SFTTrainer</li><li>RewardTrainer: Train easily your reward model using RewardTrainer.</li><li>PPOTrainer: Further fine-tune the supervised fine-tuned model using PPO algorithm</li><li>Best-of-N Samppling: Use best of n sampling as an alternative way to sample predictions from your active model</li><li>DPOTrainer: Direct Preference Optimization training using DPOTrainer.<br> 并且贴心的附上了一些例子</li><li>Sentiment Tuning: Fine tune your model to generate positive movie contents</li><li>Training with PEFT: Memory efficient RLHF training using adapters with PEFT</li><li>Detoxifying LLMs: Detoxify your language model through RLHF</li><li>StackLlama: End-to-end RLHF training of a Llama model on Stack exchange dataset</li><li>Multi-Adapter Training: Use a single base model and multiple adapters for memory efficient end-to-end training</li></ul> 
<h4><a id="raining_with_PEFT_99"></a>raining with PEFT</h4> 
<p>该例子使用LoRA技术给出了内测高效的预训练例子。<br> <a href="https://github.com/cloneofsimo/lora">LoRA</a>（Low-Rank Adaption of Large Language Models）是微软提出的处理大语言模型fine-tunning的技术，大语言模型的参数量有数十亿，为了让其适合特定任务fine-tune的过程成本是很高的，LoRA方法建议冻结预训练模型参数并在每个Transformer block中注入可训练层（rank-decomposition matrics），因为冻结的预训练模型参数并不参与梯度计算，这极大缩减了可训练参数以及GPU内存的需求，研究人员发现，只集中于大语言模型的Transform attention blocks ，LoRA的微调质量与全模型微调相当，同时速度更快，需要更少的计算。</p> 
<p>尽管LoRA是针对大语言模型提出的，并且这一技术在Transformer blocks上得到验证，但是这个技术可以用在其它模型上，比如对Stable Diffusion模型的fine-tune，LoRA可以应用于将图像表示与描述它们的提示相关联的交叉注意力层（cross-attention layers）。</p> 
<p>这里就不进一步罗列原理和代码片段了，感兴趣可以自己去Huggingface官网查看。</p> 
<h3><a id="GPT_106"></a>构建本地化GPT</h3> 
<p>如果不想与OpenAI、讯飞、百度或其他类似的AI提供商共享私有（比如金融、医疗等具体行业和公司）信息或数据，或者一些新的知识并不在预训练模型中，这时不得不借助外部知识库来解决这些问题。本文概述了如何使用LocalGPT API创建您自己的个人AI助手。</p> 
<p><a href="https://github.com/PromtEngineer/localGPT">LocalGPT</a>是一个强大的工具，适合任何希望在本地运行类似GPT的模型的人，允许隐私、自定义和离线使用。<br> 它提供了一种方法来向特定文档或数据集提问，从这些文档中找到答案，并在不依赖互联网连接或外部服务器的情况下执行这些操作。</p> 
<p>LocalGPT使用起来是很简单的，其支持在各种类型架构上推理模型。但需要再Huggingface确认和想要的模型，在Model card的说明下有该模型支持的架构，在File and versions上可以下载想要版本的模型（量化位数等等）。<br> <img src="https://images2.imgbox.com/bf/57/yXktIOpg_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="LangChain_117"></a>LangChain</h4> 
<p>LangChain是开发用于大语言模型应用的一套框架。它支持以下特性：</p> 
<ul><li>数据感知：将语言模型连接到其他数据源</li><li>代理：允许语言模型与其环境交互<br> LangChain官网的<a href="https://python.langchain.com/docs/get_started/quickstart" rel="nofollow">quickstart</a>是基于openAI为例的，不过这里我们以LlaMA-2为例，LocaGPT已经封装好了。<br> 对于QA场景，首先需要将数据源（非结构化的数据）转为结构化的数据，然后将其注入大语言模型，大概得关系图如下。<br> <img src="https://images2.imgbox.com/82/2a/x8yPVU66_o.png" alt="在这里插入图片描述"><br> 转成结构化的又分为分割、存储和提取几个步骤，其大概过程如下：<br> <img src="https://images2.imgbox.com/31/57/vfu7BYLX_o.png" alt="在这里插入图片描述"><br> 对于QA的详细过程如下。<br> <img src="https://images2.imgbox.com/fb/e3/8WPWc7QW_o.png" alt="在这里插入图片描述"></li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bf6f37a758c860e6355da29ff7ae77ad/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C语言入门Day_26 结构体</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/259aa85acd1c2e591a8ba8989e68ca2c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">大语言模型之十二 SentencePiece扩充LLama2中文词汇</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>