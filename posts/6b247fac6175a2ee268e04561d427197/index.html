<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习目标检测：YOLOv5实现车辆检测(含车辆检测数据集&#43;训练代码) - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习目标检测：YOLOv5实现车辆检测(含车辆检测数据集&#43;训练代码)" />
<meta property="og:description" content="深度学习目标检测：YOLOv5实现车辆检测(含车辆检测数据集&#43;训练代码) 目录
深度学习目标检测：YOLOv5实现车辆检测(含车辆检测数据集&#43;训练代码)
1. 前言
2. 车辆检测数据集说明
（1）车辆检测数据集
（2）自定义数据集
3. 基于YOLOv5的车辆检测模型训练
（1）YOLOv5安装
（2）准备Train和Test数据
（3）配置数据文件
（4）配置模型文件
（5）重新聚类Anchor（可选）
（6）开始训练
（7）可视化训练过程
（8）常见的错误
4. Python版本车辆检测效果
5. Android版本车辆检测效果
6.项目源码下载
1. 前言 本篇博客，我们将手把手教你搭建一个基于YOLOv5的车辆目标检测项目。目前，基于YOLOv5s的车辆平均精度平均值mAP_0.5=0.57192，mAP_0.5:0.95=0.41403，基本满足业务的性能需求。另外，为了能部署在手机Android平台上，本人对YOLOv5s进行了模型轻量化，开发了一个轻量级的版本yolov5s05_416和yolov5s05_320，在普通Android手机上可以达到实时的检测和识别效果，CPU(4线程)约30ms左右，GPU约25ms左右 ，基本满足业务的性能需求。
先展示一下Python版本车辆检测Demo效果：
【尊重原创，转载请注明出处】https://panjinquan.blog.csdn.net/article/details/128099672
更多项目《智能驾驶 车牌检测和识别》系列文章请参考：
智能驾驶 车牌检测和识别（一）《CCPD车牌数据集》：https://blog.csdn.net/guyuealian/article/details/128704181智能驾驶 车牌检测和识别（二）《YOLOv5实现车牌检测（含车牌检测数据集和训练代码）》：https://blog.csdn.net/guyuealian/article/details/128704068智能驾驶 车牌检测和识别（三）《CRNN和LPRNet实现车牌识别（含车牌识别数据集和训练代码）》：https://blog.csdn.net/guyuealian/article/details/128704209智能驾驶 车牌检测和识别（四）《Android实现车牌检测和识别（可实时车牌识别）》：https://blog.csdn.net/guyuealian/article/details/128704242智能驾驶 车牌检测和识别（五）《C&#43;&#43;实现车牌检测和识别（可实时车牌识别）》：https://blog.csdn.net/guyuealian/article/details/128704276智能驾驶 红绿灯检测（一）《红绿灯(交通信号灯)数据集》：https://blog.csdn.net/guyuealian/article/details/128222850智能驾驶 红绿灯检测（二）《YOLOv5实现红绿灯检测(含红绿灯数据集&#43;训练代码)》：https://blog.csdn.net/guyuealian/article/details/128240198智能驾驶 红绿灯检测（三）《Android实现红绿灯检测(含Android源码 可实时运行)》：https://blog.csdn.net/guyuealian/article/details/128240334 智能驾驶 车辆检测（一）《UA-DETRAC BITVehicle车辆检测数据集》：https://blog.csdn.net/guyuealian/article/details/127907325
智能驾驶 车辆检测（二）《YOLOv5实现车辆检测(含车辆检测数据集&#43;训练代码)》：https://blog.csdn.net/guyuealian/article/details/128099672
智能驾驶 车辆检测（三）《Android实现车辆检测(含Android源码 可实时运行)》：https://blog.csdn.net/guyuealian/article/details/128190532
2. 车辆检测数据集说明 （1）车辆检测数据集 目前收集了约10W&#43;的车辆检测数据集：UA-DETRAC车辆检测数据集&#43;Vehicle-Dataset车辆检测数据集&#43;BITVehicle车辆检测数据集: 关于车辆检测数据集使用说明和下载，详见另一篇博客说明：《UA-DETRAC BITVehicle车辆检测数据集(含下载地址)》
（2）自定义数据集 如果需要增/删类别数据进行训练，或者需要自定数据集进行训练，可参考如下步骤：
采集图片，建议不少于200张图片使用Labelme等标注工具，对目标进行拉框标注：labelme工具：GitHub - wkentaro/labelme: Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/6b247fac6175a2ee268e04561d427197/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-28T09:22:22+08:00" />
<meta property="article:modified_time" content="2023-04-28T09:22:22+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习目标检测：YOLOv5实现车辆检测(含车辆检测数据集&#43;训练代码)</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="Fruit-Dataset%E6%B0%B4%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86%2B%E6%B0%B4%E6%9E%9C%E5%88%86%E7%B1%BB%E8%AF%86%E5%88%AB%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81(%E6%94%AF%E6%8C%81googlenet%2C%20resnet%2C%20inception_v3%2C%20mobilenet_v2)">深度学习目标检测：YOLOv5实现车辆检测(含车辆检测数据集+训练代码)</h2> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="Fruit-Dataset%E6%B0%B4%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86%2B%E6%B0%B4%E6%9E%9C%E5%88%86%E7%B1%BB%E8%AF%86%E5%88%AB%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81(%E6%94%AF%E6%8C%81googlenet%2C%20resnet%2C%20inception_v3%2C%20mobilenet_v2)-toc" style="margin-left:0px;"><a href="#Fruit-Dataset%E6%B0%B4%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86%2B%E6%B0%B4%E6%9E%9C%E5%88%86%E7%B1%BB%E8%AF%86%E5%88%AB%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81%28%E6%94%AF%E6%8C%81googlenet%2C%20resnet%2C%20inception_v3%2C%20mobilenet_v2%29" rel="nofollow">深度学习目标检测：YOLOv5实现车辆检测(含车辆检测数据集+训练代码)</a></p> 
<p id="1.%20%E5%89%8D%E8%A8%80-toc" style="margin-left:40px;"><a href="#1.%20%E5%89%8D%E8%A8%80" rel="nofollow">1. 前言</a></p> 
<p id="2.%20Fruit-Dataset%E6%B0%B4%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:40px;"><a href="#2.%20Fruit-Dataset%E6%B0%B4%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow">2. 车辆检测数据集说明</a></p> 
<p id="%EF%BC%881%EF%BC%89%20Fruit-Dataset-toc" style="margin-left:80px;"><a href="#%EF%BC%881%EF%BC%89%20Fruit-Dataset" rel="nofollow">（1）车辆检测数据集</a></p> 
<p id="%EF%BC%883%EF%BC%89%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:80px;"><a href="#%EF%BC%883%EF%BC%89%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow">（2）自定义数据集</a></p> 
<p id="4.%20%E5%9F%BA%E4%BA%8EYOLOv5%E7%9A%84%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB%E8%AE%AD%E7%BB%83-toc" style="margin-left:40px;"><a href="#4.%20%E5%9F%BA%E4%BA%8EYOLOv5%E7%9A%84%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB%E8%AE%AD%E7%BB%83" rel="nofollow">3. 基于YOLOv5的车辆检测模型训练</a></p> 
<p id="%EF%BC%881%EF%BC%89%E9%A1%B9%E7%9B%AE%E6%A1%86%E6%9E%B6%E8%AF%B4%E6%98%8E-toc" style="margin-left:80px;"><a href="#%EF%BC%881%EF%BC%89%E9%A1%B9%E7%9B%AE%E6%A1%86%E6%9E%B6%E8%AF%B4%E6%98%8E" rel="nofollow">（1）YOLOv5安装</a></p> 
<p id="%EF%BC%881%EF%BC%89%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE-toc" style="margin-left:80px;"><a href="#%EF%BC%881%EF%BC%89%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE" rel="nofollow">（2）准备Train和Test数据</a></p> 
<p id="%EF%BC%883%EF%BC%89%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%EF%BC%9Aconfig.yaml-toc" style="margin-left:80px;"><a href="#%EF%BC%883%EF%BC%89%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%EF%BC%9Aconfig.yaml" rel="nofollow">（3）配置数据文件</a></p> 
<p id="%C2%A0%EF%BC%884%EF%BC%89%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE-toc" style="margin-left:80px;"><a href="#%C2%A0%EF%BC%884%EF%BC%89%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE" rel="nofollow">（4）配置模型文件</a></p> 
<p id="%EF%BC%885%EF%BC%89%E9%87%8D%E6%96%B0%E8%81%9A%E7%B1%BBAnchor%EF%BC%88%E5%8F%AF%E9%80%89%EF%BC%89-toc" style="margin-left:80px;"><a href="#%EF%BC%885%EF%BC%89%E9%87%8D%E6%96%B0%E8%81%9A%E7%B1%BBAnchor%EF%BC%88%E5%8F%AF%E9%80%89%EF%BC%89" rel="nofollow">（5）重新聚类Anchor（可选）</a></p> 
<p id="%EF%BC%886%EF%BC%89%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83-toc" style="margin-left:80px;"><a href="#%EF%BC%886%EF%BC%89%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83" rel="nofollow">（6）开始训练</a></p> 
<p id="%EF%BC%883%EF%BC%89%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B-toc" style="margin-left:80px;"><a href="#%EF%BC%883%EF%BC%89%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B" rel="nofollow">（7）可视化训练过程</a></p> 
<p id="%C2%A0%EF%BC%888%EF%BC%89%E5%B8%B8%E8%A7%81%E7%9A%84%E9%94%99%E8%AF%AF-toc" style="margin-left:80px;"><a href="#%C2%A0%EF%BC%888%EF%BC%89%E5%B8%B8%E8%A7%81%E7%9A%84%E9%94%99%E8%AF%AF" rel="nofollow">（8）常见的错误</a></p> 
<p id="4.%20%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E6%B5%8B%E8%AF%95%E6%95%88%E6%9E%9C-toc" style="margin-left:40px;"><a href="#4.%20%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E6%B5%8B%E8%AF%95%E6%95%88%E6%9E%9C" rel="nofollow">4. Python版本车辆检测效果</a></p> 
<p id="5.Android%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB-toc" style="margin-left:40px;"><a href="#5.Android%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB" rel="nofollow">5. Android版本车辆检测效果</a></p> 
<p id="%C2%A07.%E9%A1%B9%E7%9B%AE%E6%BA%90%E7%A0%81%E4%B8%8B%E8%BD%BD-toc" style="margin-left:40px;"><a href="#%C2%A07.%E9%A1%B9%E7%9B%AE%E6%BA%90%E7%A0%81%E4%B8%8B%E8%BD%BD" rel="nofollow">6.项目源码下载</a></p> 
<hr> 
<h3 id="1.%20%E5%89%8D%E8%A8%80">1. 前言</h3> 
<p>本篇博客，我们将手把手教你搭建一个基于YOLOv5的车辆目标检测项目。目前，基于YOLOv5s的车辆平均精度平均值mAP_0.5=0.57192，mAP_0.5:0.95=0.41403，基本满足业务的性能需求。另外，为了能部署在手机Android平台上，本人对YOLOv5s进行了模型轻量化，开发了一个轻量级的版本yolov5s05_416和yolov5s05_320，在普通Android手机上可以达到实时的检测和识别效果，CPU(4线程)约30ms左右，GPU约25ms左右 ，基本满足业务的性能需求。</p> 
<p>先展示一下Python版本车辆检测Demo效果：</p> 
<table border="1" cellpadding="1" cellspacing="1"><tbody><tr><td><img alt="" height="234" src="https://images2.imgbox.com/ca/04/qZlUKAam_o.gif" width="416"></td><td><img alt="" height="234" src="https://images2.imgbox.com/a8/ce/edHuywHy_o.gif" width="416"></td></tr></tbody></table> 
<p>【尊重原创，转载请注明出处】<a href="https://panjinquan.blog.csdn.net/article/details/128099672" rel="nofollow" title="https://panjinquan.blog.csdn.net/article/details/128099672">https://panjinquan.blog.csdn.net/article/details/128099672</a></p> 
<hr> 
<p><strong>更多项目《智能驾驶 车牌检测和识别》系列文章请参考：</strong></p> 
<ol><li>智能驾驶 车牌检测和识别（一）《CCPD车牌数据集》：<a href="https://blog.csdn.net/guyuealian/article/details/128704181" title="https://blog.csdn.net/guyuealian/article/details/128704181">https://blog.csdn.net/guyuealian/article/details/128704181</a></li><li>智能驾驶 车牌检测和识别（二）《YOLOv5实现车牌检测（含车牌检测数据集和训练代码）》：<a href="https://blog.csdn.net/guyuealian/article/details/128704068" title="https://blog.csdn.net/guyuealian/article/details/128704068">https://blog.csdn.net/guyuealian/article/details/128704068</a></li><li>智能驾驶 车牌检测和识别（三）《CRNN和LPRNet实现车牌识别（含车牌识别数据集和训练代码）》：<a href="https://blog.csdn.net/guyuealian/article/details/128704209" title="https://blog.csdn.net/guyuealian/article/details/128704209">https://blog.csdn.net/guyuealian/article/details/128704209</a></li><li>智能驾驶 车牌检测和识别（四）《Android实现车牌检测和识别（可实时车牌识别）》：<a href="https://blog.csdn.net/guyuealian/article/details/128704242" title="https://blog.csdn.net/guyuealian/article/details/128704242">https://blog.csdn.net/guyuealian/article/details/128704242</a></li><li>智能驾驶 车牌检测和识别（五）《C++实现车牌检测和识别（可实时车牌识别）》：<a href="https://blog.csdn.net/guyuealian/article/details/128704276" title="https://blog.csdn.net/guyuealian/article/details/128704276">https://blog.csdn.net/guyuealian/article/details/128704276</a></li><li>智能驾驶 红绿灯检测（一）《红绿灯(交通信号灯)数据集》：<a href="https://blog.csdn.net/guyuealian/article/details/128222850" title="https://blog.csdn.net/guyuealian/article/details/128222850">https://blog.csdn.net/guyuealian/article/details/128222850</a></li><li>智能驾驶 红绿灯检测（二）《YOLOv5实现红绿灯检测(含红绿灯数据集+训练代码)》：<a href="https://blog.csdn.net/guyuealian/article/details/128240198" title="https://blog.csdn.net/guyuealian/article/details/128240198">https://blog.csdn.net/guyuealian/article/details/128240198</a></li><li>智能驾驶 红绿灯检测（三）《Android实现红绿灯检测(含Android源码 可实时运行)》：<a href="https://blog.csdn.net/guyuealian/article/details/128240334" title="https://blog.csdn.net/guyuealian/article/details/128240334">https://blog.csdn.net/guyuealian/article/details/128240334</a></li><li> <p id="articleContentId">智能驾驶 车辆检测（一）《UA-DETRAC BITVehicle车辆检测数据集》：<a href="https://blog.csdn.net/guyuealian/article/details/127907325" title="https://blog.csdn.net/guyuealian/article/details/127907325">https://blog.csdn.net/guyuealian/article/details/127907325</a></p> </li><li> <p id="articleContentId">智能驾驶 车辆检测（二）《YOLOv5实现车辆检测(含车辆检测数据集+训练代码)》：<a href="https://blog.csdn.net/guyuealian/article/details/128099672" title="https://blog.csdn.net/guyuealian/article/details/128099672">https://blog.csdn.net/guyuealian/article/details/128099672</a></p> </li><li> <p>智能驾驶 车辆检测（三）《Android实现车辆检测(含Android源码 可实时运行)》：<a href="https://blog.csdn.net/guyuealian/article/details/128190532" title="https://blog.csdn.net/guyuealian/article/details/128190532">https://blog.csdn.net/guyuealian/article/details/128190532</a></p> </li></ol> 
<hr> 
<h3 id="2.%20Fruit-Dataset%E6%B0%B4%E6%9E%9C%E6%95%B0%E6%8D%AE%E9%9B%86">2. 车辆检测数据集说明</h3> 
<h4 id="%EF%BC%881%EF%BC%89%20Fruit-Dataset">（1）车辆检测数据集</h4> 
<p>目前收集了约10W+的车辆检测数据集：<strong>UA-DETRAC车辆检测数据集+Vehicle-Dataset车辆检测数据集+BITVehicle车辆检测数据集: </strong></p> 
<p>关于车辆检测数据集使用说明和下载，详见另一篇博客说明：《<a href="https://blog.csdn.net/guyuealian/article/details/127907325" title="UA-DETRAC BITVehicle车辆检测数据集(含下载地址)">UA-DETRAC BITVehicle车辆检测数据集(含下载地址)</a>》</p> 
<h4 id="%EF%BC%883%EF%BC%89%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86">（2）自定义数据集</h4> 
<p>如果需要增/删类别数据进行训练，或者需要自定数据集进行训练，可参考如下步骤：</p> 
<blockquote> 
 <ol><li>采集图片，建议不少于200张图片</li><li>使用Labelme等标注工具，对目标进行拉框标注：labelme工具：<a href="https://github.com/wkentaro/labelme" title="GitHub - wkentaro/labelme: Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation).">GitHub - wkentaro/labelme: Image Polygonal Annotation with Python (polygon, rectangle, circle, line, point and image-level flag annotation).</a></li><li>将标注格式转换为VOC数据格式，参考工具：<a href="https://github.com/wkentaro/labelme/blob/main/examples/bbox_detection/labelme2voc.py" title="labelme/labelme2voc.py at main · wkentaro/labelme · GitHub">labelme/labelme2voc.py at main · wkentaro/labelme · GitHub</a></li><li>生成训练集train.txt和验证集val.txt文件列表</li><li>修改engine/configs/voc_local.yaml的train和val的数据路径</li><li>重新开始训练</li></ol> 
</blockquote> 
<p><img alt="" height="464" src="https://images2.imgbox.com/74/32/jydH3Vj8_o.png" width="429"></p> 
<hr> 
<h3 id="4.%20%E5%9F%BA%E4%BA%8EYOLOv5%E7%9A%84%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB%E8%AE%AD%E7%BB%83">3. 基于YOLOv5的车辆检测模型训练</h3> 
<h4 id="%EF%BC%881%EF%BC%89%E9%A1%B9%E7%9B%AE%E6%A1%86%E6%9E%B6%E8%AF%B4%E6%98%8E">（1）YOLOv5安装</h4> 
<p>训练Pipeline采用YOLOv5: <a href="https://github.com/ultralytics/yolov5" title="https://github.com/ultralytics/yolov5">https://github.com/ultralytics/yolov5</a> , 原始代码训练需要转换为YOLO的格式，不支持VOC的数据格式。为了适配VOC数据，本人新增了LoadVOCImagesAndLabels用于解析VOC数据集，以便正常训练。另外，为了方便测试，还增加demo.py文件，可支持对图片,视频和摄像头的测试。</p> 
<p>Python依赖环境，使用pip安装即可<span style="color:#fe2c24;"><strong>，项目代码都在Ubuntu系统和Windows系统验证正常运行，请放心使用；若出现异常，大概率是相关依赖包版本没有完全对应</strong></span></p> 
<pre><code class="language-python">
matplotlib&gt;=3.2.2
numpy&gt;=1.18.5
opencv-python&gt;=4.1.2
Pillow
PyYAML&gt;=5.3.1
scipy&gt;=1.4.1
torch&gt;=1.7.0
torchvision&gt;=0.8.1
tqdm&gt;=4.41.0
tensorboard&gt;=2.4.1
seaborn&gt;=0.11.0
pandas
thop  # FLOPs computation
pybaseutils==0.6.5</code></pre> 
<p> 项目安装教程请参考（<strong>初学者入门，麻烦先看完下面教程，配置好开发环境</strong>）：</p> 
<blockquote> 
 <ul><li><a href="https://blog.csdn.net/guyuealian/article/details/129163343" title="项目开发使用教程和常见问题和解决方法">项目开发使用教程和常见问题和解决方法</a></li><li><strong>视频教程：</strong><a href="https://www.bilibili.com/video/BV1sY411c7JS/?spm_id_from=333.999.0.0" rel="nofollow" title="1 手把手教你安装CUDA和cuDNN(1)">1 手把手教你安装CUDA和cuDNN(1)</a></li><li><strong>视频教程：</strong><a href="https://www.bilibili.com/video/BV1q5411d7GD/?spm_id_from=333.999.0.0" rel="nofollow" title="2 手把手教你安装CUDA和cuDNN(2)">2 手把手教你安装CUDA和cuDNN(2)</a></li><li><strong>视频教程：</strong><a href="https://www.bilibili.com/video/BV18Y411c7Qt/?spm_id_from=333.999.0.0" rel="nofollow" title="3 如何用Anaconda创建pycharm环境">3 如何用Anaconda创建pycharm环境</a></li><li><strong>视频教程：</strong><a href="https://www.bilibili.com/video/BV1SY4y1z7eS/?spm_id_from=333.999.0.0" rel="nofollow" title="4 如何在pycharm中使用Anaconda创建的python环境">4 如何在pycharm中使用Anaconda创建的python环境</a></li></ul> 
</blockquote> 
<h4 id="%EF%BC%881%EF%BC%89%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE">（2）准备Train和Test数据</h4> 
<p>下载车辆检测数据集，总共约10W+的图片：<strong>UA-DETRAC车辆检测数据集+Vehicle-Dataset车辆检测数据集+BITVehicle车辆检测数据集</strong></p> 
<p><img alt="" height="150" src="https://images2.imgbox.com/ca/25/ye1KEEih_o.png" width="408"></p> 
<p>考虑到<strong>UA-DETRAC车辆检测数据集</strong>比较大，其训练的模型的检测效果相对比较好，因此后续以<strong>UA-DETRAC车辆检测数据集</strong>为示例，说明训练过程。其他数据集训练，请根据自己环境，适当修改即可。</p> 
<h4 id="%EF%BC%883%EF%BC%89%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%EF%BC%9Aconfig.yaml">（3）配置数据文件</h4> 
<ul><li>修改训练和测试数据的路径：engine/configs/voc_local.yaml</li><li><span style="color:#fe2c24;">注意数据路径分隔符使用【/】,不是【\】</span></li><li><span style="color:#fe2c24;">项目不要出现含有中文字符的目录文件或路径，否则会出现很多异常！！！！！！！！</span></li></ul> 
<pre><code class="language-bash"># Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
# 数据路径
path: ""  # dataset root dir

# 注意数据路径分隔符使用【/】,不是【\】
# 项目不要出现含有中文字符的目录文件或路径，否则会出现很多异常！！！！！！！！
train:
  - "D:/path/to/UA-DETRAC/DETRAC-VOC/DETRAC-train-voc/train.txt"
  - "D:/path/to/UA-DETRAC/DETRAC-VOC/DETRAC-test-voc/test.txt" # 做模型性能测试时，测试集不要加入，避免指标有歧义

val:
  - "D:/path/to/UA-DETRAC/DETRAC-VOC/DETRAC-test-voc/test.txt"

test:  # test images (optional)
data_type: voc

# 1.设置类别个数，和要训练的类别名称，ID号从0开始递增
nc: 4  # number of classes
names: { 'car': 0, 'bus': 1,  'van': 2,'others': 3 }
# 2.如果你想合并几个类别进行训练，比如将'[car','bus','van']看作一类，others看作另一类，则
#nc: 2  # number of classes
#names: { 'car': 0, 'bus': 0,  'van': 0,'others': 1 }
# 3.如果你想合并所有类别为一个大类，进行训练： unique表示合并所有类为单独一个类别
#nc: 1  # number of classes
#names: { "unique": 0 }</code></pre> 
<ul><li>如果你想合并几个类别进行训练，比如将'[car','bus','van']看作一类，others看作另一类，则修改engine/configs/voc_local.yaml：</li></ul> 
<pre><code class="language-bash">nc: 2  # number of classes
names: { 'car': 0, 'bus': 0,  'van': 0,'others': 1 }</code></pre> 
<ul><li> 如果你想合并所有类别为一个大类，进行训练： <strong>unique表示合并所有类为单独一个类别</strong></li></ul> 
<pre><code class="language-bash">nc: 1  # number of classes
names: { "unique": 0 }</code></pre> 
<h4 id="%C2%A0%EF%BC%884%EF%BC%89%E6%A8%A1%E5%9E%8B%E9%85%8D%E7%BD%AE">（4）配置模型文件</h4> 
<p>官方YOLOv5给出了YOLOv5l,YOLOv5m,YOLOv5s等模型。考虑到手机端CPU/GPU性能比较弱鸡，直接部署yolov5s运行速度十分慢。所以本人在yolov5s基础上进行模型轻量化处理，即将yolov5s的模型的channels通道数全部都减少一半，并且模型输入由原来的640×640降低到416×416或者320×320，该轻量化的模型我称之为<strong>yolov5s05</strong>。从性能来看，<strong>yolov5s05比yolov5s快5多倍，而mAP下降了10%（</strong>0.57→0.47<strong>），对于手机端，这精度勉强可以接受。</strong></p> 
<p>下面是yolov5s05和yolov5s的参数量和计算量对比：</p> 
<table align="left" border="1" cellpadding="1" cellspacing="1"><tbody><tr><td><strong>模型</strong></td><td><strong>input-size</strong></td><td><strong>params(M)</strong></td><td><strong>GFLOPs</strong></td><td><strong>mAP0.5</strong></td></tr><tr><td><strong>yolov5s</strong></td><td>640×640</td><td>7.2</td><td>16.5</td><td>0.57192</td></tr><tr><td><strong>yolov5s05</strong></td><td>416×416</td><td>1.7</td><td>1.8</td><td>0.47022</td></tr><tr><td><strong>yolov5s05</strong></td><td>320×320</td><td>1.7</td><td>1.1</td><td>0.44788</td></tr></tbody></table> 
<p></p> 
<p></p> 
<p></p> 
<h4 id="%EF%BC%885%EF%BC%89%E9%87%8D%E6%96%B0%E8%81%9A%E7%B1%BBAnchor%EF%BC%88%E5%8F%AF%E9%80%89%EF%BC%89">（5）重新聚类Anchor（可选）</h4> 
<p>官方yolov5s的Anchor是基于COCO数据集进行聚类获得（详见models/yolov5s.yaml文件）</p> 
<p> <img alt="" height="254" src="https://images2.imgbox.com/7f/8f/hL2OZsBN_o.png" width="416"> </p> 
<p>对于yolov5s05的Anchor，由于输入大小640缩小到320，其对应的Anchor也应该缩小一倍：</p> 
<p> <img alt="" height="292" src="https://images2.imgbox.com/86/58/4Lr2A4mW_o.png" width="416"></p> 
<blockquote> 
 <p><strong>一点建议：</strong></p> 
 <ul><li>官方yolov5s的Anchor是基于COCO数据集进行聚类获得，不同数据集需要做适当的调整，其最优Anchor建议重新进行聚类 。</li><li>当然你要是觉得麻烦就跳过，不需要重新聚类Anchor，这个影响不是特别大。如果你需要重新聚类，请参考<span style="color:#fe2c24;">engine/kmeans_anchor/demo.p</span>y文件</li></ul> 
</blockquote> 
<h4 id="%EF%BC%886%EF%BC%89%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83"><strong>（6）开始训练</strong></h4> 
<p>整套训练代码非常简单操作，用户只需要将相同类别的数据放在同一个目录下，并填写好对应的数据路径，即可开始训练了。</p> 
<blockquote> 
 <ul><li>修改训练超参文件： data/hyps/hyp.scratch-v1.yaml （可以修改训练学习率，数据增强等方式，使用默认即可）</li><li>Linux系统终端运行，训练yolov5s或轻量化版本yolov5s05_416或者yolov5s05_320 (选择其中一个训练即可)</li></ul> 
</blockquote> 
<pre><code class="language-bash">#!/usr/bin/env bash

#--------------训练yolov5s--------------
# 输出项目名称路径
project="runs/yolov5s_640"
# 训练和测试数据的路径
data="engine/configs/voc_local.yaml"
# YOLOv5模型配置文件
cfg="yolov5s.yaml"
# 训练超参数文件
hyp="data/hyps/hyp.scratch-v1.yaml"
# 预训练文件
weights="engine/pretrained/yolov5s.pt"
python train.py --data $data --cfg $cfg --hyp $hyp --weights $weights --batch-size 16 --imgsz 640 --workers 4 --project $project


#--------------训练轻量化版本yolov5s05_416--------------
# 输出项目名称路径
project="runs/yolov5s05_416"
# 训练和测试数据的路径
data="engine/configs/voc_local.yaml"
# YOLOv5模型配置文件
cfg="yolov5s05_416.yaml"
# 训练超参数文件
hyp="data/hyps/hyp.scratch-v1.yaml"
# 预训练文件
weights="engine/pretrained/yolov5s.pt"
python train.py --data $data --cfg $cfg --hyp $hyp --weights $weights --batch-size 16 --imgsz 416 --workers 4 --project $project


#--------------训练轻量化版本yolov5s05_320--------------
# 输出项目名称路径
project="runs/yolov5s05_320"
# 训练和测试数据的路径
data="engine/configs/voc_local.yaml"
# YOLOv5模型配置文件
cfg="yolov5s05_320.yaml"
# 训练超参数文件
hyp="data/hyps/hyp.scratch-v1.yaml"
# 预训练文件
weights="engine/pretrained/yolov5s.pt"
python train.py --data $data --cfg $cfg --hyp $hyp --weights $weights --batch-size 16 --imgsz 320 --workers 4 --project $project

</code></pre> 
<p> </p> 
<blockquote> 
 <ul><li>Windows系统终端运行，yolov5s或轻量化版本yolov5s05_416或者yolov5s05_320 (选择其中一个训练即可)</li></ul> 
</blockquote> 
<pre><code class="language-bash">#!/usr/bin/env bash

#--------------训练yolov5s--------------
python train.py --data engine/configs/voc_local.yaml --cfg yolov5s.yaml --hyp data/hyps/hyp.scratch-v1.yaml --weights engine/pretrained/yolov5s.pt --batch-size 16 --imgsz 640 --workers 4 --project runs/yolov5s_640



#--------------训练轻量化版本yolov5s05_416--------------
python train.py --data engine/configs/voc_local.yaml --cfg yolov5s05_416.yaml --hyp data/hyps/hyp.scratch-v1.yaml --weights engine/pretrained/yolov5s.pt --batch-size 16 --imgsz 416 --workers 4 --project runs/yolov5s05_416



#--------------训练轻量化版本yolov5s05_320--------------
python train.py --data engine/configs/voc_local.yaml --cfg yolov5s05_320.yaml --hyp data/hyps/hyp.scratch-v1.yaml --weights engine/pretrained/yolov5s.pt --batch-size 16 --imgsz 320 --workers 4 --project runs/yolov5s05_320

</code></pre> 
<p></p> 
<ul><li>开始训练：</li></ul> 
<p><img alt="" height="575" src="https://images2.imgbox.com/04/dd/hKSls37f_o.png" width="816"></p> 
<ul><li>训练数据量比较大，训练时间比较长，请耐心等待哈</li><li>训练完成后，在模型输出目录中有个results.csv文件，记录每个epoch测试的结果，如loss,mAP等信息</li></ul> 
<blockquote> 
 <p>训练模型收敛后，yolov5s车辆检测的mAP指标大约mAP_0.5=0.57192；而，yolov5s05_416 mAP_0.5=0.47022左右；yolov5s05_320 mAP_0.5=0.44788左右</p> 
</blockquote> 
<p><img alt="" height="324" src="https://images2.imgbox.com/1d/0a/Ij82XhBq_o.png" width="846"></p> 
<h4 id="%EF%BC%883%EF%BC%89%20%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B">（7）可视化训练过程</h4> 
<p>训练过程可视化工具是使用Tensorboard，使用方法：</p> 
<pre><code class="language-bash"># 基本方法
tensorboard --logdir=path/to/log/
# 例如
tensorboard --logdir ./data/model/yolov5s_640</code></pre> 
<table border="1" cellpadding="1" cellspacing="1"><tbody><tr><td><img alt="" height="308" src="https://images2.imgbox.com/01/8f/JGlKGKjs_o.png" width="1033"></td></tr><tr><td><img alt="" height="297" src="https://images2.imgbox.com/16/a1/M3DW8Mhz_o.png" width="1030"></td></tr><tr><td><img alt="" height="245" src="https://images2.imgbox.com/45/08/qSyjGtkX_o.png" width="681"></td></tr><tr><td><img alt="" height="241" src="https://images2.imgbox.com/22/62/UcJO6Y0J_o.png" width="677"></td></tr></tbody></table> 
<p>当然，在输出目录，也保存很多性能指标的图片</p> 
<ul><li>这是训练epoch的可视化图，可以看到mAP随着Epoch训练，逐渐提高</li></ul> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/2f/77/ryj2R9VI_o.png" width="1200"></p> 
<p></p> 
<ul><li>这是每个类别的F1-Score分数</li></ul> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/2f/aa/Nx3dokTE_o.png" width="1200"></p> 
<p></p> 
<ul><li>这是模型的PR曲线</li></ul> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/7e/eb/PVhEJpXc_o.png" width="1200"></p> 
<ul><li>这是混淆矩阵：</li></ul> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/56/80/KQMqAJQH_o.png" width="1200"></p> 
<h4 id="%C2%A0%EF%BC%888%EF%BC%89%E5%B8%B8%E8%A7%81%E7%9A%84%E9%94%99%E8%AF%AF">（8）常见的错误</h4> 
<ul><li><a href="https://blog.csdn.net/guyuealian/article/details/128327221" title="YOLOv5 BUG修复记录">YOLOv5 BUG修复记录</a></li><li> 项目安装教程请参考：<a href="https://blog.csdn.net/guyuealian/article/details/129163343" title="项目开发使用教程和常见问题和解决方法">项目开发使用教程和常见问题和解决方法</a>   </li><li><strong>项目不要出现含有中文字符的目录文件或路径，否则会出现很多异常</strong>！！！！！！！！</li></ul> 
<hr> 
<h3 id="4.%20%E5%9E%83%E5%9C%BE%E5%88%86%E7%B1%BB%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E6%B5%8B%E8%AF%95%E6%95%88%E6%9E%9C">4. Python版本车辆检测效果</h3> 
<p>demo.py文件用于推理和测试模型的效果，填写好配置文件，模型文件以及测试图片即可运行测试了</p> 
<ul><li>测试图片</li></ul> 
<pre><code class="language-bash"># 测试图片(Linux系统)
image_dir='data/car-test' # 测试图片的目录
weights="data/model/yolov5s_640/weights/best.pt" # 模型文件
out_dir="runs/car-result" # 保存检测结果
python demo.py --image_dir $image_dir --weights $weights --out_dir $out_dir</code></pre> 
<p>Windows系统，请将$image_dir， $weights ，$out_dir等变量代替为对应的变量值即可，如</p> 
<pre><code class="language-bash"># 测试图片(Windows系统)
python demo.py --image_dir data/car-test --weights data/model/yolov5s_640/weights/best.pt --out_dir runs/car-result
</code></pre> 
<ul><li>测试视频文件</li></ul> 
<pre><code class="language-bash"># 测试视频文件(Linux系统)
video_file="data/car-video.mp4" # path/to/video.mp4 测试视频文件，如*.mp4,*.avi等
weights="data/model/yolov5s_640/weights/best.pt" # 模型文件
out_dir="runs/car-result" # 保存检测结果
python demo.py --video_file $video_file --weights $weights --out_dir $out_dir</code></pre> 
<pre><code class="language-bash"># 测试视频文件(Windows系统)
python demo.py --video_file data/car-video.mp4 --weights data/model/yolov5s_640/weights/best.pt --out_dir runs/car-result
</code></pre> 
<p></p> 
<ul><li> 测试摄像头</li></ul> 
<pre><code class="language-bash"># 测试摄像头(Linux系统)
video_file=0 # 测试摄像头ID
weights="data/model/yolov5s_640/weights/best.pt" # 模型文件
out_dir="runs/car-result" # 保存检测结果
python demo.py --video_file $video_file --weights $weights --out_dir $out_dir
</code></pre> 
<pre><code class="language-bash"># 测试摄像头(Windows系统)
python demo.py --video_file 0 --weights data/model/yolov5s_640/weights/best.pt --out_dir runs/car-result

</code></pre> 
<p></p> 
<table border="1" cellpadding="1" cellspacing="1"><tbody><tr><td><img alt="" height="234" src="https://images2.imgbox.com/c2/ad/5XPhpe1I_o.gif" width="416"></td><td><img alt="" height="234" src="https://images2.imgbox.com/6f/17/7ARMMR0Z_o.gif" width="416"></td></tr><tr><td><img alt="" height="540" src="https://images2.imgbox.com/b6/21/ZgGOWWk1_o.jpg" width="960"></td><td><img alt="" height="540" src="https://images2.imgbox.com/cd/79/Cz80Ksd8_o.jpg" width="960"></td></tr></tbody></table> 
<p>如果想进一步提高模型的性能，可以尝试：</p> 
<blockquote> 
 <ol><li>​增加训练的样本数据： 目前只有10W+的数据量，<strong>建议根据自己的业务场景，采集相关数据，提高模型泛化能力</strong></li><li>使用参数量更大的模型： 本教程使用的YOLOv5s，其参数量才7.2M，而YOLOv5x的参数量有86.7M，理论上其精度更高，但推理速度也较慢。</li><li>尝试不同数据增强的组合进行训练</li></ol> 
</blockquote> 
<hr> 
<h3 id="5.Android%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB">5. <a class="link-info" href="https://panjinquan.blog.csdn.net/article/details/128190532" rel="nofollow" title="Android版本车辆检测效果">Android版本车辆检测效果</a></h3> 
<p>已经完成Android版本车辆检测模型算法开发，APP在普通Android手机上可以达到实时的检测和识别效果，CPU(4线程)约30ms左右，GPU约20ms左右 ，基本满足业务的性能需求。详细说明请查看《<a class="link-info" href="https://panjinquan.blog.csdn.net/article/details/128190532" rel="nofollow" title="Android实现车辆检测(含Android源码，可实时运行)">Android实现车辆检测(含Android源码，可实时运行)</a>》</p> 
<p>Android Demo体验：</p> 
<p class="img-center"><img alt="" height="556" src="https://images2.imgbox.com/84/18/5W5LVKsg_o.gif" width="256"></p> 
<hr> 
<h3 id="%C2%A07.%E9%A1%B9%E7%9B%AE%E6%BA%90%E7%A0%81%E4%B8%8B%E8%BD%BD">6.项目源码下载</h3> 
<p>整套项目源码内容包含：<strong>车辆检测数据集 + YOLOv5训练代码和测试代码</strong></p> 
<p>整套项目下载地址：<a href="https://mp.weixin.qq.com/s/H8pLal6xNw4HCLNrTK4cCg" rel="nofollow" title="深度学习目标检测：YOLOv5实现车辆检测(含车辆检测数据集+训练代码)">深度学习目标检测：YOLOv5实现车辆检测(含车辆检测数据集+训练代码)</a></p> 
<p><strong>（1）车辆检测数据集：</strong><a href="https://blog.csdn.net/guyuealian/article/details/127907325" title="UA-DETRAC BITVehicle车辆检测数据集(含下载地址)">UA-DETRAC BITVehicle车辆检测数据集(含下载地址)</a></p> 
<blockquote> 
 <ol><li>UA-DETRAC车辆检测数据集</li><li>Vehicle-Dataset车辆检测数据集</li><li>BIT-Vehicle车辆检测数据集</li></ol> 
</blockquote> 
<p><strong>（2）YOLOv5训练代码和测试代码（Pytorch）</strong></p> 
<blockquote> 
 <ol><li>整套YOLOv5项目工程的训练代码和测试代码</li><li>支持高精度版本yolov5s训练和测试</li><li>支持轻量化版本yolov5s05_320和yolov5s05_416训练和测试</li><li>项目源码自带训练好的模型文件，可直接运行测试Demo</li><li>根据本篇博文说明，简单配置即可开始训练</li></ol> 
</blockquote> 
<p><strong>更多项目《智能驾驶 车牌检测和识别》系列文章请参考：</strong></p> 
<ol><li>智能驾驶 车牌检测和识别（一）《CCPD车牌数据集》：<a href="https://blog.csdn.net/guyuealian/article/details/128704181" title="https://blog.csdn.net/guyuealian/article/details/128704181">https://blog.csdn.net/guyuealian/article/details/128704181</a></li><li>智能驾驶 车牌检测和识别（二）《YOLOv5实现车牌检测（含车牌检测数据集和训练代码）》：<a href="https://blog.csdn.net/guyuealian/article/details/128704068" title="https://blog.csdn.net/guyuealian/article/details/128704068">https://blog.csdn.net/guyuealian/article/details/128704068</a></li><li>智能驾驶 车牌检测和识别（三）《CRNN和LPRNet实现车牌识别（含车牌识别数据集和训练代码）》：<a href="https://blog.csdn.net/guyuealian/article/details/128704209" title="https://blog.csdn.net/guyuealian/article/details/128704209">https://blog.csdn.net/guyuealian/article/details/128704209</a></li><li>智能驾驶 车牌检测和识别（四）《Android实现车牌检测和识别（可实时车牌识别）》：<a href="https://blog.csdn.net/guyuealian/article/details/128704242" title="https://blog.csdn.net/guyuealian/article/details/128704242">https://blog.csdn.net/guyuealian/article/details/128704242</a></li><li>智能驾驶 车牌检测和识别（五）《C++实现车牌检测和识别（可实时车牌识别）》：<a href="https://blog.csdn.net/guyuealian/article/details/128704276" title="https://blog.csdn.net/guyuealian/article/details/128704276">https://blog.csdn.net/guyuealian/article/details/128704276</a></li><li>智能驾驶 红绿灯检测（一）《红绿灯(交通信号灯)数据集》：<a href="https://blog.csdn.net/guyuealian/article/details/128222850" title="https://blog.csdn.net/guyuealian/article/details/128222850">https://blog.csdn.net/guyuealian/article/details/128222850</a></li><li>智能驾驶 红绿灯检测（二）《YOLOv5实现红绿灯检测(含红绿灯数据集+训练代码)》：<a href="https://blog.csdn.net/guyuealian/article/details/128240198" title="https://blog.csdn.net/guyuealian/article/details/128240198">https://blog.csdn.net/guyuealian/article/details/128240198</a></li><li>智能驾驶 红绿灯检测（三）《Android实现红绿灯检测(含Android源码 可实时运行)》：<a href="https://blog.csdn.net/guyuealian/article/details/128240334" title="https://blog.csdn.net/guyuealian/article/details/128240334">https://blog.csdn.net/guyuealian/article/details/128240334</a></li><li> <p id="articleContentId">智能驾驶 车辆检测（一）《UA-DETRAC BITVehicle车辆检测数据集》：<a href="https://blog.csdn.net/guyuealian/article/details/127907325" title="https://blog.csdn.net/guyuealian/article/details/127907325">https://blog.csdn.net/guyuealian/article/details/127907325</a></p> </li><li> <p id="articleContentId">智能驾驶 车辆检测（二）《YOLOv5实现车辆检测(含车辆检测数据集+训练代码)》：<a href="https://blog.csdn.net/guyuealian/article/details/128099672" title="https://blog.csdn.net/guyuealian/article/details/128099672">https://blog.csdn.net/guyuealian/article/details/128099672</a></p> </li><li> <p>智能驾驶 车辆检测（三）《Android实现车辆检测(含Android源码 可实时运行)》：<a href="https://blog.csdn.net/guyuealian/article/details/128190532" title="https://blog.csdn.net/guyuealian/article/details/128190532">https://blog.csdn.net/guyuealian/article/details/128190532</a></p> </li></ol> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2633004fc102cccd5c88278c94cb3d12/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【MySQL自学之路】第4天——模式、表、视图、索引（数据定义详细版）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/474d9e7d5c876a1b2dc889cc792d1d12/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">华为机试真题Java 实现【通信误码】【2022.11 Q4】</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>