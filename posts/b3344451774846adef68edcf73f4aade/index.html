<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【数据集】Learn2Reg2021 Task 03 —— 预处理的 OASIS 3D 脑部 MRI - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【数据集】Learn2Reg2021 Task 03 —— 预处理的 OASIS 3D 脑部 MRI" />
<meta property="og:description" content="Reference Learn2Reg: Comprehensive Multi-Task Medical Image Registration Challenge, Dataset and Evaluation in the Era of Deep Learning 👉
Abstract Medical image registration plays a very important role in improving clinical workflows, computer-assisted interventions and diagnosis as well as for research studies involving e.g. morphological analysis. Besides ongoing research into new concepts for optimisation, similarity metrics, domain adaptation and deformation models, deep learning for medical registration is currently starting to show promising advances that could improve the robustness, generalisation, computation speed and accuracy of conventional algorithms to enable better practical translation." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/b3344451774846adef68edcf73f4aade/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-09T09:39:38+08:00" />
<meta property="article:modified_time" content="2023-07-09T09:39:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【数据集】Learn2Reg2021 Task 03 —— 预处理的 OASIS 3D 脑部 MRI</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="Reference_0"></a>Reference</h4> 
<p>Learn2Reg: Comprehensive Multi-Task Medical Image Registration Challenge, Dataset and Evaluation in the Era of Deep Learning <a href="https://ieeexplore.ieee.org/ielx7/42/10057585/09925717.pdf" rel="nofollow">👉</a></p> 
<h4><a id="Abstract_2"></a>Abstract</h4> 
<blockquote> 
 <p>Medical image registration plays a very important role in improving clinical workflows, computer-assisted interventions and diagnosis as well as for research studies involving e.g. morphological analysis. Besides ongoing research into new concepts for optimisation, similarity metrics, domain adaptation and deformation models, <mark>deep learning for medical registration is currently starting to show promising advances that could improve the robustness, generalisation, computation speed and accuracy of conventional algorithms to enable better practical translation</mark>. <strong>Nevertheless, before Learn2Reg there was no commonly used benchmark dataset to compare stateof-the-art learning based registration among another and with their conventional (not trained) counterparts</strong>. With few exceptions (CuRIOUS at MICCAI 2018/2019, the Continuous Registration Challenge at WBIR 2018 and Learn2Reg 2020) there has also been no comprehensive registration challenge covering different anatomical structures and evaluation metrics. We also believe that the entry barrier for new teams to contribute to this emerging field are higher than e.g. for segmentation, where standardised datasets (e.g. Medical Decathlon, BraTS) are easily available. <mark>In contrast, many registration tasks, require resampling from different voxel spacings, affine pre-registration and can lead to ambiguous and error-prone evaluation of whole deformation fields</mark>. We propose a simplified challenge design that removes many of the common pitfalls for learning and applying transformations. <strong>We will provide pre-preprocessed data (resample, crop, pre-align, etc.) that can be directly employed by most conventional and learning frameworks</strong>. Only docker containers that generate displacement fields in voxel dimensions in a standard orientation will have to be provided by participants and python code to test their application (on local machines) to training data will be provided as open-source along with all evaluation metrics. Our challenge will consist of three clinically relevant sub-tasks (datasets) that are complementary in nature. <strong>They can either be individually or comprehensively addressed by participants and cover both intra- and inter-patient alignment, CT, ultrasound and MRI modalities, neuro-, thorax and abdominal anatomies and the four of the imminent challenges of medical image registration:</strong></p> 
 <ul><li><strong>learning from small datasets</strong></li><li><strong>estimating large deformations</strong></li><li><strong>dealing with multi-modal scans</strong></li><li><strong>learning from noisy annotations</strong></li></ul> 
</blockquote> 
<blockquote> 
 <p><mark>黄色部分</mark> 是可以直接引用在论文写作中的；<strong>黑体部分</strong> 是 <a href="https://learn2reg.grand-challenge.org/Description/" rel="nofollow">Learn2Reg2021</a> 的意义和提供的数据集以及提出的挑战。</p> 
</blockquote> 
<hr> 
<h4><a id="Task_03_Whole_Brain_MRI_13"></a>Task 03: Whole Brain MRI</h4> 
<h5><a id="Abstract_14"></a>Abstract</h5> 
<p>皮层下和脑深部结构涉及许多认知、记忆和情绪任务。众所周知，海马体与衰老、记忆和空间导航有关。全脑 MRI 的区域分析也被确定为阿尔茨海默病、精神分裂症和癫痫的病理生理学的关键指标。</p> 
<blockquote> 
 <p>Subcortical and deep brain structures are involved in many cognitive, memory and emotional tasks. The hippocampus e.g. is known to be involved in aging, memory, and spatial navigation. Regional analysis of whole brain MRI has also been identified as a key indicator for pathophysiology of Alzheimer’s disease, schizophrenia, and epilepsy.</p> 
</blockquote> 
<p>这项任务的挑战是在不同患者之间，在单模态 MRI 图像上以高精度对齐形状和大小可变的小结构。与其他任务相比，这种配准预计更容易估计：有较小的变形，MRI 中结构的对比度足够，并且在对齐之前解剖结构通常至少部分重叠。</p> 
<p>我们还期望对基于学习的配准有新的见解，因为这是一个包含大量有标注的 3D 扫描的大型数据集。 <a href="https://www.oasis-brains.org/" rel="nofollow">OASIS dataset project</a> 包含数百个神经成像数据集，专门专注于自由共享数据。</p> 
<p><strong>我们已经预处理了一个由 400 个大脑组成的重要亚组，分为训练（300）、验证（50）和测试（50）</strong>。我们使用几个软件包（FreeSurfer 7.1 和 SAMSEG）计算了包含 40 个皮质和皮质下解剖标签的分割图。我们将融合这些标签图，并在 MGH 神经科学家的帮助下手动验证所有 400 次扫描。</p> 
<blockquote> 
 <p>We have pre-processed a significant subgroup of 400 brains split among train (300), validation (50), and test (50).</p> 
</blockquote> 
<hr> 
<h5><a id="Keywords_26"></a>Keywords</h5> 
<p>inter-patient, MRI, brain, small deformation</p> 
<hr> 
<h5><a id="Cohorts_30"></a>Cohorts</h5> 
<ul><li> <p><strong>Target cohorts</strong> - 哪些主体 / 对象将在最终的应用中获得有用的数据？</p> <p>神经影像学配准是神经科学和临床治疗的一个重要部分，并规划了一系列疾病和程序，如神经退行性疾病（AD、精神分裂症、癫痫）或肿瘤切除术。</p> 
  <blockquote> 
   <p>Neuroimaging registration is an important part of neuroscience and clinical treatment and planning for a wide range of diseases and procedures, such as neurodegenerative diseases (AD, schizophrenia, epilepsy) or tumor resections.</p> 
  </blockquote> </li><li> <p><strong>challenge cohort</strong> - 获取这些数据的主体 / 对象。</p> <p>该数据集是 <a href="https://www.oasis-brains.org/" rel="nofollow">OASIS</a> 数据集项目的一部分 T1w MRI，其中包含数百个神经成像数据集，受试者年龄从 42 岁到 95 岁不等，涵盖正常人以及处于不同认知衰退阶段的受试者。</p> 
  <blockquote> 
   <p>The dataset consists of T1w MRIs acquired as part of the OASIS dataset project (https://www.oasis-brains.org/)</p> 
  </blockquote> </li></ul> 
<hr> 
<h5><a id="Imaging_modalityies_42"></a>Imaging modality(ies)</h5> 
<p>Magnetic Resonance Imaging (MRI)</p> 
<hr> 
<h5><a id="Algorithm_target_46"></a>Algorithm target</h5> 
<blockquote> 
 <p>即，说明算法设计用于关注的结构 / 主题 / 对象 / 组件（例如大脑肿瘤、医疗器械尖端、手术室护士、透视扫描中的导管）。</p> 
</blockquote> 
<p><strong>算法应该关注全脑 MRI 重要的神经解剖学区域：皮质、皮质下和脑深部结构。实现在同一模态（MRI）内，跨患者的皮质下和脑深部解剖结构的高度精确配准</strong></p> 
<blockquote> 
 <p>Whole brain MRI showing important neuroanatomical regions: cortical, subcortical and deep brain structures. Highly accurate alignment of subcortical and deep brain anatomy across patients within the same modality (MRI)</p> 
</blockquote> 
<hr> 
<h5><a id="Training_and_test_case_characteristics_54"></a>Training and test case characteristics</h5> 
<p>数据是获取的或重塑到 T1-weighted MRI 全脑扫描的 1x1x1mm 各向同性分辨率。</p> 
<ul><li> <p>说明训练、验证和测试案例的总数。</p> <p>Training: 300 cases + 50 validation<br> Test: 50 cases<br> 足够大的训练集得以可靠地训练深层网络。</p> 
  <blockquote> 
   <p>Sufficiently large number to robustly train deep networks.</p> 
  </blockquote> </li></ul> 
<hr> 
<h5><a id="_66"></a>手动分割标签的特征</h5> 
<p>Annotation characteristics</p> 
<p>40 个小结构（皮质下和脑深部）的自动自由曲面分割，手动验证。所使用的软件是 FreeSurfer 7.1 和 SAMSEG。<br> <img src="https://images2.imgbox.com/07/bb/OaeztkYt_o.png" alt="0"></p> 
<hr> 
<h5><a id="_73"></a>数据预处理</h5> 
<p>Data pre-processing method(s)</p> 
<p><strong>提供相同体素分辨率的通用预处理、强度标准化和空间维度以及仿射预配准</strong>，以便于先前在图像配准方面经验不足的参与者使用基于学习的算法。</p> 
<blockquote> 
 <p><strong>Common pre-processing to same voxel resolutions, intensity normalization, and spatial dimensions as well as affine pre-registration</strong> will be provided to ease the use of learning-based algorithms for participants with little prior experience in image registration.</p> 
</blockquote> 
<hr> 
<h5><a id="_81"></a>误差来源</h5> 
<p>先前的研究表明，在所有结构中，标注者之间的一致性达到超过 75% 的 Dice 值，但这些差异很大。某些深层结构（如丘脑）缺乏明显的对比，而皮层缺乏足够的分辨率。</p> 
<hr> 
<h5><a id="_85"></a>指标</h5> 
<ul><li>DSC (Dice similarity coefficient) of segmentations</li><li>HD95 (95% percentile of Haussdorff distance) of segmentations</li><li>Robustness: 30% lowest DSC of all cases</li><li>SD (standard deviation) of log Jacobian determinant</li><li>Run-time computation time</li></ul> 
<p>DSC 或 TRE 度量准确度；HD95 度量可靠性；使用稳健性得分（最低平均 DSC 的 30% 或最高平均 TRE 的 30%）对异常值进行惩罚；变形场的平滑度（对数雅可比行列式的标准差）在配准中很重要；运行时计算时间与临床应用相关。</p> 
<p>我们认为逆一致性（inverse consistency）是一个附加的度量标准，这在医学图像配准中是有争议的。我们决定不使用它作为竞争（排名）指标，而是出于信息的原因（即逆一致算法是否更稳健的问题）计算它。</p> 
<hr> 
<h5><a id="Baselines_97"></a>Baselines</h5> 
<p>我们将提供几种 baseline 算法来比较你的方法，包括：</p> 
<ul><li><a href="https://github.com/multimodallearning/pdd_net">PDD-Net (MICCAI '19)</a> unsupervised training</li><li><a href="https://blog.csdn.net/zuzhiang/article/details/108601599">Voxelmorph (CVPR’18)</a> with and without label supervision</li><li><a href="https://github.com/multimodallearning/pdd_net">Deeds</a></li><li>Elastix, NiftyReg, and/or <a href="https://blog.csdn.net/zuzhiang/article/details/104930000">ANTs</a> (where applicable)</li></ul> 
<hr> 
<p>得益于 MICCAI 2020 的成功经验，我们有信心为模态域迁移、无监督/弱监督学习、几何网络等前沿深度学习主题提供极具洞察力的新发现。。</p> 
<blockquote> 
 <p>provide very insightful new findings for cutting-edge deep learning topics such as domain adaptation, unsupervised/weaklysupervised learning, geometric networks, etc…</p> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e8d2c0aff5dc6e2906f1cda5adff8c66/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JAVA | 第一次例会</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6da2a1d46fcf26ea10954a456c2ecb94/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【数据集】Learn2Reg2021 Task 01 —— 3D 腹部多模态 MR-CT</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>