<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ã€æ•°æ®é›†ã€‘Learn2Reg2021 Task 03 â€”â€” é¢„å¤„ç†çš„ OASIS 3D è„‘éƒ¨ MRI - ç¼–ç¨‹éšæƒ³</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ã€æ•°æ®é›†ã€‘Learn2Reg2021 Task 03 â€”â€” é¢„å¤„ç†çš„ OASIS 3D è„‘éƒ¨ MRI" />
<meta property="og:description" content="Reference Learn2Reg: Comprehensive Multi-Task Medical Image Registration Challenge, Dataset and Evaluation in the Era of Deep Learning ğŸ‘‰
Abstract Medical image registration plays a very important role in improving clinical workflows, computer-assisted interventions and diagnosis as well as for research studies involving e.g. morphological analysis. Besides ongoing research into new concepts for optimisation, similarity metrics, domain adaptation and deformation models, deep learning for medical registration is currently starting to show promising advances that could improve the robustness, generalisation, computation speed and accuracy of conventional algorithms to enable better practical translation." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/b3344451774846adef68edcf73f4aade/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-09T09:39:38+08:00" />
<meta property="article:modified_time" content="2023-07-09T09:39:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹éšæƒ³" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹éšæƒ³</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ã€æ•°æ®é›†ã€‘Learn2Reg2021 Task 03 â€”â€” é¢„å¤„ç†çš„ OASIS 3D è„‘éƒ¨ MRI</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="Reference_0"></a>Reference</h4> 
<p>Learn2Reg: Comprehensive Multi-Task Medical Image Registration Challenge, Dataset and Evaluation in the Era of Deep Learning <a href="https://ieeexplore.ieee.org/ielx7/42/10057585/09925717.pdf" rel="nofollow">ğŸ‘‰</a></p> 
<h4><a id="Abstract_2"></a>Abstract</h4> 
<blockquote> 
 <p>Medical image registration plays a very important role in improving clinical workflows, computer-assisted interventions and diagnosis as well as for research studies involving e.g. morphological analysis. Besides ongoing research into new concepts for optimisation, similarity metrics, domain adaptation and deformation models, <mark>deep learning for medical registration is currently starting to show promising advances that could improve the robustness, generalisation, computation speed and accuracy of conventional algorithms to enable better practical translation</mark>. <strong>Nevertheless, before Learn2Reg there was no commonly used benchmark dataset to compare stateof-the-art learning based registration among another and with their conventional (not trained) counterparts</strong>. With few exceptions (CuRIOUS at MICCAI 2018/2019, the Continuous Registration Challenge at WBIR 2018 and Learn2Reg 2020) there has also been no comprehensive registration challenge covering different anatomical structures and evaluation metrics. We also believe that the entry barrier for new teams to contribute to this emerging field are higher than e.g. for segmentation, where standardised datasets (e.g. Medical Decathlon, BraTS) are easily available. <mark>In contrast, many registration tasks, require resampling from different voxel spacings, affine pre-registration and can lead to ambiguous and error-prone evaluation of whole deformation fields</mark>. We propose a simplified challenge design that removes many of the common pitfalls for learning and applying transformations. <strong>We will provide pre-preprocessed data (resample, crop, pre-align, etc.) that can be directly employed by most conventional and learning frameworks</strong>. Only docker containers that generate displacement fields in voxel dimensions in a standard orientation will have to be provided by participants and python code to test their application (on local machines) to training data will be provided as open-source along with all evaluation metrics. Our challenge will consist of three clinically relevant sub-tasks (datasets) that are complementary in nature. <strong>They can either be individually or comprehensively addressed by participants and cover both intra- and inter-patient alignment, CT, ultrasound and MRI modalities, neuro-, thorax and abdominal anatomies and the four of the imminent challenges of medical image registration:</strong></p> 
 <ul><li><strong>learning from small datasets</strong></li><li><strong>estimating large deformations</strong></li><li><strong>dealing with multi-modal scans</strong></li><li><strong>learning from noisy annotations</strong></li></ul> 
</blockquote> 
<blockquote> 
 <p><mark>é»„è‰²éƒ¨åˆ†</mark> æ˜¯å¯ä»¥ç›´æ¥å¼•ç”¨åœ¨è®ºæ–‡å†™ä½œä¸­çš„ï¼›<strong>é»‘ä½“éƒ¨åˆ†</strong> æ˜¯ <a href="https://learn2reg.grand-challenge.org/Description/" rel="nofollow">Learn2Reg2021</a> çš„æ„ä¹‰å’Œæä¾›çš„æ•°æ®é›†ä»¥åŠæå‡ºçš„æŒ‘æˆ˜ã€‚</p> 
</blockquote> 
<hr> 
<h4><a id="Task_03_Whole_Brain_MRI_13"></a>Task 03: Whole Brain MRI</h4> 
<h5><a id="Abstract_14"></a>Abstract</h5> 
<p>çš®å±‚ä¸‹å’Œè„‘æ·±éƒ¨ç»“æ„æ¶‰åŠè®¸å¤šè®¤çŸ¥ã€è®°å¿†å’Œæƒ…ç»ªä»»åŠ¡ã€‚ä¼—æ‰€å‘¨çŸ¥ï¼Œæµ·é©¬ä½“ä¸è¡°è€ã€è®°å¿†å’Œç©ºé—´å¯¼èˆªæœ‰å…³ã€‚å…¨è„‘ MRI çš„åŒºåŸŸåˆ†æä¹Ÿè¢«ç¡®å®šä¸ºé˜¿å°”èŒ¨æµ·é»˜ç—…ã€ç²¾ç¥åˆ†è£‚ç—‡å’Œç™«ç—«çš„ç—…ç†ç”Ÿç†å­¦çš„å…³é”®æŒ‡æ ‡ã€‚</p> 
<blockquote> 
 <p>Subcortical and deep brain structures are involved in many cognitive, memory and emotional tasks. The hippocampus e.g. is known to be involved in aging, memory, and spatial navigation. Regional analysis of whole brain MRI has also been identified as a key indicator for pathophysiology of Alzheimerâ€™s disease, schizophrenia, and epilepsy.</p> 
</blockquote> 
<p>è¿™é¡¹ä»»åŠ¡çš„æŒ‘æˆ˜æ˜¯åœ¨ä¸åŒæ‚£è€…ä¹‹é—´ï¼Œåœ¨å•æ¨¡æ€ MRI å›¾åƒä¸Šä»¥é«˜ç²¾åº¦å¯¹é½å½¢çŠ¶å’Œå¤§å°å¯å˜çš„å°ç»“æ„ã€‚ä¸å…¶ä»–ä»»åŠ¡ç›¸æ¯”ï¼Œè¿™ç§é…å‡†é¢„è®¡æ›´å®¹æ˜“ä¼°è®¡ï¼šæœ‰è¾ƒå°çš„å˜å½¢ï¼ŒMRI ä¸­ç»“æ„çš„å¯¹æ¯”åº¦è¶³å¤Ÿï¼Œå¹¶ä¸”åœ¨å¯¹é½ä¹‹å‰è§£å‰–ç»“æ„é€šå¸¸è‡³å°‘éƒ¨åˆ†é‡å ã€‚</p> 
<p>æˆ‘ä»¬è¿˜æœŸæœ›å¯¹åŸºäºå­¦ä¹ çš„é…å‡†æœ‰æ–°çš„è§è§£ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªåŒ…å«å¤§é‡æœ‰æ ‡æ³¨çš„ 3D æ‰«æçš„å¤§å‹æ•°æ®é›†ã€‚ <a href="https://www.oasis-brains.org/" rel="nofollow">OASIS dataset project</a> åŒ…å«æ•°ç™¾ä¸ªç¥ç»æˆåƒæ•°æ®é›†ï¼Œä¸“é—¨ä¸“æ³¨äºè‡ªç”±å…±äº«æ•°æ®ã€‚</p> 
<p><strong>æˆ‘ä»¬å·²ç»é¢„å¤„ç†äº†ä¸€ä¸ªç”± 400 ä¸ªå¤§è„‘ç»„æˆçš„é‡è¦äºšç»„ï¼Œåˆ†ä¸ºè®­ç»ƒï¼ˆ300ï¼‰ã€éªŒè¯ï¼ˆ50ï¼‰å’Œæµ‹è¯•ï¼ˆ50ï¼‰</strong>ã€‚æˆ‘ä»¬ä½¿ç”¨å‡ ä¸ªè½¯ä»¶åŒ…ï¼ˆFreeSurfer 7.1 å’Œ SAMSEGï¼‰è®¡ç®—äº†åŒ…å« 40 ä¸ªçš®è´¨å’Œçš®è´¨ä¸‹è§£å‰–æ ‡ç­¾çš„åˆ†å‰²å›¾ã€‚æˆ‘ä»¬å°†èåˆè¿™äº›æ ‡ç­¾å›¾ï¼Œå¹¶åœ¨ MGH ç¥ç»ç§‘å­¦å®¶çš„å¸®åŠ©ä¸‹æ‰‹åŠ¨éªŒè¯æ‰€æœ‰ 400 æ¬¡æ‰«æã€‚</p> 
<blockquote> 
 <p>We have pre-processed a significant subgroup of 400 brains split among train (300), validation (50), and test (50).</p> 
</blockquote> 
<hr> 
<h5><a id="Keywords_26"></a>Keywords</h5> 
<p>inter-patient, MRI, brain, small deformation</p> 
<hr> 
<h5><a id="Cohorts_30"></a>Cohorts</h5> 
<ul><li> <p><strong>Target cohorts</strong> - å“ªäº›ä¸»ä½“ / å¯¹è±¡å°†åœ¨æœ€ç»ˆçš„åº”ç”¨ä¸­è·å¾—æœ‰ç”¨çš„æ•°æ®ï¼Ÿ</p> <p>ç¥ç»å½±åƒå­¦é…å‡†æ˜¯ç¥ç»ç§‘å­¦å’Œä¸´åºŠæ²»ç–—çš„ä¸€ä¸ªé‡è¦éƒ¨åˆ†ï¼Œå¹¶è§„åˆ’äº†ä¸€ç³»åˆ—ç–¾ç—…å’Œç¨‹åºï¼Œå¦‚ç¥ç»é€€è¡Œæ€§ç–¾ç—…ï¼ˆADã€ç²¾ç¥åˆ†è£‚ç—‡ã€ç™«ç—«ï¼‰æˆ–è‚¿ç˜¤åˆ‡é™¤æœ¯ã€‚</p> 
  <blockquote> 
   <p>Neuroimaging registration is an important part of neuroscience and clinical treatment and planning for a wide range of diseases and procedures, such as neurodegenerative diseases (AD, schizophrenia, epilepsy) or tumor resections.</p> 
  </blockquote> </li><li> <p><strong>challenge cohort</strong> - è·å–è¿™äº›æ•°æ®çš„ä¸»ä½“ / å¯¹è±¡ã€‚</p> <p>è¯¥æ•°æ®é›†æ˜¯ <a href="https://www.oasis-brains.org/" rel="nofollow">OASIS</a> æ•°æ®é›†é¡¹ç›®çš„ä¸€éƒ¨åˆ† T1w MRIï¼Œå…¶ä¸­åŒ…å«æ•°ç™¾ä¸ªç¥ç»æˆåƒæ•°æ®é›†ï¼Œå—è¯•è€…å¹´é¾„ä» 42 å²åˆ° 95 å²ä¸ç­‰ï¼Œæ¶µç›–æ­£å¸¸äººä»¥åŠå¤„äºä¸åŒè®¤çŸ¥è¡°é€€é˜¶æ®µçš„å—è¯•è€…ã€‚</p> 
  <blockquote> 
   <p>The dataset consists of T1w MRIs acquired as part of the OASIS dataset project (https://www.oasis-brains.org/)</p> 
  </blockquote> </li></ul> 
<hr> 
<h5><a id="Imaging_modalityies_42"></a>Imaging modality(ies)</h5> 
<p>Magnetic Resonance Imaging (MRI)</p> 
<hr> 
<h5><a id="Algorithm_target_46"></a>Algorithm target</h5> 
<blockquote> 
 <p>å³ï¼Œè¯´æ˜ç®—æ³•è®¾è®¡ç”¨äºå…³æ³¨çš„ç»“æ„ / ä¸»é¢˜ / å¯¹è±¡ / ç»„ä»¶ï¼ˆä¾‹å¦‚å¤§è„‘è‚¿ç˜¤ã€åŒ»ç–—å™¨æ¢°å°–ç«¯ã€æ‰‹æœ¯å®¤æŠ¤å£«ã€é€è§†æ‰«æä¸­çš„å¯¼ç®¡ï¼‰ã€‚</p> 
</blockquote> 
<p><strong>ç®—æ³•åº”è¯¥å…³æ³¨å…¨è„‘ MRI é‡è¦çš„ç¥ç»è§£å‰–å­¦åŒºåŸŸï¼šçš®è´¨ã€çš®è´¨ä¸‹å’Œè„‘æ·±éƒ¨ç»“æ„ã€‚å®ç°åœ¨åŒä¸€æ¨¡æ€ï¼ˆMRIï¼‰å†…ï¼Œè·¨æ‚£è€…çš„çš®è´¨ä¸‹å’Œè„‘æ·±éƒ¨è§£å‰–ç»“æ„çš„é«˜åº¦ç²¾ç¡®é…å‡†</strong></p> 
<blockquote> 
 <p>Whole brain MRI showing important neuroanatomical regions: cortical, subcortical and deep brain structures. Highly accurate alignment of subcortical and deep brain anatomy across patients within the same modality (MRI)</p> 
</blockquote> 
<hr> 
<h5><a id="Training_and_test_case_characteristics_54"></a>Training and test case characteristics</h5> 
<p>æ•°æ®æ˜¯è·å–çš„æˆ–é‡å¡‘åˆ° T1-weighted MRI å…¨è„‘æ‰«æçš„ 1x1x1mm å„å‘åŒæ€§åˆ†è¾¨ç‡ã€‚</p> 
<ul><li> <p>è¯´æ˜è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ¡ˆä¾‹çš„æ€»æ•°ã€‚</p> <p>Training: 300 cases + 50 validation<br> Test: 50 cases<br> è¶³å¤Ÿå¤§çš„è®­ç»ƒé›†å¾—ä»¥å¯é åœ°è®­ç»ƒæ·±å±‚ç½‘ç»œã€‚</p> 
  <blockquote> 
   <p>Sufficiently large number to robustly train deep networks.</p> 
  </blockquote> </li></ul> 
<hr> 
<h5><a id="_66"></a>æ‰‹åŠ¨åˆ†å‰²æ ‡ç­¾çš„ç‰¹å¾</h5> 
<p>Annotation characteristics</p> 
<p>40 ä¸ªå°ç»“æ„ï¼ˆçš®è´¨ä¸‹å’Œè„‘æ·±éƒ¨ï¼‰çš„è‡ªåŠ¨è‡ªç”±æ›²é¢åˆ†å‰²ï¼Œæ‰‹åŠ¨éªŒè¯ã€‚æ‰€ä½¿ç”¨çš„è½¯ä»¶æ˜¯ FreeSurfer 7.1 å’Œ SAMSEGã€‚<br> <img src="https://images2.imgbox.com/07/bb/OaeztkYt_o.png" alt="0"></p> 
<hr> 
<h5><a id="_73"></a>æ•°æ®é¢„å¤„ç†</h5> 
<p>Data pre-processing method(s)</p> 
<p><strong>æä¾›ç›¸åŒä½“ç´ åˆ†è¾¨ç‡çš„é€šç”¨é¢„å¤„ç†ã€å¼ºåº¦æ ‡å‡†åŒ–å’Œç©ºé—´ç»´åº¦ä»¥åŠä»¿å°„é¢„é…å‡†</strong>ï¼Œä»¥ä¾¿äºå…ˆå‰åœ¨å›¾åƒé…å‡†æ–¹é¢ç»éªŒä¸è¶³çš„å‚ä¸è€…ä½¿ç”¨åŸºäºå­¦ä¹ çš„ç®—æ³•ã€‚</p> 
<blockquote> 
 <p><strong>Common pre-processing to same voxel resolutions, intensity normalization, and spatial dimensions as well as affine pre-registration</strong> will be provided to ease the use of learning-based algorithms for participants with little prior experience in image registration.</p> 
</blockquote> 
<hr> 
<h5><a id="_81"></a>è¯¯å·®æ¥æº</h5> 
<p>å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼Œåœ¨æ‰€æœ‰ç»“æ„ä¸­ï¼Œæ ‡æ³¨è€…ä¹‹é—´çš„ä¸€è‡´æ€§è¾¾åˆ°è¶…è¿‡ 75% çš„ Dice å€¼ï¼Œä½†è¿™äº›å·®å¼‚å¾ˆå¤§ã€‚æŸäº›æ·±å±‚ç»“æ„ï¼ˆå¦‚ä¸˜è„‘ï¼‰ç¼ºä¹æ˜æ˜¾çš„å¯¹æ¯”ï¼Œè€Œçš®å±‚ç¼ºä¹è¶³å¤Ÿçš„åˆ†è¾¨ç‡ã€‚</p> 
<hr> 
<h5><a id="_85"></a>æŒ‡æ ‡</h5> 
<ul><li>DSC (Dice similarity coefficient) of segmentations</li><li>HD95 (95% percentile of Haussdorff distance) of segmentations</li><li>Robustness: 30% lowest DSC of all cases</li><li>SD (standard deviation) of log Jacobian determinant</li><li>Run-time computation time</li></ul> 
<p>DSC æˆ– TRE åº¦é‡å‡†ç¡®åº¦ï¼›HD95 åº¦é‡å¯é æ€§ï¼›ä½¿ç”¨ç¨³å¥æ€§å¾—åˆ†ï¼ˆæœ€ä½å¹³å‡ DSC çš„ 30% æˆ–æœ€é«˜å¹³å‡ TRE çš„ 30%ï¼‰å¯¹å¼‚å¸¸å€¼è¿›è¡Œæƒ©ç½šï¼›å˜å½¢åœºçš„å¹³æ»‘åº¦ï¼ˆå¯¹æ•°é›…å¯æ¯”è¡Œåˆ—å¼çš„æ ‡å‡†å·®ï¼‰åœ¨é…å‡†ä¸­å¾ˆé‡è¦ï¼›è¿è¡Œæ—¶è®¡ç®—æ—¶é—´ä¸ä¸´åºŠåº”ç”¨ç›¸å…³ã€‚</p> 
<p>æˆ‘ä»¬è®¤ä¸ºé€†ä¸€è‡´æ€§ï¼ˆinverse consistencyï¼‰æ˜¯ä¸€ä¸ªé™„åŠ çš„åº¦é‡æ ‡å‡†ï¼Œè¿™åœ¨åŒ»å­¦å›¾åƒé…å‡†ä¸­æ˜¯æœ‰äº‰è®®çš„ã€‚æˆ‘ä»¬å†³å®šä¸ä½¿ç”¨å®ƒä½œä¸ºç«äº‰ï¼ˆæ’åï¼‰æŒ‡æ ‡ï¼Œè€Œæ˜¯å‡ºäºä¿¡æ¯çš„åŸå› ï¼ˆå³é€†ä¸€è‡´ç®—æ³•æ˜¯å¦æ›´ç¨³å¥çš„é—®é¢˜ï¼‰è®¡ç®—å®ƒã€‚</p> 
<hr> 
<h5><a id="Baselines_97"></a>Baselines</h5> 
<p>æˆ‘ä»¬å°†æä¾›å‡ ç§ baseline ç®—æ³•æ¥æ¯”è¾ƒä½ çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ï¼š</p> 
<ul><li><a href="https://github.com/multimodallearning/pdd_net">PDD-Net (MICCAI '19)</a> unsupervised training</li><li><a href="https://blog.csdn.net/zuzhiang/article/details/108601599">Voxelmorph (CVPRâ€™18)</a> with and without label supervision</li><li><a href="https://github.com/multimodallearning/pdd_net">Deeds</a></li><li>Elastix, NiftyReg, and/or <a href="https://blog.csdn.net/zuzhiang/article/details/104930000">ANTs</a> (where applicable)</li></ul> 
<hr> 
<p>å¾—ç›Šäº MICCAI 2020 çš„æˆåŠŸç»éªŒï¼Œæˆ‘ä»¬æœ‰ä¿¡å¿ƒä¸ºæ¨¡æ€åŸŸè¿ç§»ã€æ— ç›‘ç£/å¼±ç›‘ç£å­¦ä¹ ã€å‡ ä½•ç½‘ç»œç­‰å‰æ²¿æ·±åº¦å­¦ä¹ ä¸»é¢˜æä¾›æå…·æ´å¯ŸåŠ›çš„æ–°å‘ç°ã€‚ã€‚</p> 
<blockquote> 
 <p>provide very insightful new findings for cutting-edge deep learning topics such as domain adaptation, unsupervised/weaklysupervised learning, geometric networks, etcâ€¦</p> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e8d2c0aff5dc6e2906f1cda5adff8c66/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">JAVA | ç¬¬ä¸€æ¬¡ä¾‹ä¼š</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6da2a1d46fcf26ea10954a456c2ecb94/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">ã€æ•°æ®é›†ã€‘Learn2Reg2021 Task 01 â€”â€” 3D è…¹éƒ¨å¤šæ¨¡æ€ MR-CT</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 ç¼–ç¨‹éšæƒ³.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>