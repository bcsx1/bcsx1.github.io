<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>《PaddlePaddle从入门到炼丹》一——新版本PaddlePaddle的安装 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="《PaddlePaddle从入门到炼丹》一——新版本PaddlePaddle的安装" />
<meta property="og:description" content="前言 这一章我们介绍如何安装新版本的PaddlePaddle，这里说的新版本主要是说Fluid版本。Fluid 是设计用来让用户像Pytorch和Tensorflow Eager Execution一样执行程序。在这些系统中，不再有模型这个概念，应用也不再包含一个用于描述Operator图或者一系列层的符号描述，而是像通用程序那样描述训练或者预测的过程。也就是说PaddlePaddle从Fluid版本开始使用动态图机制，所以我们这个系列也是使用Fluid版本编写的教程。
环境 系统：64位Windows 10专业版，64位Ubuntu 16.04Python环境：Python 3.5内存：8G Windows下安装 PaddlePaddle在1.2版本之后开始支持Windows，也就是说使用Windows的用户不需要再安装Docker容器，或者使用Windows的Liunx子系统，直接可以在Windows系统本身安装PaddlePaddle。下面我们就介绍如何在Windows安装PaddlePaddle，分为两个部分介绍，首先安装Python 3.5环境，然后再使用命令安装PaddlePaddle。
安装Python 1、本系列使用的是Python 3.5，官方在Windows上支持Python2.7.15，Python3.5.x，Python3.6.x，Python3.7.x。读者根据自己的实际情况安装自己喜欢的版本。官网下载页面：https://www.python.org/downloads/windows/ ，官网下载地址：https://www.python.org/ftp/python/3.5.4/python-3.5.4-amd64.exe
2、双击运行Python 3.5安装包开始安装，记住要选上添加环境变量，这很重要，之后使用命令都要依赖这个环境变量，要不每次都要进入到pip的目录比较麻烦。然后点击Install Now开始安装。
3、安装完成之后，测试安装是否成功，打开Windows PowerShell或者cmd，笔者的系统是Windows 10，可以使用Windows PowerShell，如果读者是其他系统，可以使用cmd。用命令python -V查看是否安装成功。正常安装之后可以显示安装Python的版本。
安装PaddlePaddle PaddlePaddle支持Windows之后，安装起来非常简单，只需要一条命令就可以完成安装。
安装CPU版本，打开Windows PowerShell，输入以下命令。可以使用==指定安装PaddlePaddle的版本，如没有指定版本，默认安装是最新版本。-i后面是镜像源地址，使用国内镜像源可以大大提高下载速度： pip3 install paddlepaddle==1.4.1 -i https://mirrors.aliyun.com/pypi/simple/ 安装GPU版本，目前支持Windows的CUDA 8.0 cuDNN v7的GPU版本 pip3 install paddlepaddle-gpu==1.4.1 -i https://mirrors.aliyun.com/pypi/simple/ 测试安装是否成功，在Windows PowerShell中输入命令python，进入到Python 编辑环境，并输入以下代码，导没有保存证明安装成功： import paddle.fluid Ubuntu下安装 下面介绍在Ubuntu系统下安装PaddlePaddle，PaddlePaddle支持64位的Ubuntu 14.04 /16.04 /18.04系统，Python支持Python2.7.15，Python3.5.x，Python3.6.x，Python3.7.x。
安装Python 3.5（通常不需要执行）。通常情况下Ubuntu 16.04自带的就是Python 3.5，其他Ubuntu的版本自带的可能是其他版本，不过没有关系，PaddlePaddle基本都支持，所以不必专门安装Python3.5。 sudo apt install python3.5 sudo apt install python3.5-dev 安装CPU版本，打开Ubuntu的终端，快捷键是Ctrl&#43;Alt&#43;T，输入以下命令。可以使用==指定安装PaddlePaddle的版本，如没有指定版本，默认安装是最新版本。-i后面是镜像源地址，使用国内镜像源可以大大提高下载速度： pip3 install paddlepaddle==1.4.1 -i https://mirrors." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/1d2743f32ff86436e51d162f1019819b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-25T23:18:18+08:00" />
<meta property="article:modified_time" content="2023-05-25T23:18:18+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">《PaddlePaddle从入门到炼丹》一——新版本PaddlePaddle的安装</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_2"></a>前言</h2> 
<p>这一章我们介绍如何安装新版本的PaddlePaddle，这里说的新版本主要是说Fluid版本。Fluid 是设计用来让用户像Pytorch和Tensorflow Eager Execution一样执行程序。在这些系统中，不再有模型这个概念，应用也不再包含一个用于描述Operator图或者一系列层的符号描述，而是像通用程序那样描述训练或者预测的过程。也就是说PaddlePaddle从Fluid版本开始使用动态图机制，所以我们这个系列也是使用Fluid版本编写的教程。</p> 
<h2><a id="_5"></a>环境</h2> 
<ul><li>系统：64位Windows 10专业版，64位Ubuntu 16.04</li><li>Python环境：Python 3.5</li><li>内存：8G</li></ul> 
<h2><a id="Windows_10"></a>Windows下安装</h2> 
<p>PaddlePaddle在1.2版本之后开始支持Windows，也就是说使用Windows的用户不需要再安装Docker容器，或者使用Windows的Liunx子系统，直接可以在Windows系统本身安装PaddlePaddle。下面我们就介绍如何在Windows安装PaddlePaddle，分为两个部分介绍，首先安装Python 3.5环境，然后再使用命令安装PaddlePaddle。</p> 
<h3><a id="Python_13"></a>安装Python</h3> 
<p>1、本系列使用的是Python 3.5，官方在Windows上支持Python2.7.15，Python3.5.x，Python3.6.x，Python3.7.x。读者根据自己的实际情况安装自己喜欢的版本。官网下载页面：https://www.python.org/downloads/windows/ ，官网下载地址：https://www.python.org/ftp/python/3.5.4/python-3.5.4-amd64.exe<br> <img src="https://images2.imgbox.com/32/28/VRlPGfN0_o.png" alt="在这里插入图片描述"></p> 
<p>2、双击运行Python 3.5安装包开始安装，记住要选上添加环境变量，这很重要，之后使用命令都要依赖这个环境变量，要不每次都要进入到<code>pip</code>的目录比较麻烦。然后点击<code>Install Now</code>开始安装。<br> <img src="https://images2.imgbox.com/54/f6/RkEVPB92_o.png" alt="在这里插入图片描述"></p> 
<p>3、安装完成之后，测试安装是否成功，打开<code>Windows PowerShell</code>或者<code>cmd</code>，笔者的系统是Windows 10，可以使用<code>Windows PowerShell</code>，如果读者是其他系统，可以使用<code>cmd</code>。用命令<code>python -V</code>查看是否安装成功。正常安装之后可以显示安装Python的版本。<br> <img src="https://images2.imgbox.com/40/a8/o8wEmKG7_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="PaddlePaddle_23"></a>安装PaddlePaddle</h3> 
<p>PaddlePaddle支持Windows之后，安装起来非常简单，只需要一条命令就可以完成安装。</p> 
<ul><li>安装CPU版本，打开<code>Windows PowerShell</code>，输入以下命令。可以使用<code>==</code>指定安装PaddlePaddle的版本，如没有指定版本，默认安装是最新版本。<code>-i</code>后面是镜像源地址，使用国内镜像源可以大大提高下载速度：</li></ul> 
<pre><code>pip3 install paddlepaddle==1.4.1 -i https://mirrors.aliyun.com/pypi/simple/
</code></pre> 
<ul><li>安装GPU版本，目前支持Windows的CUDA 8.0 cuDNN v7的GPU版本</li></ul> 
<pre><code>pip3 install paddlepaddle-gpu==1.4.1 -i https://mirrors.aliyun.com/pypi/simple/
</code></pre> 
<ul><li>测试安装是否成功，在<code>Windows PowerShell</code>中输入命令<code>python</code>，进入到Python 编辑环境，并输入以下代码，导没有保存证明安装成功：</li></ul> 
<pre><code>import paddle.fluid
</code></pre> 
<p><img src="https://images2.imgbox.com/56/8c/E4VjUTDg_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Ubuntu_43"></a>Ubuntu下安装</h2> 
<p>下面介绍在Ubuntu系统下安装PaddlePaddle，PaddlePaddle支持64位的Ubuntu 14.04 /16.04 /18.04系统，Python支持Python2.7.15，Python3.5.x，Python3.6.x，Python3.7.x。</p> 
<ul><li>安装Python 3.5（通常不需要执行）。通常情况下Ubuntu 16.04自带的就是Python 3.5，其他Ubuntu的版本自带的可能是其他版本，不过没有关系，PaddlePaddle基本都支持，所以不必专门安装Python3.5。</li></ul> 
<pre><code>sudo apt install python3.5
sudo apt install python3.5-dev
</code></pre> 
<ul><li>安装CPU版本，打开Ubuntu的终端，快捷键是<code>Ctrl+Alt+T</code>，输入以下命令。可以使用<code>==</code>指定安装PaddlePaddle的版本，如没有指定版本，默认安装是最新版本。<code>-i</code>后面是镜像源地址，使用国内镜像源可以大大提高下载速度：</li></ul> 
<pre><code>pip3 install paddlepaddle==1.4.1 -i https://mirrors.aliyun.com/pypi/simple/
</code></pre> 
<ul><li>安装GPU版本，安装GPU版本之前，要先安装CUDA，可以查看笔者之前的文章<a href="https://blog.csdn.net/qq_33200967/article/details/80689543">《Ubuntu安装和卸载CUDA和CUDNN》</a>，安装完成 CUDA 9 和 CUDNN 7 之后，再安装PaddlePaddle的GPU版本，安装命令如下。可以使用<code>==</code>指定安装PaddlePaddle的版本和CUDA、CUDNN的版本，这必须要跟读者系统本身安装的CUDA版本对应，比如以下命令就是安装支持CUDA 9.0和CUDNN 7的PaddlePaddle版本。<code>-i</code>后面是镜像源地址，使用国内镜像源可以大大提高下载速度：</li></ul> 
<pre><code>pip3 install paddlepaddle-gpu==1.4.1.post97 -i https://mirrors.aliyun.com/pypi/simple/
</code></pre> 
<ul><li>测试安装是否成功，在终端中输入命令<code>python3</code>，进入到Python 编辑环境，并输入以下代码，正确情况下如图所示：</li></ul> 
<pre><code>import paddle.fluid
</code></pre> 
<p><img src="https://images2.imgbox.com/86/f2/LP7iNM3Q_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_68"></a>源码编译</h2> 
<p>这部分我们将介绍使用源码编译PaddlePaddle，可以通过这种方式安装符合读者需求的PaddlePaddle，比如笔者的电脑安装的是CUDA 10 和 CUDNN 7，而目前官方提供的没有支持CUDA 10 和 CUDNN 7的PaddlePaddle版本，所以笔者就可以通过源码编译的方式编译PaddlePaddle安装包，当然也要PaddlePaddle支持才行。</p> 
<h3><a id="Windows_71"></a>Windows下源码编译</h3> 
<p>下面我们将介绍在Windows系统下进行源码编译PaddlePaddle。目前支持使用的系统是64位的Windows 10 家庭版/专业版/企业版。</p> 
<ol><li> <p>安装<code>Visual Studio 2015 Update3</code>。下载地址：https://visualstudio.microsoft.com/zh-hans/vs/older-downloads/ ，因为是旧版本，还有<code>加入免费的 Dev Essentials 计划</code>才能正常下载。<br> <img src="https://images2.imgbox.com/58/6e/ZWKMNIYZ_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/5d/73/GM9Zhw3T_o.png" alt="在这里插入图片描述"></p> </li><li> <p>安装<code>cmake 3.13</code>，下载cmake的安装包，下载地址：https://cmake.org/download/ ，一路默认，只需要在添加环境变量的时候注意添加环境变量就可以了。如何存在环境变量问题，可以重启系统。<br> <img src="https://images2.imgbox.com/99/42/7qoU23na_o.png" alt="在这里插入图片描述"></p> </li><li> <p>安装Python的依赖库，只要执行以下命令。关于Windows安装Python，在“Windows下安装”部分已经介绍过，这里就不介绍了。</p> </li></ol> 
<pre><code>pip3 install numpy
pip3 install protobuf
pip3 install wheel
</code></pre> 
<ol start="4"><li> <p>安装 git 工具。git的下载地址：https://git-scm.com/downloads ，下载git的安装包，安装的时候一路默认就可以了。<br> <img src="https://images2.imgbox.com/b1/b1/ZbVljFJv_o.png" alt="在这里插入图片描述"></p> </li><li> <p>右键打开<code>Git Bash Here</code>，执行以下两条命令。将PaddlePaddle的源码clone在当下目录下的Paddle的文件夹中，并进入Padde目录下，操作如下图所示，之后的命令也是在这个终端操作：</p> </li></ol> 
<pre><code>git clone https://github.com/PaddlePaddle/Paddle.git
cd Paddle
</code></pre> 
<p><img src="https://images2.imgbox.com/24/c3/0HsV3r8Z_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b7/26/ePcnV69P_o.png" alt="在这里插入图片描述"></p> 
<ol start="6"><li>切换到较稳定release分支下进行编译，入笔者选择1.2版本的代码：</li></ol> 
<pre><code>git checkout release/1.2
</code></pre> 
<ol start="7"><li>创建名为build的目录并进入：</li></ol> 
<pre><code>mkdir build
cd build
</code></pre> 
<ol start="8"><li> <p>执行编译</p> 
  <ul><li>编译<strong>CPU版本</strong>命令如下：</li></ul> <pre><code>cmake .. -G "Visual Studio 14 2015 Win64" -DPY_VERSION=3.5 -DPYTHON_INCLUDE_DIR=${PYTHON_INCLUDE_DIRS} -DPYTHON_LIBRARY=${PYTHON_LIBRARY} -DPYTHON_EXECUTABLE=${PYTHON_EXECUTABLE} -DWITH_FLUID_ONLY=ON -DWITH_GPU=OFF -DWITH_TESTING=OFF -DCMAKE_BUILD_TYPE=Release
</code></pre> 
  <ul><li>编译<strong>GPU版本</strong>，目前Windows还不支持GPU，支持后会更新。</li></ul> </li></ol> 
<p><img src="https://images2.imgbox.com/50/70/46qpHpcZ_o.png" alt="在这里插入图片描述"><br> 9. 下载第三方依赖包（openblas，snappystream），下载地址：https://github.com/wopeizl/Paddle_deps ，将整个<code>third_party</code>文件夹放到上面第7步创建的<code>build</code>目录下。<br> 10. 使用<code>Blend for Visual Studio 2015</code> 打开<code>paddle.sln</code>文件，选择平台为<code>x64</code>，配置为<code>Release</code>，开始编译<br> 11. 编译成功后进入<code>\paddle\build\python\dist</code>目录下找到生成的<code>.whl</code>包<br> 12. 执行以下命令安装编译好的PaddlePaddle包：</p> 
<pre><code>pip3 install （whl包的名字）
</code></pre> 
<h3><a id="Ubuntu_127"></a>Ubuntu本地下源码编译</h3> 
<p>下面介绍的是使用Ubuntu编译PaddlePaddle源码，笔者的系统是64位的Ubuntu 16.04，Python环境是Python 3.5。</p> 
<h4><a id="openCV_130"></a>安装openCV</h4> 
<ol><li>更新apt的源，命令如下：</li></ol> 
<pre><code>sudo apt update
</code></pre> 
<ol start="2"><li> <p>下载openCV源码，官方地址：https://opencv.org/releases.html ， 笔者下载的是3.4.5版本，选择的是<code>Sources</code>点击下载。<br> <img src="https://images2.imgbox.com/b3/a3/j9GHnt96_o.png" alt="在这里插入图片描述"></p> </li><li> <p>解压openCV源码，命令如下：</p> </li></ol> 
<pre><code>unzip opencv-3.4.5.zip
</code></pre> 
<ol start="4"><li>安装可能需要的依赖库，命令如下：</li></ol> 
<pre><code>sudo apt-get install cmake
sudo apt-get install build-essential libgtk2.0-dev libavcodec-dev libavformat-dev libjpeg.dev libtiff4.dev libswscale-dev libjasper-dev
</code></pre> 
<ol start="5"><li>开始执行cmake。</li></ol> 
<pre><code>cd opencv-3.4.5/
mkdir my_build_dir
cd my_build_dir
cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..
</code></pre> 
<ol start="6"><li>开始执行编译</li></ol> 
<pre><code>make -j$(nproc)
</code></pre> 
<ol start="7"><li>执行安装命令</li></ol> 
<pre><code>sudo make install
</code></pre> 
<h4><a id="_168"></a>安装依赖环境</h4> 
<p>编译PaddlePaddle源码之前，还需要安装以下的一些依赖环境。</p> 
<pre><code>sudo apt install python3.5-dev
sudo apt-get udpate
sudo apt-get install -y software-properties-common
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt install curl
sudo curl https://bootstrap.pypa.io/get-pip.py -o - | python3.5
sudo easy_install pip
sudo apt install swig
sudo apt install wget
sudo pip install numpy==1.14.0
sudo pip install protobuf==3.1.0
sudo pip install wheel
sudo apt install patchelf
</code></pre> 
<h4><a id="PaddlePaddle_186"></a>编译PaddlePaddle</h4> 
<ol><li>将PaddlePaddle的源码clone在当下目录下的Paddle的文件夹中，并进入Padde目录下，命令如下：</li></ol> 
<pre><code>git clone https://github.com/PaddlePaddle/Paddle.git
cd Paddle
</code></pre> 
<ol start="2"><li>切换到较稳定release分支下进行编译，比如笔者使用的是1.2版本，读者可以根据自己的情况选择其他版本：</li></ol> 
<pre><code>git checkout release/1.4
</code></pre> 
<ol start="3"><li>创建并进入一个叫build的目录下：</li></ol> 
<pre><code>mkdir build &amp;&amp; cd build
</code></pre> 
<ol start="4"><li> <p>执行cmake，这里分为CPU版本和GPU版本。</p> 
  <ul><li>编译<strong>CPU版本</strong>，命令如下。使用参数<code>-DPY_VERSION</code>指定编译的PaddlePaddle支持的Python版本，笔者这里选择的是Python 3.5。并且使用参数<code>-DWITH_FLUID_ONLY</code>指定不编译V2版本的PaddlePaddle代码。使用参数<code>-DWITH_GPU</code>指定不使用GPU，也就是只编译CPU版本：</li></ul> <pre><code>cmake .. -DPY_VERSION=3.5 -DWITH_FLUID_ONLY=ON -DWITH_GPU=OFF -DWITH_TESTING=OFF -DCMAKE_BUILD_TYPE=Release
</code></pre> 
  <ul><li>编译<strong>GPU版本</strong>，还要安装一下依赖环境，如下： 
    <ol><li>安装 CUDA 和 CUDNN，可以查看笔者之前的文章<a href="https://blog.csdn.net/qq_33200967/article/details/80689543">《Ubuntu安装和卸载CUDA和CUDNN》</a></li><li>安装nccl2，命令如下</li></ol> <pre><code>wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb
dpkg -i nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb
sudo apt-get install -y libnccl2=2.2.13-1+cuda9.0 libnccl-dev=2.2.13-1+cuda9.0
</code></pre> 
    <ol start="3"><li>执行cmake。使用参数<code>-DPY_VERSION</code>指定编译的PaddlePaddle支持的Python版本，笔者这里选择的是Python 3.5。并且使用参数<code>-DWITH_FLUID_ONLY</code>指定不编译V2版本的PaddlePaddle代码。使用参数<code>-DWITH_GPU</code>指定使用GPU，同时编译支持CPU和GPU版本的PaddlePaddle。</li></ol> <pre><code>cmake .. -DPY_VERSION=3.5 -DWITH_FLUID_ONLY=ON -DWITH_GPU=ON -DWITH_TESTING=OFF -DCMAKE_BUILD_TYPE=Release
</code></pre> </li></ul> </li><li> <p>使用以下命令正式编译，编译时间比较长：</p> </li></ol> 
<pre><code>make -j$(nproc)
</code></pre> 
<ol start="6"><li>编译成功后进入<code>/paddle/build/python/dist</code>目录下找到生成的PaddlePaddle<code>.whl</code>包，可以使用这个命令进入到指定目录。</li></ol> 
<pre><code>cd /paddle/build/python/dist
</code></pre> 
<ol start="7"><li>在当前机器或目标机器安装编译好的<code>.whl</code>包：</li></ol> 
<pre><code>pip3 install （whl包的名字）
</code></pre> 
<h3><a id="UbuntuDocker_237"></a>Ubuntu使用Docker源码编译</h3> 
<p>使用docker编译的安装包只能支持Ubuntu的PaddlePaddle，因为下载docker镜像也是Ubuntu系统的。通过使用docker编译PaddlePaddle得到的安装包，可以在docker本身使用，之后可以使用docker执行PaddlePaddle。也可以本地的Ubuntu上安装使用，不过要注意的是docker中的系统是Ubuntu 16.04。</p> 
<h4><a id="Docker_240"></a>安装Docker</h4> 
<ol><li>安装前准备</li></ol> 
<pre><code class="prism language-shell"><span class="token comment"># 卸载系统原有docker</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> remove docker docker-engine docker.io containerd runc
<span class="token comment"># 更新apt-get源 </span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token comment"># 安装docker的依赖 </span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token punctuation">\</span>
    apt-transport-https <span class="token punctuation">\</span>
    ca-certificates <span class="token punctuation">\</span>
    <span class="token function">curl</span> <span class="token punctuation">\</span>
    gnupg-agent <span class="token punctuation">\</span>
    software-properties-common
<span class="token comment"># 添加Docker的官方GPG密钥：</span>
<span class="token function">curl</span> -fsSL https://download.docker.com/linux/ubuntu/gpg <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> -
<span class="token comment"># 验证拥有指纹</span>
<span class="token function">sudo</span> apt-key fingerprint 0EBFCD88
<span class="token comment"># 设置稳定存储库</span>
<span class="token function">sudo</span> add-apt-repository <span class="token punctuation">\</span>
   <span class="token string">"deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   <span class="token variable"><span class="token variable">$(</span>lsb_release -cs<span class="token variable">)</span></span> \
   stable"</span>
</code></pre> 
<ol start="2"><li>安装Docker，编译<strong>CPU版本</strong>使用。</li></ol> 
<pre><code class="prism language-shell"><span class="token comment"># 再次更新apt-get源 </span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token comment"># 开始安装docker </span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> docker-ce
<span class="token comment"># 加载docker </span>
<span class="token function">sudo</span> <span class="token function">apt-cache</span> madison docker-ce
<span class="token comment"># 验证docker是否安装成功</span>
<span class="token function">sudo</span> docker run hello-world
</code></pre> 
<p>正常情况下输出如下图所示。<br> <img src="https://images2.imgbox.com/ab/f9/WSGxc5CD_o.png" alt="在这里插入图片描述"></p> 
<ol start="3"><li>安装nvidia-docker，编译<strong>GPU版本</strong>使用（根据情况安装）。安装之前要确认本地有独立显卡并安装的显卡驱动。</li></ol> 
<pre><code class="prism language-shell"><span class="token comment"># 设置stable存储库和GPG密钥</span>
<span class="token assign-left variable">distribution</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">.</span> /etc/os-release<span class="token punctuation">;</span><span class="token builtin class-name">echo</span> $ID$VERSION_ID<span class="token variable">)</span></span> <span class="token punctuation">\</span>
   <span class="token operator">&amp;&amp;</span> <span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-docker/gpgkey <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> - <span class="token punctuation">\</span>
   <span class="token operator">&amp;&amp;</span> <span class="token function">curl</span> -s -L https://nvidia.github.io/nvidia-docker/<span class="token variable">$distribution</span>/nvidia-docker.list <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/nvidia-docker.list

<span class="token comment"># 更新软件包清单后</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> update

<span class="token comment"># 安装软件包</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> -y nvidia-docker2

<span class="token comment"># 设置默认运行时后，重新启动Docker守护程序以完成安装：</span>
<span class="token function">sudo</span> systemctl restart docker

<span class="token comment"># 测试</span>
<span class="token function">sudo</span> docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
</code></pre> 
<h4><a id="PaddlePaddle_299"></a>编译PaddlePaddle</h4> 
<ol><li>克隆PaddlePaddle源码：</li></ol> 
<pre><code class="prism language-shell"><span class="token function">git</span> clone https://github.com/PaddlePaddle/Paddle.git
</code></pre> 
<ol start="2"><li>进入Paddle目录下：</li></ol> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> Paddle
</code></pre> 
<ol start="3"><li> <p>启动docker镜像</p> 
  <ul><li>编译<strong>CPU版本</strong>，使用命令</li></ul> <pre><code class="prism language-shell"><span class="token function">sudo</span> docker run --name paddle-test -v <span class="token environment constant">$PWD</span>:/paddle --network<span class="token operator">=</span>host -it hub.baidubce.com/paddlepaddle/paddle:latest-dev /bin/bash
</code></pre> 
  <ul><li>编译<strong>GPU版本</strong>，使用命令</li></ul> <pre><code class="prism language-shell"><span class="token function">sudo</span> nvidia-docker run --name paddle-test -v <span class="token environment constant">$PWD</span>:/paddle --network<span class="token operator">=</span>host -it hub.baidubce.com/paddlepaddle/paddle:latest-dev /bin/bash
</code></pre> </li><li> <p>进入Docker后进入paddle目录下：</p> </li></ol> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> paddle
</code></pre> 
<ol start="5"><li>切换到较稳定release分支下进行编译，读者可以根据自己的情况选择其他版本：</li></ol> 
<pre><code class="prism language-shell"><span class="token function">git</span> checkout release/1.4
</code></pre> 
<ol start="6"><li>创建并进入<code>/paddle/build</code>路径下：</li></ol> 
<pre><code>mkdir -p /paddle/build &amp;&amp; cd /paddle/build
</code></pre> 
<ol start="7"><li>使用以下命令安装相关依赖：</li></ol> 
<pre><code>pip3 install protobuf==3.1.0
apt install patchelf
</code></pre> 
<ol start="8"><li> <p>执行cmake：</p> 
  <ul><li>编译<strong>CPU版本</strong>PaddlePaddle的命令。使用参数<code>-DPY_VERSION</code>指定编译的PaddlePaddle支持的Python版本，笔者这里选择的是Python 3.5。并且使用参数<code>-DWITH_FLUID_ONLY</code>指定不编译V2版本的PaddlePaddle代码。使用参数<code>-DWITH_GPU</code>指定不使用GPU，只编译支持CPU的PaddlePaddle：</li></ul> <pre><code>cmake .. -DPY_VERSION=3.5 -DWITH_FLUID_ONLY=ON -DWITH_GPU=OFF -DWITH_TESTING=OFF -DCMAKE_BUILD_TYPE=Release
</code></pre> 
  <ul><li>编译<strong>GPU版本</strong>PaddlePaddle的命令。使用参数<code>-DPY_VERSION</code>指定编译的PaddlePaddle支持的Python版本，笔者这里选择的是Python 3.5。并且使用参数<code>-DWITH_FLUID_ONLY</code>指定不编译V2版本的PaddlePaddle代码。使用参数<code>-DWITH_GPU</code>指定使用GPU，同时编译支持CPU和GPU版本的PaddlePaddle。这里要注意一下，我们拉取的这个镜像是CUDA 8.0的，不一定跟读者本地的CUDA版本对应，这可能导致编译的安装包在本地不可用：</li></ul> <pre><code>cmake .. -DPY_VERSION=3.5 -DWITH_FLUID_ONLY=ON -DWITH_GPU=ON -DWITH_TESTING=OFF -DCMAKE_BUILD_TYPE=Release
</code></pre> </li><li> <p>执行编译：</p> </li></ol> 
<pre><code>make -j$(nproc)
</code></pre> 
<ol start="10"><li>编译成功后，生成的安装包存放在<code>/paddle/build/python/dist</code>目录下，如果是想在docker中安装PaddlePaddle，可以直接在docker中打开这个目录。如果要在本地安装的话，还有先退出docker，并进入到这个目录：</li></ol> 
<pre><code class="prism language-python"><span class="token comment"># 在docker镜像中安装</span>
cd <span class="token operator">/</span>paddle<span class="token operator">/</span>build<span class="token operator">/</span>python<span class="token operator">/</span>dist
<span class="token comment"># 在Ubuntu本地安装</span>
exit
cd build<span class="token operator">/</span>python<span class="token operator">/</span>dist
</code></pre> 
<ol start="11"><li>安装PaddlePaddle，执行以下命令：</li></ol> 
<pre><code>pip3.5 install （whl包的名字）
</code></pre> 
<h2><a id="_370"></a>测试环境</h2> 
<p>下面介绍在Windows测试PaddlePaddle的安装情况，Ubuntu环境类似。</p> 
<ol><li> <p>开发工具笔者喜欢使用PyCharm，下载地址：https://www.jetbrains.com/pycharm/download/#section=windows ， 笔者使用的是社区版本的PyCharm，因为这个是免费的[坏笑]。<br> <img src="https://images2.imgbox.com/2b/ef/fB2lQGey_o.png" alt="在这里插入图片描述"></p> </li><li> <p>创建一个新项目，并选择系统的Python环境，第一个是创建一个Python的虚拟环境，这里选择第二个外部的Python环境，点击<code>...</code>选择外部Python环境。<br> <img src="https://images2.imgbox.com/8d/4e/wW4oGqO1_o.png" alt="在这里插入图片描述"></p> </li><li> <p>这里选择系统的Python环境，选择的路径是之前安装Python的路径。<br> <img src="https://images2.imgbox.com/91/9b/4wBjOJyV_o.png" alt="在这里插入图片描述"></p> </li><li> <p>创建一个Python程序文件，并命名为<code>test_paddle.py</code>，编写并执行以下测试代码，现在看不懂没有关系，跟着这个系列教程来学，我们会熟悉使用PaddlePaddle的：</p> </li></ol> 
<pre><code class="prism language-python"><span class="token comment"># Include libraries.</span>
<span class="token keyword">import</span> paddle
<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>fluid <span class="token keyword">as</span> fluid
<span class="token keyword">import</span> numpy
<span class="token keyword">import</span> six

<span class="token comment"># Configure the neural network.</span>
<span class="token keyword">def</span> <span class="token function">net</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_predict <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>x<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    cost <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>square_error_cost<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>y_predict<span class="token punctuation">,</span> label<span class="token operator">=</span>y<span class="token punctuation">)</span>
    avg_cost <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
    <span class="token keyword">return</span> y_predict<span class="token punctuation">,</span> avg_cost

                                
<span class="token comment"># Define train function.</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>save_dirname<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
    y <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>data<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'y'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
    y_predict<span class="token punctuation">,</span> avg_cost <span class="token operator">=</span> net<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
    sgd_optimizer <span class="token operator">=</span> fluid<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
    sgd_optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>avg_cost<span class="token punctuation">)</span>
    train_reader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>
        paddle<span class="token punctuation">.</span>reader<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>uci_housing<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> buf_size<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        batch_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>
    place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CPUPlace<span class="token punctuation">(</span><span class="token punctuation">)</span>
    exe <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Executor<span class="token punctuation">(</span>place<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">train_loop</span><span class="token punctuation">(</span>main_program<span class="token punctuation">)</span><span class="token punctuation">:</span>
        feeder <span class="token operator">=</span> fluid<span class="token punctuation">.</span>DataFeeder<span class="token punctuation">(</span>place<span class="token operator">=</span>place<span class="token punctuation">,</span> feed_list<span class="token operator">=</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span>
        exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>default_startup_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        PASS_NUM <span class="token operator">=</span> <span class="token number">1000</span>
        <span class="token keyword">for</span> pass_id <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>PASS_NUM<span class="token punctuation">)</span><span class="token punctuation">:</span>
            total_loss_pass <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword">for</span> data <span class="token keyword">in</span> train_reader<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                avg_loss_value<span class="token punctuation">,</span> <span class="token operator">=</span> exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>
                    main_program<span class="token punctuation">,</span> feed<span class="token operator">=</span>feeder<span class="token punctuation">.</span>feed<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> fetch_list<span class="token operator">=</span><span class="token punctuation">[</span>avg_cost<span class="token punctuation">]</span><span class="token punctuation">)</span>
                total_loss_pass <span class="token operator">+=</span> avg_loss_value
                <span class="token keyword">if</span> avg_loss_value <span class="token operator">&lt;</span> <span class="token number">5.0</span><span class="token punctuation">:</span>
                    <span class="token keyword">if</span> save_dirname <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                        fluid<span class="token punctuation">.</span>io<span class="token punctuation">.</span>save_inference_model<span class="token punctuation">(</span>
                            save_dirname<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>y_predict<span class="token punctuation">]</span><span class="token punctuation">,</span> exe<span class="token punctuation">)</span>
                    <span class="token keyword">return</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Pass %d, total avg cost = %f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>pass_id<span class="token punctuation">,</span> total_loss_pass<span class="token punctuation">)</span><span class="token punctuation">)</span>

    train_loop<span class="token punctuation">(</span>fluid<span class="token punctuation">.</span>default_main_program<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Infer by using provided test data.</span>
<span class="token keyword">def</span> <span class="token function">infer</span><span class="token punctuation">(</span>save_dirname<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    place <span class="token operator">=</span> fluid<span class="token punctuation">.</span>CPUPlace<span class="token punctuation">(</span><span class="token punctuation">)</span>
    exe <span class="token operator">=</span> fluid<span class="token punctuation">.</span>Executor<span class="token punctuation">(</span>place<span class="token punctuation">)</span>
    inference_scope <span class="token operator">=</span> fluid<span class="token punctuation">.</span>core<span class="token punctuation">.</span>Scope<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> fluid<span class="token punctuation">.</span>scope_guard<span class="token punctuation">(</span>inference_scope<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token punctuation">[</span>inference_program<span class="token punctuation">,</span> feed_target_names<span class="token punctuation">,</span> fetch_targets<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>
            fluid<span class="token punctuation">.</span>io<span class="token punctuation">.</span>load_inference_model<span class="token punctuation">(</span>save_dirname<span class="token punctuation">,</span> exe<span class="token punctuation">)</span><span class="token punctuation">)</span>
        test_reader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>uci_housing<span class="token punctuation">.</span>test<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>

        test_data <span class="token operator">=</span> six<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span>test_reader<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        test_feat <span class="token operator">=</span> numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> test_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">"float32"</span><span class="token punctuation">)</span>
        test_label <span class="token operator">=</span> numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> test_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">"float32"</span><span class="token punctuation">)</span>

        results <span class="token operator">=</span> exe<span class="token punctuation">.</span>run<span class="token punctuation">(</span>inference_program<span class="token punctuation">,</span>
                          feed<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>feed_target_names<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span> numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span>test_feat<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                          fetch_list<span class="token operator">=</span>fetch_targets<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"infer results: "</span><span class="token punctuation">,</span> results<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ground truth: "</span><span class="token punctuation">,</span> test_label<span class="token punctuation">)</span>

                                
<span class="token comment"># Run train and infer.</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    save_dirname <span class="token operator">=</span> <span class="token string">"fit_a_line.inference.model"</span>
    train<span class="token punctuation">(</span>save_dirname<span class="token punctuation">)</span>
    infer<span class="token punctuation">(</span>save_dirname<span class="token punctuation">)</span>
</code></pre> 
<p>正常情况下会输出：</p> 
<pre><code>Pass 0, total avg cost = 13527.760742
Pass 1, total avg cost = 12497.969727
Pass 2, total avg cost = 11737.727539
Pass 3, total avg cost = 11017.893555
Pass 4, total avg cost = 9801.554688
Pass 5, total avg cost = 9150.510742
Pass 6, total avg cost = 8611.593750
Pass 7, total avg cost = 7924.654297
......
</code></pre> 
<p>PaddlePaddle的安装已经介绍完成，那我们开始进入深度学习的大门吧。本系列教程将会一步步介绍如何使用PaddlePaddle，并使用PaddlePaddle应用到实际项目中。</p> 
<p>项目代码GitHub地址：https://github.com/yeyupiaoling/LearnPaddle2/tree/master/note1</p> 
<p><strong>注意：</strong> 最新代码以GitHub上的为准</p> 
<br> 
<h6><a id="PaddlePaddle11httpsblogdoiduoyicomarticles1584974387872html_479"></a>下一章：<a href="https://blog.doiduoyi.com/articles/1584974387872.html" rel="nofollow">《PaddlePaddle从入门到炼丹》二——计算1+1</a></h6> 
<br> 
<h2><a id="_483"></a>参考资料</h2> 
<ol><li>http://www.paddlepaddle.org/documentation/docs/zh/1.2/beginners_guide/install/install_Ubuntu.html</li><li>http://www.paddlepaddle.org/documentation/docs/zh/1.2/beginners_guide/install/install_Windows.html</li><li>https://blog.csdn.net/cocoaqin/article/details/78163171</li></ol>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/74d30f6a0e4254885b89691ede264234/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">数据结构学习之——线性表</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8b14bf0578cd3b74ee6890f1a37bfbfc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">How to configure grup in Linux Mint 19</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>