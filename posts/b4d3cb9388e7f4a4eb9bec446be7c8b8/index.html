<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>NNDL 实验七 循环神经网络（3）LSTM的记忆能力实验 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="NNDL 实验七 循环神经网络（3）LSTM的记忆能力实验" />
<meta property="og:description" content="目录 6.3 LSTM的记忆能力实验6.3.1 模型构建6.3.1.1 LSTM层 6.3.2 模型训练6.3.2.1 训练指定长度的数字预测模型6.3.2.2 多组训练6.3.2.3 损失曲线展示【思考题1】LSTM与SRN实验结果对比，谈谈看法。（选做） 6.3.3 模型评价6.3.3.2 模型在不同长度的数据集上的准确率变化图【思考题2】LSTM与SRN在不同长度数据集上的准确度对比，谈谈看法。（选做） 6.3.3.3 LSTM模型门状态和单元状态的变化【思考题3】分析LSTM中单元状态和门数值的变化图，并用自己的话解释该图。 全面总结RNN（必做）总结参考 6.3 LSTM的记忆能力实验 使用LSTM模型重新进行数字求和实验，验证LSTM模型的长程依赖能力。
6.3.1 模型构建 使用第6.1.2.4节中定义Model_RNN4SeqClass模型，并构建 LSTM 算子．
只需要实例化 LSTM ，并传入Model_RNN4SeqClass模型，就可以用 LSTM 进行数字求和实验。
6.3.1.1 LSTM层 自定义LSTM算子 import torch.nn.functional as F import torch import torch.nn as nn # 声明LSTM和相关参数 class LSTM(nn.Module): def __init__(self, input_size, hidden_size, Wi_attr=None, Wf_attr=None, Wo_attr=None, Wc_attr=None, Ui_attr=None, Uf_attr=None, Uo_attr=None, Uc_attr=None, bi_attr=None, bf_attr=None, bo_attr=None, bc_attr=None): super(LSTM, self).__init__() self.input_size = input_size self.hidden_size = hidden_size # 初始化模型参数 if Wi_attr==None: Wi= torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/b4d3cb9388e7f4a4eb9bec446be7c8b8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-01T17:42:44+08:00" />
<meta property="article:modified_time" content="2022-12-01T17:42:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">NNDL 实验七 循环神经网络（3）LSTM的记忆能力实验</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#63_LSTM_1" rel="nofollow">6.3 LSTM的记忆能力实验</a></li><li><ul><li><a href="#631__4" rel="nofollow">6.3.1 模型构建</a></li><li><ul><li><a href="#6311_LSTM_9" rel="nofollow">6.3.1.1 LSTM层</a></li></ul> 
   </li><li><a href="#632__270" rel="nofollow">6.3.2 模型训练</a></li><li><ul><li><a href="#6321__271" rel="nofollow">6.3.2.1 训练指定长度的数字预测模型</a></li><li><a href="#6322__644" rel="nofollow">6.3.2.2 多组训练</a></li><li><a href="#6323__666" rel="nofollow">6.3.2.3 损失曲线展示</a></li><li><ul><li><a href="#1LSTMSRN_715" rel="nofollow">【思考题1】LSTM与SRN实验结果对比，谈谈看法。（选做）</a></li></ul> 
   </li></ul> 
   </li><li><a href="#633__722" rel="nofollow">6.3.3 模型评价</a></li><li><ul><li><a href="#6332__752" rel="nofollow">6.3.3.2 模型在不同长度的数据集上的准确率变化图</a></li><li><ul><li><a href="#2LSTMSRN_772" rel="nofollow">【思考题2】LSTM与SRN在不同长度数据集上的准确度对比，谈谈看法。（选做）</a></li></ul> 
    </li><li><a href="#6333_LSTM_774" rel="nofollow">6.3.3.3 LSTM模型门状态和单元状态的变化</a></li><li><ul><li><a href="#3LSTM_971" rel="nofollow">【思考题3】分析LSTM中单元状态和门数值的变化图，并用自己的话解释该图。</a></li></ul> 
   </li></ul> 
  </li></ul> 
  </li><li><a href="#RNN_975" rel="nofollow">全面总结RNN（必做）</a></li><li><a href="#_978" rel="nofollow">总结</a></li><li><a href="#_981" rel="nofollow">参考</a></li></ul> 
</div> 
<p></p> 
<h2><a id="63_LSTM_1"></a>6.3 LSTM的记忆能力实验</h2> 
<p>使用LSTM模型重新进行数字求和实验，验证LSTM模型的长程依赖能力。<br> <img src="https://images2.imgbox.com/a9/9b/DsOTQPT4_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="631__4"></a>6.3.1 模型构建</h3> 
<p>使用第6.1.2.4节中定义Model_RNN4SeqClass模型，并构建 LSTM 算子．</p> 
<p>只需要实例化 LSTM ，并传入Model_RNN4SeqClass模型，就可以用 LSTM 进行数字求和实验。</p> 
<h4><a id="6311_LSTM_9"></a>6.3.1.1 LSTM层</h4> 
<ul><li>自定义LSTM算子</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn

<span class="token comment"># 声明LSTM和相关参数</span>
<span class="token keyword">class</span> <span class="token class-name">LSTM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> Wi_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 Ui_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bi_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 bo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LSTM<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size

        <span class="token comment"># 初始化模型参数</span>
        <span class="token keyword">if</span> Wi_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wi<span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wi <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wi_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wi<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wf_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wf<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wf<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wo_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wo<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_o <span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wo<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wc_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
            Wc<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Wc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wc<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Ui_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
            Ui <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Ui <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Ui_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Ui<span class="token punctuation">)</span>
        <span class="token keyword">if</span> Uf_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uf <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uf<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Uo_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uo <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_o <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uo<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Uc_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uc <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uc<span class="token punctuation">)</span>

        <span class="token keyword">if</span> bi_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bi <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bi <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bi_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bi<span class="token punctuation">)</span>
        <span class="token keyword">if</span> bf_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bf <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bf<span class="token punctuation">)</span>

        <span class="token keyword">if</span> bo_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bo <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_o <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bo<span class="token punctuation">)</span>
        <span class="token keyword">if</span> bc_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bc <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bc<span class="token punctuation">)</span>

    <span class="token comment"># 初始化状态向量和隐状态向量</span>
    <span class="token keyword">def</span> <span class="token function">init_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        hidden_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        cell_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">return</span> hidden_state<span class="token punctuation">,</span> cell_state

    <span class="token comment"># 定义前向计算</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> states<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># inputs: 输入数据，其shape为batch_size x seq_len x input_size</span>
        batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size <span class="token operator">=</span> inputs<span class="token punctuation">.</span>shape

        <span class="token comment"># 初始化起始的单元状态和隐状态向量，其shape为batch_size x hidden_size</span>
        <span class="token keyword">if</span> states <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            states <span class="token operator">=</span> self<span class="token punctuation">.</span>init_state<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
        hidden_state<span class="token punctuation">,</span> cell_state <span class="token operator">=</span> states

        <span class="token comment"># 执行LSTM计算，包括：输入门、遗忘门和输出门、候选内部状态、内部状态和隐状态向量</span>
        <span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 获取当前时刻的输入数据step_input: 其shape为batch_size x input_size</span>
            step_input <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> step<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            <span class="token comment"># 计算输入门, 遗忘门和输出门, 其shape为：batch_size x hidden_size</span>
            I_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>step_input<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_i<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_i<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_i<span class="token punctuation">)</span>
            F_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>step_input<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_f<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_f<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_f<span class="token punctuation">)</span>
            O_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>step_input<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_o<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_o<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_o<span class="token punctuation">)</span>
            <span class="token comment"># 计算候选状态向量, 其shape为：batch_size x hidden_size</span>
            C_tilde <span class="token operator">=</span> F<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>step_input<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_c<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_c<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_c<span class="token punctuation">)</span>
            <span class="token comment"># 计算单元状态向量, 其shape为：batch_size x hidden_size</span>
            cell_state <span class="token operator">=</span> F_gate <span class="token operator">*</span> cell_state <span class="token operator">+</span> I_gate <span class="token operator">*</span> C_tilde
            <span class="token comment"># 计算隐状态向量，其shape为：batch_size x hidden_size</span>
            hidden_state <span class="token operator">=</span> O_gate <span class="token operator">*</span> F<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>cell_state<span class="token punctuation">)</span>

        <span class="token keyword">return</span> hidden_state
</code></pre> 
<pre><code class="prism language-python">Wi_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Wf_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Wo_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Wc_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Ui_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Uf_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Uo_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Uc_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
bi_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
bf_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
bo_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
bc_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> Wi_attr<span class="token operator">=</span>Wi_attr<span class="token punctuation">,</span> Wf_attr<span class="token operator">=</span>Wf_attr<span class="token punctuation">,</span> Wo_attr<span class="token operator">=</span>Wo_attr<span class="token punctuation">,</span> Wc_attr<span class="token operator">=</span>Wc_attr<span class="token punctuation">,</span>
                 Ui_attr<span class="token operator">=</span>Ui_attr<span class="token punctuation">,</span> Uf_attr<span class="token operator">=</span>Uf_attr<span class="token punctuation">,</span> Uo_attr<span class="token operator">=</span>Uo_attr<span class="token punctuation">,</span> Uc_attr<span class="token operator">=</span>Uc_attr<span class="token punctuation">,</span>
                 bi_attr<span class="token operator">=</span>bi_attr<span class="token punctuation">,</span> bf_attr<span class="token operator">=</span>bf_attr<span class="token punctuation">,</span> bo_attr<span class="token operator">=</span>bo_attr<span class="token punctuation">,</span> bc_attr<span class="token operator">=</span>bc_attr<span class="token punctuation">)</span>

inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
hidden_state <span class="token operator">=</span> lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>hidden_state<span class="token punctuation">)</span>
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/3e/d3/T9AtKLmZ_o.png" alt="在这里插入图片描述"></p> 
<ul><li>nn.LSTM</li></ul> 
<pre><code class="prism language-python"><span class="token comment"># 这里创建一个随机数组作为测试数据，数据shape为batch_size x seq_len x input_size</span>
batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">32</span>
inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 设置模型的hidden_size</span>
hidden_size <span class="token operator">=</span> <span class="token number">32</span>
torch_lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
self_lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>

self_hidden_state <span class="token operator">=</span> self_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
torch_outputs<span class="token punctuation">,</span> <span class="token punctuation">(</span>torch_hidden_state<span class="token punctuation">,</span> torch_cell_state<span class="token punctuation">)</span> <span class="token operator">=</span> torch_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"self_lstm hidden_state: "</span><span class="token punctuation">,</span> self_hidden_state<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"torch_lstm outpus:"</span><span class="token punctuation">,</span> torch_outputs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"torch_lstm hidden_state:"</span><span class="token punctuation">,</span> torch_hidden_state<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"torch_lstm cell_state:"</span><span class="token punctuation">,</span> torch_cell_state<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/12/17/XRUM3flT_o.png" alt="在这里插入图片描述"><br> 可以看到，自己实现的LSTM由于没有考虑多层因素，因此没有层次这个维度，因此其输出shape为[8, 32]。同时由于在以上代码使用Paddle内置API实例化LSTM时，默认定义的是1层的单向SRN，因此其shape为[1, 8, 32]，同时隐状态向量为[8,20, 32].</p> 
<ul><li>将自定义LSTM与pytorch内置的LSTM进行对比</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
torch<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 这里创建一个随机数组作为测试数据，数据shape为batch_size x seq_len x input_size</span>
batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span>
inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 设置模型的hidden_size</span>
torch_lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 获取torch_lstm中的参数，并设置相应的paramAttr,用于初始化lstm</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch_lstm<span class="token punctuation">.</span>weight_ih_l0<span class="token punctuation">.</span>T<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
chunked_W <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>torch_lstm<span class="token punctuation">.</span>weight_ih_l0<span class="token punctuation">.</span>T<span class="token punctuation">,</span> split_size_or_sections<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
chunked_U <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>torch_lstm<span class="token punctuation">.</span>weight_hh_l0<span class="token punctuation">.</span>T<span class="token punctuation">,</span> split_size_or_sections<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
chunked_b <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>torch_lstm<span class="token punctuation">.</span>bias_hh_l0<span class="token punctuation">.</span>T<span class="token punctuation">,</span> split_size_or_sections<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

Wi_attr <span class="token operator">=</span> chunked_W<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
Wf_attr <span class="token operator">=</span> chunked_W<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
Wc_attr <span class="token operator">=</span> chunked_W<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
Wo_attr <span class="token operator">=</span> chunked_W<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
Ui_attr <span class="token operator">=</span> chunked_U<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
Uf_attr <span class="token operator">=</span> chunked_U<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
Uc_attr <span class="token operator">=</span> chunked_U<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
Uo_attr <span class="token operator">=</span> chunked_U<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
bi_attr <span class="token operator">=</span> chunked_b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
bf_attr <span class="token operator">=</span> chunked_b<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
bc_attr <span class="token operator">=</span> chunked_b<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
bo_attr <span class="token operator">=</span> chunked_b<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
self_lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> Wi_attr<span class="token operator">=</span>Wi_attr<span class="token punctuation">,</span> Wf_attr<span class="token operator">=</span>Wf_attr<span class="token punctuation">,</span> Wo_attr<span class="token operator">=</span>Wo_attr<span class="token punctuation">,</span> Wc_attr<span class="token operator">=</span>Wc_attr<span class="token punctuation">,</span>
                 Ui_attr<span class="token operator">=</span>Ui_attr<span class="token punctuation">,</span> Uf_attr<span class="token operator">=</span>Uf_attr<span class="token punctuation">,</span> Uo_attr<span class="token operator">=</span>Uo_attr<span class="token punctuation">,</span> Uc_attr<span class="token operator">=</span>Uc_attr<span class="token punctuation">,</span>
                 bi_attr<span class="token operator">=</span>bi_attr<span class="token punctuation">,</span> bf_attr<span class="token operator">=</span>bf_attr<span class="token punctuation">,</span> bo_attr<span class="token operator">=</span>bo_attr<span class="token punctuation">,</span> bc_attr<span class="token operator">=</span>bc_attr<span class="token punctuation">)</span>

<span class="token comment"># 进行前向计算，获取隐状态向量，并打印展示</span>
self_hidden_state <span class="token operator">=</span> self_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
torch_outputs<span class="token punctuation">,</span> <span class="token punctuation">(</span>torch_hidden_state<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token operator">=</span> torch_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"torch SRN:\n"</span><span class="token punctuation">,</span> torch_hidden_state<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"self SRN:\n"</span><span class="token punctuation">,</span> self_hidden_state<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/78/78/PoJQ8Cq1_o.png" alt="在这里插入图片描述"><br> 可以看到，两者的输出基本是一致的。另外，还可以进行对比两者在运算速度方面的差异。代码实现如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> time

<span class="token comment"># 这里创建一个随机数组作为测试数据，数据shape为batch_size x seq_len x input_size</span>
batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">32</span>
inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 设置模型的hidden_size</span>
hidden_size <span class="token operator">=</span> <span class="token number">32</span>
self_lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
torch_lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>

<span class="token comment"># 计算自己实现的SRN运算速度</span>
model_time <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    strat_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    hidden_state <span class="token operator">=</span> self_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment"># 预热10次运算，不计入最终速度统计</span>
    <span class="token keyword">if</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">:</span>
        <span class="token keyword">continue</span>
    end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model_time <span class="token operator">+=</span> <span class="token punctuation">(</span>end_time <span class="token operator">-</span> strat_time<span class="token punctuation">)</span>
avg_model_time <span class="token operator">=</span> model_time <span class="token operator">/</span> <span class="token number">90</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'self_lstm speed:'</span><span class="token punctuation">,</span> avg_model_time<span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">)</span>

<span class="token comment"># 计算torch内置的SRN运算速度</span>
model_time <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    strat_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    outputs<span class="token punctuation">,</span> <span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> cell_state<span class="token punctuation">)</span> <span class="token operator">=</span> torch_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment"># 预热10次运算，不计入最终速度统计</span>
    <span class="token keyword">if</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">:</span>
        <span class="token keyword">continue</span>
    end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model_time <span class="token operator">+=</span> <span class="token punctuation">(</span>end_time <span class="token operator">-</span> strat_time<span class="token punctuation">)</span>
avg_model_time <span class="token operator">=</span> model_time <span class="token operator">/</span> <span class="token number">90</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'torch_lstm speed:'</span><span class="token punctuation">,</span> avg_model_time<span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/68/58/gW3f4wlb_o.png" alt="在这里插入图片描述"><br> 可以看到，由于PyTorch底层采用了C++实现并进行优化，Paddle框架内置的LSTM运行效率远远高于自己实现的LSTM。</p> 
<h3><a id="632__270"></a>6.3.2 模型训练</h3> 
<h4><a id="6321__271"></a>6.3.2.1 训练指定长度的数字预测模型</h4> 
<p>DigitSumDataset()</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span>DataLoader
<span class="token keyword">import</span> torch
<span class="token keyword">class</span> <span class="token class-name">DigitSumDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        example <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        seq <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
        label <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
        <span class="token keyword">return</span> seq<span class="token punctuation">,</span> label

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
</code></pre> 
<p>load_data()</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os
<span class="token comment"># 加载数据</span>
<span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span>data_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 加载训练集</span>
    train_examples <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    train_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">"train.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>train_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 解析一行数据，将其处理为数字序列seq和标签label</span>
            items <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>
            seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            train_examples<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>seq<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载验证集</span>
    dev_examples <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    dev_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">"dev.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dev_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 解析一行数据，将其处理为数字序列seq和标签label</span>
            items <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>
            seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            dev_examples<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>seq<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载测试集</span>
    test_examples <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    test_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">"test.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>test_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 解析一行数据，将其处理为数字序列seq和标签label</span>
            items <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>
            seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            test_examples<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>seq<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> train_examples<span class="token punctuation">,</span> dev_examples<span class="token punctuation">,</span> test_examples
</code></pre> 
<p>Embedding()</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Embedding</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_embeddings<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Embedding<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>num_embeddings<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>gain<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 根据索引获取对应词向量</span>
        embs <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">[</span>inputs<span class="token punctuation">]</span>
        <span class="token keyword">return</span> embs


emb_layer <span class="token operator">=</span> Embedding<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
emb_layer<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
</code></pre> 
<p>Model_RNN4SeqClass()</p> 
<pre><code class="prism language-python">
<span class="token comment"># 基于RNN实现数字预测的模型</span>
<span class="token keyword">class</span> <span class="token class-name">Model_RNN4SeqClass</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> num_digits<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Model_RNN4SeqClass<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 传入实例化的RNN层，例如SRN</span>
        self<span class="token punctuation">.</span>rnn_model <span class="token operator">=</span> model
        <span class="token comment"># 词典大小</span>
        self<span class="token punctuation">.</span>num_digits <span class="token operator">=</span> num_digits
        <span class="token comment"># 嵌入向量的维度</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        <span class="token comment"># 定义Embedding层</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>num_digits<span class="token punctuation">,</span> input_size<span class="token punctuation">)</span>
        <span class="token comment"># 定义线性层</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将数字序列映射为相应向量</span>
        inputs_emb <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        <span class="token comment"># 调用RNN模型</span>
        hidden_state <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn_model<span class="token punctuation">(</span>inputs_emb<span class="token punctuation">)</span>
        <span class="token comment"># 使用最后一个时刻的状态进行数字预测</span>
        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>hidden_state<span class="token punctuation">)</span>
        <span class="token keyword">return</span> logits
</code></pre> 
<p>RunnerV3()</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">RunnerV3</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> metric<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model
        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> optimizer
        self<span class="token punctuation">.</span>loss_fn <span class="token operator">=</span> loss_fn
        self<span class="token punctuation">.</span>metric <span class="token operator">=</span> metric  <span class="token comment"># 只用于计算评价指标</span>

        <span class="token comment"># 记录训练过程中的评价指标变化情况</span>
        self<span class="token punctuation">.</span>dev_scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># 记录训练过程中的损失函数变化情况</span>
        self<span class="token punctuation">.</span>train_epoch_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 一个epoch记录一次loss</span>
        self<span class="token punctuation">.</span>train_step_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 一个step记录一次loss</span>
        self<span class="token punctuation">.</span>dev_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># 记录全局最优指标</span>
        self<span class="token punctuation">.</span>best_score <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> dev_loader<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将模型切换为训练模式</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 传入训练轮数，如果没有传入值则默认为0</span>
        num_epochs <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"num_epochs"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token comment"># 传入log打印频率，如果没有传入值则默认为100</span>
        log_steps <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"log_steps"</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
        <span class="token comment"># 评价频率</span>
        eval_steps <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"eval_steps"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token comment"># 传入模型保存路径，如果没有传入值则默认为"best_model.pdparams"</span>
        save_path <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"save_path"</span><span class="token punctuation">,</span> <span class="token string">"best_model.pdparams"</span><span class="token punctuation">)</span>

        custom_print_log <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"custom_print_log"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>

        <span class="token comment"># 训练总的步数</span>
        num_training_steps <span class="token operator">=</span> num_epochs <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>

        <span class="token keyword">if</span> eval_steps<span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>metric <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> RuntimeError<span class="token punctuation">(</span><span class="token string">'Error: Metric can not be None!'</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> dev_loader <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> RuntimeError<span class="token punctuation">(</span><span class="token string">'Error: dev_loader can not be None!'</span><span class="token punctuation">)</span>

        <span class="token comment"># 运行的step数目</span>
        global_step <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token comment"># 进行num_epochs轮训练</span>
        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 用于统计训练集的损失</span>
            total_loss <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword">for</span> step<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
                X<span class="token punctuation">,</span> y <span class="token operator">=</span> data
                <span class="token comment"># 获取模型预测</span>
                logits <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> self<span class="token punctuation">.</span>loss_fn<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> y<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 默认求mean</span>
                total_loss <span class="token operator">+=</span> loss

                <span class="token comment"># 训练过程中，每个step的loss进行保存</span>
                self<span class="token punctuation">.</span>train_step_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>global_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

                <span class="token keyword">if</span> log_steps <span class="token keyword">and</span> global_step <span class="token operator">%</span> log_steps <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span>
                        <span class="token string-interpolation"><span class="token string">f"[Train] epoch: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>num_epochs<span class="token punctuation">}</span></span><span class="token string">, step: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>global_step<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>num_training_steps<span class="token punctuation">}</span></span><span class="token string">, loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

                <span class="token comment"># 梯度反向传播，计算每个参数的梯度值</span>
                loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

                <span class="token keyword">if</span> custom_print_log<span class="token punctuation">:</span>
                    custom_print_log<span class="token punctuation">(</span>self<span class="token punctuation">)</span>

                <span class="token comment"># 小批量梯度下降进行参数更新</span>
                self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token comment"># 梯度归零</span>
                self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

                <span class="token comment"># 判断是否需要评价</span>
                <span class="token keyword">if</span> eval_steps <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">and</span> global_step <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">and</span> \
                        <span class="token punctuation">(</span>global_step <span class="token operator">%</span> eval_steps <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> global_step <span class="token operator">==</span> <span class="token punctuation">(</span>num_training_steps <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

                    dev_score<span class="token punctuation">,</span> dev_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>dev_loader<span class="token punctuation">,</span> global_step<span class="token operator">=</span>global_step<span class="token punctuation">)</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"[Evaluate]  dev score: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dev_score<span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string">, dev loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dev_loss<span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

                    <span class="token comment"># 将模型切换为训练模式</span>
                    self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

                    <span class="token comment"># 如果当前指标为最优指标，保存该模型</span>
                    <span class="token keyword">if</span> dev_score <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>best_score<span class="token punctuation">:</span>
                        self<span class="token punctuation">.</span>save_model<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span>
                        <span class="token keyword">print</span><span class="token punctuation">(</span>
                            <span class="token string-interpolation"><span class="token string">f"[Evaluate] best accuracy performence has been updated: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>best_score<span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string"> --&gt; </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dev_score<span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
                        self<span class="token punctuation">.</span>best_score <span class="token operator">=</span> dev_score

                global_step <span class="token operator">+=</span> <span class="token number">1</span>

            <span class="token comment"># 当前epoch 训练loss累计值</span>
            trn_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># epoch粒度的训练loss保存</span>
            self<span class="token punctuation">.</span>train_epoch_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>trn_loss<span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"[Train] Training done!"</span><span class="token punctuation">)</span>

    <span class="token comment"># 模型评估阶段，使用'torch.no_grad()'控制不计算和存储梯度</span>
    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dev_loader<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>metric <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>

        <span class="token comment"># 将模型设置为评估模式</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

        global_step <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"global_step"</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 用于统计训练集的损失</span>
        total_loss <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token comment"># 重置评价</span>
        self<span class="token punctuation">.</span>metric<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 遍历验证集每个批次</span>
        <span class="token keyword">for</span> batch_id<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dev_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            X<span class="token punctuation">,</span> y <span class="token operator">=</span> data

            <span class="token comment"># 计算模型输出</span>
            logits <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

            <span class="token comment"># 计算损失函数</span>
            loss <span class="token operator">=</span> self<span class="token punctuation">.</span>loss_fn<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> y<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 累积损失</span>
            total_loss <span class="token operator">+=</span> loss

            <span class="token comment"># 累积评价</span>
            self<span class="token punctuation">.</span>metric<span class="token punctuation">.</span>update<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

        dev_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dev_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>
        dev_score <span class="token operator">=</span> self<span class="token punctuation">.</span>metric<span class="token punctuation">.</span>accumulate<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 记录验证集loss</span>
        <span class="token keyword">if</span> global_step <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>dev_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>global_step<span class="token punctuation">,</span> dev_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>dev_scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_score<span class="token punctuation">)</span>

        <span class="token keyword">return</span> dev_score<span class="token punctuation">,</span> dev_loss

    <span class="token comment"># 模型评估阶段，使用'torch.no_grad()'控制不计算和存储梯度</span>
    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将模型设置为评估模式</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 运行模型前向计算，得到预测值</span>
        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> logits

    <span class="token keyword">def</span> <span class="token function">save_model</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> save_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">load_model</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">)</span>
</code></pre> 
<p>Accuracy()</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Accuracy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> is_logist<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 用于统计正确的样本个数</span>
        self<span class="token punctuation">.</span>num_correct <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment"># 用于统计样本的总数</span>
        self<span class="token punctuation">.</span>num_count <span class="token operator">=</span> <span class="token number">0</span>

        self<span class="token punctuation">.</span>is_logist <span class="token operator">=</span> is_logist

    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 判断是二分类任务还是多分类任务，shape[1]=1时为二分类任务，shape[1]&gt;1时为多分类任务</span>
        <span class="token keyword">if</span> outputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>  <span class="token comment"># 二分类</span>
            outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>is_logist<span class="token punctuation">:</span>
                <span class="token comment"># logist判断是否大于0</span>
                preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">(</span>outputs <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment"># 如果不是logist，判断每个概率值是否大于0.5，当大于0.5时，类别为1，否则类别为0</span>
                preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">(</span>outputs <span class="token operator">&gt;=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># 多分类时，使用'torch.argmax'计算最大元素索引作为类别</span>
            preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 获取本批数据中预测正确的样本个数</span>
        labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        batch_correct <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>preds <span class="token operator">==</span> labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        batch_count <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>

        <span class="token comment"># 更新num_correct 和 num_count</span>
        self<span class="token punctuation">.</span>num_correct <span class="token operator">+=</span> batch_correct
        self<span class="token punctuation">.</span>num_count <span class="token operator">+=</span> batch_count

    <span class="token keyword">def</span> <span class="token function">accumulate</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 使用累计的数据，计算总的指标</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>num_count <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token number">0</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>num_correct <span class="token operator">/</span> self<span class="token punctuation">.</span>num_count

    <span class="token keyword">def</span> <span class="token function">reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 重置正确的数目和总数</span>
        self<span class="token punctuation">.</span>num_correct <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>num_count <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">def</span> <span class="token function">name</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">"Accuracy"</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> random
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># 训练轮次</span>
num_epochs <span class="token operator">=</span> <span class="token number">500</span>
<span class="token comment"># 学习率</span>
lr <span class="token operator">=</span> <span class="token number">0.001</span>
<span class="token comment"># 输入数字的类别数</span>
num_digits <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment"># 将数字映射为向量的维度</span>
input_size <span class="token operator">=</span> <span class="token number">32</span>
<span class="token comment"># 隐状态向量的维度</span>
hidden_size <span class="token operator">=</span> <span class="token number">32</span>
<span class="token comment"># 预测数字的类别数</span>
num_classes <span class="token operator">=</span> <span class="token number">19</span>
<span class="token comment"># 批大小 </span>
batch_size <span class="token operator">=</span> <span class="token number">8</span>
<span class="token comment"># 模型保存目录</span>
save_dir <span class="token operator">=</span> <span class="token string">"./checkpoints"</span>

<span class="token comment"># 可以设置不同的length进行不同长度数据的预测实验</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>length<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\n====&gt; Training LSTM with data of length </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">."</span></span><span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载长度为length的数据</span>
    data_path <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"./datasets/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">"</span></span>
    train_examples<span class="token punctuation">,</span> dev_examples<span class="token punctuation">,</span> test_examples <span class="token operator">=</span> load_data<span class="token punctuation">(</span>data_path<span class="token punctuation">)</span>
    train_set<span class="token punctuation">,</span> dev_set<span class="token punctuation">,</span> test_set <span class="token operator">=</span> DigitSumDataset<span class="token punctuation">(</span>train_examples<span class="token punctuation">)</span><span class="token punctuation">,</span> DigitSumDataset<span class="token punctuation">(</span>dev_examples<span class="token punctuation">)</span><span class="token punctuation">,</span> DigitSumDataset<span class="token punctuation">(</span>test_examples<span class="token punctuation">)</span>
    train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
    dev_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dev_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
    test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
    <span class="token comment"># 实例化模型</span>
    base_model <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
    model <span class="token operator">=</span> Model_RNN4SeqClass<span class="token punctuation">(</span>base_model<span class="token punctuation">,</span> num_digits<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span> 
    <span class="token comment"># 指定优化器</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> params<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 定义评价指标</span>
    metric <span class="token operator">=</span> Accuracy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 定义损失函数</span>
    loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 基于以上组件，实例化Runner</span>
    runner <span class="token operator">=</span> RunnerV3<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> metric<span class="token punctuation">)</span>

    <span class="token comment"># 进行模型训练</span>
    model_save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"best_lstm_model_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">.pdparams"</span></span><span class="token punctuation">)</span>
    runner<span class="token punctuation">.</span>train<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> dev_loader<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span>num_epochs<span class="token punctuation">,</span> eval_steps<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> log_steps<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> save_path<span class="token operator">=</span>model_save_path<span class="token punctuation">)</span>

    <span class="token keyword">return</span> runner
</code></pre> 
<h4><a id="6322__644"></a>6.3.2.2 多组训练</h4> 
<pre><code class="prism language-python">lstm_runners <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>

lengths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> length <span class="token keyword">in</span> lengths<span class="token punctuation">:</span>
    runner <span class="token operator">=</span> train<span class="token punctuation">(</span>length<span class="token punctuation">)</span>
    lstm_runners<span class="token punctuation">[</span>length<span class="token punctuation">]</span> <span class="token operator">=</span> runner
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/a0/07/69ZjW8jE_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/47/4a/pD56I0F3_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/64/28/3WXOTAH4_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/c5/01/jnu60YCD_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/69/fb/trFrT6V4_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="6323__666"></a>6.3.2.3 损失曲线展示</h4> 
<p>plot_training_loss():</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">def</span> <span class="token function">plot_training_loss</span><span class="token punctuation">(</span>runner<span class="token punctuation">,</span> fig_name<span class="token punctuation">,</span> sample_step<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
    train_items <span class="token operator">=</span> runner<span class="token punctuation">.</span>train_step_losses<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span>sample_step<span class="token punctuation">]</span>
    train_steps <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> train_items<span class="token punctuation">]</span>
    train_losses <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> train_items<span class="token punctuation">]</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_steps<span class="token punctuation">,</span> train_losses<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'#e4007f'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Train loss"</span><span class="token punctuation">)</span>

    dev_steps <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> runner<span class="token punctuation">.</span>dev_losses<span class="token punctuation">]</span>
    dev_losses <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> runner<span class="token punctuation">.</span>dev_losses<span class="token punctuation">]</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>dev_steps<span class="token punctuation">,</span> dev_losses<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'#f19ec2'</span><span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Dev loss"</span><span class="token punctuation">)</span>

    <span class="token comment"># 绘制坐标轴和图例</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"loss"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'large'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"step"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'large'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'x-large'</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>fig_name<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 画出训练过程中的损失图</span>
<span class="token keyword">for</span> length <span class="token keyword">in</span> lengths<span class="token punctuation">:</span>
    runner <span class="token operator">=</span> lstm_runners<span class="token punctuation">[</span>length<span class="token punctuation">]</span>
    fig_name <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"./images/6.11_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">.pdf"</span></span>
    plot_training_loss<span class="token punctuation">(</span>runner<span class="token punctuation">,</span> fig_name<span class="token punctuation">,</span> sample_step<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果：<br> 从上至下依次为10, 15, 20, 25, 30, 35。<br> <img src="https://images2.imgbox.com/19/81/E2aMLHBy_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b9/2c/1qylvjn1_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/93/70/WeemLxGX_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/3b/f6/lB1z7D0M_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/98/4b/pzK1L3CA_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/cf/4e/nd9c8Vqw_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="1LSTMSRN_715"></a>【思考题1】LSTM与SRN实验结果对比，谈谈看法。（选做）</h5> 
<p>长短期记忆神经网络（LSTM）是一种特殊的循环神经网络(RNN)。原始的RNN在训练中，随着训练时间的加长以及网络层数的增多，很容易出现梯度爆炸或者梯度消失的问题，导致无法处理较长序列数据，从而无法获取长距离数据的信息。</p> 
<p>LSTM模型在不同长度数据集上进行训练后的损失变化，同SRN模型一样，随着序列长度的增加，训练集上的损失逐渐不稳定，验证集上的损失整体趋向于变大，这说明当序列长度增加时，保持长期依赖的能力同样在逐渐变弱。LSTM模型在序列长度增加时，收敛情况比SRN模型更好，确率也要优于SRN。</p> 
<h3><a id="633__722"></a>6.3.3 模型评价</h3> 
<pre><code class="prism language-python">lstm_dev_scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
lstm_test_scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> length <span class="token keyword">in</span> lengths<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Evaluate LSTM with data length </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">."</span></span><span class="token punctuation">)</span>
    runner <span class="token operator">=</span> lstm_runners<span class="token punctuation">[</span>length<span class="token punctuation">]</span>
    <span class="token comment"># 加载训练过程中效果最好的模型</span>
    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"best_lstm_model_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">.pdparams"</span></span><span class="token punctuation">)</span>
    runner<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

    <span class="token comment"># 加载长度为length的数据</span>
    data_path <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"./datasets/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">"</span></span>
    train_examples<span class="token punctuation">,</span> dev_examples<span class="token punctuation">,</span> test_examples <span class="token operator">=</span> load_data<span class="token punctuation">(</span>data_path<span class="token punctuation">)</span>
    test_set <span class="token operator">=</span> DigitSumDataset<span class="token punctuation">(</span>test_examples<span class="token punctuation">)</span>
    test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>

    <span class="token comment"># 使用测试集评价模型，获取测试集上的预测准确率</span>
    score<span class="token punctuation">,</span> _ <span class="token operator">=</span> runner<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>
    lstm_test_scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span>score<span class="token punctuation">)</span>
    lstm_dev_scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>runner<span class="token punctuation">.</span>dev_scores<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> length<span class="token punctuation">,</span> dev_score<span class="token punctuation">,</span> test_score <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>lengths<span class="token punctuation">,</span> lstm_dev_scores<span class="token punctuation">,</span> lstm_test_scores<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"[LSTM] length:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">, dev_score: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dev_score<span class="token punctuation">}</span></span><span class="token string">, test_score: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>test_score<span class="token punctuation">:</span><span class="token format-spec"> .5f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/27/f7/wp0CIEf0_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="6332__752"></a>6.3.3.2 模型在不同长度的数据集上的准确率变化图</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>lengths<span class="token punctuation">,</span> lstm_dev_scores<span class="token punctuation">,</span> <span class="token string">'-o'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'#e8609b'</span><span class="token punctuation">,</span>  label<span class="token operator">=</span><span class="token string">"LSTM Dev Accuracy"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>lengths<span class="token punctuation">,</span> lstm_test_scores<span class="token punctuation">,</span><span class="token string">'-o'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'#000000'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"LSTM Test Accuracy"</span><span class="token punctuation">)</span>

<span class="token comment">#绘制坐标轴和图例</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'large'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"sequence length"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'large'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower left'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'x-large'</span><span class="token punctuation">)</span>

fig_name <span class="token operator">=</span> <span class="token string">"./images/6.12.pdf"</span>
plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>fig_name<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/69/55/8smDeLkq_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="2LSTMSRN_772"></a>【思考题2】LSTM与SRN在不同长度数据集上的准确度对比，谈谈看法。（选做）</h5> 
<p>随着数据集长度的增加，LSTM模型和SRN模型的准确率降低，但是LSTM模型的准确率显著高于SRN模型，说明LSTM模型保持长期依赖的能力要优于SRN模型。</p> 
<h4><a id="6333_LSTM_774"></a>6.3.3.3 LSTM模型门状态和单元状态的变化</h4> 
<pre><code class="prism language-python"><span class="token comment"># 声明LSTM和相关参数</span>
<span class="token keyword">class</span> <span class="token class-name">LSTM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> Wi_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 Ui_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bi_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 bo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LSTM<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size

        <span class="token comment"># 初始化模型参数</span>
        <span class="token keyword">if</span> Wi_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wi<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wi <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wi_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wi<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wf_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wf<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wf<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wo_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wo<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_o <span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wo<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wc_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
            Wc<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Wc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wc<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Ui_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
            Ui <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Ui <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Ui_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Ui<span class="token punctuation">)</span>
        <span class="token keyword">if</span> Uf_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uf <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uf<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Uo_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uo <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_o <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uo<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Uc_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uc <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uc<span class="token punctuation">)</span>

        <span class="token keyword">if</span> bi_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bi <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bi <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bi_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bi<span class="token punctuation">)</span>
        <span class="token keyword">if</span> bf_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bf <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bf<span class="token punctuation">)</span>
        <span class="token keyword">if</span> bo_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bo <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_o <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bo<span class="token punctuation">)</span>
        <span class="token keyword">if</span> bc_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bc <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bc<span class="token punctuation">)</span>

    <span class="token comment"># 初始化状态向量和隐状态向量</span>
    <span class="token keyword">def</span> <span class="token function">init_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        hidden_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        cell_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">return</span> hidden_state<span class="token punctuation">,</span> cell_state

    <span class="token comment"># 定义前向计算</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> states<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># inputs: 输入数据，其shape为batch_size x seq_len x input_size</span>
        batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size <span class="token operator">=</span> inputs<span class="token punctuation">.</span>shape

        <span class="token comment"># 初始化起始的单元状态和隐状态向量，其shape为batch_size x hidden_size</span>
        <span class="token keyword">if</span> states <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            states <span class="token operator">=</span> self<span class="token punctuation">.</span>init_state<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
        hidden_state<span class="token punctuation">,</span> cell_state <span class="token operator">=</span> states

    
        <span class="token comment"># 定义相应的门状态和单元状态向量列表</span>
        self<span class="token punctuation">.</span>Is <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>Fs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>Os <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>Cs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment"># 初始化状态向量和隐状态向量</span>
        cell_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        hidden_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

        <span class="token comment"># 执行LSTM计算，包括：隐藏门、输入门、遗忘门、候选状态向量、状态向量和隐状态向量</span>
        <span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            input_step <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> step<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            I_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_step<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_i<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_i<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_i<span class="token punctuation">)</span>
            F_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_step<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_f<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_f<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_f<span class="token punctuation">)</span>
            O_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_step<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_o<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_o<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_o<span class="token punctuation">)</span>
            C_tilde <span class="token operator">=</span> F<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_step<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_c<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_c<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_c<span class="token punctuation">)</span>
            cell_state <span class="token operator">=</span> F_gate <span class="token operator">*</span> cell_state <span class="token operator">+</span> I_gate <span class="token operator">*</span> C_tilde
            hidden_state <span class="token operator">=</span> O_gate <span class="token operator">*</span> F<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>cell_state<span class="token punctuation">)</span>
            <span class="token comment"># 存储门状态向量和单元状态向量</span>
            self<span class="token punctuation">.</span>Is<span class="token punctuation">.</span>append<span class="token punctuation">(</span>I_gate<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>Fs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>F_gate<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>Os<span class="token punctuation">.</span>append<span class="token punctuation">(</span>O_gate<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>Cs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cell_state<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> hidden_state
</code></pre> 
<p>接下来，需要使用新的LSTM模型，重新实例化一个runner，本节使用序列长度为10的模型进行此项实验，因此需要加载序列长度为10的模型。</p> 
<pre><code class="prism language-python"><span class="token comment"># 实例化模型</span>
base_model <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
model <span class="token operator">=</span> Model_RNN4SeqClass<span class="token punctuation">(</span>base_model<span class="token punctuation">,</span> num_digits<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span> 
<span class="token comment"># 指定优化器</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> params<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 定义评价指标</span>
metric <span class="token operator">=</span> Accuracy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 定义损失函数</span>
loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 基于以上组件，重新实例化Runner</span>
runner <span class="token operator">=</span> RunnerV3<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> metric<span class="token punctuation">)</span>

length <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment"># 加载训练过程中效果最好的模型</span>
model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"best_lstm_model_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">.pdparams"</span></span><span class="token punctuation">)</span>
runner<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
</code></pre> 
<p>接下来，给定一条数字序列，并使用数字预测模型进行数字预测，这样便会将相应的门状态和单元状态向量保存至模型中. 然后分别从模型中取出这些向量，并将这些向量进行绘制展示。代码实现如下：</p> 
<pre><code class="prism language-python">
<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">def</span> <span class="token function">plot_tensor</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> tensor<span class="token punctuation">,</span>  save_path<span class="token punctuation">,</span> vmin<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> vmax<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    tensor <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T

    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># vmin, vmax定义了色彩图的上下界</span>
    ax <span class="token operator">=</span> sns<span class="token punctuation">.</span>heatmap<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> vmin<span class="token operator">=</span>vmin<span class="token punctuation">,</span> vmax<span class="token operator">=</span>vmax<span class="token punctuation">)</span> 
    ax<span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>figure<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span>


<span class="token comment"># 定义模型输入</span>
inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> X<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># 进行模型预测，并获取相应的预测结果</span>
logits <span class="token operator">=</span> runner<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
predict_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"predict result: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>predict_label<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># 输入门</span>
Is <span class="token operator">=</span> runner<span class="token punctuation">.</span>model<span class="token punctuation">.</span>rnn_model<span class="token punctuation">.</span>Is
plot_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> Is<span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">"./images/6.13_I.pdf"</span><span class="token punctuation">)</span>
<span class="token comment"># 遗忘门</span>
Fs <span class="token operator">=</span> runner<span class="token punctuation">.</span>model<span class="token punctuation">.</span>rnn_model<span class="token punctuation">.</span>Fs
plot_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> Fs<span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">"./images/6.13_F.pdf"</span><span class="token punctuation">)</span>
<span class="token comment"># 输出门</span>
Os <span class="token operator">=</span> runner<span class="token punctuation">.</span>model<span class="token punctuation">.</span>rnn_model<span class="token punctuation">.</span>Os
plot_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> Os<span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">"./images/6.13_O.pdf"</span><span class="token punctuation">)</span>
<span class="token comment"># 单元状态</span>
Cs <span class="token operator">=</span> runner<span class="token punctuation">.</span>model<span class="token punctuation">.</span>rnn_model<span class="token punctuation">.</span>Cs
plot_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> Cs<span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">"./images/6.13_C.pdf"</span><span class="token punctuation">,</span> vmin<span class="token operator">=</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> vmax<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果：</p> 
<p>输入门<br> <img src="https://images2.imgbox.com/80/fe/NyVU2p5m_o.png" alt="在这里插入图片描述"><br> 遗忘门<br> <img src="https://images2.imgbox.com/7c/c1/8ptPnwzw_o.png" alt="在这里插入图片描述"><br> 输出门<br> <img src="https://images2.imgbox.com/f6/3e/ksFa2qND_o.png" alt="在这里插入图片描述"><br> 单元状态<br> <img src="https://images2.imgbox.com/70/db/96h8gFU2_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="3LSTM_971"></a>【思考题3】分析LSTM中单元状态和门数值的变化图，并用自己的话解释该图。</h5> 
<p>其中横坐标为输入数字，纵坐标为相应门或单元状态向量的维度，颜色的深浅代表数值的大小。可以看到，当输入门遇到不同位置的数字0时，保持了相对一致的数值大小，表明对于0元素保持相同的门控过滤机制，避免输入信息的变化给当前模型带来困扰；当遗忘门遇到数字1后，遗忘门数值在一些维度上变小，表明对某些信息进行了遗忘；随着序列的输入，输出门和单元状态在某些维度上数值变小，在某些维度上数值变大，表明输出门在根据信息的重要性选择信息进行输出，同时单元状态也在保持着对文本预测重要的一些信息.</p> 
<h2><a id="RNN_975"></a>全面总结RNN（必做）</h2> 
<p><img src="https://images2.imgbox.com/8c/6d/t2uiH8Rk_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_978"></a>总结</h2> 
<p>这部分是新学的知识，一开始有点吃力，后来系统的跟着老师学下来，收获很大，但是还需要进一步总结一下才能熟练掌握。</p> 
<h2><a id="_981"></a>参考</h2> 
<p><a href="https://www.cnblogs.com/hbuwyg/p/16617681.html" rel="nofollow">NNDL 实验6（上）</a></p> 
<p><a href="https://blog.csdn.net/qq_38975453/article/details/126800091?spm=1001.2014.3001.5502">作业链接</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0c2ab5c3c17e577a0d18afaa036f47a6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">实验七 循环神经网络（3）LSTM的记忆能力实验</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9408b1e4139fe70e46ca1a772ddb8c9f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">windocs连接麒麟桌面---vnc软件</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>