<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>13. 机器学习 - 数据集的处理 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="13. 机器学习 - 数据集的处理" />
<meta property="og:description" content="文章目录 Training data splitNormalizationStandardizedONE-HOT补充：SOFTMAX 和 CROSS-ENTROPY Hi， 你好。我是茶桁。
上一节课，咱们讲解了『拟合』，了解了什么是过拟合，什么是欠拟合。也说过，如果大家以后在工作中做的就是机器学习的相关事情，那么欠拟合和过拟合就会一直陪伴着你，这两者是相互冲突的。
现在，让我们一起来思考一个问题：overfitting，过拟合产生的原因是什么？
如果这是在模型层面的话，参数过多还是过少？如果从数据层面来看，是过多还是过少呢？
好，我们来揭晓答案。如果模型层面思考，那是就是参数过多。如果从数据层面来看， 那是数据过少。
现在我们需要理解一件事情，这两个事情其实是一回事，数据量多和模型复杂其实是一回事。它背后的原因就是因为任何一个f(x)如果有很多的参数，拟合的时候随着这个参数数量越多，那么我们所需要的训练数据集也要增多。也就是说当模型非常复杂，参数特别多，只要数据量特别大，那就不算多。就说现有的数据量对于参数不够，训练力度不够。
这就好比是有一个天才的孩子，脑子极其聪明，就跟茶桁一样。哎， 这个孩子呢智商极其高，但是他想事情想的特别的复杂，结果他现在见到的事情都是太过于简单的东西。那么就不能把他的这个潜力发挥出来。
好，我们接着下一个问题：如何判断一件事情有没有发生过拟合或者欠拟合呢？
我们看这张图，假如这是一个2分类问题，咱们训练时候结果的准确度是0.7左右。那么大家想一下， 这个是过拟合还是欠拟合呢？
如果模型训练的时候效果还不错，快接近于1了，达到了百分之九十几。但是实际上用validation数据集去测的时候发现准确度下到百分之八十几，或者百分之七十几，总之就是比在训练的时候那个效果要差。这个就叫作过拟合。
咱们上节课给大家说的就是这个问题，机器学习的整个流程最终的目的不是为了把loss函数降到最低，我们要关心的是像recall，precition，这种信息才是最关键的。
Training data split 接下来，咱么要再讲几个机器学习里面极其重要的几个概念，第一个是数据集的切分(Training data split)。第二个是Normalization。第三个，Standardized。
其实上节课，咱们已经说过了数据集的切分问题。数据集切分最主要的原因是因为我们经常会遇见过拟合的情况，为了避免我们把所有的数据拿来不断的做training, 然后在使用的时候效果变得不好，那我们不如自己找一些数据出来做test sets，为了可以反复多次的去检验效果好不好，就增加了一个validation sets。
在真实环境下我们是怎么去做这样一件事呢？我们来简单的演示下：
from sklearn.model_selection import train_test_split import numpy as np sample_data = np.random.random(size(100, 5)) train, test = train_test_split(sample_data, train_size=0.8) train --- array([[1.55582066e-01, 8.19437761e-01, 3.54628257e-02, 5.53248385e-01, 4.23785508e-01], ... [7.24889349e-01, 1.23458057e-01, 9.74101303e-01, 1.72605427e-01, 6.59164912e-01]]) 非常的简单，我们来看，sklearn里自带了这种分割方法。我们随机了100行5列的数据，然后使用train_test_split将其分割成train和test两份，在后面的参数内设置了百分位。
这样，这个数据就做了一个拆分。值得注意的是，给大家教一个小技巧，这是第一种方法：split。其实不只是sklearn， pytorch和keras也都有split方法。
但是我们去看一下源码会发现， 这个split方法是没有validation，它的输出只有train和test两部分。
为了解决这个问题，我们可以用一个简单的方法。这次我们使用Numpy。
indices = np." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/5cccd0bbfcd7e7a70698bd1ecb1bfc0c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-25T13:08:48+08:00" />
<meta property="article:modified_time" content="2023-10-25T13:08:48+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">13. 机器学习 - 数据集的处理</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#Training_data_split_28" rel="nofollow">Training data split</a></li><li><a href="#Normalization_80" rel="nofollow">Normalization</a></li><li><a href="#Standardized_134" rel="nofollow">Standardized</a></li><li><a href="#ONEHOT_164" rel="nofollow">ONE-HOT</a></li><li><a href="#SOFTMAX__CROSSENTROPY_337" rel="nofollow">补充：SOFTMAX 和 CROSS-ENTROPY</a></li></ul> 
 </li></ul> 
</div> 
<br> 
<img src="https://images2.imgbox.com/b3/eb/pqxG41qJ_o.png" alt="茶桁的AI秘籍  核心基础 13"> 
<p></p> 
<p>Hi， 你好。我是茶桁。</p> 
<p>上一节课，咱们讲解了『拟合』，了解了什么是过拟合，什么是欠拟合。也说过，如果大家以后在工作中做的就是机器学习的相关事情，那么欠拟合和过拟合就会一直陪伴着你，这两者是相互冲突的。</p> 
<p>现在，让我们一起来思考一个问题：<code>overfitting</code>，过拟合产生的原因是什么？</p> 
<p>如果这是在模型层面的话，参数过多还是过少？如果从数据层面来看，是过多还是过少呢？</p> 
<p>好，我们来揭晓答案。如果模型层面思考，那是就是参数过多。如果从数据层面来看， 那是数据过少。</p> 
<p>现在我们需要理解一件事情，这两个事情其实是一回事，数据量多和模型复杂其实是一回事。它背后的原因就是因为任何一个f(x)如果有很多的参数，拟合的时候随着这个参数数量越多，那么我们所需要的训练数据集也要增多。也就是说当模型非常复杂，参数特别多，只要数据量特别大，那就不算多。就说现有的数据量对于参数不够，训练力度不够。</p> 
<p>这就好比是有一个天才的孩子，脑子极其聪明，就跟茶桁一样。哎， 这个孩子呢智商极其高，但是他想事情想的特别的复杂，结果他现在见到的事情都是太过于简单的东西。那么就不能把他的这个潜力发挥出来。</p> 
<p>好，我们接着下一个问题：如何判断一件事情有没有发生过拟合或者欠拟合呢？</p> 
<p><img src="https://images2.imgbox.com/15/c6/gY5cPvxY_o.jpg" alt="Alt text"></p> 
<p>我们看这张图，假如这是一个2分类问题，咱们训练时候结果的准确度是0.7左右。那么大家想一下， 这个是过拟合还是欠拟合呢？</p> 
<p>如果模型训练的时候效果还不错，快接近于1了，达到了百分之九十几。但是实际上用validation数据集去测的时候发现准确度下到百分之八十几，或者百分之七十几，总之就是比在训练的时候那个效果要差。这个就叫作过拟合。</p> 
<p>咱们上节课给大家说的就是这个问题，机器学习的整个流程最终的目的不是为了把loss函数降到最低，我们要关心的是像recall，precition，这种信息才是最关键的。</p> 
<h3><a id="Training_data_split_28"></a>Training data split</h3> 
<p>接下来，咱么要再讲几个机器学习里面极其重要的几个概念，第一个是数据集的切分(Training data split)。第二个是Normalization。第三个，Standardized。</p> 
<p>其实上节课，咱们已经说过了数据集的切分问题。数据集切分最主要的原因是因为我们经常会遇见过拟合的情况，为了避免我们把所有的数据拿来不断的做training, 然后在使用的时候效果变得不好，那我们不如自己找一些数据出来做test sets，为了可以反复多次的去检验效果好不好，就增加了一个validation sets。</p> 
<p>在真实环境下我们是怎么去做这样一件事呢？我们来简单的演示下：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

sample_data <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span>size<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

train<span class="token punctuation">,</span> test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>sample_data<span class="token punctuation">,</span> train_size<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span>
train

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.55582066e-01</span><span class="token punctuation">,</span> <span class="token number">8.19437761e-01</span><span class="token punctuation">,</span> <span class="token number">3.54628257e-02</span><span class="token punctuation">,</span> <span class="token number">5.53248385e-01</span><span class="token punctuation">,</span>
        <span class="token number">4.23785508e-01</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
       <span class="token punctuation">[</span><span class="token number">7.24889349e-01</span><span class="token punctuation">,</span> <span class="token number">1.23458057e-01</span><span class="token punctuation">,</span> <span class="token number">9.74101303e-01</span><span class="token punctuation">,</span> <span class="token number">1.72605427e-01</span><span class="token punctuation">,</span>
        <span class="token number">6.59164912e-01</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>非常的简单，我们来看，<code>sklearn</code>里自带了这种分割方法。我们随机了100行5列的数据，然后使用<code>train_test_split</code>将其分割成<code>train</code>和<code>test</code>两份，在后面的参数内设置了百分位。</p> 
<p>这样，这个数据就做了一个拆分。值得注意的是，给大家教一个小技巧，这是第一种方法：split。其实不只是sklearn， pytorch和keras也都有split方法。</p> 
<p>但是我们去看一下源码会发现， 这个split方法是没有validation，它的输出只有train和test两部分。</p> 
<p><img src="https://images2.imgbox.com/73/2c/8JN10orD_o.png" alt="Alt text"></p> 
<p>为了解决这个问题，我们可以用一个简单的方法。这次我们使用Numpy。</p> 
<pre><code class="prism language-python">indices <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sample_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sample_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> replace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

indices

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">49</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">99</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">76</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span>
       <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">87</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">94</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">76</span><span class="token punctuation">,</span> <span class="token number">98</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span>
       <span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">49</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">,</span>
       <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">97</span><span class="token punctuation">,</span> <span class="token number">43</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">71</span><span class="token punctuation">,</span> <span class="token number">76</span><span class="token punctuation">,</span> <span class="token number">38</span><span class="token punctuation">,</span> <span class="token number">92</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">98</span><span class="token punctuation">,</span>
       <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">39</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">71</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>这里我们等于是把它的整体的顺序打乱，后面的replace就是可以重复的去取。这样我们就随机的取了一些下标。</p> 
<p>这是一个比较简单的方法, 那么我们为什么要设置<code>replace=True</code>呢？当数量特别大的时候，多取几个少取几个其实不是很影响，另外replace的话，他内部的那个随机的算法其实是不一样的，速度会快的多。以后如果遇到类似的事情，你也可以去用这个方法去做它。</p> 
<h3><a id="Normalization_80"></a>Normalization</h3> 
<p>除了这个以外， 做机器学习的时候，要做数值的归一化(Normalization)和标准化(Standardized)这样一个动作。</p> 
<p><img src="https://images2.imgbox.com/93/25/Q0CUXwko_o.png" alt="Alt text"></p> 
<p>我们这么做的目的是什么呢？假设我们现在有多个特征的数据集，不过我们注意到一点，就是这些特征值跨越的范围是无法进行比较的。</p> 
<p>比如，一个特征在1和10之间变化，但是另外一个实在1和1000之间变化。如果我们忽略了这一点而直接进行建模，模型分配给这些特征的权重将会受到严重影响，模型最终会为较大的变量分配较高的权重。</p> 
<p>现在要解决这个问题，将这些特征置于相同或者至少是可比较的范围内，那就需要对数据做一个数据归一化。</p> 
<p>归一化的目标是讲数据缩放到特定范围内，一般来说是[0,1]或者[-1,1]之间。这有助于消除不同特征之间的尺度差异，确保它们对模型的权重贡献大致相等。</p> 
<p>数据归一化对于每个特征x，归一化后的值<code>Xnormalized</code>计算如下：</p> 
<p><img src="https://images2.imgbox.com/69/ed/ADcY8kCA_o.png" alt="Alt text"></p> 
<p>其中min是特征的最小值，max是特征的最大值。这个操作确保了数据的最小值映射到0， 最大值映射到1.</p> 
<p>在数据预处理过程中，首先计算每个特征的最小值和最大值，然后使用上述公式对数据进行归一化。这通常通过一次遍历数据来实现。</p> 
<p>在进行归一化的时候，我们所使用的那个公式会有一个缺点，就是它并不能很好的去处理异常值。比方说，如果有0到40之间的99个值，其中一个值为100， 则这99个值讲全部转换为0到0.4之间的值。这些数据和以前一样被压缩！下图就是个示例：</p> 
<p><img src="https://images2.imgbox.com/7f/47/83yqM9sV_o.png" alt="Alt text"></p> 
<p>这些数据在进行归一化之后，解决的是y轴上堆集的问题，但是x轴上的问题依然存在，就像途中橙色点那个异常值：</p> 
<p><img src="https://images2.imgbox.com/4b/34/uo6DTs0H_o.png" alt="Alt text"></p> 
<p>关于这个知识点，我们来看一个极其简单的例子：</p> 
<pre><code class="prism language-python">some_large_number <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">23421421</span><span class="token punctuation">,</span><span class="token number">42155151</span><span class="token punctuation">,</span><span class="token number">25531238</span><span class="token punctuation">,</span><span class="token number">21826139</span><span class="token punctuation">,</span> <span class="token number">32189732</span><span class="token punctuation">,</span> <span class="token number">32103721</span><span class="token punctuation">]</span>
<span class="token keyword">def</span> <span class="token function">normalize</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
ic<span class="token punctuation">(</span>normalize<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>some_large_number<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.07847317</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.18225672</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.50979325</span><span class="token punctuation">,</span> <span class="token number">0.5055623</span> <span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>我手动定义了6个比较大的数字，在进行处理之后我们看到了，都变成了一些特别小的数字。</p> 
<p>同样的，对于特别小的数字，它一样可以进行处理：</p> 
<pre><code class="prism language-python">some_small_number <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.00000231213</span><span class="token punctuation">,</span>  <span class="token number">0.0005600321</span><span class="token punctuation">,</span> <span class="token number">0.0000041412892</span><span class="token punctuation">,</span> <span class="token number">0.000987890576</span><span class="token punctuation">,</span> <span class="token number">0.0000578921764</span><span class="token punctuation">]</span>
ic<span class="token punctuation">(</span>normalize<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>some_small_number<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span> 
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.56588085</span><span class="token punctuation">,</span> <span class="token number">0.00185592</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.05639333</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="Standardized_134"></a>Standardized</h3> 
<p>那么还有就是标准化，对于标准化，其目标是讲数据转化为均值为0， 标准差为1的分布，也就是标准正态分布。这有助于处理偏斜分布的数据，并确保数据的均值和方差在模型中起到合适的作用。</p> 
<p><img src="https://images2.imgbox.com/b7/7d/bhS5yQMm_o.png" alt="Alt text"></p> 
<p>那对于每一个特征x，标准化的值<code>z</code>计算如下：</p> 
<p><img src="https://images2.imgbox.com/47/61/NdmDd5Xr_o.png" alt="Alt text"></p> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         μ 
        
       
      
        \mu 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span></span>是特征的均值，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         σ 
        
       
      
        \sigma 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span></span></span></span></span>是特征的标准差。这个操作使数据的均值为0，标准差为1。</p> 
<p>在数据预处理的过程中，首先计算每个特征的均值和标准差，然后使用上述公式对数据进行标准化处理。标准化后的数据具有均值0和标准差1，这有助于模型更好的理解和捕捉数据之间的关系。</p> 
<p>无论是归一化还是标准化，其实依据来源都是基于线性代数的变化理论，这确保了归一化和标准化后的数据分布具有特定的属性，这些属性对于机器学习算法的表现非常有帮助。</p> 
<p>我们来看一个标准化的例子，为了让大家更为明显的了解其意义，我做了一些非常大的数据，但是每一个都不相同。这些数据有一个特点，就是相对于数值本身的大小来说，几个数值之间的差距可以说是非常微小的：</p> 
<pre><code class="prism language-python">some_dense_number <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">47238941</span><span class="token punctuation">,</span> <span class="token number">47238946</span><span class="token punctuation">,</span> <span class="token number">47238951</span><span class="token punctuation">,</span> <span class="token number">47238931</span><span class="token punctuation">,</span> <span class="token number">47238949</span><span class="token punctuation">,</span> <span class="token number">47238936</span><span class="token punctuation">]</span>
<span class="token keyword">def</span> <span class="token function">standarlize</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

ic<span class="token punctuation">(</span>standarlize<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>some_dense_number<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.18752289</span><span class="token punctuation">,</span>  <span class="token number">0.51568795</span><span class="token punctuation">,</span>  <span class="token number">1.2188988</span> <span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.59394459</span><span class="token punctuation">,</span>  <span class="token number">0.93761446</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.89073374</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>我们定义的数据实际上是非常密集，但是使用standarlize公式之后，就变得比较的分散，比较的均匀了。这个情况还是很多的。</p> 
<h3><a id="ONEHOT_164"></a>ONE-HOT</h3> 
<p>在讲完training data split, normalization, Standardized之后，我们来看下面一点： ONE-HOT。</p> 
<p>为什么要用ONE-HOT？ 我们都直到，咱们计算机里其实都是数字，包括视频，图片，声音，文字等其实都是数字。</p> 
<p>数字和数字其实是不一样的。比如，有一群人分成了<code>4</code>组：</p> 
<p><img src="https://images2.imgbox.com/79/6b/ItNbjzbz_o.png" alt="Alt text"></p> 
<p>然后有一个女生的GPA是<code>4</code>:</p> 
<p><img src="https://images2.imgbox.com/79/1c/fN3sIoRI_o.png" alt="Alt text"></p> 
<p>那么分组的<code>4</code>和GPA的<code>4</code>有什么区别？最明显的一个区别就是，分组的<code>4</code>只是一个组名，那么假如和<code>1</code>组交换组名并没有太大的关系，但是GPA的这个<code>4</code>如何和<code>1</code>交换一下，那就从4分变成1分了，那这两个是不能相互变换的。本质上，其区别就是一个可比一个不可比。</p> 
<p>我们也就发现了，数字其实是有区别的。这个世界中，数字其实可以分成两类：</p> 
<p>第一类叫作Categorical，叫作分类数据，也被称为离散数据或名义数据。它们之间不能被比较，也不能被排序，这些数字也仅仅是表示一个和另外一个不一样。就我们刚才讲人群分为1、2、3、4组，其实分成A、B、C、D组也是一样的，只是表示区别。</p> 
<p><img src="https://images2.imgbox.com/2f/78/JsJI8dkk_o.png" alt="Alt text"></p> 
<p>第二类是Numerical，数值数据，也被称为连续数据。这个是可以比较的，也可以进行排序。这种数据包括可以用来进行数学运算的实数值。</p> 
<p><img src="https://images2.imgbox.com/15/84/98kH2gq2_o.png" alt="Alt text"></p> 
<p>Numerical还可以进一步分为整数和浮点数。</p> 
<p>知道了这一点之后，那我们以后遇到类似的情况不要随便的做加减乘除。</p> 
<p>那我们有了Categorical和Numerical这两种类型之后，会对我们有一些什么比较重要的影响？</p> 
<p>如果现在有一个函数，这个函数输入一个x向量，它输出就是分为一个Categorical和numerical。</p> 
<p>输出是0-1这样一个数字，是一个典型的逻辑回归。</p> 
<p>假如有一个人在北京，年龄27，性别男，月入一万二。然后还有一个人，生活在安徽，年龄28，性别女，月入8,000。第三个住在上海，年龄28，性别男，月入一万三。</p> 
<ol><li>北京, 27, 12000</li><li>安徽, 28, 8000</li><li>上海, 28, 13000</li></ol> 
<p>我们注意这三组数据，如果现在做一个向量表证。</p> 
<p>关于地域，我们常常使用的方法包括邮编排序，或者使用拼音排序。假如这里我们就使用拼音首字母来进行排序，安徽假如是1， 北京是2， 上海是27。</p> 
<p>我们的数据进行向量化可能就会变成下面这样：</p> 
<pre><code class="prism language-python"><span class="token comment"># 1. 北京</span>
vec<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">12000</span><span class="token punctuation">)</span>
<span class="token comment"># 2. 安徽</span>
vec<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">8000</span><span class="token punctuation">)</span>
<span class="token comment"># 3. 上海</span>
vec<span class="token punctuation">(</span><span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">13000</span><span class="token punctuation">)</span>
</code></pre> 
<p>然后我们定义一个函数：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<p>非常简单一个函数，返回表示对某一样东西买还是不买。</p> 
<p>函数的实现过程就是类似于<code>wi * xi + b</code>这种形式。</p> 
<p>我们观察向量发现，就向量值而言，北京这个人和安徽这个人之间的向量差比北京和上海这两人之间的向量差还要小。</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ∣ 
         
         
         
           v 
          
         
           1 
          
         
        
          − 
         
         
         
           v 
          
         
           2 
          
         
        
          ∣ 
         
        
          &lt; 
         
        
          ∣ 
         
         
         
           v 
          
         
           1 
          
         
        
          − 
         
         
         
           v 
          
         
           3 
          
         
        
          ∣ 
         
        
       
         |v_1 - v_2| &lt; |v_1 - v_3| 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span></span></span></span></span></span></p> 
<p>我们假如说经过函数<code>f(x)</code>之后，输出的结果分别为Y1, Y2, Y3。因为v1和v2离的更近，就会有一个结果，Y1和Y2的结果其实会更相似。但是其实呢，这种结果完全不对。这样乱比其实会出问题，会让程序出错。</p> 
<p>我们现在知道，这其实是一个Categorical的问题。为了解决Categorical的这种问题，我把Categorical改成这样：</p> 
<pre><code class="prism language-python">北京<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
安徽<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
上海<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
</code></pre> 
<p>改成这样之后这个向量就变成了这样：</p> 
<pre><code class="prism language-python"><span class="token comment"># 1. 北京</span>
vec<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">12000</span><span class="token punctuation">)</span>
<span class="token comment"># 2. 安徽</span>
vec<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">8000</span><span class="token punctuation">)</span>
<span class="token comment"># 3. 上海</span>
vec<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">13000</span><span class="token punctuation">)</span>
</code></pre> 
<p>向量变成这样之后，就解决了我们刚刚说的那个问题。不会导致因为分类过于相似让北京和安徽向量相似度大于北京和上海的相似度。</p> 
<p>对于这样一个向量，三组数据中改变的那个值向量值就都为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          2 
         
        
       
      
        \sqrt 2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.04em; vertical-align: -0.1328em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9072em;"><span class="svg-align" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord" style="padding-left: 0.833em;">2</span></span><span class="" style="top: -2.8672em;"><span class="pstrut" style="height: 3em;"></span><span class="hide-tail" style="min-width: 0.853em; height: 1.08em;"> 
           <svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"> 
            <path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path> 
           </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1328em;"><span class=""></span></span></span></span></span></span></span></span></span>，这一种方式就被称为ONE-HOT。</p> 
<p>那这种方式也是存在问题的，目前我们只去考虑三个城市。可是当存在成百上千个城市的时候，比如说Google地图等等这些应用。</p> 
<p><img src="https://images2.imgbox.com/57/1f/W4bHCv94_o.png" alt="Alt text"></p> 
<p>当城市越来越多的时候，那它的维度就会变得很高：</p> 
<pre><code class="prism language-python">Beijing     <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
Shanghai    <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
Chengdu     <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
Shenzhen    <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> 
<p>我们想想一下，这样得有多少个地址？可能空间会极其的大，你这样的话数字光存起来得上亿个存储单元。</p> 
<p>ONE-HOT就有这样的问题：</p> 
<ol><li>耗费空间</li><li>数据量大，更新起来，效率极低</li><li>遗漏了很多重要新息</li></ol> 
<p>就比如，我们再增加几个人如下：</p> 
<pre><code class="prism language-python"><span class="token operator">-</span> 重庆 <span class="token number">27</span> <span class="token number">9000</span>
<span class="token operator">-</span> 成都 <span class="token number">26</span> <span class="token number">8500</span>
<span class="token operator">-</span> 呼和浩特 <span class="token number">26</span> <span class="token number">8500</span>
</code></pre> 
<p>在这三个城市中，我们脑子里其实就直到，重庆和成都是非常接近的。但是在ONE-HOT里是体现不出来，其向量值依然是根号2。</p> 
<p>为了解决这些问题，人们就用到了更先进的一种方法：embedding，<br> 叫作嵌入。</p> 
<p>嵌入就是把东西放在固定的位置，这个就是嵌入的意思。在这里，就我们空间中如果有几个实体NTT1 NTT2 NTT3，我们把这些实体放到这个空间中，要达到一个结果就是如果实体1和实体2的相似度小于实体1和实体3的相似度，这个相似度我们可以自己来定义，比如成都和重庆的生活方式，再比如重庆和北京都是直辖市。</p> 
<p>在这个问题场景下，我们期望达到的结果是如果这两个实体相似那么他们在空间中的距离也接近。</p> 
<p>如何实现Embedding, 这本身是一个研究领域, 是现在非监督学习，表证学习里面非常重要的一个研究领域，属于比较高级的一个知识点。</p> 
<p>第二就是如果之后咱们学NLP，那么一定会讲到这个，因为要把文本单词进行嵌入，到时候会学到。如果是学推荐系统的，大家也会学什么Graph embedding，基于图的用户行为。</p> 
<p>那之后咱们学习NLP，其基础就是Embedding。关于这个问题，我们其实目前了解到这里就行了。再往下延展下去，又是一个专门的研究话题。延展后的这个问题解决方案，在我们后面的课程中会等着大家去学习。</p> 
<p>我们再来看看ONE-HOT的实际展示：</p> 
<pre><code class="prism language-python">array <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'北京'</span><span class="token punctuation">,</span><span class="token string">'上海'</span><span class="token punctuation">,</span><span class="token string">'广州'</span><span class="token punctuation">,</span><span class="token string">'宁夏'</span><span class="token punctuation">,</span><span class="token string">'成都'</span><span class="token punctuation">,</span><span class="token string">'上海'</span><span class="token punctuation">,</span><span class="token string">'北京'</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">one_hot</span><span class="token punctuation">(</span>elements<span class="token punctuation">)</span><span class="token punctuation">:</span>
    pure <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>elements<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    vectors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> elements<span class="token punctuation">:</span>
        vec <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pure<span class="token punctuation">)</span>
        vec<span class="token punctuation">[</span>pure<span class="token punctuation">.</span>index<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
        vectors<span class="token punctuation">.</span>append<span class="token punctuation">(</span>vec<span class="token punctuation">)</span>

    <span class="token keyword">return</span> vectors
ic<span class="token punctuation">(</span>one_hot<span class="token punctuation">(</span>array<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
one_hot<span class="token punctuation">(</span>array<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
<p>其实ONE-HOT非常简单，但是基本上很多面试官都喜欢问这个问题。这个问题主要就是一个可以考察一下你的Python编程能力，其次他可以去问一下你one hot的作用是什么，再者还可以往后问你one hot有什么缺点，怎么解决等等。一个问题就可以问你半个小时。</p> 
<h3><a id="SOFTMAX__CROSSENTROPY_337"></a>补充：SOFTMAX 和 CROSS-ENTROPY</h3> 
<p>好，在本节课最后，我们来做一个前面课程的补充，在今天才想起来，有一个相关的点遗漏了没有讲到。</p> 
<p>之前我们讲过逻辑回归的loss函数：</p> 
<p>假如y=1， loss可以等于-log(yhat), 如果y等于0， loss就可以写成-log(1-yhat)。两个合并后就组成了最终的loss函数：</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          l 
         
        
          o 
         
        
          s 
         
        
          s 
         
        
          = 
         
        
          − 
         
        
          ( 
         
        
          y 
         
        
          l 
         
        
          o 
         
        
          g 
         
         
         
           y 
          
         
           ^ 
          
         
        
          + 
         
        
          ( 
         
        
          1 
         
        
          − 
         
        
          y 
         
        
          ) 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
          ( 
         
        
          1 
         
        
          − 
         
         
         
           y 
          
         
           ^ 
          
         
        
          ) 
         
        
          ) 
         
        
       
         loss = -(ylog\hat y + (1-y)log(1- \hat y)) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">oss</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">−</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1944em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1944em;"><span class=""></span></span></span></span></span><span class="mclose">))</span></span></span></span></span></span></p> 
<p>那么，这个是解决二分类的，结果才不是0就是1。现在的问题就是如果我们要解决多分类的问题怎么办。</p> 
<p>如果要解决多分类的话，需要把x变成一种能预测多分类的东西。那最终yhat可以表示成 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          y 
         
        
          ^ 
         
        
       
         = 
        
       
         ( 
        
       
         0.25 
        
       
         , 
        
       
         0.20 
        
       
         , 
        
       
         0.75 
        
       
         ) 
        
       
      
        \hat y = (0.25, 0.20, 0.75) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1944em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">0.25</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">0.20</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">0.75</span><span class="mclose">)</span></span></span></span></span>。</p> 
<p>也就是，现在要表示三个类别，那我们可以用三个小数来表示。这个向量经过各种计算，如果能够变成一个三维的向量，然后再去优化里边的参数就可以做到。</p> 
<p>那这也就代表的是类别1、类别2、类别3的概率。ytrue就可以写成yhat的形式，就变成(1, 0, 0)。</p> 
<p>就是我们给定一个<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          ⃗ 
         
        
       
      
        \vec x 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.714em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.714em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">x</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2077em;"><span class="overlay" style="height: 0.714em; width: 0.471em;"> 
            <svg width="0.471em" height="0.714em" style="width:0.471em" viewbox="0 0 471 714" preserveaspectratio="xMinYMin"> 
             <path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path> 
            </svg></span></span></span></span></span></span></span></span></span></span></span>, 它实际的y是(1, 0, 0)， 那么yhat就是估计值等于0.25、0.20和0.75。然后对比一下两组数据之间的差别，这样我们就可以优化其中的形成参数(w, b)。</p> 
<p>通过不断优化, 就可以计算到更接近于(1, 0, 0)这样的值。</p> 
<p>首先就是怎么样把x向量变成3维的。</p> 
<p>这个其实不难，如果x是10维的，1<em>10。那么给他再乘以一个<br> 10</em>3的矩阵，它最后就会变成一个1行乘3列的矩阵。</p> 
<p>那么现在假如说现在有这样一个x:</p> 
<pre><code class="prism language-python">x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1231</span><span class="token punctuation">,</span> <span class="token number">12314</span><span class="token punctuation">,</span> <span class="token number">4341</span><span class="token punctuation">,</span> <span class="token number">1542</span><span class="token punctuation">,</span> <span class="token number">4123</span><span class="token punctuation">,</span> <span class="token number">4512</span><span class="token punctuation">,</span> <span class="token number">3213</span><span class="token punctuation">,</span> <span class="token number">1241</span><span class="token punctuation">,</span> <span class="token number">1231</span><span class="token punctuation">,</span> <span class="token number">6842</span><span class="token punctuation">]</span>
</code></pre> 
<p>然后我们来做这样一件事:</p> 
<pre><code class="prism language-python">x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>normalize<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
weights <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> weights<span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.86907231</span><span class="token punctuation">,</span> <span class="token number">1.32234548</span><span class="token punctuation">,</span> <span class="token number">0.88170994</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>这样，我们就生成了一个维度是3的一串数字。在机器学习里面，我们把这个叫做算子：logits。</p> 
<p>现在我们将一个10维的x变成了一个3维的logit，下一步我们就要考虑，怎么将这个logit变成一个概率分布呢？</p> 
<p>我们就要用到一个和逻辑函数特别像的一个函数，Softmax：</p> 
<p><img src="https://images2.imgbox.com/d3/b6/hmW23N9j_o.png" alt="Alt text"></p> 
<p>我把它写出来:</p> 
<pre><code class="prism language-python">logits <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> weights<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

ic<span class="token punctuation">(</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.27884889</span><span class="token punctuation">,</span> <span class="token number">0.43875588</span><span class="token punctuation">,</span> <span class="token number">0.28239524</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>这样，我们输入的是logits，输入到Softmax，输出的就是概率了。</p> 
<p>输出成概率之后，我们定义一个依然和逻辑函数很像的一个函数，叫做Cross-entropy。</p> 
<p>我们刚才使用softmax输出的数组就是概率，也就是估算的yhat。这个Cross-entropy的loss就是：</p> 
<p><img src="https://images2.imgbox.com/85/73/Ivj81c2N_o.png" alt="Alt text"></p> 
<p>求得loss，然后再对x求偏导，就可以通过梯度下降让输入的x得到和真正的y相近的yhat。</p> 
<p>那我们将cross-entropy也写一下：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">cross_entropy</span><span class="token punctuation">(</span>yhat<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token operator">-</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_i <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>yhat_i<span class="token punctuation">)</span> <span class="token keyword">for</span> y_i<span class="token punctuation">,</span> yhat_i <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> yhat<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>现在我们需要一组真正的y，也就是真实值，和我们预测房价时所使用的真实值是一样的东西，只是现在我们的y的维度不太一样：</p> 
<pre><code class="prism language-python">y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
</code></pre> 
<p>接着我们使用<code>cross_entropy</code>将我们之前使用softmax计算的概率分布和真实的y放进去：</p> 
<pre><code class="prism language-python">ic<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">(</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
<span class="token number">1.040664959870481</span>
</code></pre> 
<p>这个时候我们就得到了一个loss值。</p> 
<p>我们现在去给weights求偏导。然后通过不断的迭代，就能找到一组wi， 和x进行点乘就能够生成和y接近的值。</p> 
<p>以上这些就是softmax和cross-entropy的作用。</p> 
<p>cross-centropy就是用来衡量产生的yhat和y之间的相似程度差距的。 Softmax是把任意的一组数字变成概率分布，然后这个概率分布就可以送到loss函数里面和实际上的y进行对比。</p> 
<p>Softmax有这么几个特性，它的结果是一个典型的概率分布。还有就是Softmax中有e的n次方，可以把Max变得更大。除了把Max变得更大，还保留原来小的数字。</p> 
<p>理论上完全可以找别的函数代替，计算机里边很多东西，只要好用就行。这就是放大特征，正是面对多分类任务的一个做法。</p> 
<p>Softmax在实现的时候有个坑稍微要注意一下，在实现的时候我们多加一句：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">-=</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 多加这么两句</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

ic<span class="token punctuation">(</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>首先，如果x的输入是一个array就不用管了，但是如果不是，我们就要强制转换一下。</p> 
<p>下一句代码是因为e的x次方可能非常的大，但是我们计算机的存储是有限的，最大只能表示2^63的数字，再大就表示不了了。所以我们就需要这样一段代码来处理一下，让最后结果的数字不要那么大。</p> 
<p>好，那这一节课的内容到这里也就结束了。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f08e004fdaf71f24bfc2cc908f2b2270/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">mysql学习</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ffa2e5a99349027b4ea8166d516fb19b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Apache poi xwpf word转PDF中文显示与页码问题解决</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>