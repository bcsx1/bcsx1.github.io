<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【图像处理】 -041 MTCNN&#43;DCNN人脸检测 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【图像处理】 -041 MTCNN&#43;DCNN人脸检测" />
<meta property="og:description" content="【图像处理】 -041 MTCNN&#43;DCNN人脸检测 文章目录 【图像处理】 -041 MTCNN&#43;DCNN人脸检测1 简介2 C&#43;&#43;实现3 检测效果4 分析 1 简介 相比于R-CNN系列通用检测方法，本文更加针对人脸检测这一专门的任务，速度和精度都有足够的提升。R-CNN，Fast R-CNN，FasterR-CNN这一系列的方法不是一篇博客能讲清楚的，有兴趣可以找相关论文阅读。类似于TCDCN，本文提出了一种Multi-task的人脸检测框架，将人脸检测和人脸特征点检测同时进行。论文使用3个CNN级联的方式，和Viola-Jones类似，实现了coarse-to-fine的算法结构。
当给定一张照片的时候，将其缩放到不同尺度形成图像金字塔，以达到尺度不变。
Stage 1：使用P-Net是一个全卷积网络，用来生成候选窗和边框回归向量(bounding box regression vectors)。使用Bounding box regression的方法来校正这些候选窗，使用非极大值抑制（NMS）合并重叠的候选框。全卷积网络和Faster R-CNN中的RPN一脉相承。
Stage 2：使用N-Net改善候选窗。将通过P-Net的候选窗输入R-Net中，拒绝掉大部分false的窗口，继续使用Bounding box regression和NMS合并。
Stage 3：最后使用O-Net输出最终的人脸框和特征点位置。和第二步类似，但是不同的是生成5个特征点位置。
2 C&#43;&#43;实现 #include &lt;opencv2/opencv.hpp&gt; #include &#34;mtcnn.h&#34; #include &#34;HighPerformanceTimer.hpp&#34; #include &lt;fstream&gt; using namespace cv; #define MAXFACEOPEN 0 //设置是否开关最大人脸调试，1为开，其它为关 //读取待检测文件列表 std::vector&lt;std::string&gt; ReadImgList(std::string&amp; imglistfilename) { std::vector&lt;std::string&gt; imgs; std::ifstream imglistfile(imglistfilename, std::ifstream::in); std::string line; while (getline(imglistfile, line))//按行读取 { imgs.push_back(line); } return imgs; } int main(int argc, char** argv) { if (argc &lt; 3) { std::cout &lt;&lt; &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/747cae3c2584b76ce75561e54d3268b6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-08-13T14:45:26+08:00" />
<meta property="article:modified_time" content="2019-08-13T14:45:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【图像处理】 -041 MTCNN&#43;DCNN人脸检测</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_041_MTCNNDCNN_1"></a>【图像处理】 -041 MTCNN+DCNN人脸检测</h2> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_041_MTCNNDCNN_1" rel="nofollow">【图像处理】 -041 MTCNN+DCNN人脸检测</a></li><li><ul><li><a href="#1__4" rel="nofollow">1 简介</a></li><li><a href="#2_C_16" rel="nofollow">2 C++实现</a></li><li><a href="#3__633" rel="nofollow">3 检测效果</a></li><li><a href="#4__642" rel="nofollow">4 分析</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="1__4"></a>1 简介</h3> 
<p>  相比于R-CNN系列通用检测方法，本文更加针对人脸检测这一专门的任务，速度和精度都有足够的提升。R-CNN，Fast R-CNN，FasterR-CNN这一系列的方法不是一篇博客能讲清楚的，有兴趣可以找相关论文阅读。类似于TCDCN，本文提出了一种Multi-task的人脸检测框架，将人脸检测和人脸特征点检测同时进行。论文使用3个CNN级联的方式，和Viola-Jones类似，实现了coarse-to-fine的算法结构。</p> 
<p>  当给定一张照片的时候，将其缩放到不同尺度形成图像金字塔，以达到尺度不变。</p> 
<ul><li> <p>Stage 1：使用P-Net是一个全卷积网络，用来生成候选窗和边框回归向量(bounding box regression vectors)。使用Bounding box regression的方法来校正这些候选窗，使用非极大值抑制（NMS）合并重叠的候选框。全卷积网络和Faster R-CNN中的RPN一脉相承。</p> </li><li> <p>Stage 2：使用N-Net改善候选窗。将通过P-Net的候选窗输入R-Net中，拒绝掉大部分false的窗口，继续使用Bounding box regression和NMS合并。</p> </li><li> <p>Stage 3：最后使用O-Net输出最终的人脸框和特征点位置。和第二步类似，但是不同的是生成5个特征点位置。</p> </li></ul> 
<h3><a id="2_C_16"></a>2 C++实现</h3> 
<pre><code class="prism language-C++">#include &lt;opencv2/opencv.hpp&gt;
#include "mtcnn.h"

#include "HighPerformanceTimer.hpp"
#include &lt;fstream&gt;
using namespace cv;

#define MAXFACEOPEN 0 //设置是否开关最大人脸调试，1为开，其它为关


//读取待检测文件列表
std::vector&lt;std::string&gt; ReadImgList(std::string&amp; imglistfilename)
{
    std::vector&lt;std::string&gt; imgs;
    std::ifstream imglistfile(imglistfilename, std::ifstream::in);
    std::string line;
    while (getline(imglistfile, line))//按行读取
    {
        imgs.push_back(line);
    }
    return imgs;
}

int main(int argc, char** argv) {

    if (argc &lt; 3)
    {
        std::cout &lt;&lt; "Please use this exe like this:" &lt;&lt; std::endl;
        std::cout &lt;&lt; "OpenCV_Harrx.exe imglist.txt outputpath" &lt;&lt; std::endl;
        system("pause");
    }
    std::string imglistfile(argv[1]);
    std::string outputpath(argv[2]);
    std::vector&lt;std::string&gt; imgs = ReadImgList(imglistfile);

    char *model_path = "./models";
    MTCNN mtcnn(model_path);
    char* pTname = (char*)"timer";
    CHighPerformanceTimer* pTimer = new CHighPerformanceTimer(pTname, 6, true);
    std::ofstream of(outputpath, std::ofstream::out);
    for (int i = 0; i &lt; imgs.size(); i++)
    {
        cv::Mat image = cv::imread((char*)imgs[i].c_str());
        pTimer-&gt;Reset();
        ncnn::Mat ncnn_img = ncnn::Mat::from_pixels(image.data, ncnn::Mat::PIXEL_BGR2RGB, image.cols, image.rows);
        std::vector&lt;Bbox&gt; finalBbox;
#if(MAXFACEOPEN==1)
        mtcnn.detectMaxFace(ncnn_img, finalBbox);
#else
        mtcnn.detect(ncnn_img, finalBbox);
#endif
        double dt = pTimer-&gt;GetTime();



        const int num_box = finalBbox.size();
        std::vector&lt;cv::Rect&gt; bbox;
        bbox.resize(num_box);
        of &lt;&lt; imgs[i] &lt;&lt; " " &lt;&lt; dt &lt;&lt; "s " &lt;&lt; bbox.size() &lt;&lt; " ";
        std::cout &lt;&lt; imgs[i] &lt;&lt; " " &lt;&lt; dt &lt;&lt; "s " &lt;&lt; bbox.size() &lt;&lt; " ";
        for (int i = 0; i &lt; num_box; i++) {
            bbox[i] = cv::Rect(finalBbox[i].x1, finalBbox[i].y1, finalBbox[i].x2 - finalBbox[i].x1 + 1, finalBbox[i].y2 - finalBbox[i].y1 + 1);

            of &lt;&lt; bbox[i];
            std::cout &lt;&lt; bbox[i];
            for (int j = 0; j &lt; 5; j = j + 1)
            {
                cv::circle(image, cv::Point(finalBbox[i].ppoint[j], finalBbox[i].ppoint[j + 5]), 2, CV_RGB(0, 255, 0), cv::FILLED);
            }
        }
        for (vector&lt;cv::Rect&gt;::iterator it = bbox.begin(); it != bbox.end(); it++)
        {
            rectangle(image, (*it), Scalar(0, 0, 255), 2, 8, 0);
        }
        of &lt;&lt; std::endl;
        std::cout &lt;&lt; std::endl;
        imshow("face_detection", image);
        cv::waitKey(0);
    }
    of.close();

    return 0;
}

</code></pre> 
<pre><code class="prism language-C++">#pragma once

#ifndef __MTCNN_NCNN_H__
#define __MTCNN_NCNN_H__
#include "net.h"
//#include &lt;opencv2/opencv.hpp&gt;
#include &lt;string&gt;
#include &lt;vector&gt;
#include &lt;time.h&gt;
#include &lt;algorithm&gt;
#include &lt;map&gt;
#include &lt;iostream&gt;
using namespace std;
//using namespace cv;
struct Bbox
{
    float score;
    int x1;
    int y1;
    int x2;
    int y2;
    float area;
    float ppoint[10];
    float regreCoord[4];
};


class MTCNN {

public:
    MTCNN(const string &amp;model_path);
    MTCNN(const std::vector&lt;std::string&gt; param_files, const std::vector&lt;std::string&gt; bin_files);
    ~MTCNN();

    void SetMinFace(int minSize);
    void detect(ncnn::Mat&amp; img_, std::vector&lt;Bbox&gt;&amp; finalBbox);
    void detectMaxFace(ncnn::Mat&amp; img_, std::vector&lt;Bbox&gt;&amp; finalBbox);
    //  void detection(const cv::Mat&amp; img, std::vector&lt;cv::Rect&gt;&amp; rectangles);
private:
    void generateBbox(ncnn::Mat score, ncnn::Mat location, vector&lt;Bbox&gt;&amp; boundingBox_, float scale);
    void nmsTwoBoxs(vector&lt;Bbox&gt; &amp;boundingBox_, vector&lt;Bbox&gt; &amp;previousBox_, const float overlap_threshold, string modelname = "Union");
    void nms(vector&lt;Bbox&gt; &amp;boundingBox_, const float overlap_threshold, string modelname = "Union");
    void refine(vector&lt;Bbox&gt; &amp;vecBbox, const int &amp;height, const int &amp;width, bool square);
    void extractMaxFace(vector&lt;Bbox&gt; &amp;boundingBox_);

    void PNet(float scale);
    void PNet();
    void RNet();
    void ONet();

    ncnn::Net Pnet, Rnet, Onet;
    ncnn::Mat img;

    const float nms_threshold[3] = { 0.5f, 0.7f, 0.7f };
    const float mean_vals[3] = { 127.5, 127.5, 127.5 };
    const float norm_vals[3] = { 0.0078125, 0.0078125, 0.0078125 };
    const int MIN_DET_SIZE = 12;
    std::vector&lt;Bbox&gt; firstPreviousBbox_, secondPreviousBbox_, thirdPrevioussBbox_;
    std::vector&lt;Bbox&gt; firstBbox_, secondBbox_, thirdBbox_;
    int img_w, img_h;

private://部分可调参数
    const float threshold[3] = { 0.8f, 0.8f, 0.6f };
    int minsize = 40;
    const float pre_facetor = 0.709f;

};


#endif //__MTCNN_NCNN_H__


</code></pre> 
<pre><code class="prism language-C++">#include "mtcnn.h"

bool cmpScore(Bbox lsh, Bbox rsh) {
    if (lsh.score &lt; rsh.score)
        return true;
    else
        return false;
}

bool cmpArea(Bbox lsh, Bbox rsh) {
    if (lsh.area &lt; rsh.area)
        return false;
    else
        return true;
}

//MTCNN::MTCNN(){}
MTCNN::MTCNN(const string &amp;model_path) {

    std::vector&lt;std::string&gt; param_files = {
        model_path + "/det1.param",
        model_path + "/det2.param",
        model_path + "/det3.param"
    };

    std::vector&lt;std::string&gt; bin_files = {
        model_path + "/det1.bin",
        model_path + "/det2.bin",
        model_path + "/det3.bin"
    };

    Pnet.load_param(param_files[0].data());
    Pnet.load_model(bin_files[0].data());
    Rnet.load_param(param_files[1].data());
    Rnet.load_model(bin_files[1].data());
    Onet.load_param(param_files[2].data());
    Onet.load_model(bin_files[2].data());
}

MTCNN::MTCNN(const std::vector&lt;std::string&gt; param_files, const std::vector&lt;std::string&gt; bin_files) {
    Pnet.load_param(param_files[0].data());
    Pnet.load_model(bin_files[0].data());
    Rnet.load_param(param_files[1].data());
    Rnet.load_model(bin_files[1].data());
    Onet.load_param(param_files[2].data());
    Onet.load_model(bin_files[2].data());
}


MTCNN::~MTCNN() {
    Pnet.clear();
    Rnet.clear();
    Onet.clear();
}
void MTCNN::SetMinFace(int minSize) {
    minsize = minSize;
}
void MTCNN::generateBbox(ncnn::Mat score, ncnn::Mat location, std::vector&lt;Bbox&gt;&amp; boundingBox_, float scale) {
    const int stride = 2;
    const int cellsize = 12;
    //score p
    float *p = score.channel(1);//score.data + score.cstep;
    //float *plocal = location.data;
    Bbox bbox;
    float inv_scale = 1.0f / scale;
    for (int row = 0; row &lt; score.h; row++) {
        for (int col = 0; col &lt; score.w; col++) {
            if (*p &gt; threshold[0]) {
                bbox.score = *p;
                bbox.x1 = round((stride*col + 1)*inv_scale);
                bbox.y1 = round((stride*row + 1)*inv_scale);
                bbox.x2 = round((stride*col + 1 + cellsize)*inv_scale);
                bbox.y2 = round((stride*row + 1 + cellsize)*inv_scale);
                bbox.area = (bbox.x2 - bbox.x1) * (bbox.y2 - bbox.y1);
                const int index = row * score.w + col;
                for (int channel = 0; channel &lt; 4; channel++) {
                    bbox.regreCoord[channel] = location.channel(channel)[index];
                }
                boundingBox_.push_back(bbox);
            }
            p++;
            //plocal++;
        }
    }
}

void MTCNN::nmsTwoBoxs(vector&lt;Bbox&gt;&amp; boundingBox_, vector&lt;Bbox&gt;&amp; previousBox_, const float overlap_threshold, string modelname)
{
    if (boundingBox_.empty()) {
        return;
    }
    sort(boundingBox_.begin(), boundingBox_.end(), cmpScore);
    float IOU = 0;
    float maxX = 0;
    float maxY = 0;
    float minX = 0;
    float minY = 0;
    //std::cout &lt;&lt; boundingBox_.size() &lt;&lt; " ";
    for (std::vector&lt;Bbox&gt;::iterator ity = previousBox_.begin(); ity != previousBox_.end(); ity++) {
        for (std::vector&lt;Bbox&gt;::iterator itx = boundingBox_.begin(); itx != boundingBox_.end();) {
            int i = itx - boundingBox_.begin();
            int j = ity - previousBox_.begin();
            maxX = max(boundingBox_.at(i).x1, previousBox_.at(j).x1);
            maxY = max(boundingBox_.at(i).y1, previousBox_.at(j).y1);
            minX = min(boundingBox_.at(i).x2, previousBox_.at(j).x2);
            minY = min(boundingBox_.at(i).y2, previousBox_.at(j).y2);
            //maxX1 and maxY1 reuse
            maxX = ((minX - maxX + 1) &gt; 0) ? (minX - maxX + 1) : 0;
            maxY = ((minY - maxY + 1) &gt; 0) ? (minY - maxY + 1) : 0;
            //IOU reuse for the area of two bbox
            IOU = maxX * maxY;
            if (!modelname.compare("Union"))
                IOU = IOU / (boundingBox_.at(i).area + previousBox_.at(j).area - IOU);
            else if (!modelname.compare("Min")) {
                IOU = IOU / ((boundingBox_.at(i).area &lt; previousBox_.at(j).area) ? boundingBox_.at(i).area : previousBox_.at(j).area);
            }
            if (IOU &gt; overlap_threshold&amp;&amp;boundingBox_.at(i).score &gt; previousBox_.at(j).score) {
                //if (IOU &gt; overlap_threshold) {
                itx = boundingBox_.erase(itx);
            }
            else {
                itx++;
            }
        }
    }
    //std::cout &lt;&lt; boundingBox_.size() &lt;&lt; std::endl;
}

void MTCNN::nms(std::vector&lt;Bbox&gt; &amp;boundingBox_, const float overlap_threshold, string modelname) {
    if (boundingBox_.empty()) {
        return;
    }
    sort(boundingBox_.begin(), boundingBox_.end(), cmpScore);
    float IOU = 0;
    float maxX = 0;
    float maxY = 0;
    float minX = 0;
    float minY = 0;
    std::vector&lt;int&gt; vPick;
    int nPick = 0;
    std::multimap&lt;float, int&gt; vScores;
    const int num_boxes = boundingBox_.size();
    vPick.resize(num_boxes);
    for (int i = 0; i &lt; num_boxes; ++i) {
        vScores.insert(std::pair&lt;float, int&gt;(boundingBox_[i].score, i));
    }
    while (vScores.size() &gt; 0) {
        int last = vScores.rbegin()-&gt;second;
        vPick[nPick] = last;
        nPick += 1;
        for (std::multimap&lt;float, int&gt;::iterator it = vScores.begin(); it != vScores.end();) {
            int it_idx = it-&gt;second;
            maxX = max(boundingBox_.at(it_idx).x1, boundingBox_.at(last).x1);
            maxY = max(boundingBox_.at(it_idx).y1, boundingBox_.at(last).y1);
            minX = min(boundingBox_.at(it_idx).x2, boundingBox_.at(last).x2);
            minY = min(boundingBox_.at(it_idx).y2, boundingBox_.at(last).y2);
            //maxX1 and maxY1 reuse
            maxX = ((minX - maxX + 1) &gt; 0) ? (minX - maxX + 1) : 0;
            maxY = ((minY - maxY + 1) &gt; 0) ? (minY - maxY + 1) : 0;
            //IOU reuse for the area of two bbox
            IOU = maxX * maxY;
            if (!modelname.compare("Union"))
                IOU = IOU / (boundingBox_.at(it_idx).area + boundingBox_.at(last).area - IOU);
            else if (!modelname.compare("Min")) {
                IOU = IOU / ((boundingBox_.at(it_idx).area &lt; boundingBox_.at(last).area) ? boundingBox_.at(it_idx).area : boundingBox_.at(last).area);
            }
            if (IOU &gt; overlap_threshold) {
                it = vScores.erase(it);
            }
            else {
                it++;
            }
        }
    }

    vPick.resize(nPick);
    std::vector&lt;Bbox&gt; tmp_;
    tmp_.resize(nPick);
    for (int i = 0; i &lt; nPick; i++) {
        tmp_[i] = boundingBox_[vPick[i]];
    }
    boundingBox_ = tmp_;
}
void MTCNN::refine(vector&lt;Bbox&gt; &amp;vecBbox, const int &amp;height, const int &amp;width, bool square) {
    if (vecBbox.empty()) {
        cout &lt;&lt; "Bbox is empty!!" &lt;&lt; endl;
        return;
    }
    float bbw = 0, bbh = 0, maxSide = 0;
    float h = 0, w = 0;
    float x1 = 0, y1 = 0, x2 = 0, y2 = 0;
    for (vector&lt;Bbox&gt;::iterator it = vecBbox.begin(); it != vecBbox.end(); it++) {
        bbw = (*it).x2 - (*it).x1 + 1;
        bbh = (*it).y2 - (*it).y1 + 1;
        x1 = (*it).x1 + (*it).regreCoord[0] * bbw;
        y1 = (*it).y1 + (*it).regreCoord[1] * bbh;
        x2 = (*it).x2 + (*it).regreCoord[2] * bbw;
        y2 = (*it).y2 + (*it).regreCoord[3] * bbh;



        if (square) {
            w = x2 - x1 + 1;
            h = y2 - y1 + 1;
            maxSide = (h &gt; w) ? h : w;
            x1 = x1 + w * 0.5 - maxSide * 0.5;
            y1 = y1 + h * 0.5 - maxSide * 0.5;
            (*it).x2 = round(x1 + maxSide - 1);
            (*it).y2 = round(y1 + maxSide - 1);
            (*it).x1 = round(x1);
            (*it).y1 = round(y1);
        }

        //boundary check
        if ((*it).x1 &lt; 0)(*it).x1 = 0;
        if ((*it).y1 &lt; 0)(*it).y1 = 0;
        if ((*it).x2 &gt; width)(*it).x2 = width - 1;
        if ((*it).y2 &gt; height)(*it).y2 = height - 1;

        it-&gt;area = (it-&gt;x2 - it-&gt;x1)*(it-&gt;y2 - it-&gt;y1);
    }
}

void MTCNN::extractMaxFace(vector&lt;Bbox&gt;&amp; boundingBox_)
{
    if (boundingBox_.empty()) {
        return;
    }
    sort(boundingBox_.begin(), boundingBox_.end(), cmpArea);
    for (std::vector&lt;Bbox&gt;::iterator itx = boundingBox_.begin() + 1; itx != boundingBox_.end();) {
        itx = boundingBox_.erase(itx);
    }
}

void MTCNN::PNet(float scale)
{
    //first stage
    int hs = (int)ceil(img_h*scale);
    int ws = (int)ceil(img_w*scale);
    ncnn::Mat in;
    resize_bilinear(img, in, ws, hs);
    ncnn::Extractor ex = Pnet.create_extractor();
    ex.set_light_mode(true);
    //sex.set_num_threads(4);
    ex.input("data", in);
    ncnn::Mat score_, location_;
    ex.extract("prob1", score_);
    ex.extract("conv4-2", location_);
    std::vector&lt;Bbox&gt; boundingBox_;

    generateBbox(score_, location_, boundingBox_, scale);
    nms(boundingBox_, nms_threshold[0]);

    firstBbox_.insert(firstBbox_.end(), boundingBox_.begin(), boundingBox_.end());
    boundingBox_.clear();
}

void MTCNN::PNet() {
    firstBbox_.clear();
    float minl = img_w &lt; img_h ? img_w : img_h;
    float m = (float)MIN_DET_SIZE / minsize;
    minl *= m;
    float factor = pre_facetor;
    vector&lt;float&gt; scales_;
    while (minl &gt; MIN_DET_SIZE) {
        scales_.push_back(m);
        minl *= factor;
        m = m * factor;
    }
    for (size_t i = 0; i &lt; scales_.size(); i++) {
        int hs = (int)ceil(img_h*scales_[i]);
        int ws = (int)ceil(img_w*scales_[i]);
        ncnn::Mat in;
        resize_bilinear(img, in, ws, hs);
        ncnn::Extractor ex = Pnet.create_extractor();
        //ex.set_num_threads(2);
        ex.set_light_mode(true);
        ex.input("data", in);
        ncnn::Mat score_, location_;
        ex.extract("prob1", score_);
        ex.extract("conv4-2", location_);
        std::vector&lt;Bbox&gt; boundingBox_;
        generateBbox(score_, location_, boundingBox_, scales_[i]);
        nms(boundingBox_, nms_threshold[0]);
        firstBbox_.insert(firstBbox_.end(), boundingBox_.begin(), boundingBox_.end());
        boundingBox_.clear();
    }
}
void MTCNN::RNet() {
    secondBbox_.clear();
    int count = 0;
    for (vector&lt;Bbox&gt;::iterator it = firstBbox_.begin(); it != firstBbox_.end(); it++) {
        ncnn::Mat tempIm;
        copy_cut_border(img, tempIm, (*it).y1, img_h - (*it).y2, (*it).x1, img_w - (*it).x2);
        ncnn::Mat in;
        resize_bilinear(tempIm, in, 24, 24);
        ncnn::Extractor ex = Rnet.create_extractor();
        //ex.set_num_threads(2);
        ex.set_light_mode(true);
        ex.input("data", in);
        ncnn::Mat score, bbox;
        ex.extract("prob1", score);
        ex.extract("conv5-2", bbox);
        if ((float)score[1] &gt; threshold[1]) {
            for (int channel = 0; channel &lt; 4; channel++) {
                it-&gt;regreCoord[channel] = (float)bbox[channel];//*(bbox.data+channel*bbox.cstep);
            }
            it-&gt;area = (it-&gt;x2 - it-&gt;x1)*(it-&gt;y2 - it-&gt;y1);
            it-&gt;score = score.channel(1)[0];//*(score.data+score.cstep);
            secondBbox_.push_back(*it);
        }
    }
}
void MTCNN::ONet() {
    thirdBbox_.clear();
    for (vector&lt;Bbox&gt;::iterator it = secondBbox_.begin(); it != secondBbox_.end(); it++) {
        ncnn::Mat tempIm;
        copy_cut_border(img, tempIm, (*it).y1, img_h - (*it).y2, (*it).x1, img_w - (*it).x2);
        ncnn::Mat in;
        resize_bilinear(tempIm, in, 48, 48);
        ncnn::Extractor ex = Onet.create_extractor();
        //ex.set_num_threads(2);
        ex.set_light_mode(true);
        ex.input("data", in);
        ncnn::Mat score, bbox, keyPoint;
        ex.extract("prob1", score);
        ex.extract("conv6-2", bbox);
        ex.extract("conv6-3", keyPoint);
        if ((float)score[1] &gt; threshold[2]) {
            for (int channel = 0; channel &lt; 4; channel++) {
                it-&gt;regreCoord[channel] = (float)bbox[channel];
            }
            it-&gt;area = (it-&gt;x2 - it-&gt;x1) * (it-&gt;y2 - it-&gt;y1);
            it-&gt;score = score.channel(1)[0];
            for (int num = 0; num &lt; 5; num++) {
                (it-&gt;ppoint)[num] = it-&gt;x1 + (it-&gt;x2 - it-&gt;x1) * keyPoint[num];
                (it-&gt;ppoint)[num + 5] = it-&gt;y1 + (it-&gt;y2 - it-&gt;y1) * keyPoint[num + 5];
            }

            thirdBbox_.push_back(*it);
        }
    }
}
void MTCNN::detect(ncnn::Mat&amp; img_, std::vector&lt;Bbox&gt;&amp; finalBbox_) {
    img = img_;
    img_w = img.w;
    img_h = img.h;
    img.substract_mean_normalize(mean_vals, norm_vals);

    PNet();
    //the first stage's nms
    if (firstBbox_.size() &lt; 1) return;
    nms(firstBbox_, nms_threshold[0]);
    refine(firstBbox_, img_h, img_w, true);
    //printf("firstBbox_.size()=%d\n", firstBbox_.size());


    //second stage
    RNet();
    //printf("secondBbox_.size()=%d\n", secondBbox_.size());
    if (secondBbox_.size() &lt; 1) return;
    nms(secondBbox_, nms_threshold[1]);
    refine(secondBbox_, img_h, img_w, true);

    //third stage
    ONet();
    //printf("thirdBbox_.size()=%d\n", thirdBbox_.size());
    if (thirdBbox_.size() &lt; 1) return;
    refine(thirdBbox_, img_h, img_w, true);
    nms(thirdBbox_, nms_threshold[2], "Min");
    finalBbox_ = thirdBbox_;
}


void MTCNN::detectMaxFace(ncnn::Mat&amp; img_, std::vector&lt;Bbox&gt;&amp; finalBbox) {
    firstPreviousBbox_.clear();
    secondPreviousBbox_.clear();
    thirdPrevioussBbox_.clear();
    firstBbox_.clear();
    secondBbox_.clear();
    thirdBbox_.clear();

    //norm
    img = img_;
    img_w = img.w;
    img_h = img.h;
    img.substract_mean_normalize(mean_vals, norm_vals);

    //pyramid size
    float minl = img_w &lt; img_h ? img_w : img_h;
    float m = (float)MIN_DET_SIZE / minsize;
    minl *= m;
    float factor = pre_facetor;
    vector&lt;float&gt; scales_;
    while (minl &gt; MIN_DET_SIZE) {
        scales_.push_back(m);
        minl *= factor;
        m = m * factor;
    }
    sort(scales_.begin(), scales_.end());
    //printf("scales_.size()=%d\n", scales_.size());

    //Change the sampling process.
    for (size_t i = 0; i &lt; scales_.size(); i++)
    {
        //first stage
        PNet(scales_[i]);
        nms(firstBbox_, nms_threshold[0]);
        nmsTwoBoxs(firstBbox_, firstPreviousBbox_, nms_threshold[0]);
        if (firstBbox_.size() &lt; 1) {
            firstBbox_.clear();
            continue;
        }
        firstPreviousBbox_.insert(firstPreviousBbox_.end(), firstBbox_.begin(), firstBbox_.end());
        refine(firstBbox_, img_h, img_w, true);
        //printf("firstBbox_.size()=%d\n", firstBbox_.size());

        //second stage
        RNet();
        nms(secondBbox_, nms_threshold[1]);
        nmsTwoBoxs(secondBbox_, secondPreviousBbox_, nms_threshold[0]);
        secondPreviousBbox_.insert(secondPreviousBbox_.end(), secondBbox_.begin(), secondBbox_.end());
        if (secondBbox_.size() &lt; 1) {
            firstBbox_.clear();
            secondBbox_.clear();
            continue;
        }
        refine(secondBbox_, img_h, img_w, true);
        //printf("secondBbox_.size()=%d\n", secondBbox_.size());

        //third stage
        ONet();
        //printf("thirdBbox_.size()=%d\n", thirdBbox_.size());
        if (thirdBbox_.size() &lt; 1) {
            firstBbox_.clear();
            secondBbox_.clear();
            thirdBbox_.clear();
            continue;
        }
        refine(thirdBbox_, img_h, img_w, true);
        nms(thirdBbox_, nms_threshold[2], "Min");

        if (thirdBbox_.size() &gt; 0) {
            extractMaxFace(thirdBbox_);
            finalBbox = thirdBbox_;//if largest face size is similar,.
            break;
        }
    }

}
</code></pre> 
<h3><a id="3__633"></a>3 检测效果</h3> 
<p><img src="https://images2.imgbox.com/d0/ee/eo1k3Bxu_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c6/3b/pc0V2GoK_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/82/37/ZDJwIcHe_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/f5/fa/sWS6dmuU_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/4f/fb/BDz5xitQ_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/1a/1b/zLozsNa3_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="4__642"></a>4 分析</h3> 
<ul><li>将人脸检测与人脸5个特征点检测同时进行；</li><li>人脸检测准确率高；</li><li>对人脸偏移、倾斜、旋转、缩放的兼容性强；</li><li>运行速度快</li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/30737a7e5c9e022107ea9abcd1b249de/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">shell反引号`与$()的区别</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ad446ea6e2611f84e1b333b32df23018/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">QML Charts 往图表上添加 文字</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>