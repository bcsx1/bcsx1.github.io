<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FFmpeg的H.264解码器源代码简单分析：解析器（Parser）部分 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="FFmpeg的H.264解码器源代码简单分析：解析器（Parser）部分" />
<meta property="og:description" content="=====================================================
H.264源代码分析文章列表：
【编码 - x264】
x264源代码简单分析：概述
x264源代码简单分析：x264命令行工具（x264.exe）
x264源代码简单分析：编码器主干部分-1
x264源代码简单分析：编码器主干部分-2
x264源代码简单分析：x264_slice_write()
x264源代码简单分析：滤波（Filter）部分
x264源代码简单分析：宏块分析（Analysis）部分-帧内宏块（Intra）
x264源代码简单分析：宏块分析（Analysis）部分-帧间宏块（Inter）
x264源代码简单分析：宏块编码（Encode）部分
x264源代码简单分析：熵编码（Entropy Encoding）部分
FFmpeg与libx264接口源代码简单分析
【解码 - libavcodec H.264 解码器】
FFmpeg的H.264解码器源代码简单分析：概述
FFmpeg的H.264解码器源代码简单分析：解析器（Parser）部分
FFmpeg的H.264解码器源代码简单分析：解码器主干部分
FFmpeg的H.264解码器源代码简单分析：熵解码（EntropyDecoding）部分
FFmpeg的H.264解码器源代码简单分析：宏块解码（Decode）部分-帧内宏块（Intra）
FFmpeg的H.264解码器源代码简单分析：宏块解码（Decode）部分-帧间宏块（Inter）
FFmpeg的H.264解码器源代码简单分析：环路滤波（Loop Filter）部分
=====================================================
本文继续分析FFmpeg中libavcodec的H.264解码器（H.264 Decoder）。上篇文章概述了FFmpeg中H.264解码器的结构；从这篇文章开始，具体研究H.264解码器的源代码。本文分析H.264解码器中解析器（Parser）部分的源代码。这部分的代码用于分割H.264的NALU，并且解析SPS、PPS、SEI等信息。解析H.264码流（对应AVCodecParser结构体中的函数）和解码H.264码流（对应AVCodec结构体中的函数）的时候都会调用该部分的代码完成相应的功能。
函数调用关系图 解析器（Parser）部分的源代码在整个H.264解码器中的位置如下图所示。
单击查看更清晰的图片
解析器（Parser）部分的源代码的调用关系如下图所示。
单击查看更清晰的图片
从图中可以看出，H.264的解析器（Parser）在解析数据的时候调用h264_parse()，h264_parse()调用了parse_nal_units()，parse_nal_units()则调用了一系列解析特定NALU的函数。H.264的解码器（Decoder）在解码数据的时候调用h264_decode_frame()，h264_decode_frame()调用了decode_nal_units()，decode_nal_units()也同样调用了一系列解析不同NALU的函数。 图中简单列举了几个解析特定NALU的函数： ff_h264_decode_nal()：解析NALU Header ff_h264_decode_seq_parameter_set()：解析SPS ff_h264_decode_picture_parameter_set()：解析PPS ff_h264_decode_sei()：解析SEI H.264解码器与H.264解析器最主要的不同的地方在于它调用了ff_h264_execute_decode_slices()函数进行了解码工作。这篇文章只分析H.264解析器的源代码，至于H.264解码器的源代码，则在后面几篇文章中再进行分析。 ff_h264_decoderff_h264_decoder是FFmpeg的H.264解码器对应的AVCodec结构体。它的定义位于libavcodec\h264.c，如下所示。 AVCodec ff_h264_decoder = { .name = &#34;h264&#34;, .long_name = NULL_IF_CONFIG_SMALL(&#34;H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10&#34;), .type = AVMEDIA_TYPE_VIDEO, ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/0a379dbd775088c77a51e337df7800e8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2015-04-12T00:37:12+08:00" />
<meta property="article:modified_time" content="2015-04-12T00:37:12+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FFmpeg的H.264解码器源代码简单分析：解析器（Parser）部分</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><span style="white-space:pre"></span></p> 
<p>=====================================================</p> 
<p>H.264源代码分析文章列表：</p> 
<p>【编码 - x264】</p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45536607" rel="noopener noreferrer">x264源代码简单分析：概述</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45583217" rel="noopener noreferrer">x264源代码简单分析：x264命令行工具（x264.exe）</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45644367" rel="noopener noreferrer">x264源代码简单分析：编码器主干部分-1</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45719905" rel="noopener noreferrer">x264源代码简单分析：编码器主干部分-2</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45790195" rel="noopener noreferrer">x264源代码简单分析：x264_slice_write()</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45870269" rel="noopener noreferrer">x264源代码简单分析：滤波（Filter）部分</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45917757" rel="noopener noreferrer">x264源代码简单分析：宏块分析（Analysis）部分-帧内宏块（Intra）</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45936267" rel="noopener noreferrer">x264源代码简单分析：宏块分析（Analysis）部分-帧间宏块（Inter）</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45938927" rel="noopener noreferrer">x264源代码简单分析：宏块编码（Encode）部分</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45944811" rel="noopener noreferrer">x264源代码简单分析：熵编码（Entropy Encoding）部分</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45960409" rel="noopener noreferrer">FFmpeg与libx264接口源代码简单分析</a></p> 
<p>【解码 - libavcodec H.264 解码器】</p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/44864509" rel="noopener noreferrer">FFmpeg的H.264解码器源代码简单分析：概述</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45001033" rel="noopener noreferrer">FFmpeg的H.264解码器源代码简单分析：解析器（Parser）部分</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45042755" rel="noopener noreferrer">FFmpeg的H.264解码器源代码简单分析：解码器主干部分</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45114453" rel="noopener noreferrer">FFmpeg的H.264解码器源代码简单分析：熵解码（EntropyDecoding）部分</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45143075" rel="noopener noreferrer">FFmpeg的H.264解码器源代码简单分析：宏块解码（Decode）部分-帧内宏块（Intra）</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45195291" rel="noopener noreferrer">FFmpeg的H.264解码器源代码简单分析：宏块解码（Decode）部分-帧间宏块（Inter）</a></p> 
<p><a target="_blank" href="http://blog.csdn.net/leixiaohua1020/article/details/45224579" rel="noopener noreferrer">FFmpeg的H.264解码器源代码简单分析：环路滤波（Loop Filter）部分</a></p> 
<p>=====================================================</p> 
<br> 
<p><span style="white-space:pre"> </span>本文继续分析FFmpeg中libavcodec的H.264解码器（H.264 Decoder）。上篇文章概述了FFmpeg中H.264解码器的结构；从这篇文章开始，具体研究H.264解码器的源代码。本文分析H.264解码器中解析器（Parser）部分的源代码。这部分的代码用于分割H.264的NALU，并且解析SPS、PPS、SEI等信息。解析H.264码流（对应AVCodecParser结构体中的函数）和解码H.264码流（对应AVCodec结构体中的函数）的时候都会调用该部分的代码完成相应的功能。</p> 
<br> 
<h3>函数调用关系图</h3> 
<p>解析器（Parser）部分的源代码在整个H.264解码器中的位置如下图所示。</p> 
<p style="text-align: center;"><a target="_blank" href="https://img-my.csdn.net/uploads/201504/04/1428080288_9350.jpg" rel="nofollow noopener noreferrer"><img src="https://images2.imgbox.com/fe/2a/F9OwaNXy_o.jpg" alt=""></a><br></p> 
<p style="text-align: center;"><a target="_blank" href="https://my.csdn.net/leixiaohua1020/album/detail/1806347" rel="nofollow noopener noreferrer">单击查看更清晰的图片</a></p> 
<p style="text-align: center;"><br></p> 
<p>解析器（Parser）部分的源代码的调用关系如下图所示。</p> 
<p style="text-align: center;"><a target="_blank" href="https://img-my.csdn.net/uploads/201504/12/1428770475_6759.jpg" rel="nofollow noopener noreferrer"><img src="https://images2.imgbox.com/f8/4a/Fa6CpXbb_o.jpg" alt=""></a><br></p> 
<p style="text-align: center;"><a target="_blank" href="https://my.csdn.net/leixiaohua1020/album/detail/1806771" rel="nofollow noopener noreferrer">单击查看更清晰的图片</a><br></p>从图中可以看出，H.264的解析器（Parser）在解析数据的时候调用h264_parse()，h264_parse()调用了parse_nal_units()，parse_nal_units()则调用了一系列解析特定NALU的函数。H.264的解码器（Decoder）在解码数据的时候调用h264_decode_frame()，h264_decode_frame()调用了decode_nal_units()，decode_nal_units()也同样调用了一系列解析不同NALU的函数。 
<br>图中简单列举了几个解析特定NALU的函数： 
<br> 
<blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
  ff_h264_decode_nal()：解析NALU Header 
 <br>ff_h264_decode_seq_parameter_set()：解析SPS 
 <br>ff_h264_decode_picture_parameter_set()：解析PPS 
 <br>ff_h264_decode_sei()：解析SEI 
</blockquote>H.264解码器与H.264解析器最主要的不同的地方在于它调用了ff_h264_execute_decode_slices()函数进行了解码工作。这篇文章只分析H.264解析器的源代码，至于H.264解码器的源代码，则在后面几篇文章中再进行分析。 
<br> 
<br> 
<h3>ff_h264_decoder</h3>ff_h264_decoder是FFmpeg的H.264解码器对应的AVCodec结构体。它的定义位于libavcodec\h264.c，如下所示。 
<br> 
<pre><code class="language-cpp">AVCodec ff_h264_decoder = {
    .name                  = "h264",
    .long_name             = NULL_IF_CONFIG_SMALL("H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10"),
    .type                  = AVMEDIA_TYPE_VIDEO,
    .id                    = AV_CODEC_ID_H264,
    .priv_data_size        = sizeof(H264Context),
    .init                  = ff_h264_decode_init,
    .close                 = h264_decode_end,
    .decode                = h264_decode_frame,
    .capabilities          = /*CODEC_CAP_DRAW_HORIZ_BAND |*/ CODEC_CAP_DR1 |
                             CODEC_CAP_DELAY | CODEC_CAP_SLICE_THREADS |
                             CODEC_CAP_FRAME_THREADS,
    .flush                 = flush_dpb,
    .init_thread_copy      = ONLY_IF_THREADS_ENABLED(decode_init_thread_copy),
    .update_thread_context = ONLY_IF_THREADS_ENABLED(ff_h264_update_thread_context),
    .profiles              = NULL_IF_CONFIG_SMALL(profiles),
    .priv_class            = &amp;h264_class,
};</code></pre> 
<br>从ff_h264_decoder的定义可以看出：解码器初始化的函数指针init()指向ff_h264_decode_init()函数，解码的函数指针decode()指向h264_decode_frame()函数，解码器关闭的函数指针close()指向h264_decode_end()函数。 
<br>有关H.264解码器这方面的源代码在以后的文章中再进行详细的分析。在这里我们只需要知道h264_decode_frame()内部调用了decode_nal_units()，而decode_nal_units()调用了和H.264解析器（Parser）有关的源代码就可以了。 
<br> 
<br> 
<h3>ff_h264_parser</h3>ff_h264_parser是FFmpeg的H.264解析器对应的AVCodecParser结构体。它的定义位于libavcodec\h264_parser.c，如下所示。 
<br> 
<pre><code class="language-cpp">AVCodecParser ff_h264_parser = {
    .codec_ids      = { AV_CODEC_ID_H264 },
    .priv_data_size = sizeof(H264Context),
    .parser_init    = init,
    .parser_parse   = h264_parse,
    .parser_close   = close,
    .split          = h264_split,
};</code></pre> 
<br>从ff_h264_parser的定义可以看出：AVCodecParser初始化的函数指针parser_init()指向init()函数；解析数据的函数指针parser_parse()指向h264_parse()函数；销毁的函数指针parser_close()指向close()函数。下面分别看看这些函数。 
<br> 
<br> 
<h3>init() [对应于AVCodecParser-&gt; parser_init()]</h3>ff_h264_parser结构体中AVCodecParser的parser_init()指向init()函数。该函数完成了AVCodecParser的初始化工作。函数的定义很简单，如下所示。 
<br> 
<pre><code class="language-cpp">static av_cold int init(AVCodecParserContext *s)
{
    H264Context *h = s-&gt;priv_data;
    h-&gt;thread_context[0]   = h;
    h-&gt;slice_context_count = 1;
    ff_h264dsp_init(&amp;h-&gt;h264dsp, 8, 1);
    return 0;
}</code></pre> 
<br> 
<h3>close() [对应于AVCodecParser-&gt; parser_close()]</h3>ff_h264_parser结构体中AVCodecParser的parser_close()指向close()函数。该函数完成了AVCodecParser的关闭工作。函数的定义也比较简单，如下所示。 
<br> 
<pre><code class="language-cpp">static void close(AVCodecParserContext *s)
{
    H264Context *h   = s-&gt;priv_data;
    ParseContext *pc = &amp;h-&gt;parse_context;

    av_freep(&amp;pc-&gt;buffer);
    ff_h264_free_context(h);
}</code></pre> 
<br> 
<h3>h264_parse() [对应于AVCodecParser-&gt; parser_parse()]</h3>ff_h264_parser结构体中AVCodecParser的parser_parse()指向h264_parse()函数。该函数完成了AVCodecParser的解析工作（在这里就是H.264码流的解析工作）。h264_parse()的定义位于libavcodec\h264_parser.c，如下所示。 
<br> 
<pre><code class="language-cpp">//解析H.264码流
//输出一个完整的NAL，存储于poutbuf中
static int h264_parse(AVCodecParserContext *s,
                      AVCodecContext *avctx,
                      const uint8_t **poutbuf, int *poutbuf_size,
                      const uint8_t *buf, int buf_size)
{
    H264Context *h   = s-&gt;priv_data;
    ParseContext *pc = &amp;h-&gt;parse_context;
    int next;
    //如果还没有解析过1帧，就调用这里解析extradata
    if (!h-&gt;got_first) {
        h-&gt;got_first = 1;
        if (avctx-&gt;extradata_size) {
            h-&gt;avctx = avctx;
            // must be done like in decoder, otherwise opening the parser,
            // letting it create extradata and then closing and opening again
            // will cause has_b_frames to be always set.
            // Note that estimate_timings_from_pts does exactly this.
            if (!avctx-&gt;has_b_frames)
                h-&gt;low_delay = 1;
            //解析AVCodecContext的extradata
            ff_h264_decode_extradata(h, avctx-&gt;extradata, avctx-&gt;extradata_size);
        }
    }
    //输入的数据是完整的一帧？
    //这里通过设置flags的PARSER_FLAG_COMPLETE_FRAMES来确定
    if (s-&gt;flags &amp; PARSER_FLAG_COMPLETE_FRAMES) {
    	//和缓存大小一样
        next = buf_size;
    } else {
    	//查找帧结尾（帧开始）位置
    	//以“起始码”为依据（0x000001或0x00000001）
        next = h264_find_frame_end(h, buf, buf_size);
        //组帧
        if (ff_combine_frame(pc, next, &amp;buf, &amp;buf_size) &lt; 0) {
            *poutbuf      = NULL;
            *poutbuf_size = 0;
            return buf_size;
        }

        if (next &lt; 0 &amp;&amp; next != END_NOT_FOUND) {
            av_assert1(pc-&gt;last_index + next &gt;= 0);
            h264_find_frame_end(h, &amp;pc-&gt;buffer[pc-&gt;last_index + next], -next); // update state
        }
    }
    //解析NALU，从SPS、PPS、SEI等中获得一些基本信息。
    //此时buf中存储的是完整的1帧数据
    parse_nal_units(s, avctx, buf, buf_size);

    if (avctx-&gt;framerate.num)
        avctx-&gt;time_base = av_inv_q(av_mul_q(avctx-&gt;framerate, (AVRational){avctx-&gt;ticks_per_frame, 1}));
    if (h-&gt;sei_cpb_removal_delay &gt;= 0) {
        s-&gt;dts_sync_point    = h-&gt;sei_buffering_period_present;
        s-&gt;dts_ref_dts_delta = h-&gt;sei_cpb_removal_delay;
        s-&gt;pts_dts_delta     = h-&gt;sei_dpb_output_delay;
    } else {
        s-&gt;dts_sync_point    = INT_MIN;
        s-&gt;dts_ref_dts_delta = INT_MIN;
        s-&gt;pts_dts_delta     = INT_MIN;
    }

    if (s-&gt;flags &amp; PARSER_FLAG_ONCE) {
        s-&gt;flags &amp;= PARSER_FLAG_COMPLETE_FRAMES;
    }
    //分割后的帧数据输出至poutbuf
    *poutbuf      = buf;
    *poutbuf_size = buf_size;
    return next;
}
</code></pre> 
<br>从源代码可以看出，h264_parse()主要完成了以下3步工作： 
<br> 
<blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
  （1）如果是第一次解析，则首先调用ff_h264_decode_extradata()解析AVCodecContext的extradata（里面实际上存储了H.264的SPS、PPS）。 
 <br>（2）如果传入的flags 中包含PARSER_FLAG_COMPLETE_FRAMES，则说明传入的是完整的一帧数据，不作任何处理；如果不包含PARSER_FLAG_COMPLETE_FRAMES，则说明传入的不是完整的一帧数据而是任意一段H.264数据，则需要调用h264_find_frame_end()通过查找“起始码”（0x00000001或者0x000001）的方法，分离出完整的一帧数据。 
 <br> 
 <p>（3）调用parse_nal_units()完成了NALU的解析工作。</p> 
</blockquote>下面分别看一下这3步中涉及到的函数：ff_h264_decode_extradata()，h264_find_frame_end()，parse_nal_units()。 
<br> 
<br> 
<h3>ff_h264_decode_extradata()</h3>ff_h264_decode_extradata()用于解析AVCodecContext的extradata（里面实际上存储了H.264的SPS、PPS）。ff_h264_decode_extradata()的定义如下所示。 
<br> 
<pre><code class="language-cpp">//解析extradata
//最常见的就是解析AVCodecContext的extradata。其中extradata实际上存储的就是SPS、PPS
int ff_h264_decode_extradata(H264Context *h, const uint8_t *buf, int size)
{
    AVCodecContext *avctx = h-&gt;avctx;
    int ret;

    if (!buf || size &lt;= 0)
        return -1;

    if (buf[0] == 1) {
        int i, cnt, nalsize;
        const unsigned char *p = buf;

        //AVC1 描述:H.264 bitstream without start codes.是不带起始码0×00000001的。MKV/MOV/FLV中的H.264属于这种类型
        //H264 描述:H.264 bitstream with start codes.是带有起始码0×00000001的。MPEGTS中的H.264，或者H.264裸流属于这种类型
        h-&gt;is_avc = 1;
        //数据量太小
        //随意测了一个视频
        //SPS: 30 Byte
        //PPS: 6 Byte
        if (size &lt; 7) {
            av_log(avctx, AV_LOG_ERROR,
                   "avcC %d too short\n", size);
            return AVERROR_INVALIDDATA;
        }
        /* sps and pps in the avcC always have length coded with 2 bytes,
         * so put a fake nal_length_size = 2 while parsing them */
        h-&gt;nal_length_size = 2;
        // Decode sps from avcC
        //解码SPS
        cnt = *(p + 5) &amp; 0x1f; // Number of sps
        p  += 6;
        for (i = 0; i &lt; cnt; i++) {
            nalsize = AV_RB16(p) + 2;
            if(nalsize &gt; size - (p-buf))
                return AVERROR_INVALIDDATA;
            //解析
            ret = decode_nal_units(h, p, nalsize, 1);
            if (ret &lt; 0) {
                av_log(avctx, AV_LOG_ERROR,
                       "Decoding sps %d from avcC failed\n", i);
                return ret;
            }
            p += nalsize;
        }
        // Decode pps from avcC
        //解码PPS
        cnt = *(p++); // Number of pps
        for (i = 0; i &lt; cnt; i++) {
            nalsize = AV_RB16(p) + 2;
            if(nalsize &gt; size - (p-buf))
                return AVERROR_INVALIDDATA;
            ret = decode_nal_units(h, p, nalsize, 1);
            if (ret &lt; 0) {
                av_log(avctx, AV_LOG_ERROR,
                       "Decoding pps %d from avcC failed\n", i);
                return ret;
            }
            p += nalsize;
        }
        // Store right nal length size that will be used to parse all other nals
        h-&gt;nal_length_size = (buf[4] &amp; 0x03) + 1;
    } else {
        h-&gt;is_avc = 0;
        //解析
        ret = decode_nal_units(h, buf, size, 1);
        if (ret &lt; 0)
            return ret;
    }
    return size;
}
</code></pre> 
<br>从源代码中可以看出，ff_h264_decode_extradata()调用decode_nal_units()解析SPS、PPS信息。有关decode_nal_units()的源代码在后续文章中再进行分析。 
<br> 
<br> 
<h3>h264_find_frame_end()</h3>h264_find_frame_end()用于查找H.264码流中的“起始码”（start code）。在H.264码流中有两种起始码：0x000001和0x00000001。其中4Byte的长度的起始码最为常见。只有当一个完整的帧被编为多个slice的时候，包含这些slice的NALU才会使用3Byte的起始码。h264_find_frame_end()的定义位于libavcodec\h264_parser.c，如下所示。 
<br> 
<pre><code class="language-cpp">//查找帧结尾（帧开始）位置
//
//几种状态state：
//2 - 找到1个0
//1 - 找到2个0
//0 - 找到大于等于3个0
//4 - 找到2个0和1个1，即001（即找到了起始码）
//5 - 找到至少3个0和1个1，即0001等等（即找到了起始码）
//7 - 初始化状态
//&gt;=8 - 找到2个Slice Header
//
//关于起始码startcode的两种形式：3字节的0x000001和4字节的0x00000001
//3字节的0x000001只有一种场合下使用，就是一个完整的帧被编为多个slice的时候，
//包含这些slice的nalu使用3字节起始码。其余场合都是4字节的。
//
static int h264_find_frame_end(H264Context *h, const uint8_t *buf,
                               int buf_size)
{
    int i, j;
    uint32_t state;
    ParseContext *pc = &amp;h-&gt;parse_context;
    int next_avc= h-&gt;is_avc ? 0 : buf_size;

//    mb_addr= pc-&gt;mb_addr - 1;
    state = pc-&gt;state;
    if (state &gt; 13)
        state = 7;

    if (h-&gt;is_avc &amp;&amp; !h-&gt;nal_length_size)
        av_log(h-&gt;avctx, AV_LOG_ERROR, "AVC-parser: nal length size invalid\n");
    //
    //每次循环前进1个字节，读取该字节的值
    //根据此前的状态state做不同的处理
    //state取值为4,5代表找到了起始码
    //类似于一个状态机，简单画一下状态转移图：
    //                            +-----+
    //                            |     |
    //                            v     |
    // 7--(0)--&gt;2--(0)--&gt;1--(0)--&gt;0-(0)-+
    // ^        |        |        |
    // |       (1)      (1)      (1)
    // |        |        |        |
    // +--------+        v        v
    //                   4        5
    //
    for (i = 0; i &lt; buf_size; i++) {
    	//超过了
        if (i &gt;= next_avc) {
            int nalsize = 0;
            i = next_avc;
            for (j = 0; j &lt; h-&gt;nal_length_size; j++)
                nalsize = (nalsize &lt;&lt; 8) | buf[i++];
            if (nalsize &lt;= 0 || nalsize &gt; buf_size - i) {
                av_log(h-&gt;avctx, AV_LOG_ERROR, "AVC-parser: nal size %d remaining %d\n", nalsize, buf_size - i);
                return buf_size;
            }
            next_avc = i + nalsize;
            state    = 5;
        }
        //初始state为7
        if (state == 7) {
        	//查找startcode的候选者？
        	//从一段内存中查找取值为0的元素的位置并返回
        	//增加i取值
            i += h-&gt;h264dsp.startcode_find_candidate(buf + i, next_avc - i);
            //因为找到1个0，状态转换为2
            if (i &lt; next_avc)
                state = 2;
        } else if (state &lt;= 2) {       //找到0时候的state。包括1个0（状态2），2个0（状态1），或者3个及3个以上0（状态0）。
            if (buf[i] == 1)           //发现了一个1
                state ^= 5;            //状态转换关系：2-&gt;7, 1-&gt;4, 0-&gt;5。状态4代表找到了001，状态5代表找到了0001
            else if (buf[i])
                state = 7;             //恢复初始
            else                       //发现了一个0
                state &gt;&gt;= 1;           // 2-&gt;1, 1-&gt;0, 0-&gt;0
        } else if (state &lt;= 5) {
        	//状态4代表找到了001，状态5代表找到了0001
        	//获取NALU类型
        	//NALU Header（1Byte）的后5bit
            int nalu_type = buf[i] &amp; 0x1F;

            if (nalu_type == NAL_SEI || nalu_type == NAL_SPS ||
                nalu_type == NAL_PPS || nalu_type == NAL_AUD) {
                //SPS，PPS，SEI类型的NALU
                if (pc-&gt;frame_start_found) {    //如果之前已找到了帧头
                    i++;
                    goto found;
                }
            } else if (nalu_type == NAL_SLICE || nalu_type == NAL_DPA ||
                       nalu_type == NAL_IDR_SLICE) {
            	//表示有slice header的NALU
            	//大于等于8的状态表示找到了两个帧头，但没有找到帧尾的状态
                state += 8;
                continue;
            }
            //上述两个条件都不满足，回归初始状态（state取值7）
            state = 7;
        } else {
            h-&gt;parse_history[h-&gt;parse_history_count++]= buf[i];
            if (h-&gt;parse_history_count&gt;5) {
                unsigned int mb, last_mb= h-&gt;parse_last_mb;
                GetBitContext gb;

                init_get_bits(&amp;gb, h-&gt;parse_history, 8*h-&gt;parse_history_count);
                h-&gt;parse_history_count=0;
                mb= get_ue_golomb_long(&amp;gb);
                h-&gt;parse_last_mb= mb;
                if (pc-&gt;frame_start_found) {
                    if (mb &lt;= last_mb)
                        goto found;
                } else
                    pc-&gt;frame_start_found = 1;
                state = 7;
            }
        }
    }
    pc-&gt;state = state;
    if (h-&gt;is_avc)
        return next_avc;
    //没找到
    return END_NOT_FOUND;

found:
    pc-&gt;state             = 7;
    pc-&gt;frame_start_found = 0;
    if (h-&gt;is_avc)
        return next_avc;
    //state=4时候，state &amp; 5=4
    //找到的是001（长度为3），i减小3+1=4，标识帧结尾
    //state=5时候，state &amp; 5=5
    //找到的是0001（长度为4），i减小4+1=5，标识帧结尾
    return i - (state &amp; 5) - 5 * (state &gt; 7);
}
</code></pre> 
<br>从源代码可以看出，h264_find_frame_end()使用了一种类似于状态机的方式查找起始码。函数中的for()循环每执行一遍，状态机的状态就会改变一次。该状态机主要包含以下几种状态： 
<br> 
<blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
  7 - 初始化状态 
 <br>2 - 找到1个0 
 <br>1 - 找到2个0 
 <br>0 - 找到大于等于3个0 
 <br>4 - 找到2个0和1个1，即001（即找到了起始码） 
 <br>5 - 找到至少3个0和1个1，即0001等等（即找到了起始码） 
 <br>&gt;=8 - 找到2个Slice Header 
</blockquote> 
<p>这些状态之间的状态转移图如下所示。图中粉红色代表初始状态，绿色代表找到“起始码”的状态。</p> 
<p style="text-align: center;"><img src="https://images2.imgbox.com/0d/2a/YWHZBuTy_o.png" alt=""><br></p> 
<p><span style="white-space:pre"> </span>如图所示，h264_find_frame_end()初始化时候位于状态“7”；当找到1个“0”之后，状态从“7”变为“2”；在状态“2”下，如果再次找到1个“0”，则状态变为“1”；在状态“1”下，如果找到“1”，则状态变换为“4”，表明找到了“0x000001”起始码；在状态“1”下，如果找到“0”，则状态变换为“0”；在状态“0”下，如果找到“1”，则状态变换为“5” ，表明找到了“0x000001”起始码。</p> 
<p><br></p> 
<strong>startcode_find_candidate()</strong> 
<br> 
<span style="white-space:pre"> </span>其中，在查找数据中第1个“0”的时候，使用了H264DSPContext结构体中的startcode_find_candidate()函数。startcode_find_candidate()除了包含C语言版本的函数外，还包含了ARMV6等平台下经过汇编优化的函数（估计效率会比C语言版本函数高一些）。C语言版本的函数ff_startcode_find_candidate_c()的定义很简单，位于libavcodec\startcode.c，如下所示。 
<br> 
<pre><code class="language-cpp">int ff_startcode_find_candidate_c(const uint8_t *buf, int size)
{
    int i = 0;
    for (; i &lt; size; i++)
        if (!buf[i])
            break;
    return i;
}</code></pre> 
<br> 
<h3>parse_nal_units()</h3>parse_nal_units()用于解析NALU，从SPS、PPS、SEI等中获得一些基本信息。在该函数中，根据NALU的不同，分别调用不同的函数进行具体的处理。parse_nal_units()的定义位于libavcodec\h264_parser.c，如下所示。 
<br> 
<pre><code class="language-cpp">/**
 * Parse NAL units of found picture and decode some basic information.
 *
 * @param s parser context.
 * @param avctx codec context.
 * @param buf buffer with field/frame data.
 * @param buf_size size of the buffer.
 */
//解析NALU，从SPS、PPS、SEI等中获得一些基本信息。
static inline int parse_nal_units(AVCodecParserContext *s,
                                  AVCodecContext *avctx,
                                  const uint8_t * const buf, int buf_size)
{
    H264Context *h         = s-&gt;priv_data;
    int buf_index, next_avc;
    unsigned int pps_id;
    unsigned int slice_type;
    int state = -1, got_reset = 0;
    const uint8_t *ptr;
    int q264 = buf_size &gt;=4 &amp;&amp; !memcmp("Q264", buf, 4);
    int field_poc[2];

    /* set some sane default values */
    s-&gt;pict_type         = AV_PICTURE_TYPE_I;
    s-&gt;key_frame         = 0;
    s-&gt;picture_structure = AV_PICTURE_STRUCTURE_UNKNOWN;

    h-&gt;avctx = avctx;
    ff_h264_reset_sei(h);
    h-&gt;sei_fpa.frame_packing_arrangement_cancel_flag = -1;

    if (!buf_size)
        return 0;

    buf_index     = 0;
    next_avc      = h-&gt;is_avc ? 0 : buf_size;
    for (;;) {
        int src_length, dst_length, consumed, nalsize = 0;

        if (buf_index &gt;= next_avc) {
            nalsize = get_avc_nalsize(h, buf, buf_size, &amp;buf_index);
            if (nalsize &lt; 0)
                break;
            next_avc = buf_index + nalsize;
        } else {
            buf_index = find_start_code(buf, buf_size, buf_index, next_avc);
            if (buf_index &gt;= buf_size)
                break;
            if (buf_index &gt;= next_avc)
                continue;
        }
        src_length = next_avc - buf_index;
        //NALU Header (1 Byte)
        state = buf[buf_index];
        switch (state &amp; 0x1f) {
        case NAL_SLICE:
        case NAL_IDR_SLICE:
            // Do not walk the whole buffer just to decode slice header
            if ((state &amp; 0x1f) == NAL_IDR_SLICE || ((state &gt;&gt; 5) &amp; 0x3) == 0) {
                /* IDR or disposable slice
                 * No need to decode many bytes because MMCOs shall not be present. */
                if (src_length &gt; 60)
                    src_length = 60;
            } else {
                /* To decode up to MMCOs */
                if (src_length &gt; 1000)
                    src_length = 1000;
            }
            break;
        }
        //解析NAL Header，获得nal_unit_type等信息
        ptr = ff_h264_decode_nal(h, buf + buf_index, &amp;dst_length,
                                 &amp;consumed, src_length);
        if (!ptr || dst_length &lt; 0)
            break;

        buf_index += consumed;
        //初始化GetBitContext
        //H264Context-&gt;gb
        //后面的解析都是从这里获取数据
        init_get_bits(&amp;h-&gt;gb, ptr, 8 * dst_length);
        switch (h-&gt;nal_unit_type) {
        case NAL_SPS:
        	//解析SPS
            ff_h264_decode_seq_parameter_set(h);
            break;
        case NAL_PPS:
        	//解析PPS
            ff_h264_decode_picture_parameter_set(h, h-&gt;gb.size_in_bits);
            break;
        case NAL_SEI:
        	//解析SEI
            ff_h264_decode_sei(h);
            break;
        case NAL_IDR_SLICE:
        	//如果是IDR Slice
        	//赋值AVCodecParserContext的key_frame为1
            s-&gt;key_frame = 1;

            h-&gt;prev_frame_num        = 0;
            h-&gt;prev_frame_num_offset = 0;
            h-&gt;prev_poc_msb          =
            h-&gt;prev_poc_lsb          = 0;
        /* fall through */
        case NAL_SLICE:
        	//获取Slice的一些信息
        	//跳过first_mb_in_slice这一字段
            get_ue_golomb_long(&amp;h-&gt;gb);  // skip first_mb_in_slice
            //获取帧类型（I,B,P）
            slice_type   = get_ue_golomb_31(&amp;h-&gt;gb);
            //赋值到AVCodecParserContext的pict_type（外部可以访问到）
            s-&gt;pict_type = golomb_to_pict_type[slice_type % 5];
            //关键帧
            if (h-&gt;sei_recovery_frame_cnt &gt;= 0) {
                /* key frame, since recovery_frame_cnt is set */
            	//赋值AVCodecParserContext的key_frame为1
                s-&gt;key_frame = 1;
            }
            //获取 PPS ID
            pps_id = get_ue_golomb(&amp;h-&gt;gb);
            if (pps_id &gt;= MAX_PPS_COUNT) {
                av_log(h-&gt;avctx, AV_LOG_ERROR,
                       "pps_id %u out of range\n", pps_id);
                return -1;
            }
            if (!h-&gt;pps_buffers[pps_id]) {
                av_log(h-&gt;avctx, AV_LOG_ERROR,
                       "non-existing PPS %u referenced\n", pps_id);
                return -1;
            }
            h-&gt;pps = *h-&gt;pps_buffers[pps_id];
            if (!h-&gt;sps_buffers[h-&gt;pps.sps_id]) {
                av_log(h-&gt;avctx, AV_LOG_ERROR,
                       "non-existing SPS %u referenced\n", h-&gt;pps.sps_id);
                return -1;
            }
            h-&gt;sps       = *h-&gt;sps_buffers[h-&gt;pps.sps_id];
            h-&gt;frame_num = get_bits(&amp;h-&gt;gb, h-&gt;sps.log2_max_frame_num);

            if(h-&gt;sps.ref_frame_count &lt;= 1 &amp;&amp; h-&gt;pps.ref_count[0] &lt;= 1 &amp;&amp; s-&gt;pict_type == AV_PICTURE_TYPE_I)
                s-&gt;key_frame = 1;
            //获得“型”和“级”
            //赋值到AVCodecContext的profile和level
            avctx-&gt;profile = ff_h264_get_profile(&amp;h-&gt;sps);
            avctx-&gt;level   = h-&gt;sps.level_idc;

            if (h-&gt;sps.frame_mbs_only_flag) {
                h-&gt;picture_structure = PICT_FRAME;
            } else {
                if (get_bits1(&amp;h-&gt;gb)) { // field_pic_flag
                    h-&gt;picture_structure = PICT_TOP_FIELD + get_bits1(&amp;h-&gt;gb); // bottom_field_flag
                } else {
                    h-&gt;picture_structure = PICT_FRAME;
                }
            }

            if (h-&gt;nal_unit_type == NAL_IDR_SLICE)
                get_ue_golomb(&amp;h-&gt;gb); /* idr_pic_id */
            if (h-&gt;sps.poc_type == 0) {
                h-&gt;poc_lsb = get_bits(&amp;h-&gt;gb, h-&gt;sps.log2_max_poc_lsb);

                if (h-&gt;pps.pic_order_present == 1 &amp;&amp;
                    h-&gt;picture_structure == PICT_FRAME)
                    h-&gt;delta_poc_bottom = get_se_golomb(&amp;h-&gt;gb);
            }

            if (h-&gt;sps.poc_type == 1 &amp;&amp;
                !h-&gt;sps.delta_pic_order_always_zero_flag) {
                h-&gt;delta_poc[0] = get_se_golomb(&amp;h-&gt;gb);

                if (h-&gt;pps.pic_order_present == 1 &amp;&amp;
                    h-&gt;picture_structure == PICT_FRAME)
                    h-&gt;delta_poc[1] = get_se_golomb(&amp;h-&gt;gb);
            }

            /* Decode POC of this picture.
             * The prev_ values needed for decoding POC of the next picture are not set here. */
            field_poc[0] = field_poc[1] = INT_MAX;
            ff_init_poc(h, field_poc, &amp;s-&gt;output_picture_number);

            /* Continue parsing to check if MMCO_RESET is present.
             * FIXME: MMCO_RESET could appear in non-first slice.
             *        Maybe, we should parse all undisposable non-IDR slice of this
             *        picture until encountering MMCO_RESET in a slice of it. */
            if (h-&gt;nal_ref_idc &amp;&amp; h-&gt;nal_unit_type != NAL_IDR_SLICE) {
                got_reset = scan_mmco_reset(s);
                if (got_reset &lt; 0)
                    return got_reset;
            }

            /* Set up the prev_ values for decoding POC of the next picture. */
            h-&gt;prev_frame_num        = got_reset ? 0 : h-&gt;frame_num;
            h-&gt;prev_frame_num_offset = got_reset ? 0 : h-&gt;frame_num_offset;
            if (h-&gt;nal_ref_idc != 0) {
                if (!got_reset) {
                    h-&gt;prev_poc_msb = h-&gt;poc_msb;
                    h-&gt;prev_poc_lsb = h-&gt;poc_lsb;
                } else {
                    h-&gt;prev_poc_msb = 0;
                    h-&gt;prev_poc_lsb =
                        h-&gt;picture_structure == PICT_BOTTOM_FIELD ? 0 : field_poc[0];
                }
            }
            //包含“场”概念的时候，先不管
            if (h-&gt;sps.pic_struct_present_flag) {
                switch (h-&gt;sei_pic_struct) {
                case SEI_PIC_STRUCT_TOP_FIELD:
                case SEI_PIC_STRUCT_BOTTOM_FIELD:
                    s-&gt;repeat_pict = 0;
                    break;
                case SEI_PIC_STRUCT_FRAME:
                case SEI_PIC_STRUCT_TOP_BOTTOM:
                case SEI_PIC_STRUCT_BOTTOM_TOP:
                    s-&gt;repeat_pict = 1;
                    break;
                case SEI_PIC_STRUCT_TOP_BOTTOM_TOP:
                case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:
                    s-&gt;repeat_pict = 2;
                    break;
                case SEI_PIC_STRUCT_FRAME_DOUBLING:
                    s-&gt;repeat_pict = 3;
                    break;
                case SEI_PIC_STRUCT_FRAME_TRIPLING:
                    s-&gt;repeat_pict = 5;
                    break;
                default:
                    s-&gt;repeat_pict = h-&gt;picture_structure == PICT_FRAME ? 1 : 0;
                    break;
                }
            } else {
                s-&gt;repeat_pict = h-&gt;picture_structure == PICT_FRAME ? 1 : 0;
            }

            if (h-&gt;picture_structure == PICT_FRAME) {
                s-&gt;picture_structure = AV_PICTURE_STRUCTURE_FRAME;
                if (h-&gt;sps.pic_struct_present_flag) {
                    switch (h-&gt;sei_pic_struct) {
                    case SEI_PIC_STRUCT_TOP_BOTTOM:
                    case SEI_PIC_STRUCT_TOP_BOTTOM_TOP:
                        s-&gt;field_order = AV_FIELD_TT;
                        break;
                    case SEI_PIC_STRUCT_BOTTOM_TOP:
                    case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:
                        s-&gt;field_order = AV_FIELD_BB;
                        break;
                    default:
                        s-&gt;field_order = AV_FIELD_PROGRESSIVE;
                        break;
                    }
                } else {
                    if (field_poc[0] &lt; field_poc[1])
                        s-&gt;field_order = AV_FIELD_TT;
                    else if (field_poc[0] &gt; field_poc[1])
                        s-&gt;field_order = AV_FIELD_BB;
                    else
                        s-&gt;field_order = AV_FIELD_PROGRESSIVE;
                }
            } else {
                if (h-&gt;picture_structure == PICT_TOP_FIELD)
                    s-&gt;picture_structure = AV_PICTURE_STRUCTURE_TOP_FIELD;
                else
                    s-&gt;picture_structure = AV_PICTURE_STRUCTURE_BOTTOM_FIELD;
                s-&gt;field_order = AV_FIELD_UNKNOWN;
            }

            return 0; /* no need to evaluate the rest */
        }
    }
    if (q264)
        return 0;
    /* didn't find a picture! */
    av_log(h-&gt;avctx, AV_LOG_ERROR, "missing picture in access unit with size %d\n", buf_size);
    return -1;
}
</code></pre> 
<br>从源代码可以看出，parse_nal_units()主要做了以下几步处理： 
<br> 
<blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
  （1）对于所有的NALU，都调用ff_h264_decode_nal解析NALU的Header，得到nal_unit_type等信息 
 <br>（2）根据nal_unit_type的不同，调用不同的解析函数进行处理。例如： 
 <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
   a)解析SPS的时候调用ff_h264_decode_seq_parameter_set() 
 </blockquote> 
 <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
   b)解析PPS的时候调用ff_h264_decode_picture_parameter_set() 
 </blockquote> 
 <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
   c)解析SEI的时候调用ff_h264_decode_sei() 
 </blockquote> 
 <blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
   d)解析IDR Slice / Slice的时候，获取slice_type等一些信息。 
 </blockquote> 
</blockquote> 
<br> 
<h3>ff_h264_decode_nal()</h3>ff_h264_decode_nal()用于解析NAL Header，获得nal_unit_type等信息。该函数的定义位于libavcodec\h264.c，如下所示。 
<br> 
<pre><code class="language-cpp">//解析NAL Header，获得nal_unit_type等信息
const uint8_t *ff_h264_decode_nal(H264Context *h, const uint8_t *src,
                                  int *dst_length, int *consumed, int length)
{
    int i, si, di;
    uint8_t *dst;
    int bufidx;

    // src[0]&amp;0x80; // forbidden bit
    //
    // 1 byte NALU头
    // forbidden_zero_bit: 1bit
    // nal_ref_idc: 2bit
    // nal_unit_type: 5bit
    // nal_ref_idc指示NAL的优先级，取值0-3，值越高，代表NAL越重要
    h-&gt;nal_ref_idc   = src[0] &gt;&gt; 5;
    // nal_unit_type指示NAL的类型
    h-&gt;nal_unit_type = src[0] &amp; 0x1F;
    //后移1Byte
    src++;
    //未处理数据长度减1
    length--;

    //起始码:0x000001
    //保留:0x000002
    //防止竞争:0x000003
    //既表示NALU的开始，又表示NALU的结束
    //STARTCODE_TEST这个宏在后面用到
    //得到length
    //length是指当前NALU单元长度，这里不包括nalu头信息长度（即1个字节）
#define STARTCODE_TEST                                                  \
    if (i + 2 &lt; length &amp;&amp; src[i + 1] == 0 &amp;&amp; src[i + 2] &lt;= 3) {         \
        if (src[i + 2] != 3 &amp;&amp; src[i + 2] != 0) {                       \
            /* 取值为1或者2（保留用），为起始码。startcode, so we must be past the end */\
            length = i;                                                 \
        }                                                               \
        break;                                                          \
    }

#if HAVE_FAST_UNALIGNED
#define FIND_FIRST_ZERO                                                 \
    if (i &gt; 0 &amp;&amp; !src[i])                                               \
        i--;                                                            \
    while (src[i])                                                      \
        i++

#if HAVE_FAST_64BIT
    for (i = 0; i + 1 &lt; length; i += 9) {
        if (!((~AV_RN64A(src + i) &amp;
               (AV_RN64A(src + i) - 0x0100010001000101ULL)) &amp;
              0x8000800080008080ULL))
            continue;
        FIND_FIRST_ZERO;
        STARTCODE_TEST;
        i -= 7;
    }
#else
    for (i = 0; i + 1 &lt; length; i += 5) {
        if (!((~AV_RN32A(src + i) &amp;
               (AV_RN32A(src + i) - 0x01000101U)) &amp;
              0x80008080U))
            continue;
        FIND_FIRST_ZERO;
        STARTCODE_TEST;
        i -= 3;
    }
#endif
#else
    for (i = 0; i + 1 &lt; length; i += 2) {
        if (src[i])
            continue;
        if (i &gt; 0 &amp;&amp; src[i - 1] == 0)
            i--;
        //起始码检测
        STARTCODE_TEST;
    }
#endif

    // use second escape buffer for inter data
    bufidx = h-&gt;nal_unit_type == NAL_DPC ? 1 : 0;

    av_fast_padded_malloc(&amp;h-&gt;rbsp_buffer[bufidx], &amp;h-&gt;rbsp_buffer_size[bufidx], length+MAX_MBPAIR_SIZE);
    dst = h-&gt;rbsp_buffer[bufidx];

    if (!dst)
        return NULL;

    if(i&gt;=length-1){ //no escaped 0
        *dst_length= length;
        *consumed= length+1; //+1 for the header
        if(h-&gt;avctx-&gt;flags2 &amp; CODEC_FLAG2_FAST){
            return src;
        }else{
            memcpy(dst, src, length);
            return dst;
        }
    }

    memcpy(dst, src, i);
    si = di = i;
    while (si + 2 &lt; length) {
        // remove escapes (very rare 1:2^22)
        if (src[si + 2] &gt; 3) {
            dst[di++] = src[si++];
            dst[di++] = src[si++];
        } else if (src[si] == 0 &amp;&amp; src[si + 1] == 0 &amp;&amp; src[si + 2] != 0) {
            if (src[si + 2] == 3) { // escape
                dst[di++]  = 0;
                dst[di++]  = 0;
                si        += 3;
                continue;
            } else // next start code
                goto nsc;
        }

        dst[di++] = src[si++];
    }
    while (si &lt; length)
        dst[di++] = src[si++];

nsc:
    memset(dst + di, 0, FF_INPUT_BUFFER_PADDING_SIZE);

    *dst_length = di;
    *consumed   = si + 1; // +1 for the header
    /* FIXME store exact number of bits in the getbitcontext
     * (it is needed for decoding) */
    return dst;
}
</code></pre> 
<br> 
<span style="white-space:pre"> </span>从源代码可以看出，ff_h264_decode_nal()首先从NALU Header（NALU第1个字节）中解析出了nal_ref_idc，nal_unit_type字段的值。然后函数进入了一个for()循环进行起始码检测。 
<br> 
<span style="white-space:pre"> </span>起始码检测这里稍微有点复杂，其中包含了一个STARTCODE_TEST的宏。这个宏用于做具体的起始码的判断。这部分的代码还没有细看，以后有时间再进行补充。 
<br> 
<br> 
<br> 
<h3>ff_h264_decode_seq_parameter_set()</h3>ff_h264_decode_seq_parameter_set()用于解析H.264码流中的SPS。该函数的定义位于libavcodec\h264_ps.c，如下所示。 
<br> 
<pre><code class="language-cpp">//解码SPS
int ff_h264_decode_seq_parameter_set(H264Context *h)
{
    int profile_idc, level_idc, constraint_set_flags = 0;
    unsigned int sps_id;
    int i, log2_max_frame_num_minus4;

    SPS *sps;
    //profile型，8bit
    //注意get_bits()
    profile_idc           = get_bits(&amp;h-&gt;gb, 8);
    constraint_set_flags |= get_bits1(&amp;h-&gt;gb) &lt;&lt; 0;   // constraint_set0_flag
    constraint_set_flags |= get_bits1(&amp;h-&gt;gb) &lt;&lt; 1;   // constraint_set1_flag
    constraint_set_flags |= get_bits1(&amp;h-&gt;gb) &lt;&lt; 2;   // constraint_set2_flag
    constraint_set_flags |= get_bits1(&amp;h-&gt;gb) &lt;&lt; 3;   // constraint_set3_flag
    constraint_set_flags |= get_bits1(&amp;h-&gt;gb) &lt;&lt; 4;   // constraint_set4_flag
    constraint_set_flags |= get_bits1(&amp;h-&gt;gb) &lt;&lt; 5;   // constraint_set5_flag
    skip_bits(&amp;h-&gt;gb, 2);                             // reserved_zero_2bits
    //level级，8bit
    level_idc = get_bits(&amp;h-&gt;gb, 8);
    //该SPS的ID号，该ID号将被picture引用
    //注意：get_ue_golomb()
    sps_id    = get_ue_golomb_31(&amp;h-&gt;gb);

    if (sps_id &gt;= MAX_SPS_COUNT) {
        av_log(h-&gt;avctx, AV_LOG_ERROR, "sps_id %u out of range\n", sps_id);
        return AVERROR_INVALIDDATA;
    }
    //赋值给这个结构体
    sps = av_mallocz(sizeof(SPS));
    if (!sps)
        return AVERROR(ENOMEM);
    //赋值
    sps-&gt;sps_id               = sps_id;
    sps-&gt;time_offset_length   = 24;
    sps-&gt;profile_idc          = profile_idc;
    sps-&gt;constraint_set_flags = constraint_set_flags;
    sps-&gt;level_idc            = level_idc;
    sps-&gt;full_range           = -1;

    memset(sps-&gt;scaling_matrix4, 16, sizeof(sps-&gt;scaling_matrix4));
    memset(sps-&gt;scaling_matrix8, 16, sizeof(sps-&gt;scaling_matrix8));
    sps-&gt;scaling_matrix_present = 0;
    sps-&gt;colorspace = 2; //AVCOL_SPC_UNSPECIFIED
    //Profile对应关系
    if (sps-&gt;profile_idc == 100 ||  // High profile
        sps-&gt;profile_idc == 110 ||  // High10 profile
        sps-&gt;profile_idc == 122 ||  // High422 profile
        sps-&gt;profile_idc == 244 ||  // High444 Predictive profile
        sps-&gt;profile_idc ==  44 ||  // Cavlc444 profile
        sps-&gt;profile_idc ==  83 ||  // Scalable Constrained High profile (SVC)
        sps-&gt;profile_idc ==  86 ||  // Scalable High Intra profile (SVC)
        sps-&gt;profile_idc == 118 ||  // Stereo High profile (MVC)
        sps-&gt;profile_idc == 128 ||  // Multiview High profile (MVC)
        sps-&gt;profile_idc == 138 ||  // Multiview Depth High profile (MVCD)
        sps-&gt;profile_idc == 144) {  // old High444 profile

    	//色度取样
    	//0代表单色
    	//1代表4:2:0
    	//2代表4:2:2
    	//3代表4:4:4
        sps-&gt;chroma_format_idc = get_ue_golomb_31(&amp;h-&gt;gb);
        if (sps-&gt;chroma_format_idc &gt; 3U) {
            avpriv_request_sample(h-&gt;avctx, "chroma_format_idc %u",
                                  sps-&gt;chroma_format_idc);
            goto fail;
        } else if (sps-&gt;chroma_format_idc == 3) {
            sps-&gt;residual_color_transform_flag = get_bits1(&amp;h-&gt;gb);
            if (sps-&gt;residual_color_transform_flag) {
                av_log(h-&gt;avctx, AV_LOG_ERROR, "separate color planes are not supported\n");
                goto fail;
            }
        }
        //bit_depth_luma_minus8
        //加8之后为亮度颜色深度
        //该值取值范围应该在0到4之间。即颜色深度支持0-12bit
        sps-&gt;bit_depth_luma   = get_ue_golomb(&amp;h-&gt;gb) + 8;
        //加8之后为色度颜色深度
        sps-&gt;bit_depth_chroma = get_ue_golomb(&amp;h-&gt;gb) + 8;
        if (sps-&gt;bit_depth_chroma != sps-&gt;bit_depth_luma) {
            avpriv_request_sample(h-&gt;avctx,
                                  "Different chroma and luma bit depth");
            goto fail;
        }
        if (sps-&gt;bit_depth_luma &gt; 14U || sps-&gt;bit_depth_chroma &gt; 14U) {
            av_log(h-&gt;avctx, AV_LOG_ERROR, "illegal bit depth value (%d, %d)\n",
                   sps-&gt;bit_depth_luma, sps-&gt;bit_depth_chroma);
            goto fail;
        }
        sps-&gt;transform_bypass = get_bits1(&amp;h-&gt;gb);
        decode_scaling_matrices(h, sps, NULL, 1,
                                sps-&gt;scaling_matrix4, sps-&gt;scaling_matrix8);
    } else {
    	//默认
        sps-&gt;chroma_format_idc = 1;
        sps-&gt;bit_depth_luma    = 8;
        sps-&gt;bit_depth_chroma  = 8;
    }
    //log2_max_frame_num_minus4为另一个句法元素frame_num服务
    //fram_num的解码函数是ue（v），函数中的v 在这里指定：
    //     v = log2_max_frame_num_minus4 + 4
    //从另一个角度看，这个句法元素同时也指明了frame_num 的所能达到的最大值：
    //     MaxFrameNum = 2^( log2_max_frame_num_minus4 + 4 )
    log2_max_frame_num_minus4 = get_ue_golomb(&amp;h-&gt;gb);
    if (log2_max_frame_num_minus4 &lt; MIN_LOG2_MAX_FRAME_NUM - 4 ||
        log2_max_frame_num_minus4 &gt; MAX_LOG2_MAX_FRAME_NUM - 4) {
        av_log(h-&gt;avctx, AV_LOG_ERROR,
               "log2_max_frame_num_minus4 out of range (0-12): %d\n",
               log2_max_frame_num_minus4);
        goto fail;
    }
    sps-&gt;log2_max_frame_num = log2_max_frame_num_minus4 + 4;
    //pic_order_cnt_type 指明了poc (picture order count) 的编码方法
    //poc标识图像的播放顺序。
    //由于H.264使用了B帧预测，使得图像的解码顺序并不一定等于播放顺序，但它们之间存在一定的映射关系
    //poc 可以由frame-num 通过映射关系计算得来，也可以索性由编码器显式地传送。
    //H.264 中一共定义了三种poc 的编码方法
    sps-&gt;poc_type = get_ue_golomb_31(&amp;h-&gt;gb);
    //3种poc的编码方法
    if (sps-&gt;poc_type == 0) { // FIXME #define
        unsigned t = get_ue_golomb(&amp;h-&gt;gb);
        if (t&gt;12) {
            av_log(h-&gt;avctx, AV_LOG_ERROR, "log2_max_poc_lsb (%d) is out of range\n", t);
            goto fail;
        }
        sps-&gt;log2_max_poc_lsb = t + 4;
    } else if (sps-&gt;poc_type == 1) { // FIXME #define
        sps-&gt;delta_pic_order_always_zero_flag = get_bits1(&amp;h-&gt;gb);
        sps-&gt;offset_for_non_ref_pic           = get_se_golomb(&amp;h-&gt;gb);
        sps-&gt;offset_for_top_to_bottom_field   = get_se_golomb(&amp;h-&gt;gb);
        sps-&gt;poc_cycle_length                 = get_ue_golomb(&amp;h-&gt;gb);

        if ((unsigned)sps-&gt;poc_cycle_length &gt;=
            FF_ARRAY_ELEMS(sps-&gt;offset_for_ref_frame)) {
            av_log(h-&gt;avctx, AV_LOG_ERROR,
                   "poc_cycle_length overflow %d\n", sps-&gt;poc_cycle_length);
            goto fail;
        }

        for (i = 0; i &lt; sps-&gt;poc_cycle_length; i++)
            sps-&gt;offset_for_ref_frame[i] = get_se_golomb(&amp;h-&gt;gb);
    } else if (sps-&gt;poc_type != 2) {
        av_log(h-&gt;avctx, AV_LOG_ERROR, "illegal POC type %d\n", sps-&gt;poc_type);
        goto fail;
    }
    //num_ref_frames 指定参考帧队列可能达到的最大长度，解码器依照这个句法元素的值开辟存储区，这个存储区用于存放已解码的参考帧，
    //H.264 规定最多可用16 个参考帧，因此最大值为16。
    sps-&gt;ref_frame_count = get_ue_golomb_31(&amp;h-&gt;gb);
    if (h-&gt;avctx-&gt;codec_tag == MKTAG('S', 'M', 'V', '2'))
        sps-&gt;ref_frame_count = FFMAX(2, sps-&gt;ref_frame_count);
    if (sps-&gt;ref_frame_count &gt; H264_MAX_PICTURE_COUNT - 2 ||
        sps-&gt;ref_frame_count &gt; 16U) {
        av_log(h-&gt;avctx, AV_LOG_ERROR,
               "too many reference frames %d\n", sps-&gt;ref_frame_count);
        goto fail;
    }
    sps-&gt;gaps_in_frame_num_allowed_flag = get_bits1(&amp;h-&gt;gb);
    //加1后为图像宽（以宏块为单位）
    //以像素为单位图像宽度（亮度）：width=mb_width*16
    sps-&gt;mb_width                       = get_ue_golomb(&amp;h-&gt;gb) + 1;
    //加1后为图像高（以宏块为单位）
    //以像素为单位图像高度（亮度）：height=mb_height*16
    sps-&gt;mb_height                      = get_ue_golomb(&amp;h-&gt;gb) + 1;
    //检查一下
    if ((unsigned)sps-&gt;mb_width  &gt;= INT_MAX / 16 ||
        (unsigned)sps-&gt;mb_height &gt;= INT_MAX / 16 ||
        av_image_check_size(16 * sps-&gt;mb_width,
                            16 * sps-&gt;mb_height, 0, h-&gt;avctx)) {
        av_log(h-&gt;avctx, AV_LOG_ERROR, "mb_width/height overflow\n");
        goto fail;
    }

    sps-&gt;frame_mbs_only_flag = get_bits1(&amp;h-&gt;gb);
    if (!sps-&gt;frame_mbs_only_flag)
        sps-&gt;mb_aff = get_bits1(&amp;h-&gt;gb);
    else
        sps-&gt;mb_aff = 0;

    sps-&gt;direct_8x8_inference_flag = get_bits1(&amp;h-&gt;gb);

#ifndef ALLOW_INTERLACE
    if (sps-&gt;mb_aff)
        av_log(h-&gt;avctx, AV_LOG_ERROR,
               "MBAFF support not included; enable it at compile-time.\n");
#endif
    //裁剪输出，没研究过
    sps-&gt;crop = get_bits1(&amp;h-&gt;gb);
    if (sps-&gt;crop) {
        int crop_left   = get_ue_golomb(&amp;h-&gt;gb);
        int crop_right  = get_ue_golomb(&amp;h-&gt;gb);
        int crop_top    = get_ue_golomb(&amp;h-&gt;gb);
        int crop_bottom = get_ue_golomb(&amp;h-&gt;gb);
        int width  = 16 * sps-&gt;mb_width;
        int height = 16 * sps-&gt;mb_height * (2 - sps-&gt;frame_mbs_only_flag);

        if (h-&gt;avctx-&gt;flags2 &amp; CODEC_FLAG2_IGNORE_CROP) {
            av_log(h-&gt;avctx, AV_LOG_DEBUG, "discarding sps cropping, original "
                                           "values are l:%d r:%d t:%d b:%d\n",
                   crop_left, crop_right, crop_top, crop_bottom);

            sps-&gt;crop_left   =
            sps-&gt;crop_right  =
            sps-&gt;crop_top    =
            sps-&gt;crop_bottom = 0;
        } else {
            int vsub   = (sps-&gt;chroma_format_idc == 1) ? 1 : 0;
            int hsub   = (sps-&gt;chroma_format_idc == 1 ||
                          sps-&gt;chroma_format_idc == 2) ? 1 : 0;
            int step_x = 1 &lt;&lt; hsub;
            int step_y = (2 - sps-&gt;frame_mbs_only_flag) &lt;&lt; vsub;

            if (crop_left &amp; (0x1F &gt;&gt; (sps-&gt;bit_depth_luma &gt; 8)) &amp;&amp;
                !(h-&gt;avctx-&gt;flags &amp; CODEC_FLAG_UNALIGNED)) {
                crop_left &amp;= ~(0x1F &gt;&gt; (sps-&gt;bit_depth_luma &gt; 8));
                av_log(h-&gt;avctx, AV_LOG_WARNING,
                       "Reducing left cropping to %d "
                       "chroma samples to preserve alignment.\n",
                       crop_left);
            }

            if (crop_left  &gt; (unsigned)INT_MAX / 4 / step_x ||
                crop_right &gt; (unsigned)INT_MAX / 4 / step_x ||
                crop_top   &gt; (unsigned)INT_MAX / 4 / step_y ||
                crop_bottom&gt; (unsigned)INT_MAX / 4 / step_y ||
                (crop_left + crop_right ) * step_x &gt;= width ||
                (crop_top  + crop_bottom) * step_y &gt;= height
            ) {
                av_log(h-&gt;avctx, AV_LOG_ERROR, "crop values invalid %d %d %d %d / %d %d\n", crop_left, crop_right, crop_top, crop_bottom, width, height);
                goto fail;
            }

            sps-&gt;crop_left   = crop_left   * step_x;
            sps-&gt;crop_right  = crop_right  * step_x;
            sps-&gt;crop_top    = crop_top    * step_y;
            sps-&gt;crop_bottom = crop_bottom * step_y;
        }
    } else {
        sps-&gt;crop_left   =
        sps-&gt;crop_right  =
        sps-&gt;crop_top    =
        sps-&gt;crop_bottom =
        sps-&gt;crop        = 0;
    }

    sps-&gt;vui_parameters_present_flag = get_bits1(&amp;h-&gt;gb);
    if (sps-&gt;vui_parameters_present_flag) {
        int ret = decode_vui_parameters(h, sps);
        if (ret &lt; 0)
            goto fail;
    }

    if (!sps-&gt;sar.den)
        sps-&gt;sar.den = 1;
    //Debug的时候可以输出一些信息
    if (h-&gt;avctx-&gt;debug &amp; FF_DEBUG_PICT_INFO) {
        static const char csp[4][5] = { "Gray", "420", "422", "444" };
        av_log(h-&gt;avctx, AV_LOG_DEBUG,
               "sps:%u profile:%d/%d poc:%d ref:%d %dx%d %s %s crop:%u/%u/%u/%u %s %s %"PRId32"/%"PRId32" b%d reo:%d\n",
               sps_id, sps-&gt;profile_idc, sps-&gt;level_idc,
               sps-&gt;poc_type,
               sps-&gt;ref_frame_count,
               sps-&gt;mb_width, sps-&gt;mb_height,
               sps-&gt;frame_mbs_only_flag ? "FRM" : (sps-&gt;mb_aff ? "MB-AFF" : "PIC-AFF"),
               sps-&gt;direct_8x8_inference_flag ? "8B8" : "",
               sps-&gt;crop_left, sps-&gt;crop_right,
               sps-&gt;crop_top, sps-&gt;crop_bottom,
               sps-&gt;vui_parameters_present_flag ? "VUI" : "",
               csp[sps-&gt;chroma_format_idc],
               sps-&gt;timing_info_present_flag ? sps-&gt;num_units_in_tick : 0,
               sps-&gt;timing_info_present_flag ? sps-&gt;time_scale : 0,
               sps-&gt;bit_depth_luma,
               sps-&gt;bitstream_restriction_flag ? sps-&gt;num_reorder_frames : -1
               );
    }
    sps-&gt;new = 1;

    av_free(h-&gt;sps_buffers[sps_id]);
    h-&gt;sps_buffers[sps_id] = sps;

    return 0;

fail:
    av_free(sps);
    return -1;
}
</code></pre> 
<br>解析SPS源代码并不是很有“技术含量”。只要参考ITU-T的《H.264标准》就可以理解了，不再做过多详细的分析。 
<br> 
<br> 
<h3>ff_h264_decode_picture_parameter_set()</h3>ff_h264_decode_picture_parameter_set()用于解析H.264码流中的PPS。该函数的定义位于libavcodec\h264_ps.c，如下所示。 
<br> 
<pre><code class="language-cpp">//解码PPS
int ff_h264_decode_picture_parameter_set(H264Context *h, int bit_length)
{
	//获取PPS ID
    unsigned int pps_id = get_ue_golomb(&amp;h-&gt;gb);
    PPS *pps;
    SPS *sps;
    int qp_bd_offset;
    int bits_left;

    if (pps_id &gt;= MAX_PPS_COUNT) {
        av_log(h-&gt;avctx, AV_LOG_ERROR, "pps_id %u out of range\n", pps_id);
        return AVERROR_INVALIDDATA;
    }
    //解析后赋值给PPS这个结构体
    pps = av_mallocz(sizeof(PPS));
    if (!pps)
        return AVERROR(ENOMEM);
    //该PPS引用的SPS的ID
    pps-&gt;sps_id = get_ue_golomb_31(&amp;h-&gt;gb);
    if ((unsigned)pps-&gt;sps_id &gt;= MAX_SPS_COUNT ||
        !h-&gt;sps_buffers[pps-&gt;sps_id]) {
        av_log(h-&gt;avctx, AV_LOG_ERROR, "sps_id %u out of range\n", pps-&gt;sps_id);
        goto fail;
    }
    sps = h-&gt;sps_buffers[pps-&gt;sps_id];
    qp_bd_offset = 6 * (sps-&gt;bit_depth_luma - 8);
    if (sps-&gt;bit_depth_luma &gt; 14) {
        av_log(h-&gt;avctx, AV_LOG_ERROR,
               "Invalid luma bit depth=%d\n",
               sps-&gt;bit_depth_luma);
        goto fail;
    } else if (sps-&gt;bit_depth_luma == 11 || sps-&gt;bit_depth_luma == 13) {
        av_log(h-&gt;avctx, AV_LOG_ERROR,
               "Unimplemented luma bit depth=%d\n",
               sps-&gt;bit_depth_luma);
        goto fail;
    }
    //entropy_coding_mode_flag
    //0表示熵编码使用CAVLC，1表示熵编码使用CABAC
    pps-&gt;cabac             = get_bits1(&amp;h-&gt;gb);
    pps-&gt;pic_order_present = get_bits1(&amp;h-&gt;gb);
    pps-&gt;slice_group_count = get_ue_golomb(&amp;h-&gt;gb) + 1;
    if (pps-&gt;slice_group_count &gt; 1) {
        pps-&gt;mb_slice_group_map_type = get_ue_golomb(&amp;h-&gt;gb);
        av_log(h-&gt;avctx, AV_LOG_ERROR, "FMO not supported\n");
        switch (pps-&gt;mb_slice_group_map_type) {
        case 0:
#if 0
    |       for (i = 0; i &lt;= num_slice_groups_minus1; i++)  |   |      |
    |           run_length[i]                               |1  |ue(v) |
#endif
            break;
        case 2:
#if 0
    |       for (i = 0; i &lt; num_slice_groups_minus1; i++) { |   |      |
    |           top_left_mb[i]                              |1  |ue(v) |
    |           bottom_right_mb[i]                          |1  |ue(v) |
    |       }                                               |   |      |
#endif
            break;
        case 3:
        case 4:
        case 5:
#if 0
    |       slice_group_change_direction_flag               |1  |u(1)  |
    |       slice_group_change_rate_minus1                  |1  |ue(v) |
#endif
            break;
        case 6:
#if 0
    |       slice_group_id_cnt_minus1                       |1  |ue(v) |
    |       for (i = 0; i &lt;= slice_group_id_cnt_minus1; i++)|   |      |
    |           slice_group_id[i]                           |1  |u(v)  |
#endif
            break;
        }
    }
    //num_ref_idx_l0_active_minus1 加１后指明目前参考帧队列的长度，即有多少个参考帧
    //读者可能还记得在SPS中有句法元素num_ref_frames 也是跟参考帧队列有关，它们的区
    //别是num_ref_frames 指明参考帧队列的最大值， 解码器用它的值来分配内存空间；
    //num_ref_idx_l0_active_minus1 指明在这个队列中当前实际的、已存在的参考帧数目，这从它的名字
    //“active”中也可以看出来。
    pps-&gt;ref_count[0] = get_ue_golomb(&amp;h-&gt;gb) + 1;
    pps-&gt;ref_count[1] = get_ue_golomb(&amp;h-&gt;gb) + 1;
    if (pps-&gt;ref_count[0] - 1 &gt; 32 - 1 || pps-&gt;ref_count[1] - 1 &gt; 32 - 1) {
        av_log(h-&gt;avctx, AV_LOG_ERROR, "reference overflow (pps)\n");
        goto fail;
    }
    //P Slice 是否使用加权预测？
    pps-&gt;weighted_pred                        = get_bits1(&amp;h-&gt;gb);
    //B Slice 是否使用加权预测？
    pps-&gt;weighted_bipred_idc                  = get_bits(&amp;h-&gt;gb, 2);
    //QP初始值。读取后需要加26
    pps-&gt;init_qp                              = get_se_golomb(&amp;h-&gt;gb) + 26 + qp_bd_offset;
    //SP和SI的QP初始值（没怎么见过这两种帧）
    pps-&gt;init_qs                              = get_se_golomb(&amp;h-&gt;gb) + 26 + qp_bd_offset;
    pps-&gt;chroma_qp_index_offset[0]            = get_se_golomb(&amp;h-&gt;gb);
    pps-&gt;deblocking_filter_parameters_present = get_bits1(&amp;h-&gt;gb);
    pps-&gt;constrained_intra_pred               = get_bits1(&amp;h-&gt;gb);
    pps-&gt;redundant_pic_cnt_present            = get_bits1(&amp;h-&gt;gb);

    pps-&gt;transform_8x8_mode = 0;
    // contents of sps/pps can change even if id doesn't, so reinit
    h-&gt;dequant_coeff_pps = -1;
    memcpy(pps-&gt;scaling_matrix4, h-&gt;sps_buffers[pps-&gt;sps_id]-&gt;scaling_matrix4,
           sizeof(pps-&gt;scaling_matrix4));
    memcpy(pps-&gt;scaling_matrix8, h-&gt;sps_buffers[pps-&gt;sps_id]-&gt;scaling_matrix8,
           sizeof(pps-&gt;scaling_matrix8));

    bits_left = bit_length - get_bits_count(&amp;h-&gt;gb);
    if (bits_left &gt; 0 &amp;&amp; more_rbsp_data_in_pps(h, pps)) {
        pps-&gt;transform_8x8_mode = get_bits1(&amp;h-&gt;gb);
        decode_scaling_matrices(h, h-&gt;sps_buffers[pps-&gt;sps_id], pps, 0,
                                pps-&gt;scaling_matrix4, pps-&gt;scaling_matrix8);
        // second_chroma_qp_index_offset
        pps-&gt;chroma_qp_index_offset[1] = get_se_golomb(&amp;h-&gt;gb);
    } else {
        pps-&gt;chroma_qp_index_offset[1] = pps-&gt;chroma_qp_index_offset[0];
    }

    build_qp_table(pps, 0, pps-&gt;chroma_qp_index_offset[0], sps-&gt;bit_depth_luma);
    build_qp_table(pps, 1, pps-&gt;chroma_qp_index_offset[1], sps-&gt;bit_depth_luma);
    if (pps-&gt;chroma_qp_index_offset[0] != pps-&gt;chroma_qp_index_offset[1])
        pps-&gt;chroma_qp_diff = 1;

    if (h-&gt;avctx-&gt;debug &amp; FF_DEBUG_PICT_INFO) {
        av_log(h-&gt;avctx, AV_LOG_DEBUG,
               "pps:%u sps:%u %s slice_groups:%d ref:%u/%u %s qp:%d/%d/%d/%d %s %s %s %s\n",
               pps_id, pps-&gt;sps_id,
               pps-&gt;cabac ? "CABAC" : "CAVLC",
               pps-&gt;slice_group_count,
               pps-&gt;ref_count[0], pps-&gt;ref_count[1],
               pps-&gt;weighted_pred ? "weighted" : "",
               pps-&gt;init_qp, pps-&gt;init_qs, pps-&gt;chroma_qp_index_offset[0], pps-&gt;chroma_qp_index_offset[1],
               pps-&gt;deblocking_filter_parameters_present ? "LPAR" : "",
               pps-&gt;constrained_intra_pred ? "CONSTR" : "",
               pps-&gt;redundant_pic_cnt_present ? "REDU" : "",
               pps-&gt;transform_8x8_mode ? "8x8DCT" : "");
    }

    av_free(h-&gt;pps_buffers[pps_id]);
    h-&gt;pps_buffers[pps_id] = pps;
    return 0;

fail:
    av_free(pps);
    return -1;
}
</code></pre> 
<br>和解析SPS类似，解析PPS源代码并不是很有“技术含量”。只要参考ITU-T的《H.264标准》就可以理解，不再做过多详细的分析。 
<br> 
<br> 
<h3>ff_h264_decode_sei()</h3>ff_h264_decode_sei()用于解析H.264码流中的SEI。该函数的定义位于libavcodec\h264_sei.c，如下所示。 
<br> 
<pre><code class="language-cpp">//SEI补充增强信息单元
int ff_h264_decode_sei(H264Context *h)
{
    while (get_bits_left(&amp;h-&gt;gb) &gt; 16 &amp;&amp; show_bits(&amp;h-&gt;gb, 16)) {
        int type = 0;
        unsigned size = 0;
        unsigned next;
        int ret  = 0;

        do {
            if (get_bits_left(&amp;h-&gt;gb) &lt; 8)
                return AVERROR_INVALIDDATA;
            type += show_bits(&amp;h-&gt;gb, 8);
        } while (get_bits(&amp;h-&gt;gb, 8) == 255);

        do {
            if (get_bits_left(&amp;h-&gt;gb) &lt; 8)
                return AVERROR_INVALIDDATA;
            size += show_bits(&amp;h-&gt;gb, 8);
        } while (get_bits(&amp;h-&gt;gb, 8) == 255);

        if (h-&gt;avctx-&gt;debug&amp;FF_DEBUG_STARTCODE)
            av_log(h-&gt;avctx, AV_LOG_DEBUG, "SEI %d len:%d\n", type, size);

        if (size &gt; get_bits_left(&amp;h-&gt;gb) / 8) {
            av_log(h-&gt;avctx, AV_LOG_ERROR, "SEI type %d size %d truncated at %d\n",
                   type, 8*size, get_bits_left(&amp;h-&gt;gb));
            return AVERROR_INVALIDDATA;
        }
        next = get_bits_count(&amp;h-&gt;gb) + 8 * size;

        switch (type) {
        case SEI_TYPE_PIC_TIMING: // Picture timing SEI
            ret = decode_picture_timing(h);
            if (ret &lt; 0)
                return ret;
            break;
        case SEI_TYPE_USER_DATA_ITU_T_T35:
            if (decode_user_data_itu_t_t35(h, size) &lt; 0)
                return -1;
            break;
            //x264的编码参数信息一般都会存储在USER_DATA_UNREGISTERED
            //其他种类的SEI见得很少
        case SEI_TYPE_USER_DATA_UNREGISTERED:
            ret = decode_unregistered_user_data(h, size);
            if (ret &lt; 0)
                return ret;
            break;
        case SEI_TYPE_RECOVERY_POINT:
            ret = decode_recovery_point(h);
            if (ret &lt; 0)
                return ret;
            break;
        case SEI_TYPE_BUFFERING_PERIOD:
            ret = decode_buffering_period(h);
            if (ret &lt; 0)
                return ret;
            break;
        case SEI_TYPE_FRAME_PACKING:
            ret = decode_frame_packing_arrangement(h);
            if (ret &lt; 0)
                return ret;
            break;
        case SEI_TYPE_DISPLAY_ORIENTATION:
            ret = decode_display_orientation(h);
            if (ret &lt; 0)
                return ret;
            break;
        default:
            av_log(h-&gt;avctx, AV_LOG_DEBUG, "unknown SEI type %d\n", type);
        }
        skip_bits_long(&amp;h-&gt;gb, next - get_bits_count(&amp;h-&gt;gb));

        // FIXME check bits here
        align_get_bits(&amp;h-&gt;gb);
    }

    return 0;
}
</code></pre> 
<br>在《H.264官方标准》中，SEI的种类是非常多的。在ff_h264_decode_sei()中包含以下种类的SEI： 
<br> 
<blockquote style="margin: 0 0 0 40px; border: none; padding: 0px;">
  SEI_TYPE_BUFFERING_PERIOD 
 <br>SEI_TYPE_PIC_TIMING 
 <br>SEI_TYPE_USER_DATA_ITU_T_T35 
 <br>SEI_TYPE_USER_DATA_UNREGISTERED 
 <br>SEI_TYPE_RECOVERY_POINT 
 <br>SEI_TYPE_FRAME_PACKING 
 <br>SEI_TYPE_DISPLAY_ORIENTATION 
</blockquote>其中的大部分种类的SEI信息我并没有接触过。唯一接触比较多的就是SEI_TYPE_USER_DATA_UNREGISTERED类型的信息了。使用X264编码视频的时候，会自动将配置信息以SEI_TYPE_USER_DATA_UNREGISTERED（用户数据未注册SEI）的形式写入码流。 
<br> 
<p>从ff_h264_decode_sei()的定义可以看出，该函数根据不同的SEI类型调用不同的解析函数。当SEI类型为SEI_TYPE_USER_DATA_UNREGISTERED的时候，就会调用decode_unregistered_user_data()函数。</p> 
<p><br></p> 
<strong>decode_unregistered_user_data()</strong> 
<br>decode_unregistered_user_data()的定义如下所示。从代码可以看出该函数只是简单的提取了X264的版本信息。 
<br> 
<pre><code class="language-cpp">//x264的编码参数信息一般都会存储在USER_DATA_UNREGISTERED
static int decode_unregistered_user_data(H264Context *h, int size)
{
    uint8_t user_data[16 + 256];
    int e, build, i;

    if (size &lt; 16)
        return AVERROR_INVALIDDATA;

    for (i = 0; i &lt; sizeof(user_data) - 1 &amp;&amp; i &lt; size; i++)
        user_data[i] = get_bits(&amp;h-&gt;gb, 8);
    //user_data内容示例：x264 core 118
    //int sscanf(const char *buffer,const char *format,[argument ]...);
    //sscanf会从buffer里读进数据，依照format的格式将数据写入到argument里。
    user_data[i] = 0;
    e = sscanf(user_data + 16, "x264 - core %d", &amp;build);
    if (e == 1 &amp;&amp; build &gt; 0)
        h-&gt;x264_build = build;
    if (e == 1 &amp;&amp; build == 1 &amp;&amp; !strncmp(user_data+16, "x264 - core 0000", 16))
        h-&gt;x264_build = 67;

    if (h-&gt;avctx-&gt;debug &amp; FF_DEBUG_BUGS)
        av_log(h-&gt;avctx, AV_LOG_DEBUG, "user data:\"%s\"\n", user_data + 16);

    for (; i &lt; size; i++)
        skip_bits(&amp;h-&gt;gb, 8);

    return 0;
}
</code></pre> 
<br> 
<br> 
<h3>解析Slice Header</h3>对于包含图像压缩编码的Slice，解析器（Parser）并不进行解码处理，而是简单提取一些Slice Header中的信息。该部分的代码并没有写成一个函数，而是直接写到了parse_nal_units()里面，截取出来如下所示。 
<br> 
<pre><code class="language-cpp">case NAL_IDR_SLICE:
        	//如果是IDR Slice
        	//赋值AVCodecParserContext的key_frame为1
            s-&gt;key_frame = 1;

            h-&gt;prev_frame_num        = 0;
            h-&gt;prev_frame_num_offset = 0;
            h-&gt;prev_poc_msb          =
            h-&gt;prev_poc_lsb          = 0;
        /* fall through */
        case NAL_SLICE:
        	//获取Slice的一些信息
        	//跳过first_mb_in_slice这一字段
            get_ue_golomb_long(&amp;h-&gt;gb);  // skip first_mb_in_slice
            //获取帧类型（I,B,P）
            slice_type   = get_ue_golomb_31(&amp;h-&gt;gb);
            //赋值到AVCodecParserContext的pict_type（外部可以访问到）
            s-&gt;pict_type = golomb_to_pict_type[slice_type % 5];
            //关键帧
            if (h-&gt;sei_recovery_frame_cnt &gt;= 0) {
                /* key frame, since recovery_frame_cnt is set */
            	//赋值AVCodecParserContext的key_frame为1
                s-&gt;key_frame = 1;
            }
            //获取 PPS ID
            pps_id = get_ue_golomb(&amp;h-&gt;gb);
            if (pps_id &gt;= MAX_PPS_COUNT) {
                av_log(h-&gt;avctx, AV_LOG_ERROR,
                       "pps_id %u out of range\n", pps_id);
                return -1;
            }
            if (!h-&gt;pps_buffers[pps_id]) {
                av_log(h-&gt;avctx, AV_LOG_ERROR,
                       "non-existing PPS %u referenced\n", pps_id);
                return -1;
            }
            h-&gt;pps = *h-&gt;pps_buffers[pps_id];
            if (!h-&gt;sps_buffers[h-&gt;pps.sps_id]) {
                av_log(h-&gt;avctx, AV_LOG_ERROR,
                       "non-existing SPS %u referenced\n", h-&gt;pps.sps_id);
                return -1;
            }
            h-&gt;sps       = *h-&gt;sps_buffers[h-&gt;pps.sps_id];
            h-&gt;frame_num = get_bits(&amp;h-&gt;gb, h-&gt;sps.log2_max_frame_num);

            if(h-&gt;sps.ref_frame_count &lt;= 1 &amp;&amp; h-&gt;pps.ref_count[0] &lt;= 1 &amp;&amp; s-&gt;pict_type == AV_PICTURE_TYPE_I)
                s-&gt;key_frame = 1;
            //获得“型”和“级”
            //赋值到AVCodecContext的profile和level
            avctx-&gt;profile = ff_h264_get_profile(&amp;h-&gt;sps);
            avctx-&gt;level   = h-&gt;sps.level_idc;

            if (h-&gt;sps.frame_mbs_only_flag) {
                h-&gt;picture_structure = PICT_FRAME;
            } else {
                if (get_bits1(&amp;h-&gt;gb)) { // field_pic_flag
                    h-&gt;picture_structure = PICT_TOP_FIELD + get_bits1(&amp;h-&gt;gb); // bottom_field_flag
                } else {
                    h-&gt;picture_structure = PICT_FRAME;
                }
            }

            if (h-&gt;nal_unit_type == NAL_IDR_SLICE)
                get_ue_golomb(&amp;h-&gt;gb); /* idr_pic_id */
            if (h-&gt;sps.poc_type == 0) {
                h-&gt;poc_lsb = get_bits(&amp;h-&gt;gb, h-&gt;sps.log2_max_poc_lsb);

                if (h-&gt;pps.pic_order_present == 1 &amp;&amp;
                    h-&gt;picture_structure == PICT_FRAME)
                    h-&gt;delta_poc_bottom = get_se_golomb(&amp;h-&gt;gb);
            }

            if (h-&gt;sps.poc_type == 1 &amp;&amp;
                !h-&gt;sps.delta_pic_order_always_zero_flag) {
                h-&gt;delta_poc[0] = get_se_golomb(&amp;h-&gt;gb);

                if (h-&gt;pps.pic_order_present == 1 &amp;&amp;
                    h-&gt;picture_structure == PICT_FRAME)
                    h-&gt;delta_poc[1] = get_se_golomb(&amp;h-&gt;gb);
            }

            /* Decode POC of this picture.
             * The prev_ values needed for decoding POC of the next picture are not set here. */
            field_poc[0] = field_poc[1] = INT_MAX;
            ff_init_poc(h, field_poc, &amp;s-&gt;output_picture_number);

            /* Continue parsing to check if MMCO_RESET is present.
             * FIXME: MMCO_RESET could appear in non-first slice.
             *        Maybe, we should parse all undisposable non-IDR slice of this
             *        picture until encountering MMCO_RESET in a slice of it. */
            if (h-&gt;nal_ref_idc &amp;&amp; h-&gt;nal_unit_type != NAL_IDR_SLICE) {
                got_reset = scan_mmco_reset(s);
                if (got_reset &lt; 0)
                    return got_reset;
            }

            /* Set up the prev_ values for decoding POC of the next picture. */
            h-&gt;prev_frame_num        = got_reset ? 0 : h-&gt;frame_num;
            h-&gt;prev_frame_num_offset = got_reset ? 0 : h-&gt;frame_num_offset;
            if (h-&gt;nal_ref_idc != 0) {
                if (!got_reset) {
                    h-&gt;prev_poc_msb = h-&gt;poc_msb;
                    h-&gt;prev_poc_lsb = h-&gt;poc_lsb;
                } else {
                    h-&gt;prev_poc_msb = 0;
                    h-&gt;prev_poc_lsb =
                        h-&gt;picture_structure == PICT_BOTTOM_FIELD ? 0 : field_poc[0];
                }
            }
</code></pre> 
<br>可以看出该部分代码提取了根据NALU Header、Slice Header中的信息赋值了一些字段，比如说AVCodecParserContext中的key_frame、pict_type，H264Context中的sps、pps、frame_num等等。 
<br> 
<br> 
<br> 
<br> 
<strong><span style="color:#990000;">雷霄骅<br>leixiaohua1020@126.com<br>http://blog.csdn.net/leixiaohua1020</span></strong> 
<br> 
<br>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fe86275d4d69065bf0eaeca479a762f8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">版本管理</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fbfe95a7826629a7b645fb7432439957/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java语言下的数组、链表、哈希表的增删查改效率</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>