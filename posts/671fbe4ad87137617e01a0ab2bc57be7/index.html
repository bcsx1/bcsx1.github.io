<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>精准医学中的深度学习和影像组学 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="精准医学中的深度学习和影像组学" />
<meta property="og:description" content="影像科正在经历一种范式转变，即使用人工智能与机器集成以及深度学习与影像组学更好地定义组织特征，从而实现计算机科学与影像学的共生关系。研究的目标是使用集成的深度学习和具有影像学参数的影像组学来为患者进行个性化诊断。本文概述了影像学精准医学背景下历史和当前的深度学习和影像组学方法。 本文通过“深度学习”、“影像组学”、“机器学习”、“人工智能”、“卷积神经网络”、“生成对抗网络”、“自动编码器”、“深度信念网络”、“强化学习”和“多参数 MRI&#39;在 PubMed、ArXiv、Scopus、CVPR、SPIE、IEEE Xplore 和 NIPS 中进行文献检索。
结论：总而言之，深度学习和影像组学都是两种快速发展的技术，两者将在未来联合起来产生一个统一的临床决策支持框架，有望彻底改变精准医学领域。本文发表在expert review of precision medicine and drug development杂志。
1、介绍
影像成像方法用于扫描身体的不同区域，以检测和表征潜在的异常病理并帮助临床诊断。这些影像成像程序可以通过局部或全身扫描产生大量复杂的数字成像数据，这会使“读取和解释”图像数据变得非常具有挑战性。计算机科学的发展将导致影像学在医学领域使用先进的计算方法发生范式转变 [1–7].这些计算方法包括先进的机器和深度学习算法 [8,9]加上图像纹理的定量测量，称为影像组学[10–13].通过结合这些计算方法，未来的影像科室将形成计算机科学家和影像科医生（人类专家）之间的独特合作。这种合作将使算法能够在影像学诊断决策制定的各个方面协助影像科医生，例如：识别、分割、不同组织类型的表征以及优先诊断。例如，大脑、胸部、腹部、骨盆和乳房等大型成像数据集可以通过使用深度学习方法快速分类来分为不同的组，影像科医生首先查看潜在的“更差”病例，从而增加影像科医师的准确率和信心。可以进一步开发使用机器学习的其他数据挖掘方法，以将影像学参数与使用电子健康记录从不同来源（如病理学和临床病史）提取的其他信息相结合 [14–17].这些整合的数据类型，将使临床医生更全面地了解患者的健康状况，有助于更准确的诊断并提高对疾病复杂性的理解。当数据汇集在一起时，可以实现个性化的治疗计划和精确的疾病预后，如图1所示.计算影像学的目标是提取图像中的所有定性和定量信息，并开发潜在的非侵入性生物标志物，用于检测和表征患者的疾病。深度学习和影像组学是实现这一目标的计算放射学的新兴领域。
深度学习是一个新的研究领域，涉及受我们大脑中的生物神经网络启发而开发的深度人工神经网络 [4,6,18–42].在影像学中，深度神经网络与生物神经网络一样，试图学习影像学数据的内在表示，例如，在MRI中，诸如脑脊液等流体在 T1WI上是暗的，而在T2WI上是亮的。此信息可以训练深度学习算法来识别模式并执行准确的分割。深度学习在多个领域都取得了优异的成绩，例如。对象检测和识别、文本生成、音乐创作和自动驾驶等等 [1,2,43–49].近年来，深度学习已成为计算机辅助临床和影像决策支持领域的一个活跃研究，取得了一些出色的初步成果以及最新的研究发现。
影像组学是一种纹理数学结构，可以捕获感兴趣组织的空间外观（形状和纹理）在不同类型的图像上使用纹理[10–13,50–53].最近还有一篇相关的综述也说明纹理特征在某些应用中与组织生物学相关 [影像组学特征的生物学意义 54].传统意义上，影像组学特征提供有关放射图像感兴趣区域内的灰度模式、像素间关系、形状和频谱的信息。[50–53,55,56].
将影像组学或深度学习算法从研究成功转化为精准医学临床实践的主要障碍之一就是可解释性。例如，在影像组学中，如果熵（一阶，它是异质性/无序性的量度）或灰度共生矩阵 (GLCM) 熵（基于灰度级相互关系的异质性/无序性的高阶量度某些社区）特征被测量为 6.5，如果这些指标没有控制或正常组织熵值，则很难将生物学意义附加到该熵值。影像组学指标的相同值同质或者异质的判断取决于所选的箱子数量、ROI 的大小以及其他预处理步骤，例如图像过滤，这些都会对值产生影响（请参阅以下）。
同样，由于深度学习本质上是一个“黑匣子”，当该方法将底层组织分割并预测为恶性或良性时，深度学习不会提供其预测背后的解释。医生的可解释性将基于算法以及他们是否会“信任”结果，这是目前的主要挑战。本文回顾了影像组学和深度学习技术，概述了目前最先进的精准医疗算法及其局限性，并对这两种技术在精准医疗中的潜在未来进行了展望。
图1 个性化放射诊断和预后的概念计算放射学框架。
该框架有三个主要组成部分——图像分割、特征提取和综合临床决策支持模型。
2、深度学习
近年来，随着高级优化技术的发展和计算效率的提高，深度学习技术重新流行起来。深度学习已经开始在现代社会的许多不同方面发挥不可或缺的作用，并在各种领域产生了出色的成果，例如物体检测和识别、文本生成、音乐创作和自动驾驶等 [2,43–46,48,49].先进的深度学习将在不久的将来使用计算机辅助临床和放射决策支持对精准医学产生影响。这些方法将概述用于训练、测试和验证临床测试的新方法，以更好地整合医学信息，并为诊断提供新的可视化工具。我们将重点关注深度学习方法的概述和最新技术水平。
从历史上看，深度学习方法是计算机科学中机器学习算法的一个子集。简而言之，机器学习的目标是学习特征并将这些特征转化为类标签以进行分割或分类。机器学习算法在本质上是有监督的或无监督的，线性的或非线性的[57].深度学习和传统机器学习算法之间的主要区别在于，深度学习算法不需要中间特征提取或工程步骤来学习输入 x（例如，放射图像上的灰度强度值）和相应的标签 y（例如，与这些强度值对应的组织类型）。
从概念上讲，机器学习算法使用概率分布 p 在 x 和 y 上对输入 x 和标签 y 之间的关系进行建模，一般来说，学习算法可以根据 p [57,58]。生成模型学习联合概率分布 (x, y) 以估计后验概率 p(y|x)。生成深度学习算法的一些例子包括：生成对抗网络、变分自动编码器和深度信念网络 [40,59]。相比之下，判别模型直接估计后验概率 p(y|x) 而无需计算中间环节概率分布。换句话说，判别模型学习 x 和 y 之间的直接映射。卷积神经网络、堆叠自动编码器和多层感知器是判别式深度学习算法的典型示例 [45,46] 。如果问题要求我们只根据 x 预测标签 y，那么判别模型可能是更好的选择，因为它们不关心 (x, y) 的建模，更有效地为 P(y| x) 建模参数，从而产生一个准确率更高的分类器。但是，如果输入 x 包含大量缺失值或数据点并且需要数据插补，则可能无法使用判别模型。此外，生成模型允许生成新的合成数据并模拟输入数据中的不同关系。例如，如果目标是将病变分类为良性或恶性，则判别式深度学习可能是更好的选择。然而，如果我们的目标是识别病变的内在特征并模拟它们在患者群体中的分布，那么更好的算法选择可能是生成式深度学习算法之一。下面讨论应用于精准医学的常用判别式和生成式深度学习算法。图2简要介绍了深度学习领域的主要进展历史和时间表。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/671fbe4ad87137617e01a0ab2bc57be7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-19T09:08:21+08:00" />
<meta property="article:modified_time" content="2022-12-19T09:08:21+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">精准医学中的深度学习和影像组学</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>影像科正在经历一种范式转变，即使用人工智能与机器集成以及深度学习与影像组学更好地定义组织特征，从而实现计算机科学与影像学的共生关系。研究的目标是使用集成的深度学习和具有影像学参数的影像组学来为患者进行个性化诊断。本文概述了影像学精准医学背景下历史和当前的深度学习和影像组学方法。 本文通过<strong>“深度学习”、“影像组学”、“机器学习”、“人工智能”、“卷积神经网络”、“生成对抗网络”、“自动编码器”、“深度信念网络”、“强化学习”和“多参数 MRI'</strong>在 PubMed、ArXiv、Scopus、CVPR、SPIE、IEEE Xplore 和 NIPS 中进行文献检索。</p> 
<p><strong>结论：</strong>总而言之，深度学习和影像组学都是两种快速发展的技术，两者将在未来联合起来产生一个统一的临床决策支持框架，有望彻底改变精准医学领域。本文发表在expert review of precision medicine and drug development杂志。</p> 
<p><strong>1、介绍</strong></p> 
<p>影像成像方法用于扫描身体的不同区域，以检测和表征潜在的异常病理并帮助临床诊断。这些影像成像程序可以通过局部或全身扫描产生大量复杂的数字成像数据，这会使“读取和解释”图像数据变得非常具有挑战性。计算机科学的发展将导致影像学在医学领域使用先进的计算方法发生范式转变 [1–7].这些计算方法包括<strong>先进的机器和深度学习算法 [8,9]加上图像纹理的定量测量，称为影像组学</strong>[10–13].通过结合这些计算方法，未来的影像科室将形成计算机科学家和影像科医生（人类专家）之间的独特合作。这种合作将使算法能够在影像学诊断决策制定的各个方面协助影像科医生，例如：识别、分割、不同组织类型的表征以及优先诊断。例如，大脑、胸部、腹部、骨盆和乳房等大型成像数据集可以通过使用深度学习方法快速分类来分为不同的组，影像科医生首先查看潜在的“更差”病例，从而增加影像科医师的准确率和信心。可以进一步开发使用机器学习的其他数据挖掘方法，以将影像学参数与使用电子健康记录从不同来源（如病理学和临床病史）提取的其他信息相结合 [14–17].这些整合的数据类型，将使临床医生更全面地了解患者的健康状况，有助于更准确的诊断并提高对疾病复杂性的理解。当数据汇集在一起时，可以实现个性化的治疗计划和精确的疾病预后，如图1所示.<strong>计算影像学的目标是提取图像中的所有定性和定量信息，并开发潜在的非侵入性生物标志物，用于检测和表征患者的疾病。</strong>深度学习和影像组学是实现这一目标的计算放射学的新兴领域。</p> 
<p>深度学习是一个新的研究领域，涉及受我们大脑中的生物神经网络启发而开发的<strong>深度人工神经网络</strong> [4,6,18–42].在影像学中，深度神经网络与生物神经网络一样，试图学习影像学数据的内在表示，例如，在MRI中，<strong>诸如脑脊液等流体在 T1WI上是暗的，而在T2WI上是亮的。此信息可以训练深度学习算法来识别模式并执行准确的分割。</strong>深度学习在多个领域都取得了优异的成绩，例如。对象检测和识别、文本生成、音乐创作和自动驾驶等等 [1,2,43–49].近年来，深度学习已成为计算机辅助临床和影像决策支持领域的一个活跃研究，取得了一些出色的初步成果以及最新的研究发现。</p> 
<p>影像组学是一种纹理数学结构，可以捕获感兴趣组织的空间外观（形状和纹理）在不同类型的图像上使用纹理[10–13,50–53].<strong>最近还有一篇相关的综述也说明纹理特征在某些应用中与组织生物学相关</strong> [<strong>影像组学特征的生物学意义 </strong>54].传统意义上，影像组学特征提供有关放射图像感兴趣区域内的灰度模式、像素间关系、形状和频谱的信息。[50–53,55,56].</p> 
<p>将影像组学或深度学习算法从研究成功转化为精准医学临床实践的<strong>主要障碍之一就是可解释性。</strong>例如，在影像组学中，如果熵（一阶，它是异质性/无序性的量度）或灰度共生矩阵 (GLCM) 熵（基于灰度级相互关系的异质性/无序性的高阶量度某些社区）特征被测量为 6.5，如果这些指标没有控制或正常组织熵值，则很难将生物学意义附加到该熵值。<strong>影像组学指标的相同值同质或者异质的判断取决于所选的箱子数量、ROI 的大小以及其他预处理步骤，例如图像过滤，这些都会对值产生影响</strong>（请参阅以下）。</p> 
<p>同样，由于深度学习本质上是一个“黑匣子”，当该方法将底层组织分割并预测为恶性或良性时，<strong>深度学习不会提供其预测背后的解释。</strong>医生的可解释性将基于算法以及他们是否会“信任”结果，这是目前的主要挑战。本文回顾了影像组学和深度学习技术，概述了目前最先进的精准医疗算法及其局限性，并对这两种技术在精准医疗中的潜在未来进行了展望。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/d0/23/EIlNacEn_o.png"></p> 
<p>图1 个性化放射诊断和预后的概念计算放射学框架。</p> 
<p>该框架有三个主要组成部分——图像分割、特征提取和综合临床决策支持模型。</p> 
<p><strong>2、深度学习</strong></p> 
<p>近年来，随着高级优化技术的发展和计算效率的提高，深度学习技术重新流行起来。深度学习已经开始在现代社会的许多不同方面发挥不可或缺的作用，并在各种领域产生了出色的成果，例如物体检测和识别、文本生成、音乐创作和自动驾驶等 [2,43–46,48,49].先进的深度学习将在不久的将来使用计算机辅助临床和放射决策支持对精准医学产生影响。这些方法将概述用于训练、测试和验证临床测试的新方法，以更好地整合医学信息，并为诊断提供新的可视化工具。我们将重点关注深度学习方法的概述和最新技术水平。</p> 
<p>从历史上看，深度学习方法是计算机科学中机器学习算法的一个子集。简而言之，机器学习的目标是学习特征并将这些特征转化为类标签以进行分割或分类。机器学习算法在<strong>本质上是有监督的或无监督的，线性的或非线性的</strong>[57].深度学习和传统机器学习算法之间的主要区别在于，深度学习算法不需要中间特征提取或工程步骤来学习输入 x（例如，放射图像上的灰度强度值）和相应的标签 y（例如，与这些强度值对应的组织类型）。</p> 
<p>从概念上讲，机器学习算法使用概率分布 p 在 x 和 y 上对输入 x 和标签 y 之间的关系进行建模，一般来说，学习算法可以根据 p [57,58]。生成模型学习联合概率分布 (x, y) 以估计后验概率 p(y|x)。生成深度学习算法的一些例子包括：<strong>生成对抗网络、变分自动编码器和深度信念网络</strong> [40,59]。相比之下，判别模型直接估计后验概率 p(y|x) 而无需计算中间环节概率分布。换句话说，<strong>判别模型学习 x 和 y 之间的直接映射。卷积神经网络、堆叠自动编码器和多层感知器是判别式深度学习算法的典型示例 </strong>[45,46] 。如果问题要求我们只根据 x 预测标签 y，那么判别模型可能是更好的选择，因为它们不关心 (x, y) 的建模，更有效地为 P(y| x) 建模参数，从而产生一个准确率更高的分类器。但是，如果输入 x 包含大量缺失值或数据点并且需要数据插补，则可能无法使用判别模型。此外，生成模型允许生成新的合成数据并模拟输入数据中的不同关系。例如，<strong>如果目标是将病变分类为良性或恶性，则判别式深度学习可能是更好的选择。</strong>然而，如果我们的目标是识别病变的内在特征并模拟它们在患者群体中的分布，那么更好的算法选择可能是生成式深度学习算法之一。下面讨论应用于精准医学的常用判别式和生成式深度学习算法。图2简要介绍了深度学习领域的主要进展历史和时间表。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/65/d4/owiOV8td_o.png"></p> 
<p>图2.深度学习领域主要进展的时间</p> 
<p></p> 
<p><br><strong>2.1 深度神经网络的类型</strong><br><strong>2.1.1 判别式深度学习模型</strong></p> 
<p><strong>2.1.1.1卷积神经网络。</strong></p> 
<p>卷积神经网络（CNN）是应用于计算机视觉应用的最流行的神经网络架构[27].这可能是由于可以访问可用的深度学习平台，<strong>例如Tensorflow、Pytorch、Matlab深度学习、Keras等</strong>。CNN的架构受到视觉皮层层级组织的启发 [2,29]. CNN使用局部连接和权重来分析输入数据（例如图像）的二维结构，然后进行池化操作（例如最大池化）以获得空间不变特征。此外，与同等规模的相应全连接网络相比，CNN的可训练参数要少得多。典型的CNN架构如图所示图3.</p> 
<p>传统的CNN架构已经过修改和扩展以包含不同的架构，以改进计算机视觉和其他领域应用程序的最新结果。用于分类或对象识别任务的一些最著名的架构包括 Alexnet [2]、Resnet[6], Densenet[7]，和Inception[3].不同深度学习架构的性能、单遍操作量和网络参数数量的比较详见[60].当前最先进的 CNN 语义（粗到细）分割技术包括 Segnet [4], U-net[5]，以及它们的变体。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/f8/7d/BSKo6kSY_o.png"></p> 
<p>图3 用于临床诊断的放射学图像分类的卷积神经结构（CNN）结构的图示。</p> 
<p><strong>（a） 这里所示的CNN架构由两个卷积层（每个卷积层后面是最大池化层）组成，然后是两个完全连接（密集）的图像分类层。</strong></p> 
<p><strong>（b） 基于图像块（patch)的CNN应用于多参数脑MRI数据集以分割不同脑组织类型的示例。</strong></p> 
<p><strong>2.1.1.2</strong> <strong>堆叠式自动编码器</strong></p> 
<p>自动编码器是一类无监督神经网络，它通过尝试重建输入数据来学习其输入数据的内在表示[33].因此，<strong>自动编码器将输入数据转换为其内在维度的紧凑或低维表示。</strong>为了监督学习任务，当输入数据与标记示例相比有大量未标记示例或数据在训练方面稀疏时，自动编码器特别有用 [61,62].自动编码器的典型架构如图所示图 4.</p> 
<p>自编码器的一些典型应用包括表示学习（例如稀疏自编码器）、分类（例如堆叠稀疏自编码器）和图像去噪（例如堆叠去噪自编码器 [61]).此外，<strong>自动编码器也已扩展到开发称为变分自动编码器的生成神经网络模型中</strong>[39].这是通过修改编码器使其生成大致遵循单位高斯分布的潜在向量来完成的。通过更改损失函数以包括输入和输出之间的均方误差以及潜在向量和单位高斯分布之间的 Kullback-Leibler (KL) 散度来强制执行约束。<strong>变分自动编码器已经开始在无监督和半监督的特征提取和分割中找到应用</strong>[63–65].</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/f2/25/mpTTAjHp_o.png"></p> 
<p>图4 用于通过尝试重建高维多参数MRI大脑数据集来学习低维表示的自动编码器的图示。</p> 
<p></p> 
<p><strong>2.1.1</strong> <strong>生成式深度学习模型</strong></p> 
<p><strong>2.1.2.1 深度信念网络</strong></p> 
<p>深度信念网络 (DBN) 是一类生成式深度神经网络，由多层随机潜在变量组成 [66]. <strong>DBN的每一层都充当前一层的隐藏层和后一层的输入层。</strong>此外，每一层内的节点之间没有连接。DBN的每一层都可以看作是一个无监督网络，例如受限玻尔兹曼机（RBM）[34] 或自动编码器[33]，它利用前一层的输出以贪心逐层无监督方式进行训练。图5说明了典型DBN的架构。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/f3/a4/ebNumsip_o.png"></p> 
<p>图5 具有两个隐藏层的深度信念网络（DBN）的图示，用于分割示例多参数MRI脑数据集。</p> 
<p><strong>利用前一层的输出，使用受限玻尔兹曼机器（RBMs）以无监督的方式对每一层进行预训练。示例数据集上DBN分割的输出显示在输出层中。</strong></p> 
<p><strong>2.1.2.2 生成对抗网络</strong></p> 
<p>生成对抗网络。生成对抗网络（GAN）是目前最流行的生成深度学习架构[40]. <strong>GAN由两个在零和博弈框架中相互竞争的神经网络架构组成。</strong>一个网络生成候选者（生成器），而另一个网络评估它们（鉴别器）。生成器的目标是从输入数据分布中合成真实实例，而鉴别器的目标是区分输入数据分布的真实实例和合成实例。训练生成器的目标是最大化鉴别器的错误率，大约为 50% [40,67].一旦经过训练，生成器就会学习从潜在空间映射到输入数据分布。图6展示了典型GAN的架构。GAN的主要应用是图像、视频和语音合成 [68–73].在医学图像分析中，<strong>GAN已被用于医学图像合成、分割、配准和数据增强</strong>。可以在 [67]这篇文献中进行更加详细的描述。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/86/6f/MKKxssZu_o.png"></p> 
<p>图6 生成对抗网络（GAN）架构的图示。</p> 
<p><strong>GAN由两个在零和博弈框架中相互竞争的神经网络架构组成。一个网络生成候选（生成器），而另一个网络评估候选（鉴别器）。生成器的目标是从输入数据分布中合成真实实例，而鉴别器的目标是区分输入数据分布的真实实例和合成实例。</strong></p> 
<p><strong>2.1.2.3 深度强化学习</strong></p> 
<p>从历史上看，强化学习 (RL) 是一个多方面的研究领域，其中RL算法尝试学习动作以优化定义状态下的某种类型的动作，并权衡任何的权重系数以获得最大可能的奖励 [74,75]. <strong>RL所需的主要元素是策略、奖励信号、价值函数和定义环境的模型</strong> [75]. Sutton 对这些和其他 RL 方面进行了深入讨论 [75].强化学习算法是面向目标的算法，它试图在许多动作中最大化特定奖励，其中，RL算法在每个动作中根据它采取的是正确或错误的动作来决定是奖励或惩罚。最后，该动作根据其对最终奖励的贡献进行评估[76–85].例如，找到正确的动作组合以获得最大的分数并获胜。</p> 
<p>深度强化学习是一个快速发展的领域，在强化学习领域快速发展的领域具有突破性的成果，例如语音识别[86], 玩 Atari [87] 和阿尔法围棋 [88].在深度强化学习中，深度学习算法被训练来识别当前状态并预测下一个最佳移动（<strong>例如，CNN 可以被训练来捕获游戏的计算机屏幕作为当前状态，然后预测按下哪个按钮键盘最大化游戏的最终得分</strong>）[87].</p> 
<p>深度强化学习算法已开始在计算放射学领域的里程碑检测和治疗反应预测中找到应用[83–85]。在地标检测中，深度强化学习用于搜索身体中的地标（例如胰腺），使其比标准搜索算法更快[85]。在治疗反应评估中，可以训练深度强化学习模型，以预测药物对患者治疗过程中的影响同时评估他们是否会对治疗方案产生反应[83]。</p> 
<p><strong>2.2 深度神经网络——深入了解</strong></p> 
<p>将深度学习算法从研究成功转化为精准医学实践的主要障碍之一是它们的可解释性。大量研究表明，深度神经网络很容易被干扰[89–92]，这使得它们的可解释性对于放射学应用更加重要。</p> 
<p>深度神经网络就像一个黑匣子。也就是说，我们不知道深度神经网络是如何组织、整合和解释成像信息的。例如，当放射科医生在他们的大脑中形成“脂肪”的内在表征时，他们将其存储为“T1上亮，T2 上暗”。类似地，“流体”的内在表示将存储为“T1 上暗，T2 上亮”。这里的主要问题是“<strong>深度神经网络如何对输入的内在表征进行编码？</strong>”。</p> 
<p>近年来，大量研究尝试打开深度学习的黑匣子，并取得了优异的成果，<strong>采用激活最大化 [93], 反卷积网络 [94], 网络反转 [95]，以及网络剖析[96]包括为提高网络可解释性而开发的主要技术。</strong>可以在[97].在这里，我们将在以下小节中概述这些技术。</p> 
<p><strong>2.2.1 激活最大化</strong></p> 
<p>激活最大化背后的想法是识别最大化特定神经元激活的输入模式。通过识别网络中不同神经元的最佳输入模式集，可以解码这些神经元在输入空间方面代表的内容。例如，对于经过训练可识别人脸的网络，激活最大化方法可用于识别专门用来识别不同面部特征（如鼻子、眼睛和嘴巴）的神经元。使用激活最大化的输入模式可视化的可解释性，近年来引起了人们的极大兴趣，从而改进了算法[98].</p> 
<p><strong>2.2.2 反卷积网络</strong></p> 
<p>反卷积网络从输入图像的角度解释卷积网络，而不是激活最大化的单个神经元[94,99,100].反卷积网络突出了激活每一层中单个神经元的输入图像的模式，提供了一种工具来解释网络并识别训练有素的网络的任何问题。</p> 
<p><strong>2.2.3 网络反转</strong></p> 
<p>激活最大化和反卷积网络的技术涉及从神经元的角度解释网络。另一方面，网络反转试图从一层的角度分析激活模式。顾名思义，网络反转试图从任意层的激活模式中重建输入[95].网络反演提供了一种工具来解释特定层将存储的信息。近年来，已经提出了许多不同的网络反演方法，例如Hoggles[101]和上卷积神经网络[102]能够从任何算法生成的特征空间重建输入，例如梯度直方图（HoG）[103],尺度不变特征变换(SIFT)[104]，或卷积神经网络[27].</p> 
<p><strong>2.2.4 网络剖析</strong></p> 
<p>激活最大化、反卷积网络和网络反转技术提供了理解特定神经元或层的激活模式的工具。然而，这些方法不提供对这些激活模式的语义解释。因此，Bau等人。[96]提出了网络解剖技术，试图将卷积神经网络中的每个神经元与一个语义概念相关联。</p> 
<p><strong>3．影像组学</strong></p> 
<p>放射学已广泛应用于不同器官和模式的许多不同精密医学应用实践中。关于影像组学的数学背景和应用的最新评论可以在[54]中得到解读，这篇文章讨论了影像组学的局限性105].目前最先进的影像组学技术是处理从影像图像中<strong>提取一阶和高阶统计特征</strong>[50–53,55,56].我们将概述影像组学领域的一些较新进展，然后在以下小节中详细讨论影像组学的可解释性。影像组学的简史已在图7.</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/aa/99/9SNZiSRD_o.png"></p> 
<p>图7 纹理和影像学领域重要进展的时间轴</p> 
<p></p> 
<p><strong>3.1 多参数影像组学</strong></p> 
<p>传统上，影像组学是为从单一模式（例如肺癌患者的CT扫描）中提取特征而开发的。影像组学领域正在迅速扩展到多参数成像设置的应用，其中在患者身上采集多个不同的成像序列以进行更完整的诊断。因此，最近开发了新的<strong>多参数影像组学(MPRAD)方法来整合多参数数据集中存在的所有成像信息，</strong>从而产生新的影像组学特征指标[106].MPRAD特征是基于高维多参数成像数据中组织间特征关系的提取，而不是单个图像或感兴趣区域中传统影像组学特征提取的体素间关系，如图8所示.MPRAD允许在组织类型之间更好地描绘组织，并允许改进用于精准医学诊断的定量影像组学测量。</p> 
<p>乳腺病变的多参数影像组学导致恶性和良性乳腺病变之间的分类更高，敏感性和特异性分别为82.5%和80.5%，AUC为0.87[106].更重要的是，<strong>使用多参数影像组学，AUC增加了9%-28%。</strong>通过单一影像组学方法。在患有急性中风的脑部患者中，多参数影像组学能够比单参数影像组学更完全地区分灌注-扩散不匹配[106].图9说明了多参数影像组学在良性和恶性病变中的应用。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/a1/9d/gnWqeT0a_o.png"></p> 
<p>图8 说明GLCM影像特征与常规单图像和多参数影像特征之间的差异。</p> 
<p></p> 
<p><strong>（a）单图像影像组学特征提取放射图像平面内的像素间关系，而（b）多参数影像组学提取跨多个放射图像的组织间特征关系。</strong></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/f9/11/6SMSgOR7_o.png"></p> 
<p></p> 
<p><strong>顶行：良性病变患者的示例，其中黄色直箭头突出显示病变。单参数和多参数熵放射图像之间存在明显差异，其中多参数清3晰地划分了病变。</strong></p> 
<p><strong>下排：恶性病变患者的类似分析（黄色箭头）。同样，多参数熵图改善了腺体组织和病变组织之间的组织描绘。</strong></p> 
<p><strong>3.2 影像组学的可解释性</strong></p> 
<p>自影像组学诞生以来，影像组学特征的可解释性一直是影像组学的主要限制。这部分是因为影像组学特征没有经过标准化，以及与感兴趣区组织的基础生物学相关特征不能合理解释的困难。例如，从感兴趣区域提取的影像组学特征(ROI)取决于ROI的大小以及为图像量化选择的灰度级和箱数，如以下小节所述。</p> 
<p><strong>3.2.1 取决于投资回报率的大小</strong></p> 
<p>考虑熵和均匀性的一阶特征，由以下等式给出：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/a3/bb/7e3UIIKz_o.png"></p> 
<p>这里，H是一阶直方图，具有B个箱值。</p> 
<p>以取的值范围在0到log2N之间变化，其中 N 是数字均匀性特征可以在 (1/N) 和 1 之间变化。例如，考虑一个 5 × 5 大小的 ROI。此 ROI 的最小异质性或最大均匀性发生在所有组织中的体素。同样，值的范围是体素具有相同的强度值。在这种情况下，对于所有 i ∈ {2,3, …, B}，(1) = 1 和 H(i) = 0 的值。因此，此 ROI 的熵值和均匀性值分别为 0 和 1。但是，最大异质性或最小均匀性发生在所有体素都具有不同的强度值。在这种情况下，对于所有 i ∊ {1,2, …, B}，(i) =1的值。因此，此 ROI 的熵值和均匀性值分别为 log225 = 4.64 和 0.04。</p> 
<p>ROI大小与影像组学特征之间的依赖性已在大量研究中观察到，并在[105].<strong>有两种可能的方法可以克服这一限制：影像组学特征映射和特征归一化。</strong></p> 
<p>影像组学特征映射(RFM)使用基于一阶和二阶统计的统计内核将放射图像转换为纹理图像[13].RFM计算放射图像中每个体素的影像组学值，从而抵消了尺寸依赖性的影响。然而，RFM的计算具有很高的时间复杂度。对于二阶GLCM特征，对于量化为G灰度级的N×N放射图像，使用W×W大小的滑动窗口计算RFM的时间复杂度为O(N2,G2,W2).最近，使用深度卷积神经网络在MRI乳腺癌研究中初步成功地合成了熵特征图[107]。 影像组学特征也可以归一化为ROI的大小。例如，计算一阶熵的方程可以修改为：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/c3/39/TKjpEnOh_o.png"></p> 
<p><strong>3.2.2 对图像合并和灰度级量化的依赖</strong></p> 
<p>用于影像组学分析的灰度级或箱数与相应的影像组学特征之间存在内在依赖性。从等式(1)和(2)可以看出这种依赖性，其中箱数用作计算熵和均匀性的输入变量。图10展示了熵对分箱和用于图像过滤的邻域参数的依赖性。当合并增加时，会导致信息和图像对比度丢失。</p> 
<p>Shafiqul-Hasan等人评估了灰度级量化和GLCM特征之间的依赖性。[108]对于某些二阶特征。作者发现，影像组学特征与所选特征集的灰度级数呈线性、二次或三次关系。作者进一步提出了修正方程计算不同的影像组学特征并测试它们对不同体模的功效。然而，灰度级量化实际上改变了放射图像中存在的信息。除了数学依赖性之外，<strong>灰度级量化和影像组学特征之间还存在内在依赖性，这在任何研究中尚未得到解决。</strong>例如，如果我们考虑将放射图像量化为一个灰度级的极端情况，我们将丢失图像中存在的所有信息。</p> 
<p>不能通过数学修改影像组学公式来纠正影像图像中的这种信息丢失，而是通过选择最佳数量的灰度级来纠正这个问题。目前，不存在用于选择灰度级数的标准化方法，该灰度级数将最小化所得量化图像中的信息损失。在未来，<strong>只有通过标准化选择最佳灰度级或一系列理想灰度级的程序，才能实现影像组学的标准化，以跨多个平台使用放射图像的量化。</strong></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/ae/5d/xxrypDo7_o.png"></p> 
<p>图10</p> 
<p><strong>（a）说明用于图像滤波和图像合并的邻域大小的熵值对a（b）的依赖性。CT图像（软组织窗口）。（c）熵与箱的曲线似乎遵循一种不同的模式，其中熵值在一定范围内随箱数的对数线性变化，在该范围外保持或多或少的恒定。熵的值随着邻域滤波器的大小的增加而一致地增加。</strong></p> 
<p><strong>4.讨论</strong></p> 
<p>深度学习和影像组学方法正在影响精准放射学研究的范式转变。近年来，深度学习方法在医学图像分析的许多研究领域都有应用，从图像采集到图像配准、分割和分类[8,9]。影像组学提供了一种基于图像中灰度级纹理的新定量指标，以帮助检测和表征不同的病理。通过将影像组学和深度学习结合在一起，它们有可能彻底改变放射学领域，开辟个性化影像医学的新领域[107]。</p> 
<p><strong>目前最先进的影像组学技术在可解释性、标准化和可视化方面面临一些挑战。</strong>灰度级量化的预处理步骤是影像组学研究的一个活跃领域。图像的这种量化可能会改变放射图像中存在的固有信息。放射图像中的这些变化无法进行数学校正，并且可能会在纹理特征方面产生不正确的结果。未来需要开发类似于信噪比和对比噪声比的定量影像组学指标，<strong>这将衡量原始图像和量化放射图像之间的信息损失。</strong>此外，还需要定义一个标准化的公差水平，以确保影像组学结果的正确性。最后，在将纹理特征与感兴趣组织的生物学联系起来的方面也进行了积极的研究。这种与生物学的联系可能会随着多参数影像组学的引入而加速，<strong>其中具有已知生物学特性的多个图像可以直接与纹理特征相关联。</strong>而在过去，只能使用单个图像。</p> 
<p>最近的报告表明，深度学习方法，尤其是CNN，能够在初始卷积层中捕获放射图像中存在的纹理信息。这种纹理信息可以被可视化使用先进的网络可解释性技术来更好地理解不同影像组学方法的含义。例如，可视化具有低熵值和高熵值的图像的纹理特征差异对于组织的异质性非常有用。此外，CNN有可能完全取代当前从放射图像生成影像组学数据的方法，正如该方向的初步工作所示[107].<strong>随着Resnet等新型架构的发展，深度学习方法在计算机视觉研究中取得了巨大的成功，</strong>例如Resnet [6], Densenet [7]，和Inception [3].然而，这些架构针对红色、绿色和蓝色图像的计算机视觉（例如Imagenet）应用进行了优化，但是这些优化的方案可能并没有专门的针对医学图像分析的应用进行专门的优化设定，在医学图像分析中，它们基于灰度级。将这些架构直接转化使用在医学领域可能不会产生最佳结果，尤其是对于多参数和多模态成像数据集。有关基础任务的领域知识可以为将这些深度学习架构转化为应用于医学成像方法提供必要的桥梁。Kaggle在基于光学成像的糖尿病视网膜病变挑战中展示了一些初步的转变[110].在典型的深度学习框架中有两个主要组成部分，其中领域知识可以提高深度学习在医学图像分析中的功效。第一个组件在训练深度神经网络之前处理图像预处理（例如归一化）。许多应用已经证明，<strong>尺度标准化对于训练和测试机器和深度学习算法至关重要</strong>[111,112]。</p> 
<p><strong>第二个组成部分是神经网络架构本身。</strong>为语义分割的特定任务开发的深度学习架构的典型例子是U-net[5].从视觉到医学图像分析应用程序的转换提出了一些独特的挑战。例如，分割或分类问题通常被表述为二元问题，但是这个问题不评估正常或异常组织内的异质性。通过在每种组织类型中注释所有可能的类别，可以潜在地解决此问题。然而，这种解决方案既不切实际又计算量大，因为它需要专家用所有可能的组织类别仔细注释每张图像。因此，无监督的深度学习方法，如自动编码器[33],生成对抗网络[40]，或深度信念网络[66]可用于表征潜在的组织异质性。</p> 
<p>深度学习方法目前面临一些挑战，例如可解释性、优化和验证（在前瞻性意义上）。算法的开发取得了重大进展，<strong>这些算法可能会打开许多深度神经网络的深度学习“黑匣子”。这些技术包括激活最大化[93],反卷积网络[94],网络反转[95]，以及网络剖析[96].</strong>激活最大化和反卷积网络技术从神经元的角度处理网络的可解释性，网络反转试图从网络的角度重建输入，网络解剖将卷积神经网络中的每个神经元关联起来形成具有语义概念的网络。</p> 
<p>最近，通过结合现有的解释深度神经网络的技术并将它们视为此类接口的基础和组合构建块，提出了一种新颖的接口[113].然而，这些方法尚未转化为临床和影像学数据以应用于精准医学。未来，我们将看到这些技术被转化、理解为分析临床和影像学数据而开发的算法，以及专门为理解此类数据集而开发的更新的专业技术。此外，一些深度学习模型很容易被对抗性图像块的引入所干扰[92].最近，<strong>正在开发更新的架构以产生对对抗性攻击有弹性的深度网络</strong>[114].</p> 
<p>深度神经网络架构的优化是一项重大挑战。网络参数的搜索空间通常非常大，根据经验评估完整的搜索空间来为特定任务开发最佳神经网络架构可能不切实际。为此，正在开发更新的方法来有效地计算最佳神经网络架构（例如Adanet[115]).Adanet可以自适应地优化网络结构和每个连接的权重。此外，使用或不使用高级优化算法（如Adanet）训练的深度网络仍然在一个特定时间点使用有限大小的数据集进行训练。<strong>神经网络应该能够在遇到更多数据时自动更新其架构（类似于人脑）。这种类型的网络被称为终身学习，</strong>最近的评论描述了文献中提出的几种不同的终身学习方法[116].未来，用于临床决策支持系统的深度学习方法将不仅仅是单一的神经网络，而是一个结合了决策支持、网络可解释性、网络优化和终身学习算法的混合框架。</p> 
<p>总之，深度学习和影像组学都是两种快速发展的技术，它们可能在未来联合起来产生一个统一的临床决策支持框架，有可能彻底改变精准医学领域。</p> 
<p>深度学习和影像组学正在许多研究领域迅速占据主导地位，并且是一个相对较新的研究领域，尽管它使用的是几十年前开发的方法。在发展经济和日益增长的计算方法上，深度学习在许多不同领域都取得了早期的成功。然而，需要进行广泛的研究来评估网络在每一层的工作方式以及权重到节点的传输方式。<strong>网络超参数的优化，例如，批处理规范化、正则化、拟合参数等，</strong>同样，对于影像组学来说，主要的挑战是与生物学和功能的联系，其中有几个主要步骤需要解决，例如。预处理步骤，例如量化、数据灰度级和合并的最佳方法，以及不同图像分辨率的最佳邻域大小。为这两种方法建立标准将需要更多的研究和验证研究。</p> 
<p>在接下来的五年里，我们将见证深度学习和影像组学方法改变医学成像及其在个性化医疗中的应用。这些技术将发展为基于不同网络和先进影像组学方法组合的混合系统，以实现更完整的诊断。</p> 
<p>总之，随着深度学习和影像组学方法的成熟，它们的使用将成为临床决策支持系统的一部分，可用于快速挖掘患者数据空间和放射成像生物标志物，推动医学朝着精准医疗的目标迈进。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7d04be0a87a16643f7eb27b25453d38a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">redis是单线程为什么速度还快</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bb671789c30ea44dcae01fab44faffe0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">pytest之命名规则和运行方式</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>