<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大模型高效调参—PEFT库（ Parameter-Efficient Fine-Tuning） - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="大模型高效调参—PEFT库（ Parameter-Efficient Fine-Tuning）" />
<meta property="og:description" content="介绍 在面对特定的下游任务时，如果进行Full FineTuning（即对预训练模型中的所有参数都进行微调），太过低效；而如果采用固定预训练模型的某些层，只微调接近下游任务的那几层参数，又难以达到较好的效果。
PEFT（Parameter-Efficient Fine-Tuning）是一个用于在不微调所有模型参数的情况下，有效地将预先训练的语言模型（PLM）适应各种下游应用的库。PEFT方法只微调少量（额外）模型参数，显著降低了计算和存储成本，因为微调大规模PLM的成本高得令人望而却步。最近最先进的PEFT技术实现了与完全微调相当的性能。
大模型训练的微调方法，包括prompt tuning、prefix tuning、LoRA、p-tuning和AdaLoRA等。
Adapter Tuning 谷歌的研究人员首次在论文《Parameter-Efficient Transfer Learning for NLP》提出针对 BERT 的 PEFT 微调方式，拉开了 PEFT 研究的序幕。下图所示的 Adapter 结构，将其嵌入 Transformer 的结构里面，在训练时，固定住原来预训练模型的参数不变，只对新增的 Adapter 结构进行微调。
首先是一个 down-project 层将高维度特征映射到低维特征，然后过一个非线形层之后，再用一个 up-project 结构将低维特征映射回原来的高维特征；同时也设计了 skip-connection 结构，确保了在最差的情况下能够退化为 identity。
从实验结果来看，该方法能够在只额外对增加的 3.6% 参数规模（相比原来预训练模型的参数量）的情况下取得和 Full-finetuning 接近的效果（GLUE 指标在 0.4% 以内）。
Prefix Tuning 在输入 token 之前构造一段任务相关的 virtual tokens 作为 Prefix，然后训练的时候只更新 Prefix 部分的参数，而 Transformer 中的其他部分参数固定。，学习到的前缀指令文本向量可以挖掘大模型的潜力去引导模型完成特定任务。
Prefix Tuning 和构造 Prompt 类似，只是 Prompt 是人为构造的“显式”的提示，并且无法更新参数，而 Prefix 则是可以学习的“隐式”的提示。
同时，为了防止直接更新 Prefix 的参数导致训练不稳定的情况，在 Prefix 层前面加了 MLP 结构（相当于将 Prefix 分解为更小维度的 Input 与 MLP 的组合后输出的结果），训练完成后，只保留 Prefix 的参数。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/acd07beac2d295400b53ddc18360680c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-17T12:26:39+08:00" />
<meta property="article:modified_time" content="2023-05-17T12:26:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大模型高效调参—PEFT库（ Parameter-Efficient Fine-Tuning）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="_0"></a>介绍</h4> 
<p>在面对特定的下游任务时，如果进行Full FineTuning（即对预训练模型中的所有参数都进行微调），太过低效；而如果采用固定预训练模型的某些层，只微调接近下游任务的那几层参数，又难以达到较好的效果。</p> 
<p>PEFT（Parameter-Efficient Fine-Tuning）是一个用于在不微调所有模型参数的情况下，有效地将预先训练的语言模型（PLM）适应各种下游应用的库。PEFT方法只微调少量（额外）模型参数，显著降低了计算和存储成本，因为微调大规模PLM的成本高得令人望而却步。最近最先进的PEFT技术实现了与完全微调相当的性能。</p> 
<p>大模型训练的微调方法，包括prompt tuning、prefix tuning、LoRA、p-tuning和AdaLoRA等。</p> 
<h4><a id="Adapter_Tuning_7"></a>Adapter Tuning</h4> 
<p>谷歌的研究人员首次在论文《Parameter-Efficient Transfer Learning for NLP》提出针对 BERT 的 PEFT 微调方式，拉开了 PEFT 研究的序幕。下图所示的 Adapter 结构，将其嵌入 Transformer 的结构里面，在训练时，固定住原来预训练模型的参数不变，只对新增的 Adapter 结构进行微调。<br> <img src="https://images2.imgbox.com/23/a7/UxJJug5O_o.png" alt="在这里插入图片描述"><br> 首先是一个 down-project 层将高维度特征映射到低维特征，然后过一个非线形层之后，再用一个 up-project 结构将低维特征映射回原来的高维特征；同时也设计了 skip-connection 结构，确保了在最差的情况下能够退化为 identity。</p> 
<p>从实验结果来看，该方法能够在只额外对增加的 3.6% 参数规模（相比原来预训练模型的参数量）的情况下取得和 Full-finetuning 接近的效果（GLUE 指标在 0.4% 以内）。</p> 
<p><img src="https://images2.imgbox.com/b3/63/8t5X8KG0_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Prefix_Tuning_15"></a>Prefix Tuning</h4> 
<p>在输入 token 之前构造一段任务相关的 virtual tokens 作为 Prefix，然后训练的时候只更新 Prefix 部分的参数，而 Transformer 中的其他部分参数固定。，学习到的前缀指令文本向量可以挖掘大模型的潜力去引导模型完成特定任务。</p> 
<p><img src="https://images2.imgbox.com/1c/61/sXrijVvL_o.png" alt="在这里插入图片描述"><br> Prefix Tuning 和构造 Prompt 类似，只是 Prompt 是人为构造的“显式”的提示，并且无法更新参数，而 Prefix 则是可以学习的“隐式”的提示。</p> 
<p>同时，为了防止直接更新 Prefix 的参数导致训练不稳定的情况，在 Prefix 层前面加了 MLP 结构（相当于将 Prefix 分解为更小维度的 Input 与 MLP 的组合后输出的结果），训练完成后，只保留 Prefix 的参数。</p> 
<pre><code class="prism language-python">embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_virtual_tokens<span class="token punctuation">,</span> token_dim<span class="token punctuation">)</span>
transform <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>token_dim<span class="token punctuation">,</span> encoder_hidden_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>encoder_hidden_size<span class="token punctuation">,</span> num_layers <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> token_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre> 
<pre><code>
PREFIX_TUNING 需要设置一个参数，即 指令文本的长度 num_virtual_tokens，研究表明这个数量一般设置在10-20之间。不同的任务所需要的 Prefix 的长度有差异。

```python
model_name_or_path = "./unsup-simcse-roberta-base"
peft_type = PeftType.PREFIX_TUNING
peft_config = PrefixTuningConfig(task_type="SEQ_CLS", num_virtual_tokens=20)
lr = 1e-2
model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True)
model = get_peft_model(model, peft_config)
model.print_trainable_parameters()
</code></pre> 
<h4><a id="Prompt_Tuning_45"></a>Prompt Tuning</h4> 
<p>论文《The Power of Scale for Parameter-Efficient Prompt Tuning》<br> 只要模型规模够大，简单加入 Prompt tokens 进行微调，就能取得很好的效果。<br> <img src="https://images2.imgbox.com/25/2f/4AlNWebj_o.png" alt="在这里插入图片描述"><br> 固定预训练参数，为每一个任务额外添加一个或多个embedding，之后拼接query正常输入LLM，并只训练这些embedding。左图为单任务全参数微调，右图为prompt tuning。</p> 
<h6><a id="_51"></a>实验</h6> 
<p><img src="https://images2.imgbox.com/04/a3/u4UrOJWC_o.png" alt="在这里插入图片描述"></p> 
<ul><li>(a) Prompt 长度影响：模型参数达到一定量级时，Prompt 长度为 1 也能达到不错的效果，Prompt 长度为 20 就能达到极好效果。</li><li>(b) Prompt 初始化方式影响：Random Uniform 方式明显弱于其他两种，但是当模型参数达到一定量级，这种差异也不复存在。</li><li>© 预训练的方式：LM Adaptation 的方式效果好，但是当模型达到一定规模，差异又几乎没有了。</li><li>(d) 微调步数影响：模型参数较小时，步数越多，效果越好。同样随着模型参数达到一定规模，zero shot 也能取得不错效果。</li></ul> 
<p>文章表明随着模型越大，PROMPT_TUNING 的效果几乎能和模型整个微调的效果一样。形成了只是学习一个指令然后去模型中检索某种能力的范式。</p> 
<pre><code>from peft import PromptTuningConfig, get_peft_model

model_name_or_path = "./unsup-simcse-roberta-base"
peft_type = PeftType.PROMPT_TUNING
peft_config = PromptTuningConfig(task_type="SEQ_CLS", num_virtual_tokens=20)
lr = 1e-3
model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True)
model = get_peft_model(model, peft_config)
model.print_trainable_parameters()
</code></pre> 
<p><a href="https://huggingface.co/docs/peft/conceptual_guides/prompting" rel="nofollow">https://huggingface.co/docs/peft/conceptual_guides/prompting</a></p> 
<h4><a id="PTuning_V1_74"></a>P-Tuning V1</h4> 
<p>P-Tuning 方法的提出主要是为了解决这样一个问题：大模型的 Prompt 构造方式严重影响下游任务的效果。</p> 
<p><img src="https://images2.imgbox.com/de/d8/V352FOxk_o.png" alt="在这里插入图片描述"></p> 
<p>P-Tuning 提出将 Prompt 转换为可以学习的 Embedding 层，只是考虑到直接对 Embedding 参数进行优化会存在这样两个挑战：</p> 
<ul><li>Discretenes：对输入正常语料的 Embedding 层已经经过预训练，而如果直接对输入的 prompt embedding 进行随机初始化训练，容易陷入局部最优</li><li>Association：没法捕捉到 prompt embedding 之间的相关关系。<br> <img src="https://images2.imgbox.com/d4/01/3jvFhlXZ_o.png" alt="在这里插入图片描述"><br> 手动尝试最优的提示无异于大海捞针，于是便有了自动离散提示搜索的方法（左图），但提示是离散的，神经网络是连续的，所以寻找的最优提示可能是次优的。p-tuning依然是固定LLM参数，利用多层感知机和LSTM对prompt进行编码，编码之后与其他向量进行拼接之后正常输入LLM。注意，训练之后只保留prompt编码之后的向量即可，无需保留编码器。</li></ul> 
<p>作者在这里提出用 MLP+LSTM 的方式来对 prompt embedding 进行一层处理</p> 
<p><img src="https://images2.imgbox.com/76/55/snBfKpsF_o.png" alt="在这里插入图片描述"><br> 需要提醒的是这里的指令文本是伪文本,可能就是 unused1, unused2…等,目前源代码里面就是随机初始化的一个embeding.</p> 
<pre><code class="prism language-python">self<span class="token punctuation">.</span>lstm_head <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>
                    input_size<span class="token operator">=</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span>
                    hidden_size<span class="token operator">=</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>
                    num_layers<span class="token operator">=</span>num_layers<span class="token punctuation">,</span>
                    dropout<span class="token operator">=</span>lstm_dropout<span class="token punctuation">,</span>
                    bidirectional<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                    batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
  <span class="token punctuation">)</span>

self<span class="token punctuation">.</span>mlp_head <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
self<span class="token punctuation">.</span>mlp_head<span class="token punctuation">(</span>self<span class="token punctuation">.</span>lstm_head<span class="token punctuation">(</span>input_embeds<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>以上代码可清晰展示出prompt encoder的结构。</p> 
<p>P-Tuning V1 与 Prefix-Tuning 的区别：</p> 
<ul><li>Prefix Tuning 是将额外的 embedding 加在开头，看起来更像是模仿 Instruction 指令；而 P-Tuning 的位置则不固定。</li><li>Prefix Tuning 通过在每个 Attention 层都加入 Prefix Embedding 来增加额外的参数，通过 MLP 来初始化；而 P-Tuning 只是在输入的时候加入 Embedding，并通过 LSTM+MLP 来初始化。</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> peft <span class="token keyword">import</span> PromptTuningConfig<span class="token punctuation">,</span> get_peft_model

model_name_or_path <span class="token operator">=</span> <span class="token string">"./unsup-simcse-roberta-base"</span>
peft_type <span class="token operator">=</span> PeftType<span class="token punctuation">.</span>P_TUNING
lr <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span>
peft_config <span class="token operator">=</span> PromptEncoderConfig<span class="token punctuation">(</span>task_type<span class="token operator">=</span><span class="token string">"CAUSAL_LM"</span><span class="token punctuation">,</span> num_virtual_tokens<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> encoder_hidden_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_name_or_path<span class="token punctuation">,</span> return_dict<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> peft_config<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>print_trainable_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="PTuning_V2_130"></a>P-Tuning V2</h4> 
<p>论文《P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks》<br> P-Tuning v2 的目标就是要让 Prompt Tuning 能够在不同参数规模的预训练模型、针对不同下游任务的结果上都达到匹敌 Fine-tuning 的结果。</p> 
<p>Prompt Tuning 方法可能在这两个方面都存在局限性：</p> 
<ul><li>不同模型规模：Prompt Tuning 和 P-tuning 这两种方法都是在预训练模型参数规模够足够大时，才能达到和 Fine-tuning 类似的效果，而参数规模较小时效果则很差。<img src="https://images2.imgbox.com/d8/03/74xAbp7b_o.png" alt="在这里插入图片描述"></li><li>不同任务类型：Prompt Tuning 和 P-tuning 这两种方法在 sequence tagging 任务上表现都很差。</li></ul> 
<h6><a id="_139"></a>主要结构</h6> 
<p>相比 Prompt Tuning 和 P-tuning 的方法，P-tuning v2 方法在多层加入了 Prompts tokens 作为输入，带来两个方面的好处：</p> 
<ol><li> <p>带来更多可学习的参数（从 P-tuning 和 Prompt Tuning 的 0.1% 增加到0.1%-3%），同时也足够 parameter-efficient。</p> </li><li> <p>加入到更深层结构中的 Prompt 能给模型预测带来更直接的影响。</p> </li></ol> 
<p><img src="https://images2.imgbox.com/3c/aa/E9Bj0w3L_o.png" alt="在这里插入图片描述">v1到v2的可视化：蓝色部分为参数冻结，橙色部分为可训练部分</p> 
<h6><a id="_151"></a>几个关键设计因素</h6> 
<ul><li><strong>Reparameterization</strong>：Prefix Tuning 和 P-tuning 中都有 MLP 来构造可训练的 embedding。本文发现在自然语言理解领域，面对<strong>不同的任务</strong>以及<strong>不同的数据集</strong>，这种方法可能带来<strong>完全相反的结论</strong>。</li><li><strong>Prompt Length</strong>：不同的任务对应的最合适的 Prompt Length 不一样，比如<strong>简单分类</strong>任务下 l<strong>ength=20</strong> 最好，而<strong>复杂</strong>的<strong>任务</strong>需要<strong>更长</strong>的 <strong>Prompt Length。</strong></li><li><strong>Multi-task Learning</strong> 多任务对于 P-Tuning v2 是可选的，但可以利用它提供更好的初始化来进一步提高性能。</li><li><strong>Classification Head</strong> 使<strong>用 LM head 来预测动词是 Prompt Tuning 的核心</strong>，但在完整的数据设置中没有必要这样做，并且这样做与序列标记不兼容。P-tuning v2 采用和 BERT 一样的方式，在第一个 token 处应用随机初始化的分类头。</li></ul> 
<h6><a id="_158"></a>实验结果</h6> 
<ul><li>不同预训练模型大小下的表现，在小模型下取得与Full-finetuning相近的结果，并远远优于P-Tuning。</li><li>不同任务下的 P-Tuning v2 效果都很好，而 P-Tuning 和 Prompt Learning 效果不好；同时，采用多任务学习的方式能在多数任务上取得最好的结果。</li><li>Verbalizer with LM head v.s. [CLS] label with linear head，两种方式没有太明显的区别</li><li>Prompt depth，在加入相同层数的 Prompts 前提下，往更深层网络加效果大部分优于往更浅层网络。</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> peft <span class="token keyword">import</span> PromptTuningConfig<span class="token punctuation">,</span> get_peft_model

model_name_or_path <span class="token operator">=</span> <span class="token string">"./unsup-simcse-roberta-base"</span>
peft_type <span class="token operator">=</span> PeftType<span class="token punctuation">.</span>P_TUNING
lr <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span>
peft_config <span class="token operator">=</span> PrefixTuningConfig<span class="token punctuation">(</span>task_type<span class="token operator">=</span><span class="token string">"SEQ_CLS"</span><span class="token punctuation">,</span> num_virtual_tokens<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_name_or_path<span class="token punctuation">,</span> return_dict<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> peft_config<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>print_trainable_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="LoRA_176"></a>LoRA</h4> 
<p>现有的一些 PEFT 的方法还存在这样一些问题：</p> 
<ul><li>由于增加了模型的深度从而额外增加了模型推理的延时，如 Adapter 方法</li><li>Prompt 较难训练，同时减少了模型的可用序列长度，如 Prompt Tuning、Prefix Tuning、P-Tuning 方法</li><li>往往效率和质量不可兼得，效果差于 full-finetuning</li></ul> 
<p>Low-Rank Adaption（LoRA），设计了如下所示的结构，在涉及到矩阵相乘的模块，引入 A、B 这样两个低秩矩阵模块去模拟 Full-finetune 的过程，相当于只对语言模型中起关键作用的低秩本质维度进行更新。<br> <img src="https://images2.imgbox.com/58/b4/NVrcoFIo_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/1e/83/9gGT0bDV_o.png" alt="在这里插入图片描述">这么做就能完美解决以上存在的 3 个问题：</p> 
<ul><li>相比于原始的 Adapter 方法“额外”增加网络深度，必然会带来推理过程额外的延迟，该方法可以在推理阶段直接用训练好的 A、B 矩阵参数与原预训练模型的参数相加去替换原有预训练模型的参数，这样的话推理过程就相当于和 Full-finetune 一样，没有额外的计算量，从而不会带来性能的损失。</li><li>由于没有使用 Prompt 方式，自然不会存在 Prompt 方法带来的一系列问题。</li><li>该方法由于实际上相当于是用 LoRA 去模拟 Full-finetune 的过程，几乎不会带来任何训练效果的损失，后续的实验结果也证明了这一点。</li></ul> 
<pre><code>![在这里插入图片描述](https://img-blog.csdnimg.cn/dbfdf222640b48df9879b545944e4fe1.png)

```python
from peft import PromptTuningConfig, get_peft_model

model_name_or_path = "./unsup-simcse-roberta-base"
peft_type = peft_type = PeftType.LORA
lr = 3e-4
peft_config = LoraConfig(task_type="SEQ_CLS", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)
model = AutoModelForCausalLM.from_pretrained(model_name_or_path, return_dict=True)
model = get_peft_model(model, peft_config)
model.print_trainable_parameters()
</code></pre> 
<p><a href="https://huggingface.co/docs/peft/conceptual_guides/lora" rel="nofollow">https://huggingface.co/docs/peft/conceptual_guides/lora</a></p> 
<h3><a id="PETL__205"></a>PETL 大统一</h3> 
<h6><a id="_206"></a>通用形式</h6> 
<p><img src="https://images2.imgbox.com/2d/24/eDpVAuxY_o.png" alt="在这里插入图片描述">通过对 Prefix Tuning 的推导，得出了和 Adapter Tuning 以及 LoRA 形式一致的形式。</p> 
<p>更近一步地，可以将这些 Tuning 的方法统一在同一套框架下，<br> <img src="https://images2.imgbox.com/55/9c/CSXdOr1I_o.png" alt="在这里插入图片描述"><br> 包括这几大要素：<br> <img src="https://images2.imgbox.com/0f/f8/PduYRiyz_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_214"></a>典型应用：</h4> 
<ol><li>ChatGLM-Tuning ：一种平价的chatgpt实现方案，基于清华的 ChatGLM-6B + LoRA 进行finetune。</li><li>Alpaca-Lora：使用低秩自适应（LoRA）复现斯坦福羊驼的结果。Stanford Alpaca 是在 LLaMA 整个模型上微调，而 Alpaca-Lora 则是利用 Lora 技术，在冻结原模型 LLaMA 参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。由于这些新增参数数量较少，这样不仅微调的成本显著下降，还能获得和全模型微调类似的效果。</li><li>BLOOM-LORA：由于LLaMA的限制，我们尝试使用Alpaca-Lora重新实现BLOOM-LoRA。</li></ol> 
<h4><a id="_220"></a>参考</h4> 
<ul><li>LoRA: <a href="https://arxiv.org/pdf/2106.09685.pdf" rel="nofollow">LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS</a></li><li>Prefix Tuning: <a href="https://aclanthology.org/2021.acl-long.353/" rel="nofollow">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a>， <a href="https://arxiv.org/pdf/2110.07602.pdf" rel="nofollow"> P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</a></li><li>P-Tuning: <a href="https://arxiv.org/abs/2103.10385" rel="nofollow">GPT Understands, Too</a></li><li>Prompt Tuning: <a href="https://arxiv.org/abs/2104.08691" rel="nofollow">The Power of Scale for Parameter-Efficient Prompt Tuning</a></li><li>AdaLoRA: <a href="https://arxiv.org/abs/2303.10512" rel="nofollow">Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning</a></li><li><a href="https://huggingface.co/docs/peft/index" rel="nofollow">huggingface/doc/peft</a></li><li><a href="https://github.com/huggingface/peft">github.com/huggingface/peft</a></li><li><a href="https://articles.zsxq.com/id_il58nxrs9jxr.html" rel="nofollow">【LLMs学习】关于大模型实践的一些总结</a></li><li><a href="https://mp.weixin.qq.com/s/SrPn54JJYBtrkQcgj0VDXA" rel="nofollow">ChatGPT等大模型高效调参大法——PEFT库的算法简介</a></li><li><a href="https://mp.weixin.qq.com/s/E_0-skD3__w5jLGEJlDpoA" rel="nofollow">让天下没有难Tuning的大模型：PEFT技术简介</a></li></ul>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b88500383296735d3a93d21d08fc27e1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">RK3568的HDMI分辨率传递流程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/40248358cfd3d37c41a3340c3fa929f6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Docker安装Activemq</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>