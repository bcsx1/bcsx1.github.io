<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Flink1.16 发布新特性 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Flink1.16 发布新特性" />
<meta property="og:description" content="文章目录 引用前线速看更快更稳更易用：Flink自适应批处理能力演进01 Adaptive Batch Scheduler自动设置作业并行度02 Speculative Execution 发现和缓解热点机器对作业的影响03 Hybrid Shuffle 提供资源利用率和数据传输率04 Dynamic Partition Pruning 过滤无用数据，提高处理效率 Flink 1.16 Preview: Hive SQL如何平迁到Flink SQL01 迁移的动机02 迁移的挑战03 如何迁移04 demo 基于log的通用增量 Checkpoint01 checkpoint 性能优化之路02 解析changelog03 一览State/Checkpoint优化04 总结 Flink CDC &#43; Kafka加速业务实时化01 Flink CDC技术02 Flink&#43;Kafka实时数据集成方案03 Demo：Flink&#43;Kafka实现CDC数据的实时集成和实时分析 Flink Table Store典型应用场景01 介绍Flink Table Store02 应用场景03 Demo04 后续挑战 结语 引用 虽然flink1.16已经发布，但是小编在文章发布日查看了下官网，目前最新稳定版依然是flink1.15.2，生产要用最新版flink1.16的小伙伴，请慎重使用。
flink下载页
flink主页
Flink学习网
下面内容来源于Apache Flink Meetup 北京站，小编只是加以整理。
前线速看 统一API： 对比spark程序开发，flink一套应用开发即可重用在流批环境统一计算：适配多种数据源，可以在streaming warehouse整体概念下计算，一套计算引擎解决多种场景计算统一存储：table store不仅对flink提供存储能力，对spark外部计算引擎同样可以；同时flink也适配了各式的存储中间件 上图着重强调了中国团队对flink1.16的贡献。
sql gateway这个功能超级强大，支持多租户，协议插件化，兼容hive生态，以后flink流批作业都可以通过sql gateway提交到集群了。
上图是状态存储改进。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/5d62efdb2669ae73b696bdb7ba8b8767/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-30T18:09:36+08:00" />
<meta property="article:modified_time" content="2022-09-30T18:09:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Flink1.16 发布新特性</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_2" rel="nofollow">引用</a></li><li><a href="#_9" rel="nofollow">前线速看</a></li><li><a href="#Flink_24" rel="nofollow">更快更稳更易用：Flink自适应批处理能力演进</a></li><li><ul><li><a href="#01_Adaptive_Batch_Scheduler_28" rel="nofollow">01 Adaptive Batch Scheduler自动设置作业并行度</a></li><li><a href="#02_Speculative_Execution__36" rel="nofollow">02 Speculative Execution 发现和缓解热点机器对作业的影响</a></li><li><a href="#03_Hybrid_Shuffle__45" rel="nofollow">03 Hybrid Shuffle 提供资源利用率和数据传输率</a></li><li><a href="#04_Dynamic_Partition_Pruning__53" rel="nofollow">04 Dynamic Partition Pruning 过滤无用数据，提高处理效率</a></li></ul> 
  </li><li><a href="#Flink_116_Preview_Hive_SQLFlink_SQL_65" rel="nofollow">Flink 1.16 Preview: Hive SQL如何平迁到Flink SQL</a></li><li><ul><li><a href="#01__66" rel="nofollow">01 迁移的动机</a></li><li><a href="#02__70" rel="nofollow">02 迁移的挑战</a></li><li><a href="#03__72" rel="nofollow">03 如何迁移</a></li><li><a href="#04_demo_83" rel="nofollow">04 demo</a></li></ul> 
  </li><li><a href="#log_Checkpoint_91" rel="nofollow">基于log的通用增量 Checkpoint</a></li><li><ul><li><a href="#01_checkpoint__95" rel="nofollow">01 checkpoint 性能优化之路</a></li><li><a href="#02_changelog_113" rel="nofollow">02 解析changelog</a></li><li><a href="#03_StateCheckpoint_131" rel="nofollow">03 一览State/Checkpoint优化</a></li><li><a href="#04__134" rel="nofollow">04 总结</a></li></ul> 
  </li><li><a href="#Flink_CDC__Kafka_137" rel="nofollow">Flink CDC + Kafka加速业务实时化</a></li><li><ul><li><a href="#01_Flink_CDC_140" rel="nofollow">01 Flink CDC技术</a></li><li><a href="#02_FlinkKafka_150" rel="nofollow">02 Flink+Kafka实时数据集成方案</a></li><li><a href="#03_DemoFlinkKafkaCDC_160" rel="nofollow">03 Demo：Flink+Kafka实现CDC数据的实时集成和实时分析</a></li></ul> 
  </li><li><a href="#Flink_Table_Store_165" rel="nofollow">Flink Table Store典型应用场景</a></li><li><ul><li><a href="#01_Flink_Table_Store_166" rel="nofollow">01 介绍Flink Table Store</a></li><li><a href="#02__176" rel="nofollow">02 应用场景</a></li><li><a href="#03_Demo_183" rel="nofollow">03 Demo</a></li><li><a href="#04__187" rel="nofollow">04 后续挑战</a></li></ul> 
  </li><li><a href="#_190" rel="nofollow">结语</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_2"></a>引用</h2> 
<blockquote> 
 <p>虽然flink1.16已经发布，但是小编在文章发布日查看了下官网，目前最新稳定版依然是flink1.15.2，生产要用最新版flink1.16的小伙伴，请慎重使用。<br> <a href="https://flink.apache.org/downloads.html" rel="nofollow">flink下载页</a><br> <a href="https://flink.apache.org" rel="nofollow">flink主页</a><br> <a href="https://flink-learning.org.cn/activity/detail/f30571911e47478ddf4047eeb518d796" rel="nofollow">Flink学习网</a><br> 下面内容来源于Apache Flink Meetup 北京站，小编只是加以整理。</p> 
</blockquote> 
<h2><a id="_9"></a>前线速看</h2> 
<p><img src="https://images2.imgbox.com/25/8c/6E7KyV9j_o.png" alt="在这里插入图片描述"></p> 
<ul><li>统一API： 对比spark程序开发，flink一套应用开发即可重用在流批环境</li><li>统一计算：适配多种数据源，可以在streaming warehouse整体概念下计算，一套计算引擎解决多种场景计算</li><li>统一存储：table store不仅对flink提供存储能力，对spark外部计算引擎同样可以；同时flink也适配了各式的存储中间件</li></ul> 
<p><img src="https://images2.imgbox.com/53/75/EEc0PUw4_o.png" alt="在这里插入图片描述"><br> 上图着重强调了中国团队对flink1.16的贡献。<br> <img src="https://images2.imgbox.com/00/f8/6bbbHWtt_o.png" alt="在这里插入图片描述"><br> sql gateway这个功能超级强大，支持多租户，协议插件化，兼容hive生态，以后flink流批作业都可以通过sql gateway提交到集群了。<br> <img src="https://images2.imgbox.com/bb/ce/y3NRFPiB_o.png" alt="在这里插入图片描述"><br> 上图是状态存储改进。<br> <img src="https://images2.imgbox.com/5f/09/3vNTdxMs_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/17/e1/8CywcX1r_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Flink_24"></a>更快更稳更易用：Flink自适应批处理能力演进</h2> 
<p><img src="https://images2.imgbox.com/67/5c/OqZ2eHit_o.png" alt="在这里插入图片描述"><br> 那么具体有哪些优化呢？</p> 
<h3><a id="01_Adaptive_Batch_Scheduler_28"></a>01 Adaptive Batch Scheduler自动设置作业并行度</h3> 
<p><img src="https://images2.imgbox.com/31/1d/QVDdLOdK_o.png" alt="在这里插入图片描述"><br> 综上，上面的问题，我们都思考下，怎么解决？<br> <img src="https://images2.imgbox.com/75/07/YfC6OP5l_o.png" alt="在这里插入图片描述"><br> 那么自适应批量调度<br> <img src="https://images2.imgbox.com/de/fd/VQWWrp2p_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="02_Speculative_Execution__36"></a>02 Speculative Execution 发现和缓解热点机器对作业的影响</h3> 
<p><img src="https://images2.imgbox.com/0f/60/Xy2exeB1_o.png" alt="在这里插入图片描述"><br> 从上面 现状和问题，可以看到下面的图片flink批处理推出了推测执行，这也是flink1.16新推出的机制。<br> <img src="https://images2.imgbox.com/ee/26/G0b88FwG_o.png" alt="在这里插入图片描述"><br> 下面的推测执行在flink框架层面的执行范围，目前知道的是sink层面是不支持推测机制；如果自定义source事件，SplitEnumerator需要实现SupportsHandleExecutionAttemptSourceEvent接口<br> <img src="https://images2.imgbox.com/93/bf/BxxoxV5i_o.png" alt="在这里插入图片描述"><br> 下图中是推测执行的web ui，后续会支持sink推测执行。<br> <img src="https://images2.imgbox.com/36/41/55Vv8lFI_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="03_Hybrid_Shuffle__45"></a>03 Hybrid Shuffle 提供资源利用率和数据传输率</h3> 
<p><img src="https://images2.imgbox.com/cf/66/c1jjEdRC_o.png" alt="在这里插入图片描述"><br> 那么怎么集合流和批两种的优势呢，其实就是怎样结合流的快和批的稳定，Hybrid Shufle应运而生<br> <img src="https://images2.imgbox.com/6b/f0/8kp2pmQH_o.png" alt="在这里插入图片描述"><br> Hybrid Shuffle的目标时 具备资源自适应的能力，资源充足时，直接流式shuffle，资源不足时，又具备批量shuffle的稳定性，用户完全无感（我这里抱由怀疑态度）。<br> <img src="https://images2.imgbox.com/29/5b/ivBUeWkD_o.png" alt="在这里插入图片描述"><br> Hybrid Shuffle提供了两种落盘策略，从上图中可以看出，性能是有提升，但是提升有限，期待后面有质的飞跃。</p> 
<h3><a id="04_Dynamic_Partition_Pruning__53"></a>04 Dynamic Partition Pruning 过滤无用数据，提高处理效率</h3> 
<p><img src="https://images2.imgbox.com/2a/25/Bi7yYVxO_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ee/69/hkMhyOZf_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/7a/cb/91n9PnQZ_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/f4/21/caqrFXE1_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/26/27/Fkg8JhPJ_o.png" alt="在这里插入图片描述"><br> 从上图中可以看出DynmaicFilter DataCollector左边和右边的scan是没有依赖关系的，OrderEnforcer就是建立两者之间的依赖关系，仅是为了runtime调度器他们之前是有数据依赖的，从而确保调度先后顺序是没毛病的。<br> <img src="https://images2.imgbox.com/96/85/Fg2oF5tH_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/95/a6/JGpl1lzv_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a2/71/3xM2Qs4m_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Flink_116_Preview_Hive_SQLFlink_SQL_65"></a>Flink 1.16 Preview: Hive SQL如何平迁到Flink SQL</h2> 
<h3><a id="01__66"></a>01 迁移的动机</h3> 
<p>为什么Flink要做hive sql迁移？<br> 离线用户吸引离线数仓用户，打磨批引擎，螺旋迭代；离线业务开发门槛降低用户flink开发离线业务的门槛；hive生态工具生态是最高的壁垒，融入离线生态；流批一体 推动业界，先统一殷勤，后统一API。<br> <img src="https://images2.imgbox.com/64/75/HmaIUo6b_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="02__70"></a>02 迁移的挑战</h3> 
<p><img src="https://images2.imgbox.com/7a/8e/twdR56FU_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="03__72"></a>03 如何迁移</h3> 
<p>复用hive语法<br> <img src="https://images2.imgbox.com/dd/c2/Y1wSZ2vL_o.png" alt="在这里插入图片描述"><br> hivesql到hive parser 再到flink relnode做了大量的工作，目的为了更好的与flinksql引擎的兼容。<br> hive语法兼容：Flink1.16 hive语法兼容度从85%提升至94.1%（Hive qtest 12k测试集）。</p> 
<p><img src="https://images2.imgbox.com/24/85/QmRdoFjO_o.png" alt="在这里插入图片描述"><br> hivesql 迁移在快手的实践<br> <img src="https://images2.imgbox.com/f9/03/woYY7TIb_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="04_demo_83"></a>04 demo</h3> 
<p><img src="https://images2.imgbox.com/2f/74/p3Ah8SN5_o.png" alt="在这里插入图片描述"><br> 看了大佬讲了这个功能，感觉简单的端到端的流批操作都很简单，但是大数据量下会不会出现什么问题，有待本人验证。</p> 
<p><img src="https://images2.imgbox.com/45/63/E6JypNu2_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/57/f8/RbrsOSs4_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="log_Checkpoint_91"></a>基于log的通用增量 Checkpoint</h2> 
<p>什么是checkpoint ，通常会想到状态持久化，flink独有的特性，轻量且快，容错，本地格式化，快速恢复。<br> <img src="https://images2.imgbox.com/ea/f8/nYk4Y8aw_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="01_checkpoint__95"></a>01 checkpoint 性能优化之路</h3> 
<p><img src="https://images2.imgbox.com/6c/be/xpK7oCCN_o.png" alt="在这里插入图片描述"><br> checkpoint不同版本之间的优化</p> 
<ul><li>0.9 轻量级异步的snapshot算法，把barrier作为一个特殊的record在graph中流动，同时将耗时较大的文件上传等工作放到异步的过程当中进行，这样的话对主流程的影响是变的非常小的。</li><li>1.0 当中支持了RocksDB StateBackend，对于大状态下的存储提供了很好的支持。</li><li>1.3 当中实现了基于RocksDB incremental checkpoint，这个机制是进一步提升了在异步阶段的checkpoint的性能。</li><li>1.11 当中引入了Unaligned Checkpoint</li><li>1.13 当中又引入了Unaligned Checkpoint （Production-ready），在一些场景下对于barrier对齐会有瓶颈的作业的话，基于Unaligned Checkpoint 以及 buffer debloating我们可以甚至让一些作业在反压比较严重的情况下依然可以做出Checkpoint</li><li>1.14 当中又加入了buffer debloating的概念，上面1.13中介绍的buffer debloating就是此概念，通过调整buffer debloating的大小来加速barrier的流动，进一步加速checkpoint的完成，而对 unaligned checkpoint去进一步减少 unaligned checkpoint过程中存储的数据量</li><li>1.15 1.16 当中引入了changelog backend，这个功能就是我们本次学习的重点，它的机制就是进一步的通过一个更通用的increment的checkpoint机制更进一步异步的减少开销，提升checkpoint的异步部分的性能</li></ul> 
<p><img src="https://images2.imgbox.com/2b/2d/uNcr1xo0_o.png" alt="在这里插入图片描述"><br> 我们可以通过checkpoint链路上看这些优化技术在graph中的体现，在触发checkpoint的时候，我们知道source阶段barrier随着graph进行流动，然后在刚打开了buffer debloating的时候flink会通过计算数据吞吐等方式来动态调整network buffer的大小来加速barrier的传递，而当barrier到达state节点的时候，如果是aligned checkpoint那么就会等待barrier的对齐,如果是unaligned checkpoint的话会直接将buffer当中的内容存储到hdfs当中不会阻塞，然后同时触发statebackend上的checkpoint的过程 ，buffer的传输的话就像上图中虚线所示，然后在statebackend内部再触发checkpoint的时候基于异步的checkpoint算法，在异步部分会进行一个文件的上传，如上图实现所示，开启了rocksdb increment的时候，会做些增量文件的上传，在这次介绍changelog statebackend的部分的话，我们可以看到最下面的虚线 我们会把原来的statebackend的异步上传部分和changelog进行解耦，然后会有一个独立的上传hdfs的过程，这个过程会在后面进行详细介绍。</p> 
<p><img src="https://images2.imgbox.com/ba/46/IB62H9bw_o.png" alt="在这里插入图片描述"><br> 上图中的指标会让你对checkpoint有一些直观的感受，包括像端到端延迟，这个是对checkppoint最直观的性能的一个感受。</p> 
<h3><a id="02_changelog_113"></a>02 解析changelog</h3> 
<p><img src="https://images2.imgbox.com/b9/18/OTiW3Gjh_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/59/64/aWfvYVrY_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/51/8a/v76A7aCO_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/bb/97/QDy6xgsg_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d3/a8/IXOyBv5b_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/8a/d3/9qZvkugO_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e8/ff/ydqGmpWh_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/55/23/ZDhiFEd9_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/2a/ae/cgDVMlEt_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/01/98/doaGpyA9_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/9c/62/PzvD0eTb_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/51/b6/C3XdT5gU_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/cd/73/ertsIqw1_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/1f/ff/Sq3QmrzE_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="03_StateCheckpoint_131"></a>03 一览State/Checkpoint优化</h3> 
<p><img src="https://images2.imgbox.com/ec/62/GIIbxxYJ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="04__134"></a>04 总结</h3> 
<p><img src="https://images2.imgbox.com/ce/ba/VPZDRz4r_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Flink_CDC__Kafka_137"></a>Flink CDC + Kafka加速业务实时化</h2> 
<p>广义的概念上，能够捕获数据变更的技术，我们都可以称为CDC （Change Data Capture）。通常我们说的CDC技术主要面向数据库的变更，是一种用于捕获数据库中数据变更的技术。</p> 
<h3><a id="01_Flink_CDC_140"></a>01 Flink CDC技术</h3> 
<p>主要用到的场景有以下这些：<br> <img src="https://images2.imgbox.com/cf/46/Am2gv54u_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6e/3b/fU76wjCW_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/88/c1/UuUtkoF2_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0f/3e/v1Kqp6MS_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/12/5b/ESP1mnLd_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/99/9a/l15nJTQM_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/98/bc/0FHpQutD_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="02_FlinkKafka_150"></a>02 Flink+Kafka实时数据集成方案</h3> 
<p><img src="https://images2.imgbox.com/70/22/nTNy85cB_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/40/ef/9coOfTZZ_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d0/16/49Xyz92X_o.png" alt="在这里插入图片描述"><br> 目前CDAS是阿里云商业化的功能，该部分代码在写这篇文章时暂时没有开源。</p> 
<p><img src="https://images2.imgbox.com/59/18/DxXa8aWX_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6f/be/BksJuwth_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b3/6f/QFrvciuC_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="03_DemoFlinkKafkaCDC_160"></a>03 Demo：Flink+Kafka实现CDC数据的实时集成和实时分析</h3> 
<p><img src="https://images2.imgbox.com/46/26/fbBuMeNX_o.png" alt="商用才有此功能"><br> 此处省略，有想看的请自行按照上面url查看。</p> 
<h2><a id="Flink_Table_Store_165"></a>Flink Table Store典型应用场景</h2> 
<h3><a id="01_Flink_Table_Store_166"></a>01 介绍Flink Table Store</h3> 
<p><img src="https://images2.imgbox.com/37/f8/vPtXxBMV_o.png" alt="在这里插入图片描述"><br> 其实我觉得数仓分为实时和离线最好的状态（个人想法）。</p> 
<p><img src="https://images2.imgbox.com/9e/95/odaeecJd_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/1c/ee/evWNrru5_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/cf/5b/Sq5e9PCj_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/99/56/769E7um3_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="02__176"></a>02 应用场景</h3> 
<p><img src="https://images2.imgbox.com/50/46/pQ4xQ9S4_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/35/de/IqG9hdsN_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e4/97/01zHjvbo_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/76/14/5l3fnpTI_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="03_Demo_183"></a>03 Demo</h3> 
<p><img src="https://images2.imgbox.com/cc/38/M4CWburu_o.png" alt="在这里插入图片描述"><br> 后面自己去看，去听吧，一个小姐姐讲的，声音很好听。。。</p> 
<h3><a id="04__187"></a>04 后续挑战</h3> 
<p><img src="https://images2.imgbox.com/24/7d/x9OTORvy_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_190"></a>结语</h2> 
<p>meetup看了两遍，第一遍感觉听着讲change log那节，比较晦涩，今天又全部听了一遍，感觉对checkpoint的历史节点上优化又有了更深一步的理解。</p> 
<p>还有一个感觉就是flink在实时方向已经一超多强了，社区现在除了致力于实时特性更加稳定，更强大，也在尝试着内卷flink。</p> 
<p>我始终抱着敬畏的态度学习flink，每一个组件背后都是很多前辈，老师的辛勤的付出，向这些flink等开源人致敬。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/986058f682632cfc1938c4f31ed0662f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">一文讲清楚Nginx location匹配优先级规则</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c1829545a11d2c861c10e19e128eaa52/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">NNDL 实验五 前馈神经网络（1）二分类任务</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>