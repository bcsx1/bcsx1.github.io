<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>博弈论学习笔记（3）——完全信息动态博弈 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="博弈论学习笔记（3）——完全信息动态博弈" />
<meta property="og:description" content="前言 在这个部分，我们学习的是完全信息动态博弈。主要内容包括扩展式博弈、子博弈精炼Nash均衡、重复博弈和子博弈精炼Nash均衡的应用。
一、扩展式博弈 1、扩展式博弈 1）扩展式博弈是什么 扩展式博弈是博弈问题的一种规范性描述，扩展式博弈注重对参与人在博弈过程中所遇到决策问题的序列结构的详细分析。
2）扩展式博弈包含的要素 3）博弈树是什么 博弈树是扩展式博弈中简单直观的一种描述方式。其由结和有向枝构成。
4）信息集是什么 对于信息集的描述，注意区分以下三种情况：
5）完美记忆是什么 2、扩展式博弈的战略及其Nash均衡 1）扩展式博弈中的战略 参与人的战略就是参与人在博弈中的行动规则，它规定了参与人在博弈中每一种轮到自己行动的情形下，应该采取的行动。而在博弈树中，参与人在博弈中每一种轮到自己行动的情形又可以用一个信息集来表示，因此，参与人在扩展式博弈中的战略实际上就是参与人在每个信息集上的行动规则。
2）由扩展式描述得到战略式描述 3、战略式博弈 VS 扩展式博弈 1）战略式博弈本质上是静态模型 战略式假设所有的参与人同时选择战略并得到博弈的结果，至于博弈中参与人何时行动、行动时又如何行动等等，战略式博弈并不考虑。
2）扩张式博弈本质上是动态模型 扩展式博弈不仅直观地给出了博弈的结果，而且还对博弈的过程进行详尽的描述。
可以给出博弈中参与人的行动顺序，以及参与人行动时的决策环境和行动空间。
3）两种博弈描述形式的比较 给出博弈问题的扩展式描述(如博弈树)，我们就可得到博弈问题的战略式描述。
给出博弈问题的战略式描述，我们也能构造出博弈问题的扩展式描述。
二、子博弈精炼Nash均衡 1、子博弈精炼Nash均衡 1）将Nash均衡作为扩展式博弈的解会有什么问题 Nash均衡是一个静态均衡，将Nash均衡作为扩展式博弈的解同样会遇到Nash均衡的多重性问题，而且在多个Nash均衡中有些明显不合理。
2）子博弈的概念 子博弈就是原博弈的一部分，它始于原博弈中一个位于单结信息集中的决策结 X ，并由决策结 X 及其后续结共同组成。
子博弈可以作为一个独立的博弈进行分析，并且与原博弈具有相同的信息结构。
3）子博弈精炼Nash均衡的定义 4）Kuhn定理 每个有限的扩展式博弈都存在子博弈精炼Nash均衡。
虽然Kuhn定理保证了子博弈精炼Nash均衡的存在性，但Kuhn定理并不能确保我们所讨论的有限的扩展式博弈都只存在惟一的子博弈精炼Nash均衡。
5）解的多重性问题 2、子博弈精炼Nash均衡的求解 1）求解有限扩展式博弈的一般步骤 找出博弈的所有子博弈；
按照博弈进程的“反方向”逐一求解各个子博弈，即最先求解最底层的子博弈，再求解上一层的子博弈，......，直至原博弈。也就是说，在求解每一个子博弈时，该子博弈要么不含有其它任何子博弈，要么所含子博弈都已被求解。
2）逆向归纳法 3）完美信息与完全信息 4)子博弈精炼Nash均衡 VS Nash均衡 3、承诺行动与要挟诉讼 1）承诺行动 承诺行动就是在博弈开始之前参与人采取的某种改变自己支付或行动空间的行动，该行动可使原本不可信的威胁变得可信。
在许多情况下，承诺行动对参与人来讲是有利的，因为它能使博弈的精炼均衡发生有利于自己的改变。
需要注意的是，参与人的承诺行动是有成本的（沉没成本），否则这种承诺就不可信。
2）要挟诉讼 所谓要挟诉讼是指那种原告几乎不可能胜诉而其惟一的目的可能是希望通过私了得到一笔赔偿的诉讼。
博弈的结果似乎与人们观测到的现实并不相符，因为现实中人们常常看到各种“要挟”的发生。在上述模型中，“要挟”之所以没有成果，关键在于原告将会起诉的威胁并不可信。
原告需要采取承诺行动，来使自己的威胁变得可信。
具体的扩展式博弈过程详见PPT。
4、子博弈精炼Nash均衡的合理性讨论 1）与人们直觉的差异 2）逆向归纳法对理性的要求 如同前面所定义的博弈的解一样，子博弈精炼Nash均衡不仅要求“参与人完全理性”，而且要求“参与人完全理性”为共同知识，否则就无法使用逆向归纳法求解子博弈精炼Nash均衡。
三、重复博弈 1、有限重复博弈 1）重复博弈的例子 多阶段的动态博弈，在博弈的每个阶段，重复同样的博弈。重复博弈关心的是将来可信的威胁或承诺如何影响到当前的行动。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/17c2befa70edaba76508ecf102a1d626/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-31T22:58:40+08:00" />
<meta property="article:modified_time" content="2023-10-31T22:58:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">博弈论学习笔记（3）——完全信息动态博弈</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>前言</h2> 
<blockquote> 
 <p>在这个部分，我们学习的是完全信息动态博弈。主要内容包括扩展式博弈、子博弈精炼Nash均衡、重复博弈和子博弈精炼Nash均衡的应用。</p> 
</blockquote> 
<h2>一、扩展式博弈</h2> 
<h3>1、扩展式博弈</h3> 
<h5>1）扩展式博弈是什么</h5> 
<p>扩展式博弈是博弈问题的一种规范性描述，扩展式博弈注重对参与人在博弈过程中所遇到决策问题的序列结构的详细分析。</p> 
<h5>2）扩展式博弈包含的要素</h5> 
<p><img alt="" height="483" src="https://images2.imgbox.com/7d/6b/6kjh6K0o_o.png" width="671"></p> 
<h5>3）博弈树是什么</h5> 
<p>博弈树是扩展式博弈中简单直观的一种描述方式。其由结和有向枝构成。</p> 
<h5>4）信息集是什么</h5> 
<p><img alt="" height="487" src="https://images2.imgbox.com/04/8e/wnd1m0Jb_o.png" width="687"></p> 
<p><img alt="" height="486" src="https://images2.imgbox.com/ad/a0/Yzn9wrer_o.png" width="678"></p> 
<p>对于信息集的描述，注意区分以下三种情况：</p> 
<p><img alt="" height="483" src="https://images2.imgbox.com/00/63/4JyTFJQl_o.png" width="671"></p> 
<p><img alt="" height="481" src="https://images2.imgbox.com/7c/92/7TPnrPiL_o.png" width="669"></p> 
<p><img alt="" height="483" src="https://images2.imgbox.com/38/b9/YkxjNBMr_o.png" width="674"></p> 
<h5>5）完美记忆是什么</h5> 
<p><img alt="" height="485" src="https://images2.imgbox.com/d2/7c/UxfTAmKY_o.png" width="676"></p> 
<h3>2、扩展式博弈的战略及其Nash均衡</h3> 
<h5>1）扩展式博弈中的战略</h5> 
<p>参与人的战略就是参与人在博弈中的行动规则，它规定了参与人在博弈中每一种轮到自己行动的情形下，应该采取的行动。而在博弈树中，参与人在博弈中每一种轮到自己行动的情形又可以用一个信息集来表示，因此，参与人在扩展式博弈中的战略实际上就是参与人在每个信息集上的行动规则。</p> 
<p><img alt="" height="481" src="https://images2.imgbox.com/fa/79/VXNFOaAS_o.png" width="681"></p> 
<h5>2）由扩展式描述得到战略式描述</h5> 
<p><img alt="" height="483" src="https://images2.imgbox.com/f5/fa/b6urDozh_o.png" width="672"></p> 
<h3>3、战略式博弈 <strong>VS</strong> 扩展式博弈</h3> 
<h5>1）战略式博弈本质上是静态模型</h5> 
<p>战略式假设所有的参与人同时选择战略并得到博弈的结果，至于博弈中参与人何时行动、行动时又如何行动等等，战略式博弈并不考虑。</p> 
<p><img alt="" height="480" src="https://images2.imgbox.com/56/9c/SwM5pKLe_o.png" width="679"></p> 
<h5>2）扩张式博弈本质上是动态模型</h5> 
<ul><li> <p>扩展式博弈不仅直观地给出了博弈的结果，而且还对博弈的过程进行详尽的描述。</p> </li><li> <p>可以给出博弈中参与人的行动顺序，以及参与人行动时的决策环境和行动空间。</p> </li></ul> 
<h5>3）两种博弈描述形式的比较</h5> 
<ul><li> <p>给出博弈问题的扩展式描述(如博弈树)，我们就可得到博弈问题的战略式描述。</p> </li><li> <p>给出博弈问题的战略式描述，我们也能构造出博弈问题的扩展式描述。</p> </li></ul> 
<p><img alt="" height="482" src="https://images2.imgbox.com/25/e9/0X0ttOeE_o.png" width="673"></p> 
<p><img alt="" height="479" src="https://images2.imgbox.com/19/b8/Go8b2CPF_o.png" width="670"></p> 
<p><img alt="" height="487" src="https://images2.imgbox.com/bd/4e/uqB84EXO_o.png" width="673"></p> 
<h2>二、子博弈精炼Nash均衡</h2> 
<h3>1、子博弈精炼Nash均衡</h3> 
<h5>1）将Nash均衡作为扩展式博弈的解会有什么问题</h5> 
<p>Nash均衡是一个静态均衡，将Nash均衡作为扩展式博弈的解同样会遇到Nash均衡的多重性问题，而且在多个Nash均衡中有些明显不合理。</p> 
<h5>2）子博弈的概念</h5> 
<ul><li> <p>子博弈就是原博弈的一部分，它始于原博弈中一个位于单结信息集中的决策结 X ，并由决策结 X 及其后续结共同组成。</p> </li><li> <p>子博弈可以作为一个独立的博弈进行分析，并且与原博弈具有相同的信息结构。</p> </li></ul> 
<p><img alt="" height="485" src="https://images2.imgbox.com/1d/3f/L9ufQ88i_o.png" width="675"></p> 
<p><img alt="" height="487" src="https://images2.imgbox.com/f5/2a/cpArV8Tu_o.png" width="685"></p> 
<h5>3）子博弈精炼Nash均衡的定义</h5> 
<p><img alt="" height="488" src="https://images2.imgbox.com/08/78/qrBD8gxt_o.png" width="681"></p> 
<p><img alt="" height="483" src="https://images2.imgbox.com/e1/5a/qds6jiRD_o.png" width="673"></p> 
<h5>4）Kuhn定理</h5> 
<p><strong>每个有限的扩展式博弈都存在子博弈精炼Nash均衡。</strong></p> 
<p>虽然Kuhn定理保证了子博弈精炼Nash均衡的存在性，但Kuhn定理<strong>并不能确保我们所讨论的有限的扩展式博弈都只存在惟一的子博弈精炼Nash均衡。</strong></p> 
<h5>5）解的多重性问题</h5> 
<p><img alt="" height="487" src="https://images2.imgbox.com/5f/a9/sBYykXJr_o.png" width="674"></p> 
<h3>2、子博弈精炼Nash均衡的求解</h3> 
<h5>1）求解有限扩展式博弈的一般步骤</h5> 
<ol><li> <p>找出博弈的所有子博弈；</p> </li><li> <p>按照博弈进程的“反方向”逐一求解各个子博弈，即最先求解最底层的子博弈，再求解上一层的子博弈，......，直至原博弈。也就是说，在求解每一个子博弈时，该子博弈要么不含有其它任何子博弈，要么所含子博弈都已被求解。</p> </li></ol> 
<h5>2）逆向归纳法</h5> 
<p><img alt="" height="483" src="https://images2.imgbox.com/b0/ff/mCgxrCbE_o.png" width="677"></p> 
<p><img alt="" height="479" src="https://images2.imgbox.com/b8/82/YSvK82A2_o.png" width="674"></p> 
<p><img alt="" height="483" src="https://images2.imgbox.com/2d/36/CBpHDW52_o.png" width="677"></p> 
<h5>3）完美信息与完全信息</h5> 
<p><img alt="" height="482" src="https://images2.imgbox.com/04/92/npc4F1SY_o.png" width="676"></p> 
<p><img alt="" height="482" src="https://images2.imgbox.com/01/1d/LCTuXRB2_o.png" width="672"></p> 
<h5>4)子博弈精炼Nash均衡 VS Nash均衡</h5> 
<p><img alt="" height="484" src="https://images2.imgbox.com/70/98/HFOyRdcS_o.png" width="670"></p> 
<p><img alt="" height="484" src="https://images2.imgbox.com/16/7c/NHf8iSRj_o.png" width="665"></p> 
<h3>3、承诺行动与要挟诉讼</h3> 
<h5>1）承诺行动</h5> 
<p><strong>承诺行动就是在博弈开始之前参与人采取的某种</strong><strong>改变自己支付或行动空间</strong><strong>的行动，该行动可</strong><strong>使原本不可信的威胁变得可信</strong><strong>。</strong></p> 
<ul><li> <p>在许多情况下，承诺行动对参与人来讲是有利的，因为它能使博弈的精炼均衡发生有利于自己的改变。</p> </li><li> <p>需要注意的是，参与人的承诺行动是有成本的（沉没成本），否则这种承诺就不可信。</p> </li></ul> 
<h5>2）要挟诉讼</h5> 
<p>所谓要挟诉讼是指那种<strong>原告几乎不可能胜诉</strong>而其惟一的目的可能是<strong>希望通过私了得到一笔赔偿</strong>的诉讼。</p> 
<p><img alt="" height="482" src="https://images2.imgbox.com/89/37/u8GwBICG_o.png" width="669"></p> 
<p><img alt="" height="485" src="https://images2.imgbox.com/13/90/EArWnNSp_o.png" width="673"></p> 
<p><img alt="" height="200" src="https://images2.imgbox.com/5e/7f/dtUSte35_o.png" width="591"></p> 
<p>博弈的结果似乎与人们观测到的现实并不相符，因为现实中人们常常看到各种“要挟”的发生。在上述模型中，“要挟”之所以没有成果，关键在于原告将会起诉的威胁并不可信。</p> 
<p>原告需要采取<strong>承诺行动</strong>，来使自己的威胁变得可信。</p> 
<p>具体的扩展式博弈过程详见PPT。</p> 
<h3>4、子博弈精炼Nash均衡的合理性讨论</h3> 
<h5>1）与人们直觉的差异</h5> 
<p><img alt="" height="487" src="https://images2.imgbox.com/28/74/TgLMQ9Sd_o.png" width="675"></p> 
<p><img alt="" height="481" src="https://images2.imgbox.com/9d/6d/JAdjnIsd_o.png" width="676"></p> 
<h5>2）逆向归纳法对理性的要求</h5> 
<p>如同前面所定义的博弈的解一样，子博弈精炼Nash均衡<strong>不仅要求“参与人完全理性”</strong>，而且<strong>要求“参与人完全理性”为共同知识</strong>，否则就无法使用逆向归纳法求解子博弈精炼Nash均衡。</p> 
<h2>三、重复博弈</h2> 
<h3>1、有限重复博弈</h3> 
<h5>1）重复博弈的例子</h5> 
<p>多阶段的动态博弈，在博弈的每个阶段，重复同样的博弈。重复博弈关心的是将来可信的威胁或承诺如何影响到当前的行动。</p> 
<p><img alt="" height="290" src="https://images2.imgbox.com/de/6a/kn87psC9_o.png" width="638"></p> 
<p><img alt="" height="299" src="https://images2.imgbox.com/e8/4a/cXp9OaPV_o.png" width="642"></p> 
<p><img alt="" height="488" src="https://images2.imgbox.com/c1/fd/Y3QFnBq9_o.png" width="698"></p> 
<p><img alt="" height="288" src="https://images2.imgbox.com/b6/7e/DWiLVVuE_o.png" width="592"></p> 
<h5>2）重复博弈的定义</h5> 
<p><img alt="" height="485" src="https://images2.imgbox.com/e0/48/B6ImgsGW_o.png" width="677"></p> 
<h5>3）重复博弈的特征</h5> 
<p><img alt="" height="484" src="https://images2.imgbox.com/65/e8/CQNSmI4P_o.png" width="669"></p> 
<h5>4）有限重复博弈解唯一性定理</h5> 
<p><img alt="" height="486" src="https://images2.imgbox.com/3a/95/d608DHPR_o.png" width="676"></p> 
<h5>5）触发策略</h5> 
<p><strong>明确触发策略的定义，掌握触发策略的构造</strong></p> 
<blockquote> 
 <p>在博弈论中，触发策略（Trigger Strategy）是指参与者在多次博弈中如何作出决策的一种策略。它基于一个前提条件，即当某个事件或信号（触发器）被触发时，参与者会采取特定的行动。</p> 
 <p>具体来说，触发策略通常用于描述在重复博弈中的行为模式。在这种情况下，每个参与者可以选择在每轮博弈中采取不同的策略。触发策略则是一种基于触发事件的约定，一旦触发事件发生，所有参与者都会采取预定的行动，而无需重新计算和选择策略。</p> 
 <p>触发策略的关键是确定触发事件以及参与者对该事件的响应。触发事件可以是其他参与者的特定行动、某种外部环境变化或是达到某个特定的状态。一旦触发事件发生，参与者会根据预先确定的策略来采取行动，而不会再进行重新选择。</p> 
 <p>通过使用触发策略，参与者可以在博弈中建立可靠的合作或对抗方式，并相互约束对方的行为。触发策略可以为参与者提供稳定的行为模式和预期结果，从而降低信息不完全或不确定性所带来的影响。</p> 
 <p>总之，触发策略在博弈论中描述了参与者在多次博弈中如何根据特定事件或信号来作出决策的策略。它通过约定一旦触发事件发生，参与者会采取预先确定的行动，从而建立稳定的合作或对抗关系。</p> 
</blockquote> 
<p><strong>【例子】</strong></p> 
<p><img alt="" height="484" src="https://images2.imgbox.com/e3/ce/qoXTy6jM_o.png" width="672"></p> 
<p><img alt="" height="481" src="https://images2.imgbox.com/f9/1a/Ptpfl9PR_o.png" width="680"></p> 
<p><img alt="" height="482" src="https://images2.imgbox.com/ef/47/zrlTEf74_o.png" width="675"></p> 
<h5>6）承诺或威胁的可信性</h5> 
<p><img alt="" height="482" src="https://images2.imgbox.com/d5/c5/C5tHKwkH_o.png" width="674"></p> 
<p><img alt="" height="485" src="https://images2.imgbox.com/c1/e1/8eDNhgkP_o.png" width="671"></p> 
<h3>2、无限重复博弈</h3> 
<h5>1）无限重复博弈的定义</h5> 
<p><img alt="" height="477" src="https://images2.imgbox.com/d4/99/i9KoC0Qw_o.png" width="675"></p> 
<h5>2）无限重复博弈 VS 有限重复博弈</h5> 
<p><img alt="" height="481" src="https://images2.imgbox.com/89/46/LemI1BfJ_o.png" width="677"></p> 
<p><img alt="" height="477" src="https://images2.imgbox.com/63/fe/tC5yGAhL_o.png" width="676"></p> 
<p><img alt="" height="481" src="https://images2.imgbox.com/23/a9/I6kOPOCY_o.png" width="671"></p> 
<p><strong>【二者的区别】</strong></p> 
<ul><li> <p>在有限重复博弈中，参与人在G(T)中的收益既可以是各阶段博弈收益的简单叠加，也可以是各阶段博弈收益的贴现；无限重复博弈中，参与人的收益只能是在无限次的阶段博弈中多的收益的贴现。</p> </li><li> <p>对于阶段博弈为上述博弈的有限重复博弈，合作不可能形成；但对于无限重复博弈，在一定的贴现率下，合作有可能形成。</p> </li></ul> 
<h5>3）贴现率的定义及计算</h5> 
<p><strong>【</strong><strong>贴现率</strong><strong>的定义】</strong></p> 
<blockquote> 
 <p>在博弈论中，贴现率（Discount Rate）是指用于对未来效用或收益进行折现（discounting）的利率。它是一个经济概念，用于衡量时间价值和风险的权衡。</p> 
 <p>在博弈论中，贴现率主要应用于序贯博弈（Sequential Games），其中参与者需要在不同的时间点做出决策。贴现率被用来对未来效用或收益进行折现，以反映人们在计算效用或收益时对时间的偏好和风险考虑。</p> 
 <p>具体来说，贴现率表示在将来获得的效用或收益相对于当前时刻的价值。较低的贴现率意味着人们更倾向于将未来的效用或收益视为更有价值，较高的贴现率意味着人们更倾向于将近期的效用或收益视为更有价值。</p> 
 <p>通过应用贴现率，人们可以将未来的效用或收益转化为等价的当前价值。这样可以使得不同时间点上的效用或收益可比较，从而帮助参与者做出决策。贴现率还可用于评估投资、项目选择以及对未来风险的考虑。</p> 
 <p>需要注意的是，贴现率是一个主观的概念，不同的个体或组织可能会有不同的贴现率，取决于其对时间价值和风险偏好的评估。在实际应用中，确定适当的贴现率通常需要考虑多种因素，如机会成本、市场利率、风险偏好等。</p> 
</blockquote> 
<p><strong>【</strong><strong>贴现率</strong><strong>的计算】</strong></p> 
<p><img alt="" height="511" src="https://images2.imgbox.com/9e/90/PsXJhIq8_o.png" width="667"></p> 
<p><img alt="" height="486" src="https://images2.imgbox.com/ca/a2/EbW4DkrB_o.png" width="670"></p> 
<h5>4）可行收益</h5> 
<p><img alt="" height="491" src="https://images2.imgbox.com/ff/d5/LDVXUpyQ_o.png" width="672"></p> 
<p><img alt="" height="485" src="https://images2.imgbox.com/98/e6/Mh39GKqu_o.png" width="676"></p> 
<h5>5）平均收益</h5> 
<p>【提示】</p> 
<p>左式为前T时间内的平均收益为<strong> Π</strong> ，在贴现率为<strong> δ</strong> 的情况下，T~2T时间内的预期收益为 <strong>δΠ</strong> ，2T~3T时间内的预期收益为<strong> δ²Π</strong> ，那么无限重复博弈下收益为</p> 
<p><strong>Π+δΠ+δ²Π+... </strong></p> 
<p>右式为第1个单位时间内的收益为<strong> Π1</strong> ,第2个单位时间内的（虽然实际收益为 Π2 ，但要乘以贴现率）预期收益为<strong> δΠ2</strong>，第3个单位时间内的预期收益为<strong> δ²Π3</strong> ，那么无限重复博弈下收益为</p> 
<p><strong>Π1+δΠ2+δ²Π3+··· </strong></p> 
<p>二者均为无限重复博弈的收益，左式=右式，以此求得平均收益。</p> 
<p><img alt="" height="485" src="https://images2.imgbox.com/f9/ea/AujkWk1S_o.png" width="670"></p> 
<p><img alt="" height="482" src="https://images2.imgbox.com/60/f8/46X6BjEF_o.png" width="670"></p> 
<h5>6）无名氏定理</h5> 
<p><img alt="" height="487" src="https://images2.imgbox.com/79/e1/bFIONFNQ_o.png" width="666"></p> 
<p>【<strong>无名氏定理的意义】</strong></p> 
<p>在无限重复博弈中，任何一个Pareto有效的可行收益都可以通过一个特定的子博弈精炼Nash均衡得到</p> 
<h5>7）罗伯特·爱克斯罗德实验</h5> 
<p><img alt="" height="478" src="https://images2.imgbox.com/39/7e/OrNh4Biu_o.png" width="665"></p> 
<p><strong>最终，“一报还一报”的策略，赢得了游戏</strong></p> 
<p><img alt="" height="481" src="https://images2.imgbox.com/7f/29/l3LyYD9T_o.png" width="673"></p> 
<p><img alt="" height="484" src="https://images2.imgbox.com/76/e4/Re8GdBeU_o.png" width="669"></p> 
<h2>四、子博弈精炼Nash均衡的应用</h2> 
<h3>1、Stackelberg寡头竞争模型</h3> 
<h5>1）经典案例</h5> 
<p><img alt="" height="483" src="https://images2.imgbox.com/42/e6/HAiHDtFQ_o.png" width="667"></p> 
<p><img alt="" height="479" src="https://images2.imgbox.com/b6/d9/XG393zmV_o.png" width="665"></p> 
<p><img alt="" height="482" src="https://images2.imgbox.com/64/63/dh1g9n28_o.png" width="669"></p> 
<h5><strong>2）博弈过程</strong></h5> 
<p><img alt="" height="482" src="https://images2.imgbox.com/f6/b4/QcRtfE2c_o.png" width="678"></p> 
<p><img alt="" height="482" src="https://images2.imgbox.com/3d/28/QAHgbOr1_o.png" width="668"></p> 
<p><img alt="" height="483" src="https://images2.imgbox.com/90/4b/aUWZYilu_o.png" width="667"></p> 
<p><strong>注意Stackelberg模型与Cournot模型的比较：产量、利润。</strong></p> 
<blockquote> 
 <p>Stackelberg模型说明：</p> 
 <ol><li> <p>企业具有先动优势；</p> </li><li> <p>企业具有信息优势，反而使自己不利。</p> </li></ol> 
</blockquote> 
<h5><strong>3）关于均衡结果的讨论</strong></h5> 
<p><img alt="" height="290" src="https://images2.imgbox.com/8f/9f/L2ZtItpQ_o.png" width="589"></p> 
<h3>2、Leontief劳资谈判模型</h3> 
<h5><strong>1）经典案例</strong></h5> 
<p><img alt="" height="484" src="https://images2.imgbox.com/d8/a0/fxzGGe7i_o.png" width="679"></p> 
<p><img alt="" height="487" src="https://images2.imgbox.com/2d/2a/c59kOB1f_o.png" width="666"></p> 
<p><img alt="" height="489" src="https://images2.imgbox.com/bc/d5/4yAY0Aju_o.png" width="675"></p> 
<h5><strong>2）博弈过程</strong></h5> 
<p><img alt="" height="492" src="https://images2.imgbox.com/2f/75/VaovcLms_o.png" width="669"></p> 
<p><img alt="" height="487" src="https://images2.imgbox.com/98/90/DSYmnYd0_o.png" width="675"></p> 
<p><img alt="" height="486" src="https://images2.imgbox.com/d8/6c/WhCKbrT6_o.png" width="668"></p> 
<p><img alt="" height="482" src="https://images2.imgbox.com/8d/52/X6hWAqUg_o.png" width="667"></p> 
<h3>3、关税与国际市场</h3> 
<p>此题是大国税收博弈的推广， 由战略式博弈推广到扩展式博弈。</p> 
<h5><strong>1）经典案例</strong></h5> 
<p><img alt="" height="485" src="https://images2.imgbox.com/83/bd/Rp1NLH7q_o.png" width="682"></p> 
<p><img alt="" height="484" src="https://images2.imgbox.com/a5/e1/o1TGK9uu_o.png" width="673"></p> 
<p><img alt="" height="487" src="https://images2.imgbox.com/1d/85/eDN7ERYy_o.png" width="668"></p> 
<p><img alt="" height="490" src="https://images2.imgbox.com/c4/d6/OCqvOy7x_o.png" width="668"></p> 
<p><img alt="" height="487" src="https://images2.imgbox.com/f9/16/W7fqDHdI_o.png" width="670"></p> 
<h5><strong>2）博弈过程</strong></h5> 
<p><img alt="" height="490" src="https://images2.imgbox.com/9e/b4/FZmcJp71_o.png" width="669"></p> 
<p><img alt="" height="484" src="https://images2.imgbox.com/6f/d7/J88JHINK_o.png" width="673"></p> 
<p><img alt="" height="490" src="https://images2.imgbox.com/5f/86/9geZtXsY_o.png" width="673"></p> 
<p><img alt="" height="485" src="https://images2.imgbox.com/21/41/sV3oHD9r_o.png" width="681"></p> 
<p><img alt="" height="481" src="https://images2.imgbox.com/58/c6/yI6YrvP6_o.png" width="667"></p> 
<p><img alt="" height="484" src="https://images2.imgbox.com/59/7d/DHS7IUd3_o.png" width="667"></p> 
<p><img alt="" height="486" src="https://images2.imgbox.com/6e/5d/03dahFXn_o.png" width="671"></p> 
<p><img alt="" height="482" src="https://images2.imgbox.com/4e/70/WGtPvAFg_o.png" width="674"></p> 
<h5><strong>3）关于博弈结果的讨论</strong></h5> 
<p>从上面的比较可以看出：关税的存在虽然会使政府的收益增加，但企业的收益和消费者剩余却会减少的更多，所以，非自由贸易会造成社会福利的损失。</p> 
<h3>4、投票次序效应</h3> 
<h5>1）次序效应是什么</h5> 
<p>公共政策的选择都是按一定程序进行的。选择程序不同，选择结果就不同。但是，在某些情况下即使选择程序相同，而选择过程中方案的选择次序(即议程)不同，也会造成选择结果的极大差异。这种<strong>由于议程的不同而造成的选择结果的差异就是所谓的“次序效应”。</strong>在实际的公共政策选择过程中，“次序效应”普遍存在。</p> 
<h5>2）投票悖论</h5> 
<p><img alt="" height="487" src="https://images2.imgbox.com/8c/c3/53EBtUEY_o.png" width="672"></p> 
<p><img alt="" height="480" src="https://images2.imgbox.com/7d/18/ZFUiFHne_o.png" width="663"></p> 
<h5>3）次序效应举例</h5> 
<p><img alt="" height="487" src="https://images2.imgbox.com/ca/d2/6xcDNYEK_o.png" width="680"></p> 
<p><img alt="" height="487" src="https://images2.imgbox.com/6e/94/os0NRcDc_o.png" width="670"></p> 
<p>上述<strong>由于议程的不同而造成的选择结果的差异</strong>，称之为<strong>“程序效应”(procedure effect)或“</strong><strong>投票</strong><strong>次序效应”</strong>(voting order effect，简称“次序效应”) 。</p> 
<h5>4）次序效应的结论</h5> 
<p><img alt="" height="486" src="https://images2.imgbox.com/bd/1c/6zcOcsWp_o.png" width="671"></p> 
<p>但是，上述结论是有条件的，它是在委员会中的各成员都根据自己的真实偏好进行投票的前提下得到的，也就是说，在投票过程中，对于每一轮投票各成员<strong>都是根据自己的偏好对方案进行选择，不能出现违背自己偏好的情形。</strong></p> 
<h5>5）经典案例</h5> 
<p>在实际的表决过程中，追求自身利益最大化的各成员不可能绝对地根据自己的真实偏好进行投票，尤其是当各成员相互知道对方偏好的时候。</p> 
<p><img alt="" height="489" src="https://images2.imgbox.com/5e/14/KVI7gnRv_o.png" width="673"></p> 
<p><img alt="" height="487" src="https://images2.imgbox.com/61/da/ZfpEgegT_o.png" width="670"></p> 
<p><img alt="" height="483" src="https://images2.imgbox.com/3f/fc/GiHKpJyR_o.png" width="663"></p> 
<p><img alt="" height="485" src="https://images2.imgbox.com/94/97/hbvYzfHo_o.png" width="673"></p> 
<p><img alt="" height="486" src="https://images2.imgbox.com/6c/9d/mG9lM1RU_o.png" width="667"></p> 
<h5><strong>6）博弈过程</strong></h5> 
<p><img alt="" height="492" src="https://images2.imgbox.com/0a/96/W5gCVYdo_o.png" width="673"></p> 
<p><img alt="" height="483" src="https://images2.imgbox.com/cd/2c/9Mar09Im_o.png" width="671"></p> 
<p><img alt="" height="487" src="https://images2.imgbox.com/11/ca/lnoHrSgm_o.png" width="681"></p> 
<p><img alt="" height="482" src="https://images2.imgbox.com/47/89/baJqMIpp_o.png" width="673"></p> 
<p><img alt="" height="486" src="https://images2.imgbox.com/8b/b7/B3cG301x_o.png" width="669"></p> 
<p><img alt="" height="485" src="https://images2.imgbox.com/bd/e8/t3vH6c22_o.png" width="668"></p> 
<h5>7）关于博弈结果的讨论</h5> 
<p>在委员会偏好为共同知识的条件下，每个成员在第一轮投票中都是通过比较自己选择的后果来决定自己的选择，而并非完全根据自己的真实偏好进行选择。这说明委员会成员实际上是根据前面介绍过的“逆向递推”的原则(即逆向归纳法)来决定自己的选择。</p> 
<h5><strong>8）</strong><strong>投票</strong><strong>次序效应的应用</strong></h5> 
<p>在美国国会的政治斗争中，民主党和共和党不仅要在国会中争取更多的席位， 而且还要力争获得各个委员会尤其是程序委员会的控制权，其目的就是希望在议案的表决过程中，制定对自己最为有利的方案表决顺序(即议程)。</p> 
<p>此外，由于委员会中成员偏好是否为共同知识，会对表决程序的“次序效应”产生完全不同的影响，因此，在投票表决之前是否需要对投入表决的方案进行公开、充分的辩论，各政党都会根据自身的利益进行通盘考虑。</p> 
<h2>总结</h2> 
<blockquote> 
 <p>在这学期的博弈论课程中，我们主要学习的是完全信息静态博弈和完全信息动态博弈，需要掌握基本概念、明确Nash均衡的定义和求解，结合具体的案例进行分析。以上便是我们八周学习的课程，感谢大家的支持和鼓励~</p> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dce53a8ccf45f0db322155cd8cd3d1fe/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">华为OD机试 - 需要打开多少监控器（Java &amp; JS &amp; Python &amp; C）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4ecc2d431ef87cb92ae64297462c02a4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">手机通讯录好备份，那微信通讯录怎么备份出来</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>