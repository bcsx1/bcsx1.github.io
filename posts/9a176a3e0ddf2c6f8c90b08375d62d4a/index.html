<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>一种基于神经网络的对话模型 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="一种基于神经网络的对话模型" />
<meta property="og:description" content="摘要
对话模型在自然语言理解和机器智能方面是一个非常重要的任务。尽管之前已经有一些方法，但是他们受限于特定的领域（比如：预定机票）而且需要手动指定规则。在这篇文章中，我们针对这个任务展现了一种简单的方法，这种方法使用最近被提出的sequece to sequece 框架。我们的模型通过给定之前的对话中的句子来预测下一个句子的方式进行交谈。我们模型的有点就是它可以进行端到端的训练，因此需要风少的手动指定规则。我们发现这个直接的模型可以通过一个大量的基于对话的训练数据集生成简单的对话。我们的初步结果指出，尽管优化了错误的目标函数，但是模型仍然运行的很好。它能从某个特定领域数据集和一个大量的包含噪音的电字母一般性数据集中抽取知识。在一个特定领域的IT帮助台数据集中，模型可以冲过对话找出解决耨一个技术问题的方案。通过一个包含噪音的开放性的电影剧本数据集中，该模型可以执行简单的形式的常识推理。正如期望的一样，我们也发现了我们的模型一种常见的失败模式-缺乏连贯性。 一、引言
神经网络的端到端训练的进展在许多领域都得到了显著的进展，如方言识别，计算机视觉和语言来处理。最近的工作表明，神经网络可以做的不仅仅是单纯的分类，他们可以用来映射复杂的其他复杂结构的结构。举个例子，有一个将一个序列映射成另一个序列的任务，这种任务在自然语言理解方面有直接的应用。这个框架的主要优点是，他需要很少的特征工程和领域特征，同时匹配或超越了国家的先进成果。这种进步，在我们看来，允许研究人员所工作的领域的任务涉及的知识可能不是现成的，或针对任务很难设计手动规则。对话模型可以直接受益于这一提法因为它需要查询和查询之间的映射关系响应。由于这种影响的复杂性，设计会话模型都是在非常狭窄的领域，在特征工程方面也需要有所保证。我们采用对话模型试验的目的就是采用递归神经网络，通过给定序列预测下一序列。我们发现这种方法在产生流利和准确的对话的答复方面可以做得很好。 我们在一个IT帮助台的对话数据集的聊天会话上测试模型，发现该模型有时可以跟踪问题并提供一个有用的答案给用户。我们也从一个嘈杂的电影字幕的数据集的对话中实验，发现该模型可以有一个自然的对话，有事会执行常识推理的简单形式。在这两个案例中，递归神经网络相比n元文法模型，得到更好的困惑度以及捕捉到重要的长范围相关性。从定性的角度来看，我们的模型有时能够产生自然的对话。
二、相关研究
我们的方法是基于最近的研究，该研究提出使用神经网络将一个序列映射到另一个序列。这个框架已经在神经机器翻译得到应用以及在沃尔玛14年数据集上进行应发和英德翻译任务方面得到提高。它也被用于其他任务，如图像解析和图像字幕。众所周知，普通Rnn网络容易造成梯度消失，大多数研究人员使用长的变体短期记忆（LSTM）递归神经网络（霍克赖特和所说的，1997）。 我们的工作也受到基于神经网络的语言模型的成功的启发，它表明神经网络是自言语言的一种相当有效的模型。最近，索尔多尼和Shang等人应用递归神经网络到剪短的对话模型上。 建造机器人和对话代理一直是许多研究人员在过去几十年里的追求，本文不再提供详细的参考列表。然而，大多数这些系统需要一个相当复杂的有许多阶段构成的处理管道。我们的工作不同于传统的系统。它提出一个终端到终端的方法来解决这个问题，不需要领域知识。原则上，它可以结合其他系统，重新评定候选回答的短列表，但我们的工作是基于生成的答案给定一个概率模型进行训练，以最大限度地给出了基于一些上下文的答案的概率。
三、模型
我们的方法使用序列到序列（seq2)框架所描述的。该模型是基于一个递归神经网络，一次读取一个输入序列，并预测输出序列。在训练过程中，真正的输出序列由模型给出，所以可以通过反向传播学习模型。模型训练是为了最大限度的提高由上下文提供的正确的序列的交叉熵。在推理过程中，给定的真正的输出序列并没有看到，而是简单的将预测的输出作为输入来预测下一个输出。这是一种贪婪的推导方法。一种不那么贪婪的方法时使用波束搜索，并在以前的过程中得到几个候选方案传给下一步。这种预测的序列可以是基于概率选择的。 集体来讲，假设我们观察到一个两轮对话，第一个人说：”ABC”,第二个人说：“WXYZ”。我们可以使用一个递归神经网络，如上图1所示，训练将”ABC”映射到“WXYZ”,当它接收到的模型的隐藏状态序列结束符号“&lt; EOS &gt;”可以看作是结束。 该模型的有点在于它的简单性和通用性。我们可以应用这个模型在机器翻译，QA问答系统，和没有重大改变的对话中。将这种技术应用到会话建模也非常简单：简单的序列可以是由到目前为止的上下文转换得到的一系列序列，输出序列则是答复。 不同于翻译这样简单的任务，一个像sequece to sequece这样的模型将无法成功解决建模对话的问题，因为一个明显的简化：目标函数优化不捕获通过人类沟通得到的实际目标实现，这是典型的长期的基于信息交换的而不是基于下一步预测。一个模型缺乏一致性和一般的世界知识是另一个明显的纯粹的无监督模型的局限性。
四、数据集
在我们的试验中采用两类数据集：一个封闭的IT帮助台故障修复数据集和一个开放的电影抄本数据集。这两部分数据集的细节如下： 4.1 IT帮助台故障修复数据集
在我们的第一组试验中，我们使用了一个从IT故障排除聊天服务中获取的数据集，在这个服务中，消费者面对电脑相关的问题，一个专家通过交谈和提出解决方案帮助他们解决问题。典型的相互作用（或线程）是400个单词长度，并且轮流作用是明确的信号。我们的训练数据集是30M令牌，3M被用作验证。进行了一定量的数据清洗，如删除共同的名称、数字和完整的网址。 4.2 开放电影字幕数据集
我们还在开发的电影字幕数据集上测试了我们的模型。该数据集包含XML格式的电影对话。它包含电影中人物所说的话。我们使用简单的处理步骤删除XML标签和明显的非会话文本（例如：超链接）数据集。由于轮流说话没有明确表示，我们将连续的句子看做是不同的角色的人说的。我们基于上一句来训练模型来预测下一句，我们针对每一句都这么做（注意到这是我们数据集的一杯并且每一个机组都用于上下文和目标）。我们的训练集和验证集是分开的，训练集样本是62M的序列（923令牌），验证集26M(395M 令牌）。这样分割是为了似的一组序列要么出现在训练集中，要么出现在测试集中但不是同时出现。不想之前的数据集，该opensubtitles是相当大的和嘈杂的，因为连续的句子有可能是同一个任务所说。给定广泛的电影，和技术故障排除数据集相比，这是一个开放域的会话数据集。
五、实验 在这一节中，我们描述了基于两个数据集的试验结果，并显示了一些我们训练的系统给出的相互作用的样本。我们使用一组200个问题的评价数据集，将我们的系统的性能和一个流行的以规则为基础的的Bot做了比较。 5.1 IT故障排除实验
在这个实验中，我们使用了一个简单的LSTM层，使用1024个单元，采用梯度下降法。词汇是最常见的20K个，包含特殊标记指示轮流说话和角色。 在收敛时，该模型实现了困惑度为8，而一个N-gram模型达到了18.下面是几个样本，模拟最多三个故障排除会话（远程访问，软件崩溃，和密码问题）。这这些谈话中，机器是我们的神经会话模型，人类担任和它对话的角色。 Conversation 1: VPN issues
描述你的问题： i am having issues accessing vpn Machine: hi Human: hello Machine: could you please let me know what are the operating systems you are using ? Human: i am using linux Machine: ok it was in the ssl vpn on which you stated it was broken Machine: please check if you are logged in to corp network Machine: what is the error that you are running please Human: i am seeing an error related to vpn Machine: what is the error message that you are getting when connecting to vpn using network connect ?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/9a176a3e0ddf2c6f8c90b08375d62d4a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2016-09-15T00:12:24+08:00" />
<meta property="article:modified_time" content="2016-09-15T00:12:24+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">一种基于神经网络的对话模型</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>摘要</p> 
<p>　　　对话模型在自然语言理解和机器智能方面是一个非常重要的任务。尽管之前已经有一些方法，但是他们受限于特定的领域（比如：预定机票）而且需要手动指定规则。在这篇文章中，我们针对这个任务展现了一种简单的方法，这种方法使用最近被提出的sequece to sequece 框架。我们的模型通过给定之前的对话中的句子来预测下一个句子的方式进行交谈。我们模型的有点就是它可以进行端到端的训练，因此需要风少的手动指定规则。我们发现这个直接的模型可以通过一个大量的基于对话的训练数据集生成简单的对话。我们的初步结果指出，尽管优化了错误的目标函数，但是模型仍然运行的很好。它能从某个特定领域数据集和一个大量的包含噪音的电字母一般性数据集中抽取知识。在一个特定领域的IT帮助台数据集中，模型可以冲过对话找出解决耨一个技术问题的方案。通过一个包含噪音的开放性的电影剧本数据集中，该模型可以执行简单的形式的常识推理。正如期望的一样，我们也发现了我们的模型一种常见的失败模式-缺乏连贯性。 <br> 　　　 <br> 一、引言</p> 
<p>　　　神经网络的端到端训练的进展在许多领域都得到了显著的进展，如方言识别，计算机视觉和语言来处理。最近的工作表明，神经网络可以做的不仅仅是单纯的分类，他们可以用来映射复杂的其他复杂结构的结构。举个例子，有一个将一个序列映射成另一个序列的任务，这种任务在自然语言理解方面有直接的应用。这个框架的主要优点是，他需要很少的特征工程和领域特征，同时匹配或超越了国家的先进成果。这种进步，在我们看来，允许研究人员所工作的领域的任务涉及的知识可能不是现成的，或针对任务很难设计手动规则。对话模型可以直接受益于这一提法因为它需要查询和查询之间的映射关系响应。由于这种影响的复杂性，设计会话模型都是在非常狭窄的领域，在特征工程方面也需要有所保证。我们采用对话模型试验的目的就是采用递归神经网络，通过给定序列预测下一序列。我们发现这种方法在产生流利和准确的对话的答复方面可以做得很好。 <br> 　　　我们在一个IT帮助台的对话数据集的聊天会话上测试模型，发现该模型有时可以跟踪问题并提供一个有用的答案给用户。我们也从一个嘈杂的电影字幕的数据集的对话中实验，发现该模型可以有一个自然的对话，有事会执行常识推理的简单形式。在这两个案例中，递归神经网络相比n元文法模型，得到更好的困惑度以及捕捉到重要的长范围相关性。从定性的角度来看，我们的模型有时能够产生自然的对话。</p> 
<p>二、相关研究</p> 
<p>　　　我们的方法是基于最近的研究，该研究提出使用神经网络将一个序列映射到另一个序列。这个框架已经在神经机器翻译得到应用以及在沃尔玛14年数据集上进行应发和英德翻译任务方面得到提高。它也被用于其他任务，如图像解析和图像字幕。众所周知，普通Rnn网络容易造成梯度消失，大多数研究人员使用长的变体短期记忆（LSTM）递归神经网络（霍克赖特和所说的，1997）。 <br> 　　　我们的工作也受到基于神经网络的语言模型的成功的启发，它表明神经网络是自言语言的一种相当有效的模型。最近，索尔多尼和Shang等人应用递归神经网络到剪短的对话模型上。 <br> 　　　建造机器人和对话代理一直是许多研究人员在过去几十年里的追求，本文不再提供详细的参考列表。然而，大多数这些系统需要一个相当复杂的有许多阶段构成的处理管道。我们的工作不同于传统的系统。它提出一个终端到终端的方法来解决这个问题，不需要领域知识。原则上，它可以结合其他系统，重新评定候选回答的短列表，但我们的工作是基于生成的答案给定一个概率模型进行训练，以最大限度地给出了基于一些上下文的答案的概率。</p> 
<p>三、模型</p> 
<p>　　　我们的方法使用序列到序列（seq2)框架所描述的。该模型是基于一个递归神经网络，一次读取一个输入序列，并预测输出序列。在训练过程中，真正的输出序列由模型给出，所以可以通过反向传播学习模型。模型训练是为了最大限度的提高由上下文提供的正确的序列的交叉熵。在推理过程中，给定的真正的输出序列并没有看到，而是简单的将预测的输出作为输入来预测下一个输出。这是一种贪婪的推导方法。一种不那么贪婪的方法时使用波束搜索，并在以前的过程中得到几个候选方案传给下一步。这种预测的序列可以是基于概率选择的。 <br> 　　　 <br> 　　　集体来讲，假设我们观察到一个两轮对话，第一个人说：”ABC”,第二个人说：“WXYZ”。我们可以使用一个递归神经网络，如上图1所示，训练将”ABC”映射到“WXYZ”,当它接收到的模型的隐藏状态序列结束符号“&lt; EOS &gt;”可以看作是结束。 <br> 　　　该模型的有点在于它的简单性和通用性。我们可以应用这个模型在机器翻译，QA问答系统，和没有重大改变的对话中。将这种技术应用到会话建模也非常简单：简单的序列可以是由到目前为止的上下文转换得到的一系列序列，输出序列则是答复。 <br> 　　　不同于翻译这样简单的任务，一个像sequece to sequece这样的模型将无法成功解决建模对话的问题，因为一个明显的简化：目标函数优化不捕获通过人类沟通得到的实际目标实现，这是典型的长期的基于信息交换的而不是基于下一步预测。一个模型缺乏一致性和一般的世界知识是另一个明显的纯粹的无监督模型的局限性。</p> 
<p>四、数据集</p> 
<p>　　　在我们的试验中采用两类数据集：一个封闭的IT帮助台故障修复数据集和一个开放的电影抄本数据集。这两部分数据集的细节如下： <br> 　　　 <br> 4.1 IT帮助台故障修复数据集</p> 
<p>　　　在我们的第一组试验中，我们使用了一个从IT故障排除聊天服务中获取的数据集，在这个服务中，消费者面对电脑相关的问题，一个专家通过交谈和提出解决方案帮助他们解决问题。典型的相互作用（或线程）是400个单词长度，并且轮流作用是明确的信号。我们的训练数据集是30M令牌，3M被用作验证。进行了一定量的数据清洗，如删除共同的名称、数字和完整的网址。 <br> 　　　 <br> 4.2 开放电影字幕数据集</p> 
<p>　　　我们还在开发的电影字幕数据集上测试了我们的模型。该数据集包含XML格式的电影对话。它包含电影中人物所说的话。我们使用简单的处理步骤删除XML标签和明显的非会话文本（例如：超链接）数据集。由于轮流说话没有明确表示，我们将连续的句子看做是不同的角色的人说的。我们基于上一句来训练模型来预测下一句，我们针对每一句都这么做（注意到这是我们数据集的一杯并且每一个机组都用于上下文和目标）。我们的训练集和验证集是分开的，训练集样本是62M的序列（923令牌），验证集26M(395M 令牌）。这样分割是为了似的一组序列要么出现在训练集中，要么出现在测试集中但不是同时出现。不想之前的数据集，该opensubtitles是相当大的和嘈杂的，因为连续的句子有可能是同一个任务所说。给定广泛的电影，和技术故障排除数据集相比，这是一个开放域的会话数据集。</p> 
<p>五、实验 <br> 　　　 <br> 　　　在这一节中，我们描述了基于两个数据集的试验结果，并显示了一些我们训练的系统给出的相互作用的样本。我们使用一组200个问题的评价数据集，将我们的系统的性能和一个流行的以规则为基础的的Bot做了比较。 <br> 　　　 <br> 5.1 IT故障排除实验</p> 
<p>　　　在这个实验中，我们使用了一个简单的LSTM层，使用1024个单元，采用梯度下降法。词汇是最常见的20K个，包含特殊标记指示轮流说话和角色。 <br> 　　　在收敛时，该模型实现了困惑度为8，而一个N-gram模型达到了18.下面是几个样本，模拟最多三个故障排除会话（远程访问，软件崩溃，和密码问题）。这这些谈话中，机器是我们的神经会话模型，人类担任和它对话的角色。 <br> 　　　 <br> Conversation 1: VPN issues</p> 
<p>　　　描述你的问题： i am having issues accessing vpn <br> 　　　Machine: hi <br> 　　　Human: hello <br> 　　　Machine: could you please let me know what are the operating systems you are using ? <br> 　　　Human: i am using linux <br> 　　　Machine: ok it was in the ssl vpn on which you stated it was broken <br> 　　　Machine: please check if you are logged in to corp network <br> 　　　Machine: what is the error that you are running please <br> 　　　Human: i am seeing an error related to vpn <br> 　　　Machine: what is the error message that you are getting when connecting to vpn using network connect ? <br> 　　　Human: connection refused or something like that <br> 　　　Machine: may i know the version of network connect you connect ? <br> 　　　Human: i am not sure i know that <br> 　　　Machine: is the network connect prompting for any user certificate <br> 　　　Machine: ? <br> 　　　Human: yes <br> 　　　Machine: are you at home or at work at the moment ? <br> 　　　Machine: office ? <br> 　　　Human: i am at home <br> 　　　Machine: try this <br> 　　　Machine: goto page and enter your name and password <br> 　　　Human: done <br> 　　　Machine: try logging in with and check if its working fine now <br> 　　　Human: yes , now it works ! <br> 　　　Machine: great <br> 　　　Machine: anything else that i can help <br> 　　　Human: no , that was very useful <br> 　　　Machine: you are other than : ) <br> 　　　Machine: have a nice night <br> 　　　 <br> Conversation 2: Browser issues.</p> 
<p>　　　Describe your problem: browser keeps crashing <br> 　　　Machine: hi <br> 　　　Human: hi <br> 　　　Machine: could you please let me know what is <br> 　　　the operating system you are using ? <br> 　　　Human: linux <br> 　　　Machine: ok this is the issue with the system performance , nasser , tools . <br> 　　　Human: what is that ? <br> 　　　Machine: is it a windows machine ? <br> 　　　Machine: we have linux on your machine . <br> 　　　Machine: is it windows xp or windows 7 ? <br> 　　　Human: i am using linux <br> 　　　Machine: let me take a remote of your machine and check if issue has been pushed properly . <br> 　　　Human: ok <br> 　　　Machine: please open terminal and run the below commands in one computer : <br> 　　　Machine: sudo apt - get update <br> 　　　Machine: sudo apt - get upgrade <br> 　　　Machine: sudo - updater <br> 　　　Human: done <br> 　　　Machine: let me try connecting now <br> 　　　Human: ok <br> 　　　Machine: its done <br> 　　　Machine: should use the second or hit run on <br> 　　　the background <br> 　　　Human: done <br> 　　　Machine: try signing out now and follow the <br> 　　　prompts as per the message given above <br> 　　　Machine: shd i reboot the machine . <br> 　　　Human: ok , please go ahead <br> 　　　Machine: once its completed please try to login <br> 　　　. <br> 　　　Human: sure <br> 　　　Machine: please ping me back once you have tried to login <br> 　　　Machine: are we still connected <br> 　　　Human: i now logged in <br> 　　　Machine: thanks for your confirmation <br> 　　　Human: what should i do now ? <br> 　　　Machine: wait for 1 5 minutes to complete the login policy <br> 　　　Machine: and then try logging in <br> 　　　Human: ok <br> 　　　Machine: is there anything else to help you ? <br> 　　　Human: let my try browsing a little bit and if it keeps crashing i will let you know <br> 　　　Machine: sure will do <br> 　　　Machine: seems the mail is not loading <br> 　　　Machine: are we still connected to the chat ? <br> 　　　Machine: <br> 　　　Human: it seems good now , cool , thank you ,bye <br> 　　　Machine: you , too <br> 　　　Machine: bye <br> 　　　 <br> 　　　 <br> Conversation 3: Password issues</p> 
<p>Describe your problem: i forgot my password</p> 
<p>　　　Machine: hi , this is from helpdesk connect , what can i help you with today ? <br> 　　　Human: hi , i forgot my password <br> 　　　Machine: ok great <br> 　　　Human: can you tell me how i can recover it ? <br> 　　　Machine: i ’ ll need to verify who it is at that machine <br> 　　　Machine: can we do a hangout <br> 　　　Machine: ? <br> 　　　Human: yes <br> 　　　Machine: <br> 　　　Human: cool , i am good now <br> 　　　Machine: how ‘s this looking good ? <br> 　　　Machine: i ‘ll go ahead and close this chat . <br> 　　　Machine: take care . : ) <br> 　　　Human: bye <br> 　　　Machine: bye .</p> 
<p>5.2 开放电影字幕数据集实验 <br> 　　　 <br> 　　　在这个实验中我们使用一个两层的LSTM，使用adaGrad进行梯度剪裁。每一层的LSTM有4096个记忆单元，我们使用最常见的100K个单词建立词汇。为了加快softMax过程，，在到达最终的分类器之前，先将及一单元信息发射给2048个线性单元。 <br> 　　　在收敛时，该递归模型得到的困惑度为17，我们的平滑5-gram模型实现了28的困惑度。有趣的是，添加soft attention 机制并没有显著提升训练集或校验集的困惑度。</p> 
<p>5.2.1 模型样本 <br> 　　　 <br> 　　　除了采用困惑度度量的方式，我们的递归模型也经常产生似是而非的答案。在这里我们给出一些样本问答对，使我们能够理解模型在训练包含噪音且大量的来自电影开放性字幕数据集时的能力。再次，这这些谈话中，机器是我们的神经会话模型，人类担任和它对话的角色。 <br> 　　　 <br> Conversation 1: Basic</p> 
<p>　　　Human: hello ! <br> 　　　Machine: hello ! <br> 　　　Human: how are you ? <br> 　　　Machine: i ’m good . <br> 　　　Human: what ’s your name ? <br> 　　　Machine: i ’m julia . <br> 　　　Human: when were you born ? <br> 　　　Machine: july 20th . <br> 　　　Human: what year were you born ? <br> 　　　Machine: 1977 . <br> 　　　Human: where are you from ? <br> 　　　Machine: i ’m out in the boonies. <br> 　　　Human: are you a man or a woman ? <br> 　　　Machine: i ’m a woman . <br> 　　　Human: why are we here ? <br> 　　　Machine: i ’m not sure . <br> 　　　Human: okay, bye ! <br> 　　　Machine: bye . <br> 　　　Human: see you later . <br> 　　　Machine: bye . <br> 　　　 <br> Conversation 2: Simple Q&amp;A (contexts and multiple <br> choice)</p> 
<p>　　　Human: my name is david . what is my name ? <br> 　　　Machine: david . <br> 　　　Human: my name is john . what is my name ? <br> 　　　Machine: john . <br> 　　　Human: are you a leader or a follower ? <br> 　　　Machine: i ’m a leader . <br> 　　　Human: are you a follower or a leader ? <br> 　　　Machine: i ’m a leader . <br> 　　　 <br> Conversation 3: General knowledge Q&amp;A</p> 
<p>　　　Human: who is skywalker ? <br> 　　　Machine: he is a hero . <br> 　　　Human: who is bill clinton ? <br> 　　　Machine: he ’s a billionaire . <br> 　　　Human: is sky blue or black ? <br> 　　　Machine: blue . <br> 　　　Human: does a cat have a tail ? <br> 　　　Machine: yes . <br> 　　　Human: does a cat have a wing ? <br> 　　　Machine: no <br> 　　　Human: can a cat fly ? <br> 　　　Machine: no . <br> 　　　Human: how many legs does a cat have ? <br> 　　　Machine: four , i think . <br> 　　　Human: how many legs does a spider have ? <br> 　　　Machine: three , i think . <br> 　　　Human: how many legs does a centipede have ? <br> 　　　Machine: eight . <br> 　　　Human: what is the color of the sky ? <br> 　　　Machine: blue . <br> 　　　Human: what is the color of water ? <br> 　　　Machine: water . <br> 　　　Human: what is the color of blood ? <br> 　　　Machine: it is the same as a black eye . <br> 　　　Human: what is the usual color of a leaf ? <br> 　　　Machine: it is a green one . <br> 　　　Human: what is the color of a yellow car ? <br> 　　　Machine: yellow . <br> 　　　Human: how much is two plus two ? <br> 　　　Machine: four . <br> 　　　Human: how much is ten minus two ? <br> 　　　Machine: seventy - two . <br> 　　　 <br> Conversation 4: Philosophical Q&amp;A</p> 
<p>　　　Human: what is the purpose of life ? <br> 　　　Machine: to serve the greater good . <br> 　　　Human: what is the purpose of living ? <br> 　　　Machine: to live forever . <br> 　　　Human: what is the purpose of existence ? <br> 　　　Machine: to find out what happens when we get to the planet earth . <br> 　　　Human: where are you now ? <br> 　　　Machine: i ’m in the middle of nowhere . <br> 　　　Human: what is the purpose of dying ? <br> 　　　Machine: to have a life . <br> 　　　Human: what is the purpose of being intelligent? <br> 　　　Machine: to find out what it is . <br> 　　　Human: what is the purpose of emotions ? <br> 　　　Machine: i don ’t know . <br> 　　　 <br> Conversation 5: Morality</p> 
<p>　　　Human: what is moral ? <br> 　　　Machine: what empowered humanity , what intellectual the essence is . <br> 　　　Human: what is immoral ? <br> 　　　Machine: the fact that you have a child . <br> 　　　Human: what is morality ? <br> 　　　Machine: what is altruism ? <br> 　　　Human: what is the definition of altruism ? <br> 　　　Machine: if you don ’t believe in god , then you don ’t know . <br> 　　　Human: ok … so what is the definition of morality ? <br> 　　　Machine: well , the truth is , you ’re not a believer in god almighty . <br> 　　　Human: tell me the definition of morality , i am quite upset now ! <br> 　　　Machine: i ’m not ashamed of being a philosopher ! <br> 　　　Human: tell me the definition of morality . <br> 　　　Machine: i don ’t have ethics . <br> 　　　Human: look , i need help , i need to know more about morality … <br> 　　　Machine: i don ’t know what ethics is . <br> 　　　Human: seriously , what is morality ? <br> 　　　Machine: what is the definition of living ? <br> 　　　Human: why living has anything to do with morality ? <br> 　　　Machine: you ’re not a cop . <br> 　　　Human: okay , i need to know how should i behave morally … <br> 　　　Machine: i don ’t know how to tell you . <br> 　　　Human: is morality and ethics the same ? <br> 　　　Machine: yes , sir . <br> 　　　Human: what are the things that i do to be immoral ? <br> 　　　Machine: i don ’t know . <br> 　　　Human: give me some examples of moral actions … <br> 　　　Machine: i ’m not a moralist . <br> 　　　Human: alright , morality ? <br> 　　　Machine: integrity . <br> 　　　Human: what is integrity ? <br> 　　　Machine: i ’m sorry , i don ’t know what else to say . <br> 　　　Human: be moral ! <br> 　　　Machine: be a man ! <br> 　　　Human: i really like our discussion on morality and ethics … <br> 　　　Machine: and how i ’m not in the mood for a philosophical debate . <br> 　　　Human: what do you like to talk about ? <br> 　　　Machine: nothing . <br> 　　　 <br> 　　　Conversation 6: Opinions (notice the model outputs “he” , <br> 　　　“she” or “it” depending on the subject being asked) <br> 　　　 <br> 　　　Human: what do you think about tesla ? <br> 　　　Machine: he ’s a good conductor . <br> 　　　Human: what do you think about bill gates ? <br> 　　　Machine: he ’s a good man . <br> 　　　Human: What do you think about messi ? <br> 　　　Machine: he ’s a great player . <br> 　　　Human: what do you think about cleopatra ? <br> 　　　Machine: oh , she ’s very regal . <br> 　　　Human: what do you think about england during the reign of elizabeth ? <br> 　　　Machine: it was a great place .</p> 
<p>　　我们发现它令人鼓舞的是，该模型可以记住事实，理解上下文，执行常识推理,没有传统管道的复杂性。让我们惊讶的是，该模型没有任何明确的除了在词向量中的参数之外的知识表示组件。也许最实际意义的是，事实上，模型可以推广到新的问题。换言之，它不仅仅是简单的通过现有数据库匹配答案。事实上，大多数以上提出的问题，除了第一次谈话，都不出现在训练集上。然而，这个基本模型的缺点是它只是给出简单的短的，有时候不满意的答案。也许一个更大的问题的缺点是，该模型不捕获一致的个性。事实上，如果我们问不相同，但语义上类似的问题，答案有时可以是不一致的。这是我们预期的，因为我们模型的简单以及实验的数据集造成的。下面的对话说明了这样的失败： <br> 　　　 <br> 　　　Conversation 7: Job and Personality <br> 　　　 <br> 　　　Human: what is your job ? <br> 　　　Machine: i ’m a lawyer . <br> 　　　Human: what do you do ? <br> 　　　Machine: i ’m a doctor <br> 　　　 <br> 　　最后，作为和其他传统的基本规则的机器人比较，我们提供了一些在我们测试中某些问题的上，机器人的答案： <br> 　　　 <br> 　　　Human: Are you a follower or a leader ? <br> 　　　CleverBot: No !! <br> 　　　Human: My name is david . what is my name ? <br> 　　　CleverBot: How old are you David ? <br> 　　　Human: My name is john . what is my name ? <br> 　　　CleverBot: John <br> 　　　Human: What is the purpose of being intelligent? <br> 　　　CleverBot: The purpose of life is to love God and love people. <br> 　　　Human: Is sky blue or black ? <br> 　　　CleverBot: I am 200 years old. <br> 　　　Human: What is the color of a yellow car ? <br> 　　　CleverBot: Brown. <br> 　　　Human: What is the usual color of a leaf ? <br> 　　　CleverBot: What is the color of the apple in the fridge ? <br> 　　　Human: What is the purpose of life ? <br> 　　　CleverBot: My purpose it to forward my species,in other words to make it easier for future generations of mankind to live. <br> 　　　Human: What do you think about tesla ? <br> 　　　CleverBot: I am tesla. <br> 　　　Human: What do you think about cleopatra ? <br> 　　　CleverBot: Cool is cool. <br> 　　　Human: What do you think about england during the reign of elizabeth ? <br> 　　　CleverBot: I like him. Do you ? <br> 　　　Human: What do you think about bill gates ? <br> 　　　CleverBot: Lets talk about Link. <br> 　　　Human: What is moral ? <br> 　　　CleverBot: Morality is the quality of being in accord with standards of right or good conduct. <br> 　　　Human: What is immoral ? <br> 　　　CleverBot: What is the objective of sistetic life ? <br> 　　　Human: Does a cat have a wing ? <br> 　　　CleverBot: What is the name of your husband. <br> 　　　Human: Can a cat fly ? <br> 　　　CleverBot:: What is your husband’s name ? <br> 　　　Human: Who is skywalker ? <br> 　　　CleverBot: There are two of them, Anakin Skywalker and Luke Skywalker, both haracters from star Wars. <br> 　　　Human: How many legs does a cat have ? <br> 　　　CleverBot: An ant. <br> 　　　Human: How many legs does a centipede have? <br> 　　　CleverBot: A centipede’s number of legs varies from thirty to two hundred. <br> 　　　Human: What is your job ? <br> 　　　CleverBot: I work in mental health. <br> 　　　Human: What do you do ? <br> 　　　CleverBot: I have no job.</p> 
<p>5.2.2 人类评估</p> 
<p>　　为了公平和客观地比较我们的模型和CleverBot，我们挑选了200个问题，问了四个不同人去评估我们的模型和CleaverBot. 人类法官需要被问那个机器人是他们的首选，如果答案是同等质量的，我们也允许平局。如果四个人的三个法官同意，我们记录分数。我们的模型作为首选有97个问题，而CleverBot有60。20个问题上两者是平局，23个问题上法官存在分歧。这里有一些法官评价系统的样品（粗体我们展示他们的首选答案，第三个例子显示平局，和第四个例子显示diagreement）： <br> 　　　Human: What is the deepest spot on the world ? <br> 　　　NCM: The pacific ocean. <br> 　　　CB: What ? <br> 　　　 <br> 　　　Human: Do you like Mexican food or Indian <br> 　　　food ? <br> 　　　NCM: I hate it. <br> 　　　CB: I love Mexican food. <br> 　　　 <br> 　　　Human: Who are you crazy about ? <br> 　　　NCM: You’re the one who’s crazy. <br> 　　　CB: Who are you ? <br> 　　　 <br> 　　　Human: What’s thirty plus forty ? <br> 　　　NCM: Sixty ? <br> 　　　CB: What should we talk about ? <br> 　　　 <br> 　　然而，我们相信，设计一个好的快速度量对话模型的质量的指标仍然是一个开放的研究问题。我们通过手工检查方式，通过使用Mechanical Turk和基于规则的机器人作比较获取人类评估，通过计算困惑度的方式等。然而， 这些都有明显的缺点，我们正在积极的追求这一研究方向以及其他的研究方向。</p> 
<p>六、讨论</p> 
<p>　　　在本文中，我们展示了一种简单的基于seq2seq框架的语言模型可以用来训练会话引擎。我们的结果显示它可以生成简单的基本的对话，并从嘈杂的但是开放域数据集中提取知识。尽管模型有明显的局限性，这是一个令人惊讶的一个纯数据驱动的方法，没有任何规则可以产生对许多类型的问题的正确答案。然而，该模型可能需要真正的修改来提供真实的对话。由于有许多限制，又缺乏连贯的个性，使得我们的系统很难通过图灵测试。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2cebe3629b7016ccf62e7a918800089d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JS练习实例--编写经典小游戏俄罗斯方块</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d6338cb0598c944a651efc8332a4f880/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">crontab中反引号和$()无效的解决</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>