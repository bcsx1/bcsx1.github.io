<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Landslide detection from an open satellite imagery 使用注意力增强卷积神经网络从开放的卫星图像和数字高程模型数据集检测滑坡 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Landslide detection from an open satellite imagery 使用注意力增强卷积神经网络从开放的卫星图像和数字高程模型数据集检测滑坡" />
<meta property="og:description" content="2020.01
武汉大学
论文下载地址：https://sci-hub.st/10.1007/s10346-020-01353-2
目录
Landslide detection from an open satellite imagery and digital elevation model dataset using attention boosted convolutional neural networks
使用注意力增强卷积神经网络从开放的卫星图像和数字高程模型数据集检测滑坡
摘要：
Introduction
Related work
Convolutional neural network（略去）
Attention mechanisms
Experiments and analysis
Setting
Conclusion
Landslide detection from an open satellite imagery and digital elevation model dataset using attention boosted convolutional neural networks 使用注意力增强卷积神经网络从开放的卫星图像和数字高程模型数据集检测滑坡 摘要： 卷积神经网络(Convolution neural network, CNN)是一种有效且流行的深度学习方法，它通过一系列卷积层自动学习从原始输入到给定标签或ground truth的复杂非线性映射。本研究的重点是利用基于cnn的方法从高分辨率光学卫星图像中检测滑坡，为识别潜在滑坡提供机会，并以高精度和时间效率更新大规模滑坡清单。针对滑坡的多样性和复杂背景，开发了源于人类视觉系统的注意机制，用于增强CNN从背景中提取更有特色的滑坡特征表征。由于深度学习需要大量的标记数据来训练一个学习模型，我们手工制作了一个位于中国毕节市的滑坡数据集。在数据集中，地质学者利用卫星图像和数字高程模型(digital elevation model, DEM)数据对770个滑坡进行了解释，并进一步通过野外工作进行了验证，其中包括岩崩、岩崩和少量岩屑滑坡。将滑坡数据以2:1的比例分成训练训练CNN模型的训练集和评估模型性能的测试集。试验结果表明，滑坡检测的最佳f1得分为96.62%。结果还证明，我们的空间通道注意机制的表现是相当高于其他最近的注意机制。此外，还证明了基于我们的数据集高效预测新的潜在滑坡的有效性。
Introduction 滑坡检测的必要性；实地考察费时费力；基于InSAR or satellite InSAR数据的自动化检测方法相继被提出。最近光学影像也引起关注。数字高程模型数据提供地形信息，在滑坡预测和识别中发挥重要作用。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/8387c208fb92f1d45d81d7c8592e5411/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-18T16:23:51+08:00" />
<meta property="article:modified_time" content="2020-11-18T16:23:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Landslide detection from an open satellite imagery 使用注意力增强卷积神经网络从开放的卫星图像和数字高程模型数据集检测滑坡</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="margin-left:0cm;">2020.01</p> 
<p style="margin-left:0cm;">武汉大学</p> 
<p style="margin-left:0cm;">论文下载地址：<a href="https://sci-hub.st/10.1007/s10346-020-01353-2" rel="nofollow">https://sci-hub.st/10.1007/s10346-020-01353-2</a></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="Landslide%20detection%20from%20an%20open%20satellite%20imagery%20and%20digital%20elevation%20model%20dataset%20using%20attention%20boosted%20convolutional%20neural%20networks-toc" style="margin-left:0px;"><a href="#Landslide%20detection%20from%20an%20open%20satellite%20imagery%20and%20digital%20elevation%20model%20dataset%20using%20attention%20boosted%20convolutional%20neural%20networks" rel="nofollow">Landslide detection from an open satellite imagery and digital elevation model dataset using attention boosted convolutional neural networks</a></p> 
<p id="%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%A2%9E%E5%BC%BA%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8E%E5%BC%80%E6%94%BE%E7%9A%84%E5%8D%AB%E6%98%9F%E5%9B%BE%E5%83%8F%E5%92%8C%E6%95%B0%E5%AD%97%E9%AB%98%E7%A8%8B%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A3%80%E6%B5%8B%E6%BB%91%E5%9D%A1-toc" style="margin-left:0px;"><a href="#%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%A2%9E%E5%BC%BA%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8E%E5%BC%80%E6%94%BE%E7%9A%84%E5%8D%AB%E6%98%9F%E5%9B%BE%E5%83%8F%E5%92%8C%E6%95%B0%E5%AD%97%E9%AB%98%E7%A8%8B%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A3%80%E6%B5%8B%E6%BB%91%E5%9D%A1" rel="nofollow">使用注意力增强卷积神经网络从开放的卫星图像和数字高程模型数据集检测滑坡</a></p> 
<p id="%E6%91%98%E8%A6%81%EF%BC%9A-toc" style="margin-left:40px;"><a href="#%E6%91%98%E8%A6%81%EF%BC%9A" rel="nofollow">摘要：</a></p> 
<p id="Introduction-toc" style="margin-left:40px;"><a href="#Introduction" rel="nofollow">Introduction</a></p> 
<p id="Related%20work-toc" style="margin-left:40px;"><a href="#Related%20work" rel="nofollow">Related work</a></p> 
<p id="Convolutional%20neural%20network%EF%BC%88%E7%95%A5%E5%8E%BB%EF%BC%89-toc" style="margin-left:40px;"><a href="#Convolutional%20neural%20network%EF%BC%88%E7%95%A5%E5%8E%BB%EF%BC%89" rel="nofollow">Convolutional neural network（略去）</a></p> 
<p id="Attention%20mechanisms-toc" style="margin-left:40px;"><a href="#Attention%20mechanisms" rel="nofollow">Attention mechanisms</a></p> 
<p id="Experiments%20and%20analysis-toc" style="margin-left:40px;"><a href="#Experiments%20and%20analysis" rel="nofollow">Experiments and analysis</a></p> 
<p id="Setting-toc" style="margin-left:80px;"><a href="#Setting" rel="nofollow">Setting</a></p> 
<p id="Conclusion-toc" style="margin-left:40px;"><a href="#Conclusion" rel="nofollow">Conclusion</a></p> 
<hr id="hr-toc"> 
<h2 id="Landslide%20detection%20from%20an%20open%20satellite%20imagery%20and%20digital%20elevation%20model%20dataset%20using%20attention%20boosted%20convolutional%20neural%20networks" style="margin-left:0cm;">Landslide detection from an open satellite imagery and digital elevation model dataset using attention boosted convolutional neural networks</h2> 
<h2 id="%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%A2%9E%E5%BC%BA%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8E%E5%BC%80%E6%94%BE%E7%9A%84%E5%8D%AB%E6%98%9F%E5%9B%BE%E5%83%8F%E5%92%8C%E6%95%B0%E5%AD%97%E9%AB%98%E7%A8%8B%E6%A8%A1%E5%9E%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A3%80%E6%B5%8B%E6%BB%91%E5%9D%A1" style="margin-left:0cm;"><strong>使用注意力增强卷积神经网络从开放的卫星图像和数字高程模型数据集检测滑坡</strong></h2> 
<h3 id="%E6%91%98%E8%A6%81%EF%BC%9A" style="margin-left:0cm;">摘要：</h3> 
<p style="margin-left:0cm;">卷积神经网络(Convolution neural network, CNN)是一种有效且流行的深度学习方法，它通过一系列卷积层自动学习从原始输入到给定标签或ground truth的复杂非线性映射。本研究的重点是利用基于cnn的方法从高分辨率光学卫星图像中检测滑坡，为识别潜在滑坡提供机会，并以高精度和时间效率更新大规模滑坡清单。针对滑坡的多样性和复杂背景，开发了源于人类视觉系统的注意机制，用于增强CNN从背景中提取更有特色的滑坡特征表征。由于深度学习需要大量的标记数据来训练一个学习模型，我们手工制作了一个位于<strong>中国毕节市的滑坡数据集</strong>。在数据集中，地质学者利用卫星图像和数字高程模型(digital elevation model, DEM)数据对<strong>770个滑坡</strong>进行了解释，并进一步通过野外工作进行了验证，其中包括岩崩、岩崩和少量岩屑滑坡。将滑坡数据以2:1的比例分成训练训练CNN模型的训练集和评估模型性能的测试集。试验结果表明，滑坡检测的最佳<strong>f1得分为96.62%</strong>。结果还证明，我们的<strong>空间通道注意机制</strong>的表现是相当高于其他最近的注意机制。此外，还证明了基于我们的数据集高效预测新的潜在滑坡的有效性。</p> 
<h3 id="Introduction" style="margin-left:0cm;">Introduction</h3> 
<p style="margin-left:0cm;">滑坡检测的必要性；实地考察费时费力；基于InSAR or satellite InSAR数据的自动化检测方法相继被提出。最近光学影像也引起关注。数字高程模型数据提供地形信息，在滑坡预测和识别中发挥重要作用。</p> 
<p style="margin-left:0cm;">将滑坡检测视为一个图像处理问题，数理统计和机器学习的方法被广泛应用。</p> 
<p style="margin-left:0cm;">SVM,RF,ANN…CNN</p> 
<p style="margin-left:0cm;">对于这些监督的机器/深度学习方法，需要高质量的带标签的滑坡数据作为训练和测试集，这样滑坡的显著性特征可以被自动学习到。因此构建带标签的遥感滑坡影像数据集至关重要。至今也没有公开的数据集。</p> 
<p style="margin-left:0cm;">CNN的特征提取能力超越了经验特征设计方法；在图像分类，目标检测，语义分割领域广泛应用。但基于CNN的滑坡检测的方法却刚刚起步。（介绍了一些论文。）都是比较浅层的网络。因此应该设计更复杂和具体的CNN架构，以提取滑坡区域在复杂背景下的独特表现。</p> 
<p style="margin-left:0cm;">考虑到开放数据集的缺乏以及从遥感数据中检测滑坡的高级算法的需求，我们在本文中做出了两个主要贡献:</p> 
<ol><li>我们设计了一个新颖的注意模块，生成三维空间和通道注意特征图，以强调复杂背景下不同滑坡实例的独特特征。注意力模块被整合到最先进的CNN结构中。滑坡检测中的注意模块大大加强了这些结构。我们的算法在实验上优于基线网络和由其他近期注意力机制推动的网络。</li><li>我们创建了一个开放、准确、大型的滑坡数据集，包括滑坡/非滑坡图像、滑坡边界的shapefiles和相应的DEM数据，可访问http://study.rsgis.whu.edu.cn/pages/download/。这是第一个经过仔细的三重检查的开放的滑坡遥感数据集。我们认为，这将推动光学遥感影像滑坡自动检测的研究</li></ol> 
<h3 id="Related%20work" style="margin-left:0cm;">Related work</h3> 
<p style="margin-left:0cm;">介绍了CNN: AlexNet，VGGNet，Inception，ResNet，DenseNet，WideResNet，ResNeXt，Xception</p> 
<p style="margin-left:0cm;">light-weight networks：SqueezeNet，MobileNet，适应实时的应用。</p> 
<p style="margin-left:0cm;">发展方向：wider,deeper,transforms,降低计算复杂度，减少参数量。</p> 
<p style="margin-left:0cm;"><strong>在本研究中</strong>，我们在这些经典网络的基础上开发了我们的attention模块，并选择最佳的一个用于滑坡检测。</p> 
<p style="margin-left:0cm;">介绍注意力机制，在CNN上应用注意力机制可以加强前景的特征。注意模块从CNN中提取特征图，通过突出前景，输出正则化特征图。</p> 
<p style="margin-left:0cm;">介绍了许多集成注意力的模块。</p> 
<p style="margin-left:0cm;"><strong>在这项工作中</strong>，我们开发了我们的3D注意模块，它在注意力图的推断阶段同时提取综合的空间和通道信息，这不同于上述分别处理空间和通道的注意模块。在滑坡检测任务中，与先进的SE、BAM和CBAM模块相比，我们的注意力模块获得了最好的性能。</p> 
<p style="margin-left:0cm;">研究区域覆盖毕节市全境，面积26853平方公里，位于中国贵州省西北部（图1）。该区地处青藏高原向东丘陵过渡地带，海拔457～2900m，地质不稳定，山坡多，雨量充沛（年平均降雨量849～1399mm），脆弱的生态环境使该地区成为我国滑坡最严重的地区之一。毕节市滑坡类型主要有崩塌岩滑和少量泥石流。每年都会发生许多新的山体滑坡，其中一些可能对人类住区、道路、桥梁、输电线路和农田造成毁灭性的破坏。目前，这里的滑坡主要是通过两种方法或两种方法的结合来发现的。一种是通过卫星/航空光学图像和数字高程模型（DEM）进行室内人工判读，然后通常进行精确的实地测量。也通过居民的汇报，进行测量。</p> 
<p style="margin-left:0cm;">根据图像目视解译缺少效率，并且需要额外的地理学知识。实地考察具有危险性并且浪费时间。报告通常是滞后的。对于滑坡的早期预警、风险评估和灾后恢复，特别是在紧急情况下，对自动化、高效、可靠的滑坡检测方法有着<strong>强烈的需求。</strong></p> 
<p style="margin-left:0cm;">创建了一个数据集；数据介绍；</p> 
<p style="text-align:center;"><img alt="" height="187" src="https://images2.imgbox.com/74/2d/jMiDJXgb_o.png" width="577"></p> 
<p> </p> 
<p style="text-align:center;"><img alt="" height="319" src="https://images2.imgbox.com/07/89/PiGrHvdq_o.png" width="609"></p> 
<p style="margin-left:0cm;">滑坡的边缘标记是由中国地质灾害防治与地质环境保护国家重点实验室的专家进行的。</p> 
<p style="margin-left:0cm;"><strong>从图像中看不出来的滑坡，删掉了。（只能通过实地考察看出来。）因为它会迷惑CNN模型。</strong></p> 
<p style="margin-left:0cm;">一些地质滑坡形态特征明显的地区被标记为新的<strong>潜在滑坡</strong>。</p> 
<h3 id="Convolutional%20neural%20network%EF%BC%88%E7%95%A5%E5%8E%BB%EF%BC%89" style="margin-left:0cm;">Convolutional neural network（略去）</h3> 
<p style="margin-left:0cm;">介绍了CNN原理；多种CNN结构；</p> 
<h3 id="Attention%20mechanisms" style="margin-left:0cm;">Attention mechanisms</h3> 
<p style="margin-left:0cm;">基于CNN的注意机制可以看作是自适应模块，它强调输入特征图的某些部分，抑制主干CNN中的其他部分。在图像分类任务中，注意力模块的设计是为了突出前景，抵抗噪声背景。</p> 
<p style="margin-left:0cm;">介绍了三个受欢迎的attention模块。three popular attention modules</p> 
<p>（1）The squeeze-and-excitation (SE) module</p> 
<p style="margin-left:0cm;">关注给定输入特征图的通道间关系。</p> 
<p style="margin-left:0cm;">global average pooling (AvgPool) + MLP</p> 
<p>（2）The bottleneck attention module (BAM)</p> 
<p style="margin-left:0cm;">分别利用渠道通道和空间注意机制。</p> 
<p style="margin-left:0cm;"><strong><em>channel attention</em></strong>：依次应用全局AvgPool、MLP和BN层生成通道注意图<img alt="" height="19" src="https://images2.imgbox.com/99/f5/jCiAN6bt_o.png" width="106"></p> 
<p style="margin-left:0cm;"><strong><em>spatial attention branch</em></strong>：BAM中的空间注意分支生成空间注意图<img alt="" height="22" src="https://images2.imgbox.com/2c/fd/mjEvPCpS_o.png" width="121">，帮助网络发现特征图应该关注的位置。通过四次卷积运算和一次BN运算得到空间注意图。</p> 
<p>（3）The convolutional block attention module (CBAM)</p> 
<p style="margin-left:0cm;">利用空间子模块和信道注意子模块来发现特征图中哪些位置和信道需要加强或抑制。</p> 
<p style="margin-left:0cm;">在channel attention子模块中，使用全局平均池(AvgPool)和全局最大池(MaxPool)对空间信息进行聚合，然后使用权重共享的MLP，再使用元素求和和sigmoid激活函数。</p> 
<p style="margin-left:0cm;">对于空间注意子模块，采用了沿通道轴的全局平均pooling和全局最大pooling;将它们的输出拼接起来,再通过卷积核大小为7x7的卷积层和sigmoid；</p> 
<p style="margin-left:0cm;">依次对CBAM的通道注意子模块和空间注意子模块进行细化。</p> 
<p style="margin-left:0cm;">本文提出的<strong>spatial and channel attention module (3D SCAM)</strong> ，与上面方法不同。</p> 
<p style="margin-left:0cm;">我们生成了一个整合（integrated）的空间和通道注意图，而不是分别处理一个通道和一个空间注意图;后者无法达到通道与空间的全局一致性。</p> 
<p style="text-align:center;"><img alt="" height="167" src="https://images2.imgbox.com/56/83/NNI4Bfg3_o.png" width="612"></p> 
<p style="margin-left:0cm;">Input feature map à global poolingàspatial ,channel descriptoràConv Block</p> 
<p style="margin-left:0cm;">设计一个Conv Block: 细化空间-通道依赖关系。</p> 
<p style="text-align:center;"><img alt="" height="154" src="https://images2.imgbox.com/94/68/vWOLnFca_o.png" width="474"></p> 
<p style="margin-left:0cm;">实现的时候，对输入特征图分别做了global ave pooling,global max pooling，再分别输入到两个Conv Block中（不共享权重），最终两个输出按元素求和，并被sigmoid激活，生成最后的3D空间-通道注意力图。（还挺复杂的。）</p> 
<p style="text-align:center;"><img alt="" height="129" src="https://images2.imgbox.com/09/cd/Tpdnin1l_o.png" width="586"></p> 
<p style="margin-left:0cm;">我们将我们的3D注意力模块放在resnet风格的网络的最后一个残块的隐藏层中。</p> 
<p style="text-align:center;"><img alt="" height="232" src="https://images2.imgbox.com/f5/e2/AntzZDii_o.png" width="573"></p> 
<h3 id="Experiments%20and%20analysis" style="margin-left:0cm;">Experiments and analysis</h3> 
<p style="margin-left:0cm;">实验设置，评价指标；</p> 
<p style="margin-left:0cm;">在DEM数据辅助进行下的滑坡检测；</p> 
<p style="margin-left:0cm;">不同网络结构的比较；</p> 
<p style="margin-left:0cm;">不同注意力机制方法的比较；</p> 
<p style="margin-left:0cm;">不同pooling方法比较；reduction ratio比较；注意力模块放的位置比较。</p> 
<h4 id="Setting" style="margin-left:0cm;">Setting</h4> 
<p style="margin-left:0cm;">Train_test: 2:1</p> 
<p style="text-align:center;"><img alt="" height="243" src="https://images2.imgbox.com/2b/4a/teeJJsI8_o.png" width="465"></p> 
<p style="margin-left:0cm;">A Linux PC with a GeForce GTX 1080 TI 11G  GPU and an Intel i5-8400 CPU</p> 
<p style="margin-left:0cm;">所有模型用ImageNet数据预训练60 epoch,batchsize32。</p> 
<p style="margin-left:0cm;">数据处理，增强。</p> 
<p style="margin-left:0cm;">The network outputs the probability of an image/DEM belonging to a landslide, and a <strong>threshold of 0.5 </strong>was adopted.</p> 
<p style="margin-left:0cm;"><strong>评价指标：</strong>precision, recall, accuracy, and F1-score</p> 
<p style="margin-left:0cm;">分别用vgg-16和resnet-50探索了引入DEM数据后的表现，如下表所示：</p> 
<p style="text-align:center;"><img alt="" height="157" src="https://images2.imgbox.com/ac/ce/D9mH7ObU_o.png" width="629"></p> 
<p style="margin-left:0cm;">实验表明，引入DEM数据后，性能都有相对的提高，但是只用DEM数据，结果就差的很多，这表明在滑坡检测中光学图像占据主要地位。DEM中的地形信息(高程、坡度、坡向)可以作为光学图像中一些混乱的纹理和形状（会导致预测误差）的补充信息。接下来的实验中，<strong>we use the combination of RGB images and DEM data as input.</strong></p> 
<p style="margin-left:0cm;">选取了很多主流的CNN模型，进行实验。结果表明ResNet结构与其他结构相比具有一定的整体优势。</p> 
<p style="text-align:center;"><img alt="" height="226" src="https://images2.imgbox.com/b2/e4/9h96TFsd_o.png" width="561"></p> 
<p style="margin-left:0cm;">因此接下来以ResNet进行注意力机制的对比实验。（3D SCAM ours）</p> 
<p style="margin-left:0cm;">ResNet 18, ResNet 50, ResNet 101.</p> 
<p style="text-align:center;"><img alt="" height="116" src="https://images2.imgbox.com/06/d2/aOtbeLnR_o.png" width="532"></p> 
<p style="text-align:center;"><img alt="" height="115" src="https://images2.imgbox.com/93/e7/3C4ZEvhE_o.png" width="535"></p> 
<p style="text-align:center;"><img alt="" height="113" src="https://images2.imgbox.com/bb/e1/COvEnQM3_o.png" width="518"></p> 
<p style="margin-left:0cm;"><a name="_Hlk52212880">实验结果表明，所有模型上：1. 加注意力机制的模型都比baseline好。2.我们的3D SCAM在所有模型上，表现最好。</a></p> 
<p style="margin-left:0cm;">还进行了注意力可视化，通过heat map看出我们的方法能覆盖更精确的滑坡区域，表明我们的方法对各种背景的干扰具有较好的鲁棒性。</p> 
<p style="margin-left:0cm;">Conv Block 中 不同reduction ratio比较</p> 
<p style="text-align:center;"><img alt="" height="121" src="https://images2.imgbox.com/31/0a/LG7KEzaO_o.png" width="554"></p> 
<p style="margin-left:0cm;">注意力模块放的位置比较：ResNet 最后一个残差块隐藏层后（这种性能好），还是Output特征图之后。</p> 
<p style="text-align:center;"><img alt="" height="232" src="https://images2.imgbox.com/3a/6e/b2TMlagy_o.png" width="434"></p> 
<p style="text-align:center;"><img alt="" height="96" src="https://images2.imgbox.com/eb/ed/HfWhoFlp_o.png" width="616"></p> 
<h3 id="Conclusion" style="margin-left:0cm;">Conclusion</h3> 
<p style="margin-left:0cm;">创建了一个大型滑坡检测数据集，0.8m的卫星图像分辨率，划定了滑坡边界, 高精度DEM（2m）。</p> 
<p style="margin-left:0cm;">提出先进的3D空间-通道注意力机制。（3D SCAM）</p> 
<p style="margin-left:0cm;">做了大量的对比试验进行调参。</p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/681da76c3e35da35965f11daf21474dc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">EasyExcel导出不同表头的Sheet页or分页查询导出</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/01d7bfe7e30e40de8b096926e3763c06/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">揭秘：腾讯会议背后的视频编码“神器”</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>