<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【PaperNotes】Embedding-based Retrieval in Facebook Search - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【PaperNotes】Embedding-based Retrieval in Facebook Search" />
<meta property="og:description" content="论文地址: ACM：https://dl.acm.org/doi/10.1145/3394486.3403305
arXiv：https://arxiv.org/abs/2006.11632
这是一篇Applied Data Science Track Paper，非Research Track Paper，侧重于工业界技术的落地。 从标题可以看出，论文介绍了Facebook（以下简称FB）的向量召回技术，也就是Embedding-Based Retrieval（EBR）。让我们开始吧，祝开卷有益！ 1. 预备知识 首先，搜索引擎的匹配策略按照查询关键词（Query）是否完全命中文档（Document，以下简称doc），可以分为两大类：term matching（以下译作文本匹配）与semantic matching（语义匹配）。
文本匹配，能够做到完全精确的匹配（Exact Match）。如果是中文，通常先对query进行分词，得到更细粒度的词（Term）；再用term去检索doc，term出现于doc则命中；然后取各个term检索结果的交集返回。
我之前看过一点《Introduction to Information Retrieval》，它的第一章就在讲布尔召回（Boolean Retrieval），正是上面这一套传统的做法。如果本文点赞破100，我就是不吃不喝也要啃完这部经典，与诸君交流分享。
语义匹配，不再追求完全精确的匹配，而是力图满足用户的搜索意图（Search Intent），也就是意会。用户输入的query，只是Ta搜索意图的一种表达形式而已，比如“美国前总统”、“唐纳德・特郎普”、“川普”都是“懂王”。要表示用户意图，就用到了本文的主角embedding，一种用稠密向量（Dense Vector，没有特殊说明，后文的向量都指稠密向量）来表征对象的形式（Representation）。然后基于query embedding与doc embedding来计算结果。
一个有趣的说法：万物皆可embedding。没那么高深，就是用向量来表示对象，然后用向量之间的计算来表示对象之间的关系。换个说法，如果你是一个丹青圣手，万物皆可入画，你可以用画中世界来反映现实世界。Embedding也是类似，不过是以它的方式来描摹这个世界。
按阶段划分，搜索引擎通常有两个大的步骤：召回（Retrieval）与排序（Ranking）。召回，算是一个比较生僻的词，新闻里偶尔报道“问题产品的召回”，搜索中召回是同样的意思，就是尽可能把涉及的相关的doc一个不漏找全了，宁抓错不放过，前文的两类匹配策略也可以说是召回策略；排序的话，就是在召回的基础上，把更相关的、更符合用户意图的doc排在更显眼的位置。
说到这儿，论文将要介绍的EBR应该比较清晰了：用embedding来表示query与doc，得到query embedding与doc embedding，将召回问题转化为向量空间中的最近邻搜索问题。
在搜索召回时应用EBR的一个挑战是：召回是万里挑一的工作，从海量的数据——上千万甚至亿级的doc中，找出成百上千相关的doc。这对于embeddings的训练与使用都是极其严峻的考验。
且看，FB是如何迎难而上的。
2. 本文工作 FB按照阶段划分了面临的挑战，并提出了不同的解决方案：
建模（Modeling）。他们提出了unified embedding——一个双塔模型，一端是query，另一端是doc；
服务（Serving）。针对多通道召回（EBR 与布尔召回）的问题，他们开发了一个混合召回框架；
全栈优化。为了对整个搜索系统进行全面的优化，他们将embeddings 集成到了排序层，构造了一个数据闭环，以学习更好的embeddings。
上图是FB的EBR召回系统的概览，各位不妨先花两分钟研究一下，再继续往下看。
2.1 建模 搜索召回任务可以公式化为召回优化问题，即给定query、与query相关的doc全集 、模型召回的topK个结果 ，最大化：也就是，尽可能将相关的doc找全了。
前文提到EBR将召回问题转化为向量空间中的最近邻搜索问题，EBR模型返回的topK个结果就是“向量空间中，与query embedding‘距离’最近的doc embeddings表示的K个docs”。
建模的目的就在于：如何构造query embedding与doc embedding。在此，FB并没有太多的创新，使用了目前业界常用的双塔模型——用两个神经网络分别作为query与doc的编码器，如下所示。
与常规方法（仅文本进行编码）不同的是，他们在query侧与doc侧都加入了辅助特征，比如query侧加入了用户的位置、社交关系等，是为unified（大一统的） embedding。
值得注意的是，对于类别特征（Categorical Feature），他们的处理与文本一样，先做embedding，再将得到的特征向量输入编码器，同其他特征一起计算unified embedding。
从信息的视角来看，unified embedding的有效性高度依赖于添加的特征补充的信息量。
文章简要介绍了几点特征工程的工作：
文本特征：通过char n-gram补充了subword信息；
位置特征：在query侧，补充了搜索发起者的城市、地域、国家、使用语言；在document侧，补充了开放性的位置信息，比如群组的位置；
社交embedding特征：为了更好地利用社交网络信息，基于社交图谱训练了一个embedding模型。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/a5178d384b8d15a7162b8ac8bf99c40b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-05-24T12:12:00+08:00" />
<meta property="article:modified_time" content="2021-05-24T12:12:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【PaperNotes】Embedding-based Retrieval in Facebook Search</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <blockquote> 
  <p>论文地址: </p> 
  <ol><li><p> ACM：https://dl.acm.org/doi/10.1145/3394486.3403305</p></li><li><p>arXiv：https://arxiv.org/abs/2006.11632<br></p></li></ol> 
  这是一篇Applied Data Science Track Paper，非Research Track Paper，侧重于工业界技术的落地。 
 </blockquote> 
 从标题可以看出，论文介绍了Facebook（以下简称FB）的向量召回技术，也就是Embedding-Based Retrieval（EBR）。让我们开始吧，祝开卷有益！ 
 <h3>1. 预备知识</h3> 
 <p>首先，搜索引擎的匹配策略按照查询关键词（Query）是否完全命中文档（Document，以下简称doc），可以分为两大类：<strong>term matching（以下译作文本匹配）</strong>与<strong>semantic matching（语义匹配）</strong>。</p> 
 <p>文本匹配，能够做到完全精确的匹配（Exact Match）。如果是中文，通常先对query进行分词，得到更细粒度的词（Term）；再用term去检索doc，term出现于doc则命中；然后取各个term检索结果的交集返回。</p> 
 <blockquote> 
  <p>我之前看过一点《Introduction to Information Retrieval》，它的第一章就在讲布尔召回（Boolean Retrieval），正是上面这一套传统的做法。如果本文点赞破100，我就是不吃不喝也要啃完这部经典，与诸君交流分享。</p> 
 </blockquote> 
 <p>语义匹配，不再追求完全精确的匹配，而是力图满足用户的搜索意图（Search Intent），也就是<strong>意会</strong>。用户输入的query，只是Ta搜索意图的一种表达形式而已，比如“美国前总统”、“唐纳德・特郎普”、“川普”都是“懂王”。要表示用户意图，就用到了本文的主角embedding，一种用稠密向量（Dense Vector，没有特殊说明，后文的向量都指稠密向量）来表征对象的形式（Representation）。然后基于query embedding与doc embedding来计算结果。</p> 
 <blockquote> 
  <p>一个有趣的说法：万物皆可embedding。没那么高深，就是用向量来表示对象，然后用向量之间的计算来表示对象之间的关系。换个说法，如果你是一个丹青圣手，万物皆可入画，你可以用画中世界来反映现实世界。Embedding也是类似，不过是以它的方式来描摹这个世界。</p> 
 </blockquote> 
 <p>按阶段划分，搜索引擎通常有两个大的步骤：召回（Retrieval）与排序（Ranking）。召回，算是一个比较生僻的词，新闻里偶尔报道“问题产品的召回”，搜索中召回是同样的意思，就是<strong>尽可能把涉及的相关的doc一个不漏找全了，宁抓错不放过</strong>，前文的两类匹配策略也可以说是召回策略；排序的话，就是在召回的基础上，把更相关的、更符合用户意图的doc排在更显眼的位置。</p> 
 <p>说到这儿，论文将要介绍的EBR应该比较清晰了：用embedding来表示query与doc，得到query embedding与doc embedding，将召回问题转化为<strong>向量空间中的最近邻搜索问题</strong>。</p> 
 <p>在搜索召回时应用EBR的一个挑战是：<strong>召回是万里挑一的工作，从海量的数据——上千万甚至亿级的doc中，找出成百上千相关的doc。这对于embeddings的训练与使用都是极其严峻的考验</strong>。</p> 
 <p>且看，FB是如何迎难而上的。</p> 
 <h3>2. 本文工作</h3> 
 <p>FB按照阶段划分了面临的挑战，并提出了不同的解决方案：</p> 
 <ol><li><p>建模（Modeling）。他们提出了unified embedding——一个双塔模型，一端是query，另一端是doc；</p></li><li><p>服务（Serving）。针对多通道召回（EBR 与布尔召回）的问题，他们开发了一个混合召回框架；</p></li><li><p>全栈优化。为了对整个搜索系统进行全面的优化，他们将embeddings 集成到了排序层，构造了一个数据闭环，以学习更好的embeddings。</p></li></ol> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/1f/1f/OrKuVRMx_o.png"></p> 
 <p>上图是FB的EBR召回系统的概览，各位不妨先花两分钟研究一下，再继续往下看。</p> 
 <h4>2.1 建模</h4> 
 <p>搜索召回任务可以公式化为<strong>召回优化问题</strong>，即<em>给定query、与query相关的doc全集 
    <svg xmlns="http://www.w3.org/2000/svg" width="16.467ex" height="1.971ex" viewbox="0 -677 7278.2 871" style="vertical-align: -0.439ex;"> 
     <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
      <g> 
       <g> 
        <path d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path> 
       </g> 
       <g transform="translate(981.8, 0)"> 
        <path d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path> 
       </g> 
       <g transform="translate(2037.6, 0)"> 
        <g> 
         <g> 
          <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
         </g> 
         <g transform="translate(361, -150) scale(0.707)"> 
          <path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path> 
         </g> 
        </g> 
        <g transform="translate(764.6, 0)"> 
         <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
        </g> 
        <g transform="translate(1209.2, 0)"> 
         <g> 
          <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
         </g> 
         <g transform="translate(361, -150) scale(0.707)"> 
          <path d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path> 
         </g> 
        </g> 
        <g transform="translate(1973.8, 0)"> 
         <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
        </g> 
        <g transform="translate(2418.4, 0)"> 
         <path d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250ZM525 250Q525 274 542 292T585 310Q609 310 627 294T646 251Q646 226 629 208T586 190T543 207T525 250ZM972 250Q972 274 989 292T1032 310Q1056 310 1074 294T1093 251Q1093 226 1076 208T1033 190T990 207T972 250Z"></path> 
        </g> 
        <g transform="translate(3757.1, 0)"> 
         <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
        </g> 
        <g transform="translate(4201.8, 0)"> 
         <g> 
          <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
         </g> 
         <g transform="translate(361, -150) scale(0.707)"> 
          <g> 
           <path d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path> 
          </g> 
         </g> 
        </g> 
       </g> 
      </g> 
     </g> 
    </svg>、模型召回的topK个结果  
    <svg xmlns="http://www.w3.org/2000/svg" width="12.874ex" height="2.009ex" viewbox="0 -694 5690.1 888" style="vertical-align: -0.439ex;"> 
     <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
      <g> 
       <g> 
        <g> 
         <g> 
          <path d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path> 
         </g> 
         <g transform="translate(520, -150) scale(0.707)"> 
          <path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path> 
         </g> 
        </g> 
        <g transform="translate(923.6, 0)"> 
         <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
        </g> 
        <g transform="translate(1368.2, 0)"> 
         <g> 
          <path d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path> 
         </g> 
         <g transform="translate(520, -150) scale(0.707)"> 
          <path d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path> 
         </g> 
        </g> 
        <g transform="translate(2291.8, 0)"> 
         <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
        </g> 
        <g transform="translate(2736.4, 0)"> 
         <path d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250ZM525 250Q525 274 542 292T585 310Q609 310 627 294T646 251Q646 226 629 208T586 190T543 207T525 250ZM972 250Q972 274 989 292T1032 310Q1056 310 1074 294T1093 251Q1093 226 1076 208T1033 190T990 207T972 250Z"></path> 
        </g> 
        <g transform="translate(4075.1, 0)"> 
         <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
        </g> 
        <g transform="translate(4519.8, 0)"> 
         <g> 
          <path d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path> 
         </g> 
         <g transform="translate(520, -150) scale(0.707)"> 
          <g> 
           <path d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path> 
          </g> 
         </g> 
        </g> 
       </g> 
      </g> 
     </g> 
    </svg>，最大化：</em><img src="https://images2.imgbox.com/59/ac/nl27tys6_o.png"><em>也就是，尽可能将相关的doc找全了。</em></p> 
 <p>前文提到EBR将召回问题转化为向量空间中的最近邻搜索问题，EBR模型返回的topK个结果就是“向量空间中，与query embedding‘距离’最近的doc embeddings表示的K个docs”。</p> 
 <p>建模的目的就在于：如何构造query embedding与doc embedding。在此，FB并没有太多的创新，使用了目前业界常用的双塔模型——用两个神经网络分别作为query与doc的编码器，如下所示。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/fe/b1/eBEOrrlM_o.png"></p> 
 <p>与常规方法（仅文本进行编码）不同的是，他们在query侧与doc侧都加入了辅助特征，比如query侧加入了用户的位置、社交关系等，是为<strong>unified（大一统的） embedding</strong>。</p> 
 <p>值得注意的是，对于类别特征（Categorical Feature），他们的处理与文本一样，先做embedding，再将得到的特征向量输入编码器，同其他特征一起计算unified embedding。</p> 
 <p>从信息的视角来看，unified embedding的有效性高度依赖于添加的特征补充的信息量。</p> 
 <p>文章简要介绍了几点特征工程的工作：</p> 
 <ol><li><p>文本特征：通过char <em>n</em>-gram补充了subword信息；</p></li><li><p>位置特征：在query侧，补充了搜索发起者的城市、地域、国家、使用语言；在document侧，补充了开放性的位置信息，比如群组的位置；</p></li><li><p>社交embedding特征：为了更好地利用社交网络信息，基于社交图谱训练了一个embedding模型。</p></li></ol> 
 <h4>2.2 训练</h4> 
 <p>训练使用的损失函数则是一个三元（Triplet）的间隔损失（Margin Loss）：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/d6/89/k0WKnZcK_o.png"></p> 
 <p>其中， 
   <svg xmlns="http://www.w3.org/2000/svg" width="1.009ex" height="1.439ex" viewbox="0 -442 446 636" style="vertical-align: -0.439ex;"> 
    <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
     <g> 
      <g> 
       <path d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path> 
      </g> 
     </g> 
    </g> 
   </svg>、 
   <svg xmlns="http://www.w3.org/2000/svg" width="2.534ex" height="2.041ex" viewbox="0 -694 1120.1 902" style="vertical-align: -0.471ex;"> 
    <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
     <g> 
      <g> 
       <g> 
        <path d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path> 
       </g> 
       <g transform="translate(520, -150) scale(0.707)"> 
        <g> 
         <path d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path> 
        </g> 
       </g> 
      </g> 
     </g> 
    </g> 
   </svg>、 
   <svg xmlns="http://www.w3.org/2000/svg" width="2.534ex" height="2.041ex" viewbox="0 -694 1120.1 902" style="vertical-align: -0.471ex;"> 
    <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
     <g> 
      <g> 
       <g> 
        <path d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path> 
       </g> 
       <g transform="translate(520, -150) scale(0.707)"> 
        <g> 
         <path d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path> 
        </g> 
       </g> 
      </g> 
     </g> 
    </g> 
   </svg> 分别表示query、与query相关的doc（正样本）、不相关的doc（负样本）， 
   <svg xmlns="http://www.w3.org/2000/svg" width="7.683ex" height="2.262ex" viewbox="0 -750 3395.7 1000" style="vertical-align: -0.566ex;"> 
    <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
     <g> 
      <g> 
       <path d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path> 
      </g> 
      <g transform="translate(828, 0)"> 
       <path d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path> 
      </g> 
      <g transform="translate(1217, 0)"> 
       <g> 
        <path d="M40 442L134 446Q228 450 229 450H235V273V165Q235 90 238 74T254 52Q268 46 304 46H319Q352 46 380 67T419 121L420 123Q424 135 425 199Q425 201 425 207Q425 233 425 249V316Q425 354 423 363T410 376Q396 380 369 380H356V442L554 450V267Q554 84 556 79Q561 62 610 62H623V31Q623 0 622 0Q603 0 527 -3T432 -6Q431 -6 431 25V56L420 45Q373 6 332 -1Q313 -6 281 -6Q208 -6 165 14T109 87L107 98L106 230Q106 358 104 366Q96 380 50 380H37V442H40Z"></path> 
       </g> 
      </g> 
      <g transform="translate(1856, 0)"> 
       <path d="M74 85Q74 120 97 145T159 171Q200 171 226 138Q258 101 258 37Q258 -5 246 -44T218 -109T183 -155T152 -184T135 -194Q129 -194 118 -183T106 -164Q106 -157 115 -149Q121 -145 130 -137T161 -100T195 -35Q197 -28 200 -17T204 3T205 11T199 9T183 3T159 0Q120 0 97 26T74 85Z"></path> 
      </g> 
      <g transform="translate(2341.7, 0)"> 
       <g> 
        <path d="M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z"></path> 
       </g> 
      </g> 
      <g transform="translate(2948.7, 0)"> 
       <path d="M231 251Q231 354 214 439T173 575T123 661T81 714T64 735Q64 744 73 749H75Q77 749 79 749T84 750T90 750H105Q132 732 159 708T220 639T281 542T325 413T343 251T325 89T281 -40T221 -138T159 -207T105 -249H90Q80 -249 76 -249T68 -245T64 -234Q64 -230 81 -212T123 -160T172 -75T214 61T231 251Z"></path> 
      </g> 
     </g> 
    </g> 
   </svg>是距离函数， 
   <svg xmlns="http://www.w3.org/2000/svg" width="1.986ex" height="1.025ex" viewbox="0 -442 878 453" style="vertical-align: -0.025ex;"> 
    <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
     <g> 
      <g> 
       <path d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path> 
      </g> 
     </g> 
    </g> 
   </svg>则是间隔（Margin）。</p> 
 <p>距离函数与相似度函数是一组相对的概念。作者使用常规的<strong>余弦相似度（Cosine Similarity）</strong>来度量query embedding与doc embedding的相似度： 
   <svg xmlns="http://www.w3.org/2000/svg" width="20.354ex" height="2.933ex" viewbox="0 -750 8996.4 1296.4" style="vertical-align: -1.236ex;"> 
    <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
     <g> 
      <g> 
       <path d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path> 
       <path d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path> 
       <path d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path> 
      </g> 
      <g transform="translate(1338, 0)"> 
       <path d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path> 
      </g> 
      <g transform="translate(1727, 0)"> 
       <g> 
        <path d="M40 442L134 446Q228 450 229 450H235V273V165Q235 90 238 74T254 52Q268 46 304 46H319Q352 46 380 67T419 121L420 123Q424 135 425 199Q425 201 425 207Q425 233 425 249V316Q425 354 423 363T410 376Q396 380 369 380H356V442L554 450V267Q554 84 556 79Q561 62 610 62H623V31Q623 0 622 0Q603 0 527 -3T432 -6Q431 -6 431 25V56L420 45Q373 6 332 -1Q313 -6 281 -6Q208 -6 165 14T109 87L107 98L106 230Q106 358 104 366Q96 380 50 380H37V442H40Z"></path> 
       </g> 
      </g> 
      <g transform="translate(2366, 0)"> 
       <path d="M74 85Q74 120 97 145T159 171Q200 171 226 138Q258 101 258 37Q258 -5 246 -44T218 -109T183 -155T152 -184T135 -194Q129 -194 118 -183T106 -164Q106 -157 115 -149Q121 -145 130 -137T161 -100T195 -35Q197 -28 200 -17T204 3T205 11T199 9T183 3T159 0Q120 0 97 26T74 85Z"></path> 
      </g> 
      <g transform="translate(2851.7, 0)"> 
       <g> 
        <path d="M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z"></path> 
       </g> 
      </g> 
      <g transform="translate(3458.7, 0)"> 
       <path d="M231 251Q231 354 214 439T173 575T123 661T81 714T64 735Q64 744 73 749H75Q77 749 79 749T84 750T90 750H105Q132 732 159 708T220 639T281 542T325 413T343 251T325 89T281 -40T221 -138T159 -207T105 -249H90Q80 -249 76 -249T68 -245T64 -234Q64 -230 81 -212T123 -160T172 -75T214 61T231 251Z"></path> 
      </g> 
      <g transform="translate(4183.4, 0)"> 
       <path d="M87 333Q64 343 64 362Q64 383 84 391Q89 393 448 393H807Q808 392 811 390T817 386T823 381T827 374T829 363Q829 345 807 333H87ZM87 109Q64 118 64 139Q64 159 86 168Q89 169 448 169H807L812 166Q816 163 818 162T823 157T827 149T829 139Q829 118 807 109H87Z"></path> 
      </g> 
      <g transform="translate(5355.2, 0)"> 
       <g transform="translate(1122.3, 394) scale(0.707)"> 
        <g> 
         <g> 
          <path d="M40 442L134 446Q228 450 229 450H235V273V165Q235 90 238 74T254 52Q268 46 304 46H319Q352 46 380 67T419 121L420 123Q424 135 425 199Q425 201 425 207Q425 233 425 249V316Q425 354 423 363T410 376Q396 380 369 380H356V442L554 450V267Q554 84 556 79Q561 62 610 62H623V31Q623 0 622 0Q603 0 527 -3T432 -6Q431 -6 431 25V56L420 45Q373 6 332 -1Q313 -6 281 -6Q208 -6 165 14T109 87L107 98L106 230Q106 358 104 366Q96 380 50 380H37V442H40Z"></path> 
         </g> 
        </g> 
        <g transform="translate(639, 0)"> 
         <path d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path> 
        </g> 
        <g transform="translate(917, 0)"> 
         <g> 
          <path d="M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z"></path> 
         </g> 
        </g> 
       </g> 
       <g transform="translate(220, -370) scale(0.707)"> 
        <g> 
         <path d="M160 -249Q138 -249 129 -225V250Q129 725 131 729Q139 750 159 750T190 725V-225Q181 -249 160 -249Z"></path> 
        </g> 
        <g transform="translate(319, 0)"> 
         <g> 
          <path d="M160 -249Q138 -249 129 -225V250Q129 725 131 729Q139 750 159 750T190 725V-225Q181 -249 160 -249Z"></path> 
         </g> 
        </g> 
        <g transform="translate(638, 0)"> 
         <g> 
          <path d="M40 442L134 446Q228 450 229 450H235V273V165Q235 90 238 74T254 52Q268 46 304 46H319Q352 46 380 67T419 121L420 123Q424 135 425 199Q425 201 425 207Q425 233 425 249V316Q425 354 423 363T410 376Q396 380 369 380H356V442L554 450V267Q554 84 556 79Q561 62 610 62H623V31Q623 0 622 0Q603 0 527 -3T432 -6Q431 -6 431 25V56L420 45Q373 6 332 -1Q313 -6 281 -6Q208 -6 165 14T109 87L107 98L106 230Q106 358 104 366Q96 380 50 380H37V442H40Z"></path> 
         </g> 
        </g> 
        <g transform="translate(1277, 0)"> 
         <g> 
          <path d="M160 -249Q138 -249 129 -225V250Q129 725 131 729Q139 750 159 750T190 725V-225Q181 -249 160 -249Z"></path> 
         </g> 
        </g> 
        <g transform="translate(1596, 0)"> 
         <g> 
          <path d="M160 -249Q138 -249 129 -225V250Q129 725 131 729Q139 750 159 750T190 725V-225Q181 -249 160 -249Z"></path> 
         </g> 
        </g> 
        <g transform="translate(1915, 0)"> 
         <path d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path> 
        </g> 
        <g transform="translate(2193, 0)"> 
         <g> 
          <path d="M160 -249Q138 -249 129 -225V250Q129 725 131 729Q139 750 159 750T190 725V-225Q181 -249 160 -249Z"></path> 
         </g> 
        </g> 
        <g transform="translate(2512, 0)"> 
         <g> 
          <path d="M160 -249Q138 -249 129 -225V250Q129 725 131 729Q139 750 159 750T190 725V-225Q181 -249 160 -249Z"></path> 
         </g> 
        </g> 
        <g transform="translate(2831, 0)"> 
         <g> 
          <path d="M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z"></path> 
         </g> 
        </g> 
        <g transform="translate(3438, 0)"> 
         <g> 
          <path d="M160 -249Q138 -249 129 -225V250Q129 725 131 729Q139 750 159 750T190 725V-225Q181 -249 160 -249Z"></path> 
         </g> 
        </g> 
        <g transform="translate(3757, 0)"> 
         <path d="M160 -249Q138 -249 129 -225V250Q129 725 131 729Q139 750 159 750T190 725V-225Q181 -249 160 -249Z"></path> 
        </g> 
       </g> 
      </g> 
      <g transform="translate(8677.4, 0)"> 
       <path d="M74 85Q74 121 99 146T156 171Q200 171 222 143T245 85Q245 56 224 29T160 1Q118 1 96 27T74 85Z"></path> 
      </g> 
     </g> 
    </g> 
   </svg>因此，距离函数 
   <svg xmlns="http://www.w3.org/2000/svg" width="24.259ex" height="2.262ex" viewbox="0 -750 10722.3 1000" style="vertical-align: -0.566ex;"> 
    <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
     <g> 
      <g> 
       <path d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path> 
      </g> 
      <g transform="translate(828, 0)"> 
       <path d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path> 
      </g> 
      <g transform="translate(1217, 0)"> 
       <g> 
        <path d="M40 442L134 446Q228 450 229 450H235V273V165Q235 90 238 74T254 52Q268 46 304 46H319Q352 46 380 67T419 121L420 123Q424 135 425 199Q425 201 425 207Q425 233 425 249V316Q425 354 423 363T410 376Q396 380 369 380H356V442L554 450V267Q554 84 556 79Q561 62 610 62H623V31Q623 0 622 0Q603 0 527 -3T432 -6Q431 -6 431 25V56L420 45Q373 6 332 -1Q313 -6 281 -6Q208 -6 165 14T109 87L107 98L106 230Q106 358 104 366Q96 380 50 380H37V442H40Z"></path> 
       </g> 
      </g> 
      <g transform="translate(1856, 0)"> 
       <path d="M74 85Q74 120 97 145T159 171Q200 171 226 138Q258 101 258 37Q258 -5 246 -44T218 -109T183 -155T152 -184T135 -194Q129 -194 118 -183T106 -164Q106 -157 115 -149Q121 -145 130 -137T161 -100T195 -35Q197 -28 200 -17T204 3T205 11T199 9T183 3T159 0Q120 0 97 26T74 85Z"></path> 
      </g> 
      <g transform="translate(2341.7, 0)"> 
       <g> 
        <path d="M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z"></path> 
       </g> 
      </g> 
      <g transform="translate(2948.7, 0)"> 
       <path d="M231 251Q231 354 214 439T173 575T123 661T81 714T64 735Q64 744 73 749H75Q77 749 79 749T84 750T90 750H105Q132 732 159 708T220 639T281 542T325 413T343 251T325 89T281 -40T221 -138T159 -207T105 -249H90Q80 -249 76 -249T68 -245T64 -234Q64 -230 81 -212T123 -160T172 -75T214 61T231 251Z"></path> 
      </g> 
      <g transform="translate(3673.4, 0)"> 
       <path d="M87 333Q64 343 64 362Q64 383 84 391Q89 393 448 393H807Q808 392 811 390T817 386T823 381T827 374T829 363Q829 345 807 333H87ZM87 109Q64 118 64 139Q64 159 86 168Q89 169 448 169H807L812 166Q816 163 818 162T823 157T827 149T829 139Q829 118 807 109H87Z"></path> 
      </g> 
      <g transform="translate(4845.2, 0)"> 
       <path d="M481 0L294 3Q136 3 109 0H96V62H227V304Q227 546 225 546Q169 529 97 529H80V591H97Q231 591 308 647L319 655H333Q355 655 359 644Q361 640 361 351V62H494V0H481Z"></path> 
      </g> 
      <g transform="translate(5642.4, 0)"> 
       <path d="M119 221Q96 230 96 251T116 279Q121 281 448 281H775Q776 280 779 278T785 274T791 269T795 262T797 251Q797 230 775 221H119Z"></path> 
      </g> 
      <g transform="translate(6758.7, 0)"> 
       <path d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path> 
       <path d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path> 
       <path d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path> 
      </g> 
      <g transform="translate(8096.7, 0)"> 
       <path d="M103 166T103 251T121 412T165 541T225 639T287 708T341 750H356H361Q382 750 382 736Q382 732 365 714T323 661T274 576T232 439T214 250Q214 -62 381 -229Q382 -231 382 -234Q382 -249 360 -249H356H341Q314 -231 287 -207T226 -138T165 -41T121 89Z"></path> 
      </g> 
      <g transform="translate(8543.7, 0)"> 
       <g> 
        <path d="M40 442L134 446Q228 450 229 450H235V273V165Q235 90 238 74T254 52Q268 46 304 46H319Q352 46 380 67T419 121L420 123Q424 135 425 199Q425 201 425 207Q425 233 425 249V316Q425 354 423 363T410 376Q396 380 369 380H356V442L554 450V267Q554 84 556 79Q561 62 610 62H623V31Q623 0 622 0Q603 0 527 -3T432 -6Q431 -6 431 25V56L420 45Q373 6 332 -1Q313 -6 281 -6Q208 -6 165 14T109 87L107 98L106 230Q106 358 104 366Q96 380 50 380H37V442H40Z"></path> 
       </g> 
      </g> 
      <g transform="translate(9182.7, 0)"> 
       <path d="M74 85Q74 120 97 145T159 171Q200 171 226 138Q258 101 258 37Q258 -5 246 -44T218 -109T183 -155T152 -184T135 -194Q129 -194 118 -183T106 -164Q106 -157 115 -149Q121 -145 130 -137T161 -100T195 -35Q197 -28 200 -17T204 3T205 11T199 9T183 3T159 0Q120 0 97 26T74 85Z"></path> 
      </g> 
      <g transform="translate(9668.3, 0)"> 
       <g> 
        <path d="M401 444Q413 441 495 441Q568 441 574 444H580V382H510L409 156Q348 18 339 6Q331 -4 320 -4Q318 -4 313 -4T303 -3H288Q273 -3 264 12T221 102Q206 135 197 156L96 382H26V444H34Q49 441 145 441Q252 441 270 444H279V382H231L284 264Q335 149 338 149Q338 150 389 264T442 381Q442 382 418 382H394V444H401Z"></path> 
       </g> 
      </g> 
      <g transform="translate(10275.3, 0)"> 
       <path d="M231 251Q231 354 214 439T173 575T123 661T81 714T64 735Q64 744 73 749H75Q77 749 79 749T84 750T90 750H105Q132 732 159 708T220 639T281 542T325 413T343 251T325 89T281 -40T221 -138T159 -207T105 -249H90Q80 -249 76 -249T68 -245T64 -234Q64 -230 81 -212T123 -160T172 -75T214 61T231 251Z"></path> 
      </g> 
     </g> 
    </g> 
   </svg>。</p> 
 <p>根据作者们的说法，损失函数中， 
   <svg xmlns="http://www.w3.org/2000/svg" width="1.986ex" height="1.025ex" viewbox="0 -442 878 453" style="vertical-align: -0.025ex;"> 
    <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
     <g> 
      <g> 
       <path d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path> 
      </g> 
     </g> 
    </g> 
   </svg>的选择很重要，会导致5-10%的离线召回偏差。</p> 
 <p>此外，<strong>训练样本的选择</strong>对于训练效果同样至关重要。本文的做法是，<strong>对于负样本，使用随机样本而不是展现未点击的样本</strong>。</p> 
 <p>这一点，有数据的支撑——使用展现未点击样本的召回效果明显更差。不过也很好理解：模型工作在召回层，召回的目的是海量样本中找全相关的样本。使用随机样本，召回候选集是全体样本，能够模拟真实自然的召回过程；而使用展现未点击样本，召回候选集是既有召回算法过滤后的、是有偏的，将导致模型习得的embeddings也是有偏的，无法习得未展现样本的特征。</p> 
 <p>至于正样本的选择，文章实验了点击样本与展现样本，在数据量相当的情况下，两种策略的效果相近。</p> 
 <h4>2.3 线上服务</h4> 
 <h5>2.3.1 近似近邻搜索</h5> 
 <p>向量召回的线上服务主要依赖于近似近邻搜索算法（Approximate Near Neighbor，ANN）来建立倒排索引。这一技术方案的优点在于：</p> 
 <ol><li><p>向量量化（Quantization of embedding vectors）使得存储的成本更低；</p></li><li><p>保留了倒排索引，易于集成到当前的检索系统中。</p></li></ol> 
 <p>具体的实现则依赖于FB自家的Faiss。</p> 
 <p>向量量化有两大组件：Coarse Quantization（CQ）和Product Quantization（PQ），前者主要使用<strong>K-means</strong>将向量转成相对粗糙的聚类，后者则通过更加精细的量化来支持高效的距离计算。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/6c/d5/Ys6eTP2f_o.png"></p> 
 <p>CQ、PQ都有一些算法以及参数可供选择与调整（统称ANN的参数调整），对此感兴趣的同学可以去看原文或Faiss的Wiki。以下是几点tricks：</p> 
 <ol><li><p>参数调整时，以<strong>召回率/扫描的文档数</strong>为指标，比如recall@10；</p></li><li><p>最后再调整ANN的参数，或者说一旦向量召回的模型重大变更，ANN的参数务必重新调整；</p></li><li><p>务必尝试OPO（PQ的一种算法）；</p></li><li><p>将pq_bytes（PQ算法的一项参数，指定了字节数）设为d/4（d是向量的维数）；</p></li><li><p>以线上实验效果为准，调整nprobe（决定了将为query_emb分配的聚类数），num_clusters，pq_bytes，从而更好地去理解它们对真实性能的影响。</p></li></ol> 
 <h5>2.3.1 系统实现</h5> 
 <p>在集成向量召回之前，让我们先来简单地看一看FB原来的检索系统（被称为Unicorn，独角兽）是怎样的。</p> 
 <p>以bag of terms来表示一篇doc，term并不限于文本，而是可以表征任意的二值属性，比如“北京的赵喧典”拥有的属性就包括“text:赵喧典”和“location:北京”。</p> 
 <p>类似地，以上述形式来表示一个query，比如“北京或浙江的赵喧典”，它的布尔表达式就是<code>(and (or (term location:北京)(term location:浙江)) (term text:赵喧典))</code>。利用布尔召回，将返回所有使得表达式为真的doc。</p> 
 <p>为了支持向量召回，检索系统为每一篇doc添加了额外的embedding字段。考虑到不同模型的向量召回，一篇doc可以绑定多个embedding，以不同的<code>&lt;model&gt;</code>作为区分。相应地，在query侧增加了形如<code>(nn &lt;model&gt; :radius &lt;radius&gt;)</code>的算子，表示doc需要满足在<code>&lt;model&gt;</code>向量空间中，doc_emb与query_emb的余弦距离小于<code>&lt;radius&gt;</code>。</p> 
 <p>上例中，“北京或浙江的赵喧典”，在追加向量召回通道之后，其布尔表达式就变为了：</p> 
 <pre class="has"><code class="language-php">(and
    (or (term location:北京) (term location:浙江))
    (or (term text:赵喧典) (nn M1 :radius 0.2333))
)
</code></pre> 
 <p>此处，FB的工程师们对比过按距离召回与按TOP K召回两种形式。前者在系统性能与召回结果的质量之间能取得更好的平衡，因为它对于搜索半径以及近邻的相似性都有所限制。</p> 
 <p>此外，为了提高向量召回的效率与质量，使用了query selection和index selection。</p> 
 <ol><li><p>所谓query selection，就是<strong>有选择性地触发向量召回</strong>，对于向量召回不的，比如搜索意图与模型训练的初衷不同的，或者过于简单的query，比如用户刚刚搜索过或点击过的，不进行向量召回。</p></li><li><p>所谓index selection，实际上是构建倒排索引时，只使用月活用户而不是全部用户，近期的事件，热门群组等。</p></li></ol> 
 <p>通过上述描述，我们能够知道，在双塔模型训练完毕之后，query embedding模型与doc embedding模型是分开使用的，这也是业界对双塔模型的常规使用方式。具体地，query_emb是在线实时推断的，而doc embedding模型是离线部署的，批量地为各个doc生成embedding，并发布到Faiss中。</p> 
 <h4>2.4 其他</h4> 
 <h5>2.4.1 整体优化与训练闭环</h5> 
 <p>考虑到既有的排序算法是为非向量召回的结果设计的，其排序结果对于向量召回通道的结果可能是次优的。FB的工程师们提出了以下两点解决思路：</p> 
 <ol><li><p>向量召回的embedding作为排序算法的特征。具体地，就是将向量相似度，或者向量召回模型吐出的原始向量透传给排序算法。实验表明，在FB的搜索场景下，透传<strong>余弦相似度</strong>对排序算法的提升最佳。</p></li><li><p>训练数据反馈闭环。相对于文本召回，向量召回提高了召回率（recall），但是精准率（precision）有所不如。财大气粗的FB引入了人工评估——将向量召回的结果落日志，人工评估召回结果的相关性，并用人工标注的结果重新训练模型，真正形成数据的闭环。</p></li></ol> 
 <h5>2.4.2 Hard Mining</h5> 
 <p>因为诸如文本召回、向量召回以及其他不同召回技术的混合使用（多通道召回），使得召回结果的数据分布极其多样。这对于向量召回模型的训练是一个不小的挑战——embedding的学习更加困难。</p> 
 <p>Hard mining是信息检索领域进行数据挖掘、构造合适训练集的技术的统称。</p> 
 <p>本文研究探讨了两类hard mining技术：</p> 
 <ol><li><p><strong>Hard negative mining</strong>。分析发现：当用户搜索人名时，同名情况下，向量召回模型没有充分利用样本的社交特征。这很可能是因为以随机样本作为负样本，负样本都是异名的，模型只需要关注文本特征即可。因此，工程师们提出使用与正样本更加相似的样本作为负样本来训练模型。</p></li><li><ol><li><p>Online hard negative mining（此处的online并非线上服务的意思，而是训练时构造hard negative samples的意思）。具体的做法是，对于一个query，维护了一个正样本的池子，训练时，使用与当前正样本最相似的2条作为负样本（该数量来自于实验观察），并补充上随机负样本。</p></li><li><ol><li><p>优点：带来了相当显著的召回率的提升；</p></li><li><p>缺点：拥有hard negative样本的比例相对随机负样本而言，很低。</p></li></ol> 
   </li><li><p>Offline hard negative mining（训练前，在构造训练样本时挖掘hard negative样本）。具体的做法是，先利用某一算法（KNN、ANN）得到与query最相似的N个doc，再基于一个基于业务特点的挑选策略选择若干负样本，然后对模型进行迭代训练。挑选负样本-模型迭代，是一个不断迭代的过程。以下是几点实验洞察：</p></li><li><ol><li><p>简单地用困难负样本训练的模型比随机负样本还差。分析发现，前者为非文本特征赋予了过多的权重，在文本匹配能力上差于后者；</p></li><li><p>挑选排序模型输出的位置在100-&gt;500（适合）的doc作为负样本，模型召回效果最佳；</p></li><li><p>保留随机负样本是极其必要的，它还原了召回的自然过程。可供参考的两种混合机制：1、混合随机样本与困难负样本，FB的最佳实践比例是100:1；2、迁移学习，先难后易，反之低效；</p></li><li><p>使用KNN来生成困难样本候选集的时间成本太高，可以直接上ANN。</p></li></ol> 
  </li></ol> 
  </li><li><p><strong>Hard positive mining</strong>。上文提到，使用点击样本或展现样本作为正样本的效果相似；而此处的做法是，从搜索日志中挖掘未展现的正样本。有效，但是想来成本是相当高的。</p></li></ol> 
 <ol></ol> 
 <h5>2.4.3 Embedding Ensemble</h5> 
 <p>Embedding Ensemble类似于model ensemble，就是集成多个不同的向量召回模型。在前文的介绍中，不同模型将关注到不同的特征，比如完全使用随机负样本的模型将更关注文本特征、召回能力更强，而使用困难负样本的模型的精准率更高、对排序更友好，因此embedding ensemble是一个自然能想到的优化的步骤。</p> 
 <p>是故，文章提出了多阶段召唤的方法：第一步关注扩召回，第二步在第一步的基础上关注区分相似的召回结果。并且，提供了两种思路：</p> 
 <ol><li><p><strong>Weighted concatenation</strong>：</p></li><li><ol><li><p>实际上该方式只有一步，以<strong>加权求和</strong>的方式对不同模型算得的余弦相似度进行汇总，作为query与doc最终的相似度，再取最相似的作为召回结果。</p></li><li><p>线上服务时，为了服务性能，将先计算余弦相似度再加权求和的方式，近似地变形为先拼接向量再计算且只计算一次余弦相似度。</p></li><li><p>因此，操作流程就是，不同向量加权拼接，以拼接后的向量在Faiss中进行查询。</p></li></ol> 
  </li><li><p><strong>瀑布模型</strong>：</p></li><li><ol><li><p>第一步使用简易的召回模型，可以是完全使用随机负样本训练的模型，甚至是text embedding而非unifed embedding，目的是触达更海量的候选集，不遗漏；</p></li><li><p>第二步使用精细一些的模型，比如使用离线困难负样本训练的模型，或者使用unified embedding代替text embedding，此时的目的是做一个类似rerank的动作，重新评估第一步得到的候选集中的doc与query的相似度，再按预设的召回量取TOP N条结果。</p></li></ol> 
 </li></ol> 
 <h3>3. 尾声</h3> 
 <p>我在半年前看完这篇论文，一直想写这篇笔记，与诸君交流，但总是写写停停；半年后，我有了更多的工作积累，这篇文章反而读厚了：刚毕业那会儿，我大概只能看到建模与训练部分，现在也会关注serving以及其他的工程实践。</p> 
 <p>原文真是一篇相当nice的论文，强烈建议翻一翻原文！</p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a7988020dd6d7cb047e4a76f2221a00f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python programming training(一)：最大回文子字符串</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a972fbcdb0ae3e972a29cf44df5e1d92/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">从模型制作（3dmax）到网页显示（babylonjs）全过程介绍</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>