<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop集群环境配置搭建 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Hadoop集群环境配置搭建" />
<meta property="og:description" content="一、简单介绍 Hadoop最早诞生于Cutting于1998年左右开发的一个全文文本搜索引擎
Lucene，这个搜索引擎在2001年成为Apache基金会的一个子项目，也是 ElasticSearch等重要搜索引擎的底层基础。
项目官方：https://hadoop.apache.org/
二、Linux环境搭建 首先准备三台Linux服务器，预装CentOS7。三台服务器之间需要网络互通。本地测试环境的IP地址分别为：192.168.2.128，192.168.2.129，
192.168.2.130
内存配置建议不低于4G，硬盘空间建议不低于50G。
1、配置hosts vi /etc/hosts 这里是给每个机器配置一个机器名。后续集群中都会通过机器名进行配 置管理，而不会再关注IP地址。
2、关闭防火墙 Hadoop集群节点之间需要进行频繁复杂的网络交互，在实验环境建议关闭防火墙。生产环境下，可以根据情况选择是按照端口配置复杂的防火墙规则或者关闭内部防火墙，使用堡垒机进行统一防护。
systemctl stop firewalld systemctl disable firewalld.service 3、配置SSH免密 1、在node01下执行，一路回车（四次）
ssh-keygen -t rsa 2、然后在 node01上执行
ssh-copy-id node01 3、输入 yes，然后回车，接着输入 root 密码，然后会得到如下日志
4、验证一下，在 node01节点执行
ssh node01 5、在node02，node03节点分别执行上述四个步骤（注意节点名称的替换）
6、最后分别在node01上执行
ssh-copy-id node02 ssh-copy-id node03 在node02上执行
ssh-copy-id node01 ssh-copy-id node03 同理，在node03上执行
ssh-copy-id node01 ssh-copy-id node02 7、查看是否成功免密登录
4、安装JDK 尽量不要使用Linux自带的OpenJDK。
卸载指令 ：rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/83b1ab6703a7616de547390cac8565a7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-10T16:48:00+08:00" />
<meta property="article:modified_time" content="2023-03-10T16:48:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop集群环境配置搭建</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="_0"></a>一、简单介绍</h3> 
<blockquote> 
 <p>Hadoop最早诞生于Cutting于1998年左右开发的一个全文文本搜索引擎<br> Lucene，这个搜索引擎在2001年成为Apache基金会的一个子项目，也是 ElasticSearch等重要搜索引擎的底层基础。</p> 
</blockquote> 
<p>项目官方：<a href="https://hadoop.apache.org/" rel="nofollow">https://hadoop.apache.org/</a></p> 
<h3><a id="Linux_7"></a>二、Linux环境搭建</h3> 
<p>首先准备三台Linux服务器，预装CentOS7。三台服务器之间需要网络互通。本地测试环境的IP地址分别为：192.168.2.128，192.168.2.129，<br> 192.168.2.130</p> 
<blockquote> 
 <p>内存配置建议不低于4G，硬盘空间建议不低于50G。</p> 
</blockquote> 
<h4><a id="1hosts_14"></a>1、配置hosts</h4> 
<pre><code>vi /etc/hosts
</code></pre> 
<p><img src="https://images2.imgbox.com/06/06/HKc9IjOM_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>这里是给每个机器配置一个机器名。后续集群中都会通过机器名进行配 置管理，而不会再关注IP地址。</p> 
</blockquote> 
<h4><a id="2_24"></a>2、关闭防火墙</h4> 
<blockquote> 
 <p>Hadoop集群节点之间需要进行频繁复杂的网络交互，在实验环境建议关闭防火墙。生产环境下，可以根据情况选择是按照端口配置复杂的防火墙规则或者关闭内部防火墙，使用堡垒机进行统一防护。</p> 
</blockquote> 
<pre><code>systemctl stop firewalld
</code></pre> 
<pre><code>systemctl disable firewalld.service
</code></pre> 
<h4><a id="3SSH_36"></a>3、配置SSH免密</h4> 
<p>1、在node01下执行，一路回车（四次）</p> 
<pre><code>ssh-keygen -t rsa
</code></pre> 
<p>2、然后在 node01上执行</p> 
<pre><code>ssh-copy-id node01
</code></pre> 
<p>3、输入 yes，然后回车，接着输入 root 密码，然后会得到如下日志<br> <img src="https://images2.imgbox.com/02/32/MxvRTK3N_o.png" alt="在这里插入图片描述"></p> 
<p>4、验证一下，在 node01节点执行</p> 
<pre><code>ssh node01
</code></pre> 
<p><img src="https://images2.imgbox.com/9c/f6/FjFsEmIA_o.png" alt="在这里插入图片描述"></p> 
<p>5、在node02，node03节点分别执行上述四个步骤（<em><strong>注意节点名称的替换</strong></em>）</p> 
<p>6、最后分别在node01上执行</p> 
<pre><code>ssh-copy-id node02
ssh-copy-id node03
</code></pre> 
<p>在node02上执行</p> 
<pre><code>ssh-copy-id node01
ssh-copy-id node03
</code></pre> 
<p>同理，在node03上执行</p> 
<pre><code>ssh-copy-id node01
ssh-copy-id node02
</code></pre> 
<p>7、查看是否成功免密登录</p> 
<p><img src="https://images2.imgbox.com/d4/8a/f9Eq7IXD_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="4JDK_81"></a>4、安装JDK</h4> 
<blockquote> 
 <p>尽量不要使用Linux自带的OpenJDK。</p> 
 <p>卸载指令 ：rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</p> 
</blockquote> 
<p>自行下载JDK jdk-8u212-linux-x64.tar.gz。解压到/usr/java目录。<br> 最后配置一下jdk的环境变量<br> <em>（注：node01、node02、node03三个节点都按装部署jdk环境）</em></p> 
<pre><code>export JAVA_HOME=/usr/java/jdk1.8.0_291
export CLASSPATH=$JAVA_HOME/lib/
export PATH=$PATH:$JAVA_HOME/bin
</code></pre> 
<p><img src="https://images2.imgbox.com/36/1c/d0pkcYHM_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="5_98"></a>5、创建用户(可选)</h4> 
<p>这里直接使用系统提供的root用户来直接进行操作。</p> 
<blockquote> 
 <p>通常在正是的生产环境中，root用户都是要被严格管控的，这时就需要单独创建一个用户来管理这些应用</p> 
</blockquote> 
<h3><a id="Hadoop_104"></a>三、Hadoop集群搭建</h3> 
<h4><a id="1_106"></a>1、版本选择</h4> 
<p>这里选择的是3.2.2版本 <strong>hadoop-3.2.2.tar.gz</strong> ，下载地址：<a href="https://hadoop.apache.org/release/3.2.2.html" rel="nofollow">https://hadoop.apache.org/release/3.2.2.html</a></p> 
<h4><a id="2__109"></a>2、 集群机器角色规划</h4> 
<p><img src="https://images2.imgbox.com/c6/d5/oSYJ9qdX_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>其中，HDFS是一个分布式的文件系统，主要负责文件的存储。由NameNode、Secondary<br> NameNode和DataNode三种节点组成。HDFS上的文件，会以文件块(Block)的形式存储到不同的DataNode节点当中。NameNode则用来存储文件的相关元数据，比如文件名、文件目录结果、文件的块列表等。然后SecondaryNameNode则负责每隔一段时间对NameNode上的元数据进行备份。</p> 
</blockquote> 
<blockquote> 
 <p>Yarn是一个资源调度的工具，负责对服务器集群内的计算资源，主要是CPU和内存，进行合理的分配与调度。由ResourceManager和NodeManager两种节点组成。ResourceManager负责对系统内的计算资源进行调度分配，将计算任务分配到具体的NodeManger节点上执行。而NodeManager则负责具体的计算任务执行。</p> 
</blockquote> 
<h4><a id="3Hadoop_120"></a>3、按装Hadoop</h4> 
<p>1、在所有虚拟机根目录下新建文件夹export，export文件夹中新建data、servers和software文件</p> 
<pre><code>mkdir -p /export/data
mkdir -p /export/servers
mkdir -p /export/software
</code></pre> 
<p>2、解压Hadoop安装包</p> 
<pre><code>cd /export/software
tar -zxvf hadoop-3.2.2.tar.gz  -C /export/servers/
</code></pre> 
<p>3、配置hadoop环境变量</p> 
<p>打开配置文件</p> 
<pre><code>vi /etc/profile
</code></pre> 
<p>配置文件最后追加的配置</p> 
<pre><code>export HADOOP_HOME=/export/servers/hadoop-3.2.2
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
</code></pre> 
<p>使配置文件生效</p> 
<pre><code>source /etc/profile
</code></pre> 
<p>4、查看是否配置成功</p> 
<pre><code>hadoop version
</code></pre> 
<p><img src="https://images2.imgbox.com/43/db/DeoD5TTn_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="4Hadoop_155"></a>4、Hadoop集群配置</h4> 
<p>配置前先介绍一下配置文件<br> 以下所有的配置文件都在hadoop安装目录下etc文件中，路径如下：<br> <img src="https://images2.imgbox.com/e9/2d/tpUcD8L5_o.png" alt="在这里插入图片描述"><br> 需要配置的文件有以下6个<br> <img src="https://images2.imgbox.com/19/83/3yEPThQH_o.png" alt="在这里插入图片描述"></p> 
<p>1、配置hadoop-env.sh文件</p> 
<pre><code>vi hadoop-env.sh
#找到相应位置添加这段
export JAVA_HOME=/usr/java/jdk1.8.0_291
</code></pre> 
<p><img src="https://images2.imgbox.com/92/7a/wdVViBXY_o.png" alt="在这里插入图片描述"></p> 
<p>2、配置core-site.xml文件</p> 
<pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
	&lt;!-- 指定 NameNode 的地址 --&gt;
	&lt;property&gt;
		&lt;name&gt;fs.defaultFS&lt;/name&gt;
		&lt;value&gt;hdfs://node01:8020&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 指定 hadoop 数据的存储目录 --&gt;
	&lt;property&gt;
		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
		&lt;value&gt;/export/servers/hadoop-3.2.2/data&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 配置 HDFS 网页登录使用的静态用户为当前操作系统用户 --&gt;
	&lt;property&gt;
		&lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
		&lt;value&gt;root&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
<p>3、配置hdfs-site.xml文件</p> 
<pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
	&lt;!-- NameNode web 端访问地址--&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
		&lt;value&gt;node01:9870&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 2NameNode web 端访问地址--&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
		&lt;value&gt;node03:9868&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 备份数量 --&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.replication&lt;/name&gt;
		&lt;value&gt;2&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 打开webhdfs --&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
		&lt;value&gt;true&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;

</code></pre> 
<p>4、配置yarn-site.xml文件</p> 
<pre><code>&lt;?xml version="1.0"?&gt;
&lt;!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;
&lt;configuration&gt;
	&lt;!-- 指定 MR 走 shuffle --&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 指定 ResourceManager 的地址--&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
		&lt;value&gt;node02&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 环境变量的继承 跑示例时要用到--&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
		&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 开启日志聚集功能 --&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
		&lt;value&gt;true&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 设置日志聚集服务器地址 --&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.log.server.url&lt;/name&gt;
		&lt;value&gt;http://node01:19888/jobhistory/logs&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 设置日志保留时间为 7 天 --&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
		&lt;value&gt;604800&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;

</code></pre> 
<p>5、配置mapred-site.xml文件</p> 
<pre><code>&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;

&lt;configuration&gt;
	&lt;!-- 指定 MapReduce 程序运行在 Yarn 上 --&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
		&lt;value&gt;yarn&lt;/value&gt;
	&lt;/property&gt;
	&lt;!-- 历史服务器 web 端地址 --&gt;
	&lt;property&gt;
		&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
		&lt;value&gt;node01:19888&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;

</code></pre> 
<p>6、配置workers文件</p> 
<pre><code>node01
node02
node03
</code></pre> 
<p>7、将配置完成后的hadoop整体分发到另外的节点（<em><strong>完成node02、node03两个节点和node01相同的配置</strong></em>）</p> 
<pre><code>scp ~/.bash_profile root@node02:~
scp -r /export/servers/hadoop-3.2.2 root@node02:/export/servers/hadoop-3.2.2
scp ~/.bash_profile root@node03:~
scp -r /export/servers/hadoop-3.2.2 root@node03:/export/servers/hadoop-3.2.2
</code></pre> 
<h4><a id="5Hadoop_360"></a>5、启动Hadoop集群</h4> 
<p>1、<strong>先启动hdfs服务</strong>（<em><strong>在node01上启动NameNode、DataNode</strong></em>）<br> 第一次启动hdfs服务时，需要先对NameNode进行格式化。在NameNode所<br> 在的node01机器，执行<code>hadoop namenode -format</code>执行，完成初始化。初始化完成后，会在 <em>/export/servers/hadoop-3.2.2/data/dfs/name/current</em>目录下创建一个NameNode的镜像。</p> 
<p>接下来可以尝试启动hdfs了。 hadoop的启动脚本在hadoop下的sbin目录<br> 下。 start-dfs.sh就是启动hdfs的脚本。</p> 
<blockquote> 
 <p>当前版本hadoop如果不创建单独用户，而是直接使用root用户启动，会报错。这时就需要添加之前配置的HDFS_NAMENODE_USER 等几个环境变量。</p> 
</blockquote> 
<p>打开配置文件<code>vi /etc/profile</code>在最后追加如下内容，保存退出<code>source /etc/profile</code>（<em><strong>node02、node03节点不要忘记配置</strong></em>）</p> 
<pre><code>export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
export HADOOP_PID_DIR=/export/servers
</code></pre> 
<p><img src="https://images2.imgbox.com/31/31/n2dGjJiY_o.png" alt="在这里插入图片描述"></p> 
<p>2、<strong>接下来启动Yarn</strong>（<em><strong>node02上启动ResourceManager、DataNoda</strong></em>）</p> 
<blockquote> 
 <p>注意下在yarn-site.xml中配置了日志聚合，将yarn的执行日志配置到了<br> hdfs上。所以yarn建议在hdfs后启动。当然，在生产环境下需要评估这<br> 种日志方式是否合适。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/13/8d/WDh0lMhP_o.png" alt="在这里插入图片描述"></p> 
<p>3、查看各个节点服务启动进程</p> 
<blockquote> 
 <p>DataNode: 数据节点。<br> NameNode 名称服务；<br> SecondaryNameNode 备份名称服务</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/0b/4e/bnl7j93s_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b0/5a/4rweauuW_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/fd/4a/5SvmGdzZ_o.png" alt="在这里插入图片描述"><br> 4、访问HDFS的Web页面</p> 
<blockquote> 
 <p>配置window下的host文件 C:\Windows\System32\drivers\etc打开hosts文件</p> 
</blockquote> 
<pre><code>192.168.2.128 node01
192.168.2.129 node02
192.168.2.130 node03
</code></pre> 
<p><a href="http://node01:9870/" rel="nofollow">http://node01:9870/</a></p> 
<p><img src="https://images2.imgbox.com/16/38/3vHsvQhh_o.png" alt="在这里插入图片描述"><br> 5、访问yarn的管理页面<br> <a href="http://node02:8088/" rel="nofollow">http://node02:8088/</a></p> 
<p><img src="https://images2.imgbox.com/0d/23/FP3r2z9l_o.png" alt="在这里插入图片描述"><br> hadoop集群环境配置搭建完成！</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/81a2cf499ca05d5fff1d0a4585379d3b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">dzzoffice中安装onlyoffice后打开显示文档安全令牌未正确形成的临时解决办法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/54e1a6ba8d70eff5bb9fd429fa99e95d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">想要快速学会Blender雕刻？这些Blender雕刻技巧不要错过</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>