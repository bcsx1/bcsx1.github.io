<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>干货总结！Kafka 面试大全（万字长文，37 张图，28 个知识点） - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="干货总结！Kafka 面试大全（万字长文，37 张图，28 个知识点）" />
<meta property="og:description" content="全文总计 1.2 万字、28 个知识点。35 张原理、流程图。提纲如下：
正文 ⭐ 1、 什么是 kafka ？
Kafka 起初是由 Linkedin 公司采用 Scala 语言开发的一个多分区、多副本且基于ZooKeeper协调的分布式消息系统，现己被捐献给 Apache 基金会。目前 Kafka 已经定位为一个分布式流式处理平台，它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用。
⭐ 2、kafka 的架构描述一下？
如下图所示：
Kafak 总体架构图中包含多个概念：
（1）ZooKeeper：Zookeeper 负责保存 broker 集群元数据，并对控制器进行选举等操作。
（2）Producer：生产者负责创建消息，将消息发送到 Broker。
（3）Broker: 一个独立的 Kafka 服务器被称作 broker，broker 负责接收来自生产者的消息，为消息设置偏移量，并将消息存储在磁盘。broker 为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。
（4）Consumer：消费者负责从 Broker 订阅并消费消息。
（5）Consumer Group：Consumer Group 为消费者组，一个消费者组可以包含一个或多个 Consumer 。
使用 多分区 &#43; 多消费者 方式可以极大 提高数据下游的处理速度，同一消费者组中的消费者不会重复消费消息，同样的，不同消费组中的消费者消费消息时互不影响。Kafka 就是通过消费者组的方式来实现消息 P2P 模式和广播模式。
（6）Topic：Kafka 中的消息 以 Topic 为单位进行划分，生产者将消息发送到特定的 Topic，而消费者负责订阅 Topic 的消息并进行消费。
（7）Partition：一个 Topic 可以细分为多个分区，每个分区只属于单个主题。同一个主题下不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的 日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的 偏移量（offset）。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/040e4f3489d53ea891bfcc9920fc9e20/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-27T09:54:21+08:00" />
<meta property="article:modified_time" content="2021-11-27T09:54:21+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">干货总结！Kafka 面试大全（万字长文，37 张图，28 个知识点）</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p>全文总计 <strong>1.2 万字、28 个知识点。35 张原理、流程图</strong>。提纲如下：</p> 
 <img src="https://images2.imgbox.com/bc/e8/5zdJ39o9_o.png" alt="fefc2bf5cd389ddc3d0ea7a53840686a.png"> 
 <strong>正文</strong> 
 <blockquote> 
  <p>⭐  1、 什么是 kafka ？</p> 
 </blockquote> 
 <img src="https://images2.imgbox.com/d8/c3/FXNT5zhs_o.png" alt="a0ce27f6ea1521ddf5deb05ee3945b0f.png"> 
 <p>Kafka 起初是由 Linkedin 公司采用 Scala 语言开发的一个<code>多分区</code>、<code>多副本</code>且基于<code>ZooKeeper</code>协调的分布式消息系统，现己被捐献给 Apache 基金会。目前 Kafka 已经定位为一个<strong>分布式流式处理平台</strong>，它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用。</p> 
 <blockquote> 
  <p>⭐  2、kafka 的架构描述一下？</p> 
 </blockquote> 
 <p>如下图所示：</p> 
 <img src="https://images2.imgbox.com/a3/e8/lYTRYmC6_o.png" alt="1de689cbdd1e61000a4dd6bc3733089b.png"> 
 <p>Kafak 总体架构图中包含多个概念：</p> 
 <p><strong>（1）ZooKeeper</strong>：<code>Zookeeper</code> 负责保存 <code>broker</code> 集群元数据，并对控制器进行选举等操作。</p> 
 <p><strong>（2）Producer</strong>：生产者负责创建消息，将消息发送到 Broker。</p> 
 <p><strong>（3）Broker</strong>: 一个独立的 <code>Kafka</code> 服务器被称作 <code>broker</code>，broker 负责接收来自生产者的消息，<strong>为消息设置偏移量</strong>，并将消息存储在磁盘。broker 为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。</p> 
 <p><strong>（4）Consumer</strong>：消费者负责从 <code>Broker</code> 订阅并消费消息。</p> 
 <p><strong>（5）Consumer Group</strong>：<code>Consumer Group</code> 为消费者组，一个消费者组可以包含一个或多个 <code>Consumer</code> 。</p> 
 <p>使用 <strong>多分区 + 多消费者</strong> 方式可以极大 <strong>提高数据下游的处理速度</strong>，<code>同一消费者组中的消费者不会重复消费消息</code>，同样的，不同消费组中的消费者消费消息时互不影响。Kafka 就是通过消费者组的方式来实现消息 P2P 模式和广播模式。</p> 
 <p><strong>（6）Topic</strong>：Kafka 中的消息 <strong>以 Topic 为单位进行划分</strong>，生产者将消息发送到特定的 Topic，而消费者负责订阅 Topic 的消息并进行消费。</p> 
 <p><strong>（7）Partition</strong>：一个 Topic 可以细分为多个分区，<strong>每个分区只属于单个主题</strong>。同一个主题下不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的 <strong>日志（Log）文件</strong>，消息在被追加到分区日志文件的时候都会分配一个特定的 <strong>偏移量（offset）</strong>。</p> 
 <p><strong>（8）Offset</strong>：offset 是消息在分区中的唯一标识，<strong>Kafka 通过它来保证消息在分区内的顺序性</strong>，不过 offset 并不跨越分区，也就是说，<strong>Kafka保证的是分区有序性而不是主题有序性</strong>。</p> 
 <p><strong>（9）Replication</strong>：<strong>副本</strong>，是 Kafka 保证数据高可用的方式，Kafka <strong>同一 Partition 的数据可以在多 Broker 上存在多个副本</strong>，通常只有<strong>主副本对外提供读写服务</strong>，当主副本所在 broker 崩溃或发生网络异常，Kafka 会在 Controller 的管理下会重新选择新的 Leader 副本对外提供读写服务。</p> 
 <p><strong>（10）Record</strong>：实际写入 Kafka 中并可以被读取的消息记录。每个 record 包含了 <code>key</code>、<code>value</code> 和 <code>timestamp</code>。</p> 
 <p><strong>（11）Leader</strong>: 每个分区多个副本的 "主" leader,生产者发送数据的对象，以及消费者消费数据的对象都是 leader。</p> 
 <p><strong>（12）follower</strong>: 每个分区多个副本中的"从" follower,实时从 Leader 中同步数据，保持和 leader 数据的同步。Leader 发生故障时，某个 follow 会成为新的 leader。</p> 
 <blockquote> 
  <p>⭐ 3、发布订阅的消息系统那么多，为啥选择<code>kafka</code>?</p> 
 </blockquote> 
 <p><strong>(1) 多个生产者</strong>。</p> 
 <img src="https://images2.imgbox.com/75/01/XyaOd4Sf_o.png" alt="7c2207e86dac2e81fd383f7423249b20.png"> 
 <p>KafKa 可以无缝地支持多个生产者，不管客户端使用一个主题，还是多个主题。<strong>Kafka 适合从多个前端系统收集数据</strong>，并以统一的格式堆外提供数据。</p> 
 <p><strong>（2）多个消费者</strong></p> 
 <img src="https://images2.imgbox.com/0d/66/J8p83OdE_o.png" alt="6321dac4030ecf67bf82fc995e9138a7.png"> 
 <p>Kafka 支持多个消费者从一个单独的消息流中读取数据，并且消费者之间互不影响。这与其他队列系统不同，其他队列系统一旦被客户端读取，其他客户端就不能 再读取它。并且<strong>多个消费者可以组成一个消费者组，他们共享一个消息流，并保证消费者组对每个给定的消息只消费一次</strong>。</p> 
 <p><strong>（3）基于磁盘的数据存储</strong></p> 
 <img src="https://images2.imgbox.com/7c/49/6xZP96kR_o.png" alt="93c3a00ac84d0b247e0ef773398acbd9.png"> 
 <p>Kafka 允许消费者非实时地读取消息，原因在于 Kafka 将消息提交到磁盘上，设置了保留规则进行保存，无需担心消息丢失等问题。</p> 
 <p><strong>（4）伸缩性</strong></p> 
 <p>可扩展多台 broker。用户可以先使用单个 broker，到后面可以扩展到多个 broker</p> 
 <p><strong>（5）高性能</strong></p> 
 <p>Kafka 可以轻松处理百万千万级消息流，同时还能保证 <strong>亚秒级</strong> 的消息延迟。</p> 
 <blockquote> 
  <p>⭐ 4、kafka 如何做到高吞吐量和性能的？</p> 
 </blockquote> 
 <p>kafka 实现高吞吐量和性能，主要通过以下几点：</p> 
 <p><strong>1、页缓存技术</strong></p> 
 <p><code>Kafka</code> 是基于 <strong>操作系统</strong> 的<code>页缓存</code>来实现文件写入的。</p> 
 <p>操作系统本身有一层缓存，叫做 <strong>page cache</strong>，是在 <strong>内存里的缓存</strong>，我们也可以称之为 <strong>os cache</strong>，意思就是操作系统自己管理的缓存。</p> 
 <p>Kafka 在写入磁盘文件的时候，可以直接写入这个 os cache 里，也就是仅仅写入内存中，接下来由操作系统自己决定什么时候把 os cache 里的数据真的刷入磁盘文件中。通过这一个步骤，就可以将磁盘文件<strong>写性能</strong>提升很多了，因为其实这里相当于是在写内存，不是在写磁盘，原理图如下：</p> 
 <img src="https://images2.imgbox.com/fa/58/Uz4plFEI_o.png" alt="47a41dea2fbbb99c4dfaa80c481c2556.png"> 
 <p><strong>2、磁盘顺序写</strong></p> 
 <p>另一个主要功能是 kafka 写数据的时候，是以磁盘顺序写的方式来写的。也就是说，<strong>仅仅将数据追加到文件的末尾</strong>，<code>不是在文件的随机位置来修改数据</code>。</p> 
 <p>普通的机械磁盘如果你要是随机写的话，确实性能极差，也就是随便找到文件的某个位置来写数据。</p> 
 <p>但是如果你是 <strong>追加文件末尾</strong> 按照顺序的方式来写数据的话，那么这种磁盘顺序写的性能基本上可以跟写内存的性能相差无几。</p> 
 <p><strong>基于上面两点，kafka 就实现了写入数据的超高性能</strong>。</p> 
 <p><strong>3、零拷贝</strong></p> 
 <p>大家应该都知道，从 Kafka 里经常要消费数据，那么消费的时候实际上就是要从 kafka 的<strong>磁盘文件</strong>里<strong>读取某条数据</strong>然后发送给下游的消费者，如下图所示。</p> 
 <img src="https://images2.imgbox.com/5a/d4/i95ooi1U_o.png" alt="7ed48d646fcbda0f4ff769a8352751c2.png"> 
 <p>那么这里如果频繁的从磁盘读数据然后发给消费者，会增加两次没必要的拷贝，如下图：</p> 
 <img src="https://images2.imgbox.com/5f/3a/ifK026Zb_o.png" alt="be7f90c5f5b989b5277ab880dd89a77f.png"> 
 <p>一次是从操作系统的 cache 里拷贝到应用进程的缓存里，接着又从应用程序缓存里拷贝回操作系统的 Socket 缓存里。</p> 
 <p>而且为了进行这两次拷贝，中间还发生了好几次上下文切换，一会儿是应用程序在执行，一会儿上下文切换到操作系统来执行。所以这种方式来读取数据是比较消耗性能的。</p> 
 <p><strong>Kafka 为了解决这个问题，在读数据的时候是引入零拷贝技术</strong>。</p> 
 <p>也就是说，直接让操作系统的 cache 中的数据发送到<strong>网卡</strong>后传输给下游的消费者，<strong>中间跳过了两次拷贝数据的步骤</strong>，Socket 缓存中仅仅会拷贝一个描述符过去，不会拷贝数据到 Socket 缓存，如下图所示：</p> 
 <img src="https://images2.imgbox.com/aa/e6/orksUBOF_o.png" alt="68cdcd54f8d7b06ef34e305479f79294.png"> 
 <p>通过 <strong>零拷贝技术</strong>，就不需要把 os cache 里的数据拷贝到应用缓存，再从应用缓存拷贝到 Socket 缓存了，两次拷贝都省略了，所以叫做零拷贝。</p> 
 <p>对 Socket 缓存仅仅就是拷贝数据的描述符过去，然后数据就直接从 os cache 中发送到网卡上去了，<strong>这个过程大大的提升了数据消费时读取文件数据的性能</strong>。</p> 
 <p>Kafka 从磁盘读数据的时候，会先看看 os cache 内存中是否有，如果有的话，其实读数据都是直接读内存的。</p> 
 <p>kafka 集群经过良好的调优，数据直接写入 os cache 中，然后读数据的时候也是从 os cache 中读。相当于 Kafka 完全基于内存提供数据的写和读了，所以这个整体性能会极其的高。</p> 
 <blockquote> 
  <p>⭐ 5、 kafka 和 zookeeper 之间的关系</p> 
 </blockquote> 
 <p><strong>kafka</strong> 使用 <strong>zookeeper</strong> 来保存集群的元数据信息和消费者信息(偏移量)，没有 zookeeper，kafka 是工作不起来。在 <code>zookeeper</code> 上会有一个专门用来进行 <code>Broker</code> 服务器列表记录的点，节点路径为<code>/brokers/ids</code>。</p> 
 <p>每个 Broker 服务器在启动时，都会到 Zookeeper 上进行注册，即创建 <code>/brokers/ids/[0-N]</code> 的节点，然后写入 IP，端口等信息，<strong>Broker 创建的是临时节点</strong>，所以一旦 Broker 上线或者下线，对应 Broker 节点也就被删除了，因此可以通过 zookeeper 上 Broker 节点的变化来动态表征 Broker 服务器的可用性。</p> 
 <blockquote> 
  <p>⭐  6、生产者向 Kafka 发送消息的执行流程介绍一下？</p> 
 </blockquote> 
 <p>如下图所示：</p> 
 <img src="https://images2.imgbox.com/63/fa/gEWqFjw6_o.png" alt="43b12972c1096d2335ff1675df701d54.png"> 
 <p>（1）生产者要往 Kafka 发送消息时，需要创建 <strong>ProducerRecoder</strong>,代码如下：</p> 
 <pre class="has"><code class="language-go">ProducerRecord&lt;String,String&gt; record 
      = new ProducerRecoder&lt;&gt;("CostomerCountry","Precision Products","France");
      try{
      producer.send(record);
      }catch(Exception e){
        e.printStackTrace();
      }</code></pre> 
 <p>（2）<strong>ProducerRecoder</strong> 对象会包含目标 <strong>topic</strong>，<strong>分区内容</strong>，以及指定的 <strong>key</strong> 和 <strong>value</strong>,<code>在发送 ProducerRecoder 时，生产者会先把键和值对象序列化成字节数组</code>，然后在网络上传输。</p> 
 <p>（3）生产者在将<code>消息</code>发送到某个 Topic ，需要经过<strong>拦截器</strong>、<strong>序列化器</strong>和<strong>分区器</strong>（Partitioner）。</p> 
 <p>（4）如果消息 <strong>ProducerRecord</strong> 没有指定 partition 字段，那么<strong>就需要依赖分区器</strong>，根据 key 这个字段来计算 partition 的值。<strong>分区器的作用就是为消息分配分区</strong>。</p> 
 <ol><li><p>若没有指定分区，且消息的 key 不为空，则使用 murmur 的 Hash 算法（非加密型 Hash 函数，具备高运算性能及低碰撞率）来计算分区分配。</p></li><li><p>若没有指定分区，且消息的 key 也是空，则用<strong>轮询</strong>的方式选择一个分区。</p></li></ol> 
 <p>（5）分区选择好之后，会将消息添加到一个记录批次中，这个批次的所有消息都会被发送到相同的 <strong>Topic</strong> 和 <strong>partition</strong> 上。然后会有一个独立的线程负责把这些记录批次发送到相应的 broker 中。</p> 
 <p>（6）<strong>broker</strong> 接收到 Msg 后，会作出一个响应。如果成功写入 Kafka 中，就返回一个 <strong>RecordMetaData</strong> 对象，它包含 <code>Topic</code> 和 <code>Partition</code> 信息，以及记录在分区的 <code>offset</code>。</p> 
 <p>（7）若写入失败，就返回一个错误异常，生产者在收到错误之后尝试重新发送消息，几次之后如果还失败，就返回错误信息。</p> 
 <blockquote> 
  <p>⭐  7、kafka 如何保证对应类型的消息被写到相同的分区？</p> 
 </blockquote> 
 <p>通过 <strong>消息键</strong> 和 <strong>分区器</strong> 来实现，分区器为<code>键</code>生成一个 <code>offset</code>，然后使用 offset 对主题分区进行取模，为消息选取分区，这样就可以保证包含同一个键的消息会被写到同一个分区上。</p> 
 <ol><li><p>如果 <code>ProducerRecord</code> 没有指定分区，且消息的 <code>key 不为空</code>，则使用 <code>Hash 算法</code>（非加密型 Hash 函数，具备高运算性能及低碰撞率）来计算分区分配。</p></li><li><p>如果 ProducerRecord 没有指定分区，且消息的 <code>key 也是空</code>，则用 <strong>轮询</strong> 的方式选择一个分区。</p></li></ol> 
 <blockquote> 
  <p>⭐ 8、kafka 文件存储机制了解吗？</p> 
 </blockquote> 
 <p>如下图所示：</p> 
 <img src="https://images2.imgbox.com/c2/74/P7TtA4DG_o.png" alt="364f6c64c9f40f5a72d01041ee218bb8.png"> 
 <p>在 Kafka 中，一个 Topic 会被分割成多个 Partition，而 Partition 由多个更小的 Segment 的元素组成。</p> 
 <p>一个 Partition 下会包含下图的一些文件，由 <code>log、index、timeindex</code> 三个文件组成一个 <code>Segment</code>，<strong>而文件名中的（0）表示的是一个 Segment 的起始 Offset</strong>。</p> 
 <p>Kafka 会根据 <code>log.segment.bytes</code> 的配置来决定单个 Segment 文件（log）的大小，当写入数据达到这个大小时就会创建新的 Segment 。</p> 
 <p><strong>（1）log 文件解析示意图</strong>：</p> 
 <img src="https://images2.imgbox.com/9c/be/wp0KyoXT_o.png" alt="22580d63a0cd0b09f1b3f0812b565e36.png"> 
 <p><strong>（2）index 文件解析示意图</strong>：</p> 
 <img src="https://images2.imgbox.com/2c/90/ggwYtB2N_o.png" alt="e3f34b8c43dd2d323fb9e79e75f21dce.png"> 
 <p><strong>（3）timeindex 文件解析示意图</strong>：</p> 
 <img src="https://images2.imgbox.com/dc/4d/GxGq3ycY_o.png" alt="0ef08b90802f35aebb9cf880c40f9c01.png"> 
 <p><strong>log、index、timeindex</strong> 中存储的都是<code>二进制</code>的数据（ <strong>log 中存储的是 BatchRecords 消息内容，而 index 和 timeindex 分别是一些索引信息</strong>。）</p> 
 <img src="https://images2.imgbox.com/de/51/KUt8pnZs_o.png" alt="a886036335d584eb6ec8eac6b2f2dc15.png"> 
 <p><strong>举例</strong>：现在创建一个 lyz topic，三个分区，一个副本。</p> 
 <pre class="has"><code class="language-go"># 创建一个topic
[root@hlinkui bin]$ ./kafka-topics.sh --create --bootstrap-server 192.168.244.129:9092 \
--replication-factor 1 --partitions 3 --topic lyz

# 查看创建的 topic 描述信息：
./kafka-topics.sh --describe --bootstrap-server \
192.168.244.129:9092  --topic lyz</code></pre> 
 <p>截图如下：<img src="https://images2.imgbox.com/b0/f7/g3Dm8qEa_o.png" alt="8abaaab4bebf20222bc5eb8160fe29de.png"></p> 
 <p>那么，其数据文件的目录结构如下所示，3 个分区对应 3个文件夹，文件夹命名topic-分区序号：即 lyz-0,lyz-1,lyz-2.</p> 
 <img src="https://images2.imgbox.com/1e/50/TqNMNGIl_o.png" alt="508ff97ea2235f988045eb7a074e80da.png"> 
 <p>进入其中一个分区的文件夹中，会有 3 种类型文件，</p> 
 <img src="https://images2.imgbox.com/1c/d3/gyOGP487_o.png" alt="5837f48cb9347fa38c420f82efa4ff01.png"> 
 <blockquote> 
  <blockquote> 
   <p>具体情况请看这个链接：https://www.cnblogs.com/hzmark/p/kafka_message_format.html</p> 
  </blockquote> 
 </blockquote> 
 <blockquote> 
  <p>⭐  9、如何根据 offset 找到对应的 Message？</p> 
 </blockquote> 
 <p>通过 Offset 从存储层中获取 Message 大致分为两步：</p> 
 <ol><li><p>第一步，根据 Offset 找到所属的 Segment 文件</p></li><li><p>第二步，从 Segment 中获取对应 Offset 的消息数据</p></li></ol> 
 <p><strong>第一步</strong>可以直接根据 Segment 的文件名进行查找（上面已经介绍了 Segment 的文件面就是它包含的数据的起始 Offset ）。</p> 
 <p><strong>第二步</strong>则需要一些<code>索引信息</code>来快速定位目标数据在 Segment 中的位置，否则就要读取整个 Segment 文件了，这里需要的索引信息就是上面的 index 文件存储的内容。</p> 
 <p>索引文件中包含多个索引条目，<code>每个条目表示数据文件中一条 Message 的索引</code>。索引包含两个部分（均为4个字节的数字），分别为相对 offset 和 position, 如下内容所示：</p> 
 <pre class="has"><code class="language-go">[root@hlinkui bin]$ ./kafka-run-class.sh  kafka.tools.DumpLogSegments --files \
../kafkaLog/lyz-0/00000000000000000000.index  --print-data-log

offset: 9 position: 13713
offset: 15 position: 27799
offset: 21 position: 43149
offset: 27 position: 58432</code></pre> 
 <p>如下图所示：</p> 
 <img src="https://images2.imgbox.com/78/26/wL4D8aDx_o.png" alt="ed58d4096b93b15f3346f09753ef0741.png"> 
 <p><code>index</code> 文件中存储的是 <code>Offset</code> 和 <code>Position</code>（Offset 对应的消息在 log 文件中的偏移量）的对应关系，这样当有 Offset 时可以快速定位到 Position 读取<code>BatchRecord</code> ，然后再从 <code>BatchRecord</code> 中获取某一条消息。</p> 
 <p>比如上述 <code>Offset21</code> 会被定位到 <code>27</code> 这个 <code>BatchRecord</code>，然后再从这个 <code>BatchRecord</code> 中取出第二个 <code>Record</code>（27 这个BatchRecord包含了 27 、28 两个 Record）。</p> 
 <p>Kafka 并不会为每个 Record 都保存一个索引，而是根据 log.index.interval.bytes 等配置 <strong>构建稀疏索引信息</strong>。</p> 
 <p>Kafka 中还维护了 timeindex，保存了 Timestamp 和 Offset 的关系，在一些场景需要根据 timestamp 来定位消息。<strong>timeindex 中的一个（ timestampX，offsetY ）元素的含义是所有创建时间大于 timestampX 的消息的 Offset 都大于 offsetY</strong>。</p> 
 <p><strong>查找方式如下图所示</strong>：</p> 
 <img src="https://images2.imgbox.com/dc/1e/YqoaK5xj_o.png" alt="10e6e21bc5bbef850c8121c78dabfad9.png"> 
 <blockquote> 
  <p>⭐ 10、 Producer 发送的一条 message 中包含哪些信息？</p> 
 </blockquote> 
 <p>消息由 <code>可变长度</code> 的 <strong>报头</strong>、<code>可变长度</code>的 <strong>不透明密钥字节数组</strong>和 <code>可变长度</code>的 <strong>不透明值字节数组</strong> 组成。</p> 
 <img src="https://images2.imgbox.com/84/15/xkOfKFJ1_o.png" alt="c0fc04abd9569427eb79c5de0fa3df0b.png"> 
 <p><strong>RecordBatch</strong> 是 <strong>Kafka</strong> 数据的存储单元，<code>一个 RecordBatch 中包含多个 Record</code>（即我们通常说的一条消息）。RecordBatch 中各个字段的含义如下：</p> 
 <img src="https://images2.imgbox.com/eb/5f/lRBf2eRm_o.png" alt="fae30a37e74a35087e10dd336f393966.png"> 
 <p>一个 RecordBatch 中可以包含多条消息，即上图中的 Record，而每条消息又可以包含多个 Header 信息，Header 是 Key-Value 形式的。</p> 
 <blockquote> 
  <p>⭐  11、kafka 如何实现消息是有序的？</p> 
 </blockquote> 
 <p><strong>生产者</strong>：通过分区的 leader 副本负责数据以先进先出的顺序写入，来保证消息顺序性。</p> 
 <img src="https://images2.imgbox.com/a8/8b/AWTejw1q_o.png" alt="54263af9ec73526fdb96966628dd3f9f.png"> 
 <p><strong>消费者</strong>：同一个分区内的消息只能被一个 group 里的一个消费者消费，保证分区内消费有序。</p> 
 <img src="https://images2.imgbox.com/53/d1/zaOmuSa3_o.png" alt="267ee982cc9741e5559821686d6b8e17.png"> 
 <p>kafka 每个 partition 中的消息在写入时都是有序的，消费时， 每个 partition 只能被每一个消费者组中的一个消费者消费，保证了消费时也是有序的。</p> 
 <p>整个 kafka 不保证有序。<strong>如果为了保证 kafka 全局有序，那么设置一个生产者，一个分区，一个消费者。</strong></p> 
 <blockquote> 
  <p>⭐   12、kafka 有哪些分区算法？</p> 
 </blockquote> 
 <p>kafka包含三种分区算法：</p> 
 <p><strong>（1）轮询策略</strong></p> 
 <p>也称 Round-robin 策略，即顺序分配。比如一个 topic 下有 3 个分区，那么第一条消息被发送到分区 0，第二条被发送到分区 1，第三条被发送到分区 2，以此类推。当生产第四条消息时又会重新开始。</p> 
 <img src="https://images2.imgbox.com/dc/4b/xOMbv29I_o.png" alt="28dcd86c0a0493de856debf871330cb9.png"> 
 <p>轮询策略是 kafka java 生产者 API 默认提供的分区策略。轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是平时最常用的分区策略之一。</p> 
 <p><strong>（2）随机策略</strong></p> 
 <p>也称 Randomness 策略。所谓随机就是我们随意地将消息放置在任意一个分区上，如下图：</p> 
 <img src="https://images2.imgbox.com/db/72/kYgvwfwh_o.png" alt="90359fa05a101521d3ef06b574fe38d9.png"> 
 <p><strong>（3）按 key 分配策略</strong></p> 
 <p>kafka 允许为每条消息定义消息键，简称为 key。一旦消息被定义了 key，那么你就可以保证同一个 key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，如下图所示：</p> 
 <img src="https://images2.imgbox.com/07/10/07WjoLfX_o.png" alt="0d350c41469ec51508e59bcc89cd49f3.png"> 
 <blockquote> 
  <p>⭐  13、说说 kafka 的默认消息保留策略？</p> 
 </blockquote> 
 <p>broker 默认的消息保留策略分为两种：</p> 
 <ol><li><p>日志片段通过 log.segment.bytes 配置（默认是1GB）</p></li><li><p>日志片段通过 log.segment.ms 配置 （默认7天）</p></li></ol> 
 <blockquote> 
  <p>⭐  14、kafka 如何实现单个集群间的消息复制？</p> 
 </blockquote> 
 <p>Kafka 消息负责机制只能在单个集群中进行复制，不能在多个集群之间进行。</p> 
 <p>kafka 提供了一个叫做 <strong>MirrorMaker</strong> 的核心组件，该组件包含一个生产者和一个消费者，两者之间通过一个队列进行相连，当消费者从一个集群读取消息，生产者把消息发送到另一个集群。</p> 
 <blockquote> 
  <p>⭐  15、Kafka 消息确认(ack 应答)机制了解吗？</p> 
 </blockquote> 
 <p>为保证 producer 发送的数据，能可靠的达到指定的 topic ,Producer 提供了消息确认机制。生产者往 Broker 的 topic 中发送消息时，<strong>可以通过配置来决定有几个副本收到这条消息才算消息发送成功</strong>。可以在定义 Producer 时通过 <strong>acks</strong> 参数指定，这个参数支持以下三种值：</p> 
 <p><strong>（1）acks = 0：producer 不会等待任何来自 broker 的响应</strong>。</p> 
 <p><code>特点：低延迟，高吞吐，数据可能会丢失。</code></p> 
 <p>如果当中出现问题，导致 broker 没有收到消息，那么 producer 无从得知，<code>会造成消息丢失</code>。</p> 
 <p><strong>（2）acks = 1（默认值）：只要集群中 partition 的 Leader 节点收到消息，生产者就会收到一个来自服务器的成功响应。</strong></p> 
 <p>如果在 follower 同步之前，leader 出现故障，将会丢失数据。</p> 
 <p>此时的<code>吞吐量</code>主要取决于使用的是 <strong>同步发送</strong> 还是 <strong>异步发送</strong> ，吞吐量还受到发送中消息数量的限制，例如 producer 在收到 broker 响应之前可以发送多少个消息。</p> 
 <p><strong>（3）acks = -1：只有当所有参与复制的节点全部都收到消息时，生产者才会收到一个来自服务器的成功响应</strong>。</p> 
 <p>这种模式是最安全的，可以保证不止一个服务器收到消息，就算有服务器发生崩溃，整个集群依然可以运行。</p> 
 <p>根据实际的应用场景，选择设置不同的 acks，以此保证数据的可靠性。</p> 
 <p>另外，Producer 发送消息还可以选择同步或异步模式,如果设置成异步，虽然会极大的提高消息发送的性能，但是这样会增加丢失数据的风险。如果需要<strong>确保消息的可靠性</strong>，必须将 producer.type 设置为 sync。</p> 
 <pre class="has"><code class="language-go">#同步模式
producer.type=sync 
#异步模式
producer.type=async</code></pre> 
 <blockquote> 
  <p>⭐16、说一下什么是副本？</p> 
 </blockquote> 
 <p>kafka 为了保证数据不丢失，从 <code>0.8.0</code> 版本开始引入了分区副本机制。在创建 topic 的时候指定 <code>replication-factor</code>,默认副本为 3 。</p> 
 <p>副本是相对 partition 而言的，一个分区中包含一个或多个副本，其中一个为<code>leader</code> 副本，其余为<code>follower</code> 副本，各个副本位于不同的 <code>broker</code> 节点中。</p> 
 <p>所有的<code>读写操作</code>都是经过 Leader 进行的，同时 follower 会定期地去 leader 上复制数据。当 Leader 挂掉之后，其中一个 follower 会重新成为新的 Leader。<strong>通过分区副本，引入了数据冗余，同时也提供了 Kafka 的数据可靠性</strong>。</p> 
 <p>Kafka 的分区多副本架构是 Kafka 可靠性保证的核心，把消息写入多个副本可以使 Kafka 在发生崩溃时仍能保证消息的持久性。</p> 
 <blockquote> 
  <p>⭐17、说一下 kafka 的 ISR 机制？</p> 
 </blockquote> 
 <p>在分区中，所有副本统称为 AR ，Leader 维护了一个动态的 in-sync replica(ISR),<strong>ISR 是指与 leader 副本保持同步状态的副本集合</strong>。当然 <code>leader 副本本身也是这个集合中的一员</code>。</p> 
 <p>当 ISR 中的 follower 完成数据同步之后， leader 就会给 follower 发送 ack ,如果其中一个 follower 长时间未向 leader 同步数据，该 follower 将会被踢出 ISR 集合，该时间阈值由 replica.log.time.max.ms 参数设定。当 leader 发生故障后，就会从 ISR 集合中重新选举出新的 leader。</p> 
 <blockquote> 
  <p>⭐18、LEO、HW、LSO、LW 分别代表什么？</p> 
 </blockquote> 
 <ul><li><p>LEO ：是 LogEndOffset 的简称，代表当前日志文件中下一条。</p></li><li><p>HW：水位或水印一词，也可称为高水位<code>（high watermark）</code>,通常被用在流式处理领域<code>（flink、spark）</code>，以表征元素或事件在基于时间层面上的进展。在 kafka 中，水位的概念与时间无关，而是与位置信息相关。严格来说，它表示的就是位置信息，即位移<code>（offset）</code>。取 <code>partition</code> 对应的<code>ISR</code>中最小的 <code>LEO</code>作为<code>HW</code>，<code>consumer</code> 最多只能消费到 <code>HW</code> 所在的上一条信息。</p></li><li><p>LSO: 是 <code>LastStableOffset</code> 的简称，对未完成的事务而言，<code>LSO</code> 的值等于事务中第一条消息的位置<code>（firstUnstableOffset）</code>，对已完成的事务而言，它的值同<code>HW</code> 相同。</p></li><li><p>LW: <code>Low Watermark</code> 低水位，代表<code>AR</code> 集合中最小的 <code>logStartOffset</code> 值。</p></li></ul> 
 <img src="https://images2.imgbox.com/6a/4c/gYJEJKvh_o.png" alt="511acb9ad689d6614cb9d38b55b0d291.png"> 
 <blockquote> 
  <p>⭐19、如何进行 Leader 副本选举？</p> 
 </blockquote> 
 <p>每个分区的 leader 会维护一个 ISR 集合，ISR 列表里面就是 follower 副本的 Borker 编号，只有“跟得上” Leader 的 follower 副本才能加入到 ISR 里面，这个是通过 <code>replica.lag.time.max.ms</code> 参数配置的。只有 ISR 里的成员才有被选为 leader 的可能。</p> 
 <p>所以当 Leader 挂掉了，而且 <code>unclean.leader.election.enable=false</code> 的情况下，Kafka 会从 ISR 列表中选择 <strong>第一个</strong> follower 作为新的 Leader，因为这个分区拥有最新的已经 committed 的消息。通过这个可以保证已经 committed 的消息的数据可靠性。</p> 
 <blockquote> 
  <p>⭐ 20、如何进行 broker Leader 选举？</p> 
 </blockquote> 
 <p>(1) 在 <code>kafka</code> 集群中，会有多个 <code>broker</code> 节点，集群中第一个启动的 <code>broker</code> 会通过在 zookeeper 中创建临时节点 <strong>/controller</strong> 来让自己成为控制器，其他 <code>broker</code> 启动时也会在 <code>zookeeper</code> 中创建临时节点，但是发现节点已经存在，所以它们会收到一个异常，意识到控制器已经存在，那么就会在 <code>zookeeper</code> 中创建 <strong>watch</strong> 对象，便于它们收到控制器变更的通知。</p> 
 <p>(2) 如果集群中有一个 <code>broker</code> 发生异常退出了，那么控制器就会检查这个 <code>broker</code> 是否有分区的副本 <code>leader</code> ，如果有那么这个分区就需要一个新的 <code>leader</code>，此时控制器就会去遍历其他副本，决定哪一个成为新的 <code>leader</code>，同时更新分区的 <code>ISR</code> 集合。</p> 
 <p>(3) 如果有一个 <code>broker</code> 加入集群中，那么控制器就会通过 <code>Broker ID</code> 去判断新加入的 <code>broker</code> 中是否含有现有分区的副本，如果有，就会从分区副本中去同步数据。</p> 
 <p>(4) 集群中每选举一次控制器，就会通过 zookeeper 创建一个 <strong>controller epoch</strong>，每一个选举都会创建一个更大，包含最新信息的 epoch，如果有 broker 收到比这个 epoch 旧的数据，就会忽略它们，kafka 也通过这个 epoch 来防止集群产生“脑裂”。</p> 
 <blockquote> 
  <p>⭐ 21、kafka 事务了解吗？</p> 
 </blockquote> 
 <p>Kafka 在 0.11版本引入事务支持，事务可以保证 Kafka 在 Exactly Once 语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p> 
 <p><strong>Producer 事务</strong></p> 
 <p>为了实现跨分区跨会话事务，需要引入一个全局唯一的 <code>Transaction ID</code>,<strong>并将 Producer 获取的 PID 和 Transaction ID  绑定</strong>。这样当 Producer 重启后就可以通过正在进行的 Transaction ID 获取原来的 PID。</p> 
 <p>为了管理 <code>Transaction</code>，Kafka 引入了一个新的组件 <code>Transaction Coordinator</code>。<strong>Producer 就是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态</strong>。Transaction Coordinator 还负责将事务所有写入 Kafka 的一个内部 <code>Topic</code>，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p> 
 <p>**Consumer 事务 **</p> 
 <p>上述事务机制主要是从Producer 方面考虑，对于 Consumer 而言，事务的保证就会相对较弱，尤其是无法保证 Commit 的信息被精确消费。这是由于 Consumer 可以通过 offset 访问任意信息，而且不同的Segment File 生命周期不同，同一事务的消息可能会出现重启后被删除的情况。</p> 
 <blockquote> 
  <p>⭐ 22、kafka的消费者组跟分区之间有什么关系？</p> 
 </blockquote> 
 <p>(1) 在 kafka 中，通过消费者组管理消费者，假设一个主题中包含 4 个分区，在一个消费者组中只要一个消费者。那消费者将收到全部 4 个分区的消息。</p> 
 <img src="https://images2.imgbox.com/a2/c7/UqOllTod_o.png" alt="a0659909e539f262cc239bbc00fb79a4.png"> 
 <p>(2) 如果存在两个消费者，那么四个分区将根据分区分配策略分配个两个消费者，如下图所示：</p> 
 <img src="https://images2.imgbox.com/45/a9/IuprEacJ_o.png" alt="6093660043f0763cbb39d0adaf70d593.png"> 
 <p>（3）如果存在四个消费者，将平均分配，每个消费者消费一个分区。</p> 
 <img src="https://images2.imgbox.com/f3/67/WSzJTHaR_o.png" alt="c6372a07a1aea1f8a0e4659eea25774c.png"> 
 <p>（4）如果存在5个消费者，就会出现消费者数量多于分区数量，那么多余的消费者将会被闲置，不会接收到任何信息。</p> 
 <img src="https://images2.imgbox.com/be/8e/TV8pWD3R_o.png" alt="28d30717277cc6187a22eed40d60e162.png"> 
 <blockquote> 
  <p>⭐ 23、如何保证每个应用程序都可以获取到 Kafka 主题中的所有消息，而不是部分消息？</p> 
 </blockquote> 
 <p>为每个应用程序创建一个消费者组，然后往组中添加消费者来伸缩读取能力和处理能力，每个群组消费主题中的消息时，互不干扰。</p> 
 <blockquote> 
  <p>⭐ 24、如何实现 kafka 消费者每次只消费指定数量的消息？</p> 
 </blockquote> 
 <p>写一个队列，把 consumer 作为队列类的一个属性，然后增加一个消费计数的计数器，当到达指定数量时，关闭 consumer。</p> 
 <blockquote> 
  <p>⭐ 25、kafka 如何实现多线程的消费？</p> 
 </blockquote> 
 <p><strong>kafka 允许同组的多个 partition 被一个 consumer 消费</strong>，但不允许一个 partition 被同组的多个 consumer 消费。</p> 
 <p>实现多线程步骤如下：</p> 
 <ol><li><p>生产者随机分区提交数据(自定义随机分区)。</p></li><li><p>消费者修改单线程模式为多线程，在消费方面得注意，得遍历所有分区，否则还是只消费了一个区。</p></li></ol> 
 <img src="https://images2.imgbox.com/ba/63/YnPm1usW_o.png" alt="323407c35067a1375e99754c34c54d72.png"> 
 <blockquote> 
  <p>⭐ 26、 kafka 消费支持几种消费模式？</p> 
 </blockquote> 
 <p>kafka消费消息时支持三种模式：</p> 
 <ul><li><p>at most once 模式 最多一次。保证每一条消息 commit 成功之后，再进行消费处理。消息可能会丢失，但不会重复。</p></li><li><p>at least once 模式 至少一次。保证每一条消息处理成功之后，再进行commit。消息不会丢失，但可能会重复。</p></li><li><p>exactly once 模式 精确传递一次。将 offset 作为唯一 id 与消息同时处理，并且保证处理的原子性。消息只会处理一次，不丢失也不会重复。但这种方式很难做到。</p></li></ul> 
 <p>kafka 默认的模式是 at least once ，但这种模式可能会产生重复消费的问题，所以在业务逻辑必须做幂等设计。</p> 
 <p>在业务场景保存数据时使用了 INSERT INTO ...ON DUPLICATE KEY UPDATE语法，不存在时插入，存在时更新，是天然支持幂等性的。</p> 
 <blockquote> 
  <p>⭐ 27、kafka 如何保证数据的不重复和不丢失？</p> 
 </blockquote> 
 <ul><li><p>exactly once 模式 精确传递一次。将 offset 作为唯一 id 与消息同时处理，并且保证处理的原子性。消息只会处理一次，不丢失也不会重复。但这种方式很难做到。</p></li></ul> 
 <p>kafka 默认的模式是 at least once ，但这种模式可能会产生重复消费的问题，所以在业务逻辑必须做幂等设计。</p> 
 <p>使用 exactly Once + 幂等操作，可以保证数据不重复，不丢失。</p> 
 <blockquote> 
  <p>⭐ 28、kafka 是如何清理过期数据的？</p> 
 </blockquote> 
 <p><strong>kafka</strong> 将数据持久化到了硬盘上，允许你配置一定的策略对数据清理，清理的策略有两个，<strong>删除和压缩</strong>。</p> 
 <p>数据清理的方式</p> 
 <p><strong>1、删除</strong></p> 
 <p><code>log.cleanup.policy=delete</code> 启用删除策略</p> 
 <p>直接删除，删除后的消息不可恢复。可配置以下两个策略：</p> 
 <pre class="has"><code class="language-go">#清理超过指定时间清理：  
log.retention.hours=16
#超过指定大小后，删除旧的消息：
log.retention.bytes=1073741824</code></pre> 
 <p>为了避免在删除时阻塞读操作，采用了 <code>copy-on-write</code> 形式的实现，删除操作进行时，读取操作的二分查找功能实际是在一个静态的快照副本上进行的，这类似于 Java 的 CopyOnWriteArrayList。</p> 
 <p><strong>2、压缩</strong></p> 
 <p>将数据压缩，只保留每个 key 最后一个版本的数据。</p> 
 <p>首先在 broker 的配置中设置 <code>log.cleaner.enable=true</code> 启用 cleaner，这个默认是关闭的。</p> 
 <p>在 topic 的配置中设置 <code>log.cleanup.policy=compact</code> 启用压缩策略。</p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8a89e593ab30fce4ad55092927efb2c0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">防抖和节流的总结</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2becbb753218243615be0fe05f8cb465/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">指针表示数组的几种方式</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>