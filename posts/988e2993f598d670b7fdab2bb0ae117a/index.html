<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>pytorch神经网络实现 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="pytorch神经网络实现" />
<meta property="og:description" content="我们从PyTorch中经典的quickstart示例开始，从中学习神经网络构建和训练过程。
其中要学到并熟练掌握的是如下这些流程：
数据预处理构建模型定制模型损失函数和优化器训练并观察超参数 下面我们就一步步分解这个过程，其中也会学习认识到一些pytorch为我们提供的框架内置对象和函数。初次接触可能还不是很适应，所以以先完成完整的模型训练流程为重。后续再根据任务需求，一步步的扩展pytorch的认知版图
数据预处理 模型训练用的样本，大部分都来自于外部文件系统。本次训练用的数据来自框架内置的数据集，所以代码没有泛化性。涉及到具体数据再做补充。
PyTorch 有两个用于处理数据的工具：torch.utils.data.DataLoader 和 torch.utils.data.Dataset。 Dataset 存储的是数据样本和对应的标签，DataLoader 把Dataset包装成一个可迭代的对象。
import torch from torch import nn from torch.utils.data import DataLoader from torchvision import datasets from torchvision.transforms import ToTensor, Lambda, Compose import matplotlib.pyplot as plt 本次的数据样本来自于Pytorch的TorchVision 数据集。
# 下载的数据集文件会保存到当前用户工作目录的data子目录中。 # 如果不想下载后就找不到了，建议修改root参数的值。 # 例如&#34;D:\\\\datasets\\\\fashionMNIST\\\\&#34;一类的绝对路径 training_data = datasets.FashionMNIST( root=&#34;data&#34;, train=True, download=True, transform=ToTensor(), ) # 测试集也需要下载，代码和上面一样。但参数train=False代表不是训练集(逻辑取反,就是测试集) test_data = datasets.FashionMNIST( root=&#34;data&#34;, train=False, download=True, transform=ToTensor(), ) 下一步就是对已加载数据集的封装，把Dataset 作为参数传递给 DataLoader。这样，就在我们的数据集上包装了一个迭代器(iterator)，这个迭代器还支持自动批处理、采样、打乱顺序和多进程数据加载等这些强大的功能。这里我们定义了模型训练期间，每个批次的数据样本量大小为64，即数据加载器在迭代中，每次返回一批 64 个数据特征和标签。
batch_size = 64 # 创建数据加载器 train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True) test_dataloader = DataLoader(test_data, batch_size=batch_size) # 测试数据加载器输出 for X, y in test_dataloader: print(&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/988e2993f598d670b7fdab2bb0ae117a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-01T11:22:34+08:00" />
<meta property="article:modified_time" content="2022-09-01T11:22:34+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">pytorch神经网络实现</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>我们从PyTorch中经典的quickstart示例开始，从中学习神经网络构建和训练过程。</p> 
<p>其中要学到并熟练掌握的是如下这些流程：</p> 
<ul><li>数据预处理</li><li>构建模型</li><li>定制模型损失函数和优化器</li><li>训练并观察超参数</li></ul> 
<p>下面我们就一步步分解这个过程，其中也会学习认识到一些pytorch为我们提供的框架内置对象和函数。初次接触可能还不是很适应，所以以先完成完整的模型训练流程为重。后续再根据任务需求，一步步的扩展pytorch的认知版图</p> 
<hr> 
<h4>数据预处理</h4> 
<p>模型训练用的样本，大部分都来自于外部文件系统。本次训练用的数据来自框架内置的数据集，所以代码没有泛化性。涉及到具体数据再做补充。</p> 
<p>PyTorch 有两个用于处理数据的工具：<code>torch.utils.data.DataLoader</code> 和 <code>torch.utils.data.Dataset</code>。 <code>Dataset</code> 存储的是数据样本和对应的标签，<code>DataLoader</code> 把Dataset包装成一个可迭代的对象。</p> 
<pre><code>import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor, Lambda, Compose
import matplotlib.pyplot as plt
</code></pre> 
<p>本次的数据样本来自于Pytorch的TorchVision 数据集。</p> 
<pre><code># 下载的数据集文件会保存到当前用户工作目录的data子目录中。
# 如果不想下载后就找不到了，建议修改root参数的值。
# 例如"D:\\\\datasets\\\\fashionMNIST\\\\"一类的绝对路径
training_data = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=ToTensor(),
)

# 测试集也需要下载，代码和上面一样。但参数train=False代表不是训练集(逻辑取反,就是测试集)
test_data = datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=ToTensor(),
)
</code></pre> 
<p>下一步就是对已加载数据集的封装，把Dataset 作为参数传递给 DataLoader。这样，就在我们的数据集上包装了一个迭代器(iterator)，这个迭代器还支持<strong>自动批处理</strong>、<strong>采样</strong>、<strong>打乱顺序和多进程数据加载等</strong>这些强大的功能。这里我们定义了模型训练期间，每个批次的数据样本量大小为64，即数据加载器在迭代中，每次返回一批 64 个数据特征和标签。</p> 
<pre><code>batch_size = 64

# 创建数据加载器
train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=batch_size)

# 测试数据加载器输出
for X, y in test_dataloader:
    print("Shape of X [N, C, H, W]: ", X.shape)
    print("Shape of y: ", y.shape, y.dtype)
    break
</code></pre> 
<p>Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) Shape of y: torch.Size([64]) torch.int64</p> 
<hr> 
<h4>构建模型</h4> 
<p>为了在 PyTorch 中定义神经网络，我们创建了一个继承自 nn.Module 的类。我们在 <strong>init</strong> 函数中定义网络层，并在 forward 函数中指定数据将如何通过网络。为了加速神经网络中的操作，我们将其移至 GPU（如果可用）。</p> 
<pre><code># 检验可以使用的设备
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"使用 {device} 设备")

# 定义神经网络模型
class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(28*28, 512),  # wx + b = [64,1,784] * [784,512] = 64,1,512
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 10)
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits

model = NeuralNetwork().to(device)
print(model)
</code></pre> 
<p>使用 cuda 设备</p> 
<p>NeuralNetwork(</p> 
<p>(flatten): Flatten(start_dim=1, end_dim=-1)</p> 
<p>(linear_relu_stack): Sequential(</p> 
<p>(0): Linear(in_features=784, out_features=512, bias=True)</p> 
<p>(1): ReLU()</p> 
<p>(2): Linear(in_features=512, out_features=512, bias=True)</p> 
<p>(3): ReLU()</p> 
<p>(4): Linear(in_features=512, out_features=10, bias=True) ) )</p> 
<p><strong>pytorch是通过继承 nn.Module 父类来实现自定义的网络模型。</strong></p> 
<p><strong>在 <strong>init</strong> 中初始化神经网络层。</strong></p> 
<p><strong>在 forward 方法中实现对输入数据的操作。</strong></p> 
<hr> 
<p><strong>模型层分解</strong></p> 
<p>为了方便分解 FashionMNIST 模型中的各个层进行说明，我们取一个由 3 张大小为 28x28 的图像组成的小批量样本，看看当它们通过网络传递时会发生什么。</p> 
<pre><code>input_image = torch.rand(3,28,28)
print(input_image.size())
</code></pre> 
<p>torch.Size([3, 28, 28])</p> 
<p><strong>nn.Flatten</strong></p> 
<p>我们初始化 <code>nn.Flatten</code> 层，将每个28x28 大小的二维图像转换为 784 个像素值的连续数组（保持小批量维度（dim=0））。</p> 
<pre><code>flatten = nn.Flatten()
flat_image = flatten(input_image)
print(flat_image.size())
</code></pre> 
<p>torch.Size([3, 784])</p> 
<p><strong>nn.Linear</strong></p> 
<p>linear layer线性层是一个模块，它使用其存储的权重和偏置对输入应用线性变换。</p> 
<pre><code>layer1 = nn.Linear(in_features=28*28, out_features=20)
hidden1 = layer1(flat_image)
print(hidden1.size())
</code></pre> 
<p>torch.Size([3, 20])</p> 
<p><strong>nn.ReLU</strong></p> 
<p>为了在模型的输入和输出之间创建复杂映射，我们使用非线性激活。激活函数在线性变换之后被调用，以便把结果值转为非线性，帮助神经网络学习到各种各样的关键特征值。 在这个模型中，线性层之间使用了 <code>nn.ReLU</code>，其实还有很多激活函数可以在模型中引入非线性。</p> 
<pre><code>print(f"ReLU 之前的数据: {hidden1}\\n\\n")
hidden1 = nn.ReLU()(hidden1)
print(f"ReLU 之后的数据: {hidden1}")
</code></pre> 
<p>ReLU 之前的数据: tensor([[-0.2496, 0.4432, -0.1536, 0.4439, 0.3256, 0.6594, -0.2536, 0.2348, -0.1113, 0.0732, -0.0658, 0.6014, -0.6135, -0.4709, 0.3016, 0.1500, 0.0801, 0.3644, -0.6113, 0.4129], [-0.7556, 0.1309, -0.2760, 0.3292, 0.5749, 0.6503, -0.1372, 0.3096, 0.1499, -0.0446, -0.1845, 0.2553, -0.6012, -0.3562, -0.0291, 0.1380, 0.2641, 0.2835, -0.5634, 0.1305], [-0.3772, -0.0354, -0.3879, 0.1846, 0.5425, 0.5019, 0.3323, 0.3478, 0.1171, 0.1153, -0.3414, 0.1688, -0.4068, 0.0950, -0.0322, 0.1272, 0.1653, 0.1538, -0.8849, 0.1446]], grad_fn=&lt;AddmmBackward0&gt;)</p> 
<p>ReLU 之后的数据: tensor([[0.0000, 0.4432, 0.0000, 0.4439, 0.3256, 0.6594, 0.0000, 0.2348, 0.0000, 0.0732, 0.0000, 0.6014, 0.0000, 0.0000, 0.3016, 0.1500, 0.0801, 0.3644, 0.0000, 0.4129], [0.0000, 0.1309, 0.0000, 0.3292, 0.5749, 0.6503, 0.0000, 0.3096, 0.1499, 0.0000, 0.0000, 0.2553, 0.0000, 0.0000, 0.0000, 0.1380, 0.2641, 0.2835, 0.0000, 0.1305], [0.0000, 0.0000, 0.0000, 0.1846, 0.5425, 0.5019, 0.3323, 0.3478, 0.1171, 0.1153, 0.0000, 0.1688, 0.0000, 0.0950, 0.0000, 0.1272, 0.1653, 0.1538, 0.0000, 0.1446]], grad_fn=&lt;ReluBackward0&gt;)</p> 
<p><strong>nn.Sequential</strong></p> 
<p><code>nn.Sequential</code> 是一个有序的模块容器。数据按照容器中定义的顺序通过所有模块。我们可以使用顺序容器来组合一个像 seq_modules 这样的快速处理网络。</p> 
<pre><code>seq_modules = nn.Sequential(
    flatten,
    layer1,
    nn.ReLU(),
    nn.Linear(20, 10)
)
input_image = torch.rand(3,28,28)
logits = seq_modules(input_image)
</code></pre> 
<p><strong>nn.Softmax</strong></p> 
<p>神经网络的最后一个线性层返回的是 logits类型的值，它们的取值是[-∞, ∞]。 把这些值传递给 <code>nn.Softmax</code> 模块。 logits的值将会被缩放到 [0, 1] 的取值区间，代表模型对每个类别的预测概率。 dim 参数指示我们在向量的哪个维度中计算softmax的值(和为1)。</p> 
<pre><code>softmax = nn.Softmax(dim=1)
pred_probab = softmax(logits)
</code></pre> 
<p><strong>模型参数</strong></p> 
<p>神经网络内的许多层都是包含可训练参数的，即具有在训练期间可以优化的相关权重(<strong>weight</strong>)和偏置(<strong>bias</strong>)。子类 <code>nn.Module</code> 可以自动跟踪模型对象中定义的所有参数字段。使用模型的 <code>parameters()</code> 或 <code>named_parameters()</code> 方法可以访问模型中所有的参数。 下面的代码可以迭代模型中的每一个参数，并打印出它们的大小和它们的值。</p> 
<pre><code>print("Model structure: ", model, "\\n\\n")

for name, param in model.named_parameters():
    print(f"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n")
</code></pre> 
<p>Model structure:</p> 
<p>NeuralNetwork(</p> 
<p>(flatten): Flatten(start_dim=1, end_dim=-1)</p> 
<p>(linear_relu_stack): Sequential(</p> 
<p>(0): Linear(in_features=784, out_features=512, bias=True)</p> 
<p>(1): ReLU()</p> 
<p>(2): Linear(in_features=512, out_features=512, bias=True)</p> 
<p>(3): ReLU()</p> 
<p>(4): Linear(in_features=512, out_features=10, bias=True) ) )</p> 
<p>Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0186, -0.0036, -0.0014, ..., -0.0294, -0.0217, 0.0293], [-0.0041, 0.0305, -0.0148, ..., 0.0036, -0.0100, 0.0239]], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)</p> 
<p>Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0168, -0.0071], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)</p> 
<p>Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0054, 0.0381, -0.0331, ..., 0.0163, -0.0087, -0.0287], [ 0.0252, 0.0025, -0.0126, ..., -0.0261, 0.0020, -0.0217]], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)</p> 
<p>Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0202, -0.0242], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)</p> 
<p>Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0142, -0.0315, -0.0046, ..., 0.0150, 0.0205, -0.0144], [ 0.0070, -0.0086, -0.0114, ..., -0.0193, 0.0310, 0.0325]], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)</p> 
<p>Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0353, -0.0112], device='cuda:0', grad_fn=&lt;SliceBackward0&gt;)</p> 
<hr> 
<h4>定制模型损失函数和优化器</h4> 
<p>训练模型之前，我们需要为模型定制一个损失函数<code>loss function</code>和一个优化器 <code>optimizer</code>。</p> 
<pre><code>loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)  # 使用随机梯度下降方法的优化器
</code></pre> 
<hr> 
<h4>训练并观察超参数</h4> 
<p>在单个训练循环中，模型对训练数据集进行预测（分批输入），并反向传播预测误差以调整模型参数。</p> 
<pre><code>def train(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)  # 训练数据样本总量
    model.train() # 设置模型为训练模式
    for batch, (X, y) in enumerate(dataloader):
        X, y = X.to(device), y.to(device)  # 张量加载到设备

        # 计算预测的误差
        pred = model(X)  # 调用模型获得结果(forward时被自动调用)
        loss = loss_fn(pred, y) # 计算损失

        # 反向传播 Backpropagation
        model.zero_grad() # 重置模型中参数的梯度值为0
        loss.backward() # 计算梯度
        optimizer.step() # 更新模型中参数的梯度值

        if batch % 100 == 0:
            loss, current = loss.item(), batch * len(X)
            print(f"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]")
</code></pre> 
<p>我们还要依赖测试数据集来检查模型的性能，以确保它的学习优化效果。</p> 
<pre><code>def test(dataloader, model, loss_fn):
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    model.eval()  # 模型设置为评估模式，代码等效于 model.train(False)
    test_loss, correct = 0, 0
    with torch.no_grad():
        for X, y in dataloader:
            X, y = X.to(device), y.to(device)
            pred = model(X)
            test_loss += loss_fn(pred, y).item()
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()
    test_loss /= num_batches
    correct /= size
    print(f"Test Error: \\n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \\n")
</code></pre> 
<p>默认情况下，所有 <code>requires_grad=True</code> 属性值的张量都会被跟踪，以便于根据上一次的值来支持对梯度计算。但是，在某些情况下我们并不需要这样做，例如，当我们训练了模型但只想将其应用于某些输入数据的时。或者说白了就是我们只想通过网络进行前向计算时。我们可以把所有计算代码写在 <code>torch.no_grad()</code> 下面来停止跟踪计算。</p> 
<p>训练过程在多轮迭代（epochs）中进行。在每个epoch中，模型通过学习更新内置的参数，以期做出更好的预测。我们在每个epochs打印模型的准确率和损失值；当然，最希望看到的，就是每个 epoch 过程中准确率的增加而损失函数值的减小。</p> 
<pre><code>epochs = 5
for t in range(epochs):
    print(f"Epoch {t+1}\\n-------------------------------")
    train(train_dataloader, model, loss_fn, optimizer)
    test(test_dataloader, model, loss_fn)
print("训练完成!")
</code></pre>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/623ece0fc6e22ec9223eb94bd6d3dcd4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">操作系统——环境变量</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dbdb6f7bd23065c2dd36c1f9cdb10c45/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">expect DOT, actual DOT pos 27, line 2, column 13, token DOT；SQL state [null]；</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>