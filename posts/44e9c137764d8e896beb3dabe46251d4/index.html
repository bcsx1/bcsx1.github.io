<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Query理解在美团搜索中的应用 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Query理解在美团搜索中的应用" />
<meta property="og:description" content="分享嘉宾：刘亮 美团 资深算法工程师
编辑整理：吴雪松
出品社区：DataFunTalk
导读：在过去的20年中，搜索过程中处理查询的方式以及向用户显示结果的方式已完全改变。该过程已经从仅基于文本匹配的检索发展到现阶段——尝试基于对查询的真实语义理解以及上下文，位置，时间，用户的先前短期和长期浏览活动来获得搜索结果。本文主要介绍美团搜索场景下，查询理解系统的一些建设和相关的工作。主要围绕以下几点展开：
Query理解简介
实体识别&amp;实体链接
查询改写
意图识别
▌Query理解简介
1. 美团搜索
在介绍查询 ( Query ) 理解之前，我们先了解下美团搜索，左图是美团APP首页的截图，中间是美团承接的业务，可以看出美团的业务非常多，包括了像外卖、美食、酒店住宿等大家比较熟悉的业务，也有像婚纱摄影、机票预定等相对低频业务。顶部的搜索框，是美团搜索的主入口，美团的搜索就是通过这个搜索框来获取用户的查询Query，在理解查询Query后，对接到所服务的各种各样的业务品类，最后返回给用户想要的结果。
美团搜索是典型的O2O搜索，右图显示了对比传统的网页搜索以及电商搜索的一些差异。
首先是搜索目标，美团搜索的核心是提供服务，包括团单、套餐等本地生活服务。另外也会对一些信息和商品提供查询服务，像天气或者医美百科等；另外还有商品，相对于传统电商，美团主要是本地的一些商品，包括周边的便利店，周边的商场中的商超类的产品，以及周边能配送的商品的搜索。
另外一个重要的特点是基于位置的相关性比较高，因为O2O主要是基于本地生活的服务形态。供给约束方面，网页搜索基本不用考虑；电商搜索的供给是全国的商家，购买后全国配送；O2O场景下，从蜂窝到城市到全国这些维度都有涵盖，蜂窝是类似外卖这种业务，它的配送范围是很有限的，大概可能3~5公里的范围；像美食到餐团购类，是到店里消费，基本是一个城市维度的；另外像酒店旅游这种业务，它可能是全国性质的供给，所以说它涵盖的范围会比较广。
以上就是美团搜索的大概介绍。
2. QU
下面介绍下查询理解系统。QU ( Query Understanding )，主要利用基础NLP能力，对我们的用户输入的Query进行分析，产生一系列的基础信号，然后这些信号会应用到整个搜索链路的召回、排序等各个阶段。
举个例子来说的话，用户输入：杭州东附近的7天酒店，可以通过查询的变换，纠错和扩展，把杭州东扩展成杭州东站，扩大召回。
在往下是成分识别，这个后面也会重点介绍，包括了实体识别、实体链接，它可以把Query再进行一个成分粒度的识别，把杭州东识别成车站类的地理位置，7天识别成一个商家品牌，通过实体链接可以将杭州东对应的经纬度返回，7天链接到具体的品牌ID等。在最后是一些业务应用，包括查询意图的识别方面，我们还需要把它识别出它具体是本地意图，还是异地意图。
右图是我们目前线上应用的搜索结果，可以看到首先它识别出杭州东这个主点，并链接到了杭州东站这个实体。在意图方面，由于是在北京的搜索，但是我们需要找杭州东附近的酒店，所以会有异地的提示，最终的结果是在杭州东站坐标点一定距离半径内召回7天品牌酒店。
3. DQU
上图是查询理解DQU项目的架构。
公司有非常多的业务，很多业务也有自己的垂搜系统，在业务快速迭代的阶段是独立运行的，随着业务的不断发展，如何避免低水平重复建设，更好的积累技术、经验，平台就成了很有价值的工作。目前DQU的项目已经支持了公司内大部分的搜索场景，包括美团点评大搜，还有度假、住宿等业务频道内搜索。
整个框架分三个部分，最底层是基础信号层，主要是NLP相关基础信号模块，可以提供通用和业务个性化的信号输出。中间是业务逻辑层，适配不同的垂搜业务逻辑。最上层是适配层，对于不同的业务搜索可能有不同的接口，需要接口适配再返回最终结果。
接下来重点介绍下几个核心的查询理解模块。
▌实体识别&amp;实体链接
1. 实体识别
① 简介
首先是实体识别，对比于通用网页搜索，电商和O2O搜索更多的是结构化的召回。举个例子，上图中间的“如家上地”，需要把它的商家和地址身份进行识别，然后对应到我们的Doc端，通过不同的字段进行召回。
因为在我们的场景下，Doc端的数据包含了很多结构化的字段，不同字段之间的语义差距会非常大，如果我们进行全字段检索，经常会出现一些语义漂移的问题。比如，搜“肯德基”，可能召回一个理发店，因为它的地址字段有“在肯德基对面”。所以我们需要结构化召回来保证更高的精度。其中NER是指导召回的关键信号。
② 整体架构
实体识别的整体框架，主要分两个部分：下面的离线端和上面的在线部分。
线上的识别来源主要分两部分，一部分是词典的实体匹配，一部分是模型预测，然后再往上是消歧策略，实体词典匹配，主要解决一些热门和词库里能够匹配的词，对一些长尾和泛化的词识别，还是依赖于模型。但是这两个部分中间的结果可能会有一些冲突，所以需要一个消歧策略，包括多粒度、多结果选择。我们主要通过一些模板规则，进行优先级的消歧，最终输出一个多路的结果，因为某些query会有粒度和类别的歧义。
离线部分主要是两个大的部分：一部分是实体挖掘，这个主要是为线上的实体匹配提供基础的实体库，模型方面主要是一些基础的模型训练、优化相关的工作。
③ 模型迭代
接下来讲一下NER模型迭代相关的一些工作。初期线上的模型主要是CRF，在19年引入了BERT模型。这里面主要是两个方面的改进，一方面是训练过程，引入了美团UGC的一些数据，用这些评论相关的数据进行预训练，补充O2O场景下的一些语义信息。再就是fine-tune阶段，我们除了人工标注语料的数据集，还有基于用户行为统计的半自动化生成的一些语料，来扩充训练数据。使模型训练效果，能够更好的拟合线上的应用。
④ 自动标注训练数据
这里简单介绍下，根据词典扩充训练数据的工作。
对于大规模的模型训练，语料是非常重要的一个部分，但是对于NLP任务，一般来说还是比较难以去自动化的获取这些训练语料，我们的一个核心思路是如何利用已有的标注数据、词典来指导内容半自动化的生成训练语料。首先用原始的人工标注语料，训练一个Model A，然后针对线上已有的实体库去预测打分，对打分有差异的部分，进行校正，然后把校正后的结果合并原始数据，再训练一个Model B，最终应用到线上。其中的核心就是校正的过程。
它的前提假设是，实体库和模型的质量，都是比较高的，但是其中模型预测和词典它中间还是有差异的部分，就是我们的模型预测相对于它可以提供更细的粒度。比如下面这个例子：“兄弟烧烤个性diy”，它其实是一个商家的名称，因为有比较全的美团商家库的信息，所以能够通过词典来挖掘出我们的商家信息。
但是模型预测的话，由于兄弟这个词，有影视类的电影，可能是电影名，模型也可能会识别错误，所以需要根据词典的信息进行修正。修正的方法是对模型预测的序列，进行轮巡替换，找出替换概率最高的一个，然后作为替换类型，最终生成一条校正后的训练数据，和原始数据进行联合训练。
⑤ 数据挖掘
另外一个部分就是离线词库的挖掘。
除了已有的商家库和一些结构化数据以外，线上的用户行为，也是非常重要的，怎么通过海量的用户行为数据，泛化我们的实体库，是我们的核心工作。这部分工作主要利用我们线上的用户点击日志，结合召回命中信息，来识别出Query的边界和类型，把用户Query中识别出的实体成分进行落库，同步到实体库中。
Query中的实体边界的切分，主要参考该Query召回的多个Doc结果的命中信息。由于我们是结构化召回，所以可能存在多个字段同时命中，通过统计所有Doc的命中分布情况，来考虑它的切分方式，最终转化成一个整数线性规划的问题，来寻求一个切分概率最大的方式，具体可以参考文章《美团搜索中NER技术的探索与实践》。有了这个切分边界后，再对它的每一个成分进行二分类模型识别，把识别概率比较高的目标成分，进行人工抽检，将符合要求的实体补充到实体库中。最终，通过这样的循环来扩充我们的实体库。
2. 实体链接
① 背景" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/44e9c137764d8e896beb3dabe46251d4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-05-09T11:23:00+08:00" />
<meta property="article:modified_time" content="2021-05-09T11:23:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Query理解在美团搜索中的应用</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align: left">分享嘉宾：刘亮 美团 资深算法工程师</p> 
 <p style="text-align: left">编辑整理：吴雪松<br></p> 
 <p style="text-align: left">出品社区：DataFunTalk<br></p> 
 <p><strong>导读</strong><strong>：</strong>在过去的20年中，搜索过程中处理查询的方式以及向用户显示结果的方式已完全改变。该过程已经从仅基于文本匹配的检索发展到现阶段——尝试基于对查询的真实语义理解以及上下文，位置，时间，用户的先前短期和长期浏览活动来获得搜索结果。本文主要介绍美团搜索场景下，查询理解系统的一些建设和相关的工作。主要围绕以下几点展开：</p> 
 <ul><li><p>Query理解简介</p></li><li><p>实体识别&amp;实体链接</p></li><li><p>查询改写</p></li><li><p>意图识别</p></li></ul> 
 <p><strong>▌Query理解简介</strong></p> 
 <p><strong>1. 美团搜索</strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/85/d5/UOX3oCs8_o.png"></p> 
 <p>在介绍查询 ( Query ) 理解之前，我们先了解下美团搜索，左图是美团APP首页的截图，中间是美团承接的业务，可以看出美团的业务非常多，包括了像外卖、美食、酒店住宿等大家比较熟悉的业务，也有像婚纱摄影、机票预定等相对低频业务。顶部的搜索框，是美团搜索的主入口，美团的搜索就是通过这个搜索框来获取用户的查询Query，在理解查询Query后，对接到所服务的各种各样的业务品类，最后返回给用户想要的结果。<br></p> 
 <p>美团搜索是典型的O2O搜索，右图显示了对比传统的网页搜索以及电商搜索的一些差异。</p> 
 <p>首先是搜索目标，美团搜索的核心是提供服务，包括团单、套餐等本地生活服务。另外也会对一些信息和商品提供查询服务，像天气或者医美百科等；另外还有商品，相对于传统电商，美团主要是本地的一些商品，包括周边的便利店，周边的商场中的商超类的产品，以及周边能配送的商品的搜索。</p> 
 <p>另外一个重要的特点是基于位置的相关性比较高，因为O2O主要是基于本地生活的服务形态。供给约束方面，网页搜索基本不用考虑；电商搜索的供给是全国的商家，购买后全国配送；O2O场景下，从蜂窝到城市到全国这些维度都有涵盖，蜂窝是类似外卖这种业务，它的配送范围是很有限的，大概可能3~5公里的范围；像美食到餐团购类，是到店里消费，基本是一个城市维度的；另外像酒店旅游这种业务，它可能是全国性质的供给，所以说它涵盖的范围会比较广。</p> 
 <p>以上就是美团搜索的大概介绍。</p> 
 <p><strong>2. QU<br></strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/70/df/ZYgxCPD3_o.png"></p> 
 <p>下面介绍下查询理解系统。QU ( Query Understanding )，主要利用基础NLP能力，对我们的用户输入的Query进行分析，产生一系列的基础信号，然后这些信号会应用到整个搜索链路的召回、排序等各个阶段。<br></p> 
 <p>举个例子来说的话，用户输入：杭州东附近的7天酒店，可以通过查询的变换，纠错和扩展，把杭州东扩展成杭州东站，扩大召回。</p> 
 <p>在往下是成分识别，这个后面也会重点介绍，包括了实体识别、实体链接，它可以把Query再进行一个成分粒度的识别，把杭州东识别成车站类的地理位置，7天识别成一个商家品牌，通过实体链接可以将杭州东对应的经纬度返回，7天链接到具体的品牌ID等。在最后是一些业务应用，包括查询意图的识别方面，我们还需要把它识别出它具体是本地意图，还是异地意图。</p> 
 <p>右图是我们目前线上应用的搜索结果，可以看到首先它识别出杭州东这个主点，并链接到了杭州东站这个实体。在意图方面，由于是在北京的搜索，但是我们需要找杭州东附近的酒店，所以会有异地的提示，最终的结果是在杭州东站坐标点一定距离半径内召回7天品牌酒店。</p> 
 <p><strong>3. DQU</strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/28/76/nqS1V1v5_o.png"></p> 
 <p>上图是查询理解DQU项目的架构。<br></p> 
 <p>公司有非常多的业务，很多业务也有自己的垂搜系统，在业务快速迭代的阶段是独立运行的，随着业务的不断发展，如何避免低水平重复建设，更好的积累技术、经验，平台就成了很有价值的工作。目前DQU的项目已经支持了公司内大部分的搜索场景，包括美团点评大搜，还有度假、住宿等业务频道内搜索。</p> 
 <p>整个框架分三个部分，最底层是基础信号层，主要是NLP相关基础信号模块，可以提供通用和业务个性化的信号输出。中间是业务逻辑层，适配不同的垂搜业务逻辑。最上层是适配层，对于不同的业务搜索可能有不同的接口，需要接口适配再返回最终结果。</p> 
 <p>接下来重点介绍下几个核心的查询理解模块。</p> 
 <p><strong>▌实体识别&amp;实体链接</strong></p> 
 <p><strong>1. 实体识别</strong></p> 
 <p><strong>① 简介<br></strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/5e/eb/MqQnLAMX_o.png"></p> 
 <p>首先是实体识别，对比于通用网页搜索，电商和O2O搜索更多的是结构化的召回。举个例子，上图中间的“如家上地”，需要把它的商家和地址身份进行识别，然后对应到我们的Doc端，通过不同的字段进行召回。<br></p> 
 <p>因为在我们的场景下，Doc端的数据包含了很多结构化的字段，不同字段之间的语义差距会非常大，如果我们进行全字段检索，经常会出现一些语义漂移的问题。比如，搜“肯德基”，可能召回一个理发店，因为它的地址字段有“在肯德基对面”。所以我们需要结构化召回来保证更高的精度。其中NER是指导召回的关键信号。</p> 
 <p><strong>② 整体架构</strong><br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/2a/33/by7WztGr_o.png"></p> 
 <p>实体识别的整体框架，主要分两个部分：下面的离线端和上面的在线部分。</p> 
 <p>线上的识别来源主要分两部分，一部分是词典的实体匹配，一部分是模型预测，然后再往上是消歧策略，实体词典匹配，主要解决一些热门和词库里能够匹配的词，对一些长尾和泛化的词识别，还是依赖于模型。但是这两个部分中间的结果可能会有一些冲突，所以需要一个消歧策略，包括多粒度、多结果选择。我们主要通过一些模板规则，进行优先级的消歧，最终输出一个多路的结果，因为某些query会有粒度和类别的歧义。<br></p> 
 <p>离线部分主要是两个大的部分：一部分是实体挖掘，这个主要是为线上的实体匹配提供基础的实体库，模型方面主要是一些基础的模型训练、优化相关的工作。</p> 
 <p><strong>③ 模型迭代</strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/a5/69/EyQre16B_o.png"></p> 
 <p>接下来讲一下NER模型迭代相关的一些工作。初期线上的模型主要是CRF，在19年引入了BERT模型。这里面主要是两个方面的改进，一方面是训练过程，引入了美团UGC的一些数据，用这些评论相关的数据进行预训练，补充O2O场景下的一些语义信息。再就是fine-tune阶段，我们除了人工标注语料的数据集，还有基于用户行为统计的半自动化生成的一些语料，来扩充训练数据。使模型训练效果，能够更好的拟合线上的应用。<br></p> 
 <p><strong>④ 自动标注训练数据</strong><br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/f0/ee/4ntJljVd_o.png"></p> 
 <p>这里简单介绍下，根据词典扩充训练数据的工作。<br></p> 
 <p>对于大规模的模型训练，语料是非常重要的一个部分，但是对于NLP任务，一般来说还是比较难以去自动化的获取这些训练语料，我们的一个核心思路是如何利用已有的标注数据、词典来指导内容半自动化的生成训练语料。首先用原始的人工标注语料，训练一个Model A，然后针对线上已有的实体库去预测打分，对打分有差异的部分，进行校正，然后把校正后的结果合并原始数据，再训练一个Model B，最终应用到线上。其中的核心就是校正的过程。</p> 
 <p>它的前提假设是，实体库和模型的质量，都是比较高的，但是其中模型预测和词典它中间还是有差异的部分，就是我们的模型预测相对于它可以提供更细的粒度。比如下面这个例子：“兄弟烧烤个性diy”，它其实是一个商家的名称，因为有比较全的美团商家库的信息，所以能够通过词典来挖掘出我们的商家信息。</p> 
 <p>但是模型预测的话，由于兄弟这个词，有影视类的电影，可能是电影名，模型也可能会识别错误，所以需要根据词典的信息进行修正。修正的方法是对模型预测的序列，进行轮巡替换，找出替换概率最高的一个，然后作为替换类型，最终生成一条校正后的训练数据，和原始数据进行联合训练。</p> 
 <p><strong>⑤ 数据挖掘</strong><br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/e3/19/EZotRHnC_o.png"></p> 
 <p>另外一个部分就是离线词库的挖掘。<br></p> 
 <p>除了已有的商家库和一些结构化数据以外，线上的用户行为，也是非常重要的，怎么通过海量的用户行为数据，泛化我们的实体库，是我们的核心工作。这部分工作主要利用我们线上的用户点击日志，结合召回命中信息，来识别出Query的边界和类型，把用户Query中识别出的实体成分进行落库，同步到实体库中。</p> 
 <p>Query中的实体边界的切分，主要参考该Query召回的多个Doc结果的命中信息。由于我们是结构化召回，所以可能存在多个字段同时命中，通过统计所有Doc的命中分布情况，来考虑它的切分方式，最终转化成一个整数线性规划的问题，来寻求一个切分概率最大的方式，具体可以参考文章《美团搜索中NER技术的探索与实践》。有了这个切分边界后，再对它的每一个成分进行二分类模型识别，把识别概率比较高的目标成分，进行人工抽检，将符合要求的实体补充到实体库中。最终，通过这样的循环来扩充我们的实体库。</p> 
 <p><strong>2. 实体链接</strong></p> 
 <p><strong>① 背景</strong><br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/9a/52/4QhTTxlV_o.png"></p> 
 <p>下面再介绍一下实体链接的一些相关工作，美团搜索场景下的LBS属性，决定了很多用户都有地址类搜索的习惯，所以地址识别也是我们的一个重点。实体识别把地址成分识别出来之后，后面很重要的工作是把它的经纬度坐标找到，通过半径距离召回，满足用户搜索某个地址周边结果的诉求。这就需要实体链接把用户Query中的文本链接到具体的实体，并返回实体的属性。另外实体链接模块，本身还可以修正NER的结果。<br></p> 
 <p><strong>② 整体框架</strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/74/30/BYEN6UtY_o.png"></p> 
 <p>上图是实体链接的整体框架，它主要分为两个部分：</p> 
 <p>离线的部分，其核心是对所有物理实体mention的挖掘，其实就是实体的一个别名，用来扩大实体链接召回。<br></p> 
 <p>线上部分，首先通过别名进行实体召回，然后对召回的实体进行消歧排序。消歧主要结合Query文本序列的特征、基于地理位置的特征（比如城市和GeoHash），还有上下文的一些文本信息进行消歧排序，返回给用户最相关的Top实体。</p> 
 <p><strong>③ 核心算法</strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/92/d1/qQVukp8q_o.png"></p> 
 <p>核心算法如上图。离线部分，刚才也提到了主要是Mention的挖掘，目前基础数据，主要是商家库的数据、搜索日志、UGC评论、知识图谱等。Mention挖掘目前主要有三种方式：<br></p> 
 <ul><li><p>抽取式：对已有的核心实体库进行核心词的一个识别，然后再通过核心词的组合，来泛化出标准实体的一些别名</p></li><li><p>挖掘式：主要是通过用户评论和搜索的点击session日志，通过用户行为挖掘用户对于实体的一些别名输入</p></li><li><p>生成式：主要是通过Seq2Seq的一些模型，自动化的去生产一些泛化实体的别名</p></li></ul> 
 <p>右下角是一些例子，比如说标准的别名，凯德茂望京，能够挖掘出它的一些相关的子成分（凯德mall）。</p> 
 <p>在线消歧部分，主要是一些相关性的计算和消歧排序，不再展开了。</p> 
 <p><strong>▌查询改写</strong></p> 
 <p><strong>1. 背景</strong><br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/59/4a/CMAyERqY_o.png"></p> 
 <p>为什么需要查询改写？主要因为自然语言表达的多样性，首先是Query和Doc之间表达的差异，用户的Query会相对随意，而Doc端相对正规，商家和运营录入的商家介绍等相关字段，会标准化一些。另外一个问题就是一义多词，通常一个含义的表达会有非常多种输入的方式。<br></p> 
 <p>右图是线上真实的搜索日志，是“理发”相关的搜索词。可以看到有非常多的变换形式。还有一词多义的问题，比如：结婚照，它可能包含两类的含义，一类是要找婚纱照，另外还有可能是去拍结婚证需要的证件照，如果我们不进行Query查询的改写，直接通过原词文本匹配，很可能会漏召回。</p> 
 <p><strong>2. 技术演进</strong><br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/de/43/vll9BF9r_o.png"></p> 
 <p>查询改写这块，技术演进主要分4个阶段，最初是基于词典规则，它的优点是精度高，但是召回率非常低。后面加入了基于用户行为统计挖掘的相关扩召回的方式，但由于是基于整串的匹配，召回虽然有一定提升，还是没法满足线上用户很多长尾Query的搜索。<br></p> 
 <p>为了解决长尾问题，引入了基于翻译模型的统计翻译改写，主要是通过用户行为日志，训练翻译模型和语言模型，从子串片段级别来解决覆盖问题，极大的提升了改写的召回。但它的问题是会比较容易产生语义的漂移，因为它主要是基于文本对齐和文本替换的统计概率，并未考虑语义信息。所以我们又引入了基于Bert的语义规范化，进行过滤，很大程度的缓解了语义漂移的问题。</p> 
 <p><strong>3. 为什么选择SMT</strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/77/79/Ox1sCK5r_o.png"></p> 
 <p>接下来重点介绍一下我们线上的翻译改写模型。<br></p> 
 <p>为什么要选择这样一个翻译模型呢？首先翻译所需的平行语料，在搜索场景下，比较容易通过搜索日志的Session来构造，甚至还可以用Query-Doc的点击数据来补充，通过这样的平行语料，就能够自动化的获取海量的标注数据，覆盖足够多的语言现象，解决表达多样的问题。</p> 
 <p>另外翻译模型很重要一个特点，是它能够支持子串级别的替换，并充分考虑上下文。所以说它能够很好的进行召回泛化。</p> 
 <p><strong>4. SMT改写过程</strong><br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/aa/bb/vVYgwFws_o.png"></p> 
 <p>这是SMT改写的一个大致的过程。它主要分为三个部分：</p> 
 <p>最上面是句对挖掘，通过海量的用户行为，包括Session、Query-Title、Query-Doc-Query数据，对这些数据进行特征抽取，然后再结合句对的判别模型，生成片段级别的对齐语料。<br></p> 
 <p>第二部分翻译模型训练，它的输入是上一步生成的对齐语料，然后生成N-gram的片段，再结合语义计算和统计规则，去生产翻译模型和语言模型。它主要是通过N-Gram这种方式进行子串级别的泛化。</p> 
 <p>第三部分是线上的解码和终判，主要考虑性能问题。因为线上替换时，子串候选解码如果不加限制，会产生组合爆炸的问题。所以结合了BeamSearch以及业务相关的过滤器，例如利用NER和实体链接的信息，对商家实体词限制改写，通过这样的一些业务特征来保证精度。通过路径裁减，返回概率最高的Top-K的结果，进行改写路径的生成。</p> 
 <p><strong>▌意图识别</strong></p> 
 <p><strong>1. 背景</strong></p> 
 <p>目前我们意图模块的核心是识别用户的业务需求，因为我们涵盖的业务品类非常多，不同的业务，展示模板和展示样式也都不同，比如酒店的查询，可能会有用户的入离时间展示模板。所以需要把不同的业务需求识别出来，进行多形态的召回。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/0f/14/0KT428PM_o.png"></p> 
 <p>上面是我们意图的划分，包括左边的业务意图，例如美食、酒店、旅游等等，会直接访问业务相关索引进行召回。中间是阿拉丁（开放平台），主要获取一些活动、第三方结果。最右边还会有一些基于知识内容的信息类召回，比如根据评论内容召回结果。最下面是对应的一些场景，比如时间、空间、人和事件的场景。<br></p> 
 <p><strong>2. 整体框架</strong><br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/a2/af/AYAe7KfA_o.png"></p> 
 <p>意图识别的整体框架，主要分为两个部分：</p> 
 <p>意图召回。这块是转换为了分类任务，只判断某个查询是否包含某种意图。线上采用词典匹配+规则+模型的方式进行识别，词典主要包含业务和领域相关数据，词典和Pattern规则，能比较好的解决热门识别，针对长尾部分，主要靠Bert模型来解决泛化识别问题。<br></p> 
 <p>意图分布。意图召回完了以后，我们还要知道当前搜索的各个意图的强弱，尤其是找到主意图，就是图上面部分的意图分布，我们将其转化成排序问题。由于线上展示的每条POI结果，后台都有明确的业务归属，所以我们就可以依据这个业务归属信息和用户点击行为，获得有标注的训练语料，来训练排序模型。模型特征主要分为两部分，一是统计类的特征，包括一些CTR、CVR及相关的用户行为的特征。二是Embedding类特征，来进行语义的表达。</p> 
 <p><strong>▌总结和展望</strong></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/0c/4f/pJsyzm60_o.png"></p> 
 <p>最后总结下，本文主要介绍了美团查询理解系统中的主要模块，包括实体识别、查询改写、意图识别。查询理解是搜索引擎与NLP结合的产物，用来解决搜索相关的一些文本理解任务。除了文本本身，后续我们还会考虑引入更多包括时空、用户，场景的信息来做到更深入的理解搜索场景下的用户查询意图。</p> 
 <p><strong>分享嘉宾：</strong></p> 
 <p>刘亮，美团资深算法工程师。9年搜索和NLP相关工作经验，目前是美团搜索查询理解方向架构师。</p> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f13b7d651d064dc902f11303efc60070/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">信息学奥赛一本通（C&#43;&#43;版）第4部分 数据结构(提高篇)--＞第 3 章 线段树 1994：音乐会</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1a1e986b03e51dc083a83e0b10db2b7f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">linux虚拟机搭建Kafka集群环境</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>