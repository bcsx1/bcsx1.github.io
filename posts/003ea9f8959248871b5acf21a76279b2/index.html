<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Linux-零拷贝技术 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Linux-零拷贝技术" />
<meta property="og:description" content="“零拷贝”，这名字一听就很厉害。
在看宋宝华老师的一篇吃瓜文章种，看到了这个逻辑，于是去搜索记录整理，其实东西都是东一搜西一搜搞到的，其中比较好的两篇文章：
一文彻底揭秘linux操作系统之「零拷贝」！ - 知乎
linux内核零拷贝技术_HeroKern的博客-CSDN博客_linux 零拷贝
这篇文章里面引用了很多两位的内容，大家可以去看下原著，下面内容是自己的笔记记录。
简介：
零拷贝：
[1] DMA传输可以不经过CPU copy从一个硬件传递到另一个硬件中
为啥不直接在两个硬件中传递呢？
答：从后面的例子来看，这的传递并不能满足涉及，有的时候需要对数据的操作，比如socket传输中在kernel buffer中会增加一个buffer的size和位置信息，再copy到socket上。
由此引出问题：这个中间的操作是必须的吗？假如经过kernel不可以吗？
答：自己思考，像是硬盘和socket，并不是挂在一个总线上，两个设备之间的信息传序，必须得经过kernel作为中间人来转换传输。后面再思考下吧。
[2] 零拷贝是：当用户空间发起调用，将一个数据从硬件1（硬盘）中读取然后再发送到硬件2（网口缓存）中，这个过程可以简化为：硬件1直接通过DMA传递到内核空间中，再经过DMA传递到硬件2上，这样就不用发生CPU copy了。
1、零拷贝是什么？ &#34;零拷贝&#34;中的&#34;拷贝&#34;是指操作系统在I/O操作中,将数据从一个内存区域复制到另外一个内存区域，而&#34;零&#34;并不是指0次复制, 更多的是指在用户态和内核态之间的复制是0次。
零拷贝是指的在用户与内核空间之间的复制的次数是0，那么如果不用零拷贝的话，复制的次数是几呢？如下面的例子：
例子：
从上图可以看出软件流程一共复制了4次数据，内核态到用户态切换4次。
读操作（复制两次，上下文切换两次）：
1.用户进程通过 read() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）
2.CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）
3。CPU将读缓冲区（read buffer）中的数据拷贝到用户空间（user space）的用户缓冲区（user buffer）
4.上下文从内核态（kernel space）切换回用户态（user space），read 调用执行返回。
写操作（复制两次，上下文切换两次）：
1.用户进程通过 write() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）
2.CPU 将用户缓冲区（user buffer）中的数据拷贝到内核空间（kernel space）的网络缓冲区（socket buffer）
3.CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。（虽然网络驱动会分层解析网络数据帧，但网络数据是通过sk_buff指针缓存在各个层级进行数据，所以这里网络协议层不存数据拷贝）
4.上下文从内核态（kernel space）切换回用户态（user space），write 系统调用执行返
从上面可以看到用户态和内核态之间数据拷贝流程走了两次，熟悉linux内核调度结构的知道内核态和应用态数据拷贝是比较费时，同时拷贝数据是个冗余过程，仅仅从应用态过了一圈。所以引入了零拷贝技术。
这个例子和下面的例子是重复的，但是放在这里可以更好的描述一下多次拷贝的情况。同时里面的描述也可以做为一个基础参考，可以先看仔细看看这个例子。
2、零拷贝给我们带来的好处 • 减少甚至完全避免不必要的 CPU 拷贝，从而让 CPU 解脱出来去执行其他的任务；" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/003ea9f8959248871b5acf21a76279b2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-13T21:03:49+08:00" />
<meta property="article:modified_time" content="2022-06-13T21:03:49+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Linux-零拷贝技术</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>“零拷贝”，这名字一听就很厉害。</p> 
<p>在看宋宝华老师的一篇吃瓜文章种，看到了这个逻辑，于是去搜索记录整理，其实东西都是东一搜西一搜搞到的，其中比较好的两篇文章：</p> 
<p><a href="https://zhuanlan.zhihu.com/p/430848775" rel="nofollow" title="一文彻底揭秘linux操作系统之「零拷贝」！ - 知乎">一文彻底揭秘linux操作系统之「零拷贝」！ - 知乎</a></p> 
<p><a href="https://blog.csdn.net/qq_21792169/article/details/121427900" title="linux内核零拷贝技术_HeroKern的博客-CSDN博客_linux 零拷贝">linux内核零拷贝技术_HeroKern的博客-CSDN博客_linux 零拷贝</a></p> 
<p>这篇文章里面引用了很多两位的内容，大家可以去看下原著，下面内容是自己的笔记记录。</p> 
<p>简介：</p> 
<p>零拷贝：</p> 
<p>[1] DMA传输可以不经过CPU copy从一个硬件传递到另一个硬件中</p> 
<p>      为啥不直接在两个硬件中传递呢？</p> 
<p>      答：从后面的例子来看，这的传递并不能满足涉及，有的时候需要对数据的操作，比如socket传输中在kernel buffer中会增加一个buffer的size和位置信息，再copy到socket上。</p> 
<p>由此引出问题：这个中间的操作是必须的吗？假如经过kernel不可以吗？</p> 
<p>      答：自己思考，像是硬盘和socket，并不是挂在一个总线上，两个设备之间的信息传序，必须得经过kernel作为中间人来转换传输。后面再思考下吧。</p> 
<p>[2] 零拷贝是：当用户空间发起调用，将一个数据从硬件1（硬盘）中读取然后再发送到硬件2（网口缓存）中，这个过程可以简化为：硬件1直接通过DMA传递到内核空间中，再经过DMA传递到硬件2上，这样就不用发生CPU copy了。</p> 
<h3><strong>1、零拷贝是什么？</strong></h3> 
<p>"零拷贝"中的"拷贝"是指操作系统在I/O操作中,将数据从一个内存区域复制到另外一个内存区域，而"零"并不是指0次复制, 更多的是指在用户态和内核态之间的复制是0次。</p> 
<p>零拷贝是指的在用户与内核空间之间的复制的次数是0，那么如果不用零拷贝的话，复制的次数是几呢？如下面的例子：</p> 
<p>例子：</p> 
<p class="img-center"><img alt="" height="337" src="https://images2.imgbox.com/74/56/3YqR7MOT_o.jpg" width="478"></p> 
<p>从上图可以看出软件流程一共复制了4次数据，内核态到用户态切换4次。<br><strong><span style="color:#4da8ee;">读操作</span></strong>（复制两次，上下文切换两次）：<br>         1.用户进程通过 read() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）<br>         2.CPU利用DMA控制器将数据从主存或硬盘<span style="color:#4da8ee;">拷贝</span>到内核空间（kernel space）的读缓冲区（read buffer）<br>         3。CPU将读缓冲区（read buffer）中的数据<span style="color:#4da8ee;">拷贝</span>到用户空间（user space）的用户缓冲区（user buffer）<br>         4.上下文从内核态（kernel space）切换回用户态（user space），read 调用执行返回。<br><strong><span style="color:#4da8ee;">写操作</span></strong>（复制两次，上下文切换两次）：<br>         1.用户进程通过 write() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）<br>         2.CPU 将用户缓冲区（user buffer）中的数据<span style="color:#4da8ee;">拷贝</span>到内核空间（kernel space）的网络缓冲区（socket buffer）<br>         3.CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）<span style="color:#4da8ee;">拷贝</span>到网卡进行数据传输。（虽然网络驱动会分层解析网络数据帧，但网络数据是通过sk_buff指针缓存在各个层级进行数据，所以这里网络协议层不存数据拷贝）<br>         4.上下文从内核态（kernel space）切换回用户态（user space），write 系统调用执行返<br> 从上面可以看到用户态和内核态之间数据拷贝流程走了两次，熟悉linux内核调度结构的知道内核态和应用态数据拷贝是比较费时，同时拷贝数据是个冗余过程，仅仅从应用态过了一圈。所以引入了零拷贝技术。</p> 
<p>          这个例子和下面的例子是重复的，但是放在这里可以更好的描述一下多次拷贝的情况。同时里面的描述也可以做为一个基础参考，可以先看仔细看看这个例子。</p> 
<h3><strong>2、零拷贝给我们带来的好处</strong></h3> 
<p>• 减少甚至完全避免不必要的 CPU 拷贝，从而让 CPU 解脱出来去执行其他的任务；</p> 
<p>• 减少内存带宽的占用；</p> 
<p>• 通常零拷贝技术还能够减少用户空间和操作系统内核空间之间的上下文切换。</p> 
<h3><strong>3、操作系统中谁负责IO拷贝？</strong></h3> 
<p>DMA 负责内核间的 IO 传输，CPU 负责内核和应用间的 IO 传输。</p> 
<p>两种拷贝类型：</p> 
<p>（1）CPU COPY</p> 
<p>通过计算机的组成原理我们知道, 内存的读写操作是需要 CPU 的协调数据总线,地址总线和控制总线来完成的因此在"拷贝"发生的时候,往往需要 CPU 暂停现有的处理逻辑,来协助内存的读写，这种我们称为 CPU COPY。CPU COPY 不但占用了 CPU 资源,还占用了总线的带宽。</p> 
<p>（2）DMA COPY</p> 
<p>DMA(DIRECT MEMORY ACCESS) 是现代计算机的重要功能，它有一个重要特点：当需要与外设进行数据交换时, CPU 只需要初始化这个动作便可以继续执行其他指令,剩下的数据传输的动作完全由DMA来完成可以看到<span style="color:#4da8ee;"> DMA COPY 是可以避免大量的 CPU 中断的</span>。</p> 
<p>问题：DMA的传输可以节约CPU资源，实现的原理是避免了大量的CPU中断？</p> 
<p>回答：1 - DMA传输时是不经过cpu的，即这个时候不会占用cpu资源，因此使用DMA可以达到两个效果：</p> 
<p>[1] 从cpu角度来说，可以大大减少CPU占用率，可以使得CPU的占用更多的应用与其他操作。</p> 
<p>[2] 从整体角度（CPU+操作系统）来说，减少了对CPU的使用，提高了效率</p> 
<p>但是这个时候的CPU和DMA是同时存在的，在一条总线上，这两部分如何运行呢？</p> 
<p>这个时候存在3个方案：</p> 
<p>(1)停止CPU访内存；</p> 
<p>CPU暂停访存是指在启动DMA后，CPU停止对主存的访问直到接收到DMA中断，CPU将总线控制权交给I/O操作。</p> 
<p>(2)周期挪用；</p> 
<p>周期挪用/周期窃取是指在CPU访存过程中，接收到DMA请求后挪用出一两个周期用于I/O，I/O完成后CPU继续访存。</p> 
<p>(3)DMA与CPU交替访问内存（<strong>DMA与CPU分时复用数据总线</strong>）．</p> 
<p>cpu交出总线后，会停止<strong>数据总线上的</strong>工作，<span style="color:#fe2c24;">不涉及总线的操作应该时可以进行的？（有待考究）</span></p> 
<h3><strong>4、拷贝过程中会发生什么？</strong></h3> 
<p><strong>上下文切换：</strong></p> 
<p>从内核态到用户态时会发生上下文切换，上下文切换时指由用户态切换到内核态, 以及由内核态切换到用户态。</p> 
<p>现在我们对零拷贝有一定的概念基础了，接下来，让我们深入去了解一下 Linux 操作系统与 IO 复制之间的来龙去脉。</p> 
<h3><strong>- 原理篇 -</strong></h3> 
<h3><strong>1、内存管理</strong></h3> 
<p>Linux 内存管理结构的历史：在 Linux 内核2.4版本之前，内存管理结构中 page cache 和 buffer cache 是分开的，分别是两个独立的。</p> 
<p>从 Linux 内核2.4 版本开始操作系统在内存管理机制进行了优化，才支持了零拷贝机制。</p> 
<h4><strong>2、Linux内存管理结构</strong></h4> 
<p>Linux 内核的文件 <strong><span style="color:#4da8ee;">Cache 管理机制</span></strong>来进行实现的，在 Linux 的实现中，文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache，每一个 Page Cache 包含若干 Buffer Cache。</p> 
<p><span style="color:#4da8ee;">内存管理系统和 VFS 只与 Page Cache 交互（原来如此）</span>，内存管理系统负责维护每项 Page Cache 的分配和回收，同时在使用 memory map 方式访问时负责建立映射。</p> 
<p>VFS 负责 Page Cache 与用户空间的数据交换。而具体文件系统则一般只与 Buffer Cache 交互，它们负责在外围存储设备和 Buffer Cache 之间交换数据。</p> 
<p><strong>标注：VFS（virtual File System） 的作用就是采用标准的 Unix 系统调用读写位于不同物理介质上的不同文件系统</strong>，即为各类文件系统提供了一个统一的操作界面和应用编程接口。VFS 是一个可以让open()、read()、write()等系统调用不用关心底层的存储介质和文件系统类型就可以工作的粘合层。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/44/0a/RpPJDWia_o.png"></p> 
<h4><strong>3、应用上下文与内核上下文共享内存交互过程</strong></h4> 
<p><span style="color:#4da8ee;">将 Cache 项映射到用户空间，使得应用程序可以像使用内存指针一样访问文件</span>，Memory map 访问 Cache 的方式在内核中是采用请求页面机制实现的：</p> 
<p>• 当我们应用程序调用 mmap（下图中1），陷入到内核中后调用 dommappgoff （图中2）该函数从应用程序的地址空间中分配一段区域作为映射的内存地址，并使用一个 VMA（vmareastruct）结构代表该区域，之后就返回到应用程序（图中3）；</p> 
<p>• 然后当应用程序访问 mmap 所返回的地址指针时（图中4），由于虚实映射尚未建立，会触发<strong>缺页中断</strong>（图中5）；</p> 
<p>• 之后系统会调用缺页中断处理函数（图中6），在缺页中断处理函数中，内核通过相应区域的 VMA 结构判断出该区域属于文件映射，于是调用具体文件系统的接口读入相应的 Page Cache 项（图中7、8、9），并填写相应的虚实映射表；</p> 
<p>• 经过这些步骤之后，应用程序就可以正常访问相应的内存区域了。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/c4/65/CdY4c6uy_o.png"></p> 
<p></p> 
<h3><strong>- IO 零拷贝 -</strong></h3> 
<h4><strong>1、存在多次拷贝的原因</strong></h4> 
<p>操作系统为了保护系统不被应用程序有意或无意地破坏，为操作系统设置了用户态和内核态两种状态，用户态想要获取系统资源(例如访问硬盘)，必须通过系统调用进入到内核态, 由内核态获取到系统资源，再切换回用户态返回应用程序。</p> 
<p>出于 "readahead cache" 和异步写入等等性能优化的需要, 操作系统在内核态中也增加了一个"内核缓冲区"(kernel buffer)。读取数据时并不是直接把数据读取到应用程序的 buffer， 而先读取到 kernel buffer， 再由 kernel buffer 复制到应用程序的 buffer。因此,数据在被应用程序使用之前，可能需要被多次拷贝。</p> 
<p>所以kernel buffer时多次 复制的关键，多了一个中间件。</p> 
<h4><strong>2、非零拷贝IO流程</strong></h4> 
<p>总结所有系统中, 不管是 WEB 应用服务器, FTP 服务器,数据库服务器, 静态文件服务器等等, 所有涉及到数据传输的场景，无非就一种:</p> 
<p>——<span style="color:#4da8ee;">从硬盘上读取文件数据, 发送到网络上去。</span></p> 
<p>这个场景我们简化为一个模型:</p> 
<p>File.read(fileDesc, buf, len);</p> 
<p>Socket.send(socket, buf, len);</p> 
<p>为了方便描述,上面这两行代码, 我们给它起个名字: <strong>read-send模型。</strong></p> 
<p>操作系统在实现这个 read-send 模型时,需要有以下步骤:</p> 
<ol><li>应用程序开始读文件的操作；</li><li>应用程序发起系统调用, 从用户态切换到内核态(<span style="color:#4da8ee;">第一次上下文切换</span>)；</li><li>内核态中把数据从硬盘文件<span style="color:#0d0016;"><span style="background-color:#4da8ee;">读取</span></span>到内核中间缓冲区(kernel buf)；</li><li>数据从内核中间缓冲区(kernel buf)<span style="background-color:#4da8ee;">复制</span>到(用户态)应用程序缓冲区(app buf),从内核态切换回到用户态(<span style="color:#4da8ee;">第二次上下文切换</span>)；</li><li>应用程序开始发送数据到网络上；</li><li>应用程序发起系统调用,从用户态切换到内核态(<span style="color:#4da8ee;">第三次上下文切换</span>)；</li><li>内核中把数据从应用程序(app buf)的缓冲区<span style="background-color:#4da8ee;">复制</span>到socket的缓冲区(socket)；</li><li>内核中再把数据从socket的缓冲区(socket buf)<span style="background-color:#4da8ee;">发送</span>的网卡的缓冲区(NIC buf)上；</li><li>从内核态切换回到用户态(<span style="color:#4da8ee;">第四次上下文切换</span>)</li></ol> 
<p>如下图表示：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/5b/53/Uh3ymuP3_o.png"></p> 
<p>由上图可以很清晰地看到, 一次 read-send 涉及到了四次拷贝:</p> 
<ol><li>硬盘拷贝到内核缓冲区(DMA COPY)；</li><li>内核缓冲区拷贝到应用程序缓冲区(CPU COPY)；</li><li>应用程序缓冲区拷贝到socket缓冲区(CPU COPY)；</li><li>socket buf拷贝到网卡的buf(DMA COPY)。</li></ol> 
<p>上面共发生了4次复制和4次上文切换。直接把数据从“硬盘”中发送到“网卡缓冲区上”如何？</p> 
<p>其中涉及到2次 CPU 中断, 还有4次的上下文切换。很明显,第2次和第3次的的 copy 只是把数据复制到 app buffer 又原封不动的复制回来, 为此带来了两次的 CPU COPY 和两次上下文切换, 是完全没有必要的。</p> 
<p>Linux 的零拷贝技术就是为了优化掉这两次<strong>不必要的拷贝。</strong></p> 
<h4><strong>3、sendFile 系统调用的IO流程</strong></h4> 
<p><strong>Linux 内核2.1</strong>开始引入一个叫 sendFile 系统调用,这个系统调用可以在内核态内把数据从内核缓冲区直接复制到套接字(SOCKET)缓冲区内, 从而可以减少上下文的切换和不必要数据的复制。</p> 
<p>这个系统调用其实就是一个高级 I/O 函数, 函数签名如下:</p> 
<p>#include&lt;sys/sendfile.h&gt;</p> 
<p>ssize_t senfile(int out_fd,int in_fd,off_t* offset,size_t count);</p> 
<ol><li>out_fd 是写出的文件描述符,而且必须是一个 socket；</li><li>in_fd 是读取内容的文件描述符,必须是一个真实的文件, 不能是管道或 socket；</li><li>offset 是开始读的位置；</li><li>count 是将要读取的字节数。</li></ol> 
<p>有了sendFile这个系统调用后, 我们 read-send 模型就可以简化为:</p> 
<ol><li>应用程序开始读文件的操作；</li><li>应用程序发起系统调用, 从用户态切换到内核态(<span style="color:#4da8ee;">第一次上下文切换</span>)；</li><li>内核态中把数据从硬盘文件<span style="background-color:#4da8ee;">读取</span>到内核中间缓冲区；</li><li>通过 sendFile,在内核态中把数据从内核缓冲区<span style="background-color:#4da8ee;">复制</span>到socket的缓冲区；</li><li>内核中再把数据从 socket 的缓冲区<span style="background-color:#4da8ee;">发送</span>的网卡的 buf 上；</li><li>从内核态切换到用户态(<span style="color:#4da8ee;">第二次上下文切换</span>)。</li></ol> 
<p>如下图所示：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/2d/11/OJ4tV1ZJ_o.png"></p> 
<p><strong>涉及到数据拷贝变成:</strong></p> 
<ol><li>硬盘拷贝到内核缓冲区(DMA COPY)；</li><li>内核缓冲区拷贝到socket缓冲区(CPU COPY)；</li><li>socket 缓冲区拷贝到网卡的buf(DMA COPY)。</li></ol> 
<p>可以看到,一次 read-send 模型中, 利用 sendFile 系统调用后, 可以将4次数据拷贝减少到3次, 4次上下文切换减少到2次, 2次 CPU 中断减少到1次。</p> 
<p>相对传统 I/O, 这种零拷贝技术通过减少两次上下文切换, 1次 CPU COPY, <span style="color:#4da8ee;">可以将I/O 性能提高50%以上(网络数据, 未亲测)</span>。</p> 
<p>开篇的概念中说到, 所谓的零拷贝的"零", 是指用户态和内核态之间的拷贝次数为0, 从这个定义上来说, 现在的这个零拷贝技术已经是真正的"零"了。</p> 
<p>然而, 对性能追求极致的伟大的科学家和工程师们并不满足于此，精益求精的他们对中间第2次的 CPU COPY 依旧耿耿于怀, 想尽千方百计要去掉这一次没有必要的数据拷贝和 CPU 中断。</p> 
<h4><strong>4、零拷贝的IO流程</strong></h4> 
<p>支持 scatter-gather 特性的 sendFile 的 IO 流程：</p> 
<p><strong>Linux在内核2.4</strong>以后的版本中, Linux 内核对 socket 缓冲区描述符做了优化。通过这次优化, sendFile 系统调用可以在只复制 kernel buffer 的少量元信息的基础上,<span style="background-color:#4da8ee;"> 把数据直接从 kernel buffer 复制到网卡的 buffer 中去</span>，从而避免了从"内核缓冲区"拷贝到"socket缓冲区"的这一次拷贝。</p> 
<p>这个优化后的 sendFile, 我们称之为<strong>支持 scatter-gather 特性的 sendFile。</strong></p> 
<p>在支持 scatter-gather 特性的 sendFile 的支撑下, 我们的 read-send 模型可以优化为:</p> 
<ol><li>应用程序开始读文件的操作；</li><li>应用程序发起系统调用, 从用户态进入到内核态(<span style="background-color:#4da8ee;">第一次上下文切换</span>)；</li><li>内核态中把数据从硬盘文件<span style="color:#4da8ee;">读取</span>到内核中间缓冲区；</li><li>内核态中把数据在<span style="color:#4da8ee;">内核缓冲区的位置(offset)和数据大小(size)两个信息</span>追加(append)到socket的缓冲区中去；</li><li>网卡的buf上根据socekt缓冲区的offset和size从内核缓冲区中<span style="background-color:#4da8ee;">直接拷贝</span>数据；</li><li>从内核态返回到用户态(<span style="color:#4da8ee;">第二次上下文切换</span>)；</li></ol> 
<p><strong>这个过程如下图所示:</strong></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/59/95/iBZV4PUp_o.png"></p> 
<p>最后数据拷贝变成只有两次 <strong>DMA COPY:</strong></p> 
<ol><li>硬盘拷贝到内核缓冲区(DMA COPY)；</li><li>内核缓冲区拷贝到网卡的 buf(DMA COPY)。</li></ol> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f6ba0d541f483d9017aeec8ea513be1e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue中的：__ob__: Observer无法取出数据</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bc4a3fe1b34f1b0fece8909794ca692b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">人工智能——CIFAR10 图像识别问题的卷积神经网络实践</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>