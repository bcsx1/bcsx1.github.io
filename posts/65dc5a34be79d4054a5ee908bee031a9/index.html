<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>双三次插值图像旋转_halcon之图像拼接技术 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="双三次插值图像旋转_halcon之图像拼接技术" />
<meta property="og:description" content="图像拼接技术就是针对同一场景的一系列图片，根据图片的特征，比如位置，重叠部分等，拼接成一张大幅的宽视角的图像。图像拼接要求拼接后图像最大程度的与原图一致，失真尽可能的小，并且要尽量做到天衣无缝即没有明显的拼接线或其他拼接痕迹。 为达到以上目标，图像拼接要求具备以下条件：
1：图像应具有一定的特征性能，拼接正是通过这些特征来进行的。
2：图像需要具有重叠部分，一般情况下，这些重叠部分点图像的1/4以上较为合理。
3、图像的背景亮度差异不能太大，应该低于10个灰度值，否则难以拼接成功。
4、图像的方位差异不能太大，图像应该来源同一方位。
5、拼合边界过渡应平滑，以消除接拼痕迹
图像拼接前，根据图像情况，可以进行图像预处理，主要是对图像进行校正和噪声滤波
1、校正
根据图像失真原因，建立相应的校正模型，从失真的图像中提取所需要的信息。从图像失真的逆过程来恢复图像。这个过程也可以理解为设计一个滤波器，使用其能从失真图像中计算得到真实图像的估值，从而最大程度的恢复真实图像。
2、噪声滤波
噪声在图像上分布主要有两种型式：
1、位置随机，幅值基本相同，一般称之为 椒盐噪声；
2、幅值随机，但基本上每个点都存在，从幅值的分布统计来看，主要有高斯型，瑞利型，又有如频谱均匀的噪声。
对于这些噪声，处理方法有如下几种：
1、均值滤波
就是用均值替代原图像中的各个像素。具体方法是：对将处理的像素，选择一个模板，此模板为其邻近的若干像素组成，用模板中的像素的均值去替代原来的像素值 。
2、中值滤波
中值滤波是一种非线性平滑技术，它将每一像素点的灰度值设置为该点某邻域窗口内的所有像素点灰度值的中值.
中值滤波是基于排序统计理论的一种能有效抑制噪声的非线性信号处理技术，中值滤波的基本原理是把数字图像或数字序列中一点的值用该点的一个邻域中各点值的中值代替，让周围的像素值接近的真实值，从而消除孤立的噪声点。方法是用某种结构的二维滑动模板，将板内像素按照像素值的大小进行排序，生成单调上升(或下降)的为二维数据序列。二维中值滤波输出为g(x,y)=med{f(x-k,y-l),(k,l∈W)} ，其中，f(x,y)，g(x,y)分别为原始图像和处理后图像。W为二维模板，通常为3*3，5*5区域，也可以是不同的的形状，如线状，圆形，十字形，圆环形等。
图像配比：
包含以下几个要素
1、选定特征空间
特征空间是由不参与匹配的图像特征构成。特征可以为图像的灰度特征，也可以是边界，轮廓，显著特征(如角点，线交叉点，高曲率点)，统计特征(如矩不变量，中心)，高层结构描述与句法描述等；这里其实是定义了配准的空间范围。
2、相似度
评估待匹配特征之间的相似性，它通常定义为某种代价函数或者是距离函数。这里定义为需要选定的某种算法。
3、搜索空间
待估计参数组成的空间就称为搜索空间，也就是说，搜索空间是指所有可能的变换组成的空间。这其实就定义了搜索算法的空间复杂度
4、搜索策略
用合适的方法在搜索空间中找出平移，旋转等变换参数的最佳估计，使得相似度达到最大值，这其实也就是定义了搜索算法的时间复杂度。
拼接方法：
1、基于区域的配准方法
采用拼接图像的灰度值检测，对待配准图你中一块区域与参考图像中的相机尺寸的区域使用最小二乘法或者其它数学方法计算其灰度值的差异，对此差异比较后来判断待拼接图像重叠区域的相似度，由此得到待拼接图像重叠区域的范围和位置，从而实现图像拼接。也可以通过FFT变换将图像由时域变换到频域，然后再进行配准。对位移量比较大的图像，可以先校正图像的旋转，然后建立两幅图像之间的映射关系，总而言之，这种方法有很多不足，已经不是主流了。
2、基于特征的配准方法
基于特征的图像配准方法有很多形式及其改进方式，其总体特点是：不直接利用图像的像素，而是通过像素值导出图像内容最抽像的描述和符号特征，并用此特征为匹配模板，通过二维高斯模糊过滤，把几幅待配准图像的灰度局总最大值，边界边缘轮廓，边缘点，边缘线段，组织(纹理)结构，角、项点，拐点，交叉点，封闭曲线低级对应特征点及利用特征图像关系图等高级特征，构造方程组，通过数值计算得到变换数来进行图像对齐，进而确定两者的匹配位置，实现特征点，特征线等拼接，并且可以提高运算速度。
基于特征的接拼方法，分为四个步骤
1、特征检测：从图像中检测出显著且独特的图像特征，诸如：闭合区域，直线段，边缘，轮廓，点等。
2、特征匹配：从相似度确定图像之间特征的对应关系，又分为如下几类：
2.1：使用空域关系的方法
2.2：使用不变描述符的方法
2.3:松弛方法
2.4:金字塔和小波方法
3、变换模型的估计：变换函数选择和函数参数估计
4、图像变换和重采样：可以通过前向或后向的方式来实现，插值的方法有最近邻插值、双线性插值、双三次函数插值、二次样条插值、三次B样条插值、高阶B样条插值。
基于特征的方法普遍适用于局部结构信息更显著的情况，能够处理图像之间复杂变形的情况，不足之处是特征检测困难且不稳定，最关键的一点是需要有一种判断力很强的、鲁棒性能好的且对图像之间变化保持不变的特征匹配算法。
下面是Halcon自带例程，如何拼接图像
**此例程讲解了如何将几张局部的PCB图像拼接居一张大的马赛克PCB图像。**此例程使用算子proj_match_points_ransac和算子 gen_projective_masaic完成上述工作。**请注意：这个PCB图像有一几处看起来像拼接逢合线的破损点，为了更好的区分真正的缝合线，例程呈现逢合线。dev_update_off ()dev_close_window ()dev_open_window (0, 0, 640, 480, &#39;white&#39;, WindowHandle)dev_set_color (&#39;green&#39;)set_display_font (WindowHandle, 14, &#39;mono&#39;, &#39;true&#39;, &#39;false&#39;)**一张一张的读取图像。gen_empty_obj (Images)for J := 1 to 6 by 1 read_image (Image, &#39;mosaic/pcb_&#39; &#43; J$&#39;02&#39;) concat_obj (Images, Image, Images) dev_display (Image) disp_message (WindowHandle, &#39;Image &#39; &#43; J$&#39;d&#39;, &#39;image&#39;, -1, -1, &#39;black&#39;, &#39;true&#39;) wait_seconds (1)endfordisp_continue_message (WindowHandle, &#39;black&#39;, &#39;true&#39;)stop ()* To show the point matches that are used to compute the projective* transformation between the images, we will show all images in a large* tiled image with some space between the images so that the extents* of the images are easily visible." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/65dc5a34be79d4054a5ee908bee031a9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-12-05T13:38:54+08:00" />
<meta property="article:modified_time" content="2020-12-05T13:38:54+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">双三次插值图像旋转_halcon之图像拼接技术</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div class="._5ce-wx-style" style="font-size:16px;"> 
 <div class="rich_media_content" id="js_content">
   图像拼接技术就是针对同一场景的一系列图片，根据图片的特征，比如位置，重叠部分等，拼接成一张大幅的宽视角的图像。图像拼接要求拼接后图像最大程度的与原图一致，失真尽可能的小，并且要尽量做到天衣无缝即没有明显的拼接线或其他拼接痕迹。 
  <p>为达到以上目标，图像拼接要求具备以下条件：</p> 
  <p>1：图像应具有一定的特征性能，拼接正是通过这些特征来进行的。</p> 
  <p>2：图像需要具有重叠部分，一般情况下，这些重叠部分点图像的1/4以上较为合理。</p> 
  <p>3、图像的背景亮度差异不能太大，应该低于10个灰度值，否则难以拼接成功。</p> 
  <p>4、图像的方位差异不能太大，图像应该来源同一方位。</p> 
  <p>5、拼合边界过渡应平滑，以消除接拼痕迹</p> 
  <p>图像拼接前，根据图像情况，可以进行图像预处理，主要是对图像进行校正和噪声滤波</p> 
  <p>1、校正</p> 
  <p>根据图像失真原因，建立相应的校正模型，从失真的图像中提取所需要的信息。从图像失真的逆过程来恢复图像。这个过程也可以理解为设计一个滤波器，使用其能从失真图像中计算得到真实图像的估值，从而最大程度的恢复真实图像。</p> 
  <p>2、噪声滤波</p> 
  <p>  噪声在图像上分布主要有两种型式：</p> 
  <p>1、位置随机，幅值基本相同，一般称之为 椒盐噪声；</p> 
  <p>2、幅值随机，但基本上每个点都存在，从幅值的分布统计来看，主要有高斯型，瑞利型，又有如频谱均匀的噪声。</p> 
  <p>对于这些噪声，处理方法有如下几种：</p> 
  <p>1、均值滤波</p> 
  <p>      就是用均值替代原图像中的各个像素。具体方法是：对将处理的像素，选择一个模板，此模板为其邻近的若干像素组成，用模板中的像素的均值去替代原来的像素值 。</p> 
  <p>2、中值滤波</p> 
  <p>      中值滤波是一种非线性平滑技术，它将每一像素点的灰度值设置为该点某邻域窗口内的所有像素点灰度值的中值.<br>      中值滤波是基于排序统计理论的一种能有效抑制噪声的非线性信号处理技术，中值滤波的基本原理是把数字图像或数字序列中一点的值用该点的一个邻域中各点值的中值代替，让周围的像素值接近的真实值，从而消除孤立的噪声点。方法是用某种结构的二维滑动模板，将板内像素按照像素值的大小进行排序，生成单调上升(或下降)的为二维数据序列。二维中值滤波输出为g(x,y)=med{f(x-k,y-l),(k,l∈W)} ，其中，f(x,y)，g(x,y)分别为原始图像和处理后图像。W为二维模板，通常为3*3，5*5区域，也可以是不同的的形状，如线状，圆形，十字形，圆环形等。</p> 
  <p><strong> 图像配比：</strong></p> 
  <p>    包含以下几个要素</p> 
  <p>1、选定特征空间</p> 
  <p>      特征空间是由不参与匹配的图像特征构成。特征可以为图像的灰度特征，也可以是边界，轮廓，显著特征(如角点，线交叉点，高曲率点)，统计特征(如矩不变量，中心)，高层结构描述与句法描述等；这里其实是定义了配准的空间范围。</p> 
  <p>2、相似度</p> 
  <p>     评估待匹配特征之间的相似性，它通常定义为某种代价函数或者是距离函数。这里定义为需要选定的某种算法。</p> 
  <p>3、搜索空间</p> 
  <p>      待估计参数组成的空间就称为搜索空间，也就是说，搜索空间是指所有可能的变换组成的空间。这其实就定义了搜索算法的空间复杂度</p> 
  <p>4、搜索策略</p> 
  <p>     用合适的方法在搜索空间中找出平移，旋转等变换参数的最佳估计，使得相似度达到最大值，这其实也就是定义了搜索算法的时间复杂度。</p> 
  <p>拼接方法：</p> 
  <p>1、基于区域的配准方法</p> 
  <p>     采用拼接图像的灰度值检测，对待配准图你中一块区域与参考图像中的相机尺寸的区域使用最小二乘法或者其它数学方法计算其灰度值的差异，对此差异比较后来判断待拼接图像重叠区域的相似度，由此得到待拼接图像重叠区域的范围和位置，从而实现图像拼接。也可以通过FFT变换将图像由时域变换到频域，然后再进行配准。对位移量比较大的图像，可以先校正图像的旋转，然后建立两幅图像之间的映射关系，总而言之，这种方法有很多不足，已经不是主流了。</p> 
  <p>2、基于特征的配准方法</p> 
  <p>     基于特征的图像配准方法有很多形式及其改进方式，其总体特点是：不直接利用图像的像素，而是通过像素值导出图像内容最抽像的描述和符号特征，并用此特征为匹配模板，通过二维高斯模糊过滤，把几幅待配准图像的灰度局总最大值，边界边缘轮廓，边缘点，边缘线段，组织(纹理)结构，角、项点，拐点，交叉点，封闭曲线低级对应特征点及利用特征图像关系图等高级特征，构造方程组，通过数值计算得到变换数来进行图像对齐，进而确定两者的匹配位置，实现特征点，特征线等拼接，并且可以提高运算速度。</p> 
  <p><strong>基于特征的接拼方法，分为四个步骤</strong></p> 
  <p>1、特征检测：从图像中检测出显著且独特的图像特征，诸如：闭合区域，直线段，边缘，轮廓，点等。</p> 
  <p>2、特征匹配：从相似度确定图像之间特征的对应关系，又分为如下几类：</p> 
  <p>     2.1：使用空域关系的方法</p> 
  <p>     2.2：使用不变描述符的方法</p> 
  <p>     2.3:松弛方法</p> 
  <p>     2.4:金字塔和小波方法</p> 
  <p>3、变换模型的估计：变换函数选择和函数参数估计</p> 
  <p>4、图像变换和重采样：可以通过前向或后向的方式来实现，插值的方法有最近邻插值、双线性插值、双三次函数插值、二次样条插值、三次B样条插值、高阶B样条插值。</p> 
  <p>基于特征的方法普遍适用于局部结构信息更显著的情况，能够处理图像之间复杂变形的情况，不足之处是特征检测困难且不稳定，最关键的一点是需要有一种判断力很强的、鲁棒性能好的且对图像之间变化保持不变的特征匹配算法。</p> 
  <p> 下面是Halcon自带例程，如何拼接图像</p> 
  <pre class="has"><code>**此例程讲解了如何将几张局部的PCB图像拼接居一张大的马赛克PCB图像。**此例程使用算子proj_match_points_ransac和算子 gen_projective_masaic完成上述工作。**请注意：这个PCB图像有一几处看起来像拼接逢合线的破损点，为了更好的区分真正的缝合线，例程呈现逢合线。dev_update_off ()dev_close_window ()dev_open_window (0, 0, 640, 480, 'white', WindowHandle)dev_set_color ('green')set_display_font (WindowHandle, 14, 'mono', 'true', 'false')**一张一张的读取图像。gen_empty_obj (Images)for J := 1 to 6 by 1    read_image (Image, 'mosaic/pcb_' + J$'02')    concat_obj (Images, Image, Images)    dev_display (Image)    disp_message (WindowHandle, 'Image ' + J$'d', 'image', -1, -1, 'black', 'true')    wait_seconds (1)endfordisp_continue_message (WindowHandle, 'black', 'true')stop ()* To show the point matches that are used to compute the projective* transformation between the images, we will show all images in a large* tiled image with some space between the images so that the extents* of the images are easily visible.dev_set_window_extents (-1, -1, 640 / 4, 2980 / 4)tile_images_offset (Images, TiledImage, [0,500,1000,1500,2000,2500], [0,0,0,0,0,0], [-1,-1,-1,-1,-1,-1], [-1,-1,-1,-1,-1,-1], [-1,-1,-1,-1,-1,-1], [-1,-1,-1,-1,-1,-1], 640, 2980)dev_clear_window ()dev_display (TiledImage)disp_message (WindowHandle, 'All 6 images', 'window', 12, 12, 'black', 'true')disp_message (WindowHandle, 'Click \'Run\'\nto continue', 'window', 2980 / 4 - 50, 12, 'black', 'true')stop ()* Now we compute point matches between the five pairs of images and with this* the projective transformation between the image pairs.  Note that the code* below calls the point operator for each image pair.  Since the images form* a strip, with a little book keeping we could make the process a little more* efficient by saving the points from the last iteration (ImageT in pair J will* be identical to ImageF in pair J+1).  This is not done here because such an* optimization would be quite cumbersome in the general case where the images* can lie in a general configuration that cannot be represented by a strip.dev_clear_window ()dev_display (TiledImage)disp_message (WindowHandle, 'Point matches', 'window', 12, 3, 'black', 'true')* We define the image pairs, i.e., which image should be mapped to which image.From := [1,2,3,4,5]To := [2,3,4,5,6]Num := |From|* We need a variable to accumulate the projective transformation matrices.ProjMatrices := []* Furthermore, since we want to create a rigid mosaic below we need to* accumulate all the point correspondences and the number of matches per* image pair.Rows1 := []Cols1 := []Rows2 := []Cols2 := []NumMatches := []* Now we can determine the transformations between the five image pairs.for J := 0 to Num - 1 by 1    F := From[J]    T := To[J]    select_obj (Images, ImageF, F)    select_obj (Images, ImageT, T)    * Extract the points in both images.    points_foerstner (ImageF, 1, 2, 3, 200, 0.3, 'gauss', 'false', RowJunctionsF, ColJunctionsF, CoRRJunctionsF, CoRCJunctionsF, CoCCJunctionsF, RowAreaF, ColAreaF, CoRRAreaF, CoRCAreaF, CoCCAreaF)    points_foerstner (ImageT, 1, 2, 3, 200, 0.3, 'gauss', 'false', RowJunctionsT, ColJunctionsT, CoRRJunctionsT, CoRCJunctionsT, CoCCJunctionsT, RowAreaT, ColAreaT, CoRRAreaT, CoRCAreaT, CoCCAreaT)    * Determine the point matches and the transformation for the current    * image pair.    proj_match_points_ransac (ImageF, ImageT, RowJunctionsF, ColJunctionsF, RowJunctionsT, ColJunctionsT, 'ncc', 21, 0, 0, 480, 640, 0, 0.5, 'gold_standard', 1, 4364537, ProjMatrix, Points1, Points2)    * Accumulate the transformation matrix.    ProjMatrices := [ProjMatrices,ProjMatrix]    * Accumulate the point matches and number of point matches.    Rows1 := [Rows1,subset(RowJunctionsF,Points1)]    Cols1 := [Cols1,subset(ColJunctionsF,Points1)]    Rows2 := [Rows2,subset(RowJunctionsT,Points2)]    Cols2 := [Cols2,subset(ColJunctionsT,Points2)]    NumMatches := [NumMatches,|Points1|]    * Generate crosses that represent the extracted points in the tiled image.    * Note that we have to take the row offsets of the images in the tiled image    * into account.    gen_cross_contour_xld (PointsF, RowJunctionsF + (F - 1) * 500, ColJunctionsF, 6, rad(45))    gen_cross_contour_xld (PointsT, RowJunctionsT + (T - 1) * 500, ColJunctionsT, 6, rad(45))    * Generate a representation of the matched point pairs as lines.  We create    * XLD contours from the lines so that we can zoom into the graphics window    * to take a closer look at the matches.    RowF := subset(RowJunctionsF,Points1) + (F - 1) * 500    ColF := subset(ColJunctionsF,Points1)    RowT := subset(RowJunctionsT,Points2) + (T - 1) * 500    ColT := subset(ColJunctionsT,Points2)    gen_empty_obj (Matches)    for K := 0 to |RowF| - 1 by 1        gen_contour_polygon_xld (Match, [RowF[K],RowT[K]], [ColF[K],ColT[K]])        concat_obj (Matches, Match, Matches)    endfor    * Now display the extracted data.    dev_set_color ('blue')    dev_display (Matches)    dev_set_color ('green')    dev_display (PointsF)    dev_display (PointsT)endfordisp_message (WindowHandle, 'Click \'Run\'\nto continue', 'window', 2980 / 4 - 50, 12, 'black', 'true')stop ()* Finally, we can generate the mosaic image from the projective transformations.gen_projective_mosaic (Images, MosaicImage, 2, From, To, ProjMatrices, 'default', 'false', MosaicMatrices2D)get_image_size (MosaicImage, Width, Height)dev_set_window_extents (-1, -1, Width / 3, Height / 3)dev_clear_window ()dev_display (MosaicImage)disp_message (WindowHandle, 'Projective mosaic', 'window', 12, 12, 'black', 'true')disp_message (WindowHandle, 'Click \'Run\'\nto continue', 'window', Height / 3 - 50, 12, 'black', 'true')stop ()* To show more clearly that the folds visible in the image do not result from the* mosaicking, we display the seams between the images in the mosaic image.* This can be done most easily by creating an image that contains the border* of the images, generating a mosaic from it, and segmenting the resulting* mosaic image.get_image_size (Image, Width, Height)gen_image_const (ImageBlank, 'byte', Width, Height)gen_rectangle1 (Rectangle, 0, 0, Height - 1, Width - 1)paint_region (Rectangle, ImageBlank, ImageBorder, 255, 'margin')gen_empty_obj (ImagesBorder)for J := 1 to 6 by 1    concat_obj (ImagesBorder, ImageBorder, ImagesBorder)endforgen_projective_mosaic (ImagesBorder, MosaicImageBorder, 2, From, To, ProjMatrices, 'default', 'false', MosaicMatrices2D)threshold (MosaicImageBorder, Seams, 128, 255)dev_clear_window ()dev_display (MosaicImage)disp_message (WindowHandle, 'Seams between the\nimages', 'window', 12, 12, 'black', 'true')dev_set_color ('yellow')dev_display (Seams)disp_message (WindowHandle, 'Click \'Run\'\nto continue', 'window', 550, 12, 'black', 'true')stop ()* If you look very closely at the projective mosaic above, you may note that* there is a very slight projective distortion in the mosaic.  This happens* because the transformations cannot be determined with perfect accuracy* because of very small errors in the point coordinates due to noise.  Because* of the strip configuration, essentially the overlapping area between the image* pairs can act like a hinge around which the images may rotate out of the image* plane.  In this example, we know that the mapping between the images must* be a rigid transformation.  If we want to force the transformation to be rigid* we can simply use bundle_adjust_mosaic.bundle_adjust_mosaic (6, 1, From, To, ProjMatrices, Rows1, Cols1, Rows2, Cols2, NumMatches, 'rigid', MosaicMatrices2D, Rows, Cols, Error)* Now, we can generate the mosaic image from the rigid transformations.gen_bundle_adjusted_mosaic (Images, MosaicImageRigid, MosaicMatrices2D, 'default', 'false', TransMatrix2D)get_image_size (MosaicImageRigid, Width, Height)dev_set_window_extents (-1, -1, Width / 3, Height / 3)dev_clear_window ()dev_display (MosaicImageRigid)disp_message (WindowHandle, 'Rigid mosaic', 'window', 12, 12, 'black', 'true')</code></pre> 
  <p><img src="https://images2.imgbox.com/3a/6d/lqPsWuVd_o.png" alt="e09142134dce792ae5a339d161b41351.png"><img src="https://images2.imgbox.com/75/92/kiR88Cv7_o.png" alt="623bc409b92bad7edce0267bd80504c4.png"></p> 
  <p><img src="https://images2.imgbox.com/5f/ef/WFizFPnM_o.png" alt="6772c82387522a8504271eb279a4336b.png"></p> 
  <p> <img src="https://images2.imgbox.com/99/6f/OTyvWtPM_o.png" alt="dcb84e06c9aea4b118cb3d2800178260.png"></p> 
  <p><img src="https://images2.imgbox.com/45/1b/otq14mFn_o.png" alt="2cf0a2a80ffd2eb189302caf8c2264e0.png"></p> 
  <p><img src="https://images2.imgbox.com/4b/cc/buUpvPDD_o.png" alt="f07afc84db37d1c2fca5e97cd6394d92.png"></p> 
  <p> 带逢合线的图像                    找定位点</p> 
  <p> <img src="https://images2.imgbox.com/f8/a0/cqhOKtsf_o.png" alt="47d6e02284d306b089249985d710b054.png"><img src="https://images2.imgbox.com/a6/c5/R08X0I2u_o.png" alt="e43b44f5b58485c40e05299cc50c29dd.png"></p> 
  <p> 最终图像：</p> 
  <p> <img src="https://images2.imgbox.com/c3/0f/iHwopkdF_o.png" alt="329603bc71267b7cb66af65365845241.png"></p> 
  <p>下面我们看一下另一个例程：</p> 
  <p>这个例程使用proj_match_points_ransac_guided 和 gen_projective_mosaic</p> 
  <p>主要介绍如何使用金字塔算法快速获取两个图像的特征点进行拼接。</p> 
  <pre class="has"><code>* This example program shows how images can be combined* into a mosaic image using proj_match_points_ransac_guided* and gen_projective_mosaic.* It is shown how the calculation of the projection between two* images can be accelerated using an image pyramid.** InitializationsImgPath := '3d_machine_vision/mosaic/'ImgName := 'bga_r_'Times := []Colors := ['red','coral','yellow','lime green']read_image (Images, ImgPath + ImgName + ['01','06'])dev_update_off ()dev_close_window ()dev_open_window_fit_size (0, 0, 640, 980, 320, 490, WindowHandle)dev_open_window_fit_size (0, 330, 490, 490, 1000, 490, WindowHandle1)set_display_font (WindowHandle, 14, 'mono', 'true', 'false')set_display_font (WindowHandle1, 14, 'mono', 'true', 'false')* The internal camera parameters of the used camera* (necessary to eliminate radial distortions)CamParam := [0.0121693,-2675.63,7.40046e-006,7.4e-006,290.491,258.887,640,480]change_radial_distortion_cam_par ('adaptive', CamParam, 0, CamParOut)change_radial_distortion_image (Images, Images, Images, CamParam, CamParOut)* To show the point matches that are used to compute the* transformation between the images, we will show both images in a* tiled image with some space between the images so that the extents* of the images are easily visible.tile_images_offset (Images, TiledImage, [0,500], [0,0], [-1,-1], [-1,-1], [-1,-1], [-1,-1], 640, 980)** Now we can determine the transformations between the image pairs.From := 1To := 2select_obj (Images, ImageF, From)select_obj (Images, ImageT, To)** Repeat the calculation 4 times with a different number of pyramid levelsfor NumLevels := 1 to 4 by 1    *    dev_clear_window ()    dev_set_window (WindowHandle)    dev_clear_window ()    dev_display (TiledImage)    disp_message (WindowHandle, ['Calculate point matches','with ' + NumLevels + ' pyramid levels','Please wait ...'], 'window', 20, 10, 'black', 'true')    *    * Calculate the projection between the two images    * Check the procedure's comments for details    count_seconds (S1)    proj_match_points_ransac_pyramid (ImageF, ImageT, NumLevels, RowFAll, ColFAll, RowTAll, ColTAll, ProjMatrix, Points1, Points2)    count_seconds (S2)    Times := [Times,S2 - S1]    *    * Display point correspondences    gen_cross_contour_xld (PointsF, RowFAll, ColFAll, 6, rad(45))    gen_cross_contour_xld (PointsT, RowTAll + 500, ColTAll, 6, rad(45))    RowF := subset(RowFAll,Points1)    ColF := subset(ColFAll,Points1)    RowT := subset(RowTAll,Points2) + 500    ColT := subset(ColTAll,Points2)    gen_empty_obj (Matches)    for K := 0 to |RowF| - 1 by 1        gen_contour_polygon_xld (Match, [RowF[K],RowT[K]], [ColF[K],ColT[K]])        concat_obj (Matches, Match, Matches)    endfor    dev_display (TiledImage)    dev_set_color ('blue')    dev_display (Matches)    dev_set_color ('green')    dev_display (PointsF)    dev_display (PointsT)    disp_message (WindowHandle, [|RowF| + ' point matches','Time used: ' + (S2 - S1)$'.3' + ' s'], 'window', 20, 10, 'black', 'true')    *    * Generate the mosaic image    gen_projective_mosaic (Images, MosaicImage, 1, From, To, ProjMatrix, [2,1], 'false', MosaicMatrices2D)    *    * Display mosaic image    get_image_size (MosaicImage, Width, Height)    dev_set_window (WindowHandle1)    dev_resize_window_fit_image (MosaicImage, 0, 330, [400,700], 700)    dev_clear_window ()    dev_display (MosaicImage)    disp_message (WindowHandle1, 'Projective mosaic (used ' + NumLevels + ' pyramid levels)', 'window', 20, 10, 'black', 'true')    disp_continue_message (WindowHandle1, 'black', 'true')    stop ()endfor** Display execution timesdev_set_window (WindowHandle)dev_close_window ()MaxTime := max(Times)BaseRow := 380RectHeight := 300disp_message (WindowHandle1, ['Time in s:','(#levels used)'], 'image', BaseRow + 20, 10, 'black', 'true')for Index := 0 to |Times| - 1 by 1    gen_rectangle1 (Rectangle, BaseRow - RectHeight * Times[Index] / MaxTime, 200 + Index * 100, BaseRow, 280 + Index * 100)    disp_message (WindowHandle1, [Times[Index]$'.3','(' + (Index + 1) + ')'], 'image', BaseRow + 20, 200 + 100 * Index, 'black', 'true')    dev_set_color (Colors[Index])    dev_set_draw ('fill')    dev_display (Rectangle)endfordisp_finished_message (WindowHandle1, 'black', 'true')</code></pre> 
  <p>来源：https://www.cnblogs.com/amosyang/p/8478213.html</p> 
  <p><strong><strong><strong><strong><strong><strong><strong><strong><img src="https://images2.imgbox.com/b2/04/hHbDmhZ7_o.gif" alt="76a041836d137e23fc9d2686c24c4cea.gif"></strong></strong></strong></strong></strong></strong></strong></strong><strong><strong><strong><strong><strong><strong><strong> <strong>End</strong><strong> </strong><strong><img src="https://images2.imgbox.com/77/13/etNHMyxK_o.gif" alt="76a041836d137e23fc9d2686c24c4cea.gif"></strong></strong></strong></strong></strong></strong></strong></strong></p> 
  <p>声明：部分内容来源于网络，仅供读者学习、交流之目的。文章版权归原作者所有。如有不妥，请联系删除。</p> 
 </div> 
</div>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/da463b8eebd9d1c9f048058a24978e8d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Factorization Machines 因子分解机FM</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/25d314d786b45961bf28bcb25d15a8e8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">003. kogito在spring cloud微服务项目上的应用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>