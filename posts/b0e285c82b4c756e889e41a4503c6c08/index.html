<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Jupyter Notebook与Pycharm代码连接Docker容器中的远程服务器运行 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Jupyter Notebook与Pycharm代码连接Docker容器中的远程服务器运行" />
<meta property="og:description" content="今天终于有幸让大师兄给我安排了实验室的显卡，之前我学习深度学习的一段时间都是在Google Colab中跑的，并且之前一直都用的是Tensorflow&#43;Keras框架，目前我刚学习完Pytorch，也寻思着再运行一下做过的图像分类和文本分类任务。本来用的是实验室分配的主机（笔记本带着太麻烦了，而且我笔记本用四年了，1050ti也不太行了），刚给新分配的主机装完CUDA&#43;Pytorch（Windows 10配置安装PyTorch框架：https://www.yuque.com/zbdbc/fd87kk/ring8l），但是由于主机显卡比较老（GTX 750），数据跑的太慢了，我也不想像以前那样把代码全都上传到Google硬盘用Goole分配的服务器跑（早晚都要用到实验室的显卡），既然实验室有高级的显卡，不早早地拿来白嫖就可惜了，哈哈哈！！！本篇文章分成三部分：MobaXterm 简单介绍与使用、Docker容器中安装Anaconda、CUDA与Pyorch、配置Pycharm以及Jupyter连接远程服务器。
1.MobaXterm 简单介绍与使用 首先大师兄给我分配好的容器格式是这样的：ssh @xxx.vmip.com.cn -p （&lt;&gt; 中的内容根据实际书写 ），然后还有密码密码。起初拿到手我一脸懵，这以前我见到的Linux服务器都是给出的IP地址&#43;密码，我刚开始不晓得该用哪个工具了（其实感觉当时我脑子进水了。。。。），我就在自己电脑打开cmd命令，尝试连了下，没想到还真给我连接上了。。。然后我突然就想到，以前连接Liunx服务器不都是用Xshell吗，然后我就很简单了，IP就是tt1.vmip.com.cn，选择SSH模式，端口号就是给我分配的端口，然后也连接上了。后来在查询如何配置Pycharm以及Jupyter连接远程服务器的过程中偶然接触到一个牛批的神器：MobaXterm！！！
为何说它牛批呐？去读这篇文章就知道了（含有下载地址）：https://mp.weixin.qq.com/s/p96kWPkPuJYeWxG3AqvnDQ，我总结下来就是Xshell能做到的，MobaXterm都能做到，做的还比Xshell更好，而且它的界面确实很舒适，最下方工具栏能够监视GPU和CPU的资源利用情况。同时可以直接将本地文件上传到服务器，或用本机编辑器直接编辑远程服务器端文件，不用再下载跟Xshell配套的Xftp。界面如下：
2.Docker容器安装Anaconda及Jupyter notebook远程连接服务器 俗话说，凡事踏出第一步很难，我准备看一下实验室的显卡是啥规格的，就想用nvidia-smi命令查看一下，结果发现没有这个命令，于是就依靠万能的百度，说需要装一下驱动。
我又确认一下我的容器环境是Ubuntu 20.04.3；对应实验室的显卡是：NVIDIA TiTan XP 显卡（12G），不过我看到一些文章说容器中是不需要额外安装驱动的，到这里我又是很懵。最后我自己理解是我这只是服务器中的一个容器，相当于服务器中的很小的一块地方，小家伙肯定没法查看巨兽内部的状态。在网上搜寻的Docker教程第一步都是在服务器中安装docker和创建基础容器创建容器等那些复杂的工作，大师兄已经帮我做好了，直接把创建好的容器交给了我，因此我只需要老老实实的安装一下Anaconda等就可以，没搞懂之前暂时先别安装驱动！等后面用到再说。。。。
还有个Bug就是刚分配的容器连Sudo命令都没有，一些sudo命令会报错：-bash: sudo: command not found，查看这篇文章：https://www.cnblogs.com/pengpengboshi/p/16159443.html。
另外遇到一个坑：有博客让我编辑配置文件时用 gedit命令，然而我Ubuntu系统是没有的，得去安装，结果一安装就是一个多小时（心态炸了），最后确实安装好了，不过还是不能用，看到别的博客说必须图形化界面才能用，最后我突然想到编辑文件还可以用vim命令。。（脑子不好使了）
安装Anaconda 具体Docker容器中Ubuntu下安装Anaconda如下：
1.首先去清华源下载想要的版本：https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/；我选择Anaconda3-5.3.1-Linux-x86_64.sh，听说最稳定。。。
2.安装。可以将之前下载的.sh文件通过MobaXterm终端从本机上传到容器中， 在文件下载的目录下打开终端，运行.sh文件： bash Anaconda3-5.3.1-Linux-x86_64.sh。 安装过程中会出现阅读条款，然后回车直到出现yes or no的选择，输入yes 回车继续安装。 一直回车，不要按太快，会出现可以修改安装路径，最后我的安装位置是/home/PythonTools/Anaconda/anaconda3/。
**3.设置Anaconda环境变量。**如果在安装Anaconda的过程中没有将安装路径添加到系统环境变量中，需要在安装后手工添加。
首先在终端输入：sudo vim /etc/profile ，打开profile文件。
然后在文件末尾添加一行：export PATH=&#34;/home/PythonTools/Anaconda/anaconda3/bin:$PATH&#34;。（将 “/home/PythonTools/Anaconda/anaconda3/” 替换为你实际的安装路径并保存。）
接着输入命令 source /etc/profile ，使/etc/profile文件修改后立即生效。
**4.重启Linux。**打开终端，输入conda --version，查看是否安装成功。可以在终端中输入 echo $PATH 查看已有的环境变量，确认输出里是否已有Anaconda路径了。
Jupyter Notebook连接远程服务器 启动Jupyter notebook时，遇到了Bug：OSError: [Errno 99] Cannot assign requested address。我认为是没有安装的缘故，于是就pip install一下（已经配置清华源）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/b0e285c82b4c756e889e41a4503c6c08/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-16T12:45:11+08:00" />
<meta property="article:modified_time" content="2022-09-16T12:45:11+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Jupyter Notebook与Pycharm代码连接Docker容器中的远程服务器运行</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>今天终于有幸让大师兄给我安排了实验室的显卡，之前我学习深度学习的一段时间都是在Google Colab中跑的，并且之前一直都用的是Tensorflow+Keras框架，目前我刚学习完Pytorch，也寻思着再运行一下做过的图像分类和文本分类任务。本来用的是实验室分配的主机（笔记本带着太麻烦了，而且我笔记本用四年了，1050ti也不太行了），刚给新分配的主机装完CUDA+Pytorch（Windows 10配置安装PyTorch框架：<a href="https://www.yuque.com/zbdbc/fd87kk/ring8l" rel="nofollow">https://www.yuque.com/zbdbc/fd87kk/ring8l</a>），但是由于主机显卡比较老（GTX 750），数据跑的太慢了，我也不想像以前那样把代码全都上传到Google硬盘用Goole分配的服务器跑（早晚都要用到实验室的显卡），既然实验室有高级的显卡，不早早地拿来白嫖就可惜了，哈哈哈！！！<strong>本篇文章分成三部分：MobaXterm 简单介绍与使用、Docker容器中安装Anaconda、CUDA与Pyorch、配置Pycharm以及Jupyter连接远程服务器。</strong></p> 
<h2><a id="1MobaXterm__2"></a>1.MobaXterm 简单介绍与使用</h2> 
<p>首先大师兄给我分配好的容器格式是这样的：ssh @xxx.vmip.com.cn -p （&lt;&gt; 中的内容根据实际书写 ），然后还有密码密码。起初拿到手我一脸懵，这以前我见到的Linux服务器都是给出的IP地址+密码，我刚开始不晓得该用哪个工具了（其实感觉当时我脑子进水了。。。。），我就在自己电脑打开cmd命令，尝试连了下，没想到还真给我连接上了。。。然后我突然就想到，以前连接Liunx服务器不都是用Xshell吗，然后我就很简单了，IP就是tt1.vmip.com.cn，选择SSH模式，端口号就是给我分配的端口，然后也连接上了。后来在查询如何配置Pycharm以及Jupyter连接远程服务器的过程中偶然接触到一个牛批的神器：<strong>MobaXterm！！！</strong><br>为何说它牛批呐？去读这篇文章就知道了（含有下载地址）：<a href="https://mp.weixin.qq.com/s/p96kWPkPuJYeWxG3AqvnDQ" rel="nofollow">https://mp.weixin.qq.com/s/p96kWPkPuJYeWxG3AqvnDQ</a>，我总结下来就是Xshell能做到的，MobaXterm都能做到，做的还比Xshell更好，而且它的界面确实很舒适，最下方工具栏能够监视GPU和CPU的资源利用情况。同时可以直接将本地文件上传到服务器，或用本机编辑器直接编辑远程服务器端文件，不用再下载跟Xshell配套的Xftp。界面如下：<br><br> <img src="https://images2.imgbox.com/53/62/ZadWNvIr_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="2DockerAnacondaJupyter_notebook_6"></a>2.Docker容器安装Anaconda及Jupyter notebook远程连接服务器</h2> 
<p>俗话说，凡事踏出第一步很难，我准备看一下实验室的显卡是啥规格的，就想用<strong>nvidia-smi</strong>命令查看一下，结果发现没有这个命令，于是就依靠万能的百度，说需要装一下驱动。<br>我又确认一下<strong>我的容器环境是Ubuntu 20.04.3；对应实验室的显卡是：NVIDIA TiTan XP 显卡（12G）</strong>，不过我看到一些文章说<strong>容器中是不需要额外安装驱动的</strong>，到这里我又是很懵。最后我自己理解是我这只是服务器中的一个容器，相当于服务器中的很小的一块地方，小家伙肯定没法查看巨兽内部的状态。在网上搜寻的Docker教程第一步都是在服务器中安装docker和创建基础容器创建容器等那些复杂的工作，大师兄已经帮我做好了，直接把创建好的容器交给了我，因此我只需要老老实实的安装一下Anaconda等就可以，<strong>没搞懂之前暂时先别安装驱动！等后面用到再说。。。。</strong><br>还有个Bug就是刚分配的容器连Sudo命令都没有，一些sudo命令会报错：-bash: sudo: command not found，查看这篇文章：<a href="https://www.cnblogs.com/pengpengboshi/p/16159443.html" rel="nofollow">https://www.cnblogs.com/pengpengboshi/p/16159443.html</a>。<br>另外遇到一个坑：有博客让我编辑配置文件时用 gedit命令，然而我Ubuntu系统是没有的，得去安装，结果一安装就是一个多小时（心态炸了），最后确实安装好了，不过还是不能用，看到别的博客说必须图形化界面才能用，最后我突然想到<strong>编辑文件还可以用vim命令</strong>。。（脑子不好使了）<br> </p> 
<h3><a id="Anaconda_9"></a>安装Anaconda</h3> 
<p><strong>具体</strong>Docker容器中<strong>Ubuntu下安装Anaconda如下：</strong><br><strong>1.首先去清华源下载想要的版本</strong>：<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" rel="nofollow">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/</a>；我选择Anaconda3-5.3.1-Linux-x86_64.sh，听说最稳定。。。<br><strong>2.安装。<strong>可以将之前下载的.sh文件通过MobaXterm终端从本机上传到容器中， 在文件下载的目录下打开终端，运行.sh文件： <code>bash Anaconda3-5.3.1-Linux-x86_64.sh</code>。 安装过程中会出现阅读条款，然后</strong>回车</strong>直到出现yes or no的选择，输入yes 回车继续安装。 一直回车，不要按太快，会出现可以修改安装路径，最后我的安装位置是<code>/home/PythonTools/Anaconda/anaconda3/</code>。<br>**3.设置Anaconda环境变量。**如果在安装Anaconda的过程中没有将安装路径添加到系统环境变量中，需要在安装后手工添加。<br>首先在终端输入：<code>sudo vim /etc/profile</code> ，打开profile文件。<br>然后在文件末尾添加一行：<code>export PATH="/home/PythonTools/Anaconda/anaconda3/bin:$PATH"</code>。（将 “/home/PythonTools/Anaconda/anaconda3/” 替换为你实际的安装路径并保存。）<br>接着输入命令 <code>source /etc/profile </code>，使/etc/profile文件修改后立即生效。<br>**4.重启Linux。**打开终端，输入conda --version，查看是否安装成功。可以在终端中输入<code> echo $PATH</code> 查看已有的环境变量，确认输出里是否已有Anaconda路径了。<br><br> <img src="https://images2.imgbox.com/b8/79/DFjpEz6S_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="Jupyter_Notebook_13"></a>Jupyter Notebook连接远程服务器</h3> 
<p>启动Jupyter notebook时，遇到了Bug：OSError: [Errno 99] Cannot assign requested address。我认为是没有安装的缘故，于是就pip install一下（已经配置清华源）<br><img src="https://images2.imgbox.com/ce/a5/uKuh8sMd_o.png" alt="在这里插入图片描述"><br> <br>pip install东西的时候，出现Could not fetch URL <a href="https://pypi.tuna.tsinghua.edu.cn/simple/pip/:" rel="nofollow">https://pypi.tuna.tsinghua.edu.cn/simple/pip/:</a> There was a problem confirming…的BUG，具体解决办法是在pip 命令后面都加上 <code>--trusted-host pypi.tuna.tsinghua.edu.cn </code>，如 <code>pip list --trusted-host pypi.tuna.tsinghua.edu.cn</code> 我都不明白我为啥会遇到这么奇葩的BUG，我本机安装的时候一切都很顺利。。。。一应用到容器举步维艰。。。。<br>最后终于可以安装了<code>pip install jupyter notebook --trusted-host pypi.tuna.tsinghua.edu.cn</code>。结果发现上述bug：OSError: [Errno 99] Cannot assign requested address<br>还是没有解决。。。经过一顿搜索之后终于解决了！！！参考：<a href="https://zhuanlan.zhihu.com/p/161221247" rel="nofollow">https://zhuanlan.zhihu.com/p/161221247</a><br><strong>其实我们是相当于在外网，直接访问jupyter notebook是访问不到的。所以必须用外网访问的方式才行。</strong><br>首先在服务器启动 jupyter notebook ，命令：<code>jupyter notebook --no-browser --allow-root --port=8889 --ip=127.0.0.1</code><br><img src="https://images2.imgbox.com/6c/f4/oaDsy4jS_o.png" alt="在这里插入图片描述"><br> <br>然后在本地转发端口，用win+R 打开cmd， 进入终端。输入命令：<code>ssh -N -f -L localhost:8888:localhost:8889 -p xxx（port） xxx(remote_user)@xxx(remote_ip)</code></p> 
<p>这里的port就是大师兄给分配的端口，user一般都是root，然后root_ip就是分配的主机地址<br><img src="https://images2.imgbox.com/06/0a/OiqW0UyS_o.png" alt="在这里插入图片描述"><br> <br>这里会需要你输入你的远程服务器用户的密码，输入成功后。在本地浏览器网址栏输入<a href="https://link.zhihu.com/?target=http%3A//127.0.0.1%3A8888" rel="nofollow">http://127.0.0.1:8888</a>，然后你就可以看到熟悉的jupyter-notebook界面了。<br><br>到目前为止，在通过jupyter notebook访问远程服务器已经完成。<br><br> <img src="https://images2.imgbox.com/54/7e/JnpG7kbX_o.png" alt="在这里插入图片描述"></p> 
<p></p> 
<h3><a id="_23"></a>创建并激活虚拟环境</h3> 
<p>大家最好养成良好的习惯，在虚拟环境中配置各种库和框架环境。在终端输入<code>conda create --name NAME python=3.7 </code>创建虚拟环境，其中NAME为你的虚拟环境名称，[最好名称中带有版本号以区分，如pytorch-gpu-1.2.0]。创建完后可以输入<code>conda info -e</code>查看所有虚拟环境。<br>输入<code>conda activate NAME</code>进入虚拟环境中，可以在在该环境中配置pytorch。这里<strong>使用 conda activate 激活虚拟环境时报错</strong>： CommandNotFoundError: Your shell has not been properly configured to use 'co…。<strong>解决办法： 首次激活 conda 虚拟环境，可用 source activate 激活（如下），以后就可以正常使用 conda activate 激活虚拟环境了 。</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># 首次使用 source activate 命令激活虚拟环境 my_conda_virutal_environment</span>
source activate my_conda_virutal_environment
<span class="token comment"># 退出虚拟环境</span>
conda deactivate
<span class="token comment"># 以后使用 conda activate 命令激活虚拟环境</span>
conda activate my_conda_virutal_environment

</code></pre> 
<p><img src="https://images2.imgbox.com/9a/b0/09wS2bYo_o.png" alt="在这里插入图片描述"><br> <br><strong>复制环境：</strong><code>conda create -n new_torch --clone torch</code>** 删除环境：**<code>conda remove -n torch --all</code>。<br>其实后面我的环境一直没配置好，气的我把虚拟环境给删除了，后面也是在用anaconda的base环境，唉…希望不会出事吧！！<br> </p> 
<h2><a id="DockerCUDACUDNNPyorch_37"></a>Docker容器中安装CUDA、CUDNN与Pyorch</h2> 
<p></p> 
<h3><a id="CUDA113_39"></a>安装CUDA11.3</h3> 
<p>**先查看自己容器的显卡型号。**可以去终端输入命令查看，输入命令：<strong>ubuntu-drivers devices</strong><br>![image.png](https://img-blog.csdnimg.cn/img_convert/dcae0daa5185223b21360be2c2d1897c.png#clientId=ue6616e71-304f-4&amp;crop=0&amp;crop=0&amp;crop=1&amp;<img src="https://images2.imgbox.com/45/16/0pnpWNlw_o.png" alt="在这里插入图片描述"><br> <br>可以看到显卡是TITAN Xp。到这里又看到一些博客说要安装驱动，不过我打算先直接下载CUDA，去官网（<a href="https://developer.nvidia.com/cuda-downloads" rel="nofollow">https://developer.nvidia.com/cuda-downloads</a>）选择cuda11.3版本，（听说会自动安装nvidia驱动）<br>![i<img src="https://images2.imgbox.com/be/eb/NSVcUbMb_o.png" alt="在这里插入图片描述"><br> <br>命令如下：</p> 
<pre><code class="prism language-python">wget https<span class="token punctuation">:</span><span class="token operator">//</span>developer<span class="token punctuation">.</span>download<span class="token punctuation">.</span>nvidia<span class="token punctuation">.</span>com<span class="token operator">/</span>compute<span class="token operator">/</span>cuda<span class="token operator">/</span>repos<span class="token operator">/</span>ubuntu2004<span class="token operator">/</span>x86_64<span class="token operator">/</span>cuda<span class="token operator">-</span>ubuntu2004<span class="token punctuation">.</span>pin
sudo mv cuda<span class="token operator">-</span>ubuntu2004<span class="token punctuation">.</span>pin <span class="token operator">/</span>etc<span class="token operator">/</span>apt<span class="token operator">/</span>preferences<span class="token punctuation">.</span>d<span class="token operator">/</span>cuda<span class="token operator">-</span>repository<span class="token operator">-</span>pin<span class="token operator">-</span><span class="token number">600</span>
wget https<span class="token punctuation">:</span><span class="token operator">//</span>developer<span class="token punctuation">.</span>download<span class="token punctuation">.</span>nvidia<span class="token punctuation">.</span>com<span class="token operator">/</span>compute<span class="token operator">/</span>cuda<span class="token operator">/</span><span class="token number">11.3</span><span class="token number">.0</span><span class="token operator">/</span>local_installers<span class="token operator">/</span>cuda<span class="token operator">-</span>repo<span class="token operator">-</span>ubuntu2004<span class="token operator">-</span><span class="token number">11</span><span class="token operator">-</span><span class="token number">3</span><span class="token operator">-</span>local_11<span class="token punctuation">.</span><span class="token number">3.0</span><span class="token operator">-</span><span class="token number">465.19</span><span class="token number">.01</span><span class="token operator">-</span>1_amd64<span class="token punctuation">.</span>deb
sudo dpkg <span class="token operator">-</span>i cuda<span class="token operator">-</span>repo<span class="token operator">-</span>ubuntu2004<span class="token operator">-</span><span class="token number">11</span><span class="token operator">-</span><span class="token number">3</span><span class="token operator">-</span>local_11<span class="token punctuation">.</span><span class="token number">3.0</span><span class="token operator">-</span><span class="token number">465.19</span><span class="token number">.01</span><span class="token operator">-</span>1_amd64<span class="token punctuation">.</span>deb
sudo apt<span class="token operator">-</span>key add <span class="token operator">/</span>var<span class="token operator">/</span>cuda<span class="token operator">-</span>repo<span class="token operator">-</span>ubuntu2004<span class="token operator">-</span><span class="token number">11</span><span class="token operator">-</span><span class="token number">3</span><span class="token operator">-</span>local<span class="token operator">/</span>7fa2af80<span class="token punctuation">.</span>pub
sudo apt<span class="token operator">-</span>get update
sudo apt<span class="token operator">-</span>get <span class="token operator">-</span>y install cuda
</code></pre> 
<p>执行sudo apt-get -y install cuda时遇到的BUG：W: GPG error: file:/var/cuda-repo-ubuntu2004-11-3-local Release: The following signatures couldn’t be verified because the public key is not available: NO_PUBKEY F60F4B3D7FA2AF80<br><img src="https://images2.imgbox.com/98/26/vBsHzJqB_o.png" alt="在这里插入图片描述"><br> <br>解决命令：sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys F60F4B3D7FA2AF80<br><br> 又报错：gnupg,gnupg2 and gnupg1 do not seem to be installed,but one of them is required for this operation<br>解决命令：sudo apt-get install gnupg<br>再一遍运行上面的。就可以运行完了。然后修改环境变量，运行<code>vim ~/.bashrc</code>；最下面加入</p> 
<pre><code class="prism language-python">export PATH<span class="token operator">=</span><span class="token operator">/</span>usr<span class="token operator">/</span>local<span class="token operator">/</span>cuda<span class="token operator">-</span><span class="token number">11.3</span><span class="token operator">/</span><span class="token builtin">bin</span>$<span class="token punctuation">{<!-- --></span>PATH<span class="token punctuation">:</span><span class="token operator">+</span><span class="token punctuation">:</span>$<span class="token punctuation">{<!-- --></span>PATH<span class="token punctuation">}</span><span class="token punctuation">}</span>
export LD_LIBRARY_PATH<span class="token operator">=</span><span class="token operator">/</span>usr<span class="token operator">/</span>local<span class="token operator">/</span>cuda<span class="token operator">-</span><span class="token number">11.3</span><span class="token operator">/</span>lib64$<span class="token punctuation">{<!-- --></span>LD_LIBRARY_PATH<span class="token punctuation">:</span><span class="token operator">+</span><span class="token punctuation">:</span>$<span class="token punctuation">{<!-- --></span>LD_LIBRARY_PATH<span class="token punctuation">}</span><span class="token punctuation">}</span>
export CUDA_HOME<span class="token operator">=</span><span class="token operator">/</span>usr<span class="token operator">/</span>local<span class="token operator">/</span>cuda<span class="token operator">-</span><span class="token number">11.3</span><span class="token punctuation">:</span><span class="token operator">/</span>usr<span class="token operator">/</span>local<span class="token operator">/</span>cuda
</code></pre> 
<p>保存并更新：<code>source ~/.bashrc</code>。最终终于安装好了！！！！<br><img src="https://images2.imgbox.com/c6/f4/Wmb09S5R_o.png" alt="在这里插入图片描述"></p> 
<p></p> 
<h3><a id="GPUPytorch_63"></a>安装GPU版本的Pytorch</h3> 
<p>回到终端，执行下面两行命令。<br><code>conda create -n pytorch-gpu python=3.7.0</code><br><code>conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch -n pytorch-gpu</code><br>第一个命令是创建虚拟环境，第二行命令就是安装cuda11.3版本对应的PyTorch框架。默认给我安装的Pytorch版本是1.12.1。<br>不过我感觉这样安装太慢了，我选择离线下载<br>这里以Ubuntu系统CUDA11.3以及python3.7为例，打开网址： <a href="https://download.pytorch.org/whl/cu113/torch_stable.html" rel="nofollow">https://download.pytorch.org/whl/cu113/torch_stable.html</a><br>搜索torch-1.10.0<br><img src="https://images2.imgbox.com/e6/86/p0fMfjgT_o.png" alt="在这里插入图片描述"><br> <br>搜索torchvision-0.11.1<br><img src="https://images2.imgbox.com/3d/c0/8DkKa4YA_o.png" alt="在这里插入图片描述"><br> <br>在本机下载路径里可以找到需要的torch-1.10.0+cu113-cp37-cp37m-linux_x86_64.whl以及torchvision-0.11.1+cu113-cp37-cp37m-linux_x86_64.whl两个文件即可。注意，cu113代表CUDA11.3，cp38表示python3.8的编译环境，linux_x86_64表示x86的平台64位操作系统。下载完成后，将这两个文件传入你的离线主机（服务器）中。接着进入刚刚用conda创建好的虚拟环境后依次安装whl包：<br><code>pip install torch-1.10.0+cu113-cp37-cp37m-linux_x86_64.whl</code><br><code>pip install torchvision-0.11.1+cu113-cp37-cp37m-linux_x86_64.whl</code><br>最后也是成功安装了，但是验证时cuda.is_available()一直返回的FAlSE</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> torchvision
<span class="token keyword">print</span><span class="token punctuation">(</span>torchvision<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/8f/1f/K0epQ3C8_o.png" alt="在这里插入图片描述"><br> <br>然后到这里我就很崩溃，后面其实也有重新装过好几次，不出意外都失败了，然后看到有文章说是系统驱动和内核不一致的问题，然后我又花了快一天的时间看看Ubuntu系统怎么装显卡驱动的，尝试了很久还是没有成功，我感觉真的很绝望，然后就请教了大师兄，多亏问了大师兄，他<strong>重启了一下容器就解决了</strong>，然后我真的很感谢！！！然后nvidia-smi命令也可以用了！！！<br><img src="https://images2.imgbox.com/b9/46/T1bPwXTh_o.png" alt="在这里插入图片描述"><br> <br>我那个久违的True终于出现了，真的配置的给我整的快崩溃了！！！<br>!<img src="https://images2.imgbox.com/77/de/BcYN2PSb_o.png" alt="在这里插入图片描述"></p> 
<p>最后尝试跑了一下图像检测的分类任务，成功跑出来了！！！开心！！！！<br><img src="https://images2.imgbox.com/95/71/pocWywZK_o.png" alt="在这里插入图片描述"></p> 
<p></p> 
<h2><a id="3Pycharm_83"></a>3.配置Pycharm连接远程服务器</h2> 
<p>点击pycharm左上角的file，找到python interpreter,点击右边的设置（长得像齿轮那个），然后找到<a href="https://so.csdn.net/so/search?q=SSH&amp;spm=1001.2101.3001.7020">SSH</a> interpreter填写服务器的地址和你服务器上的名字 <br><img src="https://images2.imgbox.com/a7/cd/9Ehs6b7z_o.png" alt="在这里插入图片描述"><br> <br> 点击新增，选择SSH Interpreter。 host是主机IP，username是用户名，端口也别忘记改<br><img src="https://images2.imgbox.com/e7/bb/zEGPQwvO_o.png" alt="在这里插入图片描述"><br> <br>这里下一步，输入密码<br><img src="https://images2.imgbox.com/bf/54/ie2NxBTg_o.png" alt="在这里插入图片描述"><br> <br> 选择远程docker容器python执行文件，在安装Anaconda包内， 例如我的位置是：/home/PythonTools/Anaconda/anaconda3//bin/python3.7 <br><img src="https://images2.imgbox.com/24/8d/5fGFZFG6_o.png" alt="在这里插入图片描述"><br> <br> 下一栏选择本地项目目录与远程项目目录位置映射 ，意思就是你当前项目在哪，把它上传到服务器哪个位置。<br><img src="https://images2.imgbox.com/bd/c4/g4oyud2F_o.png" alt="在这里插入图片描述"><br> <br>然后就OK了！！！<br><img src="https://images2.imgbox.com/33/20/dWKckmbT_o.png" alt="在这里插入图片描述"></p> 
<p>将本地代码与服务器进行同步<br><img src="https://images2.imgbox.com/16/4d/EkPkn0oB_o.png" alt="在这里插入图片描述"><br> <br>选择红色框的这个，不要选择always<br><img src="https://images2.imgbox.com/0f/ca/er1XBaL7_o.png" alt="在这里插入图片描述"><br> <br>然后就是愉快的测试项目了，我这个是TextRNN文本分类，然后我本机跑一个epoch都够呛，用实验室的显卡跑的飞快！！！！！<br><img src="https://images2.imgbox.com/02/29/FuqmYevm_o.png" alt="在这里插入图片描述"><br> <br>最后终于写完了这篇文章，真的是经历了太多挫折，说话说得好，工欲善其事，必先利其器。所以环境配置这一块一定要自己搞明白，以后去到新地方就可以花费更好的时间去配置这些环境，规避因环境而产生的BUG。希望爱后面我能少遇到一点BUG，继续努力向大佬们学习，敢于尝试！！！<br> </p> 
<h2><a id="_97"></a>参考文章</h2> 
<p>比 Xshell 还好用的 SSH 客户端神器，MobaXterm 太爱了！ <a href="https://mp.weixin.qq.com/s/p96kWPkPuJYeWxG3AqvnDQ" rel="nofollow">https://mp.weixin.qq.com/s/p96kWPkPuJYeWxG3AqvnDQ</a><br>配置Pycharm以及Jupyter远程服务器 <a href="https://zhuanlan.zhihu.com/p/409159969" rel="nofollow">https://zhuanlan.zhihu.com/p/409159969</a><br>Pycharm代码docker容器运行调试 | 机器学习系列 <a href="https://blog.csdn.net/zhiweihongyan1/article/details/120556923">https://blog.csdn.net/zhiweihongyan1/article/details/120556923</a><br>【Pytorch】在实验室linux系统服务器上搭建自己的pytorch-gpu环境过程详解！一篇就足够！：<a href="https://blog.csdn.net/weixin_44398263/article/details/109110773">https://blog.csdn.net/weixin_44398263/article/details/109110773</a></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8466212235be20be8e52ae12bd0d3379/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">unity关于纹理、着色器和材质的介绍</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/022dcb3cf3d4da417e35fe9f6a8d42f1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">25道Python经典面试题大全，看这一篇就够了</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>