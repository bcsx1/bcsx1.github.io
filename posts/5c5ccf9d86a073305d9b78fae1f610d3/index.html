<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark编程基础期末复习 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Spark编程基础期末复习" />
<meta property="og:description" content="选择题 1. spark 的四大组件下面哪个不是 (D) A.Spark Streaming B Mlib C Graphx D Spark R
2.下面哪个端口不是 spark 自带服务的端口 ( C) A.8080 B.4040 C.8090 D.18080
3.spark 1.4 版本的最大变化 ( B) A spark sql Release 版本 B 引入 Spark R C DataFrame D支持动态资源分配
4. Spark Job 默认的调度模式 ( A) A FIFO B FAIR C 无 D 运行时指定
5.哪个不是本地模式运行的条件 ( D) A spark.localExecution.enabled=true B 显式指定本地运行 C finalStage 无父 Stage D partition默认值
6.下面哪个不是 RDD 的特点 (C ) A." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/5c5ccf9d86a073305d9b78fae1f610d3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-03T22:37:44+08:00" />
<meta property="article:modified_time" content="2023-08-03T22:37:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark编程基础期末复习</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="_0"></a>选择题</h3> 
<h4><a id="1_spark__D_1"></a>1. spark 的四大组件下面哪个不是 (D)</h4> 
<p>A.Spark Streaming B Mlib C Graphx D Spark R</p> 
<h4><a id="2_spark___C_3"></a>2.下面哪个端口不是 spark 自带服务的端口 ( C)</h4> 
<p>A.8080 B.4040 C.8090 D.18080</p> 
<h4><a id="3spark_14___B_5"></a>3.spark 1.4 版本的最大变化 ( B)</h4> 
<p>A spark sql Release 版本 B 引入 Spark R C DataFrame D支持动态资源分配</p> 
<h4><a id="4_Spark_Job___A_7"></a>4. Spark Job 默认的调度模式 ( A)</h4> 
<p>A FIFO B FAIR C 无 D 运行时指定</p> 
<h4><a id="5__D_9"></a>5.哪个不是本地模式运行的条件 ( D)</h4> 
<p>A spark.localExecution.enabled=true B 显式指定本地运行 C finalStage 无父 Stage D partition默认值</p> 
<h4><a id="6_RDD__C__11"></a>6.下面哪个不是 RDD 的特点 (C )</h4> 
<p>A. 可分区 B 可序列化 C 可修改 D 可持久化</p> 
<h4><a id="7___D_14"></a>7. 关于广播变量，下面哪个是错误的 ( D)</h4> 
<p>A 任何函数调用 B 是只读的 C 存储在各个节点 D 存储在磁盘或 HDFS</p> 
<h4><a id="8___D_16"></a>8. 关于累加器，下面哪个是错误的 ( D)</h4> 
<p>A 支持加法 B 支持数值类型 C 可并行 D 不支持自定义类型</p> 
<h4><a id="9Spark___D_18"></a>9.Spark 支持的分布式部署方式中哪个是错误的 ( D)</h4> 
<p>A standalone B spark on mesos C spark on YARN D Spark on local</p> 
<h4><a id="10Stage__Task___A_20"></a>10.Stage 的 Task 的数量由什么决定 ( A)</h4> 
<p>A Partition B Job C Stage D TaskScheduler</p> 
<h4><a id="11__B_22"></a>11.下面哪个操作是窄依赖 ( B)</h4> 
<p>A join B filter C group D sort</p> 
<h4><a id="12__C_24"></a>12.下面哪个操作肯定是宽依赖 ( C)</h4> 
<p>A map B flatMap C reduceByKey D sample</p> 
<h4><a id="13spark__master__worker__D__26"></a>13.spark 的 master 和 worker 通过什么方式进行通信的？ (D )</h4> 
<p>A http B nio C netty D Akka</p> 
<h4><a id="14__A__28"></a>14 默认的存储级别 (A )</h4> 
<p>A MEMORY_ONLY B MEMORY_ONLY_SER<br> C MEMORY_AND_DISK D MEMORY_AND_DISK_SER</p> 
<h4><a id="15_sparkdeployrecoveryMode___D_31"></a>15 spark.deploy.recoveryMode 不支持那种 ( D)</h4> 
<p>A.ZooKeeper B. FileSystem D NONE D hadoop</p> 
<h4><a id="16_RDD__C__33"></a>16.下列哪个不是 RDD 的缓存方法 (C )</h4> 
<p>A persist() B Cache() C Memory()</p> 
<h4><a id="17Task__Executor___C_36"></a>17.Task 运行在下来哪里个选项中 Executor 上的工作单元 ( C)</h4> 
<p>A Driver program B. spark master C.worker node D Cluster manager</p> 
<h4><a id="18hive__derby__mysql__B__38"></a>18.hive 的元数据存储在 derby 和 mysql 中有什么区别 (B )</h4> 
<p>A.没区别 B.多会话 C.支持网络环境 D数据库的区别</p> 
<h4><a id="19DataFrame__RDD__B__40"></a>19.DataFrame 和 RDD 最大的区别 (B )</h4> 
<p>A.科学统计支持 B.多了 schema C.存储方式不一样 D.外部数据源支持</p> 
<h4><a id="20Master__ElectedLeader__D__42"></a>20.Master 的 ElectedLeader 事件后做了哪些操作 (D )</h4> 
<p>A. 通知 driver B.通知 worker C.注册 application D.直接 ALIVE</p> 
<h4><a id="21applicationMasterD__44"></a>21.下列哪一项不是applicationMaster的功能(D )</h4> 
<p>A.数据切分 B.为应用程序申请资源,并进一步分配给内部任务C.任务监控与容错D.所有应用的管理者</p> 
<h4><a id="22Spark_RDDD_46"></a>22.Spark RDD中没有的特性是(D)</h4> 
<p>A.位置优先B.分布式C.弹性D.固定大小</p> 
<h4><a id="23Sparkexecutor_ABC_48"></a>23.以下是Spark中executor的作用是( ABC)</h4> 
<p>A.保存计算的RDD分区数据B.向Driver反向注册C.接受Driver端发送来的任务Task,作用在RDD上进行执行D.做资源调度任务</p> 
<h4><a id="24Stage__Task_BCD__50"></a>24.Stage 的 Task 的数量不是由什么决定(BCD )</h4> 
<p>A.Partition B.Job C.Stage D.TaskScheduler</p> 
<h4><a id="25sparkABD_52"></a>25.spark的特点包括(ABD)</h4> 
<p>A. 快速 B. 通用 C. 可延伸 D. 兼容性</p> 
<h4><a id="26Task__Executor_ABD_54"></a>26.Task 运行不在以下选项中 Executor 上的工作单元(ABD)</h4> 
<p>A.Driver program B.spark master C.worker node D.Cluster manager</p> 
<h4><a id="27sparkAD_56"></a>27.关于spark容错说法错误的有（AD）</h4> 
<p>A.在容错机制中，如果一个节点死机了，而且运算窄依赖，则只要把丢失的父RDD分区重算即可，依赖于其他节点<br> B.宽依赖开销更大<br> C.Checkpoint可以节约大量的系统资源<br> D.RDD的容错机制是基于Spark Streaming的容错机制</p> 
<h4><a id="28SparkRdd_ABC_61"></a>28.SparkRdd 转换算子有(ABC)</h4> 
<p>A. map B. filter C. mapPartitions D. collect</p> 
<h4><a id="29_spark__ABD_63"></a>29.下面哪些端口是 spark 自带服务的端口 (ABD)</h4> 
<p>A. 8080 B. 4040 C. 8090 D. 18080</p> 
<h4><a id="30sparkABCD_65"></a>30.关于spark中数据倾斜引发原因正确的选项有(ABCD)</h4> 
<p>A. key本身分布不均衡 B. 计算方式有误 C. 过多的数据在一个task里面 D. shuffle并行度不够</p> 
<h4><a id="31Spark_driverABD_67"></a>31.Spark driver的功能是什么(ABD)</h4> 
<p>A. 是作业的主进程 B. 负责了作业的调度 C. 负责向HDFS申请资源 D. 负责作业的解析</p> 
<h4><a id="32Master__ElectedLeader_ABC_69"></a>32.Master 的 ElectedLeader 事件后不做哪些操作(ABC)</h4> 
<p>A. 通知 driver B. 通知 worker C. 注册 application D. 直接 ALIVE</p> 
<h4><a id="33D____71"></a>33.大数据的特点不包括（D ）</h4> 
<p>A：数据量大；B数据类型多；C：处理速度快；D：价值密度高</p> 
<h4><a id="34_B___73"></a>34.大数据的特点不包括（ B ）</h4> 
<p>A：数据量大；B数据类型单一；C：处理速度快；D：价值密度低</p> 
<h4><a id="35__D__75"></a>35.大数据计算模式不包括（ D ）</h4> 
<p>A：批处理计算；B：流计算；C：图计算；D：云计算</p> 
<h4><a id="36A____77"></a>36.大数据计算模式不包括（A ）</h4> 
<p>A：离线处理计算；B：流计算；C：图计算；D：查询分析计算</p> 
<h5><a id="37scala_D___79"></a>37.scala属于哪种编程语言（ D ）</h5> 
<p>A、函数式编程语言 B、汇编语言 C、机器语言 D、多范式编程语言</p> 
<h4><a id="38ScalaC_81"></a>38.以下Scala变量的定义不正确的是哪项©</h4> 
<p>A、val words:String=“Hello World”<br> B、val number = 12<br> C、var number:String = None<br> D、var apple:Double = 2</p> 
<h4><a id="39saprk__C__86"></a>39.以下哪一个不是saprk的特点（ C ）</h4> 
<p>A、随处运行<br> B、代码简洁<br> C、使用复杂<br> D、运行快速</p> 
<h4><a id="40sparkpiA_91"></a>40.下面哪一个命令是spark运行pi的命令(A)</h4> 
<p>A、run-example SparkPi 2<br> B、Spark-shell SparkPi 2<br> C、hadoop-daemon jar SparkPi 2<br> D、yarn jar Spark 2</p> 
<h4><a id="41ScalaA_96"></a>41.Scala编译后的文件是以什么结尾?(A)</h4> 
<p>A、.class<br> B、.bash<br> C、.pyc<br> D、.sc</p> 
<h4><a id="42scalaD_101"></a>42.以下哪种不属于scala的特性?(D)</h4> 
<p>A、命令式编程<br> B、函数式编程<br> C、静态类型<br> D、不可扩展性</p> 
<h4><a id="43aD_106"></a>43.以下哪种可以正确计算数组a的长度?(D)</h4> 
<p>A、count()<br> B、take(1)<br> C、tail( )<br> D、length( )</p> 
<h4><a id="44C_111"></a>44.关于下面函数的结果说法错误的是哪项?©</h4> 
<p>def getPageNum(file:String) = {<!-- --><br> var bookMap = Map(“Chinese” -&gt; 164,“Math” -&gt; 180,“English” -&gt; 150,“Geography” -&gt; 120)<br> book.getOrElse(file,0)<br> }<br> A、getPageNum(“Math”)=180<br> B、getPageNum(“English”)=150<br> C、getPageNum(“Physics”)=164<br> D、getPageNum(“Geography”)=120</p> 
<h4><a id="45ListC_120"></a>45.以下关于List的定义不正确的一项是哪项?©</h4> 
<p>A、val list = List(12,2,3)<br> B、val list = List(“Hello World”)<br> C、val list:String = List(“a”,“b”,“c”)<br> D、val list = ListInt</p> 
<h4><a id="46SetSet301222B_125"></a>46.对于(Set)进行操作"Set(3,0,1)+2+2-2"之后的结果为哪项(B)</h4> 
<p>A、Set(3,0,1,2)<br> B、Set(3,0,1)<br> C、Set(3,0)<br> D、以上均不正确</p> 
<h4><a id="47C_130"></a>47.关于下面元组的结果说法错误的是哪项?©</h4> 
<p>scala&gt; val tuple=(“Bigdata”,2015,45.0)<br> Scala&gt; val (t1,t2,t3)=tuple<br> A、t1:string=Bigdata<br> B、t2:Int=2015<br> C、t3:Int=45.0<br> D、t3:Double=45.0</p> 
<h3><a id="_137"></a>简答题</h3> 
<h4><a id="1_138"></a>1:请阐述大数据处理的基本流程。</h4> 
<p>大数据的基本处理流程主要包括数据采集、存储管理、处理分析、结果呈现等环节。</p> 
<h4><a id="2Scala_140"></a>2：简述Scala语言的基本特性。</h4> 
<p>简洁、兼容、可扩展和静态类型</p> 
<h4><a id="3_142"></a>3：什么是单例对象和伴生对象？</h4> 
<ul><li>单例对象：在第一次被访问的时候初始化。单例对象包括两种，即伴生对象和孤立对象。当一个单例对象和它的同名类一起出现时，这时的单例对象被称为这个同名类的“伴生对象”。没有同名类的单例对象，被称为孤立对象</li><li>伴生对象：当单例对象与某个类具相同的名称时，它被称为这个类的“伴生对象”</li></ul> 
<h4><a id="4__MapReduce_145"></a>4. 阐述MapReduce的基本设计思想。</h4> 
<ul><li>“计算向数据靠拢”</li></ul> 
<h4><a id="5__SparkSpark_147"></a>5. Spark是基于内存计算的大数据计算平台，请阐述Spark的主要特点。</h4> 
<ul><li><strong>运行速度快</strong>：spark适应先进的有向无环图执行引擎，以支持循环数据流与内存计算，基于内存的执行速度可以比hadoop MapReduce快上百倍，基于磁盘的执行速度也能快十倍‘；</li><li><strong>容易使用</strong>：spark支持使用scala、java、Python和R语言进行编程，简介的API设计有助于用户轻松构件并行程序，并且可以通过spark shell进行交互式编程</li><li><strong>通用性</strong>：spark提供了完整而强大的技术栈，包括SQL查询、流式计算、机器学习和图算法组件，这些组件可以无缝整合在同一个应用中，足以应对复杂的计算；</li><li><strong>运行模式多样</strong>：spark可运行于独立的集群模式中，或者运行与hadoop中，也可以运行与Amazon EC2等云环境中，并且可以访问HDFS、Cassandra、Hbase。HIve等多种数据源。</li></ul> 
<h4><a id="_152"></a>在下列语句的基础上，</h4> 
<p>scala&gt; import scala.collection.mutable.ListBuffer<br> scala&gt;val mutableL1=ListBuffer(1,2,3)//初始长度为3的变长列表<br> 写出下列语句的作用。<br> （1）mutableL1+=5 mutableL1-=3<br> <strong>答：在列表的尾部增加一个元素5，删除值为3的第一个元素</strong><br> （2）mutalbeL1.insert(2,5,6)<br> <strong>答：从第2个缩影位置开始，插入5和6</strong></p> 
<h5><a id="Scala_160"></a>写出Scala语句完成下列操作。</h5> 
<p>将下列 json 数据复制到你的 ubuntu 系统/usr/local/spark 下，并保存命名为 employee. json。<br> { “id”:1 ,“name”:" Ella",“age”:36 }<br> { “id”:2,“name”:“Bob”,“age”:29 }<br> { “id”:3 ,“name”:“Jack”,“age”:29 }<br> { “id”:4 ,“name”:“Jim”,“age”:28 }<br> { “id”:5 ,“name”:“Damon” }<br> { “id”:5 ,“name”:“Damon” }<br> 首先为<br> employee. json 创建 DataFrame，代码如下。<br> scala&gt; import org. apache. spark. sql. SparkSession<br> scala&gt; val spark=SparkSession. builder(). getOrCreate()<br> scala&gt; import spark. implicits. _<br> scala&gt; val df = spark. read. json(“file:///usr/local/spark/employee. json”)</p> 
<ul><li>查询 DataFrame 的所有数据； 
  <ul><li><code>df.show()</code></li></ul> </li><li>查询所有数据并去重； 
  <ul><li><code>df.distinct.show()</code></li></ul> </li><li>查询所有数据，打印时去除id字段 
  <ul><li><code>df.drop("id").show()</code></li></ul> </li><li>筛选出age&gt;=30的记录 
  <ul><li><code>df.filter(df("age")&gt;30).show()</code></li></ul> </li><li>将数据按age分组； 
  <ul><li><code>df.groupBy("age").count().show()</code></li></ul> </li><li>将数据按 name 升序排列 ； 
  <ul><li><code>df.orderBy("naem").show()</code>或者<code>df.sort(df("name").asc).show()</code></li></ul> </li><li>取出前 4 行数据 ； 
  <ul><li><code>df.limit(4).show()</code>或者<code>df.take(4)</code></li></ul> </li><li>查询所有记录的 name 列，并为其取别名为 username ； 
  <ul><li><code>df.select(df("name").as("username")).show()</code></li></ul> </li><li>查询年龄 age 的平均值 ； 
  <ul><li><code>df.agg("agg"-&gt;"avg").show()</code></li></ul> </li><li>查询年龄 age 的最小值 。 
  <ul><li><code>df.agg("agg"-&gt;"min").show()</code></li></ul> </li></ul> 
<h3><a id="_198"></a>一些散乱的知识点</h3> 
<h5><a id="4_199"></a>大数据的4个特点：</h5> 
<ul><li>数据量大，数据类型繁多，处理速度快，价值密度低</li></ul> 
<h5><a id="MapReduce_201"></a>MapReduce设计的一个理念就是</h5> 
<ul><li>“计算向数据靠拢”</li></ul> 
<h5><a id="yarn_203"></a>yarn是负责集群资源调度管理的组件</h5> 
<h5><a id="yarnMapReducesparkstormDAGTez_204"></a>目前，可以运行在yarn之上的计算框架包括离线批处理框架MapReduce，内存计算框架spark，流计算框架storm和DAG时就按框架Tez等。</h5> 
<h5><a id="sparkhadoop_205"></a>spark和hadoop的对比</h5> 
<ul><li>hadoop中的MapReduce就算框架主要存在的缺点 
  <ul><li>表达能力有限。计算都必须转化成Map和Reduce两个操作，但这并不适合所有的请款，难以描述复杂的数据处理过程；</li><li>磁盘I/O开销大。每次执行时都需要从磁盘读取数据，并且在计算完成后需要将中间结果写入到磁盘中，I/O开销较大</li><li>延迟高。一次计算可能需要分解成一系列按顺序执行的MapReduce任务，任务自己拿的衔接由于涉及到I/O开销，会产生较高的延迟。而且，在前一个任务执行完成之前，其他任务无法开始，因此，难以胜任复杂、多阶段的计算任务。</li></ul> </li><li>spark在借鉴MapReduce优点同时，很好地解决了MapReduce的缺点，spark的优点有 
  <ul><li>spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比MapReduce更灵活；</li><li>spark提供了内存计算，中间结果直接放到内存中，带来了更高效的迭代运行效率；</li><li>spark基于DAG的任务调度执行机制，要优于MapReduce的迭代执行机制</li></ul> </li></ul> 
<h5><a id="scala_214"></a>scala简介</h5> 
<ul><li>scala运行与java虚拟机（jvm）上并且兼容现有的java程序，可以与java类进行互操作，包括调用java方法，创建java对象，继承java类和实现java接口。</li><li>scala是一门纯粹的面向对象语言。在scala语言中，每个值都是对象，每个操作都是方法调用。对象的数据类型以及行为由类和特质描述。类抽象机制的扩展有两种途径，一种途径是子类继承，另一种途径是灵活的混入（mixin）机制，这两种途径能避免多重继承的问题。</li><li>scala也是一门函数式语言。在scala语言中，每个函数都是一个对象，并且和其他类型（如整数、字符串等）的值处于同一地位。scala提供了轻量级的语法用以定义匿名函数、同时支持高阶函数，允许嵌套多层函数，并支持柯里化。</li></ul> 
<h5><a id="scala_218"></a>scala的数据结构又：数组、元组、列表、映射、集合</h5> 
<h5><a id="scalalistvectorlistbufferarraybuffer_219"></a>scala中list和vector都是不可变的，其包含对象一单确定就不能增加和删除。他们对应的可变版本为listbuffer和arraybuffer</h5> 
<h5><a id="objectclass_220"></a>单例对象的定义与类定义类似，只是用object关键字替换了class关键字</h5> 
<h5><a id="_221"></a>当单例对象与某个类具相同的名称时，它被称为这个类的“伴生对象”，相应的类被称为这个单例对象的“伴生类”。伴生对象和它的伴生类必须位于同一个文件中，它们之间可以相互访问对方的私有成员。</h5> 
<h4><a id="RDD_223"></a>RDD设计背景</h4> 
<ul><li>在实际应用中，存在许多迭代式算法和交互式数据挖掘工具，这些应用场景的不同计算阶段之间会重用中间计算结果，但是这些框架的计算结果往往是存储在不同位置的，计算模式往往也是只能支持特定的计算模式，并没有一种通用的数据抽象</li></ul> 
<h5><a id="RDD_227"></a>RDD概念</h5> 
<ul><li>一个RDD就是一个分布式对象集合，本质上就是一个只读的分区记录集合，每个RDD可以分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中不同节点上进行并行计算。</li></ul> 
<h5><a id="sparkscalaRDDAPIAPIRDDRDD_230"></a>spark用scala语言实现了RDD的API，程序员可以用过调用API实现对RDD是各种操作，RDD典型的执行过程如下：</h5> 
<ul><li>RDD读入外部数据源（或者内存中的集合）进行创建；</li><li>RDD经过一系列的“转换”操作，每一次都会产生不同的RDD，提供给一下“转换”使用；</li><li>最后一个RDD经“行动”操作进行处理，并输出到外部数据源（或者编程scala集合或标量）</li></ul> 
<h5><a id="RDD_234"></a>RDD–转换操作</h5> 
<ul><li>对RDD而言，每一次转换操作都会产生不同的RDD，提供给下一个操作使用，RDD的转换过程是惰性求值的，也就是说，整个转换过程只是记录了转换的轨迹，并不会发生真正的计算，只有遇到行动操作时，才会触发“从头到尾”的真正的计算</li></ul> 
<h5><a id="RDDAPI_236"></a>常用的RDD转换操作API</h5> 
<table><thead><tr><th align="center">操作</th><th align="left">含义</th></tr></thead><tbody><tr><td align="center">filter(func)</td><td align="left">筛选出满足函数func的元素，并返回一个新的数据集</td></tr><tr><td align="center">map(func)</td><td align="left">将每个元素传递带函数func中，并将结果返回为一个新的数据集</td></tr><tr><td align="center">flatMap(func)</td><td align="left">与map()相似，但每个输入元素都可以映射到0或多个输出结果</td></tr><tr><td align="center">groupByKey()</td><td align="left">应用于（K，V）键值对的数据集时，返回一个新的 （K，Iterable）形式的数据集</td></tr><tr><td align="center">reduceByKey(func)</td><td align="left">应用于（K，V）键值对的数据集时，返回一个新的 （K，V）形式的数据集，其中每个值是将每个key传递到函数func中进行聚合后的结果</td></tr></tbody></table> 
<h5><a id="RDD_244"></a>RDD–行动操作</h5> 
<ul><li>行动操作是真正触发计算的地方，spark程序只有执行到行动操作是，才会执行真正的 计算，从文件中加载数据，完成一次又一次的转换操作，最终，完成行动操作得到结果。</li></ul> 
<h5><a id="RDDAPI_246"></a>常用的RDD行动操作API</h5> 
<table><thead><tr><th align="center">操作</th><th align="left">含义</th></tr></thead><tbody><tr><td align="center">count()</td><td align="left">返回数据集中的元素个数</td></tr><tr><td align="center">collect()</td><td align="left">以数组的形式返回数据集中的所有元素</td></tr><tr><td align="center">first()</td><td align="left">返回数据集中的第一个元素</td></tr><tr><td align="center">taken(n)</td><td align="left">以数组的形式返回数据集总共的前n个元素</td></tr><tr><td align="center">reduce(func)</td><td align="left">通过函数func（输入两个参数并返回一个值）聚合数据集中的元素</td></tr><tr><td align="center">foreach(func)</td><td align="left">将数据集中的每个元素传递到函数func中运行</td></tr></tbody></table>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/82ea9f0b07e3812b5680f399f9078d06/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">使用xlsx.js导出有复杂表头的excel</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fffbe5f59ee10cbbf1a7dd649d761be5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">第126天：内网安全-隧道技术&amp;SSH&amp;DNS&amp;ICMP&amp;SMB&amp;上线通讯Linux&amp;Mac</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>