<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Kubernetes实战入门 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Kubernetes实战入门" />
<meta property="og:description" content="通过本篇文章记录如何在Kubernetes集群中部署一个nginx服务，并且能够对其进行访问
1、Namespace Namespace是Kubernetes系统中的一种非常重要的资源，它的主要作用是用来实现多套环境的资源隔离或者多租户的资源隔离
默认情况下，Kubernetes集群中的所有Pod都是可以相互访问的，但是我们再实际过程中很可能不想让两个Pod之间进行相互的访问，那么此时就可以将两个Pod划分到不同的namespace下。Kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的“组”，以方便不同的组的资源进行隔离使用和管理。(多套环境资源隔离)
可以通过Kubernetes的授权机制，将不同的Namespace交给不同的租户进行管理，这样就实现了多租户的资源隔离。此时还能结合Kubernetes的资源配额机制，限定不同租户所能占用的资源，例如CPU的使用量，内存的使用量等等，以实现租户可用资源的管理。（多租户的资源隔离）
在Kubernetes集群启动之后，是会默认创建几个Namespace的
[root@master ~]# kubectl get ns NAME STATUS AGE default Active 2d19h #所有未指定Namespace的对象都会被分配在default空间 kube-node-lease Active 2d19h #集群节点之间的心跳维护，从v1.13开始引入 kube-public Active 2d19h #此命名空间下的资源可以被所有人访问（包括未认证用户） kube-system Active 2d19h #所有由Kubernetes系统创建的资源都处于这个命名空间 下面可以来看看Namespace资源的具体操作：
# 1、查看所有Namespace [root@master ~]# kubectl get ns NAME STATUS AGE default Active 2d19h dev Active 19h kube-node-lease Active 2d19h kube-public Active 2d19h kube-system Active 2d19h # 2、查看指定的Namespace 命令：kubectl get ns &lt;NSname&gt; [root@master ~]# kubectl get ns dev NAME STATUS AGE dev Active 19h # 3、指定输出格式 命令：kubectl get ns &lt;NSname&gt; -o &lt;格式参数&gt; # Kubernetes支持的格式有很多，比较常见的是wide、JSON、yaml [root@master ~]# kubectl get ns dev -o yaml apiVersion: v1 kind: Namespace metadata: annotations: kubectl." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/07a293c326d03295c9aff50c6bf4d816/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-10T20:53:38+08:00" />
<meta property="article:modified_time" content="2022-04-10T20:53:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kubernetes实战入门</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:center;">通过本篇文章记录如何在Kubernetes集群中部署一个nginx服务，并且能够对其进行访问</p> 
<h3>1、Namespace</h3> 
<p>Namespace是Kubernetes系统中的一种非常重要的资源，它的主要作用是用来<strong>实现多套环境的资源隔离或者多租户的资源隔离</strong></p> 
<p>默认情况下，Kubernetes集群中的所有Pod都是可以相互访问的，但是我们再实际过程中很可能不想让两个Pod之间进行相互的访问，那么此时就可以将两个Pod划分到不同的namespace下。Kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的“组”，以方便不同的组的资源进行隔离使用和管理。(多套环境资源隔离)</p> 
<p>可以通过Kubernetes的授权机制，将不同的Namespace交给不同的租户进行管理，这样就实现了多租户的资源隔离。此时还能结合Kubernetes的资源配额机制，限定不同租户所能占用的资源，例如CPU的使用量，内存的使用量等等，以实现租户可用资源的管理。（多租户的资源隔离）</p> 
<p class="img-center"><img alt="" height="401" src="https://images2.imgbox.com/a7/b7/ZDXBRAuw_o.png" width="763"></p> 
<p>在Kubernetes集群启动之后，是会默认创建几个Namespace的</p> 
<pre><code class="language-bash">[root@master ~]# kubectl get ns
NAME              STATUS   AGE
default           Active   2d19h     #所有未指定Namespace的对象都会被分配在default空间
kube-node-lease   Active   2d19h     #集群节点之间的心跳维护，从v1.13开始引入
kube-public       Active   2d19h     #此命名空间下的资源可以被所有人访问（包括未认证用户）
kube-system       Active   2d19h     #所有由Kubernetes系统创建的资源都处于这个命名空间
</code></pre> 
<p>下面可以来看看Namespace资源的具体操作：</p> 
<pre><code class="language-bash"># 1、查看所有Namespace
[root@master ~]# kubectl get ns
NAME              STATUS   AGE
default           Active   2d19h
dev               Active   19h
kube-node-lease   Active   2d19h
kube-public       Active   2d19h
kube-system       Active   2d19h

# 2、查看指定的Namespace 命令：kubectl get ns &lt;NSname&gt;
[root@master ~]# kubectl get ns dev
NAME   STATUS   AGE
dev    Active   19h

# 3、指定输出格式 命令：kubectl get ns &lt;NSname&gt; -o &lt;格式参数&gt;
# Kubernetes支持的格式有很多，比较常见的是wide、JSON、yaml
[root@master ~]# kubectl get ns dev -o yaml
apiVersion: v1
kind: Namespace
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"Namespace","metadata":{"annotations":{},"name":"dev"}}
  creationTimestamp: "2022-04-06T10:44:40Z"
  labels:
    kubernetes.io/metadata.name: dev
  name: dev
  resourceVersion: "91162"
  uid: c8973639-a1ed-4a50-a83e-93ea9f5c53a3
spec:
  finalizers:
  - kubernetes
status:
  phase: Active

# 4、查看ns详情 命令：kubectl describe ns &lt;Nsname&gt;
[root@master ~]# kubectl describe ns dev 
Name:         dev
Labels:       kubernetes.io/metadata.name=dev
Annotations:  &lt;none&gt;
Status:       Active         # Active是命名空间正在使用中 Terminating：正在删除命名空间

# ResourceQuota 针对namespace做的资源限制
# LimitRange针对namespace中的每个组件做的资源限制

No resource quota.

No LimitRange resource.

</code></pre> 
<p><strong>创建</strong></p> 
<blockquote> 
 <p>创建namespace</p> 
 <pre><code class="language-bash">[root@master ~]# kubectl create ns dev
namespace/dev created
</code></pre> 
 <p>删除namespace</p> 
 <pre><code class="language-bash">[root@master ~]# kubectl delete ns dev
namespace "dev" deleted
</code></pre> 
</blockquote> 
<p></p> 
<h3>2、Pod </h3> 
<p>      Pod是Kubernetes集群进行管理的最小单元，程序要运行必须部署在容器中，而且容器必须存在于Pod中。Pod可以认为是容器的封装，一个Pod中可以存在一个或者多个容器。</p> 
<p class="img-center"><img alt="" height="348" src="https://images2.imgbox.com/09/8f/3SgaDTnY_o.png" width="463"></p> 
<p>    Kubernetes在集群启动之后，集群中的各个组件也是以Pod方式运行的可以通过下面的命令进行查看：</p> 
<pre><code class="language-bash">[root@master ~]# kubectl get pods -n kube-system
NAME                                       READY   STATUS    RESTARTS         AGE
calico-kube-controllers-68845d5dc9-8t42r   1/1     Running   1 (5h21m ago)    27h
calico-node-f64nf                          1/1     Running   1 (5h21m ago)    27h
calico-node-gx9rm                          1/1     Running   1 (5h21m ago)    27h
calico-node-mh2s9                          1/1     Running   1 (5h21m ago)    27h
coredns-6d8c4cb4d-ndjfj                    1/1     Running   1 (5h21m ago)    2d22h
coredns-6d8c4cb4d-sfkhv                    1/1     Running   1 (5h21m ago)    2d22h
etcd-master                                1/1     Running   7 (5h21m ago)    2d22h
kube-apiserver-master                      1/1     Running   12 (5h21m ago)   2d22h
kube-controller-manager-master             1/1     Running   6 (5h21m ago)    2d22h
kube-flannel-ds-66plh                      1/1     Running   2 (5h19m ago)    27h
kube-flannel-ds-76qlm                      1/1     Running   2 (5h19m ago)    27h
kube-flannel-ds-xcwdf                      1/1     Running   1 (5h21m ago)    27h
kube-proxy-gtfkb                           1/1     Running   4 (5h21m ago)    2d22h
kube-proxy-nzrf5                           1/1     Running   4 (5h21m ago)    2d22h
kube-proxy-trd4z                           1/1     Running   4 (5h21m ago)    2d22h
kube-scheduler-master                      1/1     Running   7 (5h21m ago)    2d22h
[root@master ~]# 
</code></pre> 
<p><strong>创建并运行</strong></p> 
<p><strong>        </strong>Kubernetes没有提供单独运行Pod的命令，都是通过Pod控制器来进行实现的</p> 
<pre><code class="language-bash"># 命令格式：kubectl run &lt;Pod控制器名称&gt; &lt;参数&gt;
# --image         指定Pod的镜像
# --port          指定端口
# --namespace     指定namespace
[root@master ~]# kubectl run nginx --image=nginx:1.17.3 --port=80 -n dev
pod/nginx created

#查看pod的详细信息 -o wide
[root@master ~]# kubectl get pod -n dev -o wide
NAME    READY   STATUS    RESTARTS   AGE     IP               NODE        NOMINATED NODE   READINESS GATES
nginx   1/1     Running   0          4m59s   10.244.169.135   k8s-node2   &lt;none&gt;           &lt;none&gt;

# 查看更加详细的关于Pod的描述
[root@master ~]# kubectl describe pods nginx -n dev
Name:         nginx
Namespace:    dev
Priority:     0
Node:         k8s-node2/192.168.88.102
Start Time:   Thu, 07 Apr 2022 18:12:27 +0800
Labels:       run=nginx
Annotations:  cni.projectcalico.org/containerID: 468f473e2f618ebfdefde078143e5585c406ae553c6ef72e9bb832dddb2cb465
              cni.projectcalico.org/podIP: 10.244.169.136/32
              cni.projectcalico.org/podIPs: 10.244.169.136/32
Status:       Running
IP:           10.244.169.136
IPs:
  IP:  10.244.169.136
Containers:
  nginx:
    Container ID:   docker://582fc46f31c50a0c154a81af05f6f1e762a12a4d2fc80e5df2a14a499580a0d6
    Image:          nginx:1.17.3
    Image ID:       docker-pullable://nginx@sha256:9688d0dae8812dd2437947b756393eb0779487e361aa2ffbc3a529dca61f102c
    Port:           80/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Sat, 09 Apr 2022 10:10:02 +0800
    Last State:     Terminated
      Reason:       Error
      Exit Code:    255
      Started:      Thu, 07 Apr 2022 18:12:31 +0800
      Finished:     Sat, 09 Apr 2022 10:09:07 +0800
    Ready:          True
    Restart Count:  1
    Environment:    &lt;none&gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xwb7n (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  kube-api-access-xwb7n:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       &lt;nil&gt;
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              &lt;none&gt;
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason          Age                   From               Message
  ----    ------          ----                  ----               -------
  Normal  Scheduled       40h                   default-scheduler  Successfully assigned dev/nginx to k8s-node2
  Normal  Pulled          40h                   kubelet            Container image "nginx:1.17.3" already present on machine
  Normal  Created         40h                   kubelet            Created container nginx
  Normal  Started         40h                   kubelet            Started container nginx
  Normal  SandboxChanged  4m6s (x3 over 4m34s)  kubelet            Pod sandbox changed, it will be killed and re-created.
  Normal  Pulled          4m5s                  kubelet            Container image "nginx:1.17.3" already present on machine
  Normal  Created         4m4s                  kubelet            Created container nginx
  Normal  Started         4m4s                  kubelet            Started container nginx
</code></pre> 
<p><strong>访问Pod</strong></p> 
<pre><code class="language-bash"># 首先可以查询一下Pod的IP地址
[root@master ~]# kubectl get pods -n dev -o wide
NAME    READY   STATUS    RESTARTS      AGE   IP               NODE        NOMINATED NODE   READINESS GATES
nginx   1/1     Running   1 (43m ago)   40h   10.244.169.136   k8s-node2   &lt;none&gt;           &lt;none&gt;

#然后使用curl命令进行访问
[root@k8s-node2 ~]# curl 10.244.169.137:80
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
&lt;p&gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&lt;/p&gt;

&lt;p&gt;For online documentation and support please refer to
&lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
Commercial support is available at
&lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;

</code></pre> 
<blockquote> 
 <p><strong>删除Pod</strong></p> 
 <pre><code class="language-bash"># 先使用get命令看看空间里面运行的Pod
[root@master ~]# kubectl get pod -n dev
NAME    READY   STATUS    RESTARTS        AGE
nginx   1/1     Running   2 (6h58m ago)   2d2h
# delete命令删除想要删除的命令？试试先
[root@master ~]# kubectl delete pod nginx -n dev
pod "nginx" deleted
# 去看看有没有删除成功
[root@master ~]# kubectl get pod -n dev
No resources found in dev namespace.
</code></pre> 
 <p>kubectl delete这个命令在新版的里面是可以直接删除Pod的 因为新版本不会自动创建Deployment了 但是在老版的里面只会重启Pod，所以在老版本里面需要这个后台（deployment）给直接干掉，所以我现在再重新创建一个Pod，再使用删除deployment的方法删除Pod。</p> 
 <p>在这个过程中我发现了一个问题，就是我在自己创建的namespace中新建pod之后，是看不到ns中有deployment的，然后在我去掉了-n dev之后，发现在default空间中有一个deployment，是我之前运行在default中的nginx，然后我使用delete命令删除这个pod，就出现了我之前提过的在老版的k8s中的情况：</p> 
 <pre><code class="language-bash">[root@master ~]# kubectl get pod
NAME                     READY   STATUS    RESTARTS       AGE
nginx-85b98978db-n2rfw   1/1     Running   4 (102m ago)   5d1h
[root@master ~]# ^C
[root@master ~]# kubectl delete pod nginx-85b98978db-n2rfw 
pod "nginx-85b98978db-n2rfw" deleted
[root@master ~]# kubectl get pod
NAME                     READY   STATUS              RESTARTS   AGE
nginx-85b98978db-qhz7j   0/1     ContainerCreating   0          5s
</code></pre> 
 <p>然后试试用删除deployment的方法：</p> 
 <pre><code class="language-bash">[root@master ~]# kubectl delete deployment nginx
deployment.apps "nginx" deleted
[root@master ~]# kubectl get pod
No resources found in default namespace.
[root@master ~]# 
</code></pre> 
 <p>只要deployment没了，Pod也就消失了这就是怎么样删除一个带有Pod控制器的pod。新版本的run会直接通过Controller创建一个pod，不会创建deployment对象</p> 
</blockquote> 
<h3>3、Label</h3> 
<p>          Label是Kubernetes系统中的一个重要概念，它的作用就是在资源上添加标识，用来对他们进行区分和选择。Label的特点：</p> 
<p>● 一个Label会以key/value的键值对的形式附加到各种对象上，如Node、Pod、Service</p> 
<p>● 一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源上去</p> 
<p>● Label通常在资源对象定义时确定，当然也可以在对象创建后动态添加或者删除</p> 
<p>           可以通过Label实现资源的多维度分组，以便灵活、方便的进行资源分配、调度、配置、部署等管理工作。</p> 
<blockquote> 
 <p>一些常用的Label示例如下：</p> 
 <p>        ● 版本标签：“version”：“release”，“version”：“stable”...</p> 
 <p>        ● 环境标签：“environment”：“dev”，“environment”：“test”，“environment”：“pro”</p> 
 <p>        ● 架构标签：“tier”：“fronted”，“tier”：“backend”</p> 
</blockquote> 
<p>标签定义完毕之后还要考虑到标签的选择，这就要用到Label Selector，即：</p> 
<p>   Label用于给某个资源对象定义标识</p> 
<p>   Label Selector用于查询和筛选拥有某些标签的资源对象</p> 
<p>当前有两种Label Selector：</p> 
<p>     ● 基于等式的Label Selector</p> 
<p>name = salve :选择所有包含Label中key=“name”且value="salve"的对象</p> 
<p>env !=production：选择所有包括Label中的key=“env”且value不等于production的对象</p> 
<p>     ● 基于集合的Label Selector</p> 
<p>name in (master,salve) : 选择所有包含Label中的key=“name”且value=“master”或“salve”的对象</p> 
<p>name not in (fronted) ：选择所有包含Label中的key="name"且value不等于fronted的对象</p> 
<p>        标签的选择条件可以使用多个，此时将多个Label Selector进行组合，使用逗号进行分隔即可。例如：</p> 
<p>                    name=slave，env!=production</p> 
<p>                    name not in (fronted)，env!=production</p> 
<p><strong>命令方式</strong></p> 
<pre><code class="language-bash"># 为Pod资源打标签
[root@master ~]# kubectl label pod nginx version=1.0 -n dev
pod/nginx labeled

# 为Pod资源更新标签
[root@master ~]# kubectl label pod nginx version=2.0 -n dev --overwrite
pod/nginx labeled

# 查看标签
[root@master ~]# kubectl get pod nginx  -n dev --show-labels
NAME    READY   STATUS    RESTARTS      AGE   LABELS
nginx   1/1     Running   1 (11h ago)   13h   run=nginx,version=2.0

# 筛选标签
[root@master ~]# kubectl get pod  -n dev -l version=2.0 --show-labels
NAME    READY   STATUS    RESTARTS      AGE   LABELS
nginx   1/1     Running   1 (11h ago)   13h   run=nginx,version=2.0
[root@master ~]# kubectl get pod  -n dev -l version!=2.0 --show-labels
No resources found in dev namespace.

# 删除标签(使用的是打标签的方式，在想要删除的标签后面打上减号)
[root@master ~]# kubectl label pod nginx -n dev version-
pod/nginx unlabeled
[root@master ~]# kubectl get pod  -n dev -l version!=2.0 --show-labels
NAME    READY   STATUS    RESTARTS      AGE   LABELS
nginx   1/1     Running   1 (11h ago)   13h   run=nginx

</code></pre> 
<p><strong>配置方式</strong></p> 
<pre><code class="language-bash"># 首先创建一个YAML文件
apiVersion: v1
kind: Pod
metadata:
  name: nginx1
  namespace: dev
  #这里打两个标签
  labels:
    version: "3.0"
    env: "test"
spec:
  containers:
  - image: nginx:1.71.1
    name: pod
    ports:
    -  name: nginx1-port
       containerPort: 80
       protocol: TCP
[root@master ~]# kubectl apply -f nginx1.yaml
pod/nginx1 created
[root@master ~]# kubectl get pod -n dev --show-labels
NAME     READY   STATUS    RESTARTS      AGE    LABELS
nginx    1/1     Running   1 (13h ago)   15h    run=nginx
nginx1   1/1     Running   0             114s   env=test,version=3.0</code></pre> 
<h3>4、Deployment</h3> 
<p>       在Kubernetes，Pod是最小的控制单元，但是Kubernetes很少直接控制Pod，一般都是通过Pod控制器来完成的。Pod控制器用于Pod的管理，确保Pod资源符合预期的状态，当Pod资源出现故障时，会尝试进行重启或重建Pod。</p> 
<p>       在Kubernetes中Pod控制器的种类有很多，这里先介绍一种：<span style="color:#fe2c24;"><strong>Deployment</strong></span></p> 
<p class="img-center"><img alt="" height="323" src="https://images2.imgbox.com/04/a8/zIaWigsI_o.png" width="587"></p> 
<p><strong> 命令操作</strong></p> 
<pre><code class="language-bash"># 命令格式 ：kubectl create deploy &lt;deployment名称&gt; '
# --image 指定pod的镜像
# --port  指定端口
# --replicas 指定创建pod的数量
# --namespace 指定namespace
[root@master ~]# kubectl create deploy nginx --image=nginx --port=80 --replicas=3 -n dev
deployment.apps/nginx created
[root@master ~]# kubectl get pod -n dev
NAME                     READY   STATUS    RESTARTS      AGE
nginx                    1/1     Running   1 (15h ago)   17h
nginx-74d589986c-bsv2h   1/1     Running   0             47s
nginx-74d589986c-nxv5d   1/1     Running   0             47s
nginx-74d589986c-tbpv2   1/1     Running   0             47s
</code></pre> 
<p>可以看到dev中已经新建了三个新的nginx的pod，查看一下这个deployment</p> 
<pre><code class="language-bash">[root@master ~]# kubectl describe deployment nginx -n dev
Name:                   nginx
Namespace:              dev
CreationTimestamp:      Sun, 10 Apr 2022 14:15:09 +0800
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   nginx-74d589986c (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  6m8s  deployment-controller  Scaled up replica set nginx-74d589986c to 3
</code></pre> 
<pre><code class="language-bash"># 删除这个deployment
[root@master ~]# kubectl delete deploy nginx -n dev
deployment.apps "nginx" deleted
[root@master ~]# kubectl get pod -n dev
NAME     READY   STATUS    RESTARTS      AGE
nginx    1/1     Running   1 (16h ago)   18h
</code></pre> 
<p><strong>配置操作</strong></p> 
<p><strong>        </strong>创建一个deploy-nginx.yaml 内容如下</p> 
<pre><code class="language-bash">apiVersion : apps/v1
kind : Deployment
metadata:
  name: nginx
  namespace: dev
spec:
  replicas: 3
  selector:
    matchLabels:
      run: nginx
  template:
    metadata:
      labels:
        run: nginx
    spec:
      containers:
      -  image: nginx
         name: nginx
         ports:
         -  containerPort: 80
            protocol: TCP
[root@master ~]# kubectl create -f deploy-nginx.yaml 
deployment.apps/nginx created
[root@master ~]# vi deploy-nginx.yaml
[root@master ~]# kubectl get pod -n dev
NAME                    READY   STATUS    RESTARTS      AGE
nginx                   1/1     Running   1 (17h ago)   19h
nginx-69ccc6c65-4tw7n   1/1     Running   0             3m18s
nginx-69ccc6c65-7sw85   1/1     Running   0             3m18s
nginx-69ccc6c65-hv5bq   1/1     Running   0             3m18s
nginx1                  1/1     Running   0             3h40m
[root@master ~]# kubectl get deploy -n dev
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   3/3     3            3           3m28s
                      </code></pre> 
<h3> 5、Service</h3> 
<p>       虽然每个Pod都会被分配一个单独的Pod IP，然而却存在着如下的两个问题：</p> 
<p>              ● Pod IP会随着Pod的重建产生变化</p> 
<p>              ● Pod IP仅仅只是集群内可见的虚拟IP，外部无法访问</p> 
<p>       这样对于访问这个服务就带来了困难，也正因如此，Kubernetes设计了Service来解决这个问题。Service可以看做是<strong>一组同类Pod对外的访问接口。</strong>借助Service，应用可以方便的实现服务发现和负载均衡</p> 
<p><img alt="" class="right" height="358" src="https://images2.imgbox.com/36/21/lTmkcC1M_o.png" width="763"></p> 
<p>        Service作为对外访问的接口，收到一个请求后，直接到达Service上，Service再根据标签选择器去寻找对应的Pod。</p> 
<blockquote> 
 <p><strong>操作一：创建集群内部可访问的Service</strong></p> 
 <pre><code class="language-bash"># 暴露Service 指定名称、类型、端口号、目标端口号（从Service的80端口转发的pod的80端口）
[root@master ~]# kubectl expose deploy nginx --name=svc-nginx1 --type=ClusterIP --port=80 --target-port=80 -n dev
service/svc-nginx1 exposed
</code></pre> 
 <p>现在就可以直接通过Service的IP：端口来对里面的Pod进行访问了</p> 
 <pre><code class="language-bash">[root@master ~]# kubectl get svc -n dev
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
svc-nginx1   ClusterIP   10.110.30.14   &lt;none&gt;        80/TCP    5m45s
[root@master ~]# curl 10.110.30.14:80
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
&lt;p&gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&lt;/p&gt;

&lt;p&gt;For online documentation and support please refer to
&lt;a href="http://nginx.org/"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
Commercial support is available at
&lt;a href="http://nginx.com/"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre> 
</blockquote> 
<blockquote> 
 <p><strong>操作二：创建集群外部也可访问的Service </strong></p> 
 <p>       上面创建的Service的type类型为ClusterIP，这个IP地址只有集群内部可以进行访问，如果需要创建集群外部也可以进行访问的Service，需要修改type为NodePort</p> 
 <pre><code class="language-bash">[root@master ~]# kubectl expose deploy nginx --name=svc-nginx2 --type=NodePort --port=80 --target-port=80 -n dev
service/svc-nginx2 exposed
[root@master ~]# kubectl get svc -n dev
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
svc-nginx1   ClusterIP   10.110.30.14     &lt;none&gt;        80/TCP         33m
svc-nginx2   NodePort    10.110.131.245   &lt;none&gt;        80:31431/TCP   25s</code></pre> 
 <p>这里，访问主机的相应端口号：192.168.88.100:31431</p> 
 <p class="img-center"><img alt="" height="432" src="https://images2.imgbox.com/75/55/5pbam2G6_o.png" width="1041"></p> 
</blockquote> 
<p><strong>删除Service </strong></p> 
<pre><code class="language-bash">[root@master ~]# kubectl delete svc svc-nginx2 -n dev
service "svc-nginx2" deleted
</code></pre> 
<p></p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/67978b80f99fb08bd92d44e39ddc88a6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Rust基础-关于Option</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/571f0f2780e9404c17218b1c44699cf3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">超详细前端八股文</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>