<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>支持向量机简介 - 编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="支持向量机简介" />
<meta property="og:description" content="支持向量机（SVM）是一类非常经典的算法，在深度学习成为主流之前，曾一度统治着机器学习界。支持向量机就是要在两个类别中找到一条分隔边界，这条分隔边界可以很好的分开两个类别，并且这个边界到两个类别的距离是最大的。其中两个类别中到这条边界最近的向量叫做支持向量。如下图所示：
支持向量机一般分为三种：线性可分支持向量机，线性支持向量机（也叫软间隔支持向量机，近似线性可分支持向量机），非线性支持向量机。
一般我们所说的就是线性可分支持向量机，事实上，现实生活中更多的是近似线性可分的情况。所谓的“软间隔”就是允许某些样本不满足约束条件，但是在最大化间隔的同时，不满足约束的样本应该尽可能少。
而非线性支持向量机，就是指两个类别的间隔不再是一条直线，而是非线性的，如下图所示：
由于支持向量机算法比较复杂，涉及数学知识较多，我这次就直接用sklearn实现了，从应用角度出发，数学原理方面的内容可以参考周志华的《机器学习》和李航的《统计学习方法》，里面讲的很清楚。
下面我们通过具体的程序来熟悉一下支持向量机的使用方法。首先，从sklearn自带的鸢尾花数据集开始：
import numpy as np from sklearn import datasets from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler from sklearn.svm import LinearSVC iris = datasets.load_iris() X = iris[&#34;data&#34;][:,(2,3)] # 长度，宽度 y = (iris[&#34;target&#34;]==2).astype(np.float64) # 第二种类型的鸢尾花 svm_clf = Pipeline([(&#34;scaler&#34;, StandardScaler()), (&#34;linear_svc&#34;, LinearSVC(C=1, loss=&#34;hinge&#34;))]) # pipeline是一种类似流水线的机制 # LinearSVC，代表线性支持向量机，C是一个用来进行正则化的参数，C越小，错分会越多， # 但是泛化性较好；C越大，错分越少，但容易过拟合， # hinge损失函数 svm_clf.fit(X,y) # 预测 svm_clf.predict([[5.5,1.7]]) # 输出：array([1.]) 这里我们使用鸢尾花的长度和宽度特征来训练，标签值为是否是第二种类型的鸢尾花，1代表是，0代表否。使用pipeline机制对特征进行标准化，然后使用一个线性支持向量机来学习。可以看到，预测时候，给出特定的鸢尾花长度和宽度，即可判断该鸢尾花是否是第二种鸢尾花类型。
上次我们在介绍逻辑回归的时候使用过手写数字识别数据集，现在用支持向量机SVM来试试结果如何。
from sklearn.svm import SVC digits = datasets.load_digits() x = digits[&#39;data&#39;] y = digits[&#39;target&#39;] svm_clf = SVC(kernel=&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/95776c560ecbafa02e3ea1ea67400b82/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-22T16:37:25+08:00" />
<meta property="article:modified_time" content="2023-11-22T16:37:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">支持向量机简介</h1>
			
		</header>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>支持向量机（SVM）是一类非常经典的算法，在深度学习成为主流之前，曾一度统治着机器学习界。支持向量机就是要在两个类别中找到一条分隔边界，这条分隔边界可以很好的分开两个类别，并且这个边界到两个类别的距离是最大的。其中两个类别中到这条边界最近的向量叫做支持向量。如下图所示：</p> 
<p><img alt="" height="472" src="https://images2.imgbox.com/ad/7c/JbGXHKpa_o.png" width="672"></p> 
<p>支持向量机一般分为三种：线性可分支持向量机，线性支持向量机（也叫软间隔支持向量机，近似线性可分支持向量机），非线性支持向量机。</p> 
<p>一般我们所说的就是线性可分支持向量机，事实上，现实生活中更多的是近似线性可分的情况。所谓的“软间隔”就是允许某些样本不满足约束条件，但是在最大化间隔的同时，不满足约束的样本应该尽可能少。</p> 
<p><img alt="" height="465" src="https://images2.imgbox.com/97/58/qJHc9TDr_o.png" width="664"></p> 
<p>而非线性支持向量机，就是指两个类别的间隔不再是一条直线，而是非线性的，如下图所示：</p> 
<p><img alt="" height="499" src="https://images2.imgbox.com/ac/d3/PbQSqtFE_o.png" width="777"></p> 
<p>由于支持向量机算法比较复杂，涉及数学知识较多，我这次就直接用sklearn实现了，从应用角度出发，数学原理方面的内容可以参考周志华的《机器学习》和李航的《统计学习方法》，里面讲的很清楚。</p> 
<p>下面我们通过具体的程序来熟悉一下支持向量机的使用方法。首先，从sklearn自带的鸢尾花数据集开始：</p> 
<pre><code class="language-python">import numpy as np
from sklearn import datasets
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC

iris = datasets.load_iris()
X = iris["data"][:,(2,3)] # 长度，宽度
y = (iris["target"]==2).astype(np.float64) # 第二种类型的鸢尾花
svm_clf = Pipeline([("scaler", StandardScaler()), 
                    ("linear_svc", LinearSVC(C=1, loss="hinge"))]) # pipeline是一种类似流水线的机制
# LinearSVC，代表线性支持向量机，C是一个用来进行正则化的参数，C越小，错分会越多，
# 但是泛化性较好；C越大，错分越少，但容易过拟合，
# hinge损失函数
svm_clf.fit(X,y)

# 预测
svm_clf.predict([[5.5,1.7]])
# 输出：array([1.])</code></pre> 
<p>这里我们使用鸢尾花的长度和宽度特征来训练，标签值为是否是第二种类型的鸢尾花，1代表是，0代表否。使用pipeline机制对特征进行标准化，然后使用一个线性支持向量机来学习。可以看到，预测时候，给出特定的鸢尾花长度和宽度，即可判断该鸢尾花是否是第二种鸢尾花类型。</p> 
<p>上次我们在介绍逻辑回归的时候使用过手写数字识别数据集，现在用支持向量机SVM来试试结果如何。</p> 
<pre><code class="language-python">from sklearn.svm import SVC

digits = datasets.load_digits()
x = digits['data']
y = digits['target']
svm_clf = SVC(kernel="poly",max_iter=1000) # 采用多项式核函数训练

svm_clf.fit(x,y)

# 预测
x0 = x[5].reshape(1,-1)
print(svm_clf.predict(x0))
print(y[5])
# 输出：[5] 5</code></pre> 
<p>我这里采用了支持向量机分类器来训练，SVC是通用的支持向量机分类器，可以通过指定参数kernel来设置所使用的核函数，SVC支持的核函数有以下几种：</p> 
<p>’linear’：线性核函数</p> 
<p>‘poly’：多项式核函数</p> 
<p>‘rbf’：高斯核函数</p> 
<p>‘sigmod’：sigmod核函数</p> 
<p>‘precomputed’：核矩阵，表示自己提前计算好核函数矩阵，这时候算法内部就不再用核函数去计算核矩阵，而是直接用你给的核矩阵，核矩阵需要为n*n的。</p> 
<p>我这里选择了多项式核函数进行训练。预测值为5，真实值也是5，可以看到预测的结果还是比较准确的。</p> 
<pre><code class="language-python">import matplotlib.pyplot as plt
plt.imshow(digits['images'][5],cmap='gray') # 显示出数字图像
plt.show()</code></pre> 
<p><img alt="" height="413" src="https://images2.imgbox.com/24/74/fTrkQLkM_o.png" width="408"></p> 
<p>下面我们尝试一下非线性数据集，看看sklearn效果如何。我们先用sklearn自带的make_moons()函数生成数据集并可视化。</p> 
<pre><code class="language-python">from sklearn.datasets import make_moons
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from matplotlib import pyplot as plt

X,y = make_moons(n_samples=100, noise=0.15)
print(X.shape)
print(y.shape)
# 输出：
# (100, 2)
# (100,)
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)</code></pre> 
<p><img alt="" height="413" src="https://images2.imgbox.com/09/52/d8TtNkJ5_o.png" width="568"></p> 
<p>可见，模拟了100个数据，X的维度是(100,2)，100行2列，我们把一列作为纵坐标，一列作为横坐标，y作为颜色值区分类型，画出了图形，可以看到有很明显的非线性特征，无法用一条直线将两个数据集分开。</p> 
<p>下面我们尝试用支持向量机分隔两类数据。</p> 
<pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC
from sklearn.svm import SVC
svm_clf = Pipeline([("poly_features", PolynomialFeatures(degree=3)),
                    ("sclaer",StandardScaler()),("svm_clf",LinearSVC(C=10, loss="hinge"))])

svm_clf.fit(X,y)</code></pre> 
<p>这里我用了一个多项式回归特征，degree=3代表了生成的是三次多项式，最后通过线性SVC来进行训练，C是一个惩罚变量，如果C越大，分类会越精确但是可能存在过拟合的情况，C越小相当于允许犯错，泛化能力较强。我们把训练后的结果用等高线contourf画出来，可以清晰的看到分隔边界。np.meshgrid根据给出的x坐标点和y坐标点生成更多的点，用每个x去和每个y分别配对，得到更多的坐标，然后去预测得到结果，把结果z作为高度，画出等高线，也就得到了分隔边界。</p> 
<pre><code class="language-python"># 生成两个坐标轴的范围，生成密集可以看得更清楚
x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5 
y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5
h=0.01
print(np.arange(y_min,y_max,h).shape) # 输出：(282,)
xx,yy=np.meshgrid(np.arange(x_min,x_max,h),np.arange(y_min,y_max,h))
print(xx.shape) # 输出：(282, 440)
print(yy.shape) # 输出：(282, 440)
# ravel表示把数组拉成一维数组，np.c_表示把按列拼接两个矩阵
z=svm_clf.predict(np.c_[xx.ravel(),yy.ravel()]) 
z=z.reshape(xx.shape) # 转换成跟xx一样的维度
plt.contourf(xx, yy, z, cmap=plt.cm.Paired, alpha=0.8) # 按z来画出决策边界
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired) # 按y来画出原始数据的散点图
plt.show()</code></pre> 
<p><img alt="" height="413" src="https://images2.imgbox.com/df/f8/wOKRv2OA_o.png" width="559"></p> 
<p>可以看到，划分的还是比较准确的。</p> 
<p>如果采用高斯核函数的话，看看决策边界是怎么样的。</p> 
<pre><code class="language-python">rbf_svm_clf = Pipeline([("sclaer",StandardScaler()),
                        ("svm_clf",SVC(kernel="rbf", gamma=5, C=0.001))])
rbf_svm_clf.fit(X,y)
# 生成两个坐标轴的范围，生成密集可以看得更清楚
x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5 
y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5
h=0.01
print(np.arange(y_min,y_max,h).shape)
xx,yy=np.meshgrid(np.arange(x_min,x_max,h),np.arange(y_min,y_max,h))
print(xx.shape)
print(yy.shape)
# ravel表示把数组拉成一维数组，np.c_表示把按列拼接两个矩阵
z=rbf_svm_clf.predict(np.c_[xx.ravel(),yy.ravel()]) 
z=z.reshape(xx.shape) # 转换成跟xx一样的维度
plt.contourf(xx, yy, z, cmap=plt.cm.Paired, alpha=0.8) # 按z来画出决策边界
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired) # 按y来画出原始数据的散点图
plt.show()</code></pre> 
<p>gamma类似于C，也是一个正则项参数，只对核函数是rbf和sigmoid时生效。gamma越大越容易过拟合。画出决策边界，如下图所示：</p> 
<p><img alt="" height="413" src="https://images2.imgbox.com/06/43/j5xXGyyn_o.png" width="559"></p> 
<p>可以看到，gamma值越大，模型越倾向于准确划分每个训练数据，从而会导致过拟合的问题，所以需要通过C来做正则化，在精度和泛化性中做权衡。</p> 
<p>最后，我们尝试用sklearn提供的人脸数据集实现一个简单的人脸识别程序，看看SVM的效果。</p> 
<pre><code class="language-python">from sklearn.datasets import fetch_lfw_people

lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)
n_samples, h, w = lfw_people.images.shape
n_samples,h,w # 输出：(1288, 50, 37)

X = lfw_people.data
n_features = X.shape[1]
# the label to predict is the id of the person
y = lfw_people.target
target_names = lfw_people.target_names
n_classes = target_names.shape[0]

print("Total dataset size:")
print("n_samples: %d" % n_samples)
print("n_features: %d" % n_features)
print("n_classes: %d" % n_classes)</code></pre> 
<pre><code class="language-python"># 输出：
Total dataset size:
n_samples: 1288
n_features: 1850
n_classes: 7</code></pre> 
<p>由于LFW数据比较大，所以并不能像鸢尾花数据集iris那样直接导入，需要额外下载，如果下载不了可以百度搜索一下，通过国内的某些链接来进行下载和部署。</p> 
<p>下载后就可以正常使用了。可以看到人脸数据集一共有1288张图像，经过处理后的大小为50*37=1850个像素。类别为7类，也就是7个人。下面列出数据集中的前10张图片以及标签，也就是人名。</p> 
<pre><code class="language-python">import matplotlib.pyplot as plt 

fig = plt.figure(figsize=(20,20))
for i in range(1,11):
    ax = fig.add_subplot(1,10,i)
    ax.imshow(images[i-1],cmap='gray')
    ax.axis('off') # 关闭坐标轴
    ax.set_title(target_names[y[i-1]])

plt.show()</code></pre> 
<p><img alt="" height="217" src="https://images2.imgbox.com/a8/5d/6cSmLJtO_o.png" width="1200"></p> 
<p>先进行训练：</p> 
<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV, train_test_split
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)
svm_clf = Pipeline([("scaler",StandardScaler()),
                    ("svm_clf",SVC(kernel="linear", gamma=5, C=0.001))])
svm_clf.fit(X_train, y_train)</code></pre> 
<p>验证预测的精度：</p> 
<pre><code class="language-python">y_pred = svm_clf.predict(X_test)
correct = 0
for i in range(len(y_test)):
    if y_pred[i] == y_test[i]:
        correct += 1
print("accuracy: %f" % (correct/len(y_test)))
# 输出：accuracy: 0.835404</code></pre> 
<p>总体精度84%，下面打印出分类预测报告：</p> 
<pre><code class="language-python">from sklearn.metrics import ConfusionMatrixDisplay, classification_report
print(classification_report(y_test, y_pred, target_names=target_names))</code></pre> 
<pre><code class="language-python">                   precision    recall  f1-score   support

     Ariel Sharon       0.57      0.62      0.59        13
     Colin Powell       0.77      0.88      0.82        60
  Donald Rumsfeld       0.68      0.63      0.65        27
    George W Bush       0.89      0.92      0.90       146
Gerhard Schroeder       0.88      0.84      0.86        25
      Hugo Chavez       0.92      0.73      0.81        15
       Tony Blair       0.93      0.69      0.79        36

         accuracy                           0.84       322
        macro avg       0.80      0.76      0.78       322
     weighted avg       0.84      0.84      0.83       322</code></pre> 
<p>我们下面展示前十张图片，以及图片的真实人物名字和预测的人物名字：</p> 
<pre><code class="language-python">fig = plt.figure(figsize=(20,10))
for i in range(1,11):
    ax = fig.add_subplot(2,5,i)
    ax.imshow(X_test[i-1].reshape(h,w),cmap='gray')
    ax.axis('off') # 关闭坐标轴
    ax.set_title("pred:{}\ntrue:{}".format(target_names[y_pred[i-1]],target_names[y_test[i-1]]))

plt.show()</code></pre> 
<p><img alt="" height="827" src="https://images2.imgbox.com/61/79/YoU4tfzx_o.png" width="1200"></p> 
<p>可以看到，基本还是比较准确的。</p>
                </div>
		</div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3f7cab0935b1b97b9c3013358dca145e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Targeting S&#43; (version 31 and above) requires that one of FLAG_IMMUTABLE or FLAG_MUTABLE be specified</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0987d40328fcfa65e2c86bedb78a44bb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">AHB总线介绍</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>