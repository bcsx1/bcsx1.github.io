<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta name="generator" content="Hugo 0.121.1">
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>编程随想</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="编程随想的博客">
		<meta property="og:title" content="编程随想" />
<meta property="og:description" content="编程随想的博客" />
<meta property="og:type" content="website" />
<meta property="og:url" content="/" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="alternate" type="application/rss+xml" href="/index.xml" title="编程随想">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程随想" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程随想</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main list" role="main">
	<article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/48c0710ae7f4a8bfc5cb14e8829c0140/" rel="bookmark">
			人人都在谈的 “数据驱动” 到底是什么？你确认自己做的是数据驱动吗？
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		导读：移动互联网技术的快速发展，移动终端的广泛普及，催生了大数据技术。今天，无论是个人的日常生活，还是企业的业务发展，都和数据密切相关，大数据技术正成为新发明、新产品和新服务的创新源泉。
近几年，各种驱动在天上飘，有产品驱动、技术驱动、政策驱动还有老板驱动，大数据也不甘寂寞，于是乎“数据驱动”一词渐渐热了起来。很多企业都说自己在搞数据驱动，也有不少从事数据技术的公司在对外提供数据驱动的技术咨询和实施服务。各个行业都在激动地讨论着“数据驱动”，有些公司甚至宣称已经实现了“数据驱动”。
像大数据和区块链一样，很多人似是而非地讨论着数据驱动，而且数据驱动逐渐也有很大希望继在大数据、区块链之后成为另外一个忽悠人民恐吓百姓的民俗化名词。那么到底什么是数据驱动呢？你真的在做数据驱动吗？
01 何为“数据驱动”
在讨论数据驱动前，首先让我们看一个例子，打开手机移动应用Uber，APP页面会有优惠码提示：转发优惠码，如有下线使用该优惠码，你将获得优惠；在用车时，APP会根据坐车时间段和车辆紧张程度，提醒溢价的倍数，你如果不接受，则订单取消；打车结束后，APP自动选择优惠券进行结算，无需手动选择；最后你的邮箱将收到此次打车的中英文版本的邮件。整个过程全部由系统自动完成，无需人工决策。包括转发优惠码的部分，也是由系统自动提醒，刺激用户点击完成的。
由此可见，数据驱动是通过移动互联网或者其他的相关软件为手段采集海量的数据，将数据进行组织形成信息，之后对相关的信息进行整合和提炼，在数据的基础上经过训练和拟合形成自动化的决策模型。当新的情况发生，新数据输入的时候，系统可以用前面建立的模型以人工智能的方式直接进行决策。如下图所示，信号、数据、信息、情报、知识、智慧，一环扣一环，不断地上升迭代，完成一个又一个决策。 信号是机器可读的模拟或者数字脉冲，数据是人类可读的信号，信息是经过索引后可以查询的组织化的数据，而情报是对特定人在特定场景下有针对性的信息，知识是大量情报积累后可以改变人的知识结构的部分，智慧是基于知识和经验可用于决策的部分。这个决策在人工智能时代就是基于数据和算法，特别是机器学习建立模型和使用模型的决策。因为在移动互联网时代，业务需要海量毫秒级的瞬间决策，这是人类决策无法完成的。另外，人是感情动物，所有的决策会夹杂着情绪、亲情、关系等社会关系，所做的决策未必是完全客观的，很有可能添加了主观因素。基于数据和模型的数据驱动决策是更加靠谱的方式。
但是这个过程需要数据的不断输入，需要模型根据比对决策结果和现实数据把偏差信息反馈给机器学习，在其后不断的机器学习迭代过程中自我完善。从这个过程的描述中我们可以看到，数据驱动对企业的要求非常高，要有流式的数据不断地注入，要有以机器学习为基础的决策模型，要有能依赖模型输出结果可以推动的业务系统，要有可以反馈预测偏差的反馈机制。
现在大家常听到“数据驱动”，也有很多公司对外宣称其实现了“数据驱动”，诸如“这是一家数据驱动公司”等话语比比皆是。但它果真是一家“数据驱动”公司么？
02 “数据驱动”的特征
在一个真正的数据驱动的企业，数据是提供报告、深度模拟预测的来源，企业决策者应该将数据分析纳入公司决策流程，并对公司的决策提供价值和影响。数据驱动企业最大的特点是拥有一套完整的数据价值体系。数据价值体系指的是一套完整的从数据收集、整理、报告到转化成行业洞见和决策建议的流程。而落实到操作层面则是通过对数据的收集、整理、提炼，总结出规律形成一套智能模型，之后通过人工智能的方式作出最终的决策。因此，真正的数据驱动公司应该具备以下特征：
1、海量的数据；
2、自动化的业务；
3、强大的模型支持自动化决策。
这三个条件缺一不可，并形成一个循环，不断地进行数据收集，完成建模，自动决策。
03 何为“以数据为中心”
到目前为止，好多宣称自己是“数据驱动”业务的公司，其实并没有真正的做到“数据驱动”，也许他只是一个“以数据为中心”进行决策的公司，只是在利用数据，并没有真正实现数据的价值。
“以数据为中心进行决策”的方式与“数据驱动”相比，他没有“数据驱动”那样的智能，也没有“数据驱动”那样的高效。“以数据为中心进行决策”顾名思义就是用数据来支持决策，这些数据包括历史记录中的和现在产生的。通过对数据的整理、抽取，将数据转化为可读的知识，形成分析结果，决策者根据分析报告的结果考虑并决定决策结果，最终决策由人为参与。
举一个简单的例子，假设有A 和 B两家订票网站，A 公司将从网站收集到的数据进行分析，通过数据分析结果认为五一是出行高峰，于是决定抬高价格，并手动从后台调整了五一前后的机票价格和酒店价格。
B 公司则通过自动化手段实时收集、分析相关信息，总结规律，形成智能模型，当用户进行搜索时，后台自动根据模型规则，对价格进行调整。
这2个公司，哪家是数据驱动型的公司呢？
显而易见，公司 B 是数据驱动型的公司，而公司 A 则是一家“以数据为中心进行决策”的公司。
“以数据为中心进行决策”的公司，表面上公司所有人员，如产品、运营、技术、销售都可以贡献数据，也可以从数据里得出东西，但中间做决策的是人。如 A 公司，最终由人来决定机票是否提价。
04 数据即未来
那么该如何真正的打造一个“数据驱动”的项目或公司呢？现在市面上关于大数据的书籍汗牛充栋，扔出去一块砖也可以砸到N个大数据专家。但是数据科学作为一门严肃的新学科方兴未艾，真正关于利用数据科学的方法论解决实际工作中的数据科学问题的实践书籍少之又少。Brian Godsy（布瑞恩·戈德西）在他的《数据即未来》一书详细介绍了数据科学项目的三个阶段：
1、准备阶段进行信息收集；
2、构建阶段将计划付诸行动，利用准备阶段获得的信息以及相关统计和软件提供的可用工具来构建产品；
3、交付阶段进行产品的交付、反馈及修改等。
书中还会教你如何预见问题以及如何处理不确定性，一步步引导你完成软件和科学思维的最佳实践，堪称“数据驱动”方面的扛鼎之作。
作者 / 来源：泡面办公室
延伸阅读《数据即未来》
点击小程序了解及购买本书
点击文末右下角“写留言”发表你的观点
推荐阅读
日本老爷爷坚持17年用Excel作画，我可能用了假的Excel···
180页PPT，讲解人工智能技术与产业发展
终于有人把云计算、大数据和人工智能讲明白了！
数据告诉你：跟缺“芯”相比，中国当前的这个问题更致命！
Q: 关于数据驱动，你现在了解了多少？
欢迎留言与大家分享
觉得不错，请把这篇文章分享给你的朋友
转载 / 投稿请联系：baiyu@hzbook.com
更多精彩文章，请在公众号后台点击“历史文章”查看
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/bb8d788616f95f9ba573620d40e09fef/" rel="bookmark">
			linux安装redis 完整步骤
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		最近在linux服务器上需要安装redis，来存放数据，增加用户访问数据的速度，由于是第一次安装，于是在百度上搜了一篇文章，按照这篇博客，顺利安装好了，因此将博主的文章拷过来记录一下，方便以后使用，也为需要的朋友提供一个方便，
参考博文地址：https://www.cnblogs.com/lauhp/p/8487029.html
安装：
1.获取redis资源
wget http://download.redis.io/releases/redis-4.0.8.tar.gz
2.解压
tar xzvf redis-4.0.8.tar.gz
3.安装
cd redis-4.0.8
make
cd src
make install PREFIX=/usr/local/redis
4.移动配置文件到安装目录下
cd ../
mkdir /usr/local/redis/etc
mv redis.conf /usr/local/redis/etc
5.配置redis为后台启动
vi /usr/local/redis/etc/redis.conf //将daemonize no 改成daemonize yes
6.将redis加入到开机启动
vi /etc/rc.local //在里面添加内容：/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf (意思就是开机调用这段开启redis的命令)
7.开启redis
/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf 常用命令　redis-server /usr/local/redis/etc/redis.conf //启动redis
pkill redis //停止redis
卸载redis：
rm -rf /usr/local/redis //删除安装目录
rm -rf /usr/bin/redis-* //删除所有redis相关命令脚本
rm -rf /root/download/redis-4.0.4 //删除redis解压文件夹
8-启动redis:两种方式： redis-server &amp; 加上`&amp;`号使redis以后台程序方式运行 或者是
redis-server 9-检测后台进程是否存在 ps -ef |grep redis 10-检测6379端口是否在监听 netstat -lntp | grep 6379 有时候会报异常
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/bb8d788616f95f9ba573620d40e09fef/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/2a98179d3f766e280a2c525edff8c2cb/" rel="bookmark">
			c#动态创建数组
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 ﻿变相创建
public double[,] setArray(string i, string j) { //可以先对i和j做数字判断。 return new double[int.Parse((i != "" ? i : "1")), int.Parse((j != "" ? j : "1"))]; } 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/83f9afba3f986931a9fb30a8f5f11bb1/" rel="bookmark">
			关于学术论文投稿中的 Cover Letter
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		学术期刊报道原始研究工作的论文，一般分为需要快速发表的通信、快报类（communication, letter等）和报道系统研究工作的全文类（full paper, article）两种形式。投这两种文章，cover letter和论文Introduction的写法是不同的。
对于需要以通讯或快报形式快速发表的工作，可以是初步的研究结果(preliminary result)，强调的是工作的新颖性和重要性，因此，cover letter和论文中的Introduction怎么写，就很重要，千万不能只是客套几句，cover letter是写给主编（或编辑），如果他觉得新颖性没有足够的吸引力，审都不必审了。cover letter一般不会给审稿人，所以，说服审稿人你的工作值得快速发表，就是论文的Introduction了，不必长篇回顾，直接强调与众不同的新颖性，要写得吸引眼球。
如果是报道系统工作的全文，cover letter和论文Introduction需要注重写你的工作解决了什么科学问题，介绍你工作的完整性。特别是Introduction，要对前人相关的工作做一个回顾（有的论文甚至写成一个小的review），当然，与众不同之处也是要说的，没有新颖性的工作就不是研究论文了。
除了那些专门发表通讯、快报的杂志，一般的杂志，通信快报类的文章只占所有文章的很少一部分（不到10%），所以，难度可想而知。如果没有足够的新颖性说服编辑和审稿人你的工作需要快速发表，最好还是把工作做全了发full paper。
英文论文投稿信Cover letter模板
Case 1
Dear Editor,
We would like to submit the enclosed manuscrīpt entitled "GDNF Acutely Modulates Neuronal Excitability and A-type Potassium Channels in Midbrain Dopaminergic Neurons", which we wish to be considered for publication in Nature Neuroscience.
GDNF has long been thought to be a potent neurotrophic factor for the survival of midbrain dopaminergic neurons, which are degenerated in Parkinson’s disease.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/83f9afba3f986931a9fb30a8f5f11bb1/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/9e006ce04eaf1af673beadc9a3ca25c8/" rel="bookmark">
			关于bitset中的 to_ulong()的解答
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		做题时碰到了一个程序用到了bitset，但是在输出时却用到了to_ulong()来输出，刚开始没搞明白，在经历了一番摸索后终于搞明白了，这个to_ulong()是用来控制bitset中的输出宽度的，输出与bitset&lt;kuandu&gt; ming(chushizhi) to_ulong()可以控制输出的最大限度，例如 kuandu是4，那么在输出时，每次结果都是 模除 2^4 - 1；如果宽度是5 那么结果都是 结果模除 2^5 - 1
以此类推
注意注意注意
这个to_ulong() 只能用于bitset
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/bf773808cc20a664d7e07239902b5740/" rel="bookmark">
			ifstream
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 fstream 是一个文件， 在这个文件中写了ifstream ofstream这两个类。 所以，你包含了fstream 就可以使用ifstream 和 ofstream。 文件的输入，就是从文件里输入到内存 用ifstream。 文件的输出，就是从内存输出到文件 用ofstream。 通俗的说：写到文件中时，用ofstream。 从文件里读出数据的时候用ifstream。 #include &lt;iostream&gt; #include &lt;fstream&gt; using namespace std; int main() { ifstream ifs; //创建一个输入流对象 char buf[64] = {0}; ifs.open("sad.txt", ios::in); //以读的方式打开文件 if(!ifs) //如果不存在这个文件报错 { cout&lt;&lt;"open failure"&lt;&lt;endl; } ifs&gt;&gt;buf; cout&lt;&lt;buf&lt;&lt;endl; //最终输出为读出文件里的内容 return 0; 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/fd7f28edd913769f55ddc8b30db587d2/" rel="bookmark">
			Android实现双击事件的监听
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		今天写项目时，要求仿微信朋友圈，双击顶栏置顶，于是封装了双击回调接口：
/** * Created by Administrator on 2018/4/24. * 双击 */ public class OnDoubleClickListener implements View.OnTouchListener{ private int count = 0;//点击次数 private long firstClick = 0;//第一次点击时间 private long secondClick = 0;//第二次点击时间 /** * 两次点击时间间隔，单位毫秒 */ private final int totalTime = 1000; /** * 自定义回调接口 */ private DoubleClickCallback mCallback; public interface DoubleClickCallback { void onDoubleClick(); } public OnDoubleClickListener(DoubleClickCallback callback) { super(); this.mCallback = callback; } /** * 触摸事件处理 * @param v * @param event * @return */ @Override public boolean onTouch(View v, MotionEvent event) { if (MotionEvent.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/fd7f28edd913769f55ddc8b30db587d2/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/c5176fb345c015413c2d43c83ff02535/" rel="bookmark">
			关于(x&amp;y)&#43;((x^y)&gt;&gt;1)的解析
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		原题：
int f(int x,int y)
{
return (x&amp;y)+((x^y)&gt;&gt;1);
}
f(729,271)= （x&amp;y)+((x^y)&gt;&gt;1) 书上解析说这个函数的功能是取两个数的平均数。
不太明白，查了资料加上整理一下，仅作记录。
一种解释是：
把x和y里对应的每一位（指二进制位）都分成三类，每一类分别计算平均值，最后汇总。
其中，
一类是x,y对应位都是1，用x&amp;y计算其平均值；
一类是x,y中对应位有且只有一位是1，用(x^y)&gt;&gt;1计算其平均值；
还有一另是x,y中对应位均为0，无须计算。
具体解释一下怎样计算的：
一、x,y对应位均为1，相加后再除以2还是原来的数，如两个00001111相加后除以2仍得00001111，这是第一部分。
二、第二部分，对应位有且只有一位为1，用“异或”运算提取出来，然后&gt;&gt;1(右移一位，相当于除以2），即到到第二部分的平均值。
三、第三部分，对应位均为零，因为相加后再除以二还是0，所以不用计算。
三部分汇总之后就是(x&amp;y)+((x^y)&gt;&gt;1)
顺便解释一下前面说到可以避免溢出。
假设x,y均为unsigned char型数据(0~255，占用一字节)，显然，x,y的平均数也在0~255之间，但如果直接x+y可能会使结果大于255，这就产生溢出，虽然最终结果在255之内，但过程中需要额外处理溢出的那一位，在汇编中就需要考虑这种高位溢出的情况，如果(x&amp;y)+((x^y)&gt;&gt;1)计算则不会。
另外一种解释是：
将a和b拆成两部分的平均值相加：
a、b对应位相同部分，a、b对应位不同部分。
a&amp;b计算的是两个数用二进制表示时对应位相同的部分的平均，由于是取平均，所以若对应位相同则取其中一个数即可，所以用与操作；
a^b&gt;&gt;1计算的是对应位不同的部分的平均，也就是一个是0一个是1，那么平均就是(0+1)/2，就是异或并移位
(右移一位，相当于除以2）的结果。 举一个十进制的例子： 计算14和6的平均值，拆分数字：14=6+8，6=6+0.相同部分两个6，取一个，不同部分8和0，取(8+0)/2=4。那么结果就是6+4=10就是所要求的答案。
个人比较偏好第二种解释。
题目来源：《程序员面试宝典（第五版）》
参考：
https://zhidao.baidu.com/question/311282248.html百度知道的一个回答，很详细
(x&amp;y)+((x^y)&gt;&gt;1)这篇博客解释了另一种方法
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/4970bb511bd0011f9129548e35f868b5/" rel="bookmark">
			椭圆检测算法整理
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一、常见的椭圆检测算法思路及代码 1）OpenCV中的椭圆检测算法 博客1：opencv轮廓检测之椭圆检测:代码
2）基于霍夫变换的椭圆检测算法 博客1： Hough变换检测椭圆 附带matlab与opencv代码
3）基于随机霍夫变换的椭圆检测算法 论文1： 一种基于随机Hough变换的椭圆检测算法研究
二、高效实用椭圆检测算法 1）快速椭圆检测算法 参考论文1：A fast and effective ellipse detector for embedded vision applications 代码链接1：fast_ellipse_detector
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/191910ec165b31f921a6da3d138bce17/" rel="bookmark">
			机器学习——极大似然估计与贝叶斯估计
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		学习朴素贝叶斯分类器时，接触到贝叶斯估计，查阅了很多资料，发现对贝叶斯估计这一名词的具体解释不一，故做如下梳理。
极大似然估计 极大似然估计是频率派提出的参数的点估计方法。
基于参数theta是固定的这一条件, 即使得当前数据集D出现概率最大的参数就是实际参数。
具体求解方法就是对似然函数求导。
贝叶斯参数估计 贝叶斯参数估计是贝叶斯派提出的参数估计方法。可分为贝叶斯点估计，贝叶斯区间估计，本文暂不涉及区间估计。
基于参数theta是服从一定先验分布的随机变量这一条件。那么在数据集D出现后，有了新的信息，我们可以依此更新参数theta的分布，这个更新后的分布就是后验概率分布。
贝叶斯点估计 既然更新后的参数仍然是服从一定概率分布的随机变量，那么如果我们只要一个参数向量，该如何挑选呢？这就涉及到三类挑选方法：
后验众数估计。顾名思义，挑选出现最频繁的参数。也就是说，后验概率分布出现概率最大的theta。故对后验概率分布函数求导即可。这个做法类似于极大似然估计,数学表达式等同于似然函数乘以先验分布(当先验分布为均匀分布，表达式相同)，因此被称为是正则化的极大似然估计，又称为最大后验概率估计(MAP)，但切记背后的思想截然不同。
后验中位数估计。挑选参数的中位数，似乎用得少。后验期望估计。就是选取所有参数的均值，即 θ ^ = ∫ θ θ p ( θ ∣ D ) d θ \hat{\theta}=\int_{\theta}\theta p(\theta|D)d\theta θ^=∫θ​θp(θ∣D)dθ相对MAP而言，需要进行积分运算。但可以有效避免所要估计的概率为0的情况。由于使用较多，在很多资料中直接简称为参数的贝叶斯估计 (比较容易与下文的贝叶斯估计混淆，个人感觉还是称为后验期望估计比较好)。 贝叶斯估计 上文中，贝叶斯点估计从某种意义上讲，都是选取一个随机变量theta的统计值(众数、中位数和均值)来替代分布，这样做的目的无非就是可以减少计算量。但真正意义上的贝叶斯估计方法应该是使用参数空间中所有的参数，分别建立模型(获取模型的ensemble)，然后运用所有的模型进行估计，取所有估计值的期望为最终估计值，权值根据参数的概率分布计算。这样做可以有效避免过拟合，但计算量是十分巨大的。具体降低计算量的方法，后续再讲。
参考资料 图片来源
参考博客
注：如有不当之处，请指正。
我的GitHub
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/0e895a08dccc5ae2b240f56d962d93d6/" rel="bookmark">
			USBCAN-I使用说明书（入门指引）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		第一部分 概述 用户使用我司的USBCAN/CANalyst-I分析仪主要为以下几种应用：
CAN总线入门：学习CAN总线，了解CAN总线原理、数据格式。CAN总线进阶：调试CAN总线、调试开发板。CAN总线初级应用：简单的现场调试，采集数据。CAN总线进阶应用：二次开发、开发实时监控系统。CAN总线终级应用：之前基于国内知名品牌（周立功或吉阳）的产品开发了自已的应用软件或监控界面，现在找替代品。 USBCAN-I产品链接： https://g.alicdn.com/idleFish-F2e/app-basic/item.html?itemid=549767315200&amp;ut_sk=1.Wof7tsCLuf8DAN%2FSdIGyDYLu_21407387_1530853550653.Copy.detail.549767315200.129319713&amp;forceFlush=1
第二部分 各类应用指引 应用一： CAN总线入门：学习CAN总线，了解CAN总线原理、数据格式。
步骤： 安装USB驱动，安装原厂调试工具、做两通道间的收发测试。 进而可以使用周立功CANtest与CANpro软件。（周立功的CANtest与CANpro软件，相对于原厂 调试工具，功能更丰富，用户可以偿试使用这两款软件，注意：请按说明书操作）。
应用二： CAN总线进阶：调试CAN总线、调试开发板。 使用我公司的USBCAN\CANalyst-I分析仪调试自已编程的开发板。
步骤： 安装USB驱动，安装原厂调试工具、做两通道间的收发测试、确认设备波特率。 进而可以使用周立功CANtest与CANpro软件。（周立功的CANtest与CANpro软件，相对于原厂 调试工具，功能更丰富，用户可以偿试使用这两款软件，注意：请按说明书操作）。
应用三： CAN总线初级应用：简单的现场调试，采集数据。 接入正常运行的CAN网络中。
步骤： 安装USB驱动，安装原厂调试工具、做两通道间的收发测试、确认设备波特率。 进而可以使用周立功CANtest与CANpro软件。（周立功的CANtest与CANpro软件，相对于原厂调试工具，功能更丰富，用户可以偿试使用这两款软件，注意：请按说明书操作）。
应用四： CAN总线进阶应用：二次开发、开发实时监控系统。 基于二次开发接口函数，开发自已的软件。
应用五： CAN总线终级应用：之前基于国内知名品牌（周立功或吉阳）的相关产品开发了自已的应用软件或监控界面，现在找低成本的替代品。或是原先使用周立功的CANTest与CANPro软件当调试工具使用，现在找低成本的替代品。
步骤： 原先使用CANTest软件作为调试工具使用，型号： USBCAN-I/ USBCAN-E-U等型号，使用我们的产品，替换一下ControlCAN.dll文件，同样可以使用CANTest软件，型号选择相应的型号即可，也可以选择最新的USBCAN-E-U型号。原先使用CANPro软件作为调试工具使用,型号CANalyst-I, 使用我们的产品，替换一下ControlCAN.dll文件，同样可以使用CANPro软件，型号选择相应的型号即可。如果客户原先基于周立功的USBCAN USBCAN-E-U等型号二次开发的软件产品，那么都会用的ControlCAN.dll这个库文件，这个文件会放置在您开发的软件安装目录下面，与.exe文件同文件夹。找到这个文件，用光盘\二次开发库文件\ControlCAN.dll中的同名文件替换他即可。
第三部分 使用USBCAN模块的CAN系统组网 CAN系统组网网络拓扑结构主要分为： 1。 直线型拓扑结构 2。 手牵手式连接 可参考《CAN-bus总线现场布线和接口设计及电缆和连接器选择》 。 USBCAN模块在CAN网络拓扑中， 作为总线两端端点时， 可以插上跳线帽，接入120欧姆电阻，实现阻抗匹配， 组建网络。如果USBCAN模块接入到已经搭建好的CAN网络系统中，不需要接入120欧姆电阻。
第四部分 使用USBCAN模块的CAN系统组网 1. 通过USB总线连接笔记本或PC机USB接口。 题外话： 连接后， PC或提示安装驱动，或无任何提示。 无论有无提示， 可以先选择不用安装。 右击这台电脑-&gt;管理-&gt;设备管理器， 可以查看到其它设备中出现USBCAN-1D-V10设备，前面打了一个问号。说明设备USB通信正常，并且描述符获取成功，但设备没有可用的的驱动程序。 2. 我们打开目录USBCAN(CAN-I分析仪)\usb driver 3. 双击运行软件 ， 出现界面如下所示， 题外话： 该软件获取未安装的驱动设备， 并可为它安装通用USB驱动程序， 即微软提供的WinUSB设备驱动。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/0e895a08dccc5ae2b240f56d962d93d6/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/e5174d477290c6633dcdd5bf842a2b84/" rel="bookmark">
			在线版 Matlab Octave
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		http://www.compileonline.com/execute_matlab_online.php
http://octave-online.net/
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/4e62c9b68540893070a9e896a6415b3f/" rel="bookmark">
			动态链接库DLL的加载：隐式加载(载入时加载)和显式加载(运行时加载)
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		﻿﻿ 静态链接库在链接时，编译器会将 .obj 文件和 .LIB 文件组织成一个 .exe 文件，程序运行时，将全部数据加载到内存。 如果程序体积较大，功能较为复杂，那么加载到内存中的时间就会比较长，最直接的一个例子就是双击打开一个软件，要很久才能看到界面。这是静态链接库的一个弊端。 动态链接库有两种加载方式：隐式加载和显示加载。 隐式加载又叫载入时加载，指在主程序载入内存时搜索DLL，并将DLL载入内存。隐式加载也会有静态链接库的问题，如果程序稍大，加载时间就会过长，用户不能接受。 显式加载又叫运行时加载，指主程序在运行过程中需要DLL中的函数时再加载。显式加载是将较大的程序分开加载的，程序运行时只需要将主程序载入内存，软件打开速度快，用户体验好。 隐式加载首先创建一个工程，命名为 cDemo，添加源文件 main.c，内容如下： 找到上节创建的 dllDemo 工程，将 debug 目录下的 dllDemo.lib 和 dllDemo.dll 复制到当前工程目录下。 前面已经说过：.lib 文件包含DLL导出的函数和变量的符号名，只是用来为链接程序提供必要的信息，以便在链接时找到函数或变量的入口地址；.dll 文件才包含实际的函数和数据。所以首先需要将 dllDemo.lib 引入到当前项目。 选择”工程(Project) -&gt; 设置(Settings)“菜单，打开工程设置对话框，选择”链接(link)“选项卡，在”对象/库模块(Object/library modules)“编辑框中输入 dllDemo.lib，如下图所示：
但是这样引入 .lib 文件有一个缺点，就是将源码提供给其他用户编译时，也必须手动引入 .lib 文件，麻烦而且容易出错，所以最好是在源码中引入 .lib 文件，如下所示： #pragma comment(lib, "dllDemo.lib") 更改上面的代码： 点击确定回到项目，编译、链接并运行，输出结果如下： Congratulations! DLL is loaded! a+b=15 a-b=5 在 main.c 中除了用 extern 关键字声明 add() 和 sub() 函数来自外部文件，还可以用 _declspec(dllimport) 标识符声明函数来自动态链接库。 为了更好的进行模块化设计，最好将 add() 和 sub() 函数的声明放在头文件中，整理后的代码如下： dllDemo.h main.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/4e62c9b68540893070a9e896a6415b3f/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/4d72949608e1f95df652a499448a5b66/" rel="bookmark">
			有限差分法MATLAB程序
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		设有一个长直接地金属矩形槽，长a=40，宽b=20，其侧壁与底面电位均为零，顶盖电位为100V（相对值），求槽内电位分布。
利用高斯迭代求解代码如下（相邻两次迭代值最大允许误差为0.001）：
a=zeros(21,41); a(1,:)=100; b=zeros(19,39); c=eye(19,39); count=1; d=0; while(count==1) m=0; for i=2:1:20 for j=2:1:40 b(i-1,j-1)=a(i,j); a(i,j)=0.25*(a(i-1,j)+a(i+1,j)+a(i,j-1)+a(i,j+1)); c(i-1,j-1)=abs(a(i,j)-b(i-1,j-1)); if(c(i-1,j-1)&lt;0.001) for k=1:1:19 for n=1:1:39 if(c(k,n)&lt;0.00001) m=m+1; else m=0; break; end end if(m==0) break; end if(m==741) count=0; end end end if(count==0) break; end end if(count==0) break; end end d=d+1; end d a 利用超松弛法程序如下：
d=zeros(1,10); h=0; for e=1:0.1:1.9 a=zeros(21,41); a(1,:)=100; b=zeros(19,39); c=eye(19,39); count=1; g=0; while(count==1) m=0; for i=2:1:20 for j=2:1:40 b(i-1,j-1)=a(i,j); a(i,j)=a(i,j)+e*0.25*(a(i-1,j)+a(i+1,j)+a(i,j-1)+a(i,j+1)-4*a(i,j)); c(i-1,j-1)=abs(a(i,j)-b(i-1,j-1)); if(c(i-1,j-1)&lt;0.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/4d72949608e1f95df652a499448a5b66/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/839fde8fc72b9232f8241d369b8a35c5/" rel="bookmark">
			Fatal error: Cannot access empty property 解决办法
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 看看你有没有写 多了一个$ 。 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/e049a9de2d9374201fede0d385711ac1/" rel="bookmark">
			npm 配置项registry修改为淘宝镜像
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		在使用npm 的过程中，搜索网上的资料基本上可以看到类似如下的描述：“npm是国外的，使用起来比较慢，我们这里使用淘宝的cnpm镜像”。初体验，不知道淘宝cnpm镜像为何物。根据这句描述，我们应该可以理解有2件事要做：
1：找到淘宝的镜像地址；
2：更改当前npm所使用的下载包服务器地址；
打开https://npm.taobao.org/
上面的地址太多，根本不知道那个是我可以用的地址；
百度看了一下，例如执行下面的指令就可以使用cnpm利用国内镜像服务了：
npm install -g cnpm --registry=https://registry.npm.taobao.org;
于是乎就按照着做，这个给了我一个困惑，不是说改一个registry 地址就可以了吗?为何还要安装一个cnpm插件。删除这个cnpm插件了再看下：
于是来了个试验：
1：设置新的registry 配置：npm config set registry https://registry.npm.taobao.org;
2：查看了下当前的registry 配置：npm config get registry:
看到了淘宝的镜像地址，说明就更改成功了。
个人理解到这里应该是：只改npm registry 不安装cnpm也可以利用淘宝的镜像服务器，使用cnpm只是其中的方式之一，如果对多安装出来的cnpm感觉多余，仍然可以继续使用npm指令。两者的效果目前看一样，暂时不知道哪里会有差别。随着后面的学习深入，碰见问题再具体分析。
附注：
npm全称=node package manager 是Node.js的包管理器，用于node插件的安装、卸载、管理依赖等。
使用npm安装插件：例：npm install grunt -g --save-dev
下面的文字描述来源他人blog:记录于此供个人学习理解
-g：全局安装: 将会安装在C:\Users\用户名\AppData\Roaming\npm，window 地址框输入“%appdata%” 回车即可。并且写入系统环境变量； 非全局安装：将会安装在当前定位目录； 全局安装可以通过命令行在任何地方调用它，本地安装将安装在定位目录的node_modules文件夹下，通过require()调用；
–save：将保存配置信息至package.json（nodejs项目配置文件）；
-dev：保存至package.json的devDependencies节点，不指定-dev将保存至dependencies节点；
因为node插件包相对来说非常庞大，所以不加入版本管理，将配置信息写入package.json并将其加入版本管理，其他开发者对应下载即可（命令提示符执行npm install，则会根据package.json下载所有需要的包）。 3.使用npm卸载插件：npm uninstall [-g] [–save-dev] PS：不要直接删除本地插件包 4.使用npm更新插件：npm update [-g] [–save-dev] 5.更新全部插件：npm update [–save-dev] 6.查看npm帮助：npm help 7.查看当前目录已安装插件：npm list
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/817c3589dea7a738868ba2197839c7b4/" rel="bookmark">
			PHP cURL 超时设置 CURLOPT_CONNECTTIMEOUT 和 CURLOPT_TIMEOUT 的区别
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		PHP cURL 的超时设置有两个 CURLOPT_CONNECTTIMEOUT 和 CURLOPT_TIMEOUT，他们的区别是：
CURLOPT_CONNECTTIMEOUT 用来告诉 PHP 在成功连接服务器前等待多久（连接成功之后就会开始缓冲输出），这个参数是为了应对目标服务器的过载，下线，或者崩溃等可能状况。CURLOPT_TIMEOUT 用来告诉成功 PHP 从服务器接收缓冲完成前需要等待多长时间，如果目标是个巨大的文件，生成内容速度过慢或者链路速度过慢，这个参数就会很有用。PS 爬去的时候只加了CURLOPT_CONNECTTIMEOUT 经常会卡死 使用 cURL 下载 MP3 文件是一个对开发人员来说不错的例子，CURLOPT_CONNECTTIMEOUT 可以设置为10秒，标识如果服务器10秒内没有响应，脚本就会断开连接，CURLOPT_TIMEOUT 可以设置为100秒，如果MP3文件100秒内没有下载完成，脚本将会断开连接。
需要注意的是：CURLOPT_TIMEOUT 默认为0，意思是永远不会断开链接。所以不设置的话，可能因为链接太慢，会把 HTTP 资源用完。
在 WordPress 中，wp_http 类，这两个值是一样的，默认是设置为 5 秒。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/10901b96cdb75c1485ddcff2104af9fe/" rel="bookmark">
			uC/OS-II学习笔记之任务堆栈
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		所谓堆栈，就是在存储器中按数据LIFO的原则组织的连续存储空间
Ix86L与Ix86L-FP是与处理器有关的代码，其中后者包含浮点数运算，SOURCE是与处理器无关的代码，可用于代码移植。
注意，堆栈与处理器有关，例如，堆栈的增长方向随系统使用的处理器的不同而有所变化。
为方便定义堆栈在文件OS_CPU.H中专门定义了数据类型OS_STK:
则定义一个堆栈即定义一个OS_STK类型数组即可：
#define TASK_STK_SIZE 512;
OS_STK TaskStk[TASK_STK_SIZE]; //定义一个数组作为任务堆栈
堆栈的初始化： OSTaskCreate() 或者OSTaskCreateExt()调用OSTaskStkInit()实现堆栈的初始化。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/69a590c5a2632165e19cadab96eac141/" rel="bookmark">
			关于微信公众号支付时获取openid的方法
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		微信公众号支付是诸多支付中一种比较特殊的支付方式，它比其他支付方法多传了一个openid，而获取openid网上流传了好多种方法，小M跟着网上传的方法也走了不少的弯路，在研究了两天之后，终于把这个openid给整出来的，趁着这个兴奋劲头，我给大家按照我的思路整理下openid的获取方法。
微信公众号文档也说了要获取openid就先获取code，在通过code来获取openid
这里就先介绍获取code的方法，官方给出的是先设置js接口安全域名，再设置网页授权域名，设置域名时会规定你去下载一个txt文件，并且要将文件放到域名的根目录下，，，将文件放到域名的根目录下这个详情看小M的上一篇文章,文章链接：https://blog.csdn.net/m_y_y/article/details/80022628
获取code的链接： https://open.weixin.qq.com/connect/oauth2/authorize?appid=Appid&amp;redirect_uri=Redirect_uri&amp;response_type=code&amp;scope=snsapi_base&amp;state=STATE&amp;connect_redirect=1#wechat_redirect
注意我标红的地方，官方给我并没有加，没加的话就会发两次请求，报一个40163的错，获取code的参数配错会报40029
其中要传的参数为APPID（微信公众号的appid），redirect_uri（重定向地址），重定向地址 必须是在网页授权域名下的地址，重定向地址必须是在网页授权域名下的地址，重定向地址必须是在网页授权域名下的地址，，重要的事说三遍，并且地址必须加http://，地址必须加http://，地址必须加http://，地址必须加http://，强调这里，小M就是因为重定向地址前没加http导致一直显示redirect_uri错误，整了好久才出来的，希望大家注意
重定向完之后，地址栏中的地址会变成这样：
你这里只需要截取一下code，这里提供一种截取方式：
function GetQueryString(name){ var reg = new RegExp("(^|&amp;)"+ name +"=([^&amp;]*)(&amp;|$)"); var r = window.location.search.substr(1).match(reg); if(r!=null)return unescape(r[2]); return null; } 调用方法： GetQueryString（‘code‘） 就可以获得你想要的code，再将code传到后台换取openid，代码在这里： public Object getOpenid(String code, HttpServletRequest request) { HttpClientUtil2 http = new HttpClientUtil2(); String url = "https://api.weixin.qq.com/sns/oauth2/access_token?appid=" + config.getAppID() + "&amp;secret=" + config.secret + "&amp;code=" + code + "&amp;grant_type=authorization_code"; String str = HttpRequest.sendPost(url, null); JSONObject json = new JSONObject(str); String openid = json.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/69a590c5a2632165e19cadab96eac141/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/04c3543a5e3a172867c5dca47e506995/" rel="bookmark">
			Kafka1.1.0集群的简单使用（java）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		Kafka本地集群搭建完成，简单入门Kafka集群的shell操作后，开始Java代码实现简单功能。
kafka版本说明：此处使用最新版本（现在）—1.1.0版本
1.1.0 is the latest release. The current stable version is 1.1.0.
由于kafka集群环境搭建的遗留问题，导致运行Java代码时会报错，所以首先将环境完善了。
修改主机名和ip映射（在配置bootstrap.servers时统一用主机名，不用ip） // 修改主机名 vi /etc/sysconfig/network NETWORKING=yes HOSTNAME=tyron0 // 修改主机名和IP的映射关系 vi /etc/hosts 192.168.1.100 tyron0 192.168.1.101 tyron1 192.168.1.102 tyron2 centos修改主机名的便捷方式：hostnamectl命令，详情如图： 更详细说明可以参考：如何在CentOS 7上修改主机名 同时，本机hosts也配置上映射关系，内容与Linux环境相同。
KafkaProducer public static void main(String[] args) { // 定义属性，以了解Producer如何找到集群，对消息进行序列化，并在适当时将消息定向到特定的分区 Properties props = new Properties(); // 这里不是配置broker.id了，这个是配置bootstrap.servers props.put("bootstrap.servers", "tyron0:9092,tyron1:9092,tyron2:9092"); /* * 此配置是 Producer 在确认一个请求发送完成之前需要收到的反馈信息的数量。 * acks=0 如果设置为0，则 producer 不会等待服务器的反馈。该消息会被立刻添加到 socket buffer 中并认为已经发送完成。在这种情况下，服务器是否收到请求是没法保证的，并且参数retries也不会生效（因为客户端无法获得失败信息）。每个记录返回的 offset 总是被设置为-1。 * acks=1 如果设置为1，leader节点会将记录写入本地日志，并且在所有 follower 节点反馈之前就先确认成功。在这种情况下，如果 leader 节点在接收记录之后，并且在 follower 节点复制数据完成之前产生错误，则这条记录会丢失。 * acks=all 如果设置为all，这就意味着 leader 节点会等待所有同步中的副本确认之后再确认这条记录是否发送完成。只要至少有一个同步副本存在，记录就不会丢失。这种方式是对请求传递的最有效保证。acks=-1与acks=all是等效的。 */ props.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/04c3543a5e3a172867c5dca47e506995/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/bad3867193bba3fcdba2393a865104b5/" rel="bookmark">
			Qt的学习4,编写一个finddialog的小程序
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		1.新建一个widget工程； 2.把类名设置为finddialog，基类设置为qdialog； 取消创建界面；（使用代码创建） 3.添加头文件，有需要的控件就加进去； 4.在类中，把每个类定义一个变量； 5.定义信号与槽， signal： void find。。。。。； void findprevious; private slots: //触发点击的槽函数； //可以点击和不可点击的槽函数； cpp中： 1.先定义一个显示文字的控件； lineedit的控件； .setbuddy把俩个弄在一起； 接着就是实例化各种控件。其中findbtn把它的按钮设置为不可点击； 2.绑定信号与槽函数； 3.实现他的布局；用水平布局：QHBoxlayout， 垂直布局：QVBoxlyout。 4.设置窗口的标题；最后把这个布局显示出来； 5.设置findfialog和onenablefindbtn的方法。
学习来源：http://space.bilibili.com/84360636/#/index
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/58cf8195c1ef69d1fdb310046a064936/" rel="bookmark">
			Linux下解压和压缩jar文件
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 Java 自带的 jar 命令解压和压缩 jar 文件，可以通过jar --help 查看 jar 命令的语法。
范例：
# 解压 jar -xvf hello.jar # 压缩 jar -cvf0m hello.jar ./META-INF/MANIFEST.MF . 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/331360bea6d7477428b80142aeb3a5bf/" rel="bookmark">
			caffe在窗口上不打印log信息
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		利用caffe训练和测试时，默认都会打印很多的内容，比如训练精度等。
在caffe中常用的打印日志信息的语句有
LOG(INFO) &lt;&lt; "print log info";
LOG(WARNING) &lt;&lt; "print log warning";
LOG(ERROR) &lt;&lt; "print log error";
控制是否打印这些信息，可以通过环境变量GLOG_minloglevel来控制。
比如通过shell脚本调用程序运行前，先执行命令： export GLOG_minloglevel=1;
GLOG_minloglevel值的对应关系如下：
0 - debug1 - info (still a LOT of outputs)2 - warnings
3 - errors
那么如果设置GLOG_minloglevel=3，那么就只会打印error信息了，而不会打印普通的infos和warnings。
如果是在python环境中，那么可以通过语句
os.environ['GLOG_minloglevel'] = '3'
来控制log输出信息
在C/C++的环境中如何控制呢？
在C/C++的环境中可以通过如下命令来控制
fLI::FLAGS_minloglevel=3;
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/3a841a8565545dd0755a7a39a467d6ec/" rel="bookmark">
			kafka特性整理
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		消息投递可靠性 一个消息如何算投递成功，Kafka提供了三种模式： - 第一种是啥都不管，发送出去就当作成功，这种情况当然不能保证消息成功投递到broker； - 第二种是Master-Slave模型，只有当Master和所有Slave都接收到消息时，才算投递成功，这种模型提供了最高的投递可靠性，但是损伤了性能； - 第三种模型，即只要Master确认收到消息就算投递成功；实际使用时，根据应用特性选择，绝大多数情况下都会中和可靠性和性能选择第三种模型
Partition ack：当ack=1，表示producer写partition leader成功后，broker就返回成功，无论其他的partition follower是否写成功。当ack=2，表示producer写partition leader和其他一个follower成功的时候，broker就返回成功，无论其他的partition follower是否写成功。当ack=-1[parition的数量]的时候，表示只有producer全部写成功的时候，才算成功，kafka broker才返回成功信息。这里需要注意的是，如果ack=1的时候，一旦有个broker宕机导致partition的follower和leader切换，会导致丢数据。
如果备份replica下面两个指标不合格，则移除与其保持同步的备份列表，即不作为可靠备份，不作为优先候选者
上图是指producer在推送消息到broker时，确认推送成功的指标。
message状态：在Kafka中，消息的状态被保存在consumer中，broker不会关心哪个消息被消费了被谁消费了，只记录一个offset值（指向partition中下一个要被消费的消息位置），这就意味着如果consumer处理不好的话，broker上的一个消息可能会被消费多次。
消息的消费状态是与consumer绑定的，因为消息可以被不同 consumer group的consumer消费，所以消费偏移量也是由consumer自己决定的
message持久化：Kafka中会把消息持久化到本地文件系统中，并且保持o(1)极高的效率。我们众所周知IO读取是非常耗资源的性能也是最慢的，这就是为了数据库的瓶颈经常在IO上，需要换SSD硬盘的原因。但是Kafka作为吞吐量极高的MQ，却可以非常高效的message持久化到文件。这是因为Kafka是顺序写入o（1）的时间复杂度，速度非常快。也是高吞吐量的原因。由于message的写入持久化是顺序写入的，因此message在被消费的时候也是按顺序被消费的，保证partition的message是顺序消费的。一般的机器,单机每秒100k条数据。
message有效期：Kafka会长久保留其中的消息，以便consumer可以多次消费，当然其中很多细节是可配置的
同步异步：Producer采用异步push方式，极大提高Kafka系统的吞吐率（可以通过参数控制是采用同步还是异步方式）。是指发送消息时，是会缓存一部分消息，然后批量将缓存的消息推送，可以减少网络IO的开销，从而提升吞吐。
分区机制partition：Producer可以决定把消息发到哪个partition，在一个partition 中message的顺序就是Producer发送消息的顺序，一个topic中可以有多个partition，具体partition的数量是可配置的。partition可以设置replica副本，replica副本存在不同的kafka broker节点上，第一个partition是leader,其他的是follower，message先写到partition leader上，再由partition leader push到parition follower上。所以说kafka可以水平扩展，也就是扩展partition。
解耦: 相当于一个MQ，使得Producer和Consumer之间异步的操作，系统之间解耦
顺序保证性：由于kafka的producer的写message与consumer去读message都是顺序的读写，保证了高效的性能。
批量发送：Kafka支持以消息集合为单位进行批量发送，以提高push效率。
Broker：Kafka节点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。Topic：一类消息，消息存放的目录即主题，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列Segment：partition物理上由多个segment组成，每个Segment存着message信息Producer : 生产message发送到topicConsumer : 订阅topic消费message, consumer作为一个线程来消费Consumer Group：一个Consumer Group包含多个consumer, 这个是预先在配置文件中配置好的。各个consumer（consumer 线程）可以组成一个组（Consumer group ），partition中的每个message只能被组（Consumer group ） 中的一个consumer（consumer 线程 ）消费，如果一个message可以被多个consumer（consumer 线程 ） 消费的话，那么这些consumer必须在不同的组。Kafka不支持一个partition中的message由两个或两个以上的consumer thread来处理。它不能像AMQ那样可以多个BET作为consumer去处理message，这是因为多个BET去消费一个Queue中的数据的时候，由于要保证不能多个线程拿同一条message，所以就需要行级别悲观所（for update）,这就导致了consume的性能下降，吞吐量不够。而kafka为了保证吞吐量，只允许一个consumer线程去访问一个partition。如果觉得效率不高的时候，可以加partition的数量来横向扩展，那么再加新的consumer thread去消费。这样没有锁竞争，充分发挥了横向的扩展性，吞吐量极高。这也就形成了分布式消费的概念。 kafka集群中的任何一个broker,都可以向producer提供metadata信息,这些metadata中包含"集群中存活的servers列表"/"partitions leader列表"等信息(请参看zookeeper中的节点信息). 当producer获取到metadata信息之后, producer将会和Topic下所有partition leader保持socket连接;消息由producer直接通过socket发送到broker,中间不会经过任何"路由层". 异步发送，将多条消息暂且在客户端buffer起来,并将他们批量发送到broker;小数据IO太多,会拖慢整体的网络延迟,批量延迟发送事实上提升了网络效率;不过这也有一定的隐患,比如当producer失效时,那些尚未发送的消息将会丢失。 在kafka中,partition中的消息只有一个consumer在消费,且不存在 消息状态的控制,也没有复杂的消息确认机制, 可见kafka broker端是相当轻量级的.当消息被consumer接收之后, consumer可以在本地保存最后消息的offset,并间歇性的向zookeeper注册offset.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/3a841a8565545dd0755a7a39a467d6ec/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/3fb3a9658713a7bbbbeb75202deebc8b/" rel="bookmark">
			在PostgreSQL中使用timestamp数据类型
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		参考自：https://www.postgresql.org/docs/10/static/functions-formatting.html
To get three milliseconds, one must write 12.003, which the conversion treats as 12 + 0.003 = 12.003 seconds.
第一点：众所周知，timestamp数据类型最细粒度到微秒(us),也就是timestamp(6)
那么
postgres=# create table abc_s.test_lei (c1 timestamp(7)); WARNING: TIMESTAMP(7) precision reduced to maximum allowed, 6 第1行create table abc_s.test_lei (c1 timestamp(7)); ^ WARNING: TIMESTAMP(7) precision reduced to maximum allowed, 6 CREATE TABLE postgres=# 那么如上的语句虽然报错了，但是这个表还是create成功了，见下： postgres=# \d abc_s.test_lei 数据表 "abc_s.test_lei" 栏位 | 类型 | Collation | Nullable | Default ------+--------------------------------+-----------+----------+--------- c1 | timestamp(6) without time zone | | | ----&gt;&gt;&gt;&gt;可以看到，自动给变成6了。因为最大到6--微秒 postgres=# 第二点： sql语句中想插入400毫秒，就要写： insert into test_t1 values(to_timestamp('2049-11-22 21:21:21.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/3fb3a9658713a7bbbbeb75202deebc8b/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/df208f502342b25da146e301b13ad3df/" rel="bookmark">
			Mac连上WIFI但是无法上网的3种解决方案
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一般我们最先会认为是DNS问题，你可以试下用ip访问一个服务器（网站）看下行不行，如果也不行那就应该不是DNS的问题了。或者改变一下DNS，如114，或者自己内网要求的DNS。
经过上述尝试还是不行的话，就试按如下方法操作：
1、打开系统偏好设置—&gt;网络—&gt;WiFi—&gt;高级—&gt;WiFi—&gt;删除首选网络框内的所有网络—&gt;点击好—&gt;点击应用； 2、还是在网络页面先，在边框有WiFi、蓝牙PAN、网桥等，选中WiFi，点击下面的减号删除WiFi，点击应用； 3、再次在系统偏好设置中打开网络页面，在左边框的下方点击加号，接口选择WiFi，服务名称随便写，点击创建，然后点击打开WiFi，链接你的WiFi。应该可以上网了。亲测可行。
4、Finder—&gt;xxx的Mac—&gt;Macintosh HD—&gt;资源库–&gt;Preferences—&gt;SystemConfiguration—&gt;找到NerworkInterfaces.plist文件并删除； 如果找不到xxx的Mac或者Macintosh HD，则在finder页面按command+, 进入如下页面，选择“边栏”，把自己的mac或者macbook打上勾。然后在finder左侧就可以看到相关的了。
如果还是不行——还有最后的终极大招：command+option+p+r，开机时按住，听到3声以上声响（屏幕闪烁3下）后松开。这个方法就是完全重置你电脑的控制器了，会将设置都恢复初始化，但是不影响硬盘数据，不必备份。很多时候macbook出现莫名其妙的问题都用得上。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/bc260dfb6f0a3ec3b4bc6e3e9cdfb7f9/" rel="bookmark">
			23、 聊聊akka(三) 集群&amp;持久化
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		Akka集群支持去中心化的基于P2P的集群服务，没有单点故障（SPOF）问题，它主要是通过Gossip协议来实现。对于集群成员的状态，Akka提供了一种故障检测机制，能够自动发现出现故障而离开集群的成员节点，通过事件驱动的方式，将状态传播到整个集群的其它成员节点。
集群概念 节点（node）：集群中的逻辑成员。允许一台物理机上有多个节点。由元组hostname:port:uid唯一确定。 集群（cluster）：由成员关系服务构建的一组节点。 领导（leader）：集群中唯一扮演领导角色的节点。 种子节点（seed node）：作为其他节点加入集群的连接点的节点。实际上，一个节点可以通过向集群中的任何一个节点发送Join（加入）命令加入集群。
这里以Akka官网提供的成员状态状态图为例，如图1所示。 图1展示了状态转换的两个因素：动作和状态。
状态
joining：节点正在加入集群时的状态。 weekly up：配置了akka.cluster.allow-weakly-up-members=on时，启用的状态。 up：集群中节点的正常状态。 leaving/exiting：优雅的删除节点时，节点的状态。 down：标记为已下线的状态。 removed：墓碑状态，表示已经不再是集群的成员。
动作
join：加入集群。 leave：告知节点优雅的离开集群。 down：标记集群为已下线。
配置 本节将要展示构建集群所需要的最基本的配置, application.conf文件的内容如下： akka { actor { provider = "akka.cluster.ClusterActorRefProvider" } remote { log-remote-lifecycle-events = off netty.tcp { hostname = "127.0.0.1" port = 2551 } } cluster { seed-nodes = [ "akka.tcp://metadataAkkaSystem@127.0.0.1:2551", "akka.tcp://metadataAkkaSystem@127.0.0.1:2552" ] # auto downing is NOT safe for production deployments. auto-down-unreachable-after = 10s # Disable legacy metrics in akka-cluster.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/bc260dfb6f0a3ec3b4bc6e3e9cdfb7f9/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/8962a76e7369cce53e519bafbc8f756d/" rel="bookmark">
			Actor and Action Video Segmentation from a Sentence
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		CVPR2018 Oral的一篇关于跨媒体(Video与NLP结合)的文章，paper链接 https://arxiv.org/abs/1803.07485，一作是荷兰阿姆斯特丹大学的PHD，作者的homepage https://kgavrilyuk.github.io/，code和datasets还没有被released出来。 个人瞎扯：这是我见过的第一篇发表出来的用NLP做video segmentetion的文章，其实还有一篇已经挂载arxiv上面了，现在应该是在投ECCV 2018。 文章要做的事情（video segmentation from a sentence） 输入：sentence+video dataset　输出：video mask
可视化的分割结果如下所示。 与state-of-the-art方法定量的对比结果如下所示。 method video segmentation from a sentence framework如下所示。 从这个framework中可以看出，文章主要分为三部分。
sentence encoder。首先加padding使所有的sentence长度一样，然后用在Google News dataset上面做fine-tuning的模型提取300-300-Dim的word2ver向量，然后在用1-Dim CNN提取feature。文章在ablation study中做过分析，1-Dim CNN比vanilla LSTM和bidirectional LSTM效果都要好。video encoder。同样是先加padding使所有video的frame一样长，然后再用I3D encoder video，其中有两个trick。 – 1.在feature map的空间位置上面做L2 Norm。 – 2.把空间位置作为额外的通道学习空间关系（qualifiers），例如left of，above等等。video mask decoder。直接在video representation基础上采用deconvolutional neural network（kernel size 8 x 8 and stride 4， followed by a convolutional layer with a kernel size of 3 x 3 and a stride of 1），分别采用3个scale（32x32，128x128和512x512）的response map做loss function，highest-resolution response map是final segmentation prediction，其中也有两个trick。 – 1.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/8962a76e7369cce53e519bafbc8f756d/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/ab187d0c54dd7bc14ae33dbbf2c86ed1/" rel="bookmark">
			远程复制粘贴异常中断结束后无法使用复制粘贴解决办法
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		服务器远程复制粘贴异常中断结束后无法使用复制粘贴解决办法：
检查rdpclip.exe进程是否启用:打开服务器任务管理器-&gt;查看进程-&gt;寻找rdpclip.exe，如果存在可以结束进程再重新运行；可以使用win+r调出运行框，输入rdpclip回车即可
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/fdd6df01e1acd56ffc1979d21cd14adf/" rel="bookmark">
			基于xml方式配置spring batch
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		从平面文件(Flat File)中批量读取数据 章节用的是编码方式配置spring batch的job任务的，本节就是把上篇博客中job任务改成基于xml配置的方式配置job，因为公司中现在很大一部分还是用的xml方式配置job。
案例：还是读取User.txt文件中数据，并把每条数据中满足年纪是偶数的打印出来。
1、创建spring boot工程，并在pom.xml文件中引入所需要的jar包
&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-batch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-oxm&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.batch&lt;/groupId&gt; &lt;artifactId&gt;spring-batch-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2、读文件 spring batch提供了FlatFileItemReader，用来读取文件，把每条数据映射到User对象中，通过下面方式映射
package com.lzj.batch; import org.springframework.batch.item.file.mapping.FieldSetMapper; import org.springframework.batch.item.file.transform.FieldSet; import org.springframework.validation.BindException; public class UserFieldSetMapper implements FieldSetMapper&lt;User&gt; { @Override public User mapFieldSet(FieldSet fieldSet) throws BindException { // TODO Auto-generated method stub return new User(fieldSet.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/fdd6df01e1acd56ffc1979d21cd14adf/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/3a7d1c42013c4de625034e62bd268b1e/" rel="bookmark">
			产品经理常用术语
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		产品经理常用术语 长尾理论 : 网络时代兴起的一种新理论，由于成本和效率的因素，当商品储存流通展示的场地和渠道足够宽广，商品生产成本急剧下降以至于个人都可以进行生产，并且商品的销售成本急剧降低时，几乎任何以前看似需求极低的产品，只要有卖，都会有人买。这些需求和销量不高的产品所占据的共同市场份额，可以和主流产品的市场份额相比，甚至更大。
长尾效应，“头”（head）和“尾”（tail）是两个统计学名词。正态曲线中间的突起部分叫“头”；两边相对平缓的部分叫“尾”。从人们需求的角度来看，大多数的需求会集中在头部，而这部分我们可以称之为流行，而分布在尾部的需求是个性化的，零散的小量的需求。而这部分差异化的、少量的需求会在需求曲线上面形成一条长长的“尾巴”，而所谓长尾效应就在于它的数量上，将所有非流行的市场累加起来就会形成一个比流行市场还大的市场。
马太效应：（Matthew Effect），指强者愈强、弱者愈弱、好的愈好，坏的愈坏，多的愈多，少的愈少的现象
羊群效应：也称从众效应，指人们经常受到多数人影响，从而跟从大众的思想或行为，也被称为“从众效应”。人们会追随大众所同意的，将自己的意见默认否定，且不会主观上思考事件的意义。羊群效应是诉诸群众谬误的基础。
霍桑效应：指那些意识到自己正在被别人观察的个人具有改变自己行为的倾向。
TMT：数字新媒体，或叫TMT（Technology，Media，Telecom）产业。TMT是电信、媒体和科技三个英文单词的缩写的第一个字头，整合在一起，实际是未来电信、媒体科技(互联网),包括信息技术这样一个融合趋势所产生的大的背景，这就是TMT产业。
PDCA：这是一种用于持续改进产品的框架，计划(Plan)+执行(Do)+检查(Check)+处理(Act)，在初期确定发展目标和达到发展目标所需的关键任务，然后按照计划执行，并不断检查计划的执行情况，并给予及时的处理意见。
用户任务的闭环：指的是一系列帮助用户完成任务的环节，这些环节可以应对任务可能出现的各种情况。
MVP：是指的Minimum Viable Product，最小可行产品，即用最低的成本实现一个尽可能展示核心概念的产品，产品团队可以通过它收集到尽可能多的用户反馈和数据，从而评估这个产品能带来的效益。
CRUD：创建(Create)、检索(Retrieve)、更新(Update)、删除(Delete)，有时候也简称“增删改”这是面向对象设计中最常用的4个基本方法。说来这是数据库里的必备的知识，但作为互联网公司的产品经理，这也是经常会提起的功能点。
现金牛产品：是指利润率超高的产品，并且利润占公司总利润的很大比例，比如魔兽世界，一度占据九城90%的收入，曾经是九城最重要的现金牛。有一些平台产品本身就是最大的现金牛产品，比如百度的搜索，既是平台又是现金牛。
平台产品：就是能通过自身的资源优势拉动其他产品的产品。平台产品具有强大的生命力和拉动能力，如果成功，往往是一家公司的基石。例如QQ、百度、Google、微软等。
ARPU : (Average Revenue Per User)即每用户平均收入，用于衡量电信运营商和互联网公司业务收入的指标。
CPC : 网络中最常见的一种广告形式，它是英文单词Cost Per Click的缩写意思就是每次点击付费广告
SPAM：互联网上到处散布垃圾广告消息的现象。在搜索引擎上的Spam通常也称为作弊。搜索引擎营销中所说的SPAM是专门针对那些欺骗搜索引擎的信息。搜索引擎垃圾技术是利用不道德的技巧去提高自己搜索引擎上的排名。不诚实的网站管理员就是利用这样的手段去欺骗搜索引擎从而获得较高的排名。
病毒式营销：源于英文词汇viralmarketing。常用于进行网站推广、品牌推广等。利用的是用户口碑传播的原理，在互联网上，这种“口碑传播”更为方便，可以像病毒一样迅速蔓延，因此病毒性营销成为一种高效的信息传播方式，而且，由于这种传播是用户之间自发进行的，因此几乎是不需要费用的网络营销手段。
BRD：Business Requirements Document (商业需求文档) 是基于商业目标或价值所描述的产品需求内容文档（报告）。其核心的用途就是用于产品在投入研发之前，由企业高层作为决策评估的重要依据。其内容涉及市场分析，销售策略，盈利预测等，通常是供决策层们讨论的演示文档，一般比较短小精炼，没有产品细节。 针对人群：一般都是针对老版或CEO或者项目总负责人
MRD：Market Requirements Document (市场需求文档) 该文档在产品项目过程中属于“过程性”文档。是市场部门的产品经理或者市场经理编写的一个产品的说明需求的文档。该文档在产品项目过程中属于“过程性”文档。该文档是产品项目由“准备”阶段进入到“实施”阶段的第一文档，其作用就是“对年度产品中规划的某个产品进行市场层面的说明”，这个文档的质量好坏直接影响到产品项目的开展，并直接影响到公司产品战略意图的实现。该文档在产品项目中是一个“承上启下”的作用，“向上”是对不断积累的市场数据的一种整合和记录，“向下”是对后续工作的方向说明和工作指导。 针对人群：一般都是商务、运营、市场人员
PRD：Product Requirements Document (产品需求文档) 该文档是产品项目由“概念化”阶段进入到“图纸化”阶段的最主要的一个文档，其作用就是“对MRD中的内容进行指标化和技术化”，这个文档的质量好坏直接影响到研发部门是否能够明确产品的功能和性能。 针对人群：一般都是项目组、开发组、测试组、策划组、体验组人员
FSD：Functional Specifications Document (功能详细说明文档) 功能详细说明。有一点像“概要设计”，在BRD、MRD和PRD的基础上，这步就开始往开发衔接了，产品UI、业务逻辑的细节都要确定，细化文档并保持更新。相应的，有很多内容，比如表结构设计，要由项目经理来编写了。
C2C：Consumer to Consumer(顾客对顾客) 消费者个人间的电子商务行为。比如一个消费者有一台电脑，通过网络进行交易，把它出售给另外一个消费者，此种交易类型就称为C2C电子商务。 例如：淘宝网 拍拍网 易趣网
B2B：Business to Business(商家对商家) 模式：垂直，综合，自建，关联 指企业与企业之间通过专用网络或Internet，进行数据信息的交换、传递，开展交易活动的商业模式。它将企业内部网和企业的产品及服务，通过 B2B 网站或移动客户端与客户紧密结合起来，通过网络的快速反应，为客户提供更好的服务，从而促进企业的业务发展。
O2O：Online to Offline(线上线下电子商务) 将线下的商务机会与互联网结合，让互联网成为线下交易的平台，这个概念最早来源于美国。O2O的概念非常广泛，既可涉及到线上，又可涉及到线下,可以通称为O2O。主流商业管理课程均对O2O这种新型的商业模式有所介绍及关注。 例如：百度 阿里 腾讯
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/3a7d1c42013c4de625034e62bd268b1e/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/07432d2ad7f52b23ded6646bde0cd313/" rel="bookmark">
			c# curl post请求传json
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		备注：curl只是一个测试请求工具，和正常http协议请求一致，常用请求方式有post、get。本文讲述的是post
string httpAddress = "https://blog.csdn.net/weixin_41913666"; string sign = "?sign=24D1C"; string key = "&amp;key=4a7d"; string url=httpAddress +sign +key ; /// &lt;summary&gt; /// Post提交数据 /// &lt;/summary&gt; /// &lt;param name="url"&gt;URL&lt;/param&gt; /// &lt;param name="postData"&gt;参数&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; private string PostRequest(string url, string jsonData) { string str= string.Empty; try { var webReq = (HttpWebRequest)WebRequest.Create(new Uri(url)); webReq.Method = "POST"; webReq.ContentType = "application/json"; var sw = new StreamWriter(webUrl.GetRequestStream()); sw.Write(jsonData); sw.Flush(); sw.Close(); var response = (HttpWebResponse)webReq.GetResponse(); var sr = new StreamReader(response.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/07432d2ad7f52b23ded6646bde0cd313/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/d20cd2ebb8b6510573816cce1efd681a/" rel="bookmark">
			Redis 生产环境的安装配置
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		Redis 生产环境的安装配置 机器环境 CentOs 6.5Redis 4.0.9 （2018/4/10最新版本） 安装Redis 首先去到/usr/local/目录，redis是安装在这个目录下面：
执行如下命令
$ wget http://download.redis.io/releases/redis-4.0.9.tar.gz $ tar xzf redis-4.0.9.tar.gz $ cd redis-4.0.9 $ make &amp;&amp; make test &amp;&amp; make install 执行以上命令发现，make成功了，make test报出一下错误：
You need tcl 8.5 or newer in order to run the Redis test 如果遇到这个错误，执行如下命令：
wget http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gz tar -xzvf tcl8.6.1-src.tar.gz cd /usr/local/tcl8.6.1/unix/ ./configure make &amp;&amp; make install 安装完毕后，再次进入redis-4.0.9目录，执行make test &amp;&amp; make install 确保redis安装没有问题。
配置 在生产环境中，需要将redis作为一个deamon进程去启动，每次系统启动的时候，redis服务会跟着启动。
进入redis目录下面，然后在进入utils目录，可以看到，有一个redis_init_script文件。
将这个文件拷贝到/etc/init.d/redis_6379下面
cp /usr/local/redis-4.0.9/utils/redis_init_script /etc/init.d/redis.6379 然后我们查看一下这个文件：
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/d20cd2ebb8b6510573816cce1efd681a/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/bb393b3bad6cc4d9acf9323584db8dc2/" rel="bookmark">
			NRF5 SDK蓝牙开发——peripheral设备广播报文分析
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		peripheral设备广播报文分析 试验条件：
iar for arm开发平台1块nRF52832开发板应用程序开发版本：nRF5_SDK_15.0.0_a53641a协议栈固件： s132_nrf52_6.0.0_softdevice.hex2个基于Ble平台开发好的产品 central设备与peripheral设备的连接的前提，需要peripheral设备定时往外发送广播报文，而central设备进入扫描模式，接收所有广播报文。为了实现对peripheral设备广播报文的分析，一方面通过实例结合蓝牙核心协议来分析，一方面，在NRF52系列平台，通过peripheral设备的代码来分析广播内容。
通信试验搭建 1。 nRF52832开发板跑central设备程序来抓包，例程在examples\ble_central\ble_app_uart_c，同时配置RF_LOG信息打印到串口，并且在"sdk_config.h"中，LOG信息输出等级为4，如下代码所示，
// &lt;o&gt; NRF_LOG_DEFAULT_LEVEL - Default Severity level // &lt;0=&gt; Off // &lt;1=&gt; Error // &lt;2=&gt; Warning // &lt;3=&gt; Info // &lt;4=&gt; Debug #ifndef NRF_LOG_DEFAULT_LEVEL #define NRF_LOG_DEFAULT_LEVEL 4 #endif 2。central设备初始化完毕后，都会触发BLE_GAP_EVT_ADV_REPORT事件，该事件在函数static void ble_evt_handler(ble_evt_t const * p_ble_evt, void * p_context)中处理。进入on_adv_report，进入ble_advdata_uuid_find，合适位置添加 代码如下， 这样在搜索到任一个peripheral设备广播报文，都会打印报文信息。
NRF_LOG_DEBUG("p_encoded_data,%d",data_len); NRF_LOG_HEXDUMP_DEBUG(p_encoded_data, data_len); 使用nRF Connect工具对广播报文解析的内容&amp;central设备抓包输出到串口的原始数据，使用两个实例，对比如下
[15:53:56.117]收←◆&lt;debug&gt; app: p_encoded_data,19 &lt;debug&gt; app: 02 01 06 0F 09 4B 65 65|.....Kee &lt;debug&gt; app: 73 6F 6E 20 62 61 73 65|son base &lt;debug&gt; app: 30 30 31 |001 &lt;debug&gt; app: p_encoded_data,4 &lt;debug&gt; app: 03 03 E0 FF |.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/bb393b3bad6cc4d9acf9323584db8dc2/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/fa8652d4a0ccc7147ac90068b6246251/" rel="bookmark">
			实时对战游戏PVP开发之PUN使用中常见问题总结
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		PUN在使用过程中常遇到的问题和疑问，本篇文章可以帮你解决PUN使用和选择的疑问，顺利完成PVP实时对战游戏开发。
哪款Photon产品适合我？
这是一个难以回答的问题，因为它取决于你正在制作的游戏和你的项目的具体情况。 不过，可以推荐以下内容帮你进行选择：
PhotonPUN说明
Photon产品说明
“Photon Cloud或Photon Server
如果您仍然有疑问，请随时与我联系，直接进行留言，帮你解决问题。
Photon Realtime和PUN有什么区别？
Photon Realtime和PUN都基于相同的API：LoadBalancing API。 两种产品共享相同的后端，相同的服务器应用程序，相同的核心概念。 起初，PUN是一个更好的UNet（旧的Unity网络）产品替代者。保留一个类似的API，具有更坚实的后端和丰富的功能。 然后它逐渐分化，成为Unity上多人游戏的头号解决方案。
我们拥有Photon Realtime Unity SDK，但PUN具有更高水平的高度封装组件式即用功能，如：
Unity中callbacks
Unity组件，可以序列化和同步。 PhotonView组件
PunRPC
离线模式
然而，尽管PUN支持webhooks和持久的房间状态，但在加载已保存的游戏时，仍然无法100％地在场景中恢复网络对象的状态。 Photon Cloud
什么是默认Photon区域？
只要至少有一个区域可用，客户端应该能够连接到Photon Cloud。 因此，为保证这一点，开发人员没有明确设置或选择“最佳区域”选项时会配置或使用默认值。 默认值可能因客户端SDK而异。 在本地SDK中，它是OpGetRegions中服务器返回的区域列表的索引0处的值。 在Unity和DotNet SDK上，默认区域应该是“EU”。
是否可以禁用某些区域？
是。 它通过定义允许区域的列表，来实现禁用某些区域。 可以在“Dashboard Regions Filtering”中进行设置。
Load Balancing 负载均衡
Photon房间支持的最大玩家数量是多少？
玩家人数是增加房间内流量的主要因素。 交换的消息越多，消息越多。
理论上没有限制。 对于超过8名玩家你需要进行管理。 对于大量的玩家，你可以将他们分开 - 你的服务器中 - 跨越多个房间。
Photon字符串是否有限制？
Photon使用字符串有很多用途：房间名称，大厅名称，用户名，昵称，自定义属性键等。
Photon二进制协议可以序列化最多32767个字符的字符串。 对于名称和UserID，32个字符应该足够了（例如GUID是32个字符）。 但是，对于自定义属性键，您应该使用较短的字符串以尽量减少开销。 这对于在大厅中可见的属性尤为重要，因为这些属于房间列表的一部分，并且会发送给大厅中的所有人，而不仅仅是房间中的几个客户。
自定义属性的数量是否有限制？
没有限制。但请注意，设置的自定义属性越多，客户端加载时间就越长，因为加入房间时，客户端也会收到所有属性。 如果您的人数太多，而且客户的加载时间超过一定的时间，可能导致客户端他们断开连接。
我可以使用Photon发送大量信息吗？
我们不建议使用Photon传输大数据（即文件），除非您知道您在做什么。我们建议您优化您交换的数据，如果您确实需要发送非常重要的信息可以和官方进行联系。
Photon Cloud对客户端缓冲区有500KB的服务器端限制。因此，根据上下文，可以考虑消息：
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/fa8652d4a0ccc7147ac90068b6246251/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/77704301e221c22a7c05506a5bd71d32/" rel="bookmark">
			Matlab中读取txt文件的几种方法
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		matlab读取文本文件的几种函数： 1、load——适合读取纯数据文本； 2、importdata——只读取数据，自动省略数据格式前后的字符，超大文件不适合； 3、textread、textscan——适合读取行列规整的文本，会存到元胞中，可通过headerlines省略读取字段名（字符行）； 4、csvread、dlmread——适合读取csv、xsl等文件格式文本； 5、fprintf、fscanf——适合读取复杂的文本（中英文、数字串混杂出现）； 一、纯数据文件（没有字母和中文，纯数字） 对于这种txt文档，从matalb中读取就简单多了
例如test.txt文件，内容为“17.901 -1.1111 33.045
17.891 -1.1286 33.045
17.884 -1.1345 33.045”
可以在command window中输入load test.txt ，然后就会产生一个test的数据文件，内容跟test.txt中的数据一样；另一种方法是在file/import data....../next/finish 也可产生一个叫test的数据文件。
二、中英文和数据如test1.txt
“你好
欢迎来到
振动论坛
vib.hit.edu.cn
1 11 111 1111
2 22 222 2222
3 33 333 3333
4 44 444 4444
5 55 555 5555”
这样的文件怎么读入数据呢？
方法有多种，现举两个比较简单实用的。
方法一：
file/import data....../next/finish &gt;&gt; whos
Name Size Bytes Class
data 5x4 160 double array
textdata 4x1 300 cell array
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/77704301e221c22a7c05506a5bd71d32/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/256d8c545f3b07b364150fa368711057/" rel="bookmark">
			com.mysql.jdbc.MysqlDataTruncation: Data truncation: Division by 0
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		2019独角兽企业重金招聘Python工程师标准&gt;&gt;&gt; ### The error may involve com.restyle.api.dao.mybatis.WatchUserMapper.insertSelective-Inline ### The error occurred while setting parameters ### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Division by 0 ; SQL []; Data truncation: Division by 0; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Division by 0 at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:102) 以前用的是mysql5.6.x没问题,更新到mysql5.7.x后出现了这个问题: 1, 看系统日志Division by 0就各种折腾,数据库降级,没成功; 2, 最后发现是新增数据时在触发器中使用了TRUNCATE(NEW.FIGHT_WINN / NEW.FIGHT_COUNT,2) * 100,所以提示报错; 3, 数据库以及各种配置文件在修改前要备份,数据库要以脚本形式备份; 4, 数据库中尽量不要使用视图,触发器,函数之类的,以免给自己挖坑,尤其是sql逻辑不严谨的问题; 转载于:https://my.oschina.net/liuchangng/blog/1794988
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/f14775b4c045a06f4d02eadd1dd20253/" rel="bookmark">
			工程师如何在工作中提升自己?
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		引言 古人云：“活到老，学到老。”互联网算是最辛苦的行业之一，“加班”对工程师来说已是“家常便饭”，同时互联网技术又日新月异，很多工程师都疲于应付，叫苦不堪。以至于长期以来流传一个很广的误解：35岁是程序员工作的终点。
如何在繁忙的工作中做好技术积累，构建个人核心竞争力，相信是很多工程师同行都在思考的问题。本文是我自己的一些总结，试图从三个方面来解答：
第一部分阐述了一些学习的原则。任何时候，遵循一些经过检验的原则，都是影响效率的重要因素，正确的方法是成功的秘诀。
提升工作和学习效率的另一个重要因素是释惑和良好心态。第二部分分析了我在工作中碰到和看到的一些典型困惑。
成为优秀的架构师是大部分初中级工程师的阶段性目标。第三部分剖析架构师的能力模型，让大家对目标所需能力有一个比较清晰的认知。
如何学习 在繁忙的工作中，持之以恒、不断学习和进步是一件艰巨的任务，需要坚强的毅力和坚定的决心。如果方法不得当，更是事倍功半。幸好我们的古人和现在哲人已经总结了很多优秀的学习方法论，这里汇总了一些重要原则。遵循这些方法必会对大家的工作学习大有裨益。
贵在坚持 有报道指出，过去几十年的知识量超过之前人类几千年的知识量总和。而计算机领域绝对是当代知识更新最快的领域之一，因此，工程师必须要接受这样一个现实，现在所掌握的深厚知识体系很快就会被淘汰。要想在计算机领域持续做优秀架构师，就必须不停的学习，掌握最新技术。总之，学不可以已。
所谓“冰冻三尺，非一日之寒，水滴石穿，非一日之功”，通往架构师的道路漫长而又艰巨，轻易放弃，则所有付出瞬间付之东流。要想成为优秀的架构师，贵在坚持！
虽然知识更新很快，但是基础理论的变化却非常缓慢。这就是“道”和“象”关系，纵是世间万象，道却万变不离其宗。对于那些非常基础的理论知识，我们需要经常复习，也就是“学而时习之”。
重视实践 古人云：“纸上得来终觉浅，绝知此事要躬行。” 学习领域有所谓721模型：个人的成长70%来自于岗位实践，20%来自向他人学习，10%来自于培训。虽然这种理论存在争议，但对于工程师们来说，按照实践、学习和培训的方式进行重要性排序，大致是不错的。所以重视实践，在实践中成长是最重要的学习原则。
人类的认知有两种：感性认知和理性认知。这两种认知互相不可替代性。实践很大程度来自于感性学习，看书更像是理性学习。以学开汽车做例子，很难想象什么人能够仅仅通过学习书本知识就会开汽车。
书本知识主要是传道——讲述抽象原型，而对其具体应用场景的讲述往往含糊其辞，对抽象原型之间的关系也是浅尝辄止。采用同样精确的语言去描述应用场景和关联关系将会失去重点，让人摸不着头脑。所以，仅仅通过看书来获得成长就像是用一条腿走路。
重视实践，充分运用感性认知潜能，在项目中磨炼自己，才是正确的学习之道。在实践中，在某些关键动作上刻意练习，也会取得事半功倍的效果。
重视交流 牛顿说：“如果说我看得比别人远一些，那是因为我站在巨人的肩膀上。”我们需要从别人身上学习。从老师、领导、同事、下属甚至对手身上学习，是快速成长的重要手段。
向老师和领导学习已经是人们生活习惯的一部分了。但是从同事甚至对手那里学习也很重要，因为这些人和我们自身更相似。所以要多多观察，取其所长，弃其所短。对于团队的小兄弟和下属，也要“不耻下问”。
此外，在项目中积极参与具体方案讨论也非常重要。参与者先验感知了相关背景，并且讨论的观点和建议也是综合了发言者多种知识和技能。所以，讨论让参与者能够非常全面，立体地理解书本知识。同时，和高手讨论，他们的观点就会像修剪机剪树枝一样，快速的剪掉自己知识领域里面的疑惑点。
重视总结和输出 工程师在实践中会掌握大量细节，但是，即使掌握了所有细节，却没有深刻的总结和思考，也会陷入到“学而不思则罔”的境地。成长的“量变”来自于对细节的逐渐深入地把控，而真正的“质变”来自于对“道”的更深层次的理解。
将经验输出，接受别人的检验是高层次的总结。这种输出不仅帮助了别人，对自身更是大有裨益。总结的方式有很多，包括组织分享，撰写技术文章等等。当然“日三省吾身”也是不错的总结方式。总之，多多总结，多多分享，善莫大焉！
解答别人的问题也是个人成长的重要手段。有时候，某个问题自己本来不太懂，但是在给别人讲解的时候却豁然开朗。所以，“诲人不倦”利人惠己。
重视规划 凡事预则立，不预则废。对于漫长的学习生涯而言，好的计划是成功的一半。
长期规划 长期规划的实施需要毅力和决心，但是做正确的长期规划还需要高瞻远瞩的眼界、超级敏感的神经和中大奖的运气。对于大部分人来说，长期规划定主要是“定方向”。但遵循如下原则能够减少犯方向性错误的概率：
远离日暮西山的行业。
做自己感兴趣的事情。
做有积累的事情。
一边走一边看，切勿一条道走到黑。
短期规划 良好的短期规划应该在生活、成长、绩效和晋升之间取得平衡。大部分公司都会制定一个考核周期——少则一个月，多则一年。所以不妨以考核周期作为短期学习规划周期。本质上，规划是一个多目标优化问题，它有一系列的理论方案，这里不一一细说。基于相关理论，我给出一个简单易行的方案：
确定目标优先级。比如：成长、生活、绩效。
确定每个目标的下限。从优化理论的角度来看，这被称为约束。比如绩效必须在一般以上，之前已经规划好的旅行不能更改，必须读完《Effective Java》等等。
优先为下限目标分配足够的资源。比如，事先规划好的旅行需要10天，这10天就必须预算出去。
按照各主目标的顺序依次分配资源。比如，最终分配给学习的时间是10天。
在给定的学习预算下，制定学习目标，要激进。然后给出执行方案。比如，学习目标是掌握基本的统计学知识，并成为Java专家。具体方案为：完成《Effective Java》、《Java Performance》、《Design Pattern》、《Head First Statistics》四本书的阅读。
对规划中的各学习任务按目标优先级进行排序，并最先启动优先级最高的任务。比如，最高优先级是掌握统计理论，那么就要先看《Head First Statistics》。
对于该方案，要注意以下几点：
最低目标必须能够轻松达成的目标，否则，从优化理论的角度来讲，该命题无解。比如，类似“半年内完成晋级两次、绩效全部S、从菜鸟成为Java专家”就不太合适作为最低目标。总之，要区分理想和梦想。主要目标规划必须具备一定的挑战性，需要规划出不可能完成的目标。过度规划本质上是一种贪婪算法，目的是目标价值最大化。因为一切皆有变数，如果其他目标能够提前完成，就不妨利用这些时间去完成更多的学习目标。总之，前途必须光明，道路必须坎坷。
各目标之间不一定共享资源，规划不一定互有冲突。
此外，短期规划还可以从如下几个方面进行优化：
学习计划最好能结合工作计划，理论联系实际结合，快速学以致用。比如，本季度规划去做一些数据分析工作，那么不妨把学习目标设置为学习统计知识。
要灵活对待规划的目标和具体执行步骤，需要避免“郑人买履”式的笑话。面临新的挑战和变化，规划需要不断地调整。
那些令人纠结的困惑 人生是一场马拉松，在漫长的征途中，难免有很多困惑。困惑就像枷锁，使我们步履蹒跚，困惑就像死锁，让我们停滞不前。
接下来我将总结自己在工作中碰到和看到的一些典型困惑。这些困惑或者长期困扰作者本人，或者困扰我身边的同事和朋友。当这些困惑被释然之后，大家都感觉如重获释，为下一阶段的征程提供满满的正能量。人生就像一场旅途，不必在乎目的地，在乎的，应该是沿途的风景，以及看风景的心情。良好的心态是技术之旅最好的伴侣。期望通过这个解惑之旅，让大家拥有一个愉快的心情去感受漫长的学习旅途。
学无止境吗 必须要承认一个残酷的现实：人的生命是有限的，知识却是无限的。用有限的生命去学习无限的知识是不可能完成的任务。一想到此，有些工程师不免产生一些悲观情绪。如果方法得当并且足够勤奋，悲伤大可不必。
虽然，人类的整体知识体系一直在扩张。但是就很多重要的工程细分领域，基础理论并不高深。计算机的很多重要领域，工程师有能力在有限时间内抓住核心要害。
比如，密码学被认为是门非常高深的学科，但是一大类密码技术的基础是数论中一个非常简单的理论——素因数分解：给出两个素数，很容易算出它们的积，然而反过来给定两个素数的积，分解的计算量却非常惊人。
“一致性”算得上是计算机领域里面最经典的难题，它是所有分布式系统的基础，从多核多CPU到多线程，从跨机器到跨机房，无所不在，几乎所有的计算机从业人员都在解决这个问题，但是Paxos给出了一个很优雅的解决方案。
权限管理是很多工程师的噩梦，但如果你能搞定“Attribute Based Access Control(ABAC)”和“Role-Based Access Control(RBAC)”，也能达到相当高度。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/f14775b4c045a06f4d02eadd1dd20253/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/4c5b8ca548d0d5753488fef1df4d7d61/" rel="bookmark">
			LR与NN之区别
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		LR没有hidden layer，NN有
LR的decision boundary 是线性的，而NN可以不是
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/a97c1f9a2973cdc2f291e95a39009788/" rel="bookmark">
			linux的update和upgrade，Linux如何安装软件
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		Linux软件会维护自己的软件库，常用的软件都在这里，而且绝对可以正确安装的，维护源列表（source.list）里面的网址信息，
这些地址指向数据标识的这台服务器上哪些软件可以安装的。通过一下命令实现对源列表的维护。
sudo gedit /etc/apt/sources.list
通过执行update会访问源列表里的每个网址，并读取软件列表，然后保存在本地电脑。
sudo apt-get update
这个命令，会把本地已安装的软件，与刚下载的软件列表里对应软件进行对比，如果发现已安装的软件版本太低，就会提示你更新。
如果你的软件都是最新版本，会提示,升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 0 个软件包未被升级。
sudo apt-get upgrade
总之，update是更新软件列表，upgrade是更新软件。如果使用 apt-get 遇到速度慢或者源不存在等错误，可能需要更换源
安装软件xxx的指令
sudo apt-get install softname
卸载软件 apt-get remove softname
卸载并清除配置 apt-get remove –purge softname
搜索软件包
apt-cache search softname
安装deb软件包 dpkg -i xxx.deb
删除软件包 dpkg -r xxx.deb
连同配置文件一起删除 dpkg -r –purge xxx.deb
查看软件包信息 dpkg -info xxx.deb
查看文件拷贝详情 dpkg -L xxx.deb
查看系统中已安装软件包信息 dpkg -l
重新配置软件包 dpkg-reconfigure xxx
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/a97c1f9a2973cdc2f291e95a39009788/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/b5225bb51443e48369ab31efdd1ed80c/" rel="bookmark">
			MYSQL开发技巧(一)
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		sql开发技巧之一 正确使用sql的好处: 1.增加数据库处理效率,减少应用响应时间. 2.减少数据库服务器负载,增加服务器稳定性. 3.减少服务器间通讯的网络流量. 如何正确的使用Join从句 举例中使用的表如下:西天取经四人组VS悟空的朋友们 id user_name 1 唐僧 2 猪八戒 3 孙悟空 4 沙僧 id user_name 1 孙悟空 2 牛魔王 3 蛟魔王 4 鹏魔王 5 狮驼王 SQL标准中Join的类型 JOIN: 1. 内连接(INNER) 2. 全外连接(FULL OUTER) 3. 左外连接(LEFT OUTER) 4. 右外连接(RIGHT OUTER) 5. 交叉连接(CROSS) 1.1 JOIN操作的类型----- Inner Join 内连接Inner join基于连接谓词将两张表(如A和B)的列组合在一起,产生新的结果表.(把两张表中公共的部分选取出来) 如图所示涂红的部分是Inner JOIN产生的结果表: SELECT &lt;select_list&gt; FROM TableA A INNER JOIN TableB B ON A.Key=B.Key
取出user1表和user2表公共记录的数据:
SELECT
a.user_name
FROM
user1 a
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/b5225bb51443e48369ab31efdd1ed80c/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/1e2874cf11805f9b54763d8189367bfc/" rel="bookmark">
			在数组末尾添加对象
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 如何在数组中添加对象 根据JavaScript中的push()的方法 var array =[{name:'小可爱',age:12},{name:'小机灵',age:13},{name:'小宝贝',age:17},{name:'小姐姐',age:16}]; //如果我们想在后面在加上一组对象那个呢? array.push({name:'小哥哥',age:20}); console.log(array); //那么运行结果就是[{name:'小可爱',age:12},{name:'小机灵',age:13},{name:'小宝贝',age:17},{name:'小姐姐',age:16}，{name:'小哥哥',age:20}] 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/bd7f8b166750c93e289d4696b51bb409/" rel="bookmark">
			docker error:/root/.docker/config.json: is a directory
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		问题：
本地没有taskworker镜像，docker从远端拉取，但是拉取时需要读取config.json配置，解析配置时，发现config.json是个目录，错误信息如下：
taskworker_1 | 2018-04-11T08:41:04.688875905Z docker: Error response from daemon: taskworker:latest not found: does not exist or no pull access.
taskworker_1 | 2018-04-11T08:41:04.519870517Z WARNING: Error loading config file:/root/.docker/config.json - read /root/.docker/config.json: is a directory taskworker_1 | 2018-04-11T08:41:04.524016048Z Unable to find image 'taskworker:latest' locally 原因分析：
配置文件不正确。
解决方案：
删除/root/.docker/config.json目录（docker会自动重建该文件）。
为避免不正确的docker cli导致再创建一个config.json目录，需要在安装完成docker后，通过docker login命令正确设置注册表和账户信息
转载于:https://www.cnblogs.com/dadream/p/8797324.html
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/b9dd4a5019121dd7e54a61f9e43b1695/" rel="bookmark">
			机器学习中的数学（1）：法协方差定义和协方差矩阵计算过程实例
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		协方差的定义 在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。
协方差表示的是两个变量的总体的误差，这与只表示一个变量误差的方差不同。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。
2 协方差矩阵实例 1.协方差公式：
如果一个变量是增加的趋势，另一个也是增加的趋势，证明是正相关，如果另一个朝相反的趋势，是负相关；如果协方差的值是0，证明他们不相关。
站在大数据的基础上考虑问题，使用机器学习算法挖掘数据，一般样本会有多个特征，如果用矩阵表示就是多维数据。
2.协方差矩阵：由数据集中两两变量的协方差组成。矩阵的第(i,j)(i,j)个元素是数据集中第ii和第jj个元素的协方差。例如，三维数据的协方差矩阵如下所示：
公式：
举个例子：有4个样本，每一行代表一个样本有3个特征：
第一个样本 2 ， 0 ， -1.4
第二个样本 2.2.，0.2 ， -1.5
第三个样本 2.4.， 0.1 ， -1
第三个样本 1.9.， 0 ， -1.2
。。。。。一维 二维 三维
计算上面的矩阵的协方差，
重点是具体怎么算的呐？我被它难住就在这里，因为你需要处理样本的特征，并验证特征之间是否有关联性啊，解：
三维数据（三列元素），第一列均值2.125，第二列均值0.075，第三列均值 -1.275。
根据公式计算：
计算每个元素。
import numpy as np X = [[2, 0, -1.4], [2.2, 0.2, -1.5], [2.4, 0.1, -1], [1.9, 0, -1.2]] print(np.mean(X,axis=0)) print(np.cov(np.array(X).T)) numpy mean函数的axis参数 numpy提供的函数里含有一堆参数，有利于计算多维矩阵的求和、方差以及协方差。
axis=0，那么输出矩阵是1行，求每一列的平均（按照每一行去求平均）；axis=1，输出矩阵是1列，求每一行的平均（按照每一列去求平均）。还可以这么理解，axis是几，那就表明哪一维度被压缩成1。
结果：
[ 2.125 0.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/b9dd4a5019121dd7e54a61f9e43b1695/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/8eb961393c0ebe05d6eafc54a53231fc/" rel="bookmark">
			学习随笔：springMVC 整合 redisCluster（单节点连接集群）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 1.添加依赖 &lt;!-- jedis --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt; &lt;/dependency&gt; 2. &lt;!-- 连接池配置 --&gt; &lt;bean id="genericObjectPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxTotal" value="${redis.maxActive}" /&gt; &lt;property name="maxIdle" value="${redis.maxIdle}" /&gt; &lt;property name="maxWaitMillis" value="${redis.maxWaitMillis}" /&gt; &lt;property name="testOnBorrow" value="${redis.testOnBorrow}" /&gt; &lt;/bean&gt; 3.使用构造函数注入的方法注入 &lt;bean id="jedisCluster" class="redis.clients.jedis.JedisCluster"&gt; &lt;constructor-arg name="node" ref="node"/&gt; &lt;constructor-arg name="connectionTimeout" value="300" /&gt; &lt;constructor-arg name="soTimeout" value="300" /&gt; &lt;constructor-arg name="maxAttempts" value="10" /&gt; &lt;constructor-arg name="password" value="123456" /&gt; &lt;constructor-arg name="poolConfig" ref="genericObjectPoolConfig"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/4c598124b41ed4f57d2a0b5f9a0bf42b/" rel="bookmark">
			SQL 获取每一组第一条记录
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 根据分组取出每个分组的第一条记录数据
1.先将数据分组并对每一组进行排序；
over(partition by 分组字段 order by 排序字段)
2.根据需要获取序号1的数据
SELECT * FROM ( SELECT RECEIVE_ID,LINE_CD,REC_TIME ,ROW_NUMBER() over(partition by LINE_CD order by REC_TIME DESC) as NEWINDEX FROM MES_BM_RECEIVE ) t where t.NEWINDEX = 1 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/92aec91912f0c62aeb8fbfa0aa6007c4/" rel="bookmark">
			JVM总结（三）Minor GC、Major GC和Full GC
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人却想出来。
一、Minor GC Minor GC是指从年轻代空间（包括 Eden 和 Survivor 区域）回收内存。当 JVM 无法为一个新的对象分配空间时会触发 Minor GC，比如当 Eden 区满了。 Eden区满了触发MinorGC，这时会把Eden区存活的对象复制到Survivor区，当对象在Survivor区熬过一定次数的Minor GC之后，就会晋升到老年代（当然并不是所有的对象都是这样晋升的到老年代的），当老年代满了，就会报OutofMemory异常。所有的MinorGC都会触发全世界的暂停（stop-the-world），停止应用程序的线程，不过这个过程非常短暂。 执行 Minor GC 操作时，不会影响到永久代。 二、Major GC vs Full GC 在目前的项目中还没有明确的定义，这点需要注意。JVM规范和垃圾收集研究论文都没有提及，但是乍一看，这些建立在我们掌握了Minor GC清理新生代上的定义并非难事：
Major GC清理Tenured区(老年代)。Full GC清理整个heap区，包括Yong区和Tenured区。 Full GC触发条件 （1）调用System.gc时，系统建议执行Full GC，但是不必然执行 （2）老年代空间不足 （3）方法去空间不足 （4）通过Minor GC后进入老年代的平均大小 &gt; 老年代的可用内存 （5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。即老年代无法存放下新年代过度到老年代的对象的时候，会触发Full GC。
补充 以上的GC总结，只是在非并发GC的触发条件下的大致原理。真正的GC情况跟实际GC器的回收机制有关。不同的GC器对Major GC 和 Full GC 的机制还是有区别的。如JVM中Serial GC, Parallel GC, CMS, G1 GC。会在后续的总结中去总结。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/414af92a2c6fa2bf91d855c884b720d3/" rel="bookmark">
			Swift右滑返回时候与scrollview滑动冲突的问题
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		scrollView.panGestureRecognizer.require(toFail: (self.navigationController?.interactivePopGestureRecognizer)!)
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/1e06e2a8fc2982c9211daa5dec8411d3/" rel="bookmark">
			八、设置VIM编辑器
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		这里需要简单配置一下Linux下的编辑利器VIM。这一节的目标是开启VIM的语法高亮、显示光标所在的位置以及自动缩进选项。
完整的VIM编辑器需要安装四个包：
vim-filesystem
vim-common
vim-enhanced
vim-minimal
可惜我们在安装完CentOS之后，系统默认自带的是vim-minimal也就是最小安装版。而最小安装版时不支持语法高亮和自动缩进的。
你可以通过以下命令查看本机已经存在的包，确认以下你的VIM是否已经安装：
rpm -qa|grep vim
如果vim已经正确安装，则会显示上面四个包的名称。
可以看到这里只显示vim-minimal：
所以需要补充安装vim-filesystem、vim-common和vim-enhanced，执行以下命令，系统就会自动安装其它的组件：
yum -y install vim-enhanced
看，已经齐全了：
设置vim编辑环境有两种形式：
一种直接修改/etc/vimrc文件，这种设置方法会作用与所有登陆到Linux环境下的用户。另一种是在用户登录的~目录下创建一个.vimrc，文件，在其中进行自己习惯的编程环境的设置，这样当别的用户使用时并不相互影响。
一般情况下我们不提倡第一种方式，因为Linux是多用户的，每个人都有自己的编程习惯与环境，你不能强迫别人按你的风格和习惯来做事，因此在工作环境中我们提倡使用第一种设置方式。
不过在虚拟机就自己学习使用而已，所以这里采用第一种方案——修改/etc/vimrc文件。
其实默认的语法高亮以及光标位置已经默认打开，我们只需要再多加一个自动缩进就OK了！
做法：
vim /etc/vimrc
增加：
set cindent
设置了cindent选项。VIM便会根据C语言自动地调整缩进长度了。
最后，su ethan 切换到普通账号，输入alias命令确认下是否为vim取了"别名"vi：
如果没有的话输入命令alias vi = vim 即可，这样以后我们就可以少打一个字母了....
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/359d52fae834c7cbe638e22cc419cb5e/" rel="bookmark">
			React native version mismatch 解决方法
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 React Native version mismatch.
JavaScript version: 0.51.0
Native version: 0.49.5
根据错误提示是因为项目中RN版本过低导致
解决方法：更新项目中的RN版本至最新版本。
执行如下命令：
npm install --save react-native@0.51.0 版本不同，构建的项目模板也会发生变化，所以在更新了React Native版本之后，也要及时更新项目模板。 通过如下命令：
react-native upgrade 
	</div>
</article>
</main>

<div class="pagination">
	<a class="pagination__item pagination__item--prev btn" href="/page/513/">«</a>
	<span class="pagination__item pagination__item--current">514/578</span>
	<a class="pagination__item pagination__item--next btn" href="/page/515/">»</a>
</div>

			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程随想.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script src="https://www.w3counter.com/tracker.js?id=151182"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>